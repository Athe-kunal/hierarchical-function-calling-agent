{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "api_page = requests.get(\"https://scikit-learn.org/1.4/modules/classes.html\")\n",
    "soup = BeautifulSoup(api_page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2_elements = soup.find_all('h2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = []\n",
    "for i in range(len(h2_elements) - 1):\n",
    "    section = []\n",
    "    for sibling in h2_elements[i].next_siblings:\n",
    "        if sibling == h2_elements[i + 1]:\n",
    "            break\n",
    "        section.append(str(sibling))\n",
    "    section_text = ''.join(section)\n",
    "    sections.append(BeautifulSoup(section_text, 'lxml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "    text = re.sub(\"\\xa0\",\"\",text)\n",
    "    text = re.sub(\"¶\",\"\",text)\n",
    "    text = re.sub(\"\\n\",\"\",text)\n",
    "    return text.strip()\n",
    "def get_links(*,sub_section_elem,class_name,base_func_url,title):\n",
    "    curr_urls = []\n",
    "    try:\n",
    "        func_urls = sub_section_elem.find_all(attrs={\"class\": class_name})\n",
    "        for curr_url in func_urls:\n",
    "            try:\n",
    "                func_url = curr_url.find(\"a\")[\"href\"]\n",
    "                func_text = curr_url.text\n",
    "                if func_text.find(\")\") == -1:\n",
    "                    separator = \"\\n\"\n",
    "                else:\n",
    "                    separator = \")\"\n",
    "                func_name,func_desc = func_text[:func_text.find(separator)+1].strip(\"\\n\"),func_text[func_text.find(separator)+1:].strip(\"\\n\")\n",
    "                # curr_urls.append(base_func_url + func_url)\n",
    "                curr_urls.append({\"name\":func_name,\"description\":func_desc, \"url\":base_func_url + func_url})\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(title.text)\n",
    "        return curr_urls\n",
    "    except Exception as e:\n",
    "        curr_url = sub_section_elem.find(attrs={\"class\": class_name})\n",
    "        func_url = curr_url.find('a')[\"href\"]\n",
    "        func_text = curr_url.text\n",
    "        if func_text.find(\")\") == -1:\n",
    "            separator = \"\\n\"\n",
    "        else:\n",
    "            separator = \")\"\n",
    "        func_name,func_desc = func_text[:func_text.find(separator)+1].strip(\"\\n\"),func_text[func_text.find(separator)+1:].strip(\"\\n\")\n",
    "        curr_urls.append({\"name\":clean_text(func_name),\"description\":func_desc, \"url\":base_func_url + func_url})\n",
    "        return curr_urls\n",
    "    finally:\n",
    "        return curr_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_level_dict(h3_titles_list,base_sklearn_url):\n",
    "    sub_level_dict = {}\n",
    "    for idx,h3_title in enumerate(h3_titles_list):\n",
    "        h3_title_text = clean_text(h3_title.text)\n",
    "        title_siblings = []\n",
    "        # If it is not the last element\n",
    "        if idx != len(h3_titles_list)-1:\n",
    "            for title_functions_siblings in h3_title.next_siblings:\n",
    "                if title_functions_siblings == h3_titles_list[idx+1]: break\n",
    "                title_siblings.append(str(title_functions_siblings))\n",
    "            title_siblings_text = ''.join(title_siblings)\n",
    "            title_siblings_soup = BeautifulSoup(title_siblings_text, 'lxml')\n",
    "        else:\n",
    "            for title_functions_siblings in h3_title.next_siblings:\n",
    "                title_siblings.append(str(title_functions_siblings))\n",
    "            title_siblings_text = ''.join(title_siblings)\n",
    "            title_siblings_soup = BeautifulSoup(title_siblings_text, 'lxml')\n",
    "        odd_urls = get_links(sub_section_elem=title_siblings_soup,class_name=\"row-odd\",base_func_url=base_sklearn_url,title=h3_title)\n",
    "        even_urls = get_links(sub_section_elem=title_siblings_soup,class_name=\"row-even\",base_func_url=base_sklearn_url,title=h3_title)\n",
    "        all_urls = odd_urls + even_urls\n",
    "        sub_level_dict.update({h3_title_text:{'functions':all_urls}})\n",
    "    return sub_level_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "# parent_dict = {}\n",
    "# pbar = tqdm(total=len(h2_elements[:-1]),desc=\"Scraping Sklearn\")\n",
    "# for sub_section_h2,sub_section in zip(h2_elements[:-1],sections):\n",
    "#     base_sklearn_url = \"https://scikit-learn.org/stable/modules/\"\n",
    "#     base_parent_url = \"https://scikit-learn.org/stable/modules/classes.html\"\n",
    "#     # sub_section = sections[1]\n",
    "#     # sub_section_h2 = h2_elements[1]\n",
    "#     parent_class_href = sub_section_h2.find('a')['href']\n",
    "#     parent_name = clean_text(sub_section_h2.text)\n",
    "#     parent_function = parent_name.split(\":\")[0]\n",
    "#     parent_name = parent_name.split(\":\")[1].strip()\n",
    "#     parent_text = \" \".join([para.text for para in sub_section.find_all('p')])\n",
    "#     if \"h3\" in str(sub_section):\n",
    "#         try:\n",
    "#             h3_titles_list = sub_section.find_all('h3')\n",
    "#             sub_level_dict = get_sub_level_dict(h3_titles_list,base_sklearn_url)\n",
    "#         except:\n",
    "#             h3_titles_list = [sub_section.find('h3')]\n",
    "#         sub_level_dict = get_sub_level_dict(h3_titles_list,base_sklearn_url)\n",
    "#         for sub_level,vals in sub_level_dict.items():\n",
    "#             if vals['functions'] == []:\n",
    "#                 odd_urls = get_links(sub_section_elem=sub_section,class_name=\"row-odd\",base_func_url=base_sklearn_url,title=sub_section_h2)\n",
    "#                 even_urls = get_links(sub_section_elem=sub_section,class_name=\"row-even\",base_func_url=base_sklearn_url,title=sub_section_h2)\n",
    "#                 all_urls = odd_urls + even_urls\n",
    "#                 sub_level_dict = {parent_name:{'functions':all_urls}}\n",
    "#     elif \"h3\" not in str(sub_section):\n",
    "#         odd_urls = get_links(sub_section_elem=sub_section,class_name=\"row-odd\",base_func_url=base_sklearn_url,title=sub_section_h2)\n",
    "#         even_urls = get_links(sub_section_elem=sub_section,class_name=\"row-even\",base_func_url=base_sklearn_url,title=sub_section_h2)\n",
    "#         all_urls = odd_urls + even_urls\n",
    "#         sub_level_dict = {parent_name:{'functions':all_urls}}\n",
    "#     parent_dict.update({parent_name:{\"functions\":parent_function,\"url\":base_parent_url+parent_class_href,\"sub_level_dict\":sub_level_dict,\"parent_text\":parent_text}})\n",
    "#     pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Sklearn:   0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Sklearn:  59%|█████▉    | 23/39 [00:00<00:00, 179.54it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "parent_dict = {}\n",
    "pbar = tqdm(total=len(h2_elements[:-1]),desc=\"Scraping Sklearn\")\n",
    "for sub_section_h2,sub_section in zip(h2_elements[:-1],sections):\n",
    "    base_sklearn_url = \"https://scikit-learn.org/stable/modules/\"\n",
    "    base_parent_url = \"https://scikit-learn.org/stable/modules/classes.html\"\n",
    "    # sub_section = sections[1]\n",
    "    # sub_section_h2 = h2_elements[1]\n",
    "    parent_class_href = sub_section_h2.find('a')['href']\n",
    "    parent_name = clean_text(sub_section_h2.text)\n",
    "    parent_function = clean_text(parent_name.split(\":\")[0])\n",
    "    parent_name = parent_name.split(\":\")[1].strip()\n",
    "    parent_text = \" \".join([para.text for para in sub_section.find_all('p')])\n",
    "    try:\n",
    "        default_funcs = []\n",
    "        default_vals_list = []\n",
    "        defaul_vals = sub_section.find_all(class_=\"autosummary longtable docutils align-default\")\n",
    "        for df in defaul_vals:\n",
    "            ourl = get_links(sub_section_elem=sub_section,class_name=\"row-odd\",base_func_url=base_sklearn_url,title=sub_section_h2)\n",
    "            eurl = get_links(sub_section_elem=sub_section,class_name=\"row-even\",base_func_url=base_sklearn_url,title=sub_section_h2)\n",
    "            default_funcs.extend(ourl + eurl)\n",
    "        parent_dict.update({parent_name:{\"base_function\":parent_function,\"url\":base_parent_url+parent_class_href,\"functions\":default_funcs,\"parent_text\":parent_text}})\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    if \"h3\" in str(sub_section):\n",
    "        try:\n",
    "            h3_titles_list = sub_section.find_all('h3')\n",
    "        except:\n",
    "            h3_titles_list = [sub_section.find('h3')]\n",
    "        sub_level_dict = get_sub_level_dict(h3_titles_list,base_sklearn_url)\n",
    "        parent_dict[parent_name].update({\"sub_level_dict\":sub_level_dict})\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from markdownify import MarkdownConverter\n",
    "\n",
    "# Create shorthand method for conversion\n",
    "def md(soup, **options):\n",
    "    return MarkdownConverter(**options).convert_soup(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# import sys\n",
    "\n",
    "# def normalize_newlines(paragraph):\n",
    "#     normalized_paragraph = re.sub(r'\\n+', '\\n\\n', paragraph)\n",
    "#     return normalized_paragraph\n",
    "# def remove_links(soup):\n",
    "#         links = soup.find_all('a')\n",
    "#         for link in links:\n",
    "#             link.decompose()\n",
    "        \n",
    "#         return soup\n",
    "# def get_py_obj(base_func_url,parent_name):\n",
    "#     func_url = requests.get(base_func_url)\n",
    "#     func_soup = BeautifulSoup(func_url.content, 'lxml')\n",
    "#     func_name = clean_text(func_soup.find('h1').text)\n",
    "#     func_signature_elem = func_soup.find(class_=\"sig sig-object py\")\n",
    "#     if func_signature_elem is not None:\n",
    "#         func_signature = clean_text(func_signature_elem.text)\n",
    "#     else:\n",
    "#         func_signature = \"\"\n",
    "#     all_urls = []\n",
    "#     page_dict = {\"func_name\":func_name,\"func_signature\":func_signature}\n",
    "#     try:\n",
    "#         if func_soup.find(class_=\"py class\"):\n",
    "#             class_or_fn = \"py class\"\n",
    "#             type = \"class\"\n",
    "#         elif func_soup.find(class_=\"py function\"):\n",
    "#             class_or_fn = \"py function\"\n",
    "#             type = \"function\"\n",
    "#         py_soup = func_soup.find(class_=class_or_fn)\n",
    "#         func_text_list = []\n",
    "#         dd = py_soup.find('dd')\n",
    "#         field_list = dd.find(class_=\"field-list\")\n",
    "\n",
    "#         for i in field_list.previous_siblings:\n",
    "#             func_text_list.append(i.text)\n",
    "#         func_text = \"\".join(func_text_list[::-1]).replace(\"\\n\",\" \").strip()\n",
    "#         page_dict.update({\"func_text\":func_text})\n",
    "#         for url in py_soup.find_all('a'):\n",
    "#             url = url['href']\n",
    "#             if url is None: continue\n",
    "#             elif url.startswith(\"#\"):\n",
    "#                 all_urls.append(base_func_url + url)\n",
    "#             elif url.startswith(\"..\"):\n",
    "#                 continue\n",
    "#             elif url.startswith(\"http\"):\n",
    "#                 all_urls.append(url)\n",
    "#         py_soup = remove_links(py_soup)\n",
    "#         py_md = normalize_newlines(md(py_soup))\n",
    "#         page_dict.update({\"func_md\":py_md,\"type\":type})\n",
    "#         fodd = field_list.find_all(class_=\"field-odd\")\n",
    "#         if fodd[0].text == \"Parameters\":\n",
    "#             dts = fodd[1].find_all('dt')\n",
    "#             paremter_names_desc = {}\n",
    "\n",
    "#             for idx,dt in enumerate(dts):\n",
    "#                 param_name = dt.find('strong').text\n",
    "#                 param_type = dt.find(class_=\"classifier\").text\n",
    "#                 param_desc = \"\"\n",
    "#                 for next_sib in dt.next_siblings:\n",
    "#                     if idx == len(dts)-1:\n",
    "#                         pass\n",
    "#                     else:\n",
    "#                         if next_sib == dts[idx+1]:\n",
    "#                             break\n",
    "#                     next_sib = str(next_sib)\n",
    "#                     param_desc += next_sib[next_sib.find(\"<p>\"):next_sib.find(\"</p>\")]\n",
    "#                 paremter_names_desc.update({param_name:{\"param_type\":param_type,\"params_desc\":param_desc}})\n",
    "#             page_dict.update({\"paremter_names_desc\":paremter_names_desc})\n",
    "#     except Exception as e:\n",
    "#         print(e,parent_name)\n",
    "#         return page_dict\n",
    "\n",
    "# pbar_ = tqdm(total=len(list(parent_dict.keys())))\n",
    "# for parent_name,parent_vals in parent_dict.items():\n",
    "#     if 'functions' in parent_vals:\n",
    "#         for func in parent_vals['functions']:\n",
    "#             func_url = func['url']\n",
    "#             web_page_res = get_py_obj(func_url,parent_name)\n",
    "#             if web_page_res is not None:\n",
    "#                 for k,v in web_page_res.items():\n",
    "#                     func.update({k:v})\n",
    "#     if 'sub_level_dict' in parent_vals:\n",
    "#         for sub_level_name,sub_level_vals in parent_vals['sub_level_dict'].items():\n",
    "#             if 'functions' in sub_level_vals:\n",
    "#                 for func in sub_level_vals['functions']:\n",
    "#                     func_url = func['url']\n",
    "#                     web_page_res = get_py_obj(func_url,parent_name)\n",
    "#                     if web_page_res is not None:\n",
    "#                         for k,v in web_page_res.items():\n",
    "#                             func.update({k:v})\n",
    "#     pbar_.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "base_url = \"https://scikit-learn.org/stable/api/index.html\"\n",
    "response = requests.get(base_url)\n",
    "soup = BeautifulSoup(response.text, \"lxml\")\n",
    "l1_elems = soup.find_all(class_=\"toctree-l1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://scikit-learn.org/stable/api/index.html\"\n",
    "base_parent_url = \"https://scikit-learn.org/stable/\"\n",
    "response = requests.get(base_url)\n",
    "soup = BeautifulSoup(response.text, \"lxml\")\n",
    "base_func_url = \"https://pandas.pydata.org/docs/reference/\"\n",
    "l1_elems = soup.find_all(class_=\"toctree-l1\")\n",
    "\n",
    "first_level = {}\n",
    "curr_parent = \"\"\n",
    "for parent_functions in l1_elems:\n",
    "    for func in parent_functions.find_all(\"a\"):\n",
    "        href = func[\"href\"]\n",
    "        if \"..\" not in href:\n",
    "            first_level.update(\n",
    "                {\n",
    "                    href: {\n",
    "                        \"functions\": [],\n",
    "                        \"name\": func.text,\n",
    "                        \"url\": base_parent_url +\"api/\" + href,\n",
    "                    }\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(id_elem, class_name):\n",
    "    def process_link(link):\n",
    "        link = link.replace(\"..\",\"\")\n",
    "        return \"https://scikit-learn.org/stable\"+link\n",
    "    curr_urls = []\n",
    "    try:\n",
    "        func_urls = id_elem.find_all(attrs={\"class\": class_name})\n",
    "        for url in func_urls:\n",
    "            curr_url_dict = {}\n",
    "            # funcs_params = url.find_all('td')\n",
    "            # func_name = funcs_params[0].text\n",
    "            # curr_url_dict.update({\"func_name\":func_name})\n",
    "            # func_desc = funcs_params[1].text\n",
    "            # curr_url_dict.update({\"func_desc\":func_desc})\n",
    "            try:\n",
    "                func_url = url.find(\"a\")[\"href\"]\n",
    "                curr_url_dict.update({\"func_url\":process_link(func_url)})\n",
    "                curr_urls.append(curr_url_dict)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(url)\n",
    "                print(\"-\" * 100)\n",
    "        return curr_urls\n",
    "    except Exception as e:\n",
    "        func_urls = id_elem.find(attrs={\"class\": class_name})\n",
    "        curr_url_dict = {}\n",
    "        # funcs_params = url.find_all('td')\n",
    "        # func_name = funcs_params[0].text\n",
    "        # curr_url_dict.update({\"func_name\":func_name})\n",
    "        # func_desc = funcs_params[1].text\n",
    "        # curr_url_dict.update({\"func_desc\":func_desc})\n",
    "        func_url = func_urls.find(\"a\")[\"href\"]\n",
    "        curr_url_dict.update({\"func_url\":process_link(func_url)})\n",
    "        return [curr_url_dict]\n",
    "    finally:\n",
    "        return curr_urls\n",
    "\n",
    "def get_odd_even_urls(id_elem):\n",
    "    odd_urls = get_links(id_elem,\"row-odd\")\n",
    "    even_urls = get_links(id_elem,\"row-even\")\n",
    "    return odd_urls + even_urls\n",
    "\n",
    "# parent_name = \"sklearn.feature_extraction.html\"\n",
    "for parent_name,first_vals in first_level.items():\n",
    "    parent_page = requests.get(first_level[parent_name]['url'])\n",
    "    parent_soup = BeautifulSoup(parent_page.content, 'lxml',from_encoding=\"utf-8\")\n",
    "    func_text = parent_soup.find('h1').text.replace(\"#\",\"\")\n",
    "    parent_id = parent_name.rpartition(\".\")[0]\n",
    "    if \"<h2>\" in str(parent_soup):\n",
    "        all_urls_dict = []\n",
    "        h2_elements = parent_soup.find_all(\"h2\")\n",
    "        default_func_table = parent_soup.find(id=f\"module-{parent_id}\").find(class_=\"autosummary longtable table autosummary\",recursive=False)\n",
    "        # tables = parent_soup.find_all(class_=\"autosummary longtable table autosummary\")\n",
    "        h2_elements = parent_soup.find_all('h2')\n",
    "        h2_sections = []\n",
    "        for idx,h2 in enumerate(h2_elements):\n",
    "            curr_h2_sections = []\n",
    "            if idx == len(h2_elements)-1:\n",
    "                for next_sib in h2.next_siblings:\n",
    "                    curr_h2_sections.append(str(next_sib))\n",
    "            else: \n",
    "                for next_sib in h2.next_siblings:\n",
    "                    if h2.next_sibling != h2_elements[idx+1]:\n",
    "                        curr_h2_sections.append(str(next_sib))\n",
    "                    else:\n",
    "                        break\n",
    "            section_text = \"\".join(curr_h2_sections)\n",
    "            h2_sections.append(BeautifulSoup(section_text))\n",
    "        if default_func_table is not None:\n",
    "            default_urls = get_odd_even_urls(default_func_table)\n",
    "            default_dict = {\"defaults\":default_urls}\n",
    "            all_urls_dict.append(default_dict) \n",
    "            # Skip the first table as it is default table\n",
    "            # tables = tables[1:]  \n",
    "        assert len(h2_sections) == len(h2_elements), f\"Assertion error for {parent_name}, number of heading 2 elements is {len(h2_elements)} and number of tables is {len(h2_sections)}\"\n",
    "        h2_elems_list = [h2.text.replace(\"#\",\"\") for h2 in h2_elements]\n",
    "        for tb,h2 in zip(h2_sections,h2_elems_list):\n",
    "            all_urls_dict.append({h2:get_odd_even_urls(tb)})\n",
    "    else:\n",
    "        tables = parent_soup.find(class_=\"autosummary longtable table autosummary\")\n",
    "        all_urls_dict = [{\"defaults\":get_odd_even_urls(tables)}]\n",
    "    first_level[parent_name]['functions'] = all_urls_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sklearn.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.config_context.html#sklearn.config_context'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.set_config.html#sklearn.set_config'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.get_config.html#sklearn.get_config'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.show_versions.html#sklearn.show_versions'}]}],\n",
       "  'name': 'sklearn',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.html'},\n",
       " 'sklearn.base.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html#sklearn.base.BaseEstimator'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.base.ClassNamePrefixFeaturesOutMixin.html#sklearn.base.ClassNamePrefixFeaturesOutMixin'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.base.ClusterMixin.html#sklearn.base.ClusterMixin'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.base.MetaEstimatorMixin.html#sklearn.base.MetaEstimatorMixin'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.base.OutlierMixin.html#sklearn.base.OutlierMixin'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.base.TransformerMixin.html#sklearn.base.TransformerMixin'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.base.is_classifier.html#sklearn.base.is_classifier'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.base.BiclusterMixin.html#sklearn.base.BiclusterMixin'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.base.ClassifierMixin.html#sklearn.base.ClassifierMixin'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.base.DensityMixin.html#sklearn.base.DensityMixin'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.base.OneToOneFeatureMixin.html#sklearn.base.OneToOneFeatureMixin'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.base.RegressorMixin.html#sklearn.base.RegressorMixin'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.base.is_regressor.html#sklearn.base.is_regressor'}]}],\n",
       "  'name': 'sklearn.base',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.base.html'},\n",
       " 'sklearn.calibration.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibratedClassifierCV.html#sklearn.calibration.CalibratedClassifierCV'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.calibration.calibration_curve.html#sklearn.calibration.calibration_curve'}]},\n",
       "   {'Visualization': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibrationDisplay.html#sklearn.calibration.CalibrationDisplay'}]}],\n",
       "  'name': 'sklearn.calibration',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.calibration.html'},\n",
       " 'sklearn.cluster.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AffinityPropagation.html#sklearn.cluster.AffinityPropagation'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.cluster.Birch.html#sklearn.cluster.Birch'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.cluster.HDBSCAN.html#sklearn.cluster.HDBSCAN'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MeanShift.html#sklearn.cluster.MeanShift'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.cluster.OPTICS.html#sklearn.cluster.OPTICS'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralClustering.html#sklearn.cluster.SpectralClustering'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.cluster.affinity_propagation.html#sklearn.cluster.affinity_propagation'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.cluster.cluster_optics_xi.html#sklearn.cluster.cluster_optics_xi'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/dbscan-function.html#sklearn.cluster.dbscan'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.cluster.k_means.html#sklearn.cluster.k_means'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.cluster.mean_shift.html#sklearn.cluster.mean_shift'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.cluster.ward_tree.html#sklearn.cluster.ward_tree'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.cluster.BisectingKMeans.html#sklearn.cluster.BisectingKMeans'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.cluster.FeatureAgglomeration.html#sklearn.cluster.FeatureAgglomeration'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MiniBatchKMeans.html#sklearn.cluster.MiniBatchKMeans'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralBiclustering.html#sklearn.cluster.SpectralBiclustering'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralCoclustering.html#sklearn.cluster.SpectralCoclustering'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.cluster.cluster_optics_dbscan.html#sklearn.cluster.cluster_optics_dbscan'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.cluster.compute_optics_graph.html#sklearn.cluster.compute_optics_graph'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.cluster.estimate_bandwidth.html#sklearn.cluster.estimate_bandwidth'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.cluster.kmeans_plusplus.html#sklearn.cluster.kmeans_plusplus'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.cluster.spectral_clustering.html#sklearn.cluster.spectral_clustering'}]}],\n",
       "  'name': 'sklearn.cluster',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.cluster.html'},\n",
       " 'sklearn.compose.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.compose.make_column_selector.html#sklearn.compose.make_column_selector'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.compose.TransformedTargetRegressor.html#sklearn.compose.TransformedTargetRegressor'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.compose.make_column_transformer.html#sklearn.compose.make_column_transformer'}]}],\n",
       "  'name': 'sklearn.compose',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.compose.html'},\n",
       " 'sklearn.covariance.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.covariance.EllipticEnvelope.html#sklearn.covariance.EllipticEnvelope'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.covariance.GraphicalLasso.html#sklearn.covariance.GraphicalLasso'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.covariance.LedoitWolf.html#sklearn.covariance.LedoitWolf'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.covariance.OAS.html#sklearn.covariance.OAS'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.covariance.empirical_covariance.html#sklearn.covariance.empirical_covariance'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.covariance.ledoit_wolf.html#sklearn.covariance.ledoit_wolf'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/oas-function.html#sklearn.covariance.oas'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.covariance.EmpiricalCovariance.html#sklearn.covariance.EmpiricalCovariance'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.covariance.GraphicalLassoCV.html#sklearn.covariance.GraphicalLassoCV'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.covariance.MinCovDet.html#sklearn.covariance.MinCovDet'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.covariance.ShrunkCovariance.html#sklearn.covariance.ShrunkCovariance'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.covariance.graphical_lasso.html#sklearn.covariance.graphical_lasso'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.covariance.ledoit_wolf_shrinkage.html#sklearn.covariance.ledoit_wolf_shrinkage'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.covariance.shrunk_covariance.html#sklearn.covariance.shrunk_covariance'}]}],\n",
       "  'name': 'sklearn.covariance',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.covariance.html'},\n",
       " 'sklearn.cross_decomposition.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.cross_decomposition.CCA.html#sklearn.cross_decomposition.CCA'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.cross_decomposition.PLSRegression.html#sklearn.cross_decomposition.PLSRegression'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.cross_decomposition.PLSCanonical.html#sklearn.cross_decomposition.PLSCanonical'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.cross_decomposition.PLSSVD.html#sklearn.cross_decomposition.PLSSVD'}]}],\n",
       "  'name': 'sklearn.cross_decomposition',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.cross_decomposition.html'},\n",
       " 'sklearn.datasets.html': {'functions': [{'Loaders': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.clear_data_home.html#sklearn.datasets.clear_data_home'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html#sklearn.datasets.fetch_20newsgroups'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html#sklearn.datasets.fetch_california_housing'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_kddcup99.html#sklearn.datasets.fetch_kddcup99'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_lfw_people.html#sklearn.datasets.fetch_lfw_people'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_openml.html#sklearn.datasets.fetch_openml'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_species_distributions.html#sklearn.datasets.fetch_species_distributions'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_sample_image.html#sklearn.datasets.load_sample_image'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_svmlight_file.html#sklearn.datasets.load_svmlight_file'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.dump_svmlight_file.html#sklearn.datasets.dump_svmlight_file'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups_vectorized.html#sklearn.datasets.fetch_20newsgroups_vectorized'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_covtype.html#sklearn.datasets.fetch_covtype'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_lfw_pairs.html#sklearn.datasets.fetch_lfw_pairs'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_olivetti_faces.html#sklearn.datasets.fetch_olivetti_faces'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_rcv1.html#sklearn.datasets.fetch_rcv1'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.get_data_home.html#sklearn.datasets.get_data_home'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_files.html#sklearn.datasets.load_files'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_linnerud.html#sklearn.datasets.load_linnerud'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_sample_images.html#sklearn.datasets.load_sample_images'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_svmlight_files.html#sklearn.datasets.load_svmlight_files'}]},\n",
       "   {'Sample generators': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_biclusters.html#sklearn.datasets.make_biclusters'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_checkerboard.html#sklearn.datasets.make_checkerboard'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html#sklearn.datasets.make_classification'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_friedman2.html#sklearn.datasets.make_friedman2'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_gaussian_quantiles.html#sklearn.datasets.make_gaussian_quantiles'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_low_rank_matrix.html#sklearn.datasets.make_low_rank_matrix'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_multilabel_classification.html#sklearn.datasets.make_multilabel_classification'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_s_curve.html#sklearn.datasets.make_s_curve'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_sparse_spd_matrix.html#sklearn.datasets.make_sparse_spd_matrix'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_spd_matrix.html#sklearn.datasets.make_spd_matrix'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html#sklearn.datasets.make_blobs'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_circles.html#sklearn.datasets.make_circles'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_friedman1.html#sklearn.datasets.make_friedman1'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_friedman3.html#sklearn.datasets.make_friedman3'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_hastie_10_2.html#sklearn.datasets.make_hastie_10_2'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html#sklearn.datasets.make_moons'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html#sklearn.datasets.make_regression'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_sparse_coded_signal.html#sklearn.datasets.make_sparse_coded_signal'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_sparse_uncorrelated.html#sklearn.datasets.make_sparse_uncorrelated'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_swiss_roll.html#sklearn.datasets.make_swiss_roll'}]}],\n",
       "  'name': 'sklearn.datasets',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.datasets.html'},\n",
       " 'sklearn.decomposition.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.DictionaryLearning.html#sklearn.decomposition.DictionaryLearning'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.FastICA.html#sklearn.decomposition.FastICA'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.KernelPCA.html#sklearn.decomposition.KernelPCA'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.MiniBatchDictionaryLearning.html#sklearn.decomposition.MiniBatchDictionaryLearning'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.MiniBatchSparsePCA.html#sklearn.decomposition.MiniBatchSparsePCA'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.SparsePCA.html#sklearn.decomposition.SparsePCA'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.dict_learning.html#sklearn.decomposition.dict_learning'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/fastica-function.html#sklearn.decomposition.fastica'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.sparse_encode.html#sklearn.decomposition.sparse_encode'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.FactorAnalysis.html#sklearn.decomposition.FactorAnalysis'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.IncrementalPCA.html#sklearn.decomposition.IncrementalPCA'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#sklearn.decomposition.LatentDirichletAllocation'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.MiniBatchNMF.html#sklearn.decomposition.MiniBatchNMF'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html#sklearn.decomposition.NMF'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.SparseCoder.html#sklearn.decomposition.SparseCoder'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html#sklearn.decomposition.TruncatedSVD'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.dict_learning_online.html#sklearn.decomposition.dict_learning_online'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.non_negative_factorization.html#sklearn.decomposition.non_negative_factorization'}]}],\n",
       "  'name': 'sklearn.decomposition',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.decomposition.html'},\n",
       " 'sklearn.discriminant_analysis.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html#sklearn.discriminant_analysis.LinearDiscriminantAnalysis'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis'}]}],\n",
       "  'name': 'sklearn.discriminant_analysis',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.discriminant_analysis.html'},\n",
       " 'sklearn.dummy.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html#sklearn.dummy.DummyClassifier'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyRegressor.html#sklearn.dummy.DummyRegressor'}]}],\n",
       "  'name': 'sklearn.dummy',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.dummy.html'},\n",
       " 'sklearn.ensemble.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html#sklearn.ensemble.BaggingClassifier'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html#sklearn.ensemble.ExtraTreesClassifier'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingClassifier.html#sklearn.ensemble.HistGradientBoostingClassifier'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html#sklearn.ensemble.IsolationForest'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html#sklearn.ensemble.StackingClassifier'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html#sklearn.ensemble.VotingClassifier'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html#sklearn.ensemble.AdaBoostRegressor'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html#sklearn.ensemble.BaggingRegressor'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html#sklearn.ensemble.ExtraTreesRegressor'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#sklearn.ensemble.HistGradientBoostingRegressor'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomTreesEmbedding.html#sklearn.ensemble.RandomTreesEmbedding'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html#sklearn.ensemble.StackingRegressor'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingRegressor.html#sklearn.ensemble.VotingRegressor'}]}],\n",
       "  'name': 'sklearn.ensemble',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.ensemble.html'},\n",
       " 'sklearn.exceptions.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.exceptions.ConvergenceWarning.html#sklearn.exceptions.ConvergenceWarning'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.exceptions.DataDimensionalityWarning.html#sklearn.exceptions.DataDimensionalityWarning'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.exceptions.FitFailedWarning.html#sklearn.exceptions.FitFailedWarning'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.exceptions.NotFittedError.html#sklearn.exceptions.NotFittedError'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.exceptions.DataConversionWarning.html#sklearn.exceptions.DataConversionWarning'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.exceptions.EfficiencyWarning.html#sklearn.exceptions.EfficiencyWarning'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.exceptions.InconsistentVersionWarning.html#sklearn.exceptions.InconsistentVersionWarning'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.exceptions.UndefinedMetricWarning.html#sklearn.exceptions.UndefinedMetricWarning'}]}],\n",
       "  'name': 'sklearn.exceptions',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.exceptions.html'},\n",
       " 'sklearn.experimental.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.experimental.enable_halving_search_cv.html#module-sklearn.experimental.enable_halving_search_cv'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.experimental.enable_iterative_imputer.html#module-sklearn.experimental.enable_iterative_imputer'}]}],\n",
       "  'name': 'sklearn.experimental',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.experimental.html'},\n",
       " 'sklearn.feature_extraction.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html#sklearn.feature_extraction.DictVectorizer'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.FeatureHasher.html#sklearn.feature_extraction.FeatureHasher'}]},\n",
       "   {'From images': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.image.PatchExtractor.html#sklearn.feature_extraction.image.PatchExtractor'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.image.grid_to_graph.html#sklearn.feature_extraction.image.grid_to_graph'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.image.reconstruct_from_patches_2d.html#sklearn.feature_extraction.image.reconstruct_from_patches_2d'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.image.extract_patches_2d.html#sklearn.feature_extraction.image.extract_patches_2d'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.image.img_to_graph.html#sklearn.feature_extraction.image.img_to_graph'}]},\n",
       "   {'From text': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html#sklearn.feature_extraction.text.HashingVectorizer'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer'}]}],\n",
       "  'name': 'sklearn.feature_extraction',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.feature_extraction.html'},\n",
       " 'sklearn.feature_selection.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.GenericUnivariateSelect.html#sklearn.feature_selection.GenericUnivariateSelect'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFpr.html#sklearn.feature_selection.SelectFpr'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFwe.html#sklearn.feature_selection.SelectFwe'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectPercentile.html#sklearn.feature_selection.SelectPercentile'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html#sklearn.feature_selection.SequentialFeatureSelector'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html#sklearn.feature_selection.chi2'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html#sklearn.feature_selection.f_regression'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_regression.html#sklearn.feature_selection.mutual_info_regression'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html#sklearn.feature_selection.RFE'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFdr.html#sklearn.feature_selection.SelectFdr'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html#sklearn.feature_selection.SelectFromModel'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectorMixin.html#sklearn.feature_selection.SelectorMixin'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html#sklearn.feature_selection.VarianceThreshold'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html#sklearn.feature_selection.f_classif'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html#sklearn.feature_selection.mutual_info_classif'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.r_regression.html#sklearn.feature_selection.r_regression'}]}],\n",
       "  'name': 'sklearn.feature_selection',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.feature_selection.html'},\n",
       " 'sklearn.gaussian_process.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessClassifier.html#sklearn.gaussian_process.GaussianProcessClassifier'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.html#sklearn.gaussian_process.GaussianProcessRegressor'}]},\n",
       "   {'Kernels': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.CompoundKernel.html#sklearn.gaussian_process.kernels.CompoundKernel'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.DotProduct.html#sklearn.gaussian_process.kernels.DotProduct'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.Exponentiation.html#sklearn.gaussian_process.kernels.Exponentiation'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.Kernel.html#sklearn.gaussian_process.kernels.Kernel'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.PairwiseKernel.html#sklearn.gaussian_process.kernels.PairwiseKernel'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.RBF.html#sklearn.gaussian_process.kernels.RBF'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.Sum.html#sklearn.gaussian_process.kernels.Sum'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.ConstantKernel.html#sklearn.gaussian_process.kernels.ConstantKernel'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.ExpSineSquared.html#sklearn.gaussian_process.kernels.ExpSineSquared'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.Hyperparameter.html#sklearn.gaussian_process.kernels.Hyperparameter'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.Matern.html#sklearn.gaussian_process.kernels.Matern'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.Product.html#sklearn.gaussian_process.kernels.Product'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.RationalQuadratic.html#sklearn.gaussian_process.kernels.RationalQuadratic'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.WhiteKernel.html#sklearn.gaussian_process.kernels.WhiteKernel'}]}],\n",
       "  'name': 'sklearn.gaussian_process',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.gaussian_process.html'},\n",
       " 'sklearn.impute.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html#sklearn.impute.IterativeImputer'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.impute.MissingIndicator.html#sklearn.impute.MissingIndicator'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html#sklearn.impute.KNNImputer'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer'}]}],\n",
       "  'name': 'sklearn.impute',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.impute.html'},\n",
       " 'sklearn.inspection.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.inspection.partial_dependence.html#sklearn.inspection.partial_dependence'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html#sklearn.inspection.permutation_importance'}]},\n",
       "   {'Plotting': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.inspection.DecisionBoundaryDisplay.html#sklearn.inspection.DecisionBoundaryDisplay'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.inspection.PartialDependenceDisplay.html#sklearn.inspection.PartialDependenceDisplay'}]}],\n",
       "  'name': 'sklearn.inspection',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.inspection.html'},\n",
       " 'sklearn.isotonic.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.isotonic.IsotonicRegression.html#sklearn.isotonic.IsotonicRegression'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.isotonic.isotonic_regression.html#sklearn.isotonic.isotonic_regression'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.isotonic.check_increasing.html#sklearn.isotonic.check_increasing'}]}],\n",
       "  'name': 'sklearn.isotonic',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.isotonic.html'},\n",
       " 'sklearn.kernel_approximation.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.kernel_approximation.AdditiveChi2Sampler.html#sklearn.kernel_approximation.AdditiveChi2Sampler'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.kernel_approximation.PolynomialCountSketch.html#sklearn.kernel_approximation.PolynomialCountSketch'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.kernel_approximation.SkewedChi2Sampler.html#sklearn.kernel_approximation.SkewedChi2Sampler'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.kernel_approximation.Nystroem.html#sklearn.kernel_approximation.Nystroem'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.kernel_approximation.RBFSampler.html#sklearn.kernel_approximation.RBFSampler'}]}],\n",
       "  'name': 'sklearn.kernel_approximation',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.kernel_approximation.html'},\n",
       " 'sklearn.kernel_ridge.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html#sklearn.kernel_ridge.KernelRidge'}]}],\n",
       "  'name': 'sklearn.kernel_ridge',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.kernel_ridge.html'},\n",
       " 'sklearn.linear_model.html': {'functions': [{'Linear classifiers': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.PassiveAggressiveClassifier.html#sklearn.linear_model.PassiveAggressiveClassifier'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html#sklearn.linear_model.RidgeClassifier'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html#sklearn.linear_model.LogisticRegressionCV'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html#sklearn.linear_model.Perceptron'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifierCV.html#sklearn.linear_model.RidgeClassifierCV'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDOneClassSVM.html#sklearn.linear_model.SGDOneClassSVM'}]},\n",
       "   {'Classical linear regressors': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html#sklearn.linear_model.RidgeCV'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html#sklearn.linear_model.SGDRegressor'}]},\n",
       "   {'Regressors with variable selection': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html#sklearn.linear_model.ElasticNet'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lars.html#sklearn.linear_model.Lars'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoLars.html#sklearn.linear_model.LassoLars'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoLarsIC.html#sklearn.linear_model.LassoLarsIC'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.OrthogonalMatchingPursuitCV.html#sklearn.linear_model.OrthogonalMatchingPursuitCV'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNetCV.html#sklearn.linear_model.ElasticNetCV'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LarsCV.html#sklearn.linear_model.LarsCV'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html#sklearn.linear_model.LassoCV'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoLarsCV.html#sklearn.linear_model.LassoLarsCV'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.OrthogonalMatchingPursuit.html#sklearn.linear_model.OrthogonalMatchingPursuit'}]},\n",
       "   {'Bayesian regressors': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ARDRegression.html#sklearn.linear_model.ARDRegression'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.BayesianRidge.html#sklearn.linear_model.BayesianRidge'}]},\n",
       "   {'Multi-task linear regressors with variable selection': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.MultiTaskElasticNet.html#sklearn.linear_model.MultiTaskElasticNet'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.MultiTaskLasso.html#sklearn.linear_model.MultiTaskLasso'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.MultiTaskElasticNetCV.html#sklearn.linear_model.MultiTaskElasticNetCV'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.MultiTaskLassoCV.html#sklearn.linear_model.MultiTaskLassoCV'}]},\n",
       "   {'Outlier-robust regressors': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.HuberRegressor.html#sklearn.linear_model.HuberRegressor'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RANSACRegressor.html#sklearn.linear_model.RANSACRegressor'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.QuantileRegressor.html#sklearn.linear_model.QuantileRegressor'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.TheilSenRegressor.html#sklearn.linear_model.TheilSenRegressor'}]},\n",
       "   {'Generalized linear models (GLM) for regression': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.GammaRegressor.html#sklearn.linear_model.GammaRegressor'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.TweedieRegressor.html#sklearn.linear_model.TweedieRegressor'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.PoissonRegressor.html#sklearn.linear_model.PoissonRegressor'}]},\n",
       "   {'Miscellaneous': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.PassiveAggressiveRegressor.html#sklearn.linear_model.PassiveAggressiveRegressor'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.lars_path.html#sklearn.linear_model.lars_path'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.lasso_path.html#sklearn.linear_model.lasso_path'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.orthogonal_mp_gram.html#sklearn.linear_model.orthogonal_mp_gram'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.enet_path.html#sklearn.linear_model.enet_path'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.lars_path_gram.html#sklearn.linear_model.lars_path_gram'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.orthogonal_mp.html#sklearn.linear_model.orthogonal_mp'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ridge_regression.html#sklearn.linear_model.ridge_regression'}]}],\n",
       "  'name': 'sklearn.linear_model',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.linear_model.html'},\n",
       " 'sklearn.manifold.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.manifold.Isomap.html#sklearn.manifold.Isomap'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.manifold.MDS.html#sklearn.manifold.MDS'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html#sklearn.manifold.TSNE'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.manifold.smacof.html#sklearn.manifold.smacof'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.manifold.trustworthiness.html#sklearn.manifold.trustworthiness'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.manifold.LocallyLinearEmbedding.html#sklearn.manifold.LocallyLinearEmbedding'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.manifold.SpectralEmbedding.html#sklearn.manifold.SpectralEmbedding'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.manifold.locally_linear_embedding.html#sklearn.manifold.locally_linear_embedding'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.manifold.spectral_embedding.html#sklearn.manifold.spectral_embedding'}]}],\n",
       "  'name': 'sklearn.manifold',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.manifold.html'},\n",
       " 'sklearn.metrics.html': {'functions': [{'Model selection interface': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.check_scoring.html#sklearn.metrics.check_scoring'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.get_scorer_names.html#sklearn.metrics.get_scorer_names'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.get_scorer.html#sklearn.metrics.get_scorer'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html#sklearn.metrics.make_scorer'}]},\n",
       "   {'Classification metrics': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.brier_score_loss.html#sklearn.metrics.brier_score_loss'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.dcg_score.html#sklearn.metrics.dcg_score'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.hamming_loss.html#sklearn.metrics.hamming_loss'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.jaccard_score.html#sklearn.metrics.jaccard_score'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html#sklearn.metrics.matthews_corrcoef'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ndcg_score.html#sklearn.metrics.ndcg_score'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html#sklearn.metrics.precision_recall_fscore_support'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html#sklearn.metrics.roc_curve'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.zero_one_loss.html#sklearn.metrics.zero_one_loss'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html#sklearn.metrics.auc'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html#sklearn.metrics.balanced_accuracy_score'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.class_likelihood_ratios.html#sklearn.metrics.class_likelihood_ratios'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.cohen_kappa_score.html#sklearn.metrics.cohen_kappa_score'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.d2_log_loss_score.html#sklearn.metrics.d2_log_loss_score'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.det_curve.html#sklearn.metrics.det_curve'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.fbeta_score.html#sklearn.metrics.fbeta_score'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.hinge_loss.html#sklearn.metrics.hinge_loss'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html#sklearn.metrics.log_loss'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.multilabel_confusion_matrix.html#sklearn.metrics.multilabel_confusion_matrix'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.top_k_accuracy_score.html#sklearn.metrics.top_k_accuracy_score'}]},\n",
       "   {'Regression metrics': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.d2_absolute_error_score.html#sklearn.metrics.d2_absolute_error_score'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.d2_tweedie_score.html#sklearn.metrics.d2_tweedie_score'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.max_error.html#sklearn.metrics.max_error'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_percentage_error.html#sklearn.metrics.mean_absolute_percentage_error'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_pinball_loss.html#sklearn.metrics.mean_pinball_loss'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_tweedie_deviance.html#sklearn.metrics.mean_tweedie_deviance'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.root_mean_squared_log_error.html#sklearn.metrics.root_mean_squared_log_error'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.d2_pinball_score.html#sklearn.metrics.d2_pinball_score'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.explained_variance_score.html#sklearn.metrics.explained_variance_score'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_gamma_deviance.html#sklearn.metrics.mean_gamma_deviance'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_poisson_deviance.html#sklearn.metrics.mean_poisson_deviance'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_log_error.html#sklearn.metrics.mean_squared_log_error'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.median_absolute_error.html#sklearn.metrics.median_absolute_error'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.root_mean_squared_error.html#sklearn.metrics.root_mean_squared_error'}]},\n",
       "   {'Multilabel ranking metrics': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.coverage_error.html#sklearn.metrics.coverage_error'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.label_ranking_loss.html#sklearn.metrics.label_ranking_loss'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.label_ranking_average_precision_score.html#sklearn.metrics.label_ranking_average_precision_score'}]},\n",
       "   {'Clustering metrics': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_mutual_info_score.html#sklearn.metrics.adjusted_mutual_info_score'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.calinski_harabasz_score.html#sklearn.metrics.calinski_harabasz_score'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.cluster.pair_confusion_matrix.html#sklearn.metrics.cluster.pair_confusion_matrix'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.davies_bouldin_score.html#sklearn.metrics.davies_bouldin_score'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.homogeneity_completeness_v_measure.html#sklearn.metrics.homogeneity_completeness_v_measure'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mutual_info_score.html#sklearn.metrics.mutual_info_score'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.rand_score.html#sklearn.metrics.rand_score'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html#sklearn.metrics.silhouette_score'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html#sklearn.metrics.adjusted_rand_score'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.cluster.contingency_matrix.html#sklearn.metrics.cluster.contingency_matrix'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.completeness_score.html#sklearn.metrics.completeness_score'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.fowlkes_mallows_score.html#sklearn.metrics.fowlkes_mallows_score'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.homogeneity_score.html#sklearn.metrics.homogeneity_score'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.normalized_mutual_info_score.html#sklearn.metrics.normalized_mutual_info_score'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_samples.html#sklearn.metrics.silhouette_samples'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.v_measure_score.html#sklearn.metrics.v_measure_score'}]},\n",
       "   {'Biclustering metrics': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.consensus_score.html#sklearn.metrics.consensus_score'}]},\n",
       "   {'Distance metrics': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.DistanceMetric.html#sklearn.metrics.DistanceMetric'}]},\n",
       "   {'Pairwise metrics': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.additive_chi2_kernel.html#sklearn.metrics.pairwise.additive_chi2_kernel'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_distances.html#sklearn.metrics.pairwise.cosine_distances'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.distance_metrics.html#sklearn.metrics.pairwise.distance_metrics'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.haversine_distances.html#sklearn.metrics.pairwise.haversine_distances'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.laplacian_kernel.html#sklearn.metrics.pairwise.laplacian_kernel'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.manhattan_distances.html#sklearn.metrics.pairwise.manhattan_distances'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.paired_cosine_distances.html#sklearn.metrics.pairwise.paired_cosine_distances'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.paired_euclidean_distances.html#sklearn.metrics.pairwise.paired_euclidean_distances'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.pairwise_kernels.html#sklearn.metrics.pairwise.pairwise_kernels'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.rbf_kernel.html#sklearn.metrics.pairwise.rbf_kernel'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html#sklearn.metrics.pairwise_distances'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances_argmin_min.html#sklearn.metrics.pairwise_distances_argmin_min'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.chi2_kernel.html#sklearn.metrics.pairwise.chi2_kernel'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html#sklearn.metrics.pairwise.cosine_similarity'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.euclidean_distances.html#sklearn.metrics.pairwise.euclidean_distances'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.kernel_metrics.html#sklearn.metrics.pairwise.kernel_metrics'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.linear_kernel.html#sklearn.metrics.pairwise.linear_kernel'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.nan_euclidean_distances.html#sklearn.metrics.pairwise.nan_euclidean_distances'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.paired_distances.html#sklearn.metrics.pairwise.paired_distances'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.paired_manhattan_distances.html#sklearn.metrics.pairwise.paired_manhattan_distances'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.polynomial_kernel.html#sklearn.metrics.pairwise.polynomial_kernel'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.sigmoid_kernel.html#sklearn.metrics.pairwise.sigmoid_kernel'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances_argmin.html#sklearn.metrics.pairwise_distances_argmin'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances_chunked.html#sklearn.metrics.pairwise_distances_chunked'}]},\n",
       "   {'Plotting': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.PrecisionRecallDisplay.html#sklearn.metrics.PrecisionRecallDisplay'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.RocCurveDisplay.html#sklearn.metrics.RocCurveDisplay'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.DetCurveDisplay.html#sklearn.metrics.DetCurveDisplay'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.PredictionErrorDisplay.html#sklearn.metrics.PredictionErrorDisplay'}]}],\n",
       "  'name': 'sklearn.metrics',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.metrics.html'},\n",
       " 'sklearn.mixture.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.mixture.BayesianGaussianMixture.html#sklearn.mixture.BayesianGaussianMixture'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html#sklearn.mixture.GaussianMixture'}]}],\n",
       "  'name': 'sklearn.mixture',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.mixture.html'},\n",
       " 'sklearn.model_selection.html': {'functions': [{'Splitters': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html#sklearn.model_selection.GroupKFold'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html#sklearn.model_selection.LeaveOneOut'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeavePOut.html#sklearn.model_selection.LeavePOut'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedKFold.html#sklearn.model_selection.RepeatedKFold'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html#sklearn.model_selection.TimeSeriesSplit'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupShuffleSplit.html#sklearn.model_selection.GroupShuffleSplit'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneGroupOut.html#sklearn.model_selection.LeaveOneGroupOut'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeavePGroupsOut.html#sklearn.model_selection.LeavePGroupsOut'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.PredefinedSplit.html#sklearn.model_selection.PredefinedSplit'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedStratifiedKFold.html#sklearn.model_selection.RepeatedStratifiedKFold'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedGroupKFold.html#sklearn.model_selection.StratifiedGroupKFold'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html#sklearn.model_selection.StratifiedShuffleSplit'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.check_cv.html#sklearn.model_selection.check_cv'}]},\n",
       "   {'Hyper-parameter optimizers': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html#sklearn.model_selection.HalvingRandomSearchCV'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ParameterSampler.html#sklearn.model_selection.ParameterSampler'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html#sklearn.model_selection.HalvingGridSearchCV'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ParameterGrid.html#sklearn.model_selection.ParameterGrid'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV'}]},\n",
       "   {'Post-fit model tuning': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.FixedThresholdClassifier.html#sklearn.model_selection.FixedThresholdClassifier'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TunedThresholdClassifierCV.html#sklearn.model_selection.TunedThresholdClassifierCV'}]},\n",
       "   {'Model validation': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html#sklearn.model_selection.cross_val_predict'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.permutation_test_score.html#sklearn.model_selection.permutation_test_score'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.learning_curve.html#sklearn.model_selection.learning_curve'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html#sklearn.model_selection.validation_curve'}]},\n",
       "   {'Visualization': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LearningCurveDisplay.html#sklearn.model_selection.LearningCurveDisplay'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ValidationCurveDisplay.html#sklearn.model_selection.ValidationCurveDisplay'}]}],\n",
       "  'name': 'sklearn.model_selection',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.model_selection.html'},\n",
       " 'sklearn.multiclass.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsOneClassifier.html#sklearn.multiclass.OneVsOneClassifier'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OutputCodeClassifier.html#sklearn.multiclass.OutputCodeClassifier'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html#sklearn.multiclass.OneVsRestClassifier'}]}],\n",
       "  'name': 'sklearn.multiclass',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.multiclass.html'},\n",
       " 'sklearn.multioutput.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.ClassifierChain.html#sklearn.multioutput.ClassifierChain'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputRegressor.html#sklearn.multioutput.MultiOutputRegressor'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html#sklearn.multioutput.MultiOutputClassifier'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.RegressorChain.html#sklearn.multioutput.RegressorChain'}]}],\n",
       "  'name': 'sklearn.multioutput',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.multioutput.html'},\n",
       " 'sklearn.naive_bayes.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html#sklearn.naive_bayes.BernoulliNB'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.ComplementNB.html#sklearn.naive_bayes.ComplementNB'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.CategoricalNB.html#sklearn.naive_bayes.CategoricalNB'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB'}]}],\n",
       "  'name': 'sklearn.naive_bayes',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.naive_bayes.html'},\n",
       " 'sklearn.neighbors.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.BallTree.html#sklearn.neighbors.BallTree'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsTransformer.html#sklearn.neighbors.KNeighborsTransformer'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html#sklearn.neighbors.LocalOutlierFactor'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html#sklearn.neighbors.NearestNeighbors'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.RadiusNeighborsClassifier.html#sklearn.neighbors.RadiusNeighborsClassifier'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.RadiusNeighborsTransformer.html#sklearn.neighbors.RadiusNeighborsTransformer'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.radius_neighbors_graph.html#sklearn.neighbors.radius_neighbors_graph'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html#sklearn.neighbors.KDTree'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KernelDensity.html#sklearn.neighbors.KernelDensity'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestCentroid.html#sklearn.neighbors.NearestCentroid'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NeighborhoodComponentsAnalysis.html#sklearn.neighbors.NeighborhoodComponentsAnalysis'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.RadiusNeighborsRegressor.html#sklearn.neighbors.RadiusNeighborsRegressor'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.kneighbors_graph.html#sklearn.neighbors.kneighbors_graph'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.sort_graph_by_row_values.html#sklearn.neighbors.sort_graph_by_row_values'}]}],\n",
       "  'name': 'sklearn.neighbors',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.neighbors.html'},\n",
       " 'sklearn.neural_network.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.BernoulliRBM.html#sklearn.neural_network.BernoulliRBM'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier'}]}],\n",
       "  'name': 'sklearn.neural_network',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.neural_network.html'},\n",
       " 'sklearn.pipeline.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html#sklearn.pipeline.FeatureUnion'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_union.html#sklearn.pipeline.make_union'}]}],\n",
       "  'name': 'sklearn.pipeline',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.pipeline.html'},\n",
       " 'sklearn.preprocessing.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Binarizer.html#sklearn.preprocessing.Binarizer'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KBinsDiscretizer.html#sklearn.preprocessing.KBinsDiscretizer'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html#sklearn.preprocessing.LabelBinarizer'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html#sklearn.preprocessing.MaxAbsScaler'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html#sklearn.preprocessing.MultiLabelBinarizer'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html#sklearn.preprocessing.PolynomialFeatures'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.QuantileTransformer.html#sklearn.preprocessing.QuantileTransformer'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.SplineTransformer.html#sklearn.preprocessing.SplineTransformer'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.TargetEncoder.html#sklearn.preprocessing.TargetEncoder'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.binarize.html#sklearn.preprocessing.binarize'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.maxabs_scale.html#sklearn.preprocessing.maxabs_scale'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.normalize.html#sklearn.preprocessing.normalize'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.quantile_transform.html#sklearn.preprocessing.quantile_transform'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html#sklearn.preprocessing.scale'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html#sklearn.preprocessing.FunctionTransformer'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KernelCenterer.html#sklearn.preprocessing.KernelCenterer'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html#sklearn.preprocessing.Normalizer'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html#sklearn.preprocessing.OrdinalEncoder'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html#sklearn.preprocessing.PowerTransformer'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.add_dummy_feature.html#sklearn.preprocessing.add_dummy_feature'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.label_binarize.html#sklearn.preprocessing.label_binarize'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.minmax_scale.html#sklearn.preprocessing.minmax_scale'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.power_transform.html#sklearn.preprocessing.power_transform'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.robust_scale.html#sklearn.preprocessing.robust_scale'}]}],\n",
       "  'name': 'sklearn.preprocessing',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.preprocessing.html'},\n",
       " 'sklearn.random_projection.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.random_projection.GaussianRandomProjection.html#sklearn.random_projection.GaussianRandomProjection'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.random_projection.johnson_lindenstrauss_min_dim.html#sklearn.random_projection.johnson_lindenstrauss_min_dim'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.random_projection.SparseRandomProjection.html#sklearn.random_projection.SparseRandomProjection'}]}],\n",
       "  'name': 'sklearn.random_projection',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.random_projection.html'},\n",
       " 'sklearn.semi_supervised.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.semi_supervised.LabelPropagation.html#sklearn.semi_supervised.LabelPropagation'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.semi_supervised.SelfTrainingClassifier.html#sklearn.semi_supervised.SelfTrainingClassifier'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.semi_supervised.LabelSpreading.html#sklearn.semi_supervised.LabelSpreading'}]}],\n",
       "  'name': 'sklearn.semi_supervised',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.semi_supervised.html'},\n",
       " 'sklearn.svm.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.svm.NuSVC.html#sklearn.svm.NuSVC'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html#sklearn.svm.OneClassSVM'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html#sklearn.svm.SVR'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVR.html#sklearn.svm.LinearSVR'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.svm.NuSVR.html#sklearn.svm.NuSVR'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.svm.l1_min_c.html#sklearn.svm.l1_min_c'}]}],\n",
       "  'name': 'sklearn.svm',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.svm.html'},\n",
       " 'sklearn.tree.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.tree.ExtraTreeClassifier.html#sklearn.tree.ExtraTreeClassifier'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.tree.ExtraTreeRegressor.html#sklearn.tree.ExtraTreeRegressor'}]},\n",
       "   {'Exporting': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html#sklearn.tree.export_graphviz'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_text.html#sklearn.tree.export_text'}]},\n",
       "   {'Plotting': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html#sklearn.tree.plot_tree'}]}],\n",
       "  'name': 'sklearn.tree',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.tree.html'},\n",
       " 'sklearn.utils.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html#sklearn.utils.Bunch'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.as_float_array.html#sklearn.utils.as_float_array'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.deprecated.html#sklearn.utils.deprecated'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.gen_batches.html#sklearn.utils.gen_batches'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.indexable.html#sklearn.utils.indexable'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.resample.html#sklearn.utils.resample'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.safe_sqr.html#sklearn.utils.safe_sqr'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils._safe_indexing.html#sklearn.utils._safe_indexing'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.assert_all_finite.html#sklearn.utils.assert_all_finite'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.estimator_html_repr.html#sklearn.utils.estimator_html_repr'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.gen_even_slices.html#sklearn.utils.gen_even_slices'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.murmurhash3_32.html#sklearn.utils.murmurhash3_32'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.safe_mask.html#sklearn.utils.safe_mask'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.shuffle.html#sklearn.utils.shuffle'}]},\n",
       "   {'Input and parameter validation': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.check_X_y.html#sklearn.utils.check_X_y'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.check_consistent_length.html#sklearn.utils.check_consistent_length'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.check_scalar.html#sklearn.utils.check_scalar'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.validation.check_memory.html#sklearn.utils.validation.check_memory'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.validation.column_or_1d.html#sklearn.utils.validation.column_or_1d'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.check_array.html#sklearn.utils.check_array'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.check_random_state.html#sklearn.utils.check_random_state'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.validation.check_is_fitted.html#sklearn.utils.validation.check_is_fitted'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.validation.check_symmetric.html#sklearn.utils.validation.check_symmetric'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.validation.has_fit_parameter.html#sklearn.utils.validation.has_fit_parameter'}]},\n",
       "   {'Meta-estimators': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.metaestimators.available_if.html#sklearn.utils.metaestimators.available_if'}]},\n",
       "   {'Weight handling based on class labels': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_class_weight.html#sklearn.utils.class_weight.compute_class_weight'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_sample_weight.html#sklearn.utils.class_weight.compute_sample_weight'}]},\n",
       "   {'Dealing with multiclass target in classifiers': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.multiclass.is_multilabel.html#sklearn.utils.multiclass.is_multilabel'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.multiclass.unique_labels.html#sklearn.utils.multiclass.unique_labels'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.multiclass.type_of_target.html#sklearn.utils.multiclass.type_of_target'}]},\n",
       "   {'Optimal mathematical operations': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.density.html#sklearn.utils.extmath.density'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.safe_sparse_dot.html#sklearn.utils.extmath.safe_sparse_dot'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.fast_logdet.html#sklearn.utils.extmath.fast_logdet'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_svd.html#sklearn.utils.extmath.randomized_svd'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.weighted_mode.html#sklearn.utils.extmath.weighted_mode'}]},\n",
       "   {'Working with sparse matrices and arrays': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.sparsefuncs.incr_mean_variance_axis.html#sklearn.utils.sparsefuncs.incr_mean_variance_axis'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.sparsefuncs.inplace_csr_column_scale.html#sklearn.utils.sparsefuncs.inplace_csr_column_scale'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.sparsefuncs.inplace_swap_column.html#sklearn.utils.sparsefuncs.inplace_swap_column'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.sparsefuncs.mean_variance_axis.html#sklearn.utils.sparsefuncs.mean_variance_axis'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.sparsefuncs_fast.inplace_csr_row_normalize_l1.html#sklearn.utils.sparsefuncs_fast.inplace_csr_row_normalize_l1'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.sparsefuncs.inplace_column_scale.html#sklearn.utils.sparsefuncs.inplace_column_scale'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.sparsefuncs.inplace_row_scale.html#sklearn.utils.sparsefuncs.inplace_row_scale'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.sparsefuncs.inplace_swap_row.html#sklearn.utils.sparsefuncs.inplace_swap_row'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.sparsefuncs_fast.inplace_csr_row_normalize_l2.html#sklearn.utils.sparsefuncs_fast.inplace_csr_row_normalize_l2'}]},\n",
       "   {'Working with graphs': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.graph.single_source_shortest_path_length.html#sklearn.utils.graph.single_source_shortest_path_length'}]},\n",
       "   {'Random sampling': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.random.sample_without_replacement.html#sklearn.utils.random.sample_without_replacement'}]},\n",
       "   {'Auxiliary functions that operate on arrays': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.arrayfuncs.min_pos.html#sklearn.utils.arrayfuncs.min_pos'}]},\n",
       "   {'Metadata routing': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.metadata_routing.MetadataRequest.html#sklearn.utils.metadata_routing.MetadataRequest'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.metadata_routing.MethodMapping.html#sklearn.utils.metadata_routing.MethodMapping'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.metadata_routing.process_routing.html#sklearn.utils.metadata_routing.process_routing'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.metadata_routing.MetadataRouter.html#sklearn.utils.metadata_routing.MetadataRouter'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.metadata_routing.get_routing_for_object.html#sklearn.utils.metadata_routing.get_routing_for_object'}]},\n",
       "   {'Discovering scikit-learn objects': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.discovery.all_displays.html#sklearn.utils.discovery.all_displays'}]},\n",
       "   {'API compatibility checkers': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.estimator_checks.check_estimator.html#sklearn.utils.estimator_checks.check_estimator'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.estimator_checks.parametrize_with_checks.html#sklearn.utils.estimator_checks.parametrize_with_checks'}]},\n",
       "   {'Parallel computing': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.parallel.Parallel.html#sklearn.utils.parallel.Parallel'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.parallel.delayed.html#sklearn.utils.parallel.delayed'}]}],\n",
       "  'name': 'sklearn.utils',\n",
       "  'url': 'https://scikit-learn.org/stable/api/sklearn.utils.html'},\n",
       " 'deprecated.html': {'functions': [{'defaults': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.discovery.all_estimators.html#sklearn.utils.discovery.all_estimators'},\n",
       "     {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.utils.discovery.all_functions.html#sklearn.utils.discovery.all_functions'}]}],\n",
       "  'name': 'Recently Deprecated',\n",
       "  'url': 'https://scikit-learn.org/stable/api/deprecated.html'}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# func_url = \"https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html#sklearn.feature_extraction.DictVectorizer\"\n",
    "# func_response = requests.get(func_url)\n",
    "# func_soup = BeautifulSoup(\n",
    "#     func_response.content, \"lxml\", from_encoding=\"utf-8\"\n",
    "# )\n",
    "\n",
    "# func_name = func_soup.find(\"h1\").text.replace(\"#\", \"\")  # remove #\n",
    "# elem = func_soup.find(attrs={\"class\": \"sig sig-object py\"})\n",
    "\n",
    "# full_function = elem.text.replace(\"[source]#\", \"\").replace(\"\\n\", \"\")\n",
    "# func_text = func_soup.find(\"dd\").find(\"p\").text\n",
    "# curr_dict = {\n",
    "#     \"function_name\": func_name,\n",
    "#     \"full_function\": full_function,\n",
    "#     \"function_text\": func_text,\n",
    "#     \"parameter_names_desc\": [],\n",
    "#     \"function_url\": func_url,\n",
    "# }\n",
    "# em = func_soup.find_all(attrs={\"class\": \"field-odd\"})\n",
    "# if em[0].text == \"Parameters:\":\n",
    "#     param_names = em[-1].find_all(\"dt\")\n",
    "#     desc_list = em[-1].find_all(\"dd\")\n",
    "#     for pn, dn in zip(param_names, desc_list):\n",
    "#         param_name = pn.strong.text\n",
    "#         param_type = pn.find(attrs={\"class\": \"classifier\"}).text\n",
    "#         if param_name == \"**kwargs\":\n",
    "#             continue\n",
    "#         param_desc = dn.text\n",
    "#         curr_dict[\"parameter_names_desc\"].append(\n",
    "#             {\n",
    "#                 \"param_name\": param_name,\n",
    "#                 \"param_type\": param_type,\n",
    "#                 \"param_desc\": param_desc,\n",
    "#             }\n",
    "#         )\n",
    "# curr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def get_param_data(first_level):\n",
    "    not_worked = []\n",
    "    for parent in first_level:\n",
    "        parent_dict = first_level[parent][\"functions\"]\n",
    "        for sub_level in parent_dict:\n",
    "            for _,sub_level_vals in sub_level.items():\n",
    "                for sub_level in sub_level_vals:\n",
    "                    func_url = sub_level[\"func_url\"]\n",
    "                    func_response = requests.get(func_url)\n",
    "                    func_soup = BeautifulSoup(\n",
    "                        func_response.content, \"lxml\", from_encoding=\"utf-8\"\n",
    "                    )\n",
    "\n",
    "                    func_name = func_soup.find(\"h1\").text.replace(\"#\", \"\")  # remove #\n",
    "                    elem = func_soup.find(attrs={\"class\": \"sig sig-object py\"})\n",
    "                    try:\n",
    "                        full_function = elem.text.replace(\"[source]#\", \"\").replace(\"\\n\", \"\")\n",
    "                        func_text = func_soup.find(\"dd\").find_all(\"p\")\n",
    "                        func_text = \" \".join([ft.text for ft in func_text])\n",
    "                        curr_dict = {\n",
    "                            \"function_name\": func_name,\n",
    "                            \"full_function\": full_function,\n",
    "                            \"function_text\": func_text,\n",
    "                            \"parameter_names_desc\": [],\n",
    "                        }\n",
    "                        em = func_soup.find_all(attrs={\"class\": \"field-odd\"})\n",
    "                        if em[0].text == \"Parameters:\":\n",
    "                            param_names = em[-1].find_all(\"dt\")\n",
    "                            desc_list = em[-1].find_all(\"dd\")\n",
    "                            for pn, dn in zip(param_names, desc_list):\n",
    "                                try:\n",
    "                                    param_name = pn.strong.text\n",
    "                                    param_type = pn.find(attrs={\"class\": \"classifier\"}).text\n",
    "                                    if param_name == \"**kwargs\":\n",
    "                                        continue\n",
    "                                    param_desc = dn.text\n",
    "                                    curr_dict[\"parameter_names_desc\"].append(\n",
    "                                        {\n",
    "                                            \"param_name\": param_name,\n",
    "                                            \"param_type\": param_type,\n",
    "                                            \"param_desc\": param_desc,\n",
    "                                        }\n",
    "                                    )\n",
    "                                except Exception as e:\n",
    "                                    pass\n",
    "                    except Exception as e:\n",
    "                        not_worked.append((func_name, func_text, e, func_url))\n",
    "                    finally:\n",
    "                        sub_level.update({\"function_definitions\":curr_dict})\n",
    "    return first_level, not_worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_level_param_dict,not_worked = get_param_data(first_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sklearn.html', 'sklearn.base.html', 'sklearn.calibration.html', 'sklearn.cluster.html', 'sklearn.compose.html', 'sklearn.covariance.html', 'sklearn.cross_decomposition.html', 'sklearn.datasets.html', 'sklearn.decomposition.html', 'sklearn.discriminant_analysis.html', 'sklearn.dummy.html', 'sklearn.ensemble.html', 'sklearn.exceptions.html', 'sklearn.experimental.html', 'sklearn.feature_extraction.html', 'sklearn.feature_selection.html', 'sklearn.gaussian_process.html', 'sklearn.impute.html', 'sklearn.inspection.html', 'sklearn.isotonic.html', 'sklearn.kernel_approximation.html', 'sklearn.kernel_ridge.html', 'sklearn.linear_model.html', 'sklearn.manifold.html', 'sklearn.metrics.html', 'sklearn.mixture.html', 'sklearn.model_selection.html', 'sklearn.multiclass.html', 'sklearn.multioutput.html', 'sklearn.naive_bayes.html', 'sklearn.neighbors.html', 'sklearn.neural_network.html', 'sklearn.pipeline.html', 'sklearn.preprocessing.html', 'sklearn.random_projection.html', 'sklearn.semi_supervised.html', 'sklearn.svm.html', 'sklearn.tree.html', 'sklearn.utils.html', 'deprecated.html'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "first_level_param_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Splitters': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html#sklearn.model_selection.GroupKFold',\n",
       "    'function_definitions': {'function_name': 'GroupKFold',\n",
       "     'full_function': 'class sklearn.model_selection.GroupKFold(n_splits=5)',\n",
       "     'function_text': 'K-fold iterator variant with non-overlapping groups. Each group will appear exactly once in the test set across all folds (the\\nnumber of distinct groups has to be at least equal to the number of folds). The folds are approximately balanced in the sense that the number of\\nsamples is approximately the same in each test fold. Read more in the User Guide. For visualisation of cross-validation behaviour and\\ncomparison between common scikit-learn split methods\\nrefer to Visualizing cross-validation behavior in scikit-learn Number of folds. Must be at least 2. Changed in version 0.22: n_splits default value changed from 3 to 5. See also For splitting the data according to explicit domain-specific stratification of the dataset. Takes class information into account to avoid building folds with imbalanced class proportions (for binary or multiclass classification tasks). Notes Groups appear in an arbitrary order throughout the folds. Examples Get metadata routing of this object. Please check User Guide on how the routing\\nmechanism works. A MetadataRequest encapsulating\\nrouting information. Returns the number of splitting iterations in the cross-validator. Always ignored, exists for compatibility. Always ignored, exists for compatibility. Always ignored, exists for compatibility. Returns the number of splitting iterations in the cross-validator. Request metadata passed to the split method. Note that this method is only relevant if\\nenable_metadata_routing=True (see sklearn.set_config).\\nPlease see User Guide on how the routing\\nmechanism works. The options for each parameter are: True: metadata is requested, and passed to split if provided. The request is ignored if metadata is not provided. False: metadata is not requested and the meta-estimator will not pass it to split. None: metadata is not requested, and the meta-estimator will raise an error if the user provides it. str: metadata should be passed to the meta-estimator with this given alias instead of the original name. The default (sklearn.utils.metadata_routing.UNCHANGED) retains the\\nexisting request. This allows you to change the request for some\\nparameters and not others. Added in version 1.3. Note This method is only relevant if this estimator is used as a\\nsub-estimator of a meta-estimator, e.g. used inside a\\nPipeline. Otherwise it has no effect. Metadata routing for groups parameter in split. The updated object. Generate indices to split data into training and test set. Training data, where n_samples is the number of samples\\nand n_features is the number of features. The target variable for supervised learning problems. Group labels for the samples used while splitting the dataset into\\ntrain/test set. The training set indices for that split. The testing set indices for that split.',\n",
       "     'parameter_names_desc': [{'param_name': 'X',\n",
       "       'param_type': 'array-like of shape (n_samples, n_features)',\n",
       "       'param_desc': 'Training data, where n_samples is the number of samples\\nand n_features is the number of features.\\n'},\n",
       "      {'param_name': 'y',\n",
       "       'param_type': 'array-like of shape (n_samples,), default=None',\n",
       "       'param_desc': 'The target variable for supervised learning problems.\\n'},\n",
       "      {'param_name': 'groups',\n",
       "       'param_type': 'array-like of shape (n_samples,)',\n",
       "       'param_desc': 'Group labels for the samples used while splitting the dataset into\\ntrain/test set.\\n'}]}},\n",
       "   {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold',\n",
       "    'function_definitions': {'function_name': 'KFold',\n",
       "     'full_function': 'class sklearn.model_selection.KFold(n_splits=5, *, shuffle=False, random_state=None)',\n",
       "     'function_text': 'K-Fold cross-validator. Provides train/test indices to split data in train/test sets. Split\\ndataset into k consecutive folds (without shuffling by default). Each fold is then used once as a validation while the k - 1 remaining\\nfolds form the training set. Read more in the User Guide. For visualisation of cross-validation behaviour and\\ncomparison between common scikit-learn split methods\\nrefer to Visualizing cross-validation behavior in scikit-learn Number of folds. Must be at least 2. Changed in version 0.22: n_splits default value changed from 3 to 5. Whether to shuffle the data before splitting into batches.\\nNote that the samples within each split will not be shuffled. When shuffle is True, random_state affects the ordering of the\\nindices, which controls the randomness of each fold. Otherwise, this\\nparameter has no effect.\\nPass an int for reproducible output across multiple function calls.\\nSee Glossary. See also Takes class information into account to avoid building folds with imbalanced class distributions (for binary or multiclass classification tasks). K-fold iterator variant with non-overlapping groups. Repeats K-Fold n times. Notes The first n_samples % n_splits folds have size\\nn_samples // n_splits + 1, other folds have size\\nn_samples // n_splits, where n_samples is the number of samples. Randomized CV splitters may return different results for each call of\\nsplit. You can make the results identical by setting random_state\\nto an integer. Examples Get metadata routing of this object. Please check User Guide on how the routing\\nmechanism works. A MetadataRequest encapsulating\\nrouting information. Returns the number of splitting iterations in the cross-validator. Always ignored, exists for compatibility. Always ignored, exists for compatibility. Always ignored, exists for compatibility. Returns the number of splitting iterations in the cross-validator. Generate indices to split data into training and test set. Training data, where n_samples is the number of samples\\nand n_features is the number of features. The target variable for supervised learning problems. Always ignored, exists for compatibility. The training set indices for that split. The testing set indices for that split.',\n",
       "     'parameter_names_desc': [{'param_name': 'X',\n",
       "       'param_type': 'array-like of shape (n_samples, n_features)',\n",
       "       'param_desc': 'Training data, where n_samples is the number of samples\\nand n_features is the number of features.\\n'},\n",
       "      {'param_name': 'y',\n",
       "       'param_type': 'array-like of shape (n_samples,)',\n",
       "       'param_desc': 'The target variable for supervised learning problems.\\n'},\n",
       "      {'param_name': 'groups',\n",
       "       'param_type': 'object',\n",
       "       'param_desc': 'Always ignored, exists for compatibility.\\n'}]}},\n",
       "   {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html#sklearn.model_selection.LeaveOneOut',\n",
       "    'function_definitions': {'function_name': 'LeaveOneOut',\n",
       "     'full_function': 'class sklearn.model_selection.LeaveOneOut',\n",
       "     'function_text': 'Leave-One-Out cross-validator. Provides train/test indices to split data in train/test sets. Each\\nsample is used once as a test set (singleton) while the remaining\\nsamples form the training set. Note: LeaveOneOut() is equivalent to KFold(n_splits=n) and\\nLeavePOut(p=1) where n is the number of samples. Due to the high number of test sets (which is the same as the\\nnumber of samples) this cross-validation method can be very costly.\\nFor large datasets one should favor KFold, ShuffleSplit\\nor StratifiedKFold. Read more in the User Guide. See also For splitting the data according to explicit, domain-specific stratification of the dataset. K-fold iterator variant with non-overlapping groups. Examples Get metadata routing of this object. Please check User Guide on how the routing\\nmechanism works. A MetadataRequest encapsulating\\nrouting information. Returns the number of splitting iterations in the cross-validator. Training data, where n_samples is the number of samples\\nand n_features is the number of features. Always ignored, exists for compatibility. Always ignored, exists for compatibility. Returns the number of splitting iterations in the cross-validator. Generate indices to split data into training and test set. Training data, where n_samples is the number of samples\\nand n_features is the number of features. The target variable for supervised learning problems. Always ignored, exists for compatibility. The training set indices for that split. The testing set indices for that split.',\n",
       "     'parameter_names_desc': []}},\n",
       "   {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeavePOut.html#sklearn.model_selection.LeavePOut',\n",
       "    'function_definitions': {'function_name': 'LeavePOut',\n",
       "     'full_function': 'class sklearn.model_selection.LeavePOut(p)',\n",
       "     'function_text': 'Leave-P-Out cross-validator. Provides train/test indices to split data in train/test sets. This results\\nin testing on all distinct samples of size p, while the remaining n - p\\nsamples form the training set in each iteration. Note: LeavePOut(p) is NOT equivalent to\\nKFold(n_splits=n_samples // p) which creates non-overlapping test sets. Due to the high number of iterations which grows combinatorically with the\\nnumber of samples this cross-validation method can be very costly. For\\nlarge datasets one should favor KFold, StratifiedKFold\\nor ShuffleSplit. Read more in the User Guide. Size of the test sets. Must be strictly less than the number of\\nsamples. Examples Get metadata routing of this object. Please check User Guide on how the routing\\nmechanism works. A MetadataRequest encapsulating\\nrouting information. Returns the number of splitting iterations in the cross-validator. Training data, where n_samples is the number of samples\\nand n_features is the number of features. Always ignored, exists for compatibility. Always ignored, exists for compatibility. Generate indices to split data into training and test set. Training data, where n_samples is the number of samples\\nand n_features is the number of features. The target variable for supervised learning problems. Always ignored, exists for compatibility. The training set indices for that split. The testing set indices for that split.',\n",
       "     'parameter_names_desc': [{'param_name': 'X',\n",
       "       'param_type': 'array-like of shape (n_samples, n_features)',\n",
       "       'param_desc': 'Training data, where n_samples is the number of samples\\nand n_features is the number of features.\\n'},\n",
       "      {'param_name': 'y',\n",
       "       'param_type': 'array-like of shape (n_samples,)',\n",
       "       'param_desc': 'The target variable for supervised learning problems.\\n'},\n",
       "      {'param_name': 'groups',\n",
       "       'param_type': 'object',\n",
       "       'param_desc': 'Always ignored, exists for compatibility.\\n'}]}},\n",
       "   {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedKFold.html#sklearn.model_selection.RepeatedKFold',\n",
       "    'function_definitions': {'function_name': 'RepeatedKFold',\n",
       "     'full_function': 'class sklearn.model_selection.RepeatedKFold(*, n_splits=5, n_repeats=10, random_state=None)',\n",
       "     'function_text': 'Repeated K-Fold cross validator. Repeats K-Fold n times with different randomization in each repetition. Read more in the User Guide. Number of folds. Must be at least 2. Number of times cross-validator needs to be repeated. Controls the randomness of each repeated cross-validation instance.\\nPass an int for reproducible output across multiple function calls.\\nSee Glossary. See also Repeats Stratified K-Fold n times. Notes Randomized CV splitters may return different results for each call of\\nsplit. You can make the results identical by setting random_state\\nto an integer. Examples Get metadata routing of this object. Please check User Guide on how the routing\\nmechanism works. A MetadataRequest encapsulating\\nrouting information. Returns the number of splitting iterations in the cross-validator. Always ignored, exists for compatibility.\\nnp.zeros(n_samples) may be used as a placeholder. Always ignored, exists for compatibility.\\nnp.zeros(n_samples) may be used as a placeholder. Group labels for the samples used while splitting the dataset into\\ntrain/test set. Returns the number of splitting iterations in the cross-validator. Generate indices to split data into training and test set. Training data, where n_samples is the number of samples\\nand n_features is the number of features. The target variable for supervised learning problems. Always ignored, exists for compatibility. The training set indices for that split. The testing set indices for that split.',\n",
       "     'parameter_names_desc': [{'param_name': 'X',\n",
       "       'param_type': 'array-like of shape (n_samples, n_features)',\n",
       "       'param_desc': 'Training data, where n_samples is the number of samples\\nand n_features is the number of features.\\n'},\n",
       "      {'param_name': 'y',\n",
       "       'param_type': 'array-like of shape (n_samples,)',\n",
       "       'param_desc': 'The target variable for supervised learning problems.\\n'},\n",
       "      {'param_name': 'groups',\n",
       "       'param_type': 'object',\n",
       "       'param_desc': 'Always ignored, exists for compatibility.\\n'}]}},\n",
       "   {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit',\n",
       "    'function_definitions': {'function_name': 'ShuffleSplit',\n",
       "     'full_function': 'class sklearn.model_selection.ShuffleSplit(n_splits=10, *, test_size=None, train_size=None, random_state=None)',\n",
       "     'function_text': 'Random permutation cross-validator. Yields indices to split data into training and test sets. Note: contrary to other cross-validation strategies, random splits\\ndo not guarantee that all folds will be different, although this is\\nstill very likely for sizeable datasets. Read more in the User Guide. For visualisation of cross-validation behaviour and\\ncomparison between common scikit-learn split methods\\nrefer to Visualizing cross-validation behavior in scikit-learn Number of re-shuffling & splitting iterations. If float, should be between 0.0 and 1.0 and represent the proportion\\nof the dataset to include in the test split. If int, represents the\\nabsolute number of test samples. If None, the value is set to the\\ncomplement of the train size. If train_size is also None, it will\\nbe set to 0.1. If float, should be between 0.0 and 1.0 and represent the\\nproportion of the dataset to include in the train split. If\\nint, represents the absolute number of train samples. If None,\\nthe value is automatically set to the complement of the test size. Controls the randomness of the training and testing indices produced.\\nPass an int for reproducible output across multiple function calls.\\nSee Glossary. Examples Get metadata routing of this object. Please check User Guide on how the routing\\nmechanism works. A MetadataRequest encapsulating\\nrouting information. Returns the number of splitting iterations in the cross-validator. Always ignored, exists for compatibility. Always ignored, exists for compatibility. Always ignored, exists for compatibility. Returns the number of splitting iterations in the cross-validator. Generate indices to split data into training and test set. Training data, where n_samples is the number of samples\\nand n_features is the number of features. The target variable for supervised learning problems. Always ignored, exists for compatibility. The training set indices for that split. The testing set indices for that split.',\n",
       "     'parameter_names_desc': [{'param_name': 'X',\n",
       "       'param_type': 'array-like of shape (n_samples, n_features)',\n",
       "       'param_desc': 'Training data, where n_samples is the number of samples\\nand n_features is the number of features.\\n'},\n",
       "      {'param_name': 'y',\n",
       "       'param_type': 'array-like of shape (n_samples,)',\n",
       "       'param_desc': 'The target variable for supervised learning problems.\\n'},\n",
       "      {'param_name': 'groups',\n",
       "       'param_type': 'object',\n",
       "       'param_desc': 'Always ignored, exists for compatibility.\\n'}]}},\n",
       "   {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold',\n",
       "    'function_definitions': {'function_name': 'StratifiedKFold',\n",
       "     'full_function': 'class sklearn.model_selection.StratifiedKFold(n_splits=5, *, shuffle=False, random_state=None)',\n",
       "     'function_text': 'Stratified K-Fold cross-validator. Provides train/test indices to split data in train/test sets. This cross-validation object is a variation of KFold that returns\\nstratified folds. The folds are made by preserving the percentage of\\nsamples for each class. Read more in the User Guide. For visualisation of cross-validation behaviour and\\ncomparison between common scikit-learn split methods\\nrefer to Visualizing cross-validation behavior in scikit-learn Number of folds. Must be at least 2. Changed in version 0.22: n_splits default value changed from 3 to 5. Whether to shuffle each class’s samples before splitting into batches.\\nNote that the samples within each split will not be shuffled. When shuffle is True, random_state affects the ordering of the\\nindices, which controls the randomness of each fold for each class.\\nOtherwise, leave random_state as None.\\nPass an int for reproducible output across multiple function calls.\\nSee Glossary. See also Repeats Stratified K-Fold n times. Notes The implementation is designed to: Generate test sets such that all contain the same distribution of\\nclasses, or as close as possible. Be invariant to class label: relabelling y = [\"Happy\", \"Sad\"] to\\ny = [1, 0] should not change the indices generated. Preserve order dependencies in the dataset ordering, when\\nshuffle=False: all samples from class k in some test set were\\ncontiguous in y, or separated in y by samples from classes other than k. Generate test sets where the smallest and largest differ by at most one\\nsample. Changed in version 0.22: The previous implementation did not follow the last constraint. Examples Get metadata routing of this object. Please check User Guide on how the routing\\nmechanism works. A MetadataRequest encapsulating\\nrouting information. Returns the number of splitting iterations in the cross-validator. Always ignored, exists for compatibility. Always ignored, exists for compatibility. Always ignored, exists for compatibility. Returns the number of splitting iterations in the cross-validator. Generate indices to split data into training and test set. Training data, where n_samples is the number of samples\\nand n_features is the number of features. Note that providing y is sufficient to generate the splits and\\nhence np.zeros(n_samples) may be used as a placeholder for\\nX instead of actual training data. The target variable for supervised learning problems.\\nStratification is done based on the y labels. Always ignored, exists for compatibility. The training set indices for that split. The testing set indices for that split. Notes Randomized CV splitters may return different results for each call of\\nsplit. You can make the results identical by setting random_state\\nto an integer.',\n",
       "     'parameter_names_desc': [{'param_name': 'X',\n",
       "       'param_type': 'array-like of shape (n_samples, n_features)',\n",
       "       'param_desc': 'Training data, where n_samples is the number of samples\\nand n_features is the number of features.\\nNote that providing y is sufficient to generate the splits and\\nhence np.zeros(n_samples) may be used as a placeholder for\\nX instead of actual training data.\\n'},\n",
       "      {'param_name': 'y',\n",
       "       'param_type': 'array-like of shape (n_samples,)',\n",
       "       'param_desc': 'The target variable for supervised learning problems.\\nStratification is done based on the y labels.\\n'},\n",
       "      {'param_name': 'groups',\n",
       "       'param_type': 'object',\n",
       "       'param_desc': 'Always ignored, exists for compatibility.\\n'}]}},\n",
       "   {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html#sklearn.model_selection.TimeSeriesSplit',\n",
       "    'function_definitions': {'function_name': 'TimeSeriesSplit',\n",
       "     'full_function': 'class sklearn.model_selection.TimeSeriesSplit(n_splits=5, *, max_train_size=None, test_size=None, gap=0)',\n",
       "     'function_text': 'Time Series cross-validator. Provides train/test indices to split time series data samples\\nthat are observed at fixed time intervals, in train/test sets.\\nIn each split, test indices must be higher than before, and thus shuffling\\nin cross validator is inappropriate. This cross-validation object is a variation of KFold.\\nIn the kth split, it returns first k folds as train set and the\\n(k+1)th fold as test set. Note that unlike standard cross-validation methods, successive\\ntraining sets are supersets of those that come before them. Read more in the User Guide. For visualisation of cross-validation behaviour and\\ncomparison between common scikit-learn split methods\\nrefer to Visualizing cross-validation behavior in scikit-learn Added in version 0.18. Number of splits. Must be at least 2. Changed in version 0.22: n_splits default value changed from 3 to 5. Maximum size for a single training set. Used to limit the size of the test set. Defaults to\\nn_samples // (n_splits + 1), which is the maximum allowed value\\nwith gap=0. Added in version 0.24. Number of samples to exclude from the end of each train set before\\nthe test set. Added in version 0.24. Notes The training set has size i * n_samples // (n_splits + 1)\\n+ n_samples % (n_splits + 1) in the i th split,\\nwith a test set of size n_samples//(n_splits + 1) by default,\\nwhere n_samples is the number of samples. Examples For a more extended example see\\nTime-related feature engineering. Get metadata routing of this object. Please check User Guide on how the routing\\nmechanism works. A MetadataRequest encapsulating\\nrouting information. Returns the number of splitting iterations in the cross-validator. Always ignored, exists for compatibility. Always ignored, exists for compatibility. Always ignored, exists for compatibility. Returns the number of splitting iterations in the cross-validator. Generate indices to split data into training and test set. Training data, where n_samples is the number of samples\\nand n_features is the number of features. Always ignored, exists for compatibility. Always ignored, exists for compatibility. The training set indices for that split. The testing set indices for that split.',\n",
       "     'parameter_names_desc': [{'param_name': 'X',\n",
       "       'param_type': 'array-like of shape (n_samples, n_features)',\n",
       "       'param_desc': 'Training data, where n_samples is the number of samples\\nand n_features is the number of features.\\n'},\n",
       "      {'param_name': 'y',\n",
       "       'param_type': 'array-like of shape (n_samples,)',\n",
       "       'param_desc': 'Always ignored, exists for compatibility.\\n'},\n",
       "      {'param_name': 'groups',\n",
       "       'param_type': 'array-like of shape (n_samples,)',\n",
       "       'param_desc': 'Always ignored, exists for compatibility.\\n'}]}},\n",
       "   {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split',\n",
       "    'function_definitions': {'function_name': 'train_test_split',\n",
       "     'full_function': 'sklearn.model_selection.train_test_split(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)',\n",
       "     'function_text': 'Split arrays or matrices into random train and test subsets. Quick utility that wraps input validation,\\nnext(ShuffleSplit().split(X, y)), and application to input data\\ninto a single call for splitting (and optionally subsampling) data into a\\none-liner. Read more in the User Guide. Allowed inputs are lists, numpy arrays, scipy-sparse\\nmatrices or pandas dataframes. If float, should be between 0.0 and 1.0 and represent the proportion\\nof the dataset to include in the test split. If int, represents the\\nabsolute number of test samples. If None, the value is set to the\\ncomplement of the train size. If train_size is also None, it will\\nbe set to 0.25. If float, should be between 0.0 and 1.0 and represent the\\nproportion of the dataset to include in the train split. If\\nint, represents the absolute number of train samples. If None,\\nthe value is automatically set to the complement of the test size. Controls the shuffling applied to the data before applying the split.\\nPass an int for reproducible output across multiple function calls.\\nSee Glossary. Whether or not to shuffle the data before splitting. If shuffle=False\\nthen stratify must be None. If not None, data is split in a stratified fashion, using this as\\nthe class labels.\\nRead more in the User Guide. List containing train-test split of inputs. Added in version 0.16: If the input is sparse, the output will be a\\nscipy.sparse.csr_matrix. Else, output type is the same as the\\ninput type. Examples',\n",
       "     'parameter_names_desc': [{'param_name': '*arrays',\n",
       "       'param_type': 'sequence of indexables with same length / shape[0]',\n",
       "       'param_desc': 'Allowed inputs are lists, numpy arrays, scipy-sparse\\nmatrices or pandas dataframes.\\n'},\n",
       "      {'param_name': 'test_size',\n",
       "       'param_type': 'float or int, default=None',\n",
       "       'param_desc': 'If float, should be between 0.0 and 1.0 and represent the proportion\\nof the dataset to include in the test split. If int, represents the\\nabsolute number of test samples. If None, the value is set to the\\ncomplement of the train size. If train_size is also None, it will\\nbe set to 0.25.\\n'},\n",
       "      {'param_name': 'train_size',\n",
       "       'param_type': 'float or int, default=None',\n",
       "       'param_desc': 'If float, should be between 0.0 and 1.0 and represent the\\nproportion of the dataset to include in the train split. If\\nint, represents the absolute number of train samples. If None,\\nthe value is automatically set to the complement of the test size.\\n'},\n",
       "      {'param_name': 'random_state',\n",
       "       'param_type': 'int, RandomState instance or None, default=None',\n",
       "       'param_desc': 'Controls the shuffling applied to the data before applying the split.\\nPass an int for reproducible output across multiple function calls.\\nSee Glossary.\\n'},\n",
       "      {'param_name': 'shuffle',\n",
       "       'param_type': 'bool, default=True',\n",
       "       'param_desc': 'Whether or not to shuffle the data before splitting. If shuffle=False\\nthen stratify must be None.\\n'},\n",
       "      {'param_name': 'stratify',\n",
       "       'param_type': 'array-like, default=None',\n",
       "       'param_desc': 'If not None, data is split in a stratified fashion, using this as\\nthe class labels.\\nRead more in the User Guide.\\n'}]}},\n",
       "   {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupShuffleSplit.html#sklearn.model_selection.GroupShuffleSplit',\n",
       "    'function_definitions': {'function_name': 'GroupShuffleSplit',\n",
       "     'full_function': 'class sklearn.model_selection.GroupShuffleSplit(n_splits=5, *, test_size=None, train_size=None, random_state=None)',\n",
       "     'function_text': 'Shuffle-Group(s)-Out cross-validation iterator. Provides randomized train/test indices to split data according to a\\nthird-party provided group. This group information can be used to encode\\narbitrary domain specific stratifications of the samples as integers. For instance the groups could be the year of collection of the samples\\nand thus allow for cross-validation against time-based splits. The difference between LeavePGroupsOut and GroupShuffleSplit is that\\nthe former generates splits using all subsets of size p unique groups,\\nwhereas GroupShuffleSplit generates a user-determined number of random\\ntest splits, each with a user-determined fraction of unique groups. For example, a less computationally intensive alternative to\\nLeavePGroupsOut(p=10) would be\\nGroupShuffleSplit(test_size=10, n_splits=100). Note: The parameters test_size and train_size refer to groups, and\\nnot to samples, as in ShuffleSplit. Read more in the User Guide. For visualisation of cross-validation behaviour and\\ncomparison between common scikit-learn split methods\\nrefer to Visualizing cross-validation behavior in scikit-learn Number of re-shuffling & splitting iterations. If float, should be between 0.0 and 1.0 and represent the proportion\\nof groups to include in the test split (rounded up). If int,\\nrepresents the absolute number of test groups. If None, the value is\\nset to the complement of the train size.\\nThe default will change in version 0.21. It will remain 0.2 only\\nif train_size is unspecified, otherwise it will complement\\nthe specified train_size. If float, should be between 0.0 and 1.0 and represent the\\nproportion of the groups to include in the train split. If\\nint, represents the absolute number of train groups. If None,\\nthe value is automatically set to the complement of the test size. Controls the randomness of the training and testing indices produced.\\nPass an int for reproducible output across multiple function calls.\\nSee Glossary. See also Shuffles samples to create independent test/train sets. Train set leaves out all possible subsets of p groups. Examples Get metadata routing of this object. Please check User Guide on how the routing\\nmechanism works. A MetadataRequest encapsulating\\nrouting information. Returns the number of splitting iterations in the cross-validator. Always ignored, exists for compatibility. Always ignored, exists for compatibility. Always ignored, exists for compatibility. Returns the number of splitting iterations in the cross-validator. Request metadata passed to the split method. Note that this method is only relevant if\\nenable_metadata_routing=True (see sklearn.set_config).\\nPlease see User Guide on how the routing\\nmechanism works. The options for each parameter are: True: metadata is requested, and passed to split if provided. The request is ignored if metadata is not provided. False: metadata is not requested and the meta-estimator will not pass it to split. None: metadata is not requested, and the meta-estimator will raise an error if the user provides it. str: metadata should be passed to the meta-estimator with this given alias instead of the original name. The default (sklearn.utils.metadata_routing.UNCHANGED) retains the\\nexisting request. This allows you to change the request for some\\nparameters and not others. Added in version 1.3. Note This method is only relevant if this estimator is used as a\\nsub-estimator of a meta-estimator, e.g. used inside a\\nPipeline. Otherwise it has no effect. Metadata routing for groups parameter in split. The updated object. Generate indices to split data into training and test set. Training data, where n_samples is the number of samples\\nand n_features is the number of features. The target variable for supervised learning problems. Group labels for the samples used while splitting the dataset into\\ntrain/test set. The training set indices for that split. The testing set indices for that split. Notes Randomized CV splitters may return different results for each call of\\nsplit. You can make the results identical by setting random_state\\nto an integer.',\n",
       "     'parameter_names_desc': [{'param_name': 'X',\n",
       "       'param_type': 'array-like of shape (n_samples, n_features)',\n",
       "       'param_desc': 'Training data, where n_samples is the number of samples\\nand n_features is the number of features.\\n'},\n",
       "      {'param_name': 'y',\n",
       "       'param_type': 'array-like of shape (n_samples,), default=None',\n",
       "       'param_desc': 'The target variable for supervised learning problems.\\n'},\n",
       "      {'param_name': 'groups',\n",
       "       'param_type': 'array-like of shape (n_samples,)',\n",
       "       'param_desc': 'Group labels for the samples used while splitting the dataset into\\ntrain/test set.\\n'}]}},\n",
       "   {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneGroupOut.html#sklearn.model_selection.LeaveOneGroupOut',\n",
       "    'function_definitions': {'function_name': 'LeaveOneGroupOut',\n",
       "     'full_function': 'class sklearn.model_selection.LeaveOneGroupOut',\n",
       "     'function_text': 'Leave One Group Out cross-validator. Provides train/test indices to split data such that each training set is\\ncomprised of all samples except ones belonging to one specific group.\\nArbitrary domain specific group information is provided an array integers\\nthat encodes the group of each sample. For instance the groups could be the year of collection of the samples\\nand thus allow for cross-validation against time-based splits. Read more in the User Guide. See also K-fold iterator variant with non-overlapping groups. Notes Splits are ordered according to the index of the group left out. The first\\nsplit has testing set consisting of the group whose index in groups is\\nlowest, and so on. Examples Get metadata routing of this object. Please check User Guide on how the routing\\nmechanism works. A MetadataRequest encapsulating\\nrouting information. Returns the number of splitting iterations in the cross-validator. Always ignored, exists for compatibility. Always ignored, exists for compatibility. Group labels for the samples used while splitting the dataset into\\ntrain/test set. This ‘groups’ parameter must always be specified to\\ncalculate the number of splits, though the other parameters can be\\nomitted. Returns the number of splitting iterations in the cross-validator. Request metadata passed to the split method. Note that this method is only relevant if\\nenable_metadata_routing=True (see sklearn.set_config).\\nPlease see User Guide on how the routing\\nmechanism works. The options for each parameter are: True: metadata is requested, and passed to split if provided. The request is ignored if metadata is not provided. False: metadata is not requested and the meta-estimator will not pass it to split. None: metadata is not requested, and the meta-estimator will raise an error if the user provides it. str: metadata should be passed to the meta-estimator with this given alias instead of the original name. The default (sklearn.utils.metadata_routing.UNCHANGED) retains the\\nexisting request. This allows you to change the request for some\\nparameters and not others. Added in version 1.3. Note This method is only relevant if this estimator is used as a\\nsub-estimator of a meta-estimator, e.g. used inside a\\nPipeline. Otherwise it has no effect. Metadata routing for groups parameter in split. The updated object. Generate indices to split data into training and test set. Training data, where n_samples is the number of samples\\nand n_features is the number of features. The target variable for supervised learning problems. Group labels for the samples used while splitting the dataset into\\ntrain/test set. The training set indices for that split. The testing set indices for that split.',\n",
       "     'parameter_names_desc': []}},\n",
       "   {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeavePGroupsOut.html#sklearn.model_selection.LeavePGroupsOut',\n",
       "    'function_definitions': {'function_name': 'LeavePGroupsOut',\n",
       "     'full_function': 'class sklearn.model_selection.LeavePGroupsOut(n_groups)',\n",
       "     'function_text': 'Leave P Group(s) Out cross-validator. Provides train/test indices to split data according to a third-party\\nprovided group. This group information can be used to encode arbitrary\\ndomain specific stratifications of the samples as integers. For instance the groups could be the year of collection of the samples\\nand thus allow for cross-validation against time-based splits. The difference between LeavePGroupsOut and LeaveOneGroupOut is that\\nthe former builds the test sets with all the samples assigned to\\np different values of the groups while the latter uses samples\\nall assigned the same groups. Read more in the User Guide. Number of groups (p) to leave out in the test split. See also K-fold iterator variant with non-overlapping groups. Examples Get metadata routing of this object. Please check User Guide on how the routing\\nmechanism works. A MetadataRequest encapsulating\\nrouting information. Returns the number of splitting iterations in the cross-validator. Always ignored, exists for compatibility. Always ignored, exists for compatibility. Group labels for the samples used while splitting the dataset into\\ntrain/test set. This ‘groups’ parameter must always be specified to\\ncalculate the number of splits, though the other parameters can be\\nomitted. Returns the number of splitting iterations in the cross-validator. Request metadata passed to the split method. Note that this method is only relevant if\\nenable_metadata_routing=True (see sklearn.set_config).\\nPlease see User Guide on how the routing\\nmechanism works. The options for each parameter are: True: metadata is requested, and passed to split if provided. The request is ignored if metadata is not provided. False: metadata is not requested and the meta-estimator will not pass it to split. None: metadata is not requested, and the meta-estimator will raise an error if the user provides it. str: metadata should be passed to the meta-estimator with this given alias instead of the original name. The default (sklearn.utils.metadata_routing.UNCHANGED) retains the\\nexisting request. This allows you to change the request for some\\nparameters and not others. Added in version 1.3. Note This method is only relevant if this estimator is used as a\\nsub-estimator of a meta-estimator, e.g. used inside a\\nPipeline. Otherwise it has no effect. Metadata routing for groups parameter in split. The updated object. Generate indices to split data into training and test set. Training data, where n_samples is the number of samples\\nand n_features is the number of features. The target variable for supervised learning problems. Group labels for the samples used while splitting the dataset into\\ntrain/test set. The training set indices for that split. The testing set indices for that split.',\n",
       "     'parameter_names_desc': [{'param_name': 'X',\n",
       "       'param_type': 'array-like of shape (n_samples, n_features)',\n",
       "       'param_desc': 'Training data, where n_samples is the number of samples\\nand n_features is the number of features.\\n'},\n",
       "      {'param_name': 'y',\n",
       "       'param_type': 'array-like of shape (n_samples,), default=None',\n",
       "       'param_desc': 'The target variable for supervised learning problems.\\n'},\n",
       "      {'param_name': 'groups',\n",
       "       'param_type': 'array-like of shape (n_samples,)',\n",
       "       'param_desc': 'Group labels for the samples used while splitting the dataset into\\ntrain/test set.\\n'}]}},\n",
       "   {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.PredefinedSplit.html#sklearn.model_selection.PredefinedSplit',\n",
       "    'function_definitions': {'function_name': 'PredefinedSplit',\n",
       "     'full_function': 'class sklearn.model_selection.PredefinedSplit(test_fold)',\n",
       "     'function_text': 'Predefined split cross-validator. Provides train/test indices to split data into train/test sets using a\\npredefined scheme specified by the user with the test_fold parameter. Read more in the User Guide. Added in version 0.16. The entry test_fold[i] represents the index of the test set that\\nsample i belongs to. It is possible to exclude sample i from\\nany test set (i.e. include sample i in every training set) by\\nsetting test_fold[i] equal to -1. Examples Get metadata routing of this object. Please check User Guide on how the routing\\nmechanism works. A MetadataRequest encapsulating\\nrouting information. Returns the number of splitting iterations in the cross-validator. Always ignored, exists for compatibility. Always ignored, exists for compatibility. Always ignored, exists for compatibility. Returns the number of splitting iterations in the cross-validator. Generate indices to split data into training and test set. Always ignored, exists for compatibility. Always ignored, exists for compatibility. Always ignored, exists for compatibility. The training set indices for that split. The testing set indices for that split.',\n",
       "     'parameter_names_desc': [{'param_name': 'X',\n",
       "       'param_type': 'object',\n",
       "       'param_desc': 'Always ignored, exists for compatibility.\\n'},\n",
       "      {'param_name': 'y',\n",
       "       'param_type': 'object',\n",
       "       'param_desc': 'Always ignored, exists for compatibility.\\n'},\n",
       "      {'param_name': 'groups',\n",
       "       'param_type': 'object',\n",
       "       'param_desc': 'Always ignored, exists for compatibility.\\n'}]}},\n",
       "   {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedStratifiedKFold.html#sklearn.model_selection.RepeatedStratifiedKFold',\n",
       "    'function_definitions': {'function_name': 'RepeatedStratifiedKFold',\n",
       "     'full_function': 'class sklearn.model_selection.RepeatedStratifiedKFold(*, n_splits=5, n_repeats=10, random_state=None)',\n",
       "     'function_text': 'Repeated Stratified K-Fold cross validator. Repeats Stratified K-Fold n times with different randomization in each\\nrepetition. Read more in the User Guide. Number of folds. Must be at least 2. Number of times cross-validator needs to be repeated. Controls the generation of the random states for each repetition.\\nPass an int for reproducible output across multiple function calls.\\nSee Glossary. See also Repeats K-Fold n times. Notes Randomized CV splitters may return different results for each call of\\nsplit. You can make the results identical by setting random_state\\nto an integer. Examples Get metadata routing of this object. Please check User Guide on how the routing\\nmechanism works. A MetadataRequest encapsulating\\nrouting information. Returns the number of splitting iterations in the cross-validator. Always ignored, exists for compatibility.\\nnp.zeros(n_samples) may be used as a placeholder. Always ignored, exists for compatibility.\\nnp.zeros(n_samples) may be used as a placeholder. Group labels for the samples used while splitting the dataset into\\ntrain/test set. Returns the number of splitting iterations in the cross-validator. Generate indices to split data into training and test set. Training data, where n_samples is the number of samples\\nand n_features is the number of features. The target variable for supervised learning problems. Always ignored, exists for compatibility. The training set indices for that split. The testing set indices for that split.',\n",
       "     'parameter_names_desc': [{'param_name': 'X',\n",
       "       'param_type': 'array-like of shape (n_samples, n_features)',\n",
       "       'param_desc': 'Training data, where n_samples is the number of samples\\nand n_features is the number of features.\\n'},\n",
       "      {'param_name': 'y',\n",
       "       'param_type': 'array-like of shape (n_samples,)',\n",
       "       'param_desc': 'The target variable for supervised learning problems.\\n'},\n",
       "      {'param_name': 'groups',\n",
       "       'param_type': 'object',\n",
       "       'param_desc': 'Always ignored, exists for compatibility.\\n'}]}},\n",
       "   {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedGroupKFold.html#sklearn.model_selection.StratifiedGroupKFold',\n",
       "    'function_definitions': {'function_name': 'StratifiedGroupKFold',\n",
       "     'full_function': 'class sklearn.model_selection.StratifiedGroupKFold(n_splits=5, shuffle=False, random_state=None)',\n",
       "     'function_text': 'Stratified K-Fold iterator variant with non-overlapping groups. This cross-validation object is a variation of StratifiedKFold attempts to\\nreturn stratified folds with non-overlapping groups. The folds are made by\\npreserving the percentage of samples for each class. Each group will appear exactly once in the test set across all folds (the\\nnumber of distinct groups has to be at least equal to the number of folds). The difference between GroupKFold\\nand StratifiedGroupKFold is that\\nthe former attempts to create balanced folds such that the number of\\ndistinct groups is approximately the same in each fold, whereas\\nStratifiedGroupKFold attempts to create folds which preserve the\\npercentage of samples for each class as much as possible given the\\nconstraint of non-overlapping groups between splits. Read more in the User Guide. For visualisation of cross-validation behaviour and\\ncomparison between common scikit-learn split methods\\nrefer to Visualizing cross-validation behavior in scikit-learn Number of folds. Must be at least 2. Whether to shuffle each class’s samples before splitting into batches.\\nNote that the samples within each split will not be shuffled.\\nThis implementation can only shuffle groups that have approximately the\\nsame y distribution, no global shuffle will be performed. When shuffle is True, random_state affects the ordering of the\\nindices, which controls the randomness of each fold for each class.\\nOtherwise, leave random_state as None.\\nPass an int for reproducible output across multiple function calls.\\nSee Glossary. See also Takes class information into account to build folds which retain class distributions (for binary or multiclass classification tasks). K-fold iterator variant with non-overlapping groups. Notes The implementation is designed to: Mimic the behavior of StratifiedKFold as much as possible for trivial\\ngroups (e.g. when each group contains only one sample). Be invariant to class label: relabelling y = [\"Happy\", \"Sad\"] to\\ny = [1, 0] should not change the indices generated. Stratify based on samples as much as possible while keeping\\nnon-overlapping groups constraint. That means that in some cases when\\nthere is a small number of groups containing a large number of samples\\nthe stratification will not be possible and the behavior will be close\\nto GroupKFold. Examples Get metadata routing of this object. Please check User Guide on how the routing\\nmechanism works. A MetadataRequest encapsulating\\nrouting information. Returns the number of splitting iterations in the cross-validator. Always ignored, exists for compatibility. Always ignored, exists for compatibility. Always ignored, exists for compatibility. Returns the number of splitting iterations in the cross-validator. Request metadata passed to the split method. Note that this method is only relevant if\\nenable_metadata_routing=True (see sklearn.set_config).\\nPlease see User Guide on how the routing\\nmechanism works. The options for each parameter are: True: metadata is requested, and passed to split if provided. The request is ignored if metadata is not provided. False: metadata is not requested and the meta-estimator will not pass it to split. None: metadata is not requested, and the meta-estimator will raise an error if the user provides it. str: metadata should be passed to the meta-estimator with this given alias instead of the original name. The default (sklearn.utils.metadata_routing.UNCHANGED) retains the\\nexisting request. This allows you to change the request for some\\nparameters and not others. Added in version 1.3. Note This method is only relevant if this estimator is used as a\\nsub-estimator of a meta-estimator, e.g. used inside a\\nPipeline. Otherwise it has no effect. Metadata routing for groups parameter in split. The updated object. Generate indices to split data into training and test set. Training data, where n_samples is the number of samples\\nand n_features is the number of features. The target variable for supervised learning problems. Group labels for the samples used while splitting the dataset into\\ntrain/test set. The training set indices for that split. The testing set indices for that split.',\n",
       "     'parameter_names_desc': [{'param_name': 'X',\n",
       "       'param_type': 'array-like of shape (n_samples, n_features)',\n",
       "       'param_desc': 'Training data, where n_samples is the number of samples\\nand n_features is the number of features.\\n'},\n",
       "      {'param_name': 'y',\n",
       "       'param_type': 'array-like of shape (n_samples,), default=None',\n",
       "       'param_desc': 'The target variable for supervised learning problems.\\n'},\n",
       "      {'param_name': 'groups',\n",
       "       'param_type': 'array-like of shape (n_samples,), default=None',\n",
       "       'param_desc': 'Group labels for the samples used while splitting the dataset into\\ntrain/test set.\\n'}]}},\n",
       "   {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html#sklearn.model_selection.StratifiedShuffleSplit',\n",
       "    'function_definitions': {'function_name': 'StratifiedShuffleSplit',\n",
       "     'full_function': 'class sklearn.model_selection.StratifiedShuffleSplit(n_splits=10, *, test_size=None, train_size=None, random_state=None)',\n",
       "     'function_text': 'Stratified ShuffleSplit cross-validator. Provides train/test indices to split data in train/test sets. This cross-validation object is a merge of StratifiedKFold and\\nShuffleSplit, which returns stratified randomized folds. The folds\\nare made by preserving the percentage of samples for each class. Note: like the ShuffleSplit strategy, stratified random splits\\ndo not guarantee that all folds will be different, although this is\\nstill very likely for sizeable datasets. Read more in the User Guide. For visualisation of cross-validation behaviour and\\ncomparison between common scikit-learn split methods\\nrefer to Visualizing cross-validation behavior in scikit-learn Number of re-shuffling & splitting iterations. If float, should be between 0.0 and 1.0 and represent the proportion\\nof the dataset to include in the test split. If int, represents the\\nabsolute number of test samples. If None, the value is set to the\\ncomplement of the train size. If train_size is also None, it will\\nbe set to 0.1. If float, should be between 0.0 and 1.0 and represent the\\nproportion of the dataset to include in the train split. If\\nint, represents the absolute number of train samples. If None,\\nthe value is automatically set to the complement of the test size. Controls the randomness of the training and testing indices produced.\\nPass an int for reproducible output across multiple function calls.\\nSee Glossary. Examples Get metadata routing of this object. Please check User Guide on how the routing\\nmechanism works. A MetadataRequest encapsulating\\nrouting information. Returns the number of splitting iterations in the cross-validator. Always ignored, exists for compatibility. Always ignored, exists for compatibility. Always ignored, exists for compatibility. Returns the number of splitting iterations in the cross-validator. Generate indices to split data into training and test set. Training data, where n_samples is the number of samples\\nand n_features is the number of features. Note that providing y is sufficient to generate the splits and\\nhence np.zeros(n_samples) may be used as a placeholder for\\nX instead of actual training data. The target variable for supervised learning problems.\\nStratification is done based on the y labels. Always ignored, exists for compatibility. The training set indices for that split. The testing set indices for that split. Notes Randomized CV splitters may return different results for each call of\\nsplit. You can make the results identical by setting random_state\\nto an integer.',\n",
       "     'parameter_names_desc': [{'param_name': 'X',\n",
       "       'param_type': 'array-like of shape (n_samples, n_features)',\n",
       "       'param_desc': 'Training data, where n_samples is the number of samples\\nand n_features is the number of features.\\nNote that providing y is sufficient to generate the splits and\\nhence np.zeros(n_samples) may be used as a placeholder for\\nX instead of actual training data.\\n'},\n",
       "      {'param_name': 'y',\n",
       "       'param_type': 'array-like of shape (n_samples,) or (n_samples, n_labels)',\n",
       "       'param_desc': 'The target variable for supervised learning problems.\\nStratification is done based on the y labels.\\n'},\n",
       "      {'param_name': 'groups',\n",
       "       'param_type': 'object',\n",
       "       'param_desc': 'Always ignored, exists for compatibility.\\n'}]}},\n",
       "   {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.check_cv.html#sklearn.model_selection.check_cv',\n",
       "    'function_definitions': {'function_name': 'check_cv',\n",
       "     'full_function': 'sklearn.model_selection.check_cv(cv=5, y=None, *, classifier=False)',\n",
       "     'function_text': 'Input checker utility for building a cross-validator. Determines the cross-validation splitting strategy.\\nPossible inputs for cv are:\\n- None, to use the default 5-fold cross validation,\\n- integer, to specify the number of folds.\\n- CV splitter,\\n- An iterable that generates (train, test) splits as arrays of indices. For integer/None inputs, if classifier is True and y is either\\nbinary or multiclass, StratifiedKFold is used. In all other\\ncases, KFold is used. Refer User Guide for the various\\ncross-validation strategies that can be used here. Changed in version 0.22: cv default value changed from 3-fold to 5-fold. The target variable for supervised learning problems. Whether the task is a classification task, in which case\\nstratified KFold will be used. The return value is a cross-validator which generates the train/test\\nsplits via the split method. Examples',\n",
       "     'parameter_names_desc': [{'param_name': 'cv',\n",
       "       'param_type': 'int, cross-validation generator, iterable or None, default=5',\n",
       "       'param_desc': 'Determines the cross-validation splitting strategy.\\nPossible inputs for cv are:\\n- None, to use the default 5-fold cross validation,\\n- integer, to specify the number of folds.\\n- CV splitter,\\n- An iterable that generates (train, test) splits as arrays of indices.\\nFor integer/None inputs, if classifier is True and y is either\\nbinary or multiclass, StratifiedKFold is used. In all other\\ncases, KFold is used.\\nRefer User Guide for the various\\ncross-validation strategies that can be used here.\\n\\nChanged in version 0.22: cv default value changed from 3-fold to 5-fold.\\n\\n'},\n",
       "      {'param_name': 'y',\n",
       "       'param_type': 'array-like, default=None',\n",
       "       'param_desc': 'The target variable for supervised learning problems.\\n'},\n",
       "      {'param_name': 'classifier',\n",
       "       'param_type': 'bool, default=False',\n",
       "       'param_desc': 'Whether the task is a classification task, in which case\\nstratified KFold will be used.\\n'}]}}]},\n",
       " {'Hyper-parameter optimizers': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV',\n",
       "    'function_definitions': {'function_name': 'GridSearchCV',\n",
       "     'full_function': \"class sklearn.model_selection.GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\",\n",
       "     'function_text': \"Exhaustive search over specified parameter values for an estimator. Important members are fit, predict. GridSearchCV implements a “fit” and a “score” method.\\nIt also implements “score_samples”, “predict”, “predict_proba”,\\n“decision_function”, “transform” and “inverse_transform” if they are\\nimplemented in the estimator used. The parameters of the estimator used to apply these methods are optimized\\nby cross-validated grid-search over a parameter grid. Read more in the User Guide. This is assumed to implement the scikit-learn estimator interface.\\nEither estimator needs to provide a score function,\\nor scoring must be passed. Dictionary with parameters names (str) as keys and lists of\\nparameter settings to try as values, or a list of such\\ndictionaries, in which case the grids spanned by each dictionary\\nin the list are explored. This enables searching over any sequence\\nof parameter settings. Strategy to evaluate the performance of the cross-validated model on\\nthe test set. If scoring represents a single score, one can use: a single string (see The scoring parameter: defining model evaluation rules); a callable (see Defining your scoring strategy from metric functions) that returns a single value. If scoring represents multiple scores, one can use: a list or tuple of unique strings; a callable returning a dictionary where the keys are the metric\\nnames and the values are the metric scores; a dictionary with metric names as keys and callables a values. See Specifying multiple metrics for evaluation for an example. Number of jobs to run in parallel.\\nNone means 1 unless in a joblib.parallel_backend context.\\n-1 means using all processors. See Glossary\\nfor more details. Changed in version v0.20: n_jobs default changed from 1 to None Refit an estimator using the best found parameters on the whole\\ndataset. For multiple metric evaluation, this needs to be a str denoting the\\nscorer that would be used to find the best parameters for refitting\\nthe estimator at the end. Where there are considerations other than maximum score in\\nchoosing a best estimator, refit can be set to a function which\\nreturns the selected best_index_ given cv_results_. In that\\ncase, the best_estimator_ and best_params_ will be set\\naccording to the returned best_index_ while the best_score_\\nattribute will not be available. The refitted estimator is made available at the best_estimator_\\nattribute and permits using predict directly on this\\nGridSearchCV instance. Also for multiple metric evaluation, the attributes best_index_,\\nbest_score_ and best_params_ will only be available if\\nrefit is set and all of them will be determined w.r.t this specific\\nscorer. See scoring parameter to know more about multiple metric\\nevaluation. See Custom refit strategy of a grid search with cross-validation\\nto see how to design a custom selection strategy using a callable\\nvia refit. Changed in version 0.20: Support for callable added. Determines the cross-validation splitting strategy.\\nPossible inputs for cv are: None, to use the default 5-fold cross validation, integer, to specify the number of folds in a (Stratified)KFold, CV splitter, An iterable yielding (train, test) splits as arrays of indices. For integer/None inputs, if the estimator is a classifier and y is\\neither binary or multiclass, StratifiedKFold is used. In all\\nother cases, KFold is used. These splitters are instantiated\\nwith shuffle=False so the splits will be the same across calls. Refer User Guide for the various\\ncross-validation strategies that can be used here. Changed in version 0.22: cv default value if None changed from 3-fold to 5-fold. Controls the verbosity: the higher, the more messages. >1 : the computation time for each fold and parameter candidate is\\ndisplayed; >2 : the score is also displayed; >3 : the fold and candidate parameter indexes are also displayed\\ntogether with the starting time of the computation. Controls the number of jobs that get dispatched during parallel\\nexecution. Reducing this number can be useful to avoid an\\nexplosion of memory consumption when more jobs get dispatched\\nthan CPUs can process. This parameter can be: None, in which case all the jobs are immediately\\ncreated and spawned. Use this for lightweight and\\nfast-running jobs, to avoid delays due to on-demand\\nspawning of the jobs An int, giving the exact number of total jobs that are\\nspawned A str, giving an expression as a function of n_jobs,\\nas in ‘2*n_jobs’ Value to assign to the score if an error occurs in estimator fitting.\\nIf set to ‘raise’, the error is raised. If a numeric value is given,\\nFitFailedWarning is raised. This parameter does not affect the refit\\nstep, which will always raise the error. If False, the cv_results_ attribute will not include training\\nscores.\\nComputing training scores is used to get insights on how different\\nparameter settings impact the overfitting/underfitting trade-off.\\nHowever computing the scores on the training set can be computationally\\nexpensive and is not strictly required to select the parameters that\\nyield the best generalization performance. Added in version 0.19. Changed in version 0.21: Default value was changed from True to False A dict with keys as column headers and values as columns, that can be\\nimported into a pandas DataFrame. For instance the below given table param_kernel param_gamma param_degree split0_test_score … rank_t… ‘poly’ – 2 0.80 … 2 ‘poly’ – 3 0.70 … 4 ‘rbf’ 0.1 – 0.80 … 3 ‘rbf’ 0.2 – 0.93 … 1 will be represented by a cv_results_ dict of: NOTE The key 'params' is used to store a list of parameter\\nsettings dicts for all the parameter candidates. The mean_fit_time, std_fit_time, mean_score_time and\\nstd_score_time are all in seconds. For multi-metric evaluation, the scores for all the scorers are\\navailable in the cv_results_ dict at the keys ending with that\\nscorer’s name ('_<scorer_name>') instead of '_score' shown\\nabove. (‘split0_test_precision’, ‘mean_train_precision’ etc.) Estimator that was chosen by the search, i.e. estimator\\nwhich gave highest score (or smallest loss if specified)\\non the left out data. Not available if refit=False. See refit parameter for more information on allowed values. Mean cross-validated score of the best_estimator For multi-metric evaluation, this is present only if refit is\\nspecified. This attribute is not available if refit is a function. Parameter setting that gave the best results on the hold out data. For multi-metric evaluation, this is present only if refit is\\nspecified. The index (of the cv_results_ arrays) which corresponds to the best\\ncandidate parameter setting. The dict at search.cv_results_['params'][search.best_index_] gives\\nthe parameter setting for the best model, that gives the highest\\nmean score (search.best_score_). For multi-metric evaluation, this is present only if refit is\\nspecified. Scorer function used on the held out data to choose the best\\nparameters for the model. For multi-metric evaluation, this attribute holds the validated\\nscoring dict which maps the scorer key to the scorer callable. The number of cross-validation splits (folds/iterations). Seconds used for refitting the best model on the whole dataset. This is present only if refit is not False. Added in version 0.20. Whether or not the scorers compute several metrics. Class labels. Number of features seen during fit. Names of features seen during fit. Only defined if\\nbest_estimator_ is defined (see the documentation for the refit\\nparameter for more details) and that best_estimator_ exposes\\nfeature_names_in_ when fit. Added in version 1.0. See also Generates all the combinations of a hyperparameter grid. Utility function to split the data into a development set usable for fitting a GridSearchCV instance and an evaluation set for its final evaluation. Make a scorer from a performance metric or loss function. Notes The parameters selected are those that maximize the score of the left out\\ndata, unless an explicit score is passed in which case it is used instead. If n_jobs was set to a value higher than one, the data is copied for each\\npoint in the grid (and not n_jobs times). This is done for efficiency\\nreasons if individual jobs take very little time, but may raise errors if\\nthe dataset is large and not enough memory is available.  A workaround in\\nthis case is to set pre_dispatch. Then, the memory is copied only\\npre_dispatch many times. A reasonable value for pre_dispatch is 2 *\\nn_jobs. Examples Class labels. Only available when refit=True and the estimator is a classifier. Call decision_function on the estimator with the best found parameters. Only available if refit=True and the underlying estimator supports\\ndecision_function. Must fulfill the input assumptions of the\\nunderlying estimator. Result of the decision function for X based on the estimator with\\nthe best found parameters. Run fit with all sets of parameters. Training vector, where n_samples is the number of samples and\\nn_features is the number of features. Target relative to X for classification or regression;\\nNone for unsupervised learning. Parameters passed to the fit method of the estimator, the scorer,\\nand the CV splitter. If a fit parameter is an array-like whose length is equal to\\nnum_samples then it will be split across CV groups along with X\\nand y. For example, the sample_weight parameter is split\\nbecause len(sample_weights) = len(X). Instance of fitted estimator. Get metadata routing of this object. Please check User Guide on how the routing\\nmechanism works. Added in version 1.4. A MetadataRouter encapsulating\\nrouting information. Get parameters for this estimator. If True, will return the parameters for this estimator and\\ncontained subobjects that are estimators. Parameter names mapped to their values. Call inverse_transform on the estimator with the best found params. Only available if the underlying estimator implements\\ninverse_transform and refit=True. Must fulfill the input assumptions of the\\nunderlying estimator. Must fulfill the input assumptions of the\\nunderlying estimator. Deprecated since version 1.5: Xt was deprecated in 1.5 and will be removed in 1.7. Use X instead. Result of the inverse_transform function for Xt based on the\\nestimator with the best found parameters. Number of features seen during fit. Only available when refit=True. Call predict on the estimator with the best found parameters. Only available if refit=True and the underlying estimator supports\\npredict. Must fulfill the input assumptions of the\\nunderlying estimator. The predicted labels or values for X based on the estimator with\\nthe best found parameters. Call predict_log_proba on the estimator with the best found parameters. Only available if refit=True and the underlying estimator supports\\npredict_log_proba. Must fulfill the input assumptions of the\\nunderlying estimator. Predicted class log-probabilities for X based on the estimator\\nwith the best found parameters. The order of the classes\\ncorresponds to that in the fitted attribute classes_. Call predict_proba on the estimator with the best found parameters. Only available if refit=True and the underlying estimator supports\\npredict_proba. Must fulfill the input assumptions of the\\nunderlying estimator. Predicted class probabilities for X based on the estimator with\\nthe best found parameters. The order of the classes corresponds\\nto that in the fitted attribute classes_. Return the score on the given data, if the estimator has been refit. This uses the score defined by scoring where provided, and the\\nbest_estimator_.score method otherwise. Input data, where n_samples is the number of samples and\\nn_features is the number of features. Target relative to X for classification or regression;\\nNone for unsupervised learning. Parameters to be passed to the underlying scorer(s). Only available if enable_metadata_routing=True. See\\nMetadata Routing User Guide for more\\ndetails. The score defined by scoring if provided, and the\\nbest_estimator_.score method otherwise. Call score_samples on the estimator with the best found parameters. Only available if refit=True and the underlying estimator supports\\nscore_samples. Added in version 0.24. Data to predict on. Must fulfill input requirements\\nof the underlying estimator. The best_estimator_.score_samples method. Set the parameters of this estimator. The method works on simple estimators as well as on nested objects\\n(such as Pipeline). The latter have\\nparameters of the form <component>__<parameter> so that it’s\\npossible to update each component of a nested object. Estimator parameters. Estimator instance. Call transform on the estimator with the best found parameters. Only available if the underlying estimator supports transform and\\nrefit=True. Must fulfill the input assumptions of the\\nunderlying estimator. X transformed in the new space based on the estimator with\\nthe best found parameters.\",\n",
       "     'parameter_names_desc': [{'param_name': 'X',\n",
       "       'param_type': 'indexable, length n_samples',\n",
       "       'param_desc': 'Must fulfill the input assumptions of the\\nunderlying estimator.\\n'}]}},\n",
       "   {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html#sklearn.model_selection.HalvingRandomSearchCV',\n",
       "    'function_definitions': {'function_name': 'HalvingRandomSearchCV',\n",
       "     'full_function': \"class sklearn.model_selection.HalvingRandomSearchCV(estimator, param_distributions, *, n_candidates='exhaust', factor=3, resource='n_samples', max_resources='auto', min_resources='smallest', aggressive_elimination=False, cv=5, scoring=None, refit=True, error_score=nan, return_train_score=True, random_state=None, n_jobs=None, verbose=0)\",\n",
       "     'function_text': \"Randomized search on hyper parameters. The search strategy starts evaluating all the candidates with a small\\namount of resources and iteratively selects the best candidates, using more\\nand more resources. The candidates are sampled at random from the parameter space and the\\nnumber of sampled candidates is determined by n_candidates. Read more in the User guide. Note This estimator is still experimental for now: the predictions\\nand the API might change without any deprecation cycle. To use it,\\nyou need to explicitly import enable_halving_search_cv: This is assumed to implement the scikit-learn estimator interface.\\nEither estimator needs to provide a score function,\\nor scoring must be passed. Dictionary with parameters names (str) as keys and distributions\\nor lists of parameters to try. Distributions must provide a rvs\\nmethod for sampling (such as those from scipy.stats.distributions).\\nIf a list is given, it is sampled uniformly.\\nIf a list of dicts is given, first a dict is sampled uniformly, and\\nthen a parameter is sampled using that dict as above. The number of candidate parameters to sample, at the first\\niteration. Using ‘exhaust’ will sample enough candidates so that the\\nlast iteration uses as many resources as possible, based on\\nmin_resources, max_resources and factor. In this case,\\nmin_resources cannot be ‘exhaust’. The ‘halving’ parameter, which determines the proportion of candidates\\nthat are selected for each subsequent iteration. For example,\\nfactor=3 means that only one third of the candidates are selected. Defines the resource that increases with each iteration. By default,\\nthe resource is the number of samples. It can also be set to any\\nparameter of the base estimator that accepts positive integer\\nvalues, e.g. ‘n_iterations’ or ‘n_estimators’ for a gradient\\nboosting estimator. In this case max_resources cannot be ‘auto’\\nand must be set explicitly. The maximum number of resources that any candidate is allowed to use\\nfor a given iteration. By default, this is set n_samples when\\nresource='n_samples' (default), else an error is raised. The minimum amount of resource that any candidate is allowed to use\\nfor a given iteration. Equivalently, this defines the amount of\\nresources r0 that are allocated for each candidate at the first\\niteration. ‘smallest’ is a heuristic that sets r0 to a small value: n_splits * 2 when resource='n_samples' for a regression\\nproblem n_classes * n_splits * 2 when resource='n_samples' for a\\nclassification problem 1 when resource != 'n_samples' ‘exhaust’ will set r0 such that the last iteration uses as\\nmuch resources as possible. Namely, the last iteration will use the\\nhighest value smaller than max_resources that is a multiple of\\nboth min_resources and factor. In general, using ‘exhaust’\\nleads to a more accurate estimator, but is slightly more time\\nconsuming. ‘exhaust’ isn’t available when n_candidates='exhaust'. Note that the amount of resources used at each iteration is always a\\nmultiple of min_resources. This is only relevant in cases where there isn’t enough resources to\\nreduce the remaining candidates to at most factor after the last\\niteration. If True, then the search process will ‘replay’ the\\nfirst iteration for as long as needed until the number of candidates\\nis small enough. This is False by default, which means that the\\nlast iteration may evaluate more than factor candidates. See\\nAggressive elimination of candidates for more details. Determines the cross-validation splitting strategy.\\nPossible inputs for cv are: integer, to specify the number of folds in a (Stratified)KFold, CV splitter, An iterable yielding (train, test) splits as arrays of indices. For integer/None inputs, if the estimator is a classifier and y is\\neither binary or multiclass, StratifiedKFold is used. In all\\nother cases, KFold is used. These splitters are instantiated\\nwith shuffle=False so the splits will be the same across calls. Refer User Guide for the various\\ncross-validation strategies that can be used here. Note Due to implementation details, the folds produced by cv must be\\nthe same across multiple calls to cv.split(). For\\nbuilt-in scikit-learn iterators, this can be achieved by\\ndeactivating shuffling (shuffle=False), or by setting the\\ncv’s random_state parameter to an integer. A single string (see The scoring parameter: defining model evaluation rules) or a callable\\n(see Defining your scoring strategy from metric functions) to evaluate the predictions on the test set.\\nIf None, the estimator’s score method is used. If True, refit an estimator using the best found parameters on the\\nwhole dataset. The refitted estimator is made available at the best_estimator_\\nattribute and permits using predict directly on this\\nHalvingRandomSearchCV instance. Value to assign to the score if an error occurs in estimator fitting.\\nIf set to ‘raise’, the error is raised. If a numeric value is given,\\nFitFailedWarning is raised. This parameter does not affect the refit\\nstep, which will always raise the error. Default is np.nan. If False, the cv_results_ attribute will not include training\\nscores.\\nComputing training scores is used to get insights on how different\\nparameter settings impact the overfitting/underfitting trade-off.\\nHowever computing the scores on the training set can be computationally\\nexpensive and is not strictly required to select the parameters that\\nyield the best generalization performance. Pseudo random number generator state used for subsampling the dataset\\nwhen resources != 'n_samples'. Also used for random uniform\\nsampling from lists of possible values instead of scipy.stats\\ndistributions.\\nPass an int for reproducible output across multiple function calls.\\nSee Glossary. Number of jobs to run in parallel.\\nNone means 1 unless in a joblib.parallel_backend context.\\n-1 means using all processors. See Glossary\\nfor more details. Controls the verbosity: the higher, the more messages. The amount of resources used at each iteration. The number of candidate parameters that were evaluated at each\\niteration. The number of candidate parameters that are left after the last\\niteration. It corresponds to ceil(n_candidates[-1] / factor) The maximum number of resources that any candidate is allowed to use\\nfor a given iteration. Note that since the number of resources used at\\neach iteration must be a multiple of min_resources_, the actual\\nnumber of resources used at the last iteration may be smaller than\\nmax_resources_. The amount of resources that are allocated for each candidate at the\\nfirst iteration. The actual number of iterations that were run. This is equal to\\nn_required_iterations_ if aggressive_elimination is True.\\nElse, this is equal to min(n_possible_iterations_,\\nn_required_iterations_). The number of iterations that are possible starting with\\nmin_resources_ resources and without exceeding\\nmax_resources_. The number of iterations that are required to end up with less than\\nfactor candidates at the last iteration, starting with\\nmin_resources_ resources. This will be smaller than\\nn_possible_iterations_ when there isn’t enough resources. A dict with keys as column headers and values as columns, that can be\\nimported into a pandas DataFrame. It contains lots of information\\nfor analysing the results of a search.\\nPlease refer to the User guide\\nfor details. Estimator that was chosen by the search, i.e. estimator\\nwhich gave highest score (or smallest loss if specified)\\non the left out data. Not available if refit=False. Mean cross-validated score of the best_estimator. Parameter setting that gave the best results on the hold out data. The index (of the cv_results_ arrays) which corresponds to the best\\ncandidate parameter setting. The dict at search.cv_results_['params'][search.best_index_] gives\\nthe parameter setting for the best model, that gives the highest\\nmean score (search.best_score_). Scorer function used on the held out data to choose the best\\nparameters for the model. The number of cross-validation splits (folds/iterations). Seconds used for refitting the best model on the whole dataset. This is present only if refit is not False. Whether or not the scorers compute several metrics. Class labels. Number of features seen during fit. Names of features seen during fit. Only defined if\\nbest_estimator_ is defined (see the documentation for the refit\\nparameter for more details) and that best_estimator_ exposes\\nfeature_names_in_ when fit. Added in version 1.0. See also Search over a grid of parameters using successive halving. Notes The parameters selected are those that maximize the score of the held-out\\ndata, according to the scoring parameter. All parameter combinations scored with a NaN will share the lowest rank. Examples Class labels. Only available when refit=True and the estimator is a classifier. Call decision_function on the estimator with the best found parameters. Only available if refit=True and the underlying estimator supports\\ndecision_function. Must fulfill the input assumptions of the\\nunderlying estimator. Result of the decision function for X based on the estimator with\\nthe best found parameters. Run fit with all sets of parameters. Training vector, where n_samples is the number of samples and\\nn_features is the number of features. Target relative to X for classification or regression;\\nNone for unsupervised learning. Parameters passed to the fit method of the estimator. Instance of fitted estimator. Get metadata routing of this object. Please check User Guide on how the routing\\nmechanism works. Added in version 1.4. A MetadataRouter encapsulating\\nrouting information. Get parameters for this estimator. If True, will return the parameters for this estimator and\\ncontained subobjects that are estimators. Parameter names mapped to their values. Call inverse_transform on the estimator with the best found params. Only available if the underlying estimator implements\\ninverse_transform and refit=True. Must fulfill the input assumptions of the\\nunderlying estimator. Must fulfill the input assumptions of the\\nunderlying estimator. Deprecated since version 1.5: Xt was deprecated in 1.5 and will be removed in 1.7. Use X instead. Result of the inverse_transform function for Xt based on the\\nestimator with the best found parameters. Number of features seen during fit. Only available when refit=True. Call predict on the estimator with the best found parameters. Only available if refit=True and the underlying estimator supports\\npredict. Must fulfill the input assumptions of the\\nunderlying estimator. The predicted labels or values for X based on the estimator with\\nthe best found parameters. Call predict_log_proba on the estimator with the best found parameters. Only available if refit=True and the underlying estimator supports\\npredict_log_proba. Must fulfill the input assumptions of the\\nunderlying estimator. Predicted class log-probabilities for X based on the estimator\\nwith the best found parameters. The order of the classes\\ncorresponds to that in the fitted attribute classes_. Call predict_proba on the estimator with the best found parameters. Only available if refit=True and the underlying estimator supports\\npredict_proba. Must fulfill the input assumptions of the\\nunderlying estimator. Predicted class probabilities for X based on the estimator with\\nthe best found parameters. The order of the classes corresponds\\nto that in the fitted attribute classes_. Return the score on the given data, if the estimator has been refit. This uses the score defined by scoring where provided, and the\\nbest_estimator_.score method otherwise. Input data, where n_samples is the number of samples and\\nn_features is the number of features. Target relative to X for classification or regression;\\nNone for unsupervised learning. Parameters to be passed to the underlying scorer(s). Only available if enable_metadata_routing=True. See\\nMetadata Routing User Guide for more\\ndetails. The score defined by scoring if provided, and the\\nbest_estimator_.score method otherwise. Call score_samples on the estimator with the best found parameters. Only available if refit=True and the underlying estimator supports\\nscore_samples. Added in version 0.24. Data to predict on. Must fulfill input requirements\\nof the underlying estimator. The best_estimator_.score_samples method. Set the parameters of this estimator. The method works on simple estimators as well as on nested objects\\n(such as Pipeline). The latter have\\nparameters of the form <component>__<parameter> so that it’s\\npossible to update each component of a nested object. Estimator parameters. Estimator instance. Call transform on the estimator with the best found parameters. Only available if the underlying estimator supports transform and\\nrefit=True. Must fulfill the input assumptions of the\\nunderlying estimator. X transformed in the new space based on the estimator with\\nthe best found parameters.\",\n",
       "     'parameter_names_desc': [{'param_name': 'X',\n",
       "       'param_type': 'indexable, length n_samples',\n",
       "       'param_desc': 'Must fulfill the input assumptions of the\\nunderlying estimator.\\n'}]}},\n",
       "   {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ParameterSampler.html#sklearn.model_selection.ParameterSampler',\n",
       "    'function_definitions': {'function_name': 'ParameterSampler',\n",
       "     'full_function': 'class sklearn.model_selection.ParameterSampler(param_distributions, n_iter, *, random_state=None)',\n",
       "     'function_text': 'Generator on parameters sampled from given distributions. Non-deterministic iterable over random candidate combinations for hyper-\\nparameter search. If all parameters are presented as a list,\\nsampling without replacement is performed. If at least one parameter\\nis given as a distribution, sampling with replacement is used.\\nIt is highly recommended to use continuous distributions for continuous\\nparameters. Read more in the User Guide. Dictionary with parameters names (str) as keys and distributions\\nor lists of parameters to try. Distributions must provide a rvs\\nmethod for sampling (such as those from scipy.stats.distributions).\\nIf a list is given, it is sampled uniformly.\\nIf a list of dicts is given, first a dict is sampled uniformly, and\\nthen a parameter is sampled using that dict as above. Number of parameter settings that are produced. Pseudo random number generator state used for random uniform sampling\\nfrom lists of possible values instead of scipy.stats distributions.\\nPass an int for reproducible output across multiple\\nfunction calls.\\nSee Glossary. Yields dictionaries mapping each estimator parameter to\\nas sampled value. Examples',\n",
       "     'parameter_names_desc': [{'param_name': 'param_distributions',\n",
       "       'param_type': 'dict',\n",
       "       'param_desc': 'Dictionary with parameters names (str) as keys and distributions\\nor lists of parameters to try. Distributions must provide a rvs\\nmethod for sampling (such as those from scipy.stats.distributions).\\nIf a list is given, it is sampled uniformly.\\nIf a list of dicts is given, first a dict is sampled uniformly, and\\nthen a parameter is sampled using that dict as above.\\n'},\n",
       "      {'param_name': 'n_iter',\n",
       "       'param_type': 'int',\n",
       "       'param_desc': 'Number of parameter settings that are produced.\\n'},\n",
       "      {'param_name': 'random_state',\n",
       "       'param_type': 'int, RandomState instance or None, default=None',\n",
       "       'param_desc': 'Pseudo random number generator state used for random uniform sampling\\nfrom lists of possible values instead of scipy.stats distributions.\\nPass an int for reproducible output across multiple\\nfunction calls.\\nSee Glossary.\\n'}]}},\n",
       "   {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html#sklearn.model_selection.HalvingGridSearchCV',\n",
       "    'function_definitions': {'function_name': 'HalvingGridSearchCV',\n",
       "     'full_function': \"class sklearn.model_selection.HalvingGridSearchCV(estimator, param_grid, *, factor=3, resource='n_samples', max_resources='auto', min_resources='exhaust', aggressive_elimination=False, cv=5, scoring=None, refit=True, error_score=nan, return_train_score=True, random_state=None, n_jobs=None, verbose=0)\",\n",
       "     'function_text': \"Search over specified parameter values with successive halving. The search strategy starts evaluating all the candidates with a small\\namount of resources and iteratively selects the best candidates, using\\nmore and more resources. Read more in the User guide. Note This estimator is still experimental for now: the predictions\\nand the API might change without any deprecation cycle. To use it,\\nyou need to explicitly import enable_halving_search_cv: This is assumed to implement the scikit-learn estimator interface.\\nEither estimator needs to provide a score function,\\nor scoring must be passed. Dictionary with parameters names (string) as keys and lists of\\nparameter settings to try as values, or a list of such\\ndictionaries, in which case the grids spanned by each dictionary\\nin the list are explored. This enables searching over any sequence\\nof parameter settings. The ‘halving’ parameter, which determines the proportion of candidates\\nthat are selected for each subsequent iteration. For example,\\nfactor=3 means that only one third of the candidates are selected. Defines the resource that increases with each iteration. By default,\\nthe resource is the number of samples. It can also be set to any\\nparameter of the base estimator that accepts positive integer\\nvalues, e.g. ‘n_iterations’ or ‘n_estimators’ for a gradient\\nboosting estimator. In this case max_resources cannot be ‘auto’\\nand must be set explicitly. The maximum amount of resource that any candidate is allowed to use\\nfor a given iteration. By default, this is set to n_samples when\\nresource='n_samples' (default), else an error is raised. The minimum amount of resource that any candidate is allowed to use\\nfor a given iteration. Equivalently, this defines the amount of\\nresources r0 that are allocated for each candidate at the first\\niteration. ‘smallest’ is a heuristic that sets r0 to a small value: n_splits * 2 when resource='n_samples' for a regression\\nproblem n_classes * n_splits * 2 when resource='n_samples' for a\\nclassification problem 1 when resource != 'n_samples' ‘exhaust’ will set r0 such that the last iteration uses as\\nmuch resources as possible. Namely, the last iteration will use the\\nhighest value smaller than max_resources that is a multiple of\\nboth min_resources and factor. In general, using ‘exhaust’\\nleads to a more accurate estimator, but is slightly more time\\nconsuming. Note that the amount of resources used at each iteration is always a\\nmultiple of min_resources. This is only relevant in cases where there isn’t enough resources to\\nreduce the remaining candidates to at most factor after the last\\niteration. If True, then the search process will ‘replay’ the\\nfirst iteration for as long as needed until the number of candidates\\nis small enough. This is False by default, which means that the\\nlast iteration may evaluate more than factor candidates. See\\nAggressive elimination of candidates for more details. Determines the cross-validation splitting strategy.\\nPossible inputs for cv are: integer, to specify the number of folds in a (Stratified)KFold, CV splitter, An iterable yielding (train, test) splits as arrays of indices. For integer/None inputs, if the estimator is a classifier and y is\\neither binary or multiclass, StratifiedKFold is used. In all\\nother cases, KFold is used. These splitters are instantiated\\nwith shuffle=False so the splits will be the same across calls. Refer User Guide for the various\\ncross-validation strategies that can be used here. Note Due to implementation details, the folds produced by cv must be\\nthe same across multiple calls to cv.split(). For\\nbuilt-in scikit-learn iterators, this can be achieved by\\ndeactivating shuffling (shuffle=False), or by setting the\\ncv’s random_state parameter to an integer. A single string (see The scoring parameter: defining model evaluation rules) or a callable\\n(see Defining your scoring strategy from metric functions) to evaluate the predictions on the test set.\\nIf None, the estimator’s score method is used. If True, refit an estimator using the best found parameters on the\\nwhole dataset. The refitted estimator is made available at the best_estimator_\\nattribute and permits using predict directly on this\\nHalvingGridSearchCV instance. Value to assign to the score if an error occurs in estimator fitting.\\nIf set to ‘raise’, the error is raised. If a numeric value is given,\\nFitFailedWarning is raised. This parameter does not affect the refit\\nstep, which will always raise the error. Default is np.nan. If False, the cv_results_ attribute will not include training\\nscores.\\nComputing training scores is used to get insights on how different\\nparameter settings impact the overfitting/underfitting trade-off.\\nHowever computing the scores on the training set can be computationally\\nexpensive and is not strictly required to select the parameters that\\nyield the best generalization performance. Pseudo random number generator state used for subsampling the dataset\\nwhen resources != 'n_samples'. Ignored otherwise.\\nPass an int for reproducible output across multiple function calls.\\nSee Glossary. Number of jobs to run in parallel.\\nNone means 1 unless in a joblib.parallel_backend context.\\n-1 means using all processors. See Glossary\\nfor more details. Controls the verbosity: the higher, the more messages. The amount of resources used at each iteration. The number of candidate parameters that were evaluated at each\\niteration. The number of candidate parameters that are left after the last\\niteration. It corresponds to ceil(n_candidates[-1] / factor) The maximum number of resources that any candidate is allowed to use\\nfor a given iteration. Note that since the number of resources used\\nat each iteration must be a multiple of min_resources_, the\\nactual number of resources used at the last iteration may be smaller\\nthan max_resources_. The amount of resources that are allocated for each candidate at the\\nfirst iteration. The actual number of iterations that were run. This is equal to\\nn_required_iterations_ if aggressive_elimination is True.\\nElse, this is equal to min(n_possible_iterations_,\\nn_required_iterations_). The number of iterations that are possible starting with\\nmin_resources_ resources and without exceeding\\nmax_resources_. The number of iterations that are required to end up with less than\\nfactor candidates at the last iteration, starting with\\nmin_resources_ resources. This will be smaller than\\nn_possible_iterations_ when there isn’t enough resources. A dict with keys as column headers and values as columns, that can be\\nimported into a pandas DataFrame. It contains lots of information\\nfor analysing the results of a search.\\nPlease refer to the User guide\\nfor details. Estimator that was chosen by the search, i.e. estimator\\nwhich gave highest score (or smallest loss if specified)\\non the left out data. Not available if refit=False. Mean cross-validated score of the best_estimator. Parameter setting that gave the best results on the hold out data. The index (of the cv_results_ arrays) which corresponds to the best\\ncandidate parameter setting. The dict at search.cv_results_['params'][search.best_index_] gives\\nthe parameter setting for the best model, that gives the highest\\nmean score (search.best_score_). Scorer function used on the held out data to choose the best\\nparameters for the model. The number of cross-validation splits (folds/iterations). Seconds used for refitting the best model on the whole dataset. This is present only if refit is not False. Whether or not the scorers compute several metrics. Class labels. Number of features seen during fit. Names of features seen during fit. Only defined if\\nbest_estimator_ is defined (see the documentation for the refit\\nparameter for more details) and that best_estimator_ exposes\\nfeature_names_in_ when fit. Added in version 1.0. See also Random search over a set of parameters using successive halving. Notes The parameters selected are those that maximize the score of the held-out\\ndata, according to the scoring parameter. All parameter combinations scored with a NaN will share the lowest rank. Examples Class labels. Only available when refit=True and the estimator is a classifier. Call decision_function on the estimator with the best found parameters. Only available if refit=True and the underlying estimator supports\\ndecision_function. Must fulfill the input assumptions of the\\nunderlying estimator. Result of the decision function for X based on the estimator with\\nthe best found parameters. Run fit with all sets of parameters. Training vector, where n_samples is the number of samples and\\nn_features is the number of features. Target relative to X for classification or regression;\\nNone for unsupervised learning. Parameters passed to the fit method of the estimator. Instance of fitted estimator. Get metadata routing of this object. Please check User Guide on how the routing\\nmechanism works. Added in version 1.4. A MetadataRouter encapsulating\\nrouting information. Get parameters for this estimator. If True, will return the parameters for this estimator and\\ncontained subobjects that are estimators. Parameter names mapped to their values. Call inverse_transform on the estimator with the best found params. Only available if the underlying estimator implements\\ninverse_transform and refit=True. Must fulfill the input assumptions of the\\nunderlying estimator. Must fulfill the input assumptions of the\\nunderlying estimator. Deprecated since version 1.5: Xt was deprecated in 1.5 and will be removed in 1.7. Use X instead. Result of the inverse_transform function for Xt based on the\\nestimator with the best found parameters. Number of features seen during fit. Only available when refit=True. Call predict on the estimator with the best found parameters. Only available if refit=True and the underlying estimator supports\\npredict. Must fulfill the input assumptions of the\\nunderlying estimator. The predicted labels or values for X based on the estimator with\\nthe best found parameters. Call predict_log_proba on the estimator with the best found parameters. Only available if refit=True and the underlying estimator supports\\npredict_log_proba. Must fulfill the input assumptions of the\\nunderlying estimator. Predicted class log-probabilities for X based on the estimator\\nwith the best found parameters. The order of the classes\\ncorresponds to that in the fitted attribute classes_. Call predict_proba on the estimator with the best found parameters. Only available if refit=True and the underlying estimator supports\\npredict_proba. Must fulfill the input assumptions of the\\nunderlying estimator. Predicted class probabilities for X based on the estimator with\\nthe best found parameters. The order of the classes corresponds\\nto that in the fitted attribute classes_. Return the score on the given data, if the estimator has been refit. This uses the score defined by scoring where provided, and the\\nbest_estimator_.score method otherwise. Input data, where n_samples is the number of samples and\\nn_features is the number of features. Target relative to X for classification or regression;\\nNone for unsupervised learning. Parameters to be passed to the underlying scorer(s). Only available if enable_metadata_routing=True. See\\nMetadata Routing User Guide for more\\ndetails. The score defined by scoring if provided, and the\\nbest_estimator_.score method otherwise. Call score_samples on the estimator with the best found parameters. Only available if refit=True and the underlying estimator supports\\nscore_samples. Added in version 0.24. Data to predict on. Must fulfill input requirements\\nof the underlying estimator. The best_estimator_.score_samples method. Set the parameters of this estimator. The method works on simple estimators as well as on nested objects\\n(such as Pipeline). The latter have\\nparameters of the form <component>__<parameter> so that it’s\\npossible to update each component of a nested object. Estimator parameters. Estimator instance. Call transform on the estimator with the best found parameters. Only available if the underlying estimator supports transform and\\nrefit=True. Must fulfill the input assumptions of the\\nunderlying estimator. X transformed in the new space based on the estimator with\\nthe best found parameters.\",\n",
       "     'parameter_names_desc': [{'param_name': 'X',\n",
       "       'param_type': 'indexable, length n_samples',\n",
       "       'param_desc': 'Must fulfill the input assumptions of the\\nunderlying estimator.\\n'}]}},\n",
       "   {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ParameterGrid.html#sklearn.model_selection.ParameterGrid',\n",
       "    'function_definitions': {'function_name': 'ParameterGrid',\n",
       "     'full_function': 'class sklearn.model_selection.ParameterGrid(param_grid)',\n",
       "     'function_text': 'Grid of parameters with a discrete number of values for each. Can be used to iterate over parameter value combinations with the\\nPython built-in function iter.\\nThe order of the generated parameter combinations is deterministic. Read more in the User Guide. The parameter grid to explore, as a dictionary mapping estimator\\nparameters to sequences of allowed values. An empty dict signifies default parameters. A sequence of dicts signifies a sequence of grids to search, and is\\nuseful to avoid exploring parameter combinations that make no sense\\nor have no effect. See the examples below. See also Uses ParameterGrid to perform a full parallelized parameter search. Examples',\n",
       "     'parameter_names_desc': [{'param_name': 'param_grid',\n",
       "       'param_type': 'dict of str to sequence, or sequence of such',\n",
       "       'param_desc': 'The parameter grid to explore, as a dictionary mapping estimator\\nparameters to sequences of allowed values.\\nAn empty dict signifies default parameters.\\nA sequence of dicts signifies a sequence of grids to search, and is\\nuseful to avoid exploring parameter combinations that make no sense\\nor have no effect. See the examples below.\\n'}]}},\n",
       "   {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV',\n",
       "    'function_definitions': {'function_name': 'RandomizedSearchCV',\n",
       "     'full_function': \"class sklearn.model_selection.RandomizedSearchCV(estimator, param_distributions, *, n_iter=10, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', random_state=None, error_score=nan, return_train_score=False)\",\n",
       "     'function_text': \"Randomized search on hyper parameters. RandomizedSearchCV implements a “fit” and a “score” method.\\nIt also implements “score_samples”, “predict”, “predict_proba”,\\n“decision_function”, “transform” and “inverse_transform” if they are\\nimplemented in the estimator used. The parameters of the estimator used to apply these methods are optimized\\nby cross-validated search over parameter settings. In contrast to GridSearchCV, not all parameter values are tried out, but\\nrather a fixed number of parameter settings is sampled from the specified\\ndistributions. The number of parameter settings that are tried is\\ngiven by n_iter. If all parameters are presented as a list,\\nsampling without replacement is performed. If at least one parameter\\nis given as a distribution, sampling with replacement is used.\\nIt is highly recommended to use continuous distributions for continuous\\nparameters. Read more in the User Guide. Added in version 0.14. An object of that type is instantiated for each grid point.\\nThis is assumed to implement the scikit-learn estimator interface.\\nEither estimator needs to provide a score function,\\nor scoring must be passed. Dictionary with parameters names (str) as keys and distributions\\nor lists of parameters to try. Distributions must provide a rvs\\nmethod for sampling (such as those from scipy.stats.distributions).\\nIf a list is given, it is sampled uniformly.\\nIf a list of dicts is given, first a dict is sampled uniformly, and\\nthen a parameter is sampled using that dict as above. Number of parameter settings that are sampled. n_iter trades\\noff runtime vs quality of the solution. Strategy to evaluate the performance of the cross-validated model on\\nthe test set. If scoring represents a single score, one can use: a single string (see The scoring parameter: defining model evaluation rules); a callable (see Defining your scoring strategy from metric functions) that returns a single value. If scoring represents multiple scores, one can use: a list or tuple of unique strings; a callable returning a dictionary where the keys are the metric\\nnames and the values are the metric scores; a dictionary with metric names as keys and callables a values. See Specifying multiple metrics for evaluation for an example. If None, the estimator’s score method is used. Number of jobs to run in parallel.\\nNone means 1 unless in a joblib.parallel_backend context.\\n-1 means using all processors. See Glossary\\nfor more details. Changed in version v0.20: n_jobs default changed from 1 to None Refit an estimator using the best found parameters on the whole\\ndataset. For multiple metric evaluation, this needs to be a str denoting the\\nscorer that would be used to find the best parameters for refitting\\nthe estimator at the end. Where there are considerations other than maximum score in\\nchoosing a best estimator, refit can be set to a function which\\nreturns the selected best_index_ given the cv_results. In that\\ncase, the best_estimator_ and best_params_ will be set\\naccording to the returned best_index_ while the best_score_\\nattribute will not be available. The refitted estimator is made available at the best_estimator_\\nattribute and permits using predict directly on this\\nRandomizedSearchCV instance. Also for multiple metric evaluation, the attributes best_index_,\\nbest_score_ and best_params_ will only be available if\\nrefit is set and all of them will be determined w.r.t this specific\\nscorer. See scoring parameter to know more about multiple metric\\nevaluation. Changed in version 0.20: Support for callable added. Determines the cross-validation splitting strategy.\\nPossible inputs for cv are: None, to use the default 5-fold cross validation, integer, to specify the number of folds in a (Stratified)KFold, CV splitter, An iterable yielding (train, test) splits as arrays of indices. For integer/None inputs, if the estimator is a classifier and y is\\neither binary or multiclass, StratifiedKFold is used. In all\\nother cases, KFold is used. These splitters are instantiated\\nwith shuffle=False so the splits will be the same across calls. Refer User Guide for the various\\ncross-validation strategies that can be used here. Changed in version 0.22: cv default value if None changed from 3-fold to 5-fold. Controls the verbosity: the higher, the more messages. >1 : the computation time for each fold and parameter candidate is\\ndisplayed; >2 : the score is also displayed; >3 : the fold and candidate parameter indexes are also displayed\\ntogether with the starting time of the computation. Controls the number of jobs that get dispatched during parallel\\nexecution. Reducing this number can be useful to avoid an\\nexplosion of memory consumption when more jobs get dispatched\\nthan CPUs can process. This parameter can be: None, in which case all the jobs are immediately\\ncreated and spawned. Use this for lightweight and\\nfast-running jobs, to avoid delays due to on-demand\\nspawning of the jobs An int, giving the exact number of total jobs that are\\nspawned A str, giving an expression as a function of n_jobs,\\nas in ‘2*n_jobs’ Pseudo random number generator state used for random uniform sampling\\nfrom lists of possible values instead of scipy.stats distributions.\\nPass an int for reproducible output across multiple\\nfunction calls.\\nSee Glossary. Value to assign to the score if an error occurs in estimator fitting.\\nIf set to ‘raise’, the error is raised. If a numeric value is given,\\nFitFailedWarning is raised. This parameter does not affect the refit\\nstep, which will always raise the error. If False, the cv_results_ attribute will not include training\\nscores.\\nComputing training scores is used to get insights on how different\\nparameter settings impact the overfitting/underfitting trade-off.\\nHowever computing the scores on the training set can be computationally\\nexpensive and is not strictly required to select the parameters that\\nyield the best generalization performance. Added in version 0.19. Changed in version 0.21: Default value was changed from True to False A dict with keys as column headers and values as columns, that can be\\nimported into a pandas DataFrame. For instance the below given table param_kernel param_gamma split0_test_score … rank_test_score ‘rbf’ 0.1 0.80 … 1 ‘rbf’ 0.2 0.84 … 3 ‘rbf’ 0.3 0.70 … 2 will be represented by a cv_results_ dict of: NOTE The key 'params' is used to store a list of parameter\\nsettings dicts for all the parameter candidates. The mean_fit_time, std_fit_time, mean_score_time and\\nstd_score_time are all in seconds. For multi-metric evaluation, the scores for all the scorers are\\navailable in the cv_results_ dict at the keys ending with that\\nscorer’s name ('_<scorer_name>') instead of '_score' shown\\nabove. (‘split0_test_precision’, ‘mean_train_precision’ etc.) Estimator that was chosen by the search, i.e. estimator\\nwhich gave highest score (or smallest loss if specified)\\non the left out data. Not available if refit=False. For multi-metric evaluation, this attribute is present only if\\nrefit is specified. See refit parameter for more information on allowed values. Mean cross-validated score of the best_estimator. For multi-metric evaluation, this is not available if refit is\\nFalse. See refit parameter for more information. This attribute is not available if refit is a function. Parameter setting that gave the best results on the hold out data. For multi-metric evaluation, this is not available if refit is\\nFalse. See refit parameter for more information. The index (of the cv_results_ arrays) which corresponds to the best\\ncandidate parameter setting. The dict at search.cv_results_['params'][search.best_index_] gives\\nthe parameter setting for the best model, that gives the highest\\nmean score (search.best_score_). For multi-metric evaluation, this is not available if refit is\\nFalse. See refit parameter for more information. Scorer function used on the held out data to choose the best\\nparameters for the model. For multi-metric evaluation, this attribute holds the validated\\nscoring dict which maps the scorer key to the scorer callable. The number of cross-validation splits (folds/iterations). Seconds used for refitting the best model on the whole dataset. This is present only if refit is not False. Added in version 0.20. Whether or not the scorers compute several metrics. Class labels. Number of features seen during fit. Names of features seen during fit. Only defined if\\nbest_estimator_ is defined (see the documentation for the refit\\nparameter for more details) and that best_estimator_ exposes\\nfeature_names_in_ when fit. Added in version 1.0. See also Does exhaustive search over a grid of parameters. A generator over parameter settings, constructed from param_distributions. Notes The parameters selected are those that maximize the score of the held-out\\ndata, according to the scoring parameter. If n_jobs was set to a value higher than one, the data is copied for each\\nparameter setting(and not n_jobs times). This is done for efficiency\\nreasons if individual jobs take very little time, but may raise errors if\\nthe dataset is large and not enough memory is available.  A workaround in\\nthis case is to set pre_dispatch. Then, the memory is copied only\\npre_dispatch many times. A reasonable value for pre_dispatch is 2 *\\nn_jobs. Examples Class labels. Only available when refit=True and the estimator is a classifier. Call decision_function on the estimator with the best found parameters. Only available if refit=True and the underlying estimator supports\\ndecision_function. Must fulfill the input assumptions of the\\nunderlying estimator. Result of the decision function for X based on the estimator with\\nthe best found parameters. Run fit with all sets of parameters. Training vector, where n_samples is the number of samples and\\nn_features is the number of features. Target relative to X for classification or regression;\\nNone for unsupervised learning. Parameters passed to the fit method of the estimator, the scorer,\\nand the CV splitter. If a fit parameter is an array-like whose length is equal to\\nnum_samples then it will be split across CV groups along with X\\nand y. For example, the sample_weight parameter is split\\nbecause len(sample_weights) = len(X). Instance of fitted estimator. Get metadata routing of this object. Please check User Guide on how the routing\\nmechanism works. Added in version 1.4. A MetadataRouter encapsulating\\nrouting information. Get parameters for this estimator. If True, will return the parameters for this estimator and\\ncontained subobjects that are estimators. Parameter names mapped to their values. Call inverse_transform on the estimator with the best found params. Only available if the underlying estimator implements\\ninverse_transform and refit=True. Must fulfill the input assumptions of the\\nunderlying estimator. Must fulfill the input assumptions of the\\nunderlying estimator. Deprecated since version 1.5: Xt was deprecated in 1.5 and will be removed in 1.7. Use X instead. Result of the inverse_transform function for Xt based on the\\nestimator with the best found parameters. Number of features seen during fit. Only available when refit=True. Call predict on the estimator with the best found parameters. Only available if refit=True and the underlying estimator supports\\npredict. Must fulfill the input assumptions of the\\nunderlying estimator. The predicted labels or values for X based on the estimator with\\nthe best found parameters. Call predict_log_proba on the estimator with the best found parameters. Only available if refit=True and the underlying estimator supports\\npredict_log_proba. Must fulfill the input assumptions of the\\nunderlying estimator. Predicted class log-probabilities for X based on the estimator\\nwith the best found parameters. The order of the classes\\ncorresponds to that in the fitted attribute classes_. Call predict_proba on the estimator with the best found parameters. Only available if refit=True and the underlying estimator supports\\npredict_proba. Must fulfill the input assumptions of the\\nunderlying estimator. Predicted class probabilities for X based on the estimator with\\nthe best found parameters. The order of the classes corresponds\\nto that in the fitted attribute classes_. Return the score on the given data, if the estimator has been refit. This uses the score defined by scoring where provided, and the\\nbest_estimator_.score method otherwise. Input data, where n_samples is the number of samples and\\nn_features is the number of features. Target relative to X for classification or regression;\\nNone for unsupervised learning. Parameters to be passed to the underlying scorer(s). Only available if enable_metadata_routing=True. See\\nMetadata Routing User Guide for more\\ndetails. The score defined by scoring if provided, and the\\nbest_estimator_.score method otherwise. Call score_samples on the estimator with the best found parameters. Only available if refit=True and the underlying estimator supports\\nscore_samples. Added in version 0.24. Data to predict on. Must fulfill input requirements\\nof the underlying estimator. The best_estimator_.score_samples method. Set the parameters of this estimator. The method works on simple estimators as well as on nested objects\\n(such as Pipeline). The latter have\\nparameters of the form <component>__<parameter> so that it’s\\npossible to update each component of a nested object. Estimator parameters. Estimator instance. Call transform on the estimator with the best found parameters. Only available if the underlying estimator supports transform and\\nrefit=True. Must fulfill the input assumptions of the\\nunderlying estimator. X transformed in the new space based on the estimator with\\nthe best found parameters.\",\n",
       "     'parameter_names_desc': [{'param_name': 'X',\n",
       "       'param_type': 'indexable, length n_samples',\n",
       "       'param_desc': 'Must fulfill the input assumptions of the\\nunderlying estimator.\\n'}]}}]},\n",
       " {'Post-fit model tuning': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.FixedThresholdClassifier.html#sklearn.model_selection.FixedThresholdClassifier',\n",
       "    'function_definitions': {'function_name': 'FixedThresholdClassifier',\n",
       "     'full_function': \"class sklearn.model_selection.FixedThresholdClassifier(estimator, *, threshold='auto', pos_label=None, response_method='auto')\",\n",
       "     'function_text': 'Binary classifier that manually sets the decision threshold. This classifier allows to change the default decision threshold used for\\nconverting posterior probability estimates (i.e. output of predict_proba) or\\ndecision scores (i.e. output of decision_function) into a class label. Here, the threshold is not optimized and is set to a constant value. Read more in the User Guide. Added in version 1.5. The binary classifier, fitted or not, for which we want to optimize\\nthe decision threshold used during predict. The decision threshold to use when converting posterior probability estimates\\n(i.e. output of predict_proba) or decision scores (i.e. output of\\ndecision_function) into a class label. When \"auto\", the threshold is set\\nto 0.5 if predict_proba is used as response_method, otherwise it is set to\\n0 (i.e. the default threshold for decision_function). The label of the positive class. Used to process the output of the\\nresponse_method method. When pos_label=None, if y_true is in {-1, 1} or\\n{0, 1}, pos_label is set to 1, otherwise an error will be raised. Methods by the classifier estimator corresponding to the\\ndecision function for which we want to find a threshold. It can be: if \"auto\", it will try to invoke \"predict_proba\" or \"decision_function\"\\nin that order. otherwise, one of \"predict_proba\" or \"decision_function\".\\nIf the method is not implemented by the classifier, it will raise an\\nerror. The fitted classifier used when predicting. Classes labels. Number of features seen during fit. Only defined if the\\nunderlying estimator exposes such an attribute when fit. Names of features seen during fit. Only defined if the\\nunderlying estimator exposes such an attribute when fit. See also Classifier that post-tunes the decision threshold based on some metrics and using cross-validation. Estimator that calibrates probabilities. Examples Classes labels. Decision function for samples in X using the fitted estimator. Training vectors, where n_samples is the number of samples and\\nn_features is the number of features. The decision function computed the fitted estimator. Fit the classifier. Training data. Target values. Parameters to pass to the fit method of the underlying\\nclassifier. Returns an instance of self. Get metadata routing of this object. Please check User Guide on how the routing\\nmechanism works. A MetadataRouter encapsulating\\nrouting information. Get parameters for this estimator. If True, will return the parameters for this estimator and\\ncontained subobjects that are estimators. Parameter names mapped to their values. Predict the target of new samples. The samples, as accepted by estimator.predict. The predicted class. Predict logarithm class probabilities for X using the fitted estimator. Training vectors, where n_samples is the number of samples and\\nn_features is the number of features. The logarithm class probabilities of the input samples. Predict class probabilities for X using the fitted estimator. Training vectors, where n_samples is the number of samples and\\nn_features is the number of features. The class probabilities of the input samples. Return the mean accuracy on the given test data and labels. In multi-label classification, this is the subset accuracy\\nwhich is a harsh metric since you require for each sample that\\neach label set be correctly predicted. Test samples. True labels for X. Sample weights. Mean accuracy of self.predict(X) w.r.t. y. Set the parameters of this estimator. The method works on simple estimators as well as on nested objects\\n(such as Pipeline). The latter have\\nparameters of the form <component>__<parameter> so that it’s\\npossible to update each component of a nested object. Estimator parameters. Estimator instance. Request metadata passed to the score method. Note that this method is only relevant if\\nenable_metadata_routing=True (see sklearn.set_config).\\nPlease see User Guide on how the routing\\nmechanism works. The options for each parameter are: True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided. False: metadata is not requested and the meta-estimator will not pass it to score. None: metadata is not requested, and the meta-estimator will raise an error if the user provides it. str: metadata should be passed to the meta-estimator with this given alias instead of the original name. The default (sklearn.utils.metadata_routing.UNCHANGED) retains the\\nexisting request. This allows you to change the request for some\\nparameters and not others. Added in version 1.3. Note This method is only relevant if this estimator is used as a\\nsub-estimator of a meta-estimator, e.g. used inside a\\nPipeline. Otherwise it has no effect. Metadata routing for sample_weight parameter in score. The updated object.',\n",
       "     'parameter_names_desc': [{'param_name': 'sample_weight',\n",
       "       'param_type': 'str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED',\n",
       "       'param_desc': 'Metadata routing for sample_weight parameter in score.\\n'}]}},\n",
       "   {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TunedThresholdClassifierCV.html#sklearn.model_selection.TunedThresholdClassifierCV',\n",
       "    'function_definitions': {'function_name': 'TunedThresholdClassifierCV',\n",
       "     'full_function': \"class sklearn.model_selection.TunedThresholdClassifierCV(estimator, *, scoring='balanced_accuracy', response_method='auto', thresholds=100, cv=None, refit=True, n_jobs=None, random_state=None, store_cv_results=False)\",\n",
       "     'function_text': 'Classifier that post-tunes the decision threshold using cross-validation. This estimator post-tunes the decision threshold (cut-off point) that is\\nused for converting posterior probability estimates (i.e. output of\\npredict_proba) or decision scores (i.e. output of decision_function)\\ninto a class label. The tuning is done by optimizing a binary metric,\\npotentially constrained by a another metric. Read more in the User Guide. Added in version 1.5. The classifier, fitted or not, for which we want to optimize\\nthe decision threshold used during predict. The objective metric to be optimized. Can be one of: a string associated to a scoring function for binary classification\\n(see model evaluation documentation); a scorer callable object created with make_scorer; Methods by the classifier estimator corresponding to the\\ndecision function for which we want to find a threshold. It can be: if \"auto\", it will try to invoke, for each classifier,\\n\"predict_proba\" or \"decision_function\" in that order. otherwise, one of \"predict_proba\" or \"decision_function\".\\nIf the method is not implemented by the classifier, it will raise an\\nerror. The number of decision threshold to use when discretizing the output of the\\nclassifier method. Pass an array-like to manually specify the thresholds\\nto use. Determines the cross-validation splitting strategy to train classifier.\\nPossible inputs for cv are: None, to use the default 5-fold stratified K-fold cross validation; An integer number, to specify the number of folds in a stratified k-fold; A float number, to specify a single shuffle split. The floating number should\\nbe in (0, 1) and represent the size of the validation set; An object to be used as a cross-validation generator; An iterable yielding train, test splits; \"prefit\", to bypass the cross-validation. Refer User Guide for the various\\ncross-validation strategies that can be used here. Warning Using cv=\"prefit\" and passing the same dataset for fitting estimator\\nand tuning the cut-off point is subject to undesired overfitting. You can\\nrefer to Consideration regarding model refitting and cross-validation for an example. This option should only be used when the set used to fit estimator is\\ndifferent from the one used to tune the cut-off point (by calling\\nTunedThresholdClassifierCV.fit). Whether or not to refit the classifier on the entire training set once\\nthe decision threshold has been found.\\nNote that forcing refit=False on cross-validation having more\\nthan a single split will raise an error. Similarly, refit=True in\\nconjunction with cv=\"prefit\" will raise an error. The number of jobs to run in parallel. When cv represents a\\ncross-validation strategy, the fitting and scoring on each data split\\nis done in parallel. None means 1 unless in a\\njoblib.parallel_backend context. -1 means using all\\nprocessors. See Glossary for more details. Controls the randomness of cross-validation when cv is a float.\\nSee Glossary. Whether to store all scores and thresholds computed during the cross-validation\\nprocess. The fitted classifier used when predicting. The new decision threshold. The optimal score of the objective metric, evaluated at best_threshold_. A dictionary containing the scores and thresholds computed during the\\ncross-validation process. Only exist if store_cv_results=True. The\\nkeys are \"thresholds\" and \"scores\". Classes labels. Number of features seen during fit. Only defined if the\\nunderlying estimator exposes such an attribute when fit. Names of features seen during fit. Only defined if the\\nunderlying estimator exposes such an attribute when fit. See also Classifier that uses a constant threshold. Estimator that calibrates probabilities. Examples Classes labels. Decision function for samples in X using the fitted estimator. Training vectors, where n_samples is the number of samples and\\nn_features is the number of features. The decision function computed the fitted estimator. Fit the classifier. Training data. Target values. Parameters to pass to the fit method of the underlying\\nclassifier. Returns an instance of self. Get metadata routing of this object. Please check User Guide on how the routing\\nmechanism works. A MetadataRouter encapsulating\\nrouting information. Get parameters for this estimator. If True, will return the parameters for this estimator and\\ncontained subobjects that are estimators. Parameter names mapped to their values. Predict the target of new samples. The samples, as accepted by estimator.predict. The predicted class. Predict logarithm class probabilities for X using the fitted estimator. Training vectors, where n_samples is the number of samples and\\nn_features is the number of features. The logarithm class probabilities of the input samples. Predict class probabilities for X using the fitted estimator. Training vectors, where n_samples is the number of samples and\\nn_features is the number of features. The class probabilities of the input samples. Return the mean accuracy on the given test data and labels. In multi-label classification, this is the subset accuracy\\nwhich is a harsh metric since you require for each sample that\\neach label set be correctly predicted. Test samples. True labels for X. Sample weights. Mean accuracy of self.predict(X) w.r.t. y. Set the parameters of this estimator. The method works on simple estimators as well as on nested objects\\n(such as Pipeline). The latter have\\nparameters of the form <component>__<parameter> so that it’s\\npossible to update each component of a nested object. Estimator parameters. Estimator instance. Request metadata passed to the score method. Note that this method is only relevant if\\nenable_metadata_routing=True (see sklearn.set_config).\\nPlease see User Guide on how the routing\\nmechanism works. The options for each parameter are: True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided. False: metadata is not requested and the meta-estimator will not pass it to score. None: metadata is not requested, and the meta-estimator will raise an error if the user provides it. str: metadata should be passed to the meta-estimator with this given alias instead of the original name. The default (sklearn.utils.metadata_routing.UNCHANGED) retains the\\nexisting request. This allows you to change the request for some\\nparameters and not others. Added in version 1.3. Note This method is only relevant if this estimator is used as a\\nsub-estimator of a meta-estimator, e.g. used inside a\\nPipeline. Otherwise it has no effect. Metadata routing for sample_weight parameter in score. The updated object.',\n",
       "     'parameter_names_desc': [{'param_name': 'sample_weight',\n",
       "       'param_type': 'str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED',\n",
       "       'param_desc': 'Metadata routing for sample_weight parameter in score.\\n'}]}}]},\n",
       " {'Model validation': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html#sklearn.model_selection.cross_val_predict',\n",
       "    'function_definitions': {'function_name': 'cross_val_predict',\n",
       "     'full_function': \"sklearn.model_selection.cross_val_predict(estimator, X, y=None, *, groups=None, cv=None, n_jobs=None, verbose=0, fit_params=None, params=None, pre_dispatch='2*n_jobs', method='predict')\",\n",
       "     'function_text': \"Generate cross-validated estimates for each input data point. The data is split according to the cv parameter. Each sample belongs\\nto exactly one test set, and its prediction is computed with an\\nestimator fitted on the corresponding training set. Passing these predictions into an evaluation metric may not be a valid\\nway to measure generalization performance. Results can differ from\\ncross_validate and cross_val_score unless all tests sets\\nhave equal size and the metric decomposes over samples. Read more in the User Guide. The estimator instance to use to fit the data. It must implement a fit\\nmethod and the method given by the method parameter. The data to fit. Can be, for example a list, or an array at least 2d. The target variable to try to predict in the case of\\nsupervised learning. Group labels for the samples used while splitting the dataset into\\ntrain/test set. Only used in conjunction with a “Group” cv\\ninstance (e.g., GroupKFold). Changed in version 1.4: groups can only be passed if metadata routing is not enabled\\nvia sklearn.set_config(enable_metadata_routing=True). When routing\\nis enabled, pass groups alongside other metadata via the params\\nargument instead. E.g.:\\ncross_val_predict(..., params={'groups': groups}). Determines the cross-validation splitting strategy.\\nPossible inputs for cv are: None, to use the default 5-fold cross validation, int, to specify the number of folds in a (Stratified)KFold, CV splitter, An iterable that generates (train, test) splits as arrays of indices. For int/None inputs, if the estimator is a classifier and y is\\neither binary or multiclass, StratifiedKFold is used. In all\\nother cases, KFold is used. These splitters are instantiated\\nwith shuffle=False so the splits will be the same across calls. Refer User Guide for the various\\ncross-validation strategies that can be used here. Changed in version 0.22: cv default value if None changed from 3-fold to 5-fold. Number of jobs to run in parallel. Training the estimator and\\npredicting are parallelized over the cross-validation splits.\\nNone means 1 unless in a joblib.parallel_backend context.\\n-1 means using all processors. See Glossary\\nfor more details. The verbosity level. Parameters to pass to the fit method of the estimator. Deprecated since version 1.4: This parameter is deprecated and will be removed in version 1.6. Use\\nparams instead. Parameters to pass to the underlying estimator’s fit and the CV\\nsplitter. Added in version 1.4. Controls the number of jobs that get dispatched during parallel\\nexecution. Reducing this number can be useful to avoid an\\nexplosion of memory consumption when more jobs get dispatched\\nthan CPUs can process. This parameter can be: None, in which case all the jobs are immediately\\ncreated and spawned. Use this for lightweight and\\nfast-running jobs, to avoid delays due to on-demand\\nspawning of the jobs An int, giving the exact number of total jobs that are\\nspawned A str, giving an expression as a function of n_jobs,\\nas in ‘2*n_jobs’ The method to be invoked by estimator. This is the result of calling method. Shape: When method is ‘predict’ and in special case where method is\\n‘decision_function’ and the target is binary: (n_samples,) When method is one of {‘predict_proba’, ‘predict_log_proba’,\\n‘decision_function’} (unless special case above):\\n(n_samples, n_classes) If estimator is multioutput, an extra dimension\\n‘n_outputs’ is added to the end of each shape above. See also Calculate score for each CV split. Calculate one or more scores and timings for each CV split. Notes In the case that one or more classes are absent in a training portion, a\\ndefault score needs to be assigned to all instances for that class if\\nmethod produces columns per class, as in {‘decision_function’,\\n‘predict_proba’, ‘predict_log_proba’}.  For predict_proba this value is\\n0.  In order to ensure finite output, we approximate negative infinity by\\nthe minimum finite float value for the dtype in other cases. Examples\",\n",
       "     'parameter_names_desc': [{'param_name': 'estimator',\n",
       "       'param_type': 'estimator',\n",
       "       'param_desc': 'The estimator instance to use to fit the data. It must implement a fit\\nmethod and the method given by the method parameter.\\n'},\n",
       "      {'param_name': 'X',\n",
       "       'param_type': '{array-like, sparse matrix} of shape (n_samples, n_features)',\n",
       "       'param_desc': 'The data to fit. Can be, for example a list, or an array at least 2d.\\n'},\n",
       "      {'param_name': 'y',\n",
       "       'param_type': '{array-like, sparse matrix} of shape (n_samples,) or (n_samples, n_outputs),             default=None',\n",
       "       'param_desc': 'The target variable to try to predict in the case of\\nsupervised learning.\\n'},\n",
       "      {'param_name': 'groups',\n",
       "       'param_type': 'array-like of shape (n_samples,), default=None',\n",
       "       'param_desc': \"Group labels for the samples used while splitting the dataset into\\ntrain/test set. Only used in conjunction with a “Group” cv\\ninstance (e.g., GroupKFold).\\n\\nChanged in version 1.4: groups can only be passed if metadata routing is not enabled\\nvia sklearn.set_config(enable_metadata_routing=True). When routing\\nis enabled, pass groups alongside other metadata via the params\\nargument instead. E.g.:\\ncross_val_predict(..., params={'groups': groups}).\\n\\n\"},\n",
       "      {'param_name': 'cv',\n",
       "       'param_type': 'int, cross-validation generator or an iterable, default=None',\n",
       "       'param_desc': 'Determines the cross-validation splitting strategy.\\nPossible inputs for cv are:\\n\\nNone, to use the default 5-fold cross validation,\\nint, to specify the number of folds in a (Stratified)KFold,\\nCV splitter,\\nAn iterable that generates (train, test) splits as arrays of indices.\\n\\nFor int/None inputs, if the estimator is a classifier and y is\\neither binary or multiclass, StratifiedKFold is used. In all\\nother cases, KFold is used. These splitters are instantiated\\nwith shuffle=False so the splits will be the same across calls.\\nRefer User Guide for the various\\ncross-validation strategies that can be used here.\\n\\nChanged in version 0.22: cv default value if None changed from 3-fold to 5-fold.\\n\\n'},\n",
       "      {'param_name': 'n_jobs',\n",
       "       'param_type': 'int, default=None',\n",
       "       'param_desc': 'Number of jobs to run in parallel. Training the estimator and\\npredicting are parallelized over the cross-validation splits.\\nNone means 1 unless in a joblib.parallel_backend context.\\n-1 means using all processors. See Glossary\\nfor more details.\\n'},\n",
       "      {'param_name': 'verbose',\n",
       "       'param_type': 'int, default=0',\n",
       "       'param_desc': 'The verbosity level.\\n'},\n",
       "      {'param_name': 'fit_params',\n",
       "       'param_type': 'dict, default=None',\n",
       "       'param_desc': 'Parameters to pass to the fit method of the estimator.\\n\\nDeprecated since version 1.4: This parameter is deprecated and will be removed in version 1.6. Use\\nparams instead.\\n\\n'},\n",
       "      {'param_name': 'params',\n",
       "       'param_type': 'dict, default=None',\n",
       "       'param_desc': 'Parameters to pass to the underlying estimator’s fit and the CV\\nsplitter.\\n\\nAdded in version 1.4.\\n\\n'},\n",
       "      {'param_name': 'pre_dispatch',\n",
       "       'param_type': 'int or str, default=’2*n_jobs’',\n",
       "       'param_desc': 'Controls the number of jobs that get dispatched during parallel\\nexecution. Reducing this number can be useful to avoid an\\nexplosion of memory consumption when more jobs get dispatched\\nthan CPUs can process. This parameter can be:\\n\\n\\nNone, in which case all the jobs are immediately\\ncreated and spawned. Use this for lightweight and\\nfast-running jobs, to avoid delays due to on-demand\\nspawning of the jobs\\nAn int, giving the exact number of total jobs that are\\nspawned\\nA str, giving an expression as a function of n_jobs,\\nas in ‘2*n_jobs’\\n\\n\\n'},\n",
       "      {'param_name': 'method',\n",
       "       'param_type': '{‘predict’, ‘predict_proba’, ‘predict_log_proba’,               ‘decision_function’}, default=’predict’',\n",
       "       'param_desc': 'The method to be invoked by estimator.\\n'}]}},\n",
       "   {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate',\n",
       "    'function_definitions': {'function_name': 'cross_validate',\n",
       "     'full_function': \"sklearn.model_selection.cross_validate(estimator, X, y=None, *, groups=None, scoring=None, cv=None, n_jobs=None, verbose=0, fit_params=None, params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, return_indices=False, error_score=nan)\",\n",
       "     'function_text': 'Evaluate metric(s) by cross-validation and also record fit/score times. Read more in the User Guide. The object to use to fit the data. The data to fit. Can be for example a list, or an array. The target variable to try to predict in the case of\\nsupervised learning. Group labels for the samples used while splitting the dataset into\\ntrain/test set. Only used in conjunction with a “Group” cv\\ninstance (e.g., GroupKFold). Changed in version 1.4: groups can only be passed if metadata routing is not enabled\\nvia sklearn.set_config(enable_metadata_routing=True). When routing\\nis enabled, pass groups alongside other metadata via the params\\nargument instead. E.g.:\\ncross_validate(..., params={\\'groups\\': groups}). Strategy to evaluate the performance of the cross-validated model on\\nthe test set. If scoring represents a single score, one can use: a single string (see The scoring parameter: defining model evaluation rules); a callable (see Defining your scoring strategy from metric functions) that returns a single value. If scoring represents multiple scores, one can use: a list or tuple of unique strings; a callable returning a dictionary where the keys are the metric\\nnames and the values are the metric scores; a dictionary with metric names as keys and callables a values. See Specifying multiple metrics for evaluation for an example. Determines the cross-validation splitting strategy.\\nPossible inputs for cv are: None, to use the default 5-fold cross validation, int, to specify the number of folds in a (Stratified)KFold, CV splitter, An iterable yielding (train, test) splits as arrays of indices. For int/None inputs, if the estimator is a classifier and y is\\neither binary or multiclass, StratifiedKFold is used. In all\\nother cases, KFold is used. These splitters are instantiated\\nwith shuffle=False so the splits will be the same across calls. Refer User Guide for the various\\ncross-validation strategies that can be used here. Changed in version 0.22: cv default value if None changed from 3-fold to 5-fold. Number of jobs to run in parallel. Training the estimator and computing\\nthe score are parallelized over the cross-validation splits.\\nNone means 1 unless in a joblib.parallel_backend context.\\n-1 means using all processors. See Glossary\\nfor more details. The verbosity level. Parameters to pass to the fit method of the estimator. Deprecated since version 1.4: This parameter is deprecated and will be removed in version 1.6. Use\\nparams instead. Parameters to pass to the underlying estimator’s fit, the scorer,\\nand the CV splitter. Added in version 1.4. Controls the number of jobs that get dispatched during parallel\\nexecution. Reducing this number can be useful to avoid an\\nexplosion of memory consumption when more jobs get dispatched\\nthan CPUs can process. This parameter can be: An int, giving the exact number of total jobs that are\\nspawned A str, giving an expression as a function of n_jobs,\\nas in ‘2*n_jobs’ Whether to include train scores.\\nComputing training scores is used to get insights on how different\\nparameter settings impact the overfitting/underfitting trade-off.\\nHowever computing the scores on the training set can be computationally\\nexpensive and is not strictly required to select the parameters that\\nyield the best generalization performance. Added in version 0.19. Changed in version 0.21: Default value was changed from True to False Whether to return the estimators fitted on each split. Added in version 0.20. Whether to return the train-test indices selected for each split. Added in version 1.3. Value to assign to the score if an error occurs in estimator fitting.\\nIf set to ‘raise’, the error is raised.\\nIf a numeric value is given, FitFailedWarning is raised. Added in version 0.20. Array of scores of the estimator for each run of the cross validation. A dict of arrays containing the score/time arrays for each scorer is\\nreturned. The possible keys for this dict are: The score array for test scores on each cv split.\\nSuffix _score in test_score changes to a specific\\nmetric like test_r2 or test_auc if there are\\nmultiple scoring metrics in the scoring parameter. The score array for train scores on each cv split.\\nSuffix _score in train_score changes to a specific\\nmetric like train_r2 or train_auc if there are\\nmultiple scoring metrics in the scoring parameter.\\nThis is available only if return_train_score parameter\\nis True. The time for fitting the estimator on the train\\nset for each cv split. The time for scoring the estimator on the test set for each\\ncv split. (Note time for scoring on the train set is not\\nincluded even if return_train_score is set to True The estimator objects for each cv split.\\nThis is available only if return_estimator parameter\\nis set to True. The train/test positional indices for each cv split. A dictionary\\nis returned where the keys are either \"train\" or \"test\"\\nand the associated values are a list of integer-dtyped NumPy\\narrays with the indices. Available only if return_indices=True. See also Run cross-validation for single metric evaluation. Get predictions from each split of cross-validation for diagnostic purposes. Make a scorer from a performance metric or loss function. Examples Single metric evaluation using cross_validate Multiple metric evaluation using cross_validate\\n(please refer the scoring parameter doc for more information)',\n",
       "     'parameter_names_desc': [{'param_name': 'estimator',\n",
       "       'param_type': 'estimator object implementing ‘fit’',\n",
       "       'param_desc': 'The object to use to fit the data.\\n'},\n",
       "      {'param_name': 'X',\n",
       "       'param_type': '{array-like, sparse matrix} of shape (n_samples, n_features)',\n",
       "       'param_desc': 'The data to fit. Can be for example a list, or an array.\\n'},\n",
       "      {'param_name': 'y',\n",
       "       'param_type': 'array-like of shape (n_samples,) or (n_samples, n_outputs), default=None',\n",
       "       'param_desc': 'The target variable to try to predict in the case of\\nsupervised learning.\\n'},\n",
       "      {'param_name': 'groups',\n",
       "       'param_type': 'array-like of shape (n_samples,), default=None',\n",
       "       'param_desc': \"Group labels for the samples used while splitting the dataset into\\ntrain/test set. Only used in conjunction with a “Group” cv\\ninstance (e.g., GroupKFold).\\n\\nChanged in version 1.4: groups can only be passed if metadata routing is not enabled\\nvia sklearn.set_config(enable_metadata_routing=True). When routing\\nis enabled, pass groups alongside other metadata via the params\\nargument instead. E.g.:\\ncross_validate(..., params={'groups': groups}).\\n\\n\"},\n",
       "      {'param_name': 'scoring',\n",
       "       'param_type': 'str, callable, list, tuple, or dict, default=None',\n",
       "       'param_desc': 'Strategy to evaluate the performance of the cross-validated model on\\nthe test set.\\nIf scoring represents a single score, one can use:\\n\\na single string (see The scoring parameter: defining model evaluation rules);\\na callable (see Defining your scoring strategy from metric functions) that returns a single value.\\n\\nIf scoring represents multiple scores, one can use:\\n\\na list or tuple of unique strings;\\na callable returning a dictionary where the keys are the metric\\nnames and the values are the metric scores;\\na dictionary with metric names as keys and callables a values.\\n\\nSee Specifying multiple metrics for evaluation for an example.\\n'},\n",
       "      {'param_name': 'cv',\n",
       "       'param_type': 'int, cross-validation generator or an iterable, default=None',\n",
       "       'param_desc': 'Determines the cross-validation splitting strategy.\\nPossible inputs for cv are:\\n\\nNone, to use the default 5-fold cross validation,\\nint, to specify the number of folds in a (Stratified)KFold,\\nCV splitter,\\nAn iterable yielding (train, test) splits as arrays of indices.\\n\\nFor int/None inputs, if the estimator is a classifier and y is\\neither binary or multiclass, StratifiedKFold is used. In all\\nother cases, KFold is used. These splitters are instantiated\\nwith shuffle=False so the splits will be the same across calls.\\nRefer User Guide for the various\\ncross-validation strategies that can be used here.\\n\\nChanged in version 0.22: cv default value if None changed from 3-fold to 5-fold.\\n\\n'},\n",
       "      {'param_name': 'n_jobs',\n",
       "       'param_type': 'int, default=None',\n",
       "       'param_desc': 'Number of jobs to run in parallel. Training the estimator and computing\\nthe score are parallelized over the cross-validation splits.\\nNone means 1 unless in a joblib.parallel_backend context.\\n-1 means using all processors. See Glossary\\nfor more details.\\n'},\n",
       "      {'param_name': 'verbose',\n",
       "       'param_type': 'int, default=0',\n",
       "       'param_desc': 'The verbosity level.\\n'},\n",
       "      {'param_name': 'fit_params',\n",
       "       'param_type': 'dict, default=None',\n",
       "       'param_desc': 'Parameters to pass to the fit method of the estimator.\\n\\nDeprecated since version 1.4: This parameter is deprecated and will be removed in version 1.6. Use\\nparams instead.\\n\\n'},\n",
       "      {'param_name': 'params',\n",
       "       'param_type': 'dict, default=None',\n",
       "       'param_desc': 'Parameters to pass to the underlying estimator’s fit, the scorer,\\nand the CV splitter.\\n\\nAdded in version 1.4.\\n\\n'},\n",
       "      {'param_name': 'pre_dispatch',\n",
       "       'param_type': 'int or str, default=’2*n_jobs’',\n",
       "       'param_desc': 'Controls the number of jobs that get dispatched during parallel\\nexecution. Reducing this number can be useful to avoid an\\nexplosion of memory consumption when more jobs get dispatched\\nthan CPUs can process. This parameter can be:\\n\\n\\nAn int, giving the exact number of total jobs that are\\nspawned\\nA str, giving an expression as a function of n_jobs,\\nas in ‘2*n_jobs’\\n\\n\\n'},\n",
       "      {'param_name': 'return_train_score',\n",
       "       'param_type': 'bool, default=False',\n",
       "       'param_desc': 'Whether to include train scores.\\nComputing training scores is used to get insights on how different\\nparameter settings impact the overfitting/underfitting trade-off.\\nHowever computing the scores on the training set can be computationally\\nexpensive and is not strictly required to select the parameters that\\nyield the best generalization performance.\\n\\nAdded in version 0.19.\\n\\n\\nChanged in version 0.21: Default value was changed from True to False\\n\\n'},\n",
       "      {'param_name': 'return_estimator',\n",
       "       'param_type': 'bool, default=False',\n",
       "       'param_desc': 'Whether to return the estimators fitted on each split.\\n\\nAdded in version 0.20.\\n\\n'},\n",
       "      {'param_name': 'return_indices',\n",
       "       'param_type': 'bool, default=False',\n",
       "       'param_desc': 'Whether to return the train-test indices selected for each split.\\n\\nAdded in version 1.3.\\n\\n'},\n",
       "      {'param_name': 'error_score',\n",
       "       'param_type': '‘raise’ or numeric, default=np.nan',\n",
       "       'param_desc': 'Value to assign to the score if an error occurs in estimator fitting.\\nIf set to ‘raise’, the error is raised.\\nIf a numeric value is given, FitFailedWarning is raised.\\n\\nAdded in version 0.20.\\n\\n'}]}},\n",
       "   {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.permutation_test_score.html#sklearn.model_selection.permutation_test_score',\n",
       "    'function_definitions': {'function_name': 'permutation_test_score',\n",
       "     'full_function': 'sklearn.model_selection.permutation_test_score(estimator, X, y, *, groups=None, cv=None, n_permutations=100, n_jobs=None, random_state=0, verbose=0, scoring=None, fit_params=None)',\n",
       "     'function_text': 'Evaluate the significance of a cross-validated score with permutations. Permutes targets to generate ‘randomized data’ and compute the empirical\\np-value against the null hypothesis that features and targets are\\nindependent. The p-value represents the fraction of randomized data sets where the\\nestimator performed as well or better than in the original data. A small\\np-value suggests that there is a real dependency between features and\\ntargets which has been used by the estimator to give good predictions.\\nA large p-value may be due to lack of real dependency between features\\nand targets or the estimator was not able to use the dependency to\\ngive good predictions. Read more in the User Guide. The object to use to fit the data. The data to fit. The target variable to try to predict in the case of\\nsupervised learning. Labels to constrain permutation within groups, i.e. y values\\nare permuted among samples with the same group identifier.\\nWhen not specified, y values are permuted among all samples. When a grouped cross-validator is used, the group labels are\\nalso passed on to the split method of the cross-validator. The\\ncross-validator uses them for grouping the samples  while splitting\\nthe dataset into train/test set. Determines the cross-validation splitting strategy.\\nPossible inputs for cv are: None, to use the default 5-fold cross validation, int, to specify the number of folds in a (Stratified)KFold, CV splitter, An iterable yielding (train, test) splits as arrays of indices. For int/None inputs, if the estimator is a classifier and y is\\neither binary or multiclass, StratifiedKFold is used. In all\\nother cases, KFold is used. These splitters are instantiated\\nwith shuffle=False so the splits will be the same across calls. Refer User Guide for the various\\ncross-validation strategies that can be used here. Changed in version 0.22: cv default value if None changed from 3-fold to 5-fold. Number of times to permute y. Number of jobs to run in parallel. Training the estimator and computing\\nthe cross-validated score are parallelized over the permutations.\\nNone means 1 unless in a joblib.parallel_backend context.\\n-1 means using all processors. See Glossary\\nfor more details. Pass an int for reproducible output for permutation of\\ny values among samples. See Glossary. The verbosity level. A single str (see The scoring parameter: defining model evaluation rules) or a callable\\n(see Defining your scoring strategy from metric functions) to evaluate the predictions on the test set. If None the estimator’s score method is used. Parameters to pass to the fit method of the estimator. Added in version 0.24. The true score without permuting targets. The scores obtained for each permutations. The p-value, which approximates the probability that the score would\\nbe obtained by chance. This is calculated as: (C + 1) / (n_permutations + 1) Where C is the number of permutations whose score >= the true score. The best possible p-value is 1/(n_permutations + 1), the worst is 1.0. Notes This function implements Test 1 in: Ojala and Garriga. Permutation Tests for Studying Classifier\\nPerformance. The\\nJournal of Machine Learning Research (2010) vol. 11 Examples',\n",
       "     'parameter_names_desc': [{'param_name': 'estimator',\n",
       "       'param_type': 'estimator object implementing ‘fit’',\n",
       "       'param_desc': 'The object to use to fit the data.\\n'},\n",
       "      {'param_name': 'X',\n",
       "       'param_type': 'array-like of shape at least 2D',\n",
       "       'param_desc': 'The data to fit.\\n'},\n",
       "      {'param_name': 'y',\n",
       "       'param_type': 'array-like of shape (n_samples,) or (n_samples, n_outputs) or None',\n",
       "       'param_desc': 'The target variable to try to predict in the case of\\nsupervised learning.\\n'},\n",
       "      {'param_name': 'groups',\n",
       "       'param_type': 'array-like of shape (n_samples,), default=None',\n",
       "       'param_desc': 'Labels to constrain permutation within groups, i.e. y values\\nare permuted among samples with the same group identifier.\\nWhen not specified, y values are permuted among all samples.\\nWhen a grouped cross-validator is used, the group labels are\\nalso passed on to the split method of the cross-validator. The\\ncross-validator uses them for grouping the samples  while splitting\\nthe dataset into train/test set.\\n'},\n",
       "      {'param_name': 'cv',\n",
       "       'param_type': 'int, cross-validation generator or an iterable, default=None',\n",
       "       'param_desc': 'Determines the cross-validation splitting strategy.\\nPossible inputs for cv are:\\n\\nNone, to use the default 5-fold cross validation,\\nint, to specify the number of folds in a (Stratified)KFold,\\nCV splitter,\\nAn iterable yielding (train, test) splits as arrays of indices.\\n\\nFor int/None inputs, if the estimator is a classifier and y is\\neither binary or multiclass, StratifiedKFold is used. In all\\nother cases, KFold is used. These splitters are instantiated\\nwith shuffle=False so the splits will be the same across calls.\\nRefer User Guide for the various\\ncross-validation strategies that can be used here.\\n\\nChanged in version 0.22: cv default value if None changed from 3-fold to 5-fold.\\n\\n'},\n",
       "      {'param_name': 'n_permutations',\n",
       "       'param_type': 'int, default=100',\n",
       "       'param_desc': 'Number of times to permute y.\\n'},\n",
       "      {'param_name': 'n_jobs',\n",
       "       'param_type': 'int, default=None',\n",
       "       'param_desc': 'Number of jobs to run in parallel. Training the estimator and computing\\nthe cross-validated score are parallelized over the permutations.\\nNone means 1 unless in a joblib.parallel_backend context.\\n-1 means using all processors. See Glossary\\nfor more details.\\n'},\n",
       "      {'param_name': 'random_state',\n",
       "       'param_type': 'int, RandomState instance or None, default=0',\n",
       "       'param_desc': 'Pass an int for reproducible output for permutation of\\ny values among samples. See Glossary.\\n'},\n",
       "      {'param_name': 'verbose',\n",
       "       'param_type': 'int, default=0',\n",
       "       'param_desc': 'The verbosity level.\\n'},\n",
       "      {'param_name': 'scoring',\n",
       "       'param_type': 'str or callable, default=None',\n",
       "       'param_desc': 'A single str (see The scoring parameter: defining model evaluation rules) or a callable\\n(see Defining your scoring strategy from metric functions) to evaluate the predictions on the test set.\\nIf None the estimator’s score method is used.\\n'},\n",
       "      {'param_name': 'fit_params',\n",
       "       'param_type': 'dict, default=None',\n",
       "       'param_desc': 'Parameters to pass to the fit method of the estimator.\\n\\nAdded in version 0.24.\\n\\n'}]}},\n",
       "   {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score',\n",
       "    'function_definitions': {'function_name': 'cross_val_score',\n",
       "     'full_function': \"sklearn.model_selection.cross_val_score(estimator, X, y=None, *, groups=None, scoring=None, cv=None, n_jobs=None, verbose=0, fit_params=None, params=None, pre_dispatch='2*n_jobs', error_score=nan)\",\n",
       "     'function_text': \"Evaluate a score by cross-validation. Read more in the User Guide. The object to use to fit the data. The data to fit. Can be for example a list, or an array. The target variable to try to predict in the case of\\nsupervised learning. Group labels for the samples used while splitting the dataset into\\ntrain/test set. Only used in conjunction with a “Group” cv\\ninstance (e.g., GroupKFold). Changed in version 1.4: groups can only be passed if metadata routing is not enabled\\nvia sklearn.set_config(enable_metadata_routing=True). When routing\\nis enabled, pass groups alongside other metadata via the params\\nargument instead. E.g.:\\ncross_val_score(..., params={'groups': groups}). A str (see model evaluation documentation) or\\na scorer callable object / function with signature\\nscorer(estimator, X, y) which should return only\\na single value. Similar to cross_validate\\nbut only a single metric is permitted. If None, the estimator’s default scorer (if available) is used. Determines the cross-validation splitting strategy.\\nPossible inputs for cv are: None, to use the default 5-fold cross validation, int, to specify the number of folds in a (Stratified)KFold, CV splitter, An iterable that generates (train, test) splits as arrays of indices. For int/None inputs, if the estimator is a classifier and y is\\neither binary or multiclass, StratifiedKFold is used. In all\\nother cases, KFold is used. These splitters are instantiated\\nwith shuffle=False so the splits will be the same across calls. Refer User Guide for the various\\ncross-validation strategies that can be used here. Changed in version 0.22: cv default value if None changed from 3-fold to 5-fold. Number of jobs to run in parallel. Training the estimator and computing\\nthe score are parallelized over the cross-validation splits.\\nNone means 1 unless in a joblib.parallel_backend context.\\n-1 means using all processors. See Glossary\\nfor more details. The verbosity level. Parameters to pass to the fit method of the estimator. Deprecated since version 1.4: This parameter is deprecated and will be removed in version 1.6. Use\\nparams instead. Parameters to pass to the underlying estimator’s fit, the scorer,\\nand the CV splitter. Added in version 1.4. Controls the number of jobs that get dispatched during parallel\\nexecution. Reducing this number can be useful to avoid an\\nexplosion of memory consumption when more jobs get dispatched\\nthan CPUs can process. This parameter can be: None, in which case all the jobs are immediately\\ncreated and spawned. Use this for lightweight and\\nfast-running jobs, to avoid delays due to on-demand\\nspawning of the jobs An int, giving the exact number of total jobs that are\\nspawned A str, giving an expression as a function of n_jobs,\\nas in ‘2*n_jobs’ Value to assign to the score if an error occurs in estimator fitting.\\nIf set to ‘raise’, the error is raised.\\nIf a numeric value is given, FitFailedWarning is raised. Added in version 0.20. Array of scores of the estimator for each run of the cross validation. See also To run cross-validation on multiple metrics and also to return train scores, fit times and score times. Get predictions from each split of cross-validation for diagnostic purposes. Make a scorer from a performance metric or loss function. Examples\",\n",
       "     'parameter_names_desc': [{'param_name': 'estimator',\n",
       "       'param_type': 'estimator object implementing ‘fit’',\n",
       "       'param_desc': 'The object to use to fit the data.\\n'},\n",
       "      {'param_name': 'X',\n",
       "       'param_type': '{array-like, sparse matrix} of shape (n_samples, n_features)',\n",
       "       'param_desc': 'The data to fit. Can be for example a list, or an array.\\n'},\n",
       "      {'param_name': 'y',\n",
       "       'param_type': 'array-like of shape (n_samples,) or (n_samples, n_outputs),             default=None',\n",
       "       'param_desc': 'The target variable to try to predict in the case of\\nsupervised learning.\\n'},\n",
       "      {'param_name': 'groups',\n",
       "       'param_type': 'array-like of shape (n_samples,), default=None',\n",
       "       'param_desc': \"Group labels for the samples used while splitting the dataset into\\ntrain/test set. Only used in conjunction with a “Group” cv\\ninstance (e.g., GroupKFold).\\n\\nChanged in version 1.4: groups can only be passed if metadata routing is not enabled\\nvia sklearn.set_config(enable_metadata_routing=True). When routing\\nis enabled, pass groups alongside other metadata via the params\\nargument instead. E.g.:\\ncross_val_score(..., params={'groups': groups}).\\n\\n\"},\n",
       "      {'param_name': 'scoring',\n",
       "       'param_type': 'str or callable, default=None',\n",
       "       'param_desc': 'A str (see model evaluation documentation) or\\na scorer callable object / function with signature\\nscorer(estimator, X, y) which should return only\\na single value.\\nSimilar to cross_validate\\nbut only a single metric is permitted.\\nIf None, the estimator’s default scorer (if available) is used.\\n'},\n",
       "      {'param_name': 'cv',\n",
       "       'param_type': 'int, cross-validation generator or an iterable, default=None',\n",
       "       'param_desc': 'Determines the cross-validation splitting strategy.\\nPossible inputs for cv are:\\n\\nNone, to use the default 5-fold cross validation,\\nint, to specify the number of folds in a (Stratified)KFold,\\nCV splitter,\\nAn iterable that generates (train, test) splits as arrays of indices.\\n\\nFor int/None inputs, if the estimator is a classifier and y is\\neither binary or multiclass, StratifiedKFold is used. In all\\nother cases, KFold is used. These splitters are instantiated\\nwith shuffle=False so the splits will be the same across calls.\\nRefer User Guide for the various\\ncross-validation strategies that can be used here.\\n\\nChanged in version 0.22: cv default value if None changed from 3-fold to 5-fold.\\n\\n'},\n",
       "      {'param_name': 'n_jobs',\n",
       "       'param_type': 'int, default=None',\n",
       "       'param_desc': 'Number of jobs to run in parallel. Training the estimator and computing\\nthe score are parallelized over the cross-validation splits.\\nNone means 1 unless in a joblib.parallel_backend context.\\n-1 means using all processors. See Glossary\\nfor more details.\\n'},\n",
       "      {'param_name': 'verbose',\n",
       "       'param_type': 'int, default=0',\n",
       "       'param_desc': 'The verbosity level.\\n'},\n",
       "      {'param_name': 'fit_params',\n",
       "       'param_type': 'dict, default=None',\n",
       "       'param_desc': 'Parameters to pass to the fit method of the estimator.\\n\\nDeprecated since version 1.4: This parameter is deprecated and will be removed in version 1.6. Use\\nparams instead.\\n\\n'},\n",
       "      {'param_name': 'params',\n",
       "       'param_type': 'dict, default=None',\n",
       "       'param_desc': 'Parameters to pass to the underlying estimator’s fit, the scorer,\\nand the CV splitter.\\n\\nAdded in version 1.4.\\n\\n'},\n",
       "      {'param_name': 'pre_dispatch',\n",
       "       'param_type': 'int or str, default=’2*n_jobs’',\n",
       "       'param_desc': 'Controls the number of jobs that get dispatched during parallel\\nexecution. Reducing this number can be useful to avoid an\\nexplosion of memory consumption when more jobs get dispatched\\nthan CPUs can process. This parameter can be:\\n\\n\\nNone, in which case all the jobs are immediately\\ncreated and spawned. Use this for lightweight and\\nfast-running jobs, to avoid delays due to on-demand\\nspawning of the jobs\\nAn int, giving the exact number of total jobs that are\\nspawned\\nA str, giving an expression as a function of n_jobs,\\nas in ‘2*n_jobs’\\n\\n\\n'},\n",
       "      {'param_name': 'error_score',\n",
       "       'param_type': '‘raise’ or numeric, default=np.nan',\n",
       "       'param_desc': 'Value to assign to the score if an error occurs in estimator fitting.\\nIf set to ‘raise’, the error is raised.\\nIf a numeric value is given, FitFailedWarning is raised.\\n\\nAdded in version 0.20.\\n\\n'}]}},\n",
       "   {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.learning_curve.html#sklearn.model_selection.learning_curve',\n",
       "    'function_definitions': {'function_name': 'learning_curve',\n",
       "     'full_function': \"sklearn.model_selection.learning_curve(estimator, X, y, *, groups=None, train_sizes=array([0.1, 0.33, 0.55, 0.78, 1.]), cv=None, scoring=None, exploit_incremental_learning=False, n_jobs=None, pre_dispatch='all', verbose=0, shuffle=False, random_state=None, error_score=nan, return_times=False, fit_params=None)\",\n",
       "     'function_text': 'Learning curve. Determines cross-validated training and test scores for different training\\nset sizes. A cross-validation generator splits the whole dataset k times in training\\nand test data. Subsets of the training set with varying sizes will be used\\nto train the estimator and a score for each training subset size and the\\ntest set will be computed. Afterwards, the scores will be averaged over\\nall k runs for each training subset size. Read more in the User Guide. An object of that type which is cloned for each validation. It must\\nalso implement “predict” unless scoring is a callable that doesn’t\\nrely on “predict” to compute a score. Training vector, where n_samples is the number of samples and\\nn_features is the number of features. Target relative to X for classification or regression;\\nNone for unsupervised learning. Group labels for the samples used while splitting the dataset into\\ntrain/test set. Only used in conjunction with a “Group” cv\\ninstance (e.g., GroupKFold). Relative or absolute numbers of training examples that will be used to\\ngenerate the learning curve. If the dtype is float, it is regarded as a\\nfraction of the maximum size of the training set (that is determined\\nby the selected validation method), i.e. it has to be within (0, 1].\\nOtherwise it is interpreted as absolute sizes of the training sets.\\nNote that for classification the number of samples usually have to\\nbe big enough to contain at least one sample from each class. Determines the cross-validation splitting strategy.\\nPossible inputs for cv are: None, to use the default 5-fold cross validation, int, to specify the number of folds in a (Stratified)KFold, CV splitter, An iterable yielding (train, test) splits as arrays of indices. For int/None inputs, if the estimator is a classifier and y is\\neither binary or multiclass, StratifiedKFold is used. In all\\nother cases, KFold is used. These splitters are instantiated\\nwith shuffle=False so the splits will be the same across calls. Refer User Guide for the various\\ncross-validation strategies that can be used here. Changed in version 0.22: cv default value if None changed from 3-fold to 5-fold. A str (see model evaluation documentation) or\\na scorer callable object / function with signature\\nscorer(estimator, X, y). If the estimator supports incremental learning, this will be\\nused to speed up fitting for different training set sizes. Number of jobs to run in parallel. Training the estimator and computing\\nthe score are parallelized over the different training and test sets.\\nNone means 1 unless in a joblib.parallel_backend context.\\n-1 means using all processors. See Glossary\\nfor more details. Number of predispatched jobs for parallel execution (default is\\nall). The option can reduce the allocated memory. The str can\\nbe an expression like ‘2*n_jobs’. Controls the verbosity: the higher, the more messages. Whether to shuffle training data before taking prefixes of it\\nbased on``train_sizes``. Used when shuffle is True. Pass an int for reproducible\\noutput across multiple function calls.\\nSee Glossary. Value to assign to the score if an error occurs in estimator fitting.\\nIf set to ‘raise’, the error is raised.\\nIf a numeric value is given, FitFailedWarning is raised. Added in version 0.20. Whether to return the fit and score times. Parameters to pass to the fit method of the estimator. Added in version 0.24. Numbers of training examples that has been used to generate the\\nlearning curve. Note that the number of ticks might be less\\nthan n_ticks because duplicate entries will be removed. Scores on training sets. Scores on test set. Times spent for fitting in seconds. Only present if return_times\\nis True. Times spent for scoring in seconds. Only present if return_times\\nis True. Examples',\n",
       "     'parameter_names_desc': [{'param_name': 'estimator',\n",
       "       'param_type': 'object type that implements the “fit” method',\n",
       "       'param_desc': 'An object of that type which is cloned for each validation. It must\\nalso implement “predict” unless scoring is a callable that doesn’t\\nrely on “predict” to compute a score.\\n'},\n",
       "      {'param_name': 'X',\n",
       "       'param_type': '{array-like, sparse matrix} of shape (n_samples, n_features)',\n",
       "       'param_desc': 'Training vector, where n_samples is the number of samples and\\nn_features is the number of features.\\n'},\n",
       "      {'param_name': 'y',\n",
       "       'param_type': 'array-like of shape (n_samples,) or (n_samples, n_outputs) or None',\n",
       "       'param_desc': 'Target relative to X for classification or regression;\\nNone for unsupervised learning.\\n'},\n",
       "      {'param_name': 'groups',\n",
       "       'param_type': 'array-like of shape (n_samples,), default=None',\n",
       "       'param_desc': 'Group labels for the samples used while splitting the dataset into\\ntrain/test set. Only used in conjunction with a “Group” cv\\ninstance (e.g., GroupKFold).\\n'},\n",
       "      {'param_name': 'train_sizes',\n",
       "       'param_type': 'array-like of shape (n_ticks,),             default=np.linspace(0.1, 1.0, 5)',\n",
       "       'param_desc': 'Relative or absolute numbers of training examples that will be used to\\ngenerate the learning curve. If the dtype is float, it is regarded as a\\nfraction of the maximum size of the training set (that is determined\\nby the selected validation method), i.e. it has to be within (0, 1].\\nOtherwise it is interpreted as absolute sizes of the training sets.\\nNote that for classification the number of samples usually have to\\nbe big enough to contain at least one sample from each class.\\n'},\n",
       "      {'param_name': 'cv',\n",
       "       'param_type': 'int, cross-validation generator or an iterable, default=None',\n",
       "       'param_desc': 'Determines the cross-validation splitting strategy.\\nPossible inputs for cv are:\\n\\nNone, to use the default 5-fold cross validation,\\nint, to specify the number of folds in a (Stratified)KFold,\\nCV splitter,\\nAn iterable yielding (train, test) splits as arrays of indices.\\n\\nFor int/None inputs, if the estimator is a classifier and y is\\neither binary or multiclass, StratifiedKFold is used. In all\\nother cases, KFold is used. These splitters are instantiated\\nwith shuffle=False so the splits will be the same across calls.\\nRefer User Guide for the various\\ncross-validation strategies that can be used here.\\n\\nChanged in version 0.22: cv default value if None changed from 3-fold to 5-fold.\\n\\n'},\n",
       "      {'param_name': 'scoring',\n",
       "       'param_type': 'str or callable, default=None',\n",
       "       'param_desc': 'A str (see model evaluation documentation) or\\na scorer callable object / function with signature\\nscorer(estimator, X, y).\\n'},\n",
       "      {'param_name': 'exploit_incremental_learning',\n",
       "       'param_type': 'bool, default=False',\n",
       "       'param_desc': 'If the estimator supports incremental learning, this will be\\nused to speed up fitting for different training set sizes.\\n'},\n",
       "      {'param_name': 'n_jobs',\n",
       "       'param_type': 'int, default=None',\n",
       "       'param_desc': 'Number of jobs to run in parallel. Training the estimator and computing\\nthe score are parallelized over the different training and test sets.\\nNone means 1 unless in a joblib.parallel_backend context.\\n-1 means using all processors. See Glossary\\nfor more details.\\n'},\n",
       "      {'param_name': 'pre_dispatch',\n",
       "       'param_type': 'int or str, default=’all’',\n",
       "       'param_desc': 'Number of predispatched jobs for parallel execution (default is\\nall). The option can reduce the allocated memory. The str can\\nbe an expression like ‘2*n_jobs’.\\n'},\n",
       "      {'param_name': 'verbose',\n",
       "       'param_type': 'int, default=0',\n",
       "       'param_desc': 'Controls the verbosity: the higher, the more messages.\\n'},\n",
       "      {'param_name': 'shuffle',\n",
       "       'param_type': 'bool, default=False',\n",
       "       'param_desc': 'Whether to shuffle training data before taking prefixes of it\\nbased on``train_sizes``.\\n'},\n",
       "      {'param_name': 'random_state',\n",
       "       'param_type': 'int, RandomState instance or None, default=None',\n",
       "       'param_desc': 'Used when shuffle is True. Pass an int for reproducible\\noutput across multiple function calls.\\nSee Glossary.\\n'},\n",
       "      {'param_name': 'error_score',\n",
       "       'param_type': '‘raise’ or numeric, default=np.nan',\n",
       "       'param_desc': 'Value to assign to the score if an error occurs in estimator fitting.\\nIf set to ‘raise’, the error is raised.\\nIf a numeric value is given, FitFailedWarning is raised.\\n\\nAdded in version 0.20.\\n\\n'},\n",
       "      {'param_name': 'return_times',\n",
       "       'param_type': 'bool, default=False',\n",
       "       'param_desc': 'Whether to return the fit and score times.\\n'},\n",
       "      {'param_name': 'fit_params',\n",
       "       'param_type': 'dict, default=None',\n",
       "       'param_desc': 'Parameters to pass to the fit method of the estimator.\\n\\nAdded in version 0.24.\\n\\n'}]}},\n",
       "   {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html#sklearn.model_selection.validation_curve',\n",
       "    'function_definitions': {'function_name': 'validation_curve',\n",
       "     'full_function': \"sklearn.model_selection.validation_curve(estimator, X, y, *, param_name, param_range, groups=None, cv=None, scoring=None, n_jobs=None, pre_dispatch='all', verbose=0, error_score=nan, fit_params=None)\",\n",
       "     'function_text': 'Validation curve. Determine training and test scores for varying parameter values. Compute scores for an estimator with different values of a specified\\nparameter. This is similar to grid search with one parameter. However, this\\nwill also compute training scores and is merely a utility for plotting the\\nresults. Read more in the User Guide. An object of that type which is cloned for each validation. It must\\nalso implement “predict” unless scoring is a callable that doesn’t\\nrely on “predict” to compute a score. Training vector, where n_samples is the number of samples and\\nn_features is the number of features. Target relative to X for classification or regression;\\nNone for unsupervised learning. Name of the parameter that will be varied. The values of the parameter that will be evaluated. Group labels for the samples used while splitting the dataset into\\ntrain/test set. Only used in conjunction with a “Group” cv\\ninstance (e.g., GroupKFold). Determines the cross-validation splitting strategy.\\nPossible inputs for cv are: None, to use the default 5-fold cross validation, int, to specify the number of folds in a (Stratified)KFold, CV splitter, An iterable yielding (train, test) splits as arrays of indices. For int/None inputs, if the estimator is a classifier and y is\\neither binary or multiclass, StratifiedKFold is used. In all\\nother cases, KFold is used. These splitters are instantiated\\nwith shuffle=False so the splits will be the same across calls. Refer User Guide for the various\\ncross-validation strategies that can be used here. Changed in version 0.22: cv default value if None changed from 3-fold to 5-fold. A str (see model evaluation documentation) or\\na scorer callable object / function with signature\\nscorer(estimator, X, y). Number of jobs to run in parallel. Training the estimator and computing\\nthe score are parallelized over the combinations of each parameter\\nvalue and each cross-validation split.\\nNone means 1 unless in a joblib.parallel_backend context.\\n-1 means using all processors. See Glossary\\nfor more details. Number of predispatched jobs for parallel execution (default is\\nall). The option can reduce the allocated memory. The str can\\nbe an expression like ‘2*n_jobs’. Controls the verbosity: the higher, the more messages. Value to assign to the score if an error occurs in estimator fitting.\\nIf set to ‘raise’, the error is raised.\\nIf a numeric value is given, FitFailedWarning is raised. Added in version 0.20. Parameters to pass to the fit method of the estimator. Added in version 0.24. Scores on training sets. Scores on test set. Notes See Plotting Validation Curves Examples',\n",
       "     'parameter_names_desc': [{'param_name': 'estimator',\n",
       "       'param_type': 'object type that implements the “fit” method',\n",
       "       'param_desc': 'An object of that type which is cloned for each validation. It must\\nalso implement “predict” unless scoring is a callable that doesn’t\\nrely on “predict” to compute a score.\\n'},\n",
       "      {'param_name': 'X',\n",
       "       'param_type': '{array-like, sparse matrix} of shape (n_samples, n_features)',\n",
       "       'param_desc': 'Training vector, where n_samples is the number of samples and\\nn_features is the number of features.\\n'},\n",
       "      {'param_name': 'y',\n",
       "       'param_type': 'array-like of shape (n_samples,) or (n_samples, n_outputs) or None',\n",
       "       'param_desc': 'Target relative to X for classification or regression;\\nNone for unsupervised learning.\\n'},\n",
       "      {'param_name': 'param_name',\n",
       "       'param_type': 'str',\n",
       "       'param_desc': 'Name of the parameter that will be varied.\\n'},\n",
       "      {'param_name': 'param_range',\n",
       "       'param_type': 'array-like of shape (n_values,)',\n",
       "       'param_desc': 'The values of the parameter that will be evaluated.\\n'},\n",
       "      {'param_name': 'groups',\n",
       "       'param_type': 'array-like of shape (n_samples,), default=None',\n",
       "       'param_desc': 'Group labels for the samples used while splitting the dataset into\\ntrain/test set. Only used in conjunction with a “Group” cv\\ninstance (e.g., GroupKFold).\\n'},\n",
       "      {'param_name': 'cv',\n",
       "       'param_type': 'int, cross-validation generator or an iterable, default=None',\n",
       "       'param_desc': 'Determines the cross-validation splitting strategy.\\nPossible inputs for cv are:\\n\\nNone, to use the default 5-fold cross validation,\\nint, to specify the number of folds in a (Stratified)KFold,\\nCV splitter,\\nAn iterable yielding (train, test) splits as arrays of indices.\\n\\nFor int/None inputs, if the estimator is a classifier and y is\\neither binary or multiclass, StratifiedKFold is used. In all\\nother cases, KFold is used. These splitters are instantiated\\nwith shuffle=False so the splits will be the same across calls.\\nRefer User Guide for the various\\ncross-validation strategies that can be used here.\\n\\nChanged in version 0.22: cv default value if None changed from 3-fold to 5-fold.\\n\\n'},\n",
       "      {'param_name': 'scoring',\n",
       "       'param_type': 'str or callable, default=None',\n",
       "       'param_desc': 'A str (see model evaluation documentation) or\\na scorer callable object / function with signature\\nscorer(estimator, X, y).\\n'},\n",
       "      {'param_name': 'n_jobs',\n",
       "       'param_type': 'int, default=None',\n",
       "       'param_desc': 'Number of jobs to run in parallel. Training the estimator and computing\\nthe score are parallelized over the combinations of each parameter\\nvalue and each cross-validation split.\\nNone means 1 unless in a joblib.parallel_backend context.\\n-1 means using all processors. See Glossary\\nfor more details.\\n'},\n",
       "      {'param_name': 'pre_dispatch',\n",
       "       'param_type': 'int or str, default=’all’',\n",
       "       'param_desc': 'Number of predispatched jobs for parallel execution (default is\\nall). The option can reduce the allocated memory. The str can\\nbe an expression like ‘2*n_jobs’.\\n'},\n",
       "      {'param_name': 'verbose',\n",
       "       'param_type': 'int, default=0',\n",
       "       'param_desc': 'Controls the verbosity: the higher, the more messages.\\n'},\n",
       "      {'param_name': 'error_score',\n",
       "       'param_type': '‘raise’ or numeric, default=np.nan',\n",
       "       'param_desc': 'Value to assign to the score if an error occurs in estimator fitting.\\nIf set to ‘raise’, the error is raised.\\nIf a numeric value is given, FitFailedWarning is raised.\\n\\nAdded in version 0.20.\\n\\n'},\n",
       "      {'param_name': 'fit_params',\n",
       "       'param_type': 'dict, default=None',\n",
       "       'param_desc': 'Parameters to pass to the fit method of the estimator.\\n\\nAdded in version 0.24.\\n\\n'}]}}]},\n",
       " {'Visualization': [{'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LearningCurveDisplay.html#sklearn.model_selection.LearningCurveDisplay',\n",
       "    'function_definitions': {'function_name': 'LearningCurveDisplay',\n",
       "     'full_function': 'class sklearn.model_selection.LearningCurveDisplay(*, train_sizes, train_scores, test_scores, score_name=None)',\n",
       "     'function_text': 'Learning Curve visualization. It is recommended to use\\nfrom_estimator to\\ncreate a LearningCurveDisplay instance.\\nAll parameters are stored as attributes. Read more in the User Guide for general information\\nabout the visualization API and\\ndetailed documentation regarding the learning\\ncurve visualization. Added in version 1.2. Numbers of training examples that has been used to generate the\\nlearning curve. Scores on training sets. Scores on test set. The name of the score used in learning_curve. It will override the name\\ninferred from the scoring parameter. If score is None, we use \"Score\" if\\nnegate_score is False and \"Negative score\" otherwise. If scoring is a\\nstring or a callable, we infer the name. We replace _ by spaces and capitalize\\nthe first letter. We remove neg_ and replace it by \"Negative\" if\\nnegate_score is False or just remove it otherwise. Axes with the learning curve. Figure containing the learning curve. When the std_display_style is \"errorbar\", this is a list of\\nmatplotlib.container.ErrorbarContainer objects. If another style is\\nused, errorbar_ is None. When the std_display_style is \"fill_between\", this is a list of\\nmatplotlib.lines.Line2D objects corresponding to the mean train and\\ntest scores. If another style is used, line_ is None. When the std_display_style is \"fill_between\", this is a list of\\nmatplotlib.collections.PolyCollection objects. If another style is\\nused, fill_between_ is None. See also Compute the learning curve. Examples Create a learning curve display from an estimator. Read more in the User Guide for general\\ninformation about the visualization API and detailed\\ndocumentation regarding the learning curve\\nvisualization. An object of that type which is cloned for each validation. Training data, where n_samples is the number of samples and\\nn_features is the number of features. Target relative to X for classification or regression;\\nNone for unsupervised learning. Group labels for the samples used while splitting the dataset into\\ntrain/test set. Only used in conjunction with a “Group” cv\\ninstance (e.g., GroupKFold). Relative or absolute numbers of training examples that will be used\\nto generate the learning curve. If the dtype is float, it is\\nregarded as a fraction of the maximum size of the training set\\n(that is determined by the selected validation method), i.e. it has\\nto be within (0, 1]. Otherwise it is interpreted as absolute sizes\\nof the training sets. Note that for classification the number of\\nsamples usually have to be big enough to contain at least one\\nsample from each class. Determines the cross-validation splitting strategy.\\nPossible inputs for cv are: None, to use the default 5-fold cross validation, int, to specify the number of folds in a (Stratified)KFold, CV splitter, An iterable yielding (train, test) splits as arrays of indices. For int/None inputs, if the estimator is a classifier and y is\\neither binary or multiclass,\\nStratifiedKFold is used. In all\\nother cases, KFold is used. These\\nsplitters are instantiated with shuffle=False so the splits will\\nbe the same across calls. Refer User Guide for the various\\ncross-validation strategies that can be used here. A string (see The scoring parameter: defining model evaluation rules) or\\na scorer callable object / function with signature\\nscorer(estimator, X, y) (see Defining your scoring strategy from metric functions). If the estimator supports incremental learning, this will be\\nused to speed up fitting for different training set sizes. Number of jobs to run in parallel. Training the estimator and\\ncomputing the score are parallelized over the different training\\nand test sets. None means 1 unless in a\\njoblib.parallel_backend context. -1 means using all\\nprocessors. See Glossary for more details. Number of predispatched jobs for parallel execution (default is\\nall). The option can reduce the allocated memory. The str can\\nbe an expression like ‘2*n_jobs’. Controls the verbosity: the higher, the more messages. Whether to shuffle training data before taking prefixes of it\\nbased on`train_sizes`. Used when shuffle is True. Pass an int for reproducible\\noutput across multiple function calls.\\nSee Glossary. Value to assign to the score if an error occurs in estimator\\nfitting. If set to ‘raise’, the error is raised. If a numeric value\\nis given, FitFailedWarning is raised. Parameters to pass to the fit method of the estimator. Axes object to plot on. If None, a new figure and axes is\\ncreated. Whether or not to negate the scores obtained through\\nlearning_curve. This is\\nparticularly useful when using the error denoted by neg_* in\\nscikit-learn. The name of the score used to decorate the y-axis of the plot. It will\\noverride the name inferred from the scoring parameter. If score is\\nNone, we use \"Score\" if negate_score is False and \"Negative score\"\\notherwise. If scoring is a string or a callable, we infer the name. We\\nreplace _ by spaces and capitalize the first letter. We remove neg_ and\\nreplace it by \"Negative\" if negate_score is\\nFalse or just remove it otherwise. The type of score to plot. Can be one of \"test\", \"train\", or\\n\"both\". The style used to display the score standard deviation around the\\nmean score. If None, no representation of the standard deviation\\nis displayed. Additional keyword arguments passed to the plt.plot used to draw\\nthe mean score. Additional keyword arguments passed to the plt.fill_between used\\nto draw the score standard deviation. Additional keyword arguments passed to the plt.errorbar used to\\ndraw mean score and standard deviation score. Object that stores computed values. Examples Plot visualization. Axes object to plot on. If None, a new figure and axes is\\ncreated. Whether or not to negate the scores obtained through\\nlearning_curve. This is\\nparticularly useful when using the error denoted by neg_* in\\nscikit-learn. The name of the score used to decorate the y-axis of the plot. It will\\noverride the name inferred from the scoring parameter. If score is\\nNone, we use \"Score\" if negate_score is False and \"Negative score\"\\notherwise. If scoring is a string or a callable, we infer the name. We\\nreplace _ by spaces and capitalize the first letter. We remove neg_ and\\nreplace it by \"Negative\" if negate_score is\\nFalse or just remove it otherwise. The type of score to plot. Can be one of \"test\", \"train\", or\\n\"both\". The style used to display the score standard deviation around the\\nmean score. If None, no standard deviation representation is\\ndisplayed. Additional keyword arguments passed to the plt.plot used to draw\\nthe mean score. Additional keyword arguments passed to the plt.fill_between used\\nto draw the score standard deviation. Additional keyword arguments passed to the plt.errorbar used to\\ndraw mean score and standard deviation score. Object that stores computed values.',\n",
       "     'parameter_names_desc': [{'param_name': 'ax',\n",
       "       'param_type': 'matplotlib Axes, default=None',\n",
       "       'param_desc': 'Axes object to plot on. If None, a new figure and axes is\\ncreated.\\n'},\n",
       "      {'param_name': 'negate_score',\n",
       "       'param_type': 'bool, default=False',\n",
       "       'param_desc': 'Whether or not to negate the scores obtained through\\nlearning_curve. This is\\nparticularly useful when using the error denoted by neg_* in\\nscikit-learn.\\n'},\n",
       "      {'param_name': 'score_name',\n",
       "       'param_type': 'str, default=None',\n",
       "       'param_desc': 'The name of the score used to decorate the y-axis of the plot. It will\\noverride the name inferred from the scoring parameter. If score is\\nNone, we use \"Score\" if negate_score is False and \"Negative score\"\\notherwise. If scoring is a string or a callable, we infer the name. We\\nreplace _ by spaces and capitalize the first letter. We remove neg_ and\\nreplace it by \"Negative\" if negate_score is\\nFalse or just remove it otherwise.\\n'},\n",
       "      {'param_name': 'score_type',\n",
       "       'param_type': '{“test”, “train”, “both”}, default=”both”',\n",
       "       'param_desc': 'The type of score to plot. Can be one of \"test\", \"train\", or\\n\"both\".\\n'},\n",
       "      {'param_name': 'std_display_style',\n",
       "       'param_type': '{“errorbar”, “fill_between”} or None, default=”fill_between”',\n",
       "       'param_desc': 'The style used to display the score standard deviation around the\\nmean score. If None, no standard deviation representation is\\ndisplayed.\\n'},\n",
       "      {'param_name': 'line_kw',\n",
       "       'param_type': 'dict, default=None',\n",
       "       'param_desc': 'Additional keyword arguments passed to the plt.plot used to draw\\nthe mean score.\\n'},\n",
       "      {'param_name': 'fill_between_kw',\n",
       "       'param_type': 'dict, default=None',\n",
       "       'param_desc': 'Additional keyword arguments passed to the plt.fill_between used\\nto draw the score standard deviation.\\n'},\n",
       "      {'param_name': 'errorbar_kw',\n",
       "       'param_type': 'dict, default=None',\n",
       "       'param_desc': 'Additional keyword arguments passed to the plt.errorbar used to\\ndraw mean score and standard deviation score.\\n'}]}},\n",
       "   {'func_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ValidationCurveDisplay.html#sklearn.model_selection.ValidationCurveDisplay',\n",
       "    'function_definitions': {'function_name': 'ValidationCurveDisplay',\n",
       "     'full_function': 'class sklearn.model_selection.ValidationCurveDisplay(*, param_name, param_range, train_scores, test_scores, score_name=None)',\n",
       "     'function_text': 'Validation Curve visualization. It is recommended to use\\nfrom_estimator to\\ncreate a ValidationCurveDisplay instance.\\nAll parameters are stored as attributes. Read more in the User Guide for general information\\nabout the visualization API and detailed documentation regarding the validation curve visualization. Added in version 1.3. Name of the parameter that has been varied. The values of the parameter that have been evaluated. Scores on training sets. Scores on test set. The name of the score used in validation_curve. It will override the name\\ninferred from the scoring parameter. If score is None, we use \"Score\" if\\nnegate_score is False and \"Negative score\" otherwise. If scoring is a\\nstring or a callable, we infer the name. We replace _ by spaces and capitalize\\nthe first letter. We remove neg_ and replace it by \"Negative\" if\\nnegate_score is False or just remove it otherwise. Axes with the validation curve. Figure containing the validation curve. When the std_display_style is \"errorbar\", this is a list of\\nmatplotlib.container.ErrorbarContainer objects. If another style is\\nused, errorbar_ is None. When the std_display_style is \"fill_between\", this is a list of\\nmatplotlib.lines.Line2D objects corresponding to the mean train and\\ntest scores. If another style is used, line_ is None. When the std_display_style is \"fill_between\", this is a list of\\nmatplotlib.collections.PolyCollection objects. If another style is\\nused, fill_between_ is None. See also Compute the validation curve. Examples Create a validation curve display from an estimator. Read more in the User Guide for general\\ninformation about the visualization API and detailed\\ndocumentation regarding the validation curve\\nvisualization. An object of that type which is cloned for each validation. Training data, where n_samples is the number of samples and\\nn_features is the number of features. Target relative to X for classification or regression;\\nNone for unsupervised learning. Name of the parameter that will be varied. The values of the parameter that will be evaluated. Group labels for the samples used while splitting the dataset into\\ntrain/test set. Only used in conjunction with a “Group” cv\\ninstance (e.g., GroupKFold). Determines the cross-validation splitting strategy.\\nPossible inputs for cv are: None, to use the default 5-fold cross validation, int, to specify the number of folds in a (Stratified)KFold, CV splitter, An iterable yielding (train, test) splits as arrays of indices. For int/None inputs, if the estimator is a classifier and y is\\neither binary or multiclass,\\nStratifiedKFold is used. In all\\nother cases, KFold is used. These\\nsplitters are instantiated with shuffle=False so the splits will\\nbe the same across calls. Refer User Guide for the various\\ncross-validation strategies that can be used here. A string (see The scoring parameter: defining model evaluation rules) or\\na scorer callable object / function with signature\\nscorer(estimator, X, y) (see Defining your scoring strategy from metric functions). Number of jobs to run in parallel. Training the estimator and\\ncomputing the score are parallelized over the different training\\nand test sets. None means 1 unless in a\\njoblib.parallel_backend context. -1 means using all\\nprocessors. See Glossary for more details. Number of predispatched jobs for parallel execution (default is\\nall). The option can reduce the allocated memory. The str can\\nbe an expression like ‘2*n_jobs’. Controls the verbosity: the higher, the more messages. Value to assign to the score if an error occurs in estimator\\nfitting. If set to ‘raise’, the error is raised. If a numeric value\\nis given, FitFailedWarning is raised. Parameters to pass to the fit method of the estimator. Axes object to plot on. If None, a new figure and axes is\\ncreated. Whether or not to negate the scores obtained through\\nvalidation_curve. This is\\nparticularly useful when using the error denoted by neg_* in\\nscikit-learn. The name of the score used to decorate the y-axis of the plot. It will\\noverride the name inferred from the scoring parameter. If score is\\nNone, we use \"Score\" if negate_score is False and \"Negative score\"\\notherwise. If scoring is a string or a callable, we infer the name. We\\nreplace _ by spaces and capitalize the first letter. We remove neg_ and\\nreplace it by \"Negative\" if negate_score is\\nFalse or just remove it otherwise. The type of score to plot. Can be one of \"test\", \"train\", or\\n\"both\". The style used to display the score standard deviation around the\\nmean score. If None, no representation of the standard deviation\\nis displayed. Additional keyword arguments passed to the plt.plot used to draw\\nthe mean score. Additional keyword arguments passed to the plt.fill_between used\\nto draw the score standard deviation. Additional keyword arguments passed to the plt.errorbar used to\\ndraw mean score and standard deviation score. Object that stores computed values. Examples Plot visualization. Axes object to plot on. If None, a new figure and axes is\\ncreated. Whether or not to negate the scores obtained through\\nvalidation_curve. This is\\nparticularly useful when using the error denoted by neg_* in\\nscikit-learn. The name of the score used to decorate the y-axis of the plot. It will\\noverride the name inferred from the scoring parameter. If score is\\nNone, we use \"Score\" if negate_score is False and \"Negative score\"\\notherwise. If scoring is a string or a callable, we infer the name. We\\nreplace _ by spaces and capitalize the first letter. We remove neg_ and\\nreplace it by \"Negative\" if negate_score is\\nFalse or just remove it otherwise. The type of score to plot. Can be one of \"test\", \"train\", or\\n\"both\". The style used to display the score standard deviation around the\\nmean score. If None, no standard deviation representation is\\ndisplayed. Additional keyword arguments passed to the plt.plot used to draw\\nthe mean score. Additional keyword arguments passed to the plt.fill_between used\\nto draw the score standard deviation. Additional keyword arguments passed to the plt.errorbar used to\\ndraw mean score and standard deviation score. Object that stores computed values.',\n",
       "     'parameter_names_desc': [{'param_name': 'ax',\n",
       "       'param_type': 'matplotlib Axes, default=None',\n",
       "       'param_desc': 'Axes object to plot on. If None, a new figure and axes is\\ncreated.\\n'},\n",
       "      {'param_name': 'negate_score',\n",
       "       'param_type': 'bool, default=False',\n",
       "       'param_desc': 'Whether or not to negate the scores obtained through\\nvalidation_curve. This is\\nparticularly useful when using the error denoted by neg_* in\\nscikit-learn.\\n'},\n",
       "      {'param_name': 'score_name',\n",
       "       'param_type': 'str, default=None',\n",
       "       'param_desc': 'The name of the score used to decorate the y-axis of the plot. It will\\noverride the name inferred from the scoring parameter. If score is\\nNone, we use \"Score\" if negate_score is False and \"Negative score\"\\notherwise. If scoring is a string or a callable, we infer the name. We\\nreplace _ by spaces and capitalize the first letter. We remove neg_ and\\nreplace it by \"Negative\" if negate_score is\\nFalse or just remove it otherwise.\\n'},\n",
       "      {'param_name': 'score_type',\n",
       "       'param_type': '{“test”, “train”, “both”}, default=”both”',\n",
       "       'param_desc': 'The type of score to plot. Can be one of \"test\", \"train\", or\\n\"both\".\\n'},\n",
       "      {'param_name': 'std_display_style',\n",
       "       'param_type': '{“errorbar”, “fill_between”} or None, default=”fill_between”',\n",
       "       'param_desc': 'The style used to display the score standard deviation around the\\nmean score. If None, no standard deviation representation is\\ndisplayed.\\n'},\n",
       "      {'param_name': 'line_kw',\n",
       "       'param_type': 'dict, default=None',\n",
       "       'param_desc': 'Additional keyword arguments passed to the plt.plot used to draw\\nthe mean score.\\n'},\n",
       "      {'param_name': 'fill_between_kw',\n",
       "       'param_type': 'dict, default=None',\n",
       "       'param_desc': 'Additional keyword arguments passed to the plt.fill_between used\\nto draw the score standard deviation.\\n'},\n",
       "      {'param_name': 'errorbar_kw',\n",
       "       'param_type': 'dict, default=None',\n",
       "       'param_desc': 'Additional keyword arguments passed to the plt.errorbar used to\\ndraw mean score and standard deviation score.\\n'}]}}]}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Serializing json\n",
    "import json\n",
    "json_object = json.dumps(first_level_param_dict, indent=4,ensure_ascii=True)\n",
    " \n",
    "# Writing to sample.json\n",
    "with open(\"sklearn.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_text_to_req(s):\n",
    "    star_idx = s.find(\" *,\")\n",
    "    if star_idx == -1:\n",
    "        return []\n",
    "    req_str = s[s.find(\"(\") + 1 : s.find(\"*\")].strip()[:-1]\n",
    "    req_list = [i.strip() for i in req_str.split(\",\")]\n",
    "    return req_list\n",
    "\n",
    "def add_function_calling(data):\n",
    "    for parent in data:\n",
    "        parent_data = data[parent]\n",
    "        for sub_level in parent_data[\"functions\"]:\n",
    "            for _,sub_level_funcs in sub_level.items():\n",
    "                for sub_level_func in sub_level_funcs:\n",
    "                    function_definitions = sub_level_func['function_definitions']\n",
    "                    func_name = function_definitions[\"function_name\"]\n",
    "                    function_calling = {\n",
    "                        \"name\": func_name,\n",
    "                        \"descriptions\": function_definitions[\"function_text\"],\n",
    "                    }\n",
    "                    if function_definitions[\"parameter_names_desc\"] != []:\n",
    "                        properties_dict = {}\n",
    "                        for params in function_definitions[\"parameter_names_desc\"]:\n",
    "                            type = params[\"param_type\"]\n",
    "                            if \"int\" in type:\n",
    "                                type = \"integer\"\n",
    "                                type_dict = {\"type\": type}\n",
    "                            elif \"str\" in type:\n",
    "                                type = \"string\"\n",
    "                                type_dict = {\"type\": type}\n",
    "                            elif \"bool\" in type:\n",
    "                                type = \"boolean\"\n",
    "                                type_dict = {\"type\": type}\n",
    "                            elif \"float\" in type:\n",
    "                                type = \"float\"\n",
    "                                type_dict = {\"type\": type}\n",
    "                            elif \"float\" in type:\n",
    "                                type = \"float\"\n",
    "                                type_dict = {\"type\": type}\n",
    "                            elif \"callable\" in type or \"object\" in type:\n",
    "                                type = \"object\"\n",
    "                                type_dict = {\"type\": type}\n",
    "                            elif \"Union\" in type or \"list\" in type or \"array\" in type:\n",
    "                                type = \"array\"\n",
    "                                type_dict = {\"type\": type}\n",
    "                            elif (\n",
    "                                \"{\" in type and \"}\" in type and \"’\" in type and \"‘\" in type\n",
    "                            ):\n",
    "                                list_params = type[type.find(\"{\") + 1 : type.find(\"}\")]\n",
    "                                list_params = (\n",
    "                                    list_params.replace(\"’\", \"\").replace(\"‘\", \"\").split(\",\")\n",
    "                                )\n",
    "                                type_dict = {\"type\": \"string\", \"enum\": list_params}\n",
    "                            else:\n",
    "                                type_dict = {\"type\": type}\n",
    "                            type_dict.update({\"description\": params['param_type'] + \". \" + params[\"param_desc\"]})\n",
    "\n",
    "                            properties_dict.update({params[\"param_name\"]: type_dict})\n",
    "\n",
    "                        function_calling.update(\n",
    "                            {\n",
    "                                \"parameters\": {\n",
    "                                    \"type\": \"object\",\n",
    "                                    \"properties\": properties_dict,\n",
    "                                    \"required\": function_text_to_req(function_definitions[\"full_function\"]),\n",
    "                                }\n",
    "                            }\n",
    "                        )\n",
    "                        sub_level_func.update({\"function_calling\": function_calling})\n",
    "                    else:\n",
    "                        sub_level_func.update({\"function_calling\": {}})\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_function_data = add_function_calling(first_level_param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'config_context',\n",
       " 'descriptions': 'Context manager for global scikit-learn configuration. If True, validation for finiteness will be skipped,\\nsaving time, but leading to potential crashes. If\\nFalse, validation for finiteness will be performed,\\navoiding error. If None, the existing value won’t change.\\nThe default value is False. If set, scikit-learn will attempt to limit the size of temporary arrays\\nto this number of MiB (per job when parallelised), often saving both\\ncomputation time and memory on expensive operations that can be\\nperformed in chunks. If None, the existing value won’t change.\\nThe default value is 1024. If True, only the parameters that were set to non-default\\nvalues will be printed when printing an estimator. For example,\\nprint(SVC()) while True will only print ‘SVC()’, but would print\\n‘SVC(C=1.0, cache_size=200, …)’ with all the non-changed parameters\\nwhen False. If None, the existing value won’t change.\\nThe default value is True. Changed in version 0.23: Default changed from False to True. If ‘diagram’, estimators will be displayed as a diagram in a Jupyter\\nlab or notebook context. If ‘text’, estimators will be displayed as\\ntext. If None, the existing value won’t change.\\nThe default value is ‘diagram’. Added in version 0.23. The number of row vectors per chunk for the accelerated pairwise-\\ndistances reduction backend. Default is 256 (suitable for most of\\nmodern laptops’ caches and architectures). Intended for easier benchmarking and testing of scikit-learn internals.\\nEnd users are not expected to benefit from customizing this configuration\\nsetting. Added in version 1.1. Use the accelerated pairwise-distances reduction backend when\\npossible. Global default: True. Intended for easier benchmarking and testing of scikit-learn internals.\\nEnd users are not expected to benefit from customizing this configuration\\nsetting. Added in version 1.1. Use Array API dispatching when inputs follow the Array API standard.\\nDefault is False. See the User Guide for more details. Added in version 1.2. Configure output of transform and fit_transform. See Introducing the set_output API\\nfor an example on how to use the API. \"default\": Default output format of a transformer \"pandas\": DataFrame output \"polars\": Polars output None: Transform configuration is unchanged Added in version 1.2. Added in version 1.4: \"polars\" option was added. Enable metadata routing. By default this feature is disabled. Refer to metadata routing user guide for more\\ndetails. True: Metadata routing is enabled False: Metadata routing is disabled, use the old syntax. None: Configuration is unchanged Added in version 1.3. If True, disable the validation of the hyper-parameters’ types and values in\\nthe fit method of estimators and for arguments passed to public helper\\nfunctions. It can save time in some situations but can lead to low level\\ncrashes and exceptions with confusing error messages. Note that for data parameters, such as X and y, only type validation is\\nskipped but validation with check_array will continue to run. Added in version 1.3. See also Set global scikit-learn configuration. Retrieve current values of the global configuration. Notes All settings, not just those presently modified, will be returned to\\ntheir previous values when the context manager is exited. Examples',\n",
       " 'parameters': {'type': 'object',\n",
       "  'properties': {'assume_finite': {'type': 'boolean',\n",
       "    'description': 'bool, default=None. If True, validation for finiteness will be skipped,\\nsaving time, but leading to potential crashes. If\\nFalse, validation for finiteness will be performed,\\navoiding error. If None, the existing value won’t change.\\nThe default value is False.\\n'},\n",
       "   'working_memory': {'type': 'integer',\n",
       "    'description': 'int, default=None. If set, scikit-learn will attempt to limit the size of temporary arrays\\nto this number of MiB (per job when parallelised), often saving both\\ncomputation time and memory on expensive operations that can be\\nperformed in chunks. If None, the existing value won’t change.\\nThe default value is 1024.\\n'},\n",
       "   'print_changed_only': {'type': 'boolean',\n",
       "    'description': 'bool, default=None. If True, only the parameters that were set to non-default\\nvalues will be printed when printing an estimator. For example,\\nprint(SVC()) while True will only print ‘SVC()’, but would print\\n‘SVC(C=1.0, cache_size=200, …)’ with all the non-changed parameters\\nwhen False. If None, the existing value won’t change.\\nThe default value is True.\\n\\nChanged in version 0.23: Default changed from False to True.\\n\\n'},\n",
       "   'display': {'type': 'string',\n",
       "    'enum': ['text', ' diagram'],\n",
       "    'description': '{‘text’, ‘diagram’}, default=None. If ‘diagram’, estimators will be displayed as a diagram in a Jupyter\\nlab or notebook context. If ‘text’, estimators will be displayed as\\ntext. If None, the existing value won’t change.\\nThe default value is ‘diagram’.\\n\\nAdded in version 0.23.\\n\\n'},\n",
       "   'pairwise_dist_chunk_size': {'type': 'integer',\n",
       "    'description': 'int, default=None. The number of row vectors per chunk for the accelerated pairwise-\\ndistances reduction backend. Default is 256 (suitable for most of\\nmodern laptops’ caches and architectures).\\nIntended for easier benchmarking and testing of scikit-learn internals.\\nEnd users are not expected to benefit from customizing this configuration\\nsetting.\\n\\nAdded in version 1.1.\\n\\n'},\n",
       "   'enable_cython_pairwise_dist': {'type': 'boolean',\n",
       "    'description': 'bool, default=None. Use the accelerated pairwise-distances reduction backend when\\npossible. Global default: True.\\nIntended for easier benchmarking and testing of scikit-learn internals.\\nEnd users are not expected to benefit from customizing this configuration\\nsetting.\\n\\nAdded in version 1.1.\\n\\n'},\n",
       "   'array_api_dispatch': {'type': 'boolean',\n",
       "    'description': 'bool, default=None. Use Array API dispatching when inputs follow the Array API standard.\\nDefault is False.\\nSee the User Guide for more details.\\n\\nAdded in version 1.2.\\n\\n'},\n",
       "   'transform_output': {'type': 'string',\n",
       "    'description': 'str, default=None. Configure output of transform and fit_transform.\\nSee Introducing the set_output API\\nfor an example on how to use the API.\\n\\n\"default\": Default output format of a transformer\\n\"pandas\": DataFrame output\\n\"polars\": Polars output\\nNone: Transform configuration is unchanged\\n\\n\\nAdded in version 1.2.\\n\\n\\nAdded in version 1.4: \"polars\" option was added.\\n\\n'},\n",
       "   'enable_metadata_routing': {'type': 'boolean',\n",
       "    'description': 'bool, default=None. Enable metadata routing. By default this feature is disabled.\\nRefer to metadata routing user guide for more\\ndetails.\\n\\nTrue: Metadata routing is enabled\\nFalse: Metadata routing is disabled, use the old syntax.\\nNone: Configuration is unchanged\\n\\n\\nAdded in version 1.3.\\n\\n'},\n",
       "   'skip_parameter_validation': {'type': 'boolean',\n",
       "    'description': 'bool, default=None. If True, disable the validation of the hyper-parameters’ types and values in\\nthe fit method of estimators and for arguments passed to public helper\\nfunctions. It can save time in some situations but can lead to low level\\ncrashes and exceptions with confusing error messages.\\nNote that for data parameters, such as X and y, only type validation is\\nskipped but validation with check_array will continue to run.\\n\\nAdded in version 1.3.\\n\\n'}},\n",
       "  'required': []}}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_function_data['sklearn.html']['functions'][0]['defaults'][0]['function_calling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_object = json.dumps(openai_function_data, indent=4,ensure_ascii=True)\n",
    " \n",
    "# Writing to sample.json\n",
    "with open(\"sklearn.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn.html\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "sklearn_graph = nx.DiGraph()\n",
    "\n",
    "for parent_name in openai_function_data:\n",
    "    parent_data = openai_function_data[parent_name]\n",
    "    for sub_level in parent_data[\"functions\"]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openbb-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
