{
    "sklearn": "The global scikit-learn configuration context manager allows for various settings to be adjusted. These settings include skipping validation for finiteness, limiting the size of temporary arrays, printing only non-default parameters, displaying estimators as diagrams or text, configuring pairwise distances reduction, using Array API dispatching, setting output formats for transformations, enabling metadata routing, and disabling validation of hyper-parameters' types and values. These settings can be adjusted to optimize performance, memory usage, and output formats. Additionally, all settings return to their previous values when the context manager is exited. ",
    "sklearn.base": "The base class for all estimators in scikit-learn provides default implementations for setting and getting parameters, textual and HTML representation, serialization, and data validation. Estimators should specify all parameters in their __init__ method. The mixin classes provide functionality for transformers, cluster estimators, meta estimators, and outlier detection estimators. The cluster estimators have a fit_predict method for clustering data, while the outlier detection estimators have a fit_predict method that returns labels for outliers and inliers. The mixin classes also define required parameters and the type of estimator. The transformer mixin generates feature names and prefixes them with the class name. The mixin classes in scikit-learn provide additional functionality for different types of estimators. The OneToOneFeatureMixin and ClassNamePrefixFeaturesOutMixin help define the get_feature_names_out method. The BiclusterEstimatorMixin provides methods for working with bicluster estimators, such as getting row and column indicators, indices, shape, and submatrix. The ClassifierMixin provides functionality for classifiers, including setting the estimator type and calculating the mean accuracy on test data. The DensityEstimatorMixin provides functionality for density estimators, including setting the estimator type and returning the score of the model on the data. Each mixin class adds specific methods and attributes to the estimators they are applied to, enhancing their capabilities. ",
    "sklearn.calibration": "The ProbabilityCalibration class in scikit-learn allows for probability calibration with isotonic regression or logistic regression. It uses cross-validation to estimate the parameters of a classifier and subsequently calibrate it. By default, an ensemble approach is used where a copy of the base estimator is fitted to the training subset and calibrated using the testing subset for each cross-validation split. Predicted probabilities are then averaged across these individual calibrated classifiers. Alternatively, cross-validation can be used to obtain unbiased predictions, which are then used for calibration. The calibration can be based on the decision_function method of the estimator or predict_proba if the former does not exist. It is recommended to avoid using isotonic calibration with too few samples as it may lead to overfitting. The method for calibration can be 'sigmoid' (Platt's method) or 'isotonic'. The number of cross-validation folds, the number of jobs to run in parallel, and the fitting strategy for the calibrator can also be specified. The class provides methods for fitting the calibrated model, predicting the target of new samples, obtaining calibrated probabilities of classification, and calculating the mean accuracy on test data. Additionally, metadata routing can be enabled to pass metadata to the fit and score methods. This class is useful for calibrating the output of classifiers to provide more accurate predict_proba outputs. The function computes true and predicted probabilities for a calibration curve, assuming inputs from a binary classifier and discretizing the [0, 1] interval into bins. Calibration curves, also known as reliability diagrams, are generated. It requires true targets, probabilities of the positive class, the label of the positive class, and the number of bins to discretize the interval. A bigger number of bins requires more data. Bins with no samples will not be returned. The strategy used to define the widths of the bins can be either identical widths or based on the number of samples and y_prob. The function also calculates the fraction of positives and the mean predicted probability in each bin. References to relevant research are provided for further reading. ",
    "sklearn.cluster": "The Affinity Propagation Clustering function allows for clustering of data by passing messages between data points. It includes parameters such as damping factor, maximum number of iterations, preferences for each point, type of affinity to use, and whether to be verbose. The function also provides options for setting a pseudo-random number generator and controlling the starting state. It supports different types of clustering methods such as K-Means, Mini-Batch K-Means, Mean Shift, and applying clustering to a projection of the normalized Laplacian. The algorithmic complexity of affinity propagation is quadratic in the number of points. It is important to note that when the algorithm does not converge, caution should be taken when interpreting the results. The function also allows for fitting clustering from features or affinity matrix, returning cluster labels, predicting the closest cluster for new data, and getting metadata routing information. The BIRCH clustering algorithm is a memory-efficient, online-learning algorithm that constructs a tree data structure with cluster centroids read off the leaf. The algorithm allows for the setting of a threshold radius for subclusters and a maximum number of subclusters in each node. It also provides options for the final number of clusters, fitting a model, computing labels, and making copies of data. The tree structure consists of nodes with subclusters, each maintaining linear and squared sums, as well as the number of samples. New points entering the root are merged with the closest subcluster recursively. The algorithm also supports incremental updates of center positions using mini-batches. Additionally, there are references to alternative implementations and detailed information on the structure and properties of the tree. The algorithm allows for online learning to prevent rebuilding the tree from scratch and provides methods for predicting data using subcluster centroids and transforming data into subcluster centroids dimensions. The DBSCAN clustering algorithm is used to find core samples of high density and expand clusters from them, making it suitable for data with clusters of similar density. It has a worst-case memory complexity of \\(O({n}^2)\\) due to the eps parameter and min_samples values. The algorithm computes pointwise distances and finds nearest neighbors using the NearestNeighbors module. The Minkowski metric is used to calculate distances between points, with the default being the Euclidean distance. The algorithm can handle sparse graphs and precomputed distance matrices. The cluster labels, core sample indices, and number of features seen during fitting are provided as outputs. The implementation is optimized for memory usage, but it may attract higher memory complexity when querying nearest neighborhoods. Other clustering algorithms like OPTICS provide similar results with lower memory usage. References to the original DBSCAN algorithm and related research are also provided. The algorithm can be used to cluster training instances or distances between instances, with the option to provide sample weights. Metadata routing and parameter settings are available for customization. HDBSCAN is a hierarchical density-based clustering algorithm that performs DBSCAN over varying epsilon values to find the best stability. It can find clusters of varying densities and is more robust to parameter selection compared to DBSCAN. The algorithm includes parameters such as minimum cluster size, core point neighborhood size, distance threshold, and cluster merging threshold. It also allows for selecting cluster centers as centroids or medoids. Outliers are labeled differently, and the algorithm provides probabilities for sample clustering. HDBSCAN can handle large datasets with options for parallel processing and different cluster selection methods. The algorithm also provides cluster centroids and medoids, and can be used for online learning. References for the algorithm are provided, and it can return cluster labels based on the input data. Additionally, it offers options for metadata routing and parameter retrieval and setting. Mean shift clustering is a centroid-based algorithm that aims to discover \"blobs\" in a smooth density of samples by updating candidates for centroids to be the mean of the points within a given region. The candidates are then filtered to eliminate near-duplicates to form the final set of centroids. Seeding is performed using a binning technique for scalability. The bandwidth used in the flat kernel can be estimated using sklearn.cluster.estimate_bandwidth. Seeds can be used to initialize kernels, and the initial kernel locations can be set to the discretized version of points for faster processing. Orphans that are not within any kernel can be assigned to the nearest kernel or given a cluster label of -1. The algorithm can be parallelized for tasks such as searching for nearest neighbors and label assignments. The maximum number of iterations per seed point can be specified, as well as the number of jobs to use for computation. The complexity of the algorithm tends towards O(T*n*log(n)) in lower dimensions and O(T*n^2) in higher dimensions. The algorithm can be further optimized by using fewer seeds. The mean shift clustering algorithm is less scalable than the estimate_bandwidth function. References for the algorithm are available in the literature. The algorithm can perform clustering on input data and return cluster labels. It also provides methods for predicting cluster labels for new data and setting parameters for the estimator. The OPTICS (Ordering Points To Identify the Clustering Structure) function estimates clustering structure from a vector array. It is closely related to DBSCAN and finds core samples of high density to expand clusters from them. Unlike DBSCAN, OPTICS keeps cluster hierarchy for a variable neighborhood radius, making it better suited for large datasets. Clusters can be extracted using a DBSCAN-like method or an automatic technique. The implementation deviates from the original OPTICS by first performing k-nearest-neighborhood searches on all points to identify core sizes. The function allows for specifying parameters such as the number of samples in a neighborhood, the maximum distance between two samples, the metric for distance computation, and additional keyword arguments for the metric function. The extraction method used to extract clusters can be specified as \"xi\" or \"dbscan\". The function also allows for correcting clusters according to predecessors calculated by OPTICS. Other parameters include the algorithm used to compute nearest neighbors, leaf size, caching, and the number of parallel jobs to run for neighbor search. The function provides cluster labels for each point in the dataset and information on reachability distances, core distances, and predecessors. The list of clusters is ordered according to size, with larger clusters encompassing smaller ones. The function also provides the number of features seen during fit and names of features seen during fit. Additionally, the function allows for performing OPTICS clustering, extracting an ordered list of points and reachability distances, and performing initial clustering using a specified maximum distance. The function returns a fitted instance of itself and cluster labels for the input data. Spectral Clustering is a useful method for clustering when the structure of the individual clusters is highly non-convex or when a measure of the center and spread of the cluster is not a suitable description of the complete cluster, such as nested circles on the 2D plane. It can be used to find normalized graph cuts when the affinity matrix is the adjacency matrix of a graph. The method involves constructing an affinity matrix using a kernel function like the Gaussian kernel or a k-nearest neighbors connectivity matrix. Alternatively, a user-provided affinity matrix can be specified. The number of eigenvectors to use for the spectral embedding can be specified, along with the kernel coefficient for different types of kernels. The stopping criterion for eigen decomposition of the Laplacian matrix can also be set. Different strategies for assigning labels in the embedding space are available, including k-means, discretization, and the cluster_qr method. The function also allows for setting the degree of the polynomial kernel, the number of parallel jobs to run, and the verbosity mode. The affinity matrix used for clustering, labels of each point, number of features seen during fit, and names of features seen during fit are also available. The algorithm can be applied to perform spectral clustering from features or an affinity matrix, returning cluster labels. Additionally, metadata routing information, parameters for the estimator, and the ability to set parameters of the estimator are provided. The Affinity Propagation Clustering function performs clustering of data based on a matrix of similarities between points and preferences for each point. The number of clusters is influenced by the input preferences value, with options to set preferences to the median of similarities or the minimum value for fewer clusters. Additional parameters include the number of iterations for convergence, maximum iterations, damping factor, and verbosity level. The function can return cluster centers, labels for each point, and the number of iterations run. When the algorithm does not converge, it still provides cluster center indices and labels, but caution is advised. The Xi-steep method is used to automatically extract clusters, with reachability distances and predecessors calculated by OPTICS. Parameters such as min_samples, steepness, and correct clusters are used to define cluster boundaries and assign labels to samples.Clusters are represented as lists of indices, ordered by size. The DBSCAN clustering algorithm is used to group samples based on their proximity to each other. It requires parameters such as the maximum distance between samples to be considered neighbors, the number of samples in a neighborhood for a point to be a core point, the metric for calculating distances, and the number of parallel jobs to run. The algorithm assigns cluster labels to each point, with noisy samples labeled as -1. The implementation optimizes memory usage but may have higher memory complexity when querying nearest neighborhoods. To reduce memory and computation time, pre-compute sparse neighborhoods or remove duplicate points. OPTICS is an alternative clustering algorithm with lower memory usage. References include papers by Ester et al. (1996) and Schubert et al. (2017) on the benefits of using DBSCAN. The K-means clustering algorithm is used to cluster observations into a specified number of clusters with a given number of centroids. The algorithm can be initialized using 'k-means++' or 'random' methods, with the option to run multiple times for the best results. The maximum number of iterations and convergence tolerance can be specified. Different algorithms like \"lloyd\" and \"elkan\" can be used, with \"elkan\" being more memory intensive but efficient on certain datasets. The final output includes the centroids, labels for each observation, inertia criterion, and number of iterations for the best results. The data can be pre-processed for numerical accuracy, and options for random number generation are available. The function performs mean shift clustering of data using a flat kernel. The bandwidth can be specified or determined using a heuristic based on the median of all pairwise distances. Initial kernel locations can be set or determined based on bin seeding. The algorithm can be sped up by setting certain options. Orphans, points not within any kernel, can be assigned to the nearest kernel or given a cluster label of -1. The maximum number of iterations per seed point can be specified. Parallelization can be used for nearest neighbor search and label assignments. The function returns the coordinates of cluster centers and cluster labels for each point. For more details and an example, refer to the User Guide and examples/cluster/plot_mean_shift.py. The Ward clustering algorithm is used to recursively merge clusters in a way that minimally increases within-cluster variance. It operates on a feature matrix and can take into account topological structure between samples using a connectivity matrix. The algorithm can stop early at a specified number of clusters to save computation time. It can return various outputs such as distances between clusters, the structure of the tree, the number of connected components, and the parent of each node. The distances between the centers of nodes are calculated using a weighted Euclidean distance formula. This algorithm is also known as the incremental algorithm. Agglomerative Clustering is a function that recursively merges pairs of clusters of sample data using a linkage distance. The number of clusters to find must be specified, and the metric used to compute the linkage can be \"euclidean\", \"l1\", \"l2\", \"manhattan\", \"cosine\", or \"precomputed\". The function also allows for caching the output of the computation of the tree and defining a connectivity matrix. It provides options to stop early the construction of the tree at a certain number of clusters and specifies which linkage criterion to use, such as 'ward', 'average', 'complete', 'maximum', or 'single'. The function also includes a linkage distance threshold, computes distances between clusters, and returns the number of clusters found by the algorithm, cluster labels, number of leaves in the hierarchical tree, and the estimated number of connected components in the graph. Additionally, it provides information on the children of each non-leaf node, distances between nodes, and allows for hierarchical clustering with ward linkage. The function can fit the hierarchical clustering from features or a distance matrix, return the result of each sample's clustering assignment, get metadata routing, get parameters for the estimator, and set the parameters of the estimator. The Bisecting K-Means clustering function is used to form clusters and generate centroids. It allows for different methods of initialization, such as 'k-means++' and 'random'. The algorithm runs multiple times with different centroid seeds to produce the best output. Various parameters can be set, such as the number of iterations, verbosity mode, and convergence tolerance. The function also provides information on cluster centers, labels, and cluster distances. Additionally, it offers methods for predicting cluster indices and setting output containers. The function supports metadata routing and parameter configuration. It is important to note that the function may be inefficient when the number of clusters is less than 3. The Agglomerate features function recursively merges pairs of clusters of features based on a specified number of clusters, metric for linkage computation, and connectivity matrix. It allows for early stopping of tree construction and specifies the linkage criterion to use. Additionally, it computes distances between clusters and provides cluster labels, number of leaves in the hierarchical tree, and estimated number of connected components. The function also returns the transformer and allows for fitting and transforming data, as well as setting output containers. It provides methods for getting output feature names, metadata routing, parameters, and inverse transformation. The function can assign values to each cluster of samples and set parameters for the estimator. Finally, it allows for transforming a new matrix using the built clustering and obtaining pooled values for each feature cluster. The K-Means clustering algorithm is a method for grouping data points into a specified number of clusters. It involves selecting the number of clusters and centroids, as well as choosing an initialization method such as 'k-means++' or 'random'. The algorithm can be run multiple times with different centroid seeds to find the best output. The maximum number of iterations and convergence tolerance can also be specified. The algorithm can use either the \"lloyd\" or \"elkan\" variation, with the latter being more memory intensive but potentially more efficient. The algorithm computes cluster centers, assigns labels to each point, and calculates the sum of squared distances to the closest cluster center. It is recommended to restart the algorithm several times to avoid local minima. Various examples and demonstrations are provided for using K-Means clustering, such as color quantization, clustering text documents, and comparing K-Means with MiniBatchKMeans. Additional methods are available for transforming data, setting parameters, and requesting metadata. Mini-Batch K-Means clustering is a method for clustering data into a specified number of clusters with a specified number of centroids. The algorithm uses methods for initialization such as 'k-means++' and 'random'. It also allows for control over the maximum number of iterations, batch size, and early stopping criteria. The algorithm can handle sparse high-dimensional problems and offers options for the number of random initializations to try. The inertia criterion is used to evaluate the quality of the clustering. The algorithm can compute cluster centers, predict cluster indices, and transform data into cluster-distance space. It also provides options for metadata routing and setting output containers. The algorithm can be updated and configured with specific parameters. Overall, Mini-Batch K-Means clustering is a versatile clustering algorithm with various options for customization and optimization. Spectral biclustering is a method that partitions rows and columns of data under the assumption of an underlying checkerboard structure. The number of row and column clusters in the checkerboard structure can be specified, along with the method of normalizing and converting singular vectors into biclusters. Options for normalization include 'scale', 'bistochastic', or 'log', with 'log' being recommended by the authors. However, if the data is sparse, 'bistochastic' is the default choice. The algorithm for finding singular vectors can be 'randomized' or 'arpack', with 'randomized' being faster for large matrices and 'arpack' being more accurate. Mini-batch k-means can be used for faster results, with options for initialization and number of random initializations. Results of the clustering include row and column partition labels, as well as indicators for rows and columns. Additional features such as metadata routing and parameter retrieval are also available. The method works with sparse matrices and allows for setting parameters of the estimator. The Spectral Co-Clustering algorithm, introduced by Dhillon in 2001, clusters rows and columns of an array X to solve the relaxed normalized cut of the bipartite graph created from X. The resulting bicluster structure is block-diagonal, with each row and column belonging to exactly one bicluster. This algorithm supports sparse matrices as long as they are nonnegative. Users can specify the number of biclusters to find and select the algorithm for finding singular vectors, which can be either 'randomized' or 'arpack'. The number of vectors to use in calculating the SVD can also be specified. Additionally, users can choose to use mini-batch k-means for faster results, specify the initialization method for the k-means algorithm, and set the number of random initializations to try. The results of the clustering, including row and column indicators, as well as the bicluster labels of each row and column, are available after fitting the model. The algorithm also provides a convenient way to get row and column indicators together. Users can access metadata routing information and get parameters for the estimator. The algorithm works with sparse matrices and allows users to set parameters. The functions provided include performing DBSCAN extraction with an arbitrary epsilon, extracting clusters in linear time, calculating reachability distances using OPTICS, determining core distances, ordering point indices, setting the DBSCAN epsilon parameter to be less than the maximum epsilon, and obtaining estimated labels. It is important to note that setting eps close to max_eps will result in labels similar to DBSCAN with similar settings. The OPTICS algorithm is used to compute the reachability graph, with options for defining the neighborhood size, maximum distance between samples, and distance metric. Various metrics can be used, including those from scikit-learn and scipy.spatial.distance. The algorithm can use different methods for computing nearest neighbors, such as BallTree or KDTree. Additional parameters like leaf size and number of parallel jobs can be specified. The output includes a cluster-ordered list of sample indices, core distances, reachability distances, and predecessor points. For more details, refer to the documentation by Ankerst et al. (1999). The function estimates the bandwidth to use with the mean-shift algorithm, which takes at least quadratic time in n_samples. For large datasets, subsampling can be done by setting n_samples or setting the bandwidth parameter to a small value without estimation. The input points should be between [0, 1], with 0.5 representing the median of all pairwise distances. The number of samples to use can be specified, with all samples being used if not given. The function also allows for setting the number of parallel jobs for neighbors search, initializing n_clusters seeds according to k-means++, and specifying the weights for each observation in X. Additionally, it determines the squared Euclidean norm of each data point and the number of seeding trials for each center. The function selects initial cluster centers for k-means clustering in a smart way to speed up convergence. ",
    "sklearn.compose": "The ColumnTransformer class in scikit-learn allows for the application of different transformers to columns of an array or pandas DataFrame. This is useful for combining various feature extraction mechanisms or transformations into a single transformer, especially for heterogeneous or columnar data. The transformers are specified as a list of (name, transformer, columns) tuples, allowing for flexibility in setting parameters and searching in grid search. Special strings like 'drop' and 'passthrough' can be used to indicate dropping columns or passing them through untransformed. The data can be indexed on its second axis, with integers representing positional columns and strings referencing DataFrame columns by name. The output of the transformers can be weighted multiplicatively, and the transformed output can be either sparse or dense depending on the individual transformers and the sparse_threshold keyword. The ColumnTransformer also provides methods for accessing fitted transformers by name, getting feature names, and configuring the output format. Additionally, it supports metadata routing and allows for setting parameters of the estimator and contained subobjects. Overall, the ColumnTransformer class in scikit-learn is a powerful tool for applying multiple transformers to different columns of a dataset and concatenating the results. The make_column_selector function allows for the selection of columns to be used with ColumnTransformer based on data type or column name using regex. Multiple selection criteria can be used, with all criteria needing to match for a column to be selected. The function can be used within a ColumnTransformer to select columns based on data type. The function also allows for the inclusion or exclusion of specific data types. Overall, make_column_selector is a callable that helps in selecting columns from a DataFrame to be used in a ColumnTransformer. The Meta-estimator is used to regress on a transformed target, allowing for non-linear transformations such as QuantileTransformer or functions like np.log and np.exp. It automatically clones the regressor and transformer before fitting, with the option to use LinearRegression if no regressor is specified. The target y is converted into a 2-dimensional array internally, and reshaped during prediction. The coefficient of determination \\(R^2\\) is calculated for the prediction, with a score of 1.0 indicating the best possible fit. The method also allows for setting parameters, predicting values, and requesting metadata for scoring. Additionally, the method supports metadata routing for sample weights and returns the updated object. ",
    "sklearn.covariance": "The Minimum Covariance Determinant (MCD) estimator is used for detecting outliers in a Gaussian distributed dataset. It can estimate the precision and compute the support of robust location and covariance estimates. The algorithm can work with data whose mean is close to zero but not exactly zero. The proportion of points to be included in the support of the raw MCD estimate can be specified, as well as the amount of contamination in the dataset. The decision function is defined based on the raw scores and an offset. The estimator also provides information on the raw robust estimated location and covariance before correction and re-weighting. Mahalanobis distances of the training set observations can be computed, along with the number of features seen during fit. The estimator also includes features such as Sparse inverse covariance estimation, LedoitWolf Estimator, and Oracle Approximating Shrinkage Estimator. Outlier detection from covariance estimation may not perform well in high-dimensional settings. Corrections to raw MCD estimates can be applied using empirical correction factors. The Mean Squared Error between two covariance estimators can be computed, and the decision function of given observations can be calculated. The EllipticEnvelope model can be fitted to the data, and labels for inliers and outliers can be predicted. The precision matrix, squared Mahalanobis distances, and negative Mahalanobis distances can also be computed. Re-weighting of raw MCD estimates is possible using Rousseeuw's method. The mean accuracy on test data and labels can be calculated, and parameters of the estimator can be set. Metadata routing and sample weight parameters can also be requested. The GraphicalLasso function is used for sparse inverse covariance estimation with an l1-penalized estimator. The regularization parameter alpha controls the sparsity of the inverse covariance matrix. Users can choose between coordinate descent or LARS as the Lasso solver. The function can handle precomputed covariance matrices or estimate empirical covariances from the data. Other parameters include tolerance for convergence, maximum number of iterations, and machine-precision regularization. The function can return estimated mean, covariance matrix, pseudo-inverse matrix, number of iterations, and objective function values. It also provides options for cross-validated choice of l1 penalty, computing Mean Squared Error between covariance estimators, and computing Mahalanobis distances. Users can compute log-likelihood under the estimated Gaussian model and set parameters of the estimator. Metadata routing and parameter retrieval are also available features. The Ledoit-Wolf Estimator is a form of shrinkage used for large-dimensional covariance matrices. It computes the shrinkage coefficient using a specific formula by Ledoit and Wolf. The estimator can store the estimated precision and split the covariance matrix into blocks for memory optimization. It provides estimates for the covariance matrix, mean, pseudo-inverse matrix, and coefficient for the shrunk estimate. Additionally, it offers features for outlier detection, maximum likelihood covariance estimation, sparse inverse covariance estimation, robust covariance estimation, and shrinkage covariance estimation. The regularized covariance is calculated using a formula that includes shrinkage and the covariance matrix. The estimator also allows for computing the Mean Squared Error between two covariance estimators. Other functionalities include fitting the Ledoit-Wolf shrunk covariance model, computing Mahalanobis distances, log-likelihood of test data under a Gaussian model, setting parameters, and requesting metadata routing. The Oracle Approximating Shrinkage Estimator is a method used for covariance estimation, which can store the estimated precision if specified. It is useful when working with data that has a mean close to zero. The estimator provides various outputs such as the estimated covariance matrix, location (mean), pseudo inverse matrix, and coefficient in the convex combination. Additionally, it includes features like the number of features seen during fit and names of features seen during fit. Other related functions include outlier detection, maximum likelihood covariance estimation, sparse inverse covariance estimation, LedoitWolf Estimator, Minimum Covariance Determinant, and covariance estimator with shrinkage. The shrinkage formulation implemented in the regularized covariance differs from the original article by omitting a small value operation for large feature numbers. References are provided for further reading. The estimator also includes functions for computing Mean Squared Error between covariance estimators, fitting the model to data, getting metadata routing, retrieving parameters, computing Mahalanobis distances, computing log-likelihood, and setting parameters. Metadata routing options are available for passing metadata to the score method. The functions provided in the list are related to computing different types of covariance estimators. These include the Maximum Likelihood covariance estimator, the Ledoit-Wolf covariance matrix estimator, and the Oracle Approximating Shrinkage estimator. Each function allows for the computation of covariance estimates from data, with options to center the data before computation. The shrunk covariance is calculated using a convex combination formula, with specific coefficients and formulas provided in the notes. The Oracle Approximating Shrinkage estimator uses a different shrinkage formulation compared to the original article referenced. Overall, these functions provide tools for estimating covariance matrices with different approaches and optimizations. The Maximum Likelihood Covariance Estimator is a method used to estimate the covariance matrix, pseudo-inverse matrix, and mean of a dataset. It can be used with or without centering the data before computation. Other related functions include Sparse Inverse Covariance Estimation, LedoitWolf Estimator, Minimum Covariance Determinant, Oracle Approximating Shrinkage Estimator, and Covariance Estimator with Shrinkage. The Mean Squared Error function allows for comparison between two covariance estimators. Additional functions include computing Mahalanobis distances, log-likelihood of test data under a Gaussian model, setting parameters of the estimator, and requesting metadata routing. These functions provide a comprehensive set of tools for covariance estimation and analysis. The GraphicalLassoCV function is used for sparse inverse covariance estimation with a cross-validated choice of the l1 penalty. It allows for the selection of the penalization parameter and provides various outputs such as the estimated mean, covariance matrix, precision matrix, and penalization parameter selected. The function uses a grid search approach to find the optimal penalization parameter and can handle ill-conditioned systems. Additionally, it provides options for setting the tolerance for convergence, the solver type, number of iterations, and parallel processing. The function also offers methods for computing the Mean Squared Error between covariance estimators, fitting the covariance model, computing Mahalanobis distances, and calculating log-likelihood under the estimated Gaussian model. Furthermore, it includes options for setting parameters, getting metadata routing, and requesting metadata for the score method. The Minimum Covariance Determinant (MCD) is a robust estimator of covariance that is suitable for Gaussian-distributed data, but can also be used with unimodal, symmetric distributions. It is not recommended for multi-modal data. The MCD estimator can be used with or without storing the estimated precision, and it allows for specifying the proportion of points to be included in the support of the raw estimate. The algorithm used in MCD estimation is the FastMCD algorithm. \n\nThe MCD estimator provides estimates for the robust location, covariance matrix, and pseudo-inverse matrix. It also computes Mahalanobis distances for the training set observations. Other related estimators include the Maximum Likelihood Covariance Estimator, Sparse Inverse Covariance Estimators, and Oracle Approximating Shrinkage Estimator. \n\nThere are methods available to correct raw MCD estimates, compute Mean Squared Error between covariance estimators, re-weight observations, and compute the log-likelihood of test data under the estimated Gaussian model. Additionally, there are methods for setting parameters of the estimator and requesting metadata routing. \n\nOverall, the MCD estimator is a powerful tool for robust covariance estimation, particularly for Gaussian-distributed data, with various options and methods available for customization and analysis. The Covariance estimator with shrinkage allows for the computation of the estimated covariance matrix, estimated mean, and estimated pseudo inverse matrix. It also includes the option to store the estimated precision. The shrinkage coefficient is used in a convex combination for the computation of the shrunk estimate. Other related functions include the Maximum Likelihood Covariance Estimator, Sparse Inverse Covariance Estimation with an l1-penalized estimator, and the Minimum Covariance Determinant (robust estimator of covariance). The Oracle Approximating Shrinkage Estimator is also available. The regularized covariance is calculated using a specific formula involving the shrinkage coefficient and the covariance matrix. Additionally, functions are provided for computing the Mean Squared Error between two covariance estimators, fitting the shrunk covariance model to data, computing Mahalanobis distances, and calculating the log-likelihood of test data under the estimated Gaussian model. The precision matrix can be retrieved using a getter function, and parameters can be set using a specific method. Metadata routing is available for certain parameters, allowing for more flexibility in handling metadata. ",
    "sklearn.cross_decomposition": "Canonical Correlation Analysis, also known as \u201cMode B\u201d PLS, is a method for comparing cross decomposition algorithms. It involves determining the number of components to keep, scaling X and Y, setting the maximum number of iterations, and defining convergence criteria. The algorithm can copy X and Y before applying centering and scaling, or perform these operations in place. It calculates the left and right singular vectors of cross-covariance matrices, loadings of X and Y, projection matrices, coefficients, and intercepts of the linear model. The method also includes the number of iterations for each component, fitting the model to data, transforming data back to its original space, predicting targets, and calculating the coefficient of determination. Additional features include setting output containers, configuring output formats, setting parameters, and requesting metadata. The method is used for dimension reduction, transforming data, and applying the dimension reduction process. PLS regression, also known as PLS2 or PLS1, is a cross decomposition algorithm that allows for dimension reduction. It involves keeping a specified number of components and scaling the input and output data. The algorithm iterates through the power method until convergence criteria are met. The model fits the training data by transforming the samples and targets using projection matrices. The coefficients of the linear model are used to approximate the targets. The algorithm can also transform data back to its original space and predict targets for new samples. The coefficient of determination \\(R^2\\) is used to evaluate the prediction performance. Additionally, the algorithm provides options for setting output formats and configuring the output of transformations. Metadata routing can be used to request additional information during prediction and scoring. Overall, PLS regression is a versatile algorithm for dimension reduction and prediction tasks. The Partial Least Squares (PLS) transformer and regressor is a method for dimensionality reduction and regression. It is used to estimate the first singular vectors of the cross-covariance matrix, with options for scaling, number of components to keep, and the algorithm used. The PLS algorithm includes features such as the left and right singular vectors, loadings of X and Y, projection matrices, coefficients of the linear model, and intercepts. It also allows for fitting the model to data, transforming data back to its original space, predicting targets, and calculating the coefficient of determination. Additionally, there are options for setting output containers, configuring output formats, setting parameters, and requesting metadata. The method supports metadata routing for various parameters and provides options for copying data or performing in-place normalization. It is important to note that the 'Y' parameter is deprecated in version 1.5 and will be removed in version 1.7, with 'y' being the recommended alternative. ",
    "sklearn.datasets": "The function allows for the deletion of all content in the data home cache and specifies the path to the scikit-learn data directory. It loads filenames and data from the 20 newsgroups dataset for classification, downloading it if necessary. Users can specify a download and cache folder for datasets, select the dataset to load (train, test, or all), and choose whether or not to shuffle the data. The function also allows for the removal of certain types of text from newsgroup posts to prevent overfitting on metadata. Additionally, it provides options for handling HTTP errors, specifying the number of retries and seconds between retries. The function returns a dictionary-like object with attributes such as data list, target labels, dataset description, target class names, and ndarrays containing samples and features. The California housing dataset is loaded for regression analysis, containing 20640 samples with 8 dimensions and real features ranging from 0.15 to 5. The data can be stored in a specified folder, and can be returned as a pandas DataFrame with appropriate data types. The target values are also returned as a pandas DataFrame or Series. Additional parameters include the number of retries and seconds between retries for HTTP errors. The dataset includes 9 features, with each row corresponding to the 8 feature values in order. The average house value is in units of 100,000. The dataset can be returned as a DataFrame with data and target, or as a tuple of two ndarrays representing samples and target values. The function allows for loading the kddcup99 dataset for classification purposes. It provides options to return specific subsets of the dataset or the entire dataset. Users can specify a different download and cache folder for the datasets. Additionally, there are options to shuffle the dataset, load only 10 percent of the data, and control the number of retries and seconds between retries when encountering HTTP errors. The function returns a dictionary-like object with attributes such as the data matrix, regression target, dataset description, column names, and the data and target arrays. Users can also choose to return a pandas DataFrame for the data and target objects. The function loads the Labeled Faces in the Wild (LFW) people dataset for classification purposes. It allows for downloading and caching the dataset, specifying a custom download folder, using the funneled variant of the dataset, resizing face pictures, setting a minimum number of pictures per person, keeping RGB channels, extracting a custom 2D slice from jpeg files, handling data availability, and returning data and target as a tuple. The dataset consists of 5749 classes with a total of 13233 samples and 5828 features. Each row corresponds to a ravelled face image of size 62 x 47 pixels, with labels ranging from 0-5748 representing person IDs. The function returns a tuple of two ndarrays, one containing the samples and the other containing the target samples. The function fetches datasets from openml by name or dataset id. Datasets can be uniquely identified by an integer ID or a combination of name and version. It is recommended to specify an exact version when retrieving a dataset as there may be multiple active versions that are fundamentally different. The function allows for specifying a download and cache folder for the datasets, as well as the column name to use as the target. It also provides options for caching downloaded datasets, returning data and target as pandas DataFrames, and specifying the number of retries and seconds between retries for HTTP errors or network timeouts. The function supports different parsers for loading ARFF files, with options for pandas or liac-arff. Additional keyword arguments can be passed to pandas.read_csv when using the pandas parser. The function returns a dictionary-like object with attributes such as the feature matrix, regression target or classification labels, dataset description, column names, target column names, and metadata from OpenML. Missing values in the data and target are represented as NaNs or None. The function notes differences in data types between the \"pandas\" and \"liac-arff\" parsers, particularly in how categorical features and numerical features are encoded. The function is a loader for the species distribution dataset from Phillips et. al. (2006). It allows for specifying a different download and cache folder for the datasets, as well as setting options for handling missing data and HTTP errors. The dataset includes 14 features measured at each point on a map grid, with latitude/longitude values. It also provides training and test points for two species: \"Bradypus variegatus\" and \"Microryzomys minutus\". The dataset represents the geographic distribution of these species and can be used with scikit-learn for modeling. References to the original study and an example of using the dataset are provided. The breast cancer Wisconsin dataset is a classic and easy binary classification dataset with 569 samples and 30 features. It can be loaded and returned as a pandas DataFrame with appropriate data types. The dataset includes data matrix, classification target, dataset columns names, target classes names, and full description. The data is represented as a 2D ndarray with each row as a sample and each column as a feature. Additionally, specific samples can be selected by their index to retrieve their class name. The function loads and returns the digits dataset for classification purposes. Each datapoint is an 8x8 image of a digit, with 10 classes and approximately 180 samples in total. The dataset has 64 features represented as integers from 0 to 16. It is a copy of the test set of the UCI ML hand-written digits datasets. The function allows for returning the data and target as pandas DataFrames if specified. It provides a dictionary-like object with attributes such as the flattened data matrix, classification target, dataset columns names, and target classes names. Additionally, it includes the raw image data and a full description of the dataset. The function also allows for loading the data and visualizing the images. The iris dataset is a classic and easy multi-class classification dataset with 3 classes, 50 samples per class, and a total of 150 samples. It has 4 features that are real and positive. The dataset can be loaded and returned as a pandas DataFrame with appropriate dtypes for the columns. The target can also be returned as a pandas DataFrame or Series. The dataset includes the data matrix, classification target, column names, target class names, and a full description. The data can be returned as a tuple of two ndarrays, one containing the 2D array of samples and features, and the other containing the target samples. There have been updates to the dataset to fix incorrect data points. Additionally, there is a function to load a numpy array of a single sample image, providing the name of the image and the image itself as a numpy array with dimensions of height x width x color. The function allows for loading datasets in the svmlight/libsvm format into sparse CSR matrix. This text-based format is suitable for sparse datasets and does not store zero-valued features. It can be used to predict a target variable and is recommended to be wrapped with joblib.Memory.cache for faster loading of subsequent calls. Pairwise preference constraints can be ignored unless the query_id parameter is set to True. The implementation is written in Cython and is reasonably fast. The function accepts various parameters such as the file path, number of features, data type, and whether column indices are zero-based or one-based. It can also return the query_id array for each file. Additionally, it allows for ignoring offset bytes and stopping reading data after a certain threshold. The function returns the data matrix, target, and query_id when applicable. The wine dataset is a classic and easy multi-class classification dataset with 3 classes and 178 total samples. It has 13 real, positive features. The dataset can be loaded and returned as a pandas DataFrame with appropriate dtypes for both data and target. The dataset also includes the names of dataset columns and target classes. Additionally, the dataset can be dumped in svmlight/libsvm file format for sparse datasets. It supports multilabel datasets and pairwise preference constraints. The function provided allows for the loading and vectorization of the 20 newsgroups dataset for classification purposes. It can be used to download the dataset if necessary and transform it using the default settings for CountVectorizer. More advanced usage, such as stopword filtering and n-gram extraction, can be achieved by combining fetch_20newsgroups with a custom CountVectorizer, HashingVectorizer, TfidfTransformer, or TfidfVectorizer. The resulting counts are normalized unless specified otherwise. The dataset can be selected to load either the training set, test set, or both, with shuffled ordering. Different subsets of text, such as headers, footers, and quotes, can be removed to prevent overfitting on metadata. Various options are available for specifying download and cache folders for the datasets. Additional features include normalizing each document's feature vector to unit norm, returning data as a pandas DataFrame, and specifying the number of retries and seconds between retries for HTTP errors. The function returns a dictionary-like object with attributes such as the input data matrix, target labels, target classes, and a full description of the dataset. The covertype dataset is a classification dataset with 7 classes and a total of 581012 samples with 54 features. The data can be loaded and cached in a specified folder. Random number generation can be determined for dataset shuffling for reproducible output. The dataset can be shuffled and returned as data and target arrays. The data can be returned as pandas DataFrames with appropriate dtypes. There are options for number of retries and seconds between retries for HTTP errors. The dataset contains 54 features corresponding to 7 forest covertypes. The dataset columns and target columns are named. The dataset can be returned as a tuple of two arrays, one for features and one for target samples. The Labeled Faces in the Wild (LFW) pairs dataset is a classification dataset with a total of 13233 samples and 2 classes. The dimensionality of the dataset is 5828 features, which are real values between 0 and 255. The original images in the dataset are 250 x 250 pixels, but they are resized to 62 x 47 pixels by default. The dataset can be loaded for training, testing, or for official evaluation with 10-folds cross validation. The dataset can be downloaded and cached in a custom folder. The funneled variant of the dataset can be used, and the color channels can be kept separate instead of averaging them. Custom 2D slices can be provided to extract specific parts of the images. HTTP errors encountered during download can be retried with a specified number of retries and time between retries. The dataset consists of pairs of face images, each corresponding to the same or different person from a total of 5749 people. The labels associated with each pair indicate whether the images are of the same person or different persons, with 0 representing \"Different person\" and 1 representing \"Same person\". The functions provided are for loading two different datasets: the Olivetti faces dataset and the RCV1 multilabel dataset. \n\nFor the Olivetti faces dataset, it contains images of faces from 40 different subjects, with each image being a ravelled face image of size 64 x 64 pixels. The dataset also includes labels ranging from 0-39 corresponding to the subject IDs. The function allows for specifying a different download and cache folder, shuffling the dataset, and determining random number generation for reproducible output. It also provides options for retrying HTTP errors and specifying the number of seconds between retries. The function returns a tuple with the data and target objects.\n\nOn the other hand, the RCV1 multilabel dataset includes samples with identification numbers and topics as targets. The dataset is in CSR format with a percentage of non-zero values. Similar to the Olivetti faces dataset function, this function allows for specifying a different download and cache folder, shuffling the dataset, and determining random number generation for reproducible output. It also provides options for retrying HTTP errors and specifying the number of seconds between retries. The function returns a dictionary-like object with attributes related to the dataset. The scikit-learn library provides a function to return the path of the data directory, which is used by certain dataset loaders to avoid redundant downloads. By default, the data directory is set to a folder named 'scikit_learn_data' in the user's home folder, but it can be customized using an environment variable or programmatically. The library also offers a function to load and return the diabetes dataset for regression analysis, containing 442 samples with 10 features. The feature names may not be clear, but the documentation provides information based on scientific literature. The dataset can be returned as a pandas DataFrame with mean-centered and scaled feature variables. The function returns a dictionary-like object with attributes such as the data matrix, regression target, and dataset columns. Additionally, the function returns a tuple of two arrays representing samples and features/targets. The function allows for loading text files with categories as subfolder names. It does not extract features into a numpy array or scipy sparse matrix. If load_content is set to true, the text encoding must be specified. Shuffling the data can be important for certain models. The function can also handle different file extensions and provides a dictionary-like object with raw text data, target labels, target classes, and dataset description. It is recommended to build feature extraction transformers for different types of unstructured data inputs like images, audio, and video. The functions described include loading and returning the physical exercise Linnerud dataset, which is suitable for multi-output regression tasks. The dataset contains 20 samples with a dimensionality of 3 for both data and target features. It can return either a Bunch object or (data, target) if True. The data can be a pandas DataFrame with appropriate column types, and the target can be a DataFrame or Series depending on the number of target columns. The dataset also includes attributes such as the names of dataset and target columns, as well as the path to the data and target locations. Additionally, there is a function to load sample images for image manipulation, specifically the china and flower images. The images can be visualized after loading. The function `load_svmlight_files` allows for loading datasets from multiple files in SVMlight format. It concatenates the results into a single list and ensures that all sample vectors have the same number of features. Pairwise preference constraints can be ignored unless the `query_id` parameter is set to True. The function accepts paths of files to load, can infer the number of features, and specifies the data type of the dataset. It also handles zero-based or one-based column indices and can return the query_id array for each file. Additionally, it provides the option to ignore offset bytes and stop reading data after a certain threshold. The function returns (Xi, yi) pairs or (Xi, yi, qi) triplets if `query_id` is set to True. It is important to note that when fitting a model, the matrices X_train and X_test must have the same number of features. The functions described generate arrays with block diagonal or block checkerboard structures for biclustering. They allow for the creation of datasets with specified shapes, numbers of biclusters, standard deviations of noise, and values within biclusters. The functions also provide options for shuffling samples and controlling random number generation for reproducible output. Additionally, they return arrays with indicators for cluster membership of rows and columns. References to related work in the field of biclustering are also provided for further reading. The function generates a random n-class classification problem by creating clusters of points normally distributed about vertices of a hypercube. It introduces interdependence between features and adds noise to the data. The features are stacked in a specific order, with informative, redundant, and duplicated features included. The number of samples, total features, informative features, redundant features, duplicated features, classes, clusters per class, class proportions, and other parameters can be specified. The function can shuffle samples and features for reproducibility. The algorithm is adapted from Guyon and was designed to generate the \"Madelon\" dataset. The functions provided include generating the \"Friedman #2\" regression problem with specific inputs and outputs, generating isotropic Gaussian and labeling samples by quantile for a classification dataset, and generating a mostly low rank matrix with bell-shaped singular values. The first function creates a regression dataset based on a specific formula, the second function creates a classification dataset with classes separated by nested concentric multi-dimensional spheres, and the third function generates a matrix with structured signal and noisy components. Each function has specific parameters for customization and allows for reproducible output across multiple function calls. The functions provided include generating a random multilabel classification problem, generating an S curve dataset, and options for controlling the output format such as returning sparse matrices or prior class probabilities. The multilabel classification function involves selecting labels, classes, document lengths, and words using various distributions and rejection sampling to ensure constraints are met. The S curve dataset function generates points on an S curve with the option to add Gaussian noise. Both functions allow for reproducible output by specifying a random number generation seed. The functions provided include generating a sparse symmetric definite positive matrix, generating a random symmetric positive-definite matrix, and generating isotropic Gaussian blobs for clustering. The first function allows for the creation of a matrix with specified characteristics such as sparsity, coefficient values, and output format. The second function generates a random symmetric positive-definite matrix based on specified dimensions. The third function is used for creating Gaussian blobs for clustering, with options for defining the number of points, features, centers, standard deviation, and more. Each function has parameters for controlling random number generation and reproducibility. The functions provided generate various datasets for different purposes. \n\nThe first function creates a large circle containing a smaller circle in 2D, which can be used to visualize clustering and classification algorithms. The number of points generated can be specified, and there is an option to shuffle the samples. Gaussian noise can be added to the data, and a scale factor between the inner and outer circle can be set. The function also generates integer labels for class membership.\n\nThe second function generates the \"Friedman #1\" regression problem, where inputs are independent features uniformly distributed on the interval [0, 1]. Only 5 out of the n_features are used to compute the output, with the remaining features being independent. Gaussian noise can be applied to the output, and references to the original research are provided.\n\nThe third function generates the \"Friedman #3\" regression problem, with inputs being 4 independent features uniformly distributed on specific intervals. The output is created according to a specific formula, and Gaussian noise can be applied to the output. References to the original research are provided.\n\nThe fourth function generates data for binary classification used in a specific example, where the features are standard independent Gaussian and the target is defined by a specific formula. References to related literature are provided. Random number generation can be controlled for reproducible output.\n\nOverall, these functions provide a variety of datasets for different machine learning tasks, including clustering, regression, and classification. The functions provided generate datasets for visualization of clustering and classification algorithms. The first function creates two interleaving half circles with the option to specify the number of points, shuffle samples, and add noise. The second function generates a random regression problem with options to control the number of samples, features, informative features, regression targets, bias term, and noise level. It also allows for the manipulation of the singular values profile. The third function generates a signal as a sparse combination of dictionary elements, with options to specify the number of samples, components in the dictionary, features, and active coefficients. Each function provides the necessary outputs for further analysis and modeling. ",
    "sklearn.decomposition": "Dictionary learning is a method that finds a set of atoms that encode data sparsely. It involves solving an optimization problem using different algorithms such as least angle regression and coordinate descent. The number of dictionary elements, sparsity controlling parameter, maximum iterations, and tolerance can be specified. The algorithm used to transform the data can also be chosen. Other parameters include the number of nonzero coefficients, parallel jobs, warm restart values, and verbosity control. Additional options include splitting the feature vector, enforcing positivity, and setting maximum iterations. The process involves extracting dictionary atoms, fitting the model, transforming data, and encoding data using the dictionary atoms. The output format can be configured, and parameters can be set or retrieved. The sparse combination of dictionary atoms can be used to encode test data. References to online dictionary learning for sparse coding are provided. FastICA is a fast algorithm for Independent Component Analysis, with the implementation based on a specific reference. It allows the user to specify the number of components to use, the algorithm to use, and the whitening strategy. The default whitening strategy changed in version 1.3. The algorithm involves a functional form of the G function, which can be customized. Other parameters include the maximum number of iterations, the initial un-mixing array, and the solver to use for whitening. The algorithm also involves the use of a linear operator to apply to the data to get the independent sources. The model can be fitted to training data and the sources can be recovered from the data. The sources can also be transformed back to the mixed data using the mixing matrix. Additional functionalities include getting output feature names, metadata routing, setting parameters, and requesting metadata for transformations. The algorithm also supports incremental principal components analysis, kernel principal component analysis, mini-batch sparse principal components analysis, and sparse principal components analysis. References are provided for further reading. Kernel Principal Component Analysis (KPCA) is a non-linear dimensionality reduction technique that uses kernels. It can utilize different LAPACK implementations based on the input data shape and the number of components to extract. KPCA can also employ randomized truncated SVD for efficiency. Users can compare KPCA with PCA and see examples of its application in denoising images. Various parameters such as the number of components, kernel type, and hyperparameters can be adjusted. The eigensolver can be selected based on the number of training samples and components. The method can handle zero eigenvalues and offers options for reproducibility and memory optimization. The model can fit data, transform it, and perform inverse transformations. Additional functionalities include metadata routing, setting output containers, and updating estimator parameters. Overall, KPCA offers a comprehensive approach to dimensionality reduction with kernels. The Mini-batch dictionary learning function finds a dictionary that performs well at sparsely encoding the fitted data by solving an optimization problem using different algorithms such as 'lars' and 'cd'. It allows for controlling parameters such as the number of dictionary elements, sparsity, and maximum number of iterations. The function also includes options for parallel processing, batch size, shuffling samples, and transforming data using various algorithms. Additional features like enforcing positivity, early stopping criteria, and output configuration are available. The function can be used to fit the model from data, transform it, update the model using mini-batches, and encode data as a sparse combination of dictionary atoms. References to Sparse Principal Components Analysis and online dictionary learning are provided. Overall, the function provides a comprehensive tool for dictionary learning and sparse coding of data. Sparse Principal Components Analysis (Sparse PCA) is a method that finds a set of sparse components to reconstruct data optimally. The sparseness level is controlled by the L1 penalty coefficient alpha. The number of sparse atoms to extract can be specified, with higher values of the sparsity controlling parameter leading to sparser components. Ridge shrinkage can be applied to improve conditioning during transformation. The algorithm stops after a certain number of iterations, with the option to specify a callable function to be invoked every five iterations. The data can be shuffled before splitting it into mini-batches, with the number of parallel jobs also configurable. Two optimization methods, LARS and CD, can be used. Early stopping criteria based on dictionary changes or cost function improvement can be set. The output includes the sparse components extracted, the estimated number of components, and the number of iterations run. The model can be fit to data and transformed, with options for output format configuration. The parameters of the estimator can be set, and the data can be transformed back to the original space using the inverse transformation. Ridge regression can be applied for stability, and the test data must have the same number of features as the training data. Principal Component Analysis (PCA) is a linear dimensionality reduction technique that uses Singular Value Decomposition to project data into a lower dimensional space. The input data is centered but not scaled before applying SVD. PCA can use LAPACK or randomized truncated SVD methods depending on the input data shape and number of components to extract. It supports sparse inputs for certain solvers. The number of components to keep can be specified, and various solvers can be used based on the input data characteristics. Whitening can be applied to the transformed signal to improve downstream estimator accuracy. PCA computes principal axes in feature space, representing directions of maximum variance, and the amount of variance explained by each component. It also provides the singular values corresponding to each component. The estimated noise covariance and number of features seen during fit are also available. PCA implements various solvers and methods for dimensionality reduction, and provides options for transforming data back to its original space. Additionally, it offers methods for computing data covariance, precision, and log-likelihood. The output format of the transformation can be configured, and parameters of the estimator can be set and updated. Overall, PCA is a powerful tool for reducing the dimensionality of data while preserving important information. Sparse Principal Components Analysis (SparsePCA) is a function that finds a set of sparse components to reconstruct data optimally. The sparseness level is controlled by the L1 penalty coefficient alpha. The number of sparse atoms to extract can be specified, with higher values of the sparsity controlling parameter leading to sparser components. Ridge shrinkage can be applied to improve conditioning during transformation. The function allows for setting the maximum number of iterations, tolerance for stopping conditions, and the method for optimization (lars or cd). It also supports setting the number of parallel jobs, initial values for loadings and components in warm restart scenarios, and controlling verbosity. The function returns the sparse components extracted from the data, errors at each iteration, estimated number of components, and other relevant information. Additionally, there is a mini-batch variant available for faster but less accurate results. The function can fit the model from input data, transform it, get output feature names, retrieve metadata routing, get parameters, transform data from latent space to original space, set output container, and set parameters of the estimator. It also supports least squares projection onto sparse components with optional regularization via ridge regression. The function requires test data with the same number of features as the training data for transformation. The function solves a dictionary learning matrix factorization problem by finding the best dictionary and corresponding sparse code to approximate the data matrix. It takes into account parameters such as the number of dictionary atoms, sparsity controlling parameter, maximum number of iterations, and tolerance for the stopping condition. The method used can be 'lars' or 'cd', with 'lars' being faster for sparse components. Other parameters include the number of parallel jobs, initial values for dictionary and sparse code, verbosity control, and options for enforcing positivity. The function also provides information on the sparse code factor, dictionary factor, errors at each iteration, and number of iterations run. Additionally, it offers an online version of the algorithm, a faster but less accurate version, Sparse Principal Components Analysis, and Mini-batch Sparse Principal Components Analysis. The level of sparsity of the sparse code can be evaluated by comparing the reconstruction error to the original signal. The Fast Independent Component Analysis function is used to estimate independent components from a data matrix X, where X = AS. The function allows for specifying the number of components to use, the algorithm to use, the whitening strategy, the G function used in the approximation to neg-entropy, the maximum number of iterations, the tolerance for convergence, the initial un-mixing array, the solver for whitening, and more. The function returns the un-mixing matrix, the mixing matrix, the estimated source matrix, and the mean over features. It is possible to estimate less sources than features by setting n_components < n_features. The implementation was originally for data of shape [n_features, n_samples], but now the input is transposed before the algorithm is applied for faster processing. Sparse coding is a method used to find a sparse array code that represents a data matrix against a dictionary matrix. Various algorithms can be used such as 'lars', 'lasso_lars', 'lasso_cd', 'omp', and 'threshold'. The number of nonzero coefficients to target in each column of the solution can be specified. The initialization value of the sparse codes and maximum number of iterations can also be set. The process can be parallelized and verbosity controlled. Additionally, positivity can be enforced in the encoding. Overall, sparse coding aims to find a sparse representation of data from a precomputed dictionary using different algorithms and parameters. Factor Analysis (FA) is a simple linear generative model with Gaussian latent variables. The observations are assumed to be caused by a linear transformation of lower dimensional latent factors and added Gaussian noise. The factors are distributed according to a Gaussian with zero mean and unit covariance, while the noise has an arbitrary diagonal covariance matrix. FactorAnalysis performs a maximum likelihood estimate of the loading matrix using an SVD-based approach. The dimensionality of the latent space, stopping tolerance for log-likelihood increase, making a copy of X, maximum number of iterations, initial guess of noise variance, SVD method, number of iterations for the power method, and rotation options are all parameters that can be specified. The model can be fit to data, transformed, and used for computing data covariance, precision matrix, log-likelihood, and expected mean of the latent variables. Other related models include Principal Component Analysis (PCA) and Independent Component Analysis. The FactorAnalysis class instance can be used to fit the model to data, transform it, compute data covariance, get output feature names, get metadata routing, get parameters, set output container, configure output format, set parameters, and apply dimensionality reduction to the data. Incremental Principal Components Analysis (IPCA) is a linear dimensionality reduction technique that uses Singular Value Decomposition (SVD) to project data into a lower-dimensional space by keeping only the most significant singular vectors. This algorithm is memory efficient, especially for sparse input data, with a constant memory complexity. IPCA allows for the use of np.memmap files without loading the entire file into memory. The algorithm computes the principal axes in feature space, representing the directions of maximum variance in the data. It also provides information on the variance explained by each selected component and the singular values corresponding to each component. Whitening can be applied to the transformed signal to improve predictive accuracy, but it may remove some information. The algorithm implements the incremental PCA model and is an extension of the Sequential Karhunen-Loeve Transform. The technique omits an optimization used in specific situations to reduce algorithmic complexity, which could be considered for future optimization. The algorithm also provides methods for fitting the model, transforming data, computing data covariance, and precision matrix, as well as inverse transforming data back to its original space. Additionally, it offers options for setting output containers, configuring output formats, setting parameters, and requesting metadata. The algorithm can be used for dimensionality reduction by projecting data onto the first principal components extracted from a training set using minibatches. Latent Dirichlet Allocation with online variational Bayes algorithm is implemented based on references [1] and [2]. The number of topics can be specified, and there are options to set the prior of document topic distribution theta and topic word distribution beta. The method used to update components can be chosen between online and batch updates, with the default now being batch. Parameters such as learning rate, downweighting, and number of passes over the data can be adjusted. Perplexity can be evaluated to check convergence, but it may increase training time. Variational parameters for topic word distribution are calculated, and the model can be fit to data using variational Bayes method. The estimator can transform data and calculate perplexity or log-likelihood scores. The output format can be configured, and parameters of the estimator can be set or retrieved. The document topic distribution for a given dataset can also be obtained. Mini-Batch Non-Negative Matrix Factorization (NMF) is a method added in version 1.1 that finds two non-negative matrices (W, H) whose product approximates a non-negative matrix X. This factorization can be used for dimensionality reduction, source separation, or topic extraction. The objective function is minimized with an alternating minimization of W and H. The number of components can be automatically inferred if not set. Different methods can be used to initialize the procedure, such as 'random' or 'nndsvd'. The beta divergence, regularization terms, and rescaling of past information can be controlled. Early stopping and maximum number of iterations can also be set. The transformed data is named W and the components matrix is named H. The model can be updated using partial_fit for out-of-core or online learning. The output format can be configured as 'default', 'pandas', 'polars', or None. The model parameters can be set and the data can be transformed according to the fitted MiniBatchNMF model. Non-Negative Matrix Factorization (NMF) is a technique used to find two non-negative matrices, W and H, whose product approximates a given non-negative matrix X. This factorization can be applied for tasks such as dimensionality reduction, source separation, or topic extraction. The objective function involves minimizing the difference between X and the dot product WH, with options for different beta-divergence losses. The regularization terms for W and H are scaled to balance their impact with respect to the data fit term. The NMF model can be initialized using various methods, such as 'random' or 'nndsvd'. The solver options include Coordinate Descent and Multiplicative Update. Additional parameters like regularization constants, mixing parameters, and verbosity can be adjusted. The model can be trained on data X and transformed efficiently. The output can be configured to different formats like 'pandas' or 'polars'. Overall, NMF is a powerful tool for data analysis and dimensionality reduction. Sparse coding is a method that finds a sparse representation of data against a fixed, precomputed dictionary. The goal is to find a sparse array code such that the dictionary atoms used for sparse coding are normalized to unit norm. Various algorithms can be used to transform the data, such as 'lars', 'lasso_lars', 'lasso_cd', 'omp', and 'threshold'. The number of nonzero coefficients to target in each column of the solution can be specified, as well as whether to split the sparse feature vector into its negative and positive parts. Other parameters include the number of parallel jobs to run, whether to enforce positivity when finding the code, and the maximum number of iterations to perform. The method also includes options for dictionary learning, mini-batch sparse principal components analysis, and sparse principal components analysis. Additionally, there are methods for fitting the transformer to data, getting output feature names, metadata routing, getting parameters for the estimator, setting output container, setting parameters of the estimator, and encoding the data as a sparse combination of dictionary atoms. Dimensionality reduction using truncated SVD, also known as LSA, is a linear dimensionality reduction technique that does not center the data before computing the singular value decomposition, making it efficient for sparse matrices. It works on term count/tf-idf matrices and supports two algorithms: a fast randomized SVD solver and a \"naive\" algorithm using ARPACK. The desired dimensionality of the output data can be specified, along with the SVD solver to use, number of iterations, oversamples, and power iteration normalizer for the randomized SVD solver. The right singular vectors, variance of training samples transformed by projection, percentage of variance explained, and singular values corresponding to selected components are provided. SVD suffers from \"sign indeterminacy\", so fitting the class to data once and keeping the instance for transformations is recommended. Other related techniques include incremental principal components analysis, kernel principal component analysis, and non-negative matrix factorization. The class provides methods for fitting the model on training data, performing dimensionality reduction, transforming data back to its original space, setting output containers, configuring output formats, getting metadata routing, getting parameters, setting parameters, and performing dimensionality reduction on new data. The function solves a dictionary learning matrix factorization problem online by finding the best dictionary and corresponding sparse code to approximate the data matrix X. It iterates over mini-batches of input data, with options to control the number of dictionary atoms, sparsity, maximum iterations, and more. Deprecated parameters include max_iter=None, with the default value now set to 100. Additional options include returning the code U, setting initial dictionary values, controlling verbosity, shuffling data, enforcing positivity, and specifying the number of parallel jobs. Different methods can be used to solve the lasso problem, such as 'lars' or 'cd'. The function also provides options for early stopping based on dictionary changes or cost function improvements. The output includes the sparse code, solutions to the dictionary learning problem, and the number of iterations run. This function is a faster, less accurate version of the dictionary learning algorithm, with options for Sparse Principal Components Analysis and Mini-batch Sparse Principal Components Analysis. The level of sparsity of U can be checked by comparing the reconstruction error of the sparse coded signal to the original signal. ",
    "sklearn.discriminant_analysis": "Linear Discriminant Analysis (LDA) is a classifier with a linear decision boundary that fits a Gaussian density to each class, assuming they share the same covariance matrix. It can also reduce input dimensionality by projecting it to the most discriminative directions. LDA has different solvers like 'svd', 'lsqr', and 'eigen', each with its own advantages. The class prior probabilities, number of components for dimensionality reduction, and other parameters can be specified. LDA can compute the weighted within-class covariance matrix and estimate the rank of the input data. It also supports a covariance estimator for more accurate covariance matrix estimation. LDA provides information on explained variances, class-wise means, class priors, scaling of features, overall mean, unique class labels, and number of features seen during fit. It can apply a decision function to samples, predict class labels, estimate log probabilities, and probabilities. LDA can be fitted to data and transformed, with options to set output container and configure output format. It also allows for setting and getting parameters, as well as requesting metadata for scoring. Additionally, LDA can project data to maximize class separation, with different output shapes depending on the solver used. ",
    "sklearn.dummy": "The DummyClassifier is a simple baseline classifier that makes predictions ignoring input features. It has different strategies for generating predictions, such as \"most_frequent\", \"prior\", \"stratified\", \"uniform\", and \"constant\". The default strategy changed to \"prior\" in version 0.24. The classifier can control randomness for \"stratified\" and \"uniform\" strategies by setting the random_state parameter. It can handle multi-output classification problems and provides information about unique class labels, number of labels, frequency of classes, features seen during fit, and more. The classifier can be fitted, used for prediction, return log probability estimates, return probability estimates, calculate mean accuracy, and handle metadata routing. Additionally, it allows for setting and getting parameters, as well as updating parameters for the estimator. The DummyClassifier can also handle metadata routing for sample_weight parameters in fit and score methods. ",
    "sklearn.ensemble": "An AdaBoost classifier is a meta-estimator that fits a classifier on the original dataset and then fits additional copies of the classifier on the same dataset, adjusting the weights of incorrectly classified instances to focus more on difficult cases. It requires support for sample weighting, proper classes, and n_classes attributes. The base estimator can be a DecisionTreeClassifier initialized with max_depth=1 if None is specified. The maximum number of estimators can be specified, along with the learning rate and the boosting algorithm (SAMME.R or SAMME). The random seed can be controlled, and the feature importances can be computed. The classifier can predict classes, class log-probabilities, and class probabilities for input samples. The mean accuracy on test data can be calculated, and staged predictions, class probabilities, and scores can be returned after each boosting iteration. The estimator also supports setting and getting parameters, as well as metadata routing for sample weights. A Bagging classifier is an ensemble meta-estimator that fits base classifiers on random subsets of the original dataset and aggregates their predictions to form a final prediction. This method can reduce the variance of a black-box estimator by introducing randomization into its construction. Different variations of this algorithm include Pasting, Bagging, Random Subspaces, and Random Patches. The base estimator can be a DecisionTreeClassifier if not specified. The number of base estimators, samples, and features to draw can be specified. Out-of-bag samples can be used to estimate generalization error. The ensemble can be updated with more estimators without re-fitting. The random resampling of the dataset can be controlled, and the verbosity can be adjusted. The ensemble consists of fitted base estimators, and the training input samples are used to predict classes, class log-probabilities, and class probabilities. The mean accuracy on test data can be calculated, and metadata can be requested and passed to the fit and score methods. The parameters of the estimator can be set, and metadata routing for sample weights can be adjusted. The Extra-Trees Classifier is a meta estimator that fits randomized decision trees on sub-samples of the dataset to improve predictive accuracy and control over-fitting. It allows for setting the number of trees in the forest, the quality of a split, the maximum depth of the tree, the minimum number of samples required to split an internal node, the minimum number of samples required to be at a leaf node, the number of features to consider when looking for the best split, and more. It also controls randomness in bootstrapping, feature sampling, and split selection. The classifier supports multiclass and multioutput classifications, as well as data with missing values. The feature importances are based on impurity reduction, and the forest can be used for regression tasks as well. Additionally, the classifier provides methods for predicting class labels, class probabilities, and accuracy on test data. It also allows for metadata routing and setting parameters. Gradient Boosting for classification is an algorithm that builds an additive model in a forward stage-wise fashion, allowing for the optimization of arbitrary differentiable loss functions. It involves fitting regression trees on the negative gradient of the loss function, with options for binary or multiclass log loss. The sklearn.ensemble.HistGradientBoostingClassifier is a faster variant for intermediate datasets. The algorithm supports different loss functions such as 'log_loss' and 'exponential', with parameters like learning rate, number of boosting stages, and subsample fraction. Other parameters include the function to measure split quality, minimum samples required for splitting and leaf nodes, maximum depth of trees, and more. The algorithm also supports early stopping, feature importance computation, and monitoring of performance. References include works by J. Friedman and T. Hastie. The algorithm can be used for fitting a gradient boosting classifier with decision stumps as weak learners, and provides methods for predicting classes, class probabilities, and computing decision functions. It also supports metadata routing and parameter setting. The Histogram-based Gradient Boosting Classification Tree is a faster estimator than GradientBoostingClassifier for large datasets with native support for missing values. It uses a logistic loss function for binary classification and multinomial deviance for multiclass classification. The learning rate is used as a shrinkage factor, and the model fits one tree per boosting iteration. Other parameters include the maximum number of iterations, maximum number of leaves, maximum tree depth, minimum samples per leaf, L2 regularization, feature subsampling, and maximum number of bins for non-missing values. Categorical features can be specified, and monotonic constraints can be enforced on features. Interaction constraints can also be specified. Early stopping can be enabled based on the sample size, and a scoring parameter can be defined for early stopping. The model can be fit, predict classes and class probabilities, and compute decision functions at each iteration. The mean accuracy on test data can also be calculated. Additional features include metadata routing, setting parameters, and requesting metadata for fit and score methods. The Isolation Forest Algorithm is used to return the anomaly score of each sample by isolating observations through random selection of features and split values. The path length from the root node to the terminating node in a tree structure is used to measure normality and make decisions. Shorter path lengths indicate anomalies. The number of base estimators, contamination level, number of features, and other parameters can be adjusted. The algorithm is based on libsvm and uses an ensemble of ExtraTreeRegressor. An example of using isolation forest for anomaly detection is provided. The anomaly score of an input sample is computed as the mean anomaly score of the trees in the forest, with negative scores representing outliers and positive scores representing inliers. The algorithm fits the input samples and returns labels for inliers and outliers. Metadata routing and parameter settings are available for customization. A random forest regressor is a meta estimator that fits decision tree regressors on sub-samples of the dataset to improve predictive accuracy and control over-fitting. The number of trees in the forest can be specified, and different criteria can be used to measure the quality of a split, such as mean squared error or mean absolute error. Parameters like the maximum depth of the tree, minimum number of samples required to split a node, and number of features to consider can be adjusted. The forest can be grown with a specified number of leaf nodes and bootstrap samples can be used. Out-of-bag samples can be used to estimate the generalization score. The regressor can be parallelized over multiple jobs and the verbosity level can be controlled. Minimal Cost-Complexity Pruning can be applied to control the complexity of the trees. The forest can be built from the training set, and the predicted regression target for a sample is the mean predicted regression targets of the trees in the forest. The coefficient of determination (R^2) can be calculated to evaluate the prediction. The impurity-based feature importances can be obtained, and the forest can be applied to new data to return leaf indices or decision paths. The forest can also provide information on the samples used for fitting, as well as metadata routing and parameter settings. The StackingClassifier is a method that combines the output of individual estimators and uses a final classifier to make predictions. It allows for the strengths of each individual estimator to be utilized by using their output as input for the final estimator. The base estimators are fitted on the full dataset, while the final estimator is trained using cross-validated predictions of the base estimators. The default classifier used is LogisticRegression. The cross-validation splitting strategy used can be specified with the cv parameter. The 'prefit' option was added in version 1.1. The number of splits for cross-validation should be chosen carefully to avoid overfitting. The method used by each base estimator can be specified, and the number of jobs to run in parallel can be set. When False, only the predictions of estimators are used as training data for the final estimator, while when True, the final estimator is trained on both predictions and original training data. The StackingClassifier also supports predict_proba and decision_function methods for each estimator. The class labels and feature names seen during fit are accessible, and the final predictions are made using the output of the estimators. The StackingClassifier also supports metadata routing for sample weights and output formats. The Soft Voting/Majority Rule classifier is a method for combining predictions from multiple unfitted estimators. It fits clones of the original estimators and stores them in the self.estimators_ attribute. The 'drop' parameter can be used to remove an estimator. The 'hard' option uses predicted class labels for majority rule voting, while the 'soft' option predicts the class label based on the argmax of the sums of predicted probabilities. Weights can be assigned to predicted class labels or class probabilities. The fit method trains the estimators using training vectors and target values. The transform method returns transformed arrays. Metadata routing can be used to pass metadata to the fit and score methods. The set_params method can be used to set parameters of the estimators. The predict method returns class labels or probabilities for each estimator. The score method calculates the mean accuracy on test data. The set_output method configures the output container. An AdaBoost regressor is a meta-estimator that fits a regressor on the original dataset and then fits additional copies of the regressor on the same dataset with adjusted weights based on prediction errors. The AdaBoost.R2 algorithm is implemented in this class. The base estimator is DecisionTreeRegressor if not specified. The boosting process stops when the maximum number of estimators is reached. The learning rate and number of estimators have a trade-off. The loss function, random seed, and bootstrap weights can be controlled. The ensemble consists of fitted sub-estimators with weights and regression errors. Feature importances are calculated based on impurity and total reduction of the criterion. The predicted regression value is the weighted median prediction of the regressors. The coefficient of determination (R^2) is used to evaluate the prediction. Metadata routing can be enabled for fit and score methods. Staged predictions and scores can be returned after each boosting iteration. A Bagging regressor is an ensemble meta-estimator that fits base regressors on random subsets of the original dataset and aggregates their predictions to form a final prediction. This method can be used to reduce the variance of a black-box estimator by introducing randomization into its construction procedure. Different variations of this algorithm include Pasting, Bagging, Random Subspaces, and Random Patches, depending on how subsets are drawn. The number of base estimators, samples, and features to draw, as well as options for sampling with or without replacement, can be specified. Out-of-bag samples can be used to estimate generalization error. The ensemble can be grown by reusing the previous solution or fitting a new ensemble. The base estimator is typically a DecisionTreeRegressor. The algorithm supports parallel processing and random resampling of the dataset. The fitted ensemble includes sub-estimators, drawn samples, and features for each base estimator. The training dataset's score can be estimated using an out-of-bag estimate. The predicted regression target is the mean of the estimators' predictions. The coefficient of determination (R^2) can be calculated to evaluate the prediction. Metadata routing can be enabled to pass additional information to the fit and score methods. The Extra-Trees Regressor is a meta estimator that fits randomized decision trees on sub-samples of the dataset to improve predictive accuracy and control over-fitting. It allows for the selection of different criteria for measuring the quality of a split, such as mean squared error, mean absolute error, and Poisson deviance reduction. The number of trees in the forest can be specified, as well as parameters like maximum depth, minimum samples required for splitting, and minimum samples required at a leaf node. The function also allows for controlling the number of features considered for the best split, the use of bootstrap samples, and the estimation of generalization score using out-of-bag samples. Additionally, it supports parallel processing, controls randomness, and provides feature importances. The regressor can handle multioutput regressions and data with missing values. It also offers options for metadata routing, parameter setting, and scoring. The default values for tree size parameters should be adjusted to control memory consumption. References to the original paper on Extremely Randomized Trees by Geurts, Ernst, and Wehenkel are provided for further reading. Gradient Boosting is a powerful algorithm for regression that builds an additive model in a forward stage-wise fashion, optimizing arbitrary differentiable loss functions. The sklearn.ensemble.HistGradientBoostingRegressor is a faster variant for intermediate datasets. Different loss functions like 'squared_error', 'absolute_error', 'huber', and 'quantile' can be optimized. Parameters like learning rate, number of boosting stages, subsample fraction, split quality measure, minimum samples required for splitting and leaf nodes, maximum depth, and feature considerations can be tuned for better performance. Other options include setting initial predictions, controlling random seed, early stopping, feature importances, and monitoring progress. The algorithm fits the model, predicts regression targets, calculates the coefficient of determination, and allows for monitoring after each stage. Additional features like metadata routing and setting parameters are also available for customization. References to relevant literature and additional notes on feature importance and early stopping are provided for further understanding. The Histogram-based Gradient Boosting Regression Tree estimator is a faster alternative to GradientBoostingRegressor for large datasets with native support for missing values. During training, the tree grower learns how to handle missing values at each split point based on potential gain. The loss function options include \"squared error\", \"gamma\", \"poisson\", and \"quantile\". Other parameters include the learning rate, maximum number of iterations, maximum number of leaves, maximum tree depth, minimum samples per leaf, L2 regularization, feature subsampling, maximum number of bins, categorical features handling, monotonic constraints, interaction constraints, early stopping, scoring parameter, validation data, tolerance, verbosity level, random number generator, number of iterations, and more. The estimator fits a number of decision tree regressors on various sub-samples of the dataset and uses averaging to improve performance and control overfitting. The coefficient of determination \\(R^2\\) is used to evaluate the prediction. Additional methods include getting metadata routing, getting parameters, predicting values, scoring, setting parameters, and predicting regression target for each iteration. A random forest classifier is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset to improve predictive accuracy and control over-fitting. The trees in the forest use the best split strategy, and the sub-sample size is controlled with the max_samples parameter. The number of trees in the forest can be specified, and the function to measure the quality of a split can be selected from supported criteria. Other parameters include the maximum depth of the tree, the minimum number of samples required to split an internal node, the minimum number of samples required to be at a leaf node, and the minimum weighted fraction of the sum total of weights required to be at a leaf node. The number of features to consider when looking for the best split can also be specified. Additionally, the random forest classifier supports various options such as controlling the verbosity, using out-of-bag samples to estimate the generalization score, and setting the number of jobs to run in parallel. The classifier also allows for setting weights associated with classes, controlling the complexity parameter used for Minimal Cost-Complexity Pruning, and specifying the number of samples to draw from X to train each base estimator. Other features include constraints for monotonic increase or decrease, support for multiclass and multioutput classifications, and the ability to obtain impurity-based feature importances. The classifier can predict class labels, class log-probabilities, and class probabilities for input samples, as well as calculate the mean accuracy on test data. Additional functionalities include applying trees in the forest to input samples, returning leaf indices, decision paths, and node indicator matrices, as well as obtaining the subset of drawn samples for each base estimator. The random forest classifier also provides methods for obtaining metadata routing, getting and setting parameters, and requesting metadata for the fit and score methods. The random forest algorithm is an ensemble of totally random trees that transform a dataset into a high-dimensional sparse representation. Each data point is coded based on the leaf of each tree it is sorted into, resulting in a binary coding with as many ones as there are trees in the forest. The dimensionality of the representation is determined by the number of trees in the forest. The algorithm allows for specifying the number of trees in the forest, the maximum depth of each tree, the minimum number of samples required to split an internal node, and the minimum number of samples required to be at a leaf node. It also includes parameters for controlling the impurity-based feature importances, the number of jobs to run in parallel, and the generation of random values for fitting the trees. Additionally, the algorithm provides methods for fitting the estimator, transforming the dataset, returning leaf indices, decision paths, and node indicator matrices, as well as getting output feature names and metadata routing information. The algorithm supports different output formats such as default, pandas, and polars, and allows for setting and getting parameters of the estimator. The StackingRegressor is a method that combines the output of individual estimators to make a final prediction. It allows for the strengths of each individual estimator to be utilized by using their output as input for a final estimator. The base estimators are fitted on the full dataset, while the final estimator is trained using cross-validated predictions from the base estimators. The default regressor used is a RidgeCV. The cross-validation splitting strategy can be specified using the cv parameter. The number of jobs to run in parallel can be set, and the verbosity level can be adjusted. The method used by each base estimator can be specified. The coefficient of determination (R^2) is used to evaluate the prediction performance. The StackingRegressor also provides methods to access fitted sub-estimators, get parameter information, predict target values, and set output containers. Additionally, metadata routing options are available for passing metadata to the fit and score methods. The StackingRegressor is a powerful tool for combining multiple estimators to improve prediction accuracy. ",
    "sklearn.exceptions": "The functions include custom warnings for capturing convergence problems, notifying potential issues with data dimensionality, handling errors while fitting the estimator, raising exceptions if the estimator is used before fitting, notifying implicit data conversions, warning about inefficient computation, handling inconsistent versions when unpickling an estimator, and invalid metric warnings. These functions were moved from different modules in version 0.18 for better organization and maintenance. ",
    "sklearn.experimental": "",
    "sklearn.feature_extraction": "The DictVectorizer class transforms lists of feature-value mappings into vectors for use with scikit-learn estimators. It can handle categorical features represented as strings, sequences, or sets of strings. When feature values are strings, it performs binary one-hot encoding. If feature values are numeric, it can be followed by OneHotEncoder for binary one-hot encoding. Features not present in a sample will have a zero value. The transformer can handle multiple string values for one categorical feature. It always produces 2-d feature vectors. The inverse_transform method can transform arrays back to feature mappings. The set_output method configures the output format of the transformer. The set_params method allows for setting parameters of the estimator. The transform method converts feature-value dictionaries to arrays or sparse matrices, ignoring features not encountered during fitting. The FeatureHasher class implements feature hashing, also known as the hashing trick, to convert sequences of symbolic feature names into scipy.sparse matrices using a hash function. This class is a memory-efficient alternative to DictVectorizer and CountVectorizer, suitable for large-scale learning and situations with limited memory. It is recommended to use fit_transform instead of transform for parameter validation. The input must be an iterable over iterables of strings when input_type is set to \"string\". The estimator is stateless and does not require fitting. The method allows for parameter validation and consistency with the scikit-learn transformer API. The transform method converts a sequence of instances into a scipy.sparse matrix for use with estimators or further transformers. The set_output API allows for configuring the output format of transform and fit_transform, with options including \"default\", \"pandas\", \"polars\", or None. The set_params method can be used to set the parameters of the estimator, including nested objects. Metadata routing can be requested for the transform method if enable_metadata_routing is set to True, allowing for passing metadata to the meta-estimator with a given alias. This method is only relevant when the estimator is used as a sub-estimator of a meta-estimator, such as inside a Pipeline. The function extracts patches from a collection of images, with options to specify patch size, number of patches, and random sampling. It does not need to be fitted but can be fit to data and transformed. The function also allows for setting output containers and parameters, as well as transforming image samples into patch data. Additionally, it can generate a graph of pixel-to-pixel connections based on the extracted patches, with options for dimensions and masks. The function returns the collection of patches extracted from the images and the computed adjacency matrix. The functions provided include reconstructing an image from overlapping patches, reshaping a 2D image into patches, extracting patches from an image, and creating a graph of pixel-to-pixel gradient connections. The reconstruction function fills in patches from left to right, top to bottom, averaging overlapping regions. The reshape function allocates patches in a dedicated array, with options for color channels. The extraction function allows for specifying the number of patches to extract, with options for random sampling. The graph function creates a graph of pixel-to-pixel gradient connections, with options for masking and specifying the class for the adjacency matrix. The function described allows for the conversion of a collection of text documents into a matrix of token counts. It provides options for sparse representation, feature selection, character normalization, lowercase conversion, stop word removal, n-grams generation, vocabulary building, and more. The function also supports different types of encodings, tokenization methods, and document frequency thresholds. Additionally, it offers features for handling metadata, parameter setting, and metadata routing. The function can preprocess text, tokenize it, generate n-grams, and decode it into unicode symbols. Overall, it is a comprehensive tool for text analysis and feature extraction. The function described is used to transform a count matrix into a normalized tf or tf-idf representation. Tf stands for term-frequency and tf-idf stands for term-frequency times inverse document-frequency. This weighting scheme is commonly used in information retrieval and document classification. The goal is to scale down the impact of frequently occurring tokens in a corpus to focus on more informative features. The formula used to compute tf-idf involves term frequency, document frequency, and inverse document frequency. Different parameter settings correspond to the SMART notation used in information retrieval. The function also allows for normalization, inverse-document-frequency reweighting, and sublinear tf scaling. Additionally, the function provides the option to learn the idf vector, fit the transformer to data, get output feature names, set output container, and request metadata routing. It also includes options for setting parameters, copying data, and transforming a count matrix to a tf or tf-idf representation. The HashingVectorizer function converts a collection of text documents into a matrix of token occurrences using the hashing trick. This implementation is memory scalable, fast to pickle and unpickle, and can be used in streaming or parallel pipelines. However, it does not support inverse transform, may have collisions, and does not use IDF weighting. The hash function used is the signed 32-bit version of Murmurhash3. Various parameters can be set such as encoding, character normalization, lowercase conversion, stop words removal, tokenization, n-grams generation, and feature normalization. The function can handle different types of input data and return a callable to process input data. It is stateless and does not need to be fitted, but it is recommended to call fit_transform for parameter validation. The function also provides methods to get metadata routing, parameters, stop words list, and set output container. Additionally, it allows for setting and updating parameters of the estimator. ",
    "sklearn.feature_selection": "The Univariate feature selector is a configurable strategy that can be used for feature selection. It takes two arrays, X and y, and returns scores and p-values. It supports different modes such as 'percentile' and 'kbest' for feature selection. The feature selection can be supervised or unsupervised. It can select features based on various criteria such as F-value, mutual information, false positive rate, false discovery rate, and family-wise error rate. The selector can be fit to data and transformed. It can also mask feature names according to selected features. The routing mechanism and parameters of the estimator can be accessed. The selected features can be obtained as a mask or integer index. The transformation operation can be reversed. The output format of the transformation can be configured. The parameters of the estimator can be set. Finally, the input samples can be reduced to only include the selected features. The Recursive Feature Elimination with Cross-Validation (RFECV) function automatically selects features by fitting an RFE selector on different cross-validation splits. The performance of the RFE selector is evaluated using a scorer for varying numbers of selected features and aggregated together. The scores are then averaged across folds, and the number of features selected is set to maximize the cross-validation score. The function allows for tuning the number of features to remove at each iteration, as well as specifying the minimum number of features to be selected. It also provides options for determining the cross-validation splitting strategy and controlling the verbosity of output. The function can handle NaN/Inf values in the input and references a study on gene selection for cancer classification using support vector machines. Additionally, it includes methods for computing decision functions, fitting the RFE model, transforming input samples, predicting target values, and more. The function also allows for metadata routing and configuring the output format of the transformation. The Filter function allows for selecting p-values below a specified alpha based on a False Positive Rate test, controlling false detections. It works with classification tasks and returns scores, p-values, number of features seen during fit, and feature names. Features can be selected based on various criteria such as F-value, mutual information, percentile of highest scores, or k highest scores. The function can be run on input samples and target values, with the option for unsupervised transformations. It also allows for masking feature names, getting metadata routing, retrieving parameters, getting a mask of selected features, reversing transformations, setting output format, setting parameters, and reducing input samples to selected features. The Filter function allows for the selection of p-values corresponding to the Family-wise error rate. It takes two arrays X and y as input and returns a pair of arrays (scores, pvalues). The default function, f_classif, works with classification tasks and provides the highest uncorrected p-value for features to keep, scores of features, p-values of feature scores, number of features seen during fit, and names of features seen during fit. Additional features include selecting features based on percentile or the k highest scores, false positive rate test, estimated false discovery rate, and configurable mode. The function also allows for running score function on (X, y) and getting the appropriate features, fitting transformer to X and y, masking feature names according to selected features, getting metadata routing, parameters for the estimator, a mask or integer index of the selected features, reversing the transformation operation, setting output container, configuring output of transform and fit_transform, setting the parameters of the estimator, and reducing X to the selected features. The SelectPercentile function selects features based on a percentile of the highest scores, with options for classification and regression tasks. It returns scores, p-values, and other relevant information. The SelectKBest function selects features based on the k highest scores. Other functions include SelectFpr, SelectFdr, and SelectFwe, which select features based on false positive rate, false discovery rate, and family-wise error rate, respectively. The SelectFromModel function is a univariate feature selector with configurable mode. Ties between features with equal scores are broken in an unspecified way. These functions support unsupervised feature selection and can be used to run score functions on input samples. The fit_transform method fits a transformer to input samples and target values, with optional parameters. The get_support method returns a mask or integer index of the selected features. The reverse_transform method reverses the transformation operation. The set_params method allows for setting the parameters of an estimator. Finally, the transform method reduces input samples to the selected features. The Sequential Feature Selector is a transformer that performs feature selection by adding or removing features in a greedy fashion based on cross-validation scores. It can be used for unsupervised learning and allows for forward or backward selection. The estimator's behavior can be controlled by parameters such as \"tol\" and \"n_features_to_select\". The cross-validation splitting strategy can be specified using the \"cv\" parameter. The number of jobs to run in parallel during evaluation can also be set. The transformer keeps track of the number of features seen during fit and the names of features. It supports recursive feature elimination and feature selection based on importance weights. The transformer can fit to data and transform it, returning the transformed array. It can also mask feature names according to selected features. The transformer does not support metadata routing yet. Parameters can be retrieved and set using specific methods. The selected features can be obtained as a mask or integer index. The transformation operation can be reversed, and the output container can be configured. The transformer can be used to reduce X to only the selected features. The functions provided include computing chi-squared statistics between non-negative features and classes, performing univariate linear regression tests returning F-statistic and p-values, and selecting features based on various criteria such as highest scores, false positive rate test, false discovery rate, family-wise error rate, and percentile of the highest scores. These functions are useful for feature selection in classification and regression tasks, helping to identify the most relevant features for predictive modeling. Additionally, the functions handle cases where F-statistics may not be finite due to constant target values or perfectly correlated features. Overall, these functions offer a comprehensive approach to feature selection and model building. The function estimates mutual information for a continuous target variable, which is a non-negative value that measures the dependency between two random variables. It relies on nonparametric methods based on entropy estimation from k-nearest neighbors distances. This can be used for univariate feature selection. The function takes in a feature matrix, target vector, and parameters such as whether to consider features as discrete or continuous, the number of neighbors to use for estimation, and whether to make a copy of the data. It also allows for adding small noise to continuous variables for removing repeated values. The number of jobs for computing mutual information can be specified for parallelization. The estimated mutual information between each feature and the target is provided in nat units. It is important to note that treating continuous variables as discrete and vice versa can lead to incorrect results. Negative estimates of mutual information are replaced by zero. References to relevant literature are provided for further reading. Recursive Feature Elimination (RFE) is a feature ranking method that aims to select the most important features by recursively considering smaller and smaller sets of features. It works by training an external estimator on the initial set of features and then pruning the least important features from the current set. This process is repeated until the desired number of features to select is reached. RFE can be used with a supervised learning estimator that provides information about feature importance, such as coef_ or feature_importances_. The number of features to select can be specified as an absolute number, a fraction, or a percentage. RFE also allows for controlling the verbosity of output and specifying custom feature importance getters. Additionally, RFE provides feature ranking, a mask of selected features, and the ability to compute the decision function, predict target values, and score the estimator based on the selected features. The RFE model can be fitted and transformed using input samples and target values, and the selected features can be masked or reversed. The output format of the transformer can be configured, and the parameters of the estimator can be set or retrieved. Overall, RFE is a versatile feature selection method that can be used for various machine learning tasks. The Filter function allows for the selection of p-values based on an estimated false discovery rate using the Benjamini-Hochberg procedure. It takes two arrays, X and y, and returns scores and p-values. The function works with classification tasks and can keep features based on the highest uncorrected p-value. Other options include selecting features based on percentiles, the k highest scores, false positive rate tests, or family-wise error rate. The function also includes a univariate feature selector with configurable modes. Additionally, it provides methods for fitting and transforming data, masking feature names, getting metadata routing, retrieving parameters, getting a mask of selected features, reversing transformations, setting output containers, configuring output formats, setting parameters, and reducing X to selected features. The SelectFromModel meta-transformer is used for selecting features based on importance weights. It can be built from a base estimator and allows for setting a threshold value for feature selection. The maximum number of features to select can also be specified. The meta-transformer can be fitted with the fit method and transformed with the transform method. It also allows for routing metadata and setting output containers. Additionally, it provides methods for getting parameters, setting parameters, and reversing the transformation operation. The SelectFromModel meta-transformer is a versatile tool for feature selection based on importance weights. The SelectKBest function allows for selecting features based on the k highest scores, with options for different score functions such as f_classif, ANOVA F-value, mutual information, and more. It also provides the ability to select features based on percentiles, false positive rate tests, false discovery rates, and family-wise error rates. The function supports unsupervised feature selection and can be used for both classification and regression tasks. Additionally, it allows for transforming input samples by fitting the transformer to X and y, with options for additional fit parameters. The function also provides methods for masking feature names, getting metadata routing information, retrieving parameters for the estimator, getting a mask or integer index of selected features, reversing the transformation operation, setting output containers, configuring output formats, setting parameters of the estimator, and reducing X to only the selected features. The Transformer mixin provides feature selection functionality with methods for fitting to data, transforming it, and inversely transforming it. It includes options for specifying input features, getting a mask or index of selected features, and configuring the output format. Additionally, it allows for reducing input samples to only the selected features. The mixin is versatile and can be used for various feature selection tasks. The feature selector function removes low-variance features, focusing on the features (X) rather than the desired outputs (y), making it suitable for unsupervised learning. It removes features with training-set variance below a specified threshold, defaulting to keeping features with non-zero variance. It can handle NaN values and raises an error if no feature meets the variance threshold. The function can learn empirical variances from the input data and transform it accordingly. It can also mask feature names based on selected features and provide metadata routing information. Additionally, it allows for setting output containers and configuring output formats. The function can retrieve parameters, get a mask of selected features, and reverse the transformation operation if needed. It can also set parameters and reduce the input data to only the selected features. The function computes the ANOVA F-value for a provided sample, testing a set of regressors sequentially with the target vector. It also calculates the F-statistic and associated p-values for each feature. Additionally, it estimates the mutual information between a discrete target variable and features, measuring the dependency between variables. The function relies on nonparametric methods based on entropy estimation from k-nearest neighbors distances. It can be used for univariate feature selection, considering features as discrete or continuous. The number of neighbors used for MI estimation affects the variance and bias. The function allows for making a copy of the data, determining random number generation for adding noise, and specifying the number of jobs for computing mutual information. The estimated mutual information between each feature and the target is provided in nat units. It is important to note that treating continuous variables as discrete or vice versa may lead to incorrect results, and true mutual information cannot be negative. References for the function include Wikipedia and various research papers on mutual information estimation. ",
    "sklearn.gaussian_process": "The Gaussian process classification (GPC) based on Laplace approximation is implemented using Algorithm 3.1, 3.2, and 5.1 from [RW2006]. It approximates the non-Gaussian posterior by a Gaussian and is currently limited to using the logistic link function. For multi-class classification, binary one-versus-rest classifiers are fitted. The kernel specifying the covariance function of the GP can be customized, with hyperparameters optimized during fitting. Various optimizers can be used for optimizing the kernel's parameters. The number of restarts of the optimizer and the maximum number of iterations in Newton's method can be specified. The handling of multi-class classification problems can be set to 'one_vs_rest' or 'one_vs_one'. The number of jobs for computation can also be specified. The model can be fit with training data and target values, and predictions can be made on test data. Probability estimates and accuracy metrics can be obtained. The parameters of the estimator can be set and metadata routing can be requested. Gaussian process regression (GPR) is implemented based on Algorithm 2.1 of [RW2006]. The GaussianProcessRegressor allows prediction without prior fitting and provides methods for sampling from the GPR at given inputs. It also exposes a method for log marginal likelihood evaluation. The kernel specifying the covariance function of the GP can be customized, with options for noise level specification and optimizer selection. The model can normalize target values and store a persistent copy of the training data. The predict method can be used with an unfitted model based on the GP prior. Additionally, the model provides methods for drawing samples from the GP, evaluating the coefficient of determination, and setting parameters. Metadata routing options are available for predict and score methods. The Kernel function is a compound kernel composed of a set of other kernels, added in version 0.18. It returns the kernel k(X, Y) and optionally its gradient, stacking all simple kernels along an additional axis. The left and right arguments of the returned kernel are specified. It can compute the gradient with respect to the log of the kernel hyperparameter and return the log-transformed bounds on the hyperparameters theta. It can also clone itself with given hyperparameters, return the diagonal of the kernel k(X, X), and get parameters of the kernel. Additionally, it can provide information on hyperparameter specifications, whether the kernel is stationary, the number of non-fixed hyperparameters, whether it is defined on discrete structures, and set the parameters of the kernel. The non-fixed, log-transformed hyperparameters of the kernel are also returned. The DotProduct kernel is a non-stationary kernel that can be obtained from linear regression by putting priors on the coefficients and bias. It is invariant to rotation but not translations, and is parameterized by sigma_0 which controls the inhomogeneity of the kernel. The kernel can be combined with exponentiation and its details can be found in the User Guide. It was added in version 0.18 and has a parameter controlling its inhomogeneity. The kernel can return the kernel value, its gradient, diagonal, parameters, hyperparameter specifications, whether it is stationary, the number of non-fixed hyperparameters, and whether it is defined on fixed-length feature vectors. The kernel's hyperparameters can be set, returned, or cloned, and the non-fixed hyperparameters are log-transformed for hyperparameter search. The Exponentiation kernel combines a base kernel with a scalar parameter \\(p\\). It overrides the __pow__ magic method, allowing for operations like Exponentiation(RBF(), 2) to be equivalent to RBF() ** 2. This kernel can return the kernel function \\(k(X, Y)\\) and its gradient, with options to evaluate different arguments. It can compute the gradient with respect to the log of the kernel hyperparameter and return log-transformed bounds on the hyperparameters. Additionally, it can provide a clone with specified hyperparameters, the diagonal of the kernel function, and information on the number of non-fixed hyperparameters. The kernel can also be set with new parameters and return the non-fixed, log-transformed hyperparameters for hyperparameter search. The Base class for all kernels was added in version 0.18. It allows for the evaluation of the kernel and returns the log-transformed bounds on the hyperparameters theta. It also provides methods to clone the kernel with given hyperparameters, get the diagonal of the kernel, get parameters of the kernel, check if the kernel is stationary, get the number of non-fixed hyperparameters, check if the kernel is defined on fixed-length feature vectors, set the parameters of the kernel, and retrieve the non-fixed, log-transformed hyperparameters. This class is versatile and efficient for working with kernel functions. The function is a wrapper for kernels in sklearn.metrics.pairwise, providing a thin wrapper around the functionality of the kernels in sklearn.metrics.pairwise. It supports only isotropic distances, with the parameter gamma considered a hyperparameter that may be optimized. The other kernel parameters are set directly at initialization and kept fixed. The function calculates the kernel between instances in a feature array, with options for different metrics and the ability to return the kernel and its gradient. It also allows for setting and getting parameters of the kernel, checking if it is stationary, and determining the number of non-fixed hyperparameters. Additionally, it provides methods for cloning the kernel with given hyperparameters, setting parameters, and returning the non-fixed, log-transformed hyperparameters. The Radial Basis Function (RBF) kernel, also known as the squared-exponential kernel, is a stationary kernel parameterized by a length scale parameter. This kernel is infinitely differentiable, resulting in Gaussian Processes with smooth mean square derivatives of all orders. The length scale parameter can be set as a scalar for isotropic kernel or as a vector for anisotropic kernel. The RBF kernel is defined by the Euclidean distance and can be used for hyperparameter tuning. It is included in version 0.18 and is detailed in Chapter 4, Section 4.2 of the User Guide. The kernel can return the kernel value, its gradient, diagonal, parameters, hyperparameter specifications, and more. It is suitable for fixed-length feature vectors and can be customized with different hyperparameters. The non-fixed, log-transformed hyperparameters are used for hyperparameter search. The Sum kernel combines two kernels \\(k_1\\) and \\(k_2\\) by overriding the __add__ magic method. This allows for operations like Sum(RBF(), RBF()) which is equivalent to RBF() + RBF(). The kernel can return the result of \\(k(X, Y)\\) and its gradient, with options to evaluate the gradient with respect to the log of the hyperparameter. It also provides methods to return the diagonal of the kernel, clone the kernel with given hyperparameters, get parameters, check if the kernel is stationary, and set parameters. Additionally, it offers functionality to return hyperparameters, check the number of non-fixed hyperparameters, and retrieve the non-fixed, log-transformed hyperparameters of the kernel. The Constant kernel is a versatile function that can be used as part of a product-kernel or a sum-kernel in a Gaussian process. It scales the magnitude of the other factor or modifies the mean of the process. It is equivalent to adding a constant value to the covariance. The constant value can have lower and upper bounds, and can be fixed during hyperparameter tuning. The kernel can return its value, gradient, diagonal, and parameters. It can also determine if it is stationary, the number of non-fixed hyperparameters, and if it works only on fixed-length feature vectors. The kernel's hyperparameters can be set, updated, and returned in log-transformed form for hyperparameter search. The Exp-Sine-Squared kernel, also known as the periodic kernel, allows modeling functions that repeat themselves exactly. It is parameterized by a length scale parameter \\(l>0\\) and a periodicity parameter \\(p>0\\). The kernel is given by a specific formula involving the Euclidean distance. The length scale and periodicity of the kernel can be adjusted within certain bounds, and there is an option to fix these parameters during hyperparameter tuning. The kernel can return the kernel value, its gradient, diagonal elements, and other information. It is possible to get and set the parameters of the kernel, including non-fixed hyperparameters. The kernel can also provide information about its stationary nature, the number of non-fixed hyperparameters, and whether it is defined on fixed-length feature vectors or generic objects. The hyperparameters are typically log-transformed for better hyperparameter search. The function provides a kernel hyperparameter's specification in the form of a namedtuple. It includes the name of the hyperparameter, the type (currently only supporting numeric), lower and upper bounds, number of elements, and whether the value is fixed. The function allows access to each hyperparameter and provides methods to return the number of occurrences of a value and the first index of a value. The Matern kernel is a generalization of the RBF kernel with an additional parameter \\(\\nu\\) that controls the smoothness of the function. Different values of \\(\\nu\\) correspond to different levels of differentiability, with \\(\\nu = 1/2\\) being equivalent to the absolute exponential kernel, \\(\\nu = 1.5\\) for once differentiable functions, and \\(\\nu = 2.5\\) for twice differentiable functions. The kernel formula involves Euclidean distance, modified Bessel functions, and the gamma function. The length scale of the kernel can be isotropic or anisotropic, with options for fixed bounds. The parameter \\(\\nu\\) is crucial for determining the smoothness of the function, with values outside specific ranges incurring higher computational costs. References for further details are available. The kernel can return values, gradients, bounds, clones, diagonals, parameters, and information on stationarity and hyperparameters. The method allows for setting and updating parameters, as well as retrieving non-fixed hyperparameters in a log-transformed format for hyperparameter search. The Product kernel in version 0.18 takes two base kernels \\(k_1\\) and \\(k_2\\) and combines them. It overrides the __mul__ magic method, allowing for operations like RBF() * RBF(). The kernel can return the result of the combined base kernels, optionally with its gradient. It can also compute the gradient with respect to the log of the hyperparameters and return the log-transformed bounds on the hyperparameters. The kernel can provide a clone with given hyperparameters, return the diagonal of the kernel, and get parameters of the kernel. It can check if the kernel is stationary, return the number of non-fixed hyperparameters, and set the parameters of the kernel. Additionally, it can return the non-fixed, log-transformed hyperparameters for hyperparameter search. The RationalQuadratic kernel is a scale mixture of RBF kernels with different characteristic length scales, parameterized by a length scale parameter \\(l>0\\) and a scale mixture parameter \\(\\alpha>0\\). It supports only the isotropic variant where the length scale \\(l\\) is a scalar. The kernel is defined by an infinite sum of RBF kernels with different characteristic length scales. The lower and upper bounds on the length scale and scale mixture parameters can be set to \"fixed\" to prevent changes during hyperparameter tuning. The kernel can return the kernel matrix \\(k(X, Y)\\) and its gradient, as well as the diagonal of the kernel matrix \\(k(X, X)\\). It is possible to set and get the parameters of the kernel, including the non-fixed, log-transformed hyperparameters. The kernel can also provide information on whether it is stationary, the number of non-fixed hyperparameters, and whether it is defined on fixed-length feature vectors or generic objects. The User Guide provides advice on setting the parameters of the RationalQuadratic kernel. ",
    "sklearn.impute": "The Multivariate Imputer is a strategy for imputing missing values by modeling each feature with missing values as a function of other features in a round-robin fashion. It is still experimental and may undergo changes. To use it, enable_iterative_imputer needs to be explicitly imported. The imputer can sample from the predictive posterior of the fitted estimator for each imputation and perform multiple imputations. It has parameters for controlling the number of imputation rounds, tolerance for stopping criteria, and the strategy for initializing missing values. The order in which features are imputed can be specified, and features with no missing values can be skipped during transform. The imputer can handle minimum and maximum possible imputed values, verbosity, and random state. It also supports a MissingIndicator transform and can return features with exclusively missing values. The imputer can be fitted on data and transformed to impute missing values. It scales in complexity with the number of samples, features, and max iterations. The imputer can be used in inductive mode and references the mice and Buck methods for imputation. It can be fit on data and return the transformed data, with options for setting output format. The imputer can also provide metadata routing information and parameters for the estimator. It supports setting output containers and configuring output formats. The imputer can impute all missing values in the input data in a stochastic manner. The MissingIndicator function is used to generate binary indicators for missing values in a dataset. It can be added to a Pipeline using FeatureUnion or ColumnTransformer. The missing_values parameter specifies the placeholder for missing values, with np.nan recommended for pandas dataframes with nullable integer dtypes. The function can represent all features or only those with missing values, and the mask format can be sparse or dense. During fitting, the function computes feature indices and can raise an error if there are missing values in features not seen during fit. The function also provides information on the number and names of features seen during fit. Additionally, it offers methods to fit the transformer, generate missing value indicators, get output feature names, and set output container. The function can be used to impute missing values and works with both simple estimators and nested objects. The output format can be configured as \"default\", \"pandas\", \"polars\", or None. The KNNImputer function is used for imputing missing values by using the mean value from the nearest neighbors found in the training set. It allows for specifying the number of neighboring samples to use for imputation, the weight function used in prediction, and the distance metric for searching neighbors. Additionally, it provides options for handling missing values, adding binary indicators for missing values, and outputting feature names. The function fits the imputer on the input data and can transform it as well. It also allows for setting parameters, configuring output format, and imputing all missing values in the dataset. The function is a part of scikit-learn and is based on the work of Olga Troyanskaya et al. (2001) on missing value estimation methods for DNA microarrays. ",
    "sklearn.inspection": "Partial dependence of features is a method that corresponds to the average response of an estimator for each possible value of a feature or set of features. It is important to note that for GradientBoostingClassifier and GradientBoostingRegressor, the 'recursion' method may not account for the init predictor of the boosting process, and it is recommended to use the 'brute' method instead. This method is supported for some tree-based estimators and is more efficient in terms of speed. The method used to calculate the averaged predictions can be 'recursion', 'brute', or 'auto', with 'brute' being more computationally intensive. The summary can be averaged across all samples in the dataset or one value per sample, depending on the parameters used. The results can be visualized using the Partial Dependence visualization. Permutation importance for feature evaluation is a method used to evaluate the importance of features in a dataset. It requires a fitted estimator and can be applied to the data set used to train the estimator or a hold-out set. The process involves calculating the difference between a baseline metric and the metric obtained after permutating a feature column. The estimator must be compatible with a scorer, and the permutation importance can be computed for supervised targets or None for unsupervised. The number of times to permute a feature, the number of jobs to run in parallel, and a pseudo-random number generator can be specified. Additionally, sample weights, the number of samples to draw from the data set, and a dictionary-like object with attributes such as mean feature importance and standard deviation can be provided. This method allows for controlling the computational speed versus statistical accuracy trade-off. References to the original work by L. Breiman on Random Forests are also included. The Decision Boundary Visualization function allows for the creation of a visual representation of decision boundaries based on a trained estimator. It provides options for customizing the plot, such as the number of grid points to use and the plotting method to call. The function also allows for the selection of the target response method, the class of interest, and the labels for the x and y axes. Additionally, it offers the ability to plot the confusion matrix and provides options for customizing the visualization. This function is a useful tool for understanding and analyzing the performance of machine learning models. ",
    "sklearn.isotonic": "The Isotonic regression model is a non-parametric model that accepts monotonicity constraints. It includes features such as setting lower and upper bounds on predicted values, handling predictions outside the training domain, and interpolating monotonic functions. The model can be fit using training data and weights, with the option to transform the data. Additionally, it provides methods to predict new data, calculate the coefficient of determination, and score the model. Metadata routing can be configured for various parameters, and the output format can be set to default, pandas, or polars. The model also allows for setting and updating parameters, as well as transforming new data through linear interpolation. ",
    "sklearn.kernel_approximation": "The Approximate feature map for additive chi2 kernel is a method that uses sampling the Fourier transform of the kernel characteristic at regular intervals to approximate the additive chi2 kernel. It transforms each entry in the original space into 2*sample_steps-1 features, with typical values of sample_steps being 1, 2, or 3. The method gives the number of (complex) sampling points and the sampling interval, which must be specified when sample_steps is not in {1, 2, 3}. It also provides the number of features seen during fit and the names of features seen during fit when X has feature names that are all strings. This estimator is stateless and does not need to be fitted, but it is recommended to call fit_transform instead of transform. The method allows for validating the estimator's parameters and being consistent with the scikit-learn transformer API. It can fit to data and transform it, returning a transformed version of X. The method also allows for getting output feature names for transformation, metadata routing of the object, parameters for the estimator, setting the output container, setting the parameters of the estimator, and applying the approximate feature map to X. The return value can be an array or sparse matrix depending on the type of the input X. The estimator parameters can work on simple estimators as well as nested objects, allowing for updating each component of a nested object. Additionally, the method allows for configuring the output of transform and fit_transform, with options for \"default\", \"pandas\", \"polars\", or None. The Polynomial kernel approximation via Tensor Sketch function implements Tensor Sketch to approximate the feature map of the polynomial kernel efficiently by computing a Count Sketch of the outer product of a vector with itself using Fast Fourier Transforms (FFT). This function allows for the approximation of the feature map of the polynomial kernel based on parameters such as the degree, constant term, and dimensionality of the output feature space. It also provides options for random number generation and hash function initialization. Additionally, it offers methods for fitting the model with training data, transforming data, getting output feature names, metadata routing, setting output containers, and generating feature map approximations for new data. The function is versatile and can be used for various kernel approximation tasks, including additive chi2 kernel, RBF kernel, and skewed chi-squared kernel. It also provides options for configuring output formats and setting estimator parameters. The function descriptions provided cover the approximate feature map for the \"skewed chi-squared\" kernel, including details on the \"skewedness\" parameter, cross-validation, Monte Carlo samples, random weights and offsets, pseudo-random number generation, weight array sampling, bias term addition, number of features seen during fit, feature names, built-in kernels, fitting the model with training data, transforming data, output feature names, metadata routing, estimator parameters, setting output container, applying the feature map to new data, and more. The functions allow for fitting, transforming, and configuring the output format of the data, with options for different types of output formats such as DataFrame or Polars. The functions also provide flexibility in setting and updating parameters of the estimator, including nested objects within the estimator. Additionally, the functions ensure that all values of the new data must be strictly greater than a specified threshold. The function allows for the approximation of a kernel map using a subset of the training data. It constructs an approximate feature map for an arbitrary kernel using a subset of the data as a basis. The function includes parameters such as gamma for various kernels, degree for polynomial kernels, and additional parameters for the kernel function. It also allows for the control of the number of features to construct and the number of jobs to use for computation. The function fits the estimator to data by sampling a subset of training points, computing the kernel on these points, and computing a normalization matrix. It can also transform the data and output feature names for the transformation. Additionally, the function provides options for setting the output container and parameters of the estimator. It can apply the feature map to new data for transformation. ",
    "sklearn.kernel_ridge": "",
    "sklearn.linear_model": "Logistic Regression (aka logit, MaxEnt) classifier is a versatile algorithm that supports both binary and multiclass classification. It uses different solvers such as 'liblinear', 'newton-cg', 'sag', 'saga', and 'lbfgs' to implement regularized logistic regression. Regularization can be applied with options for L1, L2, or Elastic-Net penalties. The algorithm can handle both dense and sparse input data. The choice of solver depends on the dataset size and the type of problem being solved. The 'multinomial' option is available for certain solvers and allows for multinomial loss minimization. The algorithm also supports class weights, warm start, and parallelization over classes. Additionally, it provides methods for predicting class labels, confidence scores, and probability estimates. The algorithm can be fine-tuned with parameters such as C, intercept scaling, and l1_ratio. Overall, Logistic Regression is a powerful tool for classification tasks with various options for customization and optimization. The Passive Aggressive Classifier is a linear model that can be fit with the Passive Aggressive algorithm. It includes options for setting the maximum step size, intercept estimation, number of passes over the training data, stopping criterion, early stopping, validation set proportion, number of iterations before early stopping, shuffling of training data, loss function selection, number of CPUs to use, class weights, weights averaging, and warm start initialization. The classifier can predict class labels and confidence scores for samples, as well as provide mean accuracy on test data. It also allows for metadata routing, parameter retrieval, and setting, as well as conversion of coefficient matrices between dense and sparse formats. Additionally, it supports partial fitting and updating of parameters. The algorithm is based on Online Passive-Aggressive Algorithms and can be used for linear perceptron classification. The Ridge classifier is a classifier that first converts target values into {-1, 1} and treats the problem as a regression task. It uses regularization to improve the conditioning of the problem and reduce the variance of estimates. The regularization strength can be adjusted with the alpha parameter, which corresponds to 1 / (2C) in other linear models. The classifier can calculate the intercept for the model and has different solvers available, such as 'auto', 'svd', 'cholesky', 'sparse_cg', 'lsqr', 'sag', 'saga', and 'lbfgs'. The 'sag' and 'saga' solvers use Stochastic Average Gradient descent for faster convergence. The classifier also supports sample weights and can predict confidence scores for samples. It can be used for binary, multiclass, and multilabel classification problems. Additionally, the classifier provides methods for fitting the model, predicting class labels, and calculating the mean accuracy on test data. Metadata routing can be enabled for passing additional information to the fit and score methods. The Linear classifiers with SGD training estimator implements regularized linear models using stochastic gradient descent (SGD) learning. It allows for minibatch learning and works with dense or sparse arrays of floating point values. The model can be controlled with parameters such as loss function, penalty, learning rate, and more. The loss function options include linear SVM, logistic regression, smooth loss for outliers, and more. The penalty can be L2, L1, or a combination (Elastic Net). Other parameters include intercept estimation, number of epochs, stopping criterion, shuffling data, and more. Additional options like warm-starting, class weights, and metadata routing are also available. The estimator can be used for predicting class labels, confidence scores, and probability estimates. It also provides methods for converting coefficient matrices between dense and sparse formats. Overall, the estimator offers a flexible and efficient way to train linear models with various options for customization and optimization. The Logistic Regression CV classifier, also known as logit or MaxEnt, implements logistic regression using different optimizers such as liblinear, newton-cg, sag, or lbfgs. It supports both L1 and L2 regularization, with the option for elastic-net penalty. The choice of solver depends on the dataset size and the type of problem, with 'liblinear' being suitable for small datasets and 'sag' and 'saga' for larger ones. The default cross-validation generator is Stratified K-Folds, but this can be customized. The penalty type, solver, and scoring options can be specified, with the default scoring metric being 'accuracy'. The model can handle binary classification by default, but for multiclass problems, specific solvers need to be used. The class_weight parameter allows for adjusting class weights based on class frequencies. The model also supports warm-starting coefficients and can be used with different numbers of CPU cores for parallel processing. The intercept can be included in the decision function, and the model can be refit with the best parameters after cross-validation. The Logistic Regression CV estimator provides methods for predicting class labels, probability estimates, and confidence scores, as well as for converting coefficient matrices between dense and sparse formats. Additionally, metadata routing can be enabled to pass additional information during fitting and scoring. The Linear perceptron classifier is a wrapper around SGDClassifier with fixed loss and learning_rate parameters. Other available parameters are described in the User Guide and forwarded to SGDClassifier. Additional parameters include penalty, regularization term multiplier, Elastic Net mixing parameter, intercept estimation, maximum number of passes over training data, stopping criterion, shuffling of training data, verbosity level, number of CPUs to use, early stopping, class weights, feature weights, loss function, number of features seen during fit, feature names, number of iterations, weight updates, and more. Perceptron is a classification algorithm that shares the same implementation with SGDClassifier. It predicts confidence scores for samples based on the signed distance to the hyperplane. The classifier can be fitted with training data and target values, with options for warm-starting coefficients, sample weights, and class weights. It can predict class labels, calculate mean accuracy, and convert coefficient matrices to dense or sparse formats. Metadata routing can be requested for fit, partial_fit, and score methods. The coef_init, intercept_init, and sample_weight parameters can also have metadata routing. The Ridge classifier is a model that performs Ridge regression with built-in cross-validation. It includes features such as an array of alpha values for regularization strength, the option to calculate the intercept, and the ability to store cross-validation results. The classifier can handle cases where the number of features is greater than the number of samples efficiently. It also supports multi-class classification by training n_class classifiers in a one-versus-all approach. The confidence scores for samples are proportional to the signed distance of the sample to the hyperplane. Additionally, the classifier provides methods for fitting, predicting class labels, and calculating mean accuracy on test data. It also offers options for requesting metadata and setting parameters. The Ridge classifier is a versatile tool for regression and classification tasks, with various options for customization and evaluation. The linear One-Class SVM using Stochastic Gradient Descent is a method for solving the One-Class SVM problem with a kernel approximation technique. It includes parameters such as nu for error and support vector bounds, intercept estimation, maximum number of passes over data, stopping criterion, shuffling of data, and learning rate schedules. Other features include warm-starting, averaging of weights, feature weights, decision function offset, and metadata routing. The estimator has linear complexity and is suitable for large datasets. It provides signed distance to the hyperplane, decision function values, and raw scoring functions for samples. Additionally, it allows for conversion of coefficient matrices between dense and sparse formats. The method returns labels for inliers and outliers, and can be used with metadata routing for parameters. LinearRegression is a function that fits a linear model to minimize the residual sum of squares between observed and predicted targets. It can calculate the intercept, use multiple jobs for computation, and force coefficients to be positive. The function also provides estimated coefficients, rank of the matrix, singular values, and independent term in the linear model. Additionally, it supports Ridge regression, Lasso, and Elastic-Net for regularization. Other features include fitting the model, predicting values, calculating the coefficient of determination, and handling metadata routing. The function can also set parameters, update estimator parameters, and handle metadata routing for sample weights. The Ridge regression function with built-in cross-validation allows for efficient regularization to improve problem conditioning and reduce estimate variance. It includes options for specifying alpha values, intercept calculation, scoring rules, and cross-validation strategies. The function also supports optimizing alpha values separately for each target, storing cross-validation values, and providing weight vectors. Additionally, it offers a classifier based on ridge regression for binary labels and the ability to fit a Ridge regression model with cross-validation. The function can handle sample weights and metadata routing, and provides methods for predicting values, calculating the coefficient of determination, and retrieving parameters. It also allows for setting and updating estimator parameters, as well as requesting metadata for fit and score methods. The Linear least squares with l2 regularization function, also known as Ridge Regression or Tikhonov regularization, minimizes the objective function by solving a regression model where the loss function is the linear least squares function and regularization is given by the l2-norm. This estimator supports multi-variate regression and allows for controlling the regularization strength with the alpha parameter. Different solvers can be used, such as 'svd', 'cholesky', 'sparse_cg', 'lsqr', 'sag', 'saga', and 'lbfgs', each with its own characteristics and suitability for different types of data. Regularization improves the conditioning of the problem and reduces the variance of the estimates, with larger values of alpha indicating stronger regularization. The function also provides options for fitting intercept, setting maximum iterations, and forcing coefficients to be positive. Additionally, it supports built-in cross-validation and kernel ridge regression. The coefficient of determination \\(R^2\\) can be calculated to evaluate the prediction performance, with a score of 1.0 indicating a perfect fit. Other functionalities include metadata routing, getting and setting parameters, predicting values, and obtaining the actual number of iterations for each target. The Linear model is fitted by minimizing a regularized empirical loss with Stochastic Gradient Descent (SGD). The regularizer is a penalty added to the loss function that shrinks model parameters towards the zero vector using either L2 or L1 norm or a combination of both (Elastic Net). The loss function can be 'squared_error', 'huber', 'epsilon_insensitive', or 'squared_epsilon_insensitive'. The penalty defaults to 'l2' but can be set to 'l1' or 'elasticnet'. The learning rate can be adjusted with the regularization term. The model can learn sparse models and achieve online feature selection. Other parameters include the Elastic Net mixing parameter, intercept estimation, number of passes over the training data, stopping criterion, shuffling of training data, and more. The model can handle outliers and supports various regression models like Lasso, Ridge, SVR, and more. The model can be fitted with Stochastic Gradient Descent and predictions can be made using the linear model. The coefficient of determination can be calculated to evaluate the model's performance. The model also supports metadata routing and parameter setting. Additionally, the coefficient matrix can be converted to a sparse format for memory efficiency. The Linear regression function with combined L1 and L2 priors as regularizer minimizes the objective function by controlling the L1 and L2 penalty separately. The parameter l1_ratio corresponds to alpha in the glmnet R package while alpha corresponds to the lambda parameter in glmnet. The ElasticNet mixing parameter determines the penalty type, whether L1, L2, or a combination of both. The function allows for estimating the intercept, using a precomputed Gram matrix, setting the maximum number of iterations, and reusing the solution of the previous call to fit. It also provides options for positive coefficients, random feature selection, and setting the seed for reproducible output. The function fits the model with coordinate descent and computes the elastic net path with various parameters. Additionally, it implements logistic regression with an elastic net penalty and provides methods for prediction and scoring the model. The function supports metadata routing and parameter setting for the estimator. The Least Angle Regression model, also known as LAR, is a linear model that can be used for sparse coding. It allows for the calculation of the intercept and sets the verbosity level. The model can use a precomputed Gram matrix to speed up calculations, with the option to let the model decide or pass the matrix as an argument. The target number of non-zero coefficients can be specified, with the option to set a limit or use np.inf for no limit. The regularization parameter controls the machine-precision in the computation of the Cholesky diagonal factors. The fit_path parameter determines whether the full path is stored in the coef_path_ attribute. Setting fit_path to False can lead to a speedup, especially with a small alpha. The model also includes parameters for noise addition, random number generation, and maximum covariances at each iteration. The model provides information on active variables, coefficients along the path, parameter vector, and the number of iterations taken to find the grid of alphas. The model can be cross-validated and fit using training data and target values. It also allows for prediction using the linear model and returns the predicted values. The coefficient of determination, \\(R^2\\), can be calculated to evaluate the model's performance. The model includes options for sample weights and metadata routing. Additionally, the model allows for setting and getting parameters, as well as updating the estimator parameters. The Lasso model is a linear model trained with L1 prior as a regularizer. It optimizes the same objective function as the Elastic Net with l1_ratio=1.0. The regularization strength is controlled by the alpha parameter, which must be a non-negative float. The intercept can be calculated for the model, and a precomputed Gram matrix can be used to speed up calculations. The maximum number of iterations and tolerance for optimization can be specified. The model can be fit with coordinate descent, and the coefficients can be forced to be positive. The algorithm used is coordinate descent, and regularization improves the conditioning of the problem. The model can be used for prediction, and the coefficient of determination \\(R^2\\) can be calculated. Metadata routing can be enabled for the fit and score methods. Overall, the Lasso model is a versatile tool for linear regression with regularization. The Lasso model is a linear model trained with an L1 prior as a regularizer. It can be fit using the Least Angle Regression (Lars) algorithm. The optimization objective for Lasso is to minimize the penalty term, with the option to set the alpha parameter to control the regularization strength. The model can calculate the intercept and use a precomputed Gram matrix to speed up calculations. Other parameters include setting verbosity, maximum number of iterations, and controlling the coefficients to be non-negative. The model also supports adding noise to the target values for stability. The Lasso model can be fit using training data and used to make predictions. The coefficient of determination (R^2) can be calculated to evaluate the model's performance. Additionally, metadata routing can be used to pass additional information to the fit and score methods. The Lasso model fit with Lars using BIC or AIC for model selection involves optimizing the objective for Lasso with AIC and BIC criteria, which help in selecting the regularization parameter by balancing the goodness of fit and model complexity. The model can be customized by choosing the type of criterion, calculating the intercept, setting verbosity, using a precomputed Gram matrix, specifying the maximum number of iterations, adjusting regularization, and more. The LassoLarsIC function is suitable for obtaining sparse solutions and is based on the Lars-Lasso algorithm. The function estimates noise variance and other parameters to fit the model. Additionally, the function allows for metadata routing, parameter retrieval, prediction, and scoring based on the linear model. The coefficient of determination is used to evaluate the prediction performance, with a score of 1.0 indicating a perfect fit. The function also supports sample weights and metadata routing for various parameters. The Orthogonal Matching Pursuit (OMP) model is a sparse coding algorithm that can be used for feature selection. It can be cross-validated to find the optimal number of non-zero coefficients. The algorithm can be used with different cross-validation strategies, such as KFold. The model can fit the data using the LARS algorithm, which is a variant of Least Angle Regression (LAR) and Lasso. The fit method finds the optimal number of non-zero coefficients through cross-validation and then fits the model again using the entire training set. The predict method can be used to make predictions using the linear model. The score method calculates the coefficient of determination (R^2) of the prediction. The set_params method can be used to set parameters for the estimator. Metadata routing can be enabled to pass additional information to the score method. The Elastic Net model is a linear regression model with combined L1 and L2 priors as regularizers, allowing for iterative fitting along a regularization path. The model can be fine-tuned by adjusting the l1_ratio parameter, which determines the balance between L1 and L2 penalties. The regularization path can be customized by specifying the length of the path, the number of alphas, and the list of alphas to compute the models. Additionally, options such as intercept calculation, precomputed Gram matrix usage, and verbosity level can be set. Cross-validation strategies can be employed to optimize the model, and the fit method should be passed directly as a Fortran-contiguous numpy array for efficiency. The model can be used for both mono-output and multi-output tasks, with different optimization functions for each. The predict method can be used to make predictions based on the trained model, and the score method calculates the coefficient of determination (R^2) to evaluate the model's performance. Metadata routing can be enabled to pass additional information to the fit and score methods. Overall, the Elastic Net model provides a flexible and efficient approach to linear regression with regularization. The Least Angle Regression model is a linear model trained with an L1 prior as a regularizer, also known as the Lasso. It fits the model using a regularization path and can be used for sparse coding. The model can be fit using the entire training set after finding the best parameter alpha through cross-validation. The model can predict values using the linear model and calculate the coefficient of determination \\(R^2\\). The metadata routing mechanism can be used to request metadata passed to the fit and score methods. The parameters of the estimator can be set and retrieved, and the method works on simple estimators as well as nested objects like Pipelines. The function also provides information on the number of features seen during fit and the names of features when all strings. Additionally, the function allows for the computation of the Lasso path using the LARS algorithm or coordinate descent. The Lasso linear model is a method for fitting sparse coefficients through iterative fitting along a regularization path. It involves cross-validation to select the best model and has various parameters such as the length of the path, number of alphas, intercept calculation, precomputed Gram matrix usage, maximum number of iterations, tolerance for optimization, cross-validation splitting strategy, verbosity level, number of CPUs to use, and more. The Lasso model can be fit using Least Angle Regression (Lars) or coordinate descent. The LassoCV function uses the LARS algorithm for cross-validation. The Lasso optimization function varies for mono and multi-outputs. The predict method can be used to make predictions, and the score method calculates the coefficient of determination (R^2). Metadata routing can be used to pass additional information to the fit and score methods. Overall, the Lasso linear model is a versatile tool for estimating sparse coefficients in a linear model. The Lasso algorithm is used for cross-validated Lasso regression, with the option to calculate the intercept and set verbosity levels. It allows for setting the maximum number of iterations, using a precomputed Gram matrix, and determining the cross-validation splitting strategy. The regularization parameter alpha, coefficients, mean square error, and active variables are all tracked along the path. The model fits the training data using L1 regularization and iterative fitting. The LassoLarsCV object is more stable than LassoCV and is efficient when selecting only a small number of features. After finding the best alpha parameter through cross-validation, the model is fit again using the entire training set. The coefficient of determination R^2 is used to evaluate the prediction performance. Metadata routing can be enabled to pass additional information during fitting and scoring. The Orthogonal Matching Pursuit (OMP) model is a method used for sparse coding, where each column of the result is the solution to a Lasso problem. It involves solving multiple OMP problems using the Gram matrix X.T * X and the product X.T * y. The model allows for setting parameters such as the desired number of non-zero entries in the solution, maximum squared norm of the residual, intercept calculation, and the use of precomputed matrices for improved performance. The implementation of OMP is based on research by Mallat and Zhang, as well as Rubinstein, Zibulevsky, and Elad. The model can be fitted using training data X and target values y, and predictions can be made using the linear model. The coefficient of determination (R^2) can be calculated to evaluate the model's performance. Additionally, metadata routing and parameter setting functionalities are available for the estimator. The Bayesian ARD regression function fits the weights of a regression model using an ARD prior, assuming the weights are in Gaussian distributions. It estimates parameters lambda and alpha, as well as hyper-parameters for the Gamma distribution prior over these parameters. The estimation is done through an iterative procedure called Evidence Maximization. The function also allows for setting a maximum number of iterations and stopping the algorithm if the weights have converged. Other options include computing the objective function at each step, removing weights with high precision, calculating the intercept, and setting verbose mode. The function provides coefficients of the regression model, estimated precisions of the noise and weights, variance-covariance matrix of the weights, and the number of iterations to reach the stopping criterion. It also includes options for the independent term in the decision function, metadata routing, getting parameters, predicting using the linear model, returning the coefficient of determination, setting parameters, and requesting metadata for prediction and scoring methods. Bayesian ridge regression is a method for fitting a Bayesian ridge model. The implementation includes optimization of regularization parameters lambda and alpha. The algorithm is based on the work of Tipping (2001) and MacKay (1992). The model can compute the log marginal likelihood, intercept, coefficients, and other parameters. It can also provide predictions with standard deviation, as well as calculate the coefficient of determination (R^2). Additional features include support for sample weights, metadata routing, and setting parameters. The method can be used for training data and target values, with the option to return the instance itself. The model can also handle test samples and true values for X, along with sample weights. The R^2 score used in scoring has been updated in version 0.23 for consistency. Metadata routing options are available for fit, predict, and score methods. The Multi-task ElasticNet model is trained with L1/L2 mixed-norm as a regularizer. The optimization objective for this model is a combination of L1/L2 penalties, with the option to calculate the intercept. The model uses coordinate descent as the algorithm for fitting and can handle both mono-output and multi-output tasks. The ElasticNet mixing parameter determines the balance between L1 and L2 penalties, with a default value of 1.0. The model can be fit with coordinate descent, and the coefficients along the regularization path can be computed. The model also supports metadata routing and parameter setting. Additionally, the model can predict using the linear model and calculate the coefficient of determination \\(R^2\\) for the prediction. Overall, the Multi-task ElasticNet model is a versatile tool for regression tasks with built-in cross-validation and regularization options. The Multi-task Lasso model is trained with L1/L2 mixed-norm as a regularizer. The optimization objective for Lasso involves the sum of the norm of each row. The model includes parameters such as the constant that multiplies the L1/L2 term, whether to calculate the intercept, the maximum number of iterations, and the tolerance for optimization. The model also allows for the reuse of the solution from the previous fit. The algorithm used is coordinate descent, and it is recommended to pass data and target directly as Fortran-contiguous numpy arrays. The model also includes functions for computing the elastic net path, predicting values, and determining the coefficient of determination. Additionally, there are options for metadata routing and setting parameters for the estimator. Overall, the Multi-task Lasso model provides a comprehensive approach to linear regression with combined L1 and L2 priors as regularizers. The Multi-task L1/L2 ElasticNet function is used for linear regression with combined L1 and L2 priors as regularizer, with built-in cross-validation. The optimization objective involves a combination of L1/L2 penalties based on the ElasticNet mixing parameter. The function allows for the specification of various parameters such as the number of alphas along the regularization path, the intercept calculation, the maximum number of iterations, and the cross-validation splitting strategy. The function fits the model using coordinate descent and returns the best model selected by cross-validation. It also provides methods for predicting values, computing the coefficient of determination, and requesting metadata. Additionally, the function supports the computation of the elastic net path with coordinate descent for both mono-output and multi-output tasks. Overall, the Multi-task L1/L2 ElasticNet function is a versatile tool for regression analysis with regularization. The Multi-task Lasso model is trained with a mixed-norm (L1/L2) as a regularizer. The optimization objective for MultiTaskLasso is the sum of the norm of each row. The model includes parameters such as the length of the path, number of alphas along the regularization path, intercept calculation, maximum number of iterations, tolerance for optimization, cross-validation splitting strategy, verbosity, number of CPUs to use, random number generator seed, and more. The algorithm used for fitting the model is coordinate descent. The model can be fit with coordinate descent on a grid of alphas, and the best alpha is estimated through cross-validation. The Lasso model estimates sparse coefficients and can be fit with Least Angle Regression (Lars) or using iterative fitting along a regularization path. The model can predict values and calculate the coefficient of determination (R^2). Additional features include metadata routing, sample weights, and setting parameters for the estimator. The Lasso model can also compute the Lasso path with coordinate descent for both mono-output and multi-output tasks. The Lasso model is a linear model that estimates sparse coefficients and can be used for cross-validated Lasso using the LARS algorithm. The Huber Regressor is a L2-regularized linear regression model that is robust to outliers. It optimizes the squared loss for samples where |(y - Xw - c) / sigma| < epsilon and the absolute loss for samples where |(y - Xw - c) / sigma| > epsilon. The model coefficients w, intercept c, and scale sigma are parameters to be optimized. The parameter sigma ensures that scaling y does not require rescaling epsilon for the same robustness. The Huber loss function is advantageous as it is not heavily influenced by outliers while still considering their effect. The parameter epsilon controls the number of samples classified as outliers, with smaller epsilon values leading to more robustness. Additionally, there is a strength of squared L2 regularization parameter alpha, which must be in the range [0, inf). Other features include fitting the intercept, number of iterations, features seen during fit, names of features seen during fit, number of lbfgs iterations, boolean mask for identifying outliers, and more. The model can be fitted according to training data, with options for metadata routing, getting parameters, predicting using the model, and scoring the model's performance. The coefficient of determination R^2 is used to evaluate the prediction quality, with a score of 1.0 being the best possible. The model also supports metadata routing for sample weights and parameter settings. The RANSAC (RANdom SAmple Consensus) algorithm is an iterative algorithm used for robust parameter estimation from a subset of inliers in a complete data set. It involves fitting a model to training data, scoring the model's accuracy on test data, and predicting values using a linear model. The algorithm requires a minimum number of samples for estimation, a maximum residual threshold for classifying inliers, and a maximum number of iterations for random sample selection. It stops iteration when a certain number of inliers are found or when a specified score threshold is reached. The algorithm supports different loss functions, such as absolute error and squared error, for outlier detection. Additionally, it includes features like metadata routing, handling sample weights, and providing information on the best fitted model. The RANSAC algorithm is particularly useful for robust regression and is compared to other regression models like Theil-Sen Estimator. References and additional resources are available for further reading on the algorithm. The Linear QuantileRegressor is a linear regression model that predicts conditional quantiles and is robust to outliers. It optimizes the pinball loss for a desired quantile using L1 regularization like Lasso. The model tries to predict a specified quantile between 0 and 1, with 0.5 being the default for the median. It fits the intercept and uses different methods to solve the linear programming formulation. The model supports sparse input data and provides estimated coefficients for the features, intercept, and number of features seen during fit. It also includes feature names, iterations performed by the solver, and the coefficient of determination \\(R^2\\) for predictions. The model can be trained with training data, target values, and sample weights, and can predict values based on input samples. Additional metadata routing information can be accessed, and parameters can be set or retrieved for the estimator. The method also allows for metadata routing for sample weights in both the fit and score methods. The Theil-Sen Estimator is a robust multivariate regression model that calculates least square solutions on subsets of samples in X. The algorithm allows for a compromise between robustness and efficiency by choosing a value for n_subsamples. The spatial median is then calculated from all the least square solutions. The model can be fitted with or without an intercept, and the number of samples used for parameter calculation can be specified. The breakdown point and efficiency of the model can be adjusted by setting the number of samples. The maximum number of iterations for calculating the spatial median and the tolerance can also be specified. The model can be fitted using multiple CPUs and verbose mode can be enabled during fitting. The coefficients, intercept, breakdown point, and other relevant information can be accessed after fitting the model. The model can be used to predict values and calculate the coefficient of determination. The parameters of the estimator can be retrieved or set, and metadata routing can be defined. The method for setting parameters and metadata routing is also explained. The Generalized Linear Model with a Gamma distribution uses the \u2018log\u2019 link function and was added in version 0.23. It includes a constant that multiplies the L2 penalty term for regularization, with alpha = 0 indicating no penalty. The algorithm used is scipy\u2019s L-BFGS-B optimizer with Newton-Raphson steps and an inner Cholesky based solver. The solver is recommended for cases where n_samples >> n_features, especially with rare categories in one-hot encoded categorical features. The model also includes parameters for the maximal number of iterations, stopping criterion, and the option to reuse the solution from a previous fit. The estimated coefficients and intercept are provided, along with the number of features seen during fit and the actual number of iterations used in the solver. The model can be used to fit a Generalized Linear Model with training data, target values, and sample weights. Predictions can be made using the model, and the percentage of deviance explained (D^2) can be computed. The method also allows for requesting metadata and setting parameters of the estimator. Additionally, metadata routing options are available for both the fit and score methods, with the ability to specify whether metadata should be requested, ignored, or passed with a given alias. This functionality was added in version 1.3 and is relevant when the estimator is used as a sub-estimator of a meta-estimator. The Generalized Linear Model with a Tweedie distribution is an estimator that can model different GLMs based on the power parameter, which determines the underlying distribution. The power parameter corresponds to specific distributions such as Normal, Poisson, Compound Poisson Gamma, Gamma, and Inverse Gaussian. The estimator includes options for regularization strength, adding a bias term, selecting the link function, and choosing an optimization algorithm. It also provides features such as setting the maximum number of iterations, defining stopping criteria, reusing previous solutions, and obtaining coefficients and intercepts. Additionally, it allows for metadata routing, parameter retrieval, prediction generation, and computation of the percentage of deviance explained. The method supports passing metadata to fit and score methods, with options for enabling or disabling metadata requests. This estimator can be used as a sub-estimator in a meta-estimator like a Pipeline, with the ability to update parameters and handle metadata routing for sample weights. The Generalized Linear Model with a Poisson distribution is a regressor that uses the 'log' link function and was added in version 0.23. It includes a constant that multiplies the L2 penalty term for regularization, with alpha values ranging from 0.0 to infinity. The algorithm used in optimization is scipy's L-BFGS-B optimizer, which is suitable for cases where n_samples is much larger than n_features. The solver has a quadratic dependency on n_features due to explicit computation of the Hessian matrix. Other parameters include the maximal number of iterations, stopping criterion, and verbose setting. The model also provides estimated coefficients, intercept, number of features, and feature names. The D^2 metric is used to explain the deviance of the model, with a score ranging from -1.0 to 1.0. Metadata routing can be enabled for fit and score methods, with options for sample_weight parameter. The estimator allows for setting and getting parameters, as well as requesting metadata for routing. This method is relevant when the estimator is used as a sub-estimator of a meta-estimator, such as inside a Pipeline. The Passive Aggressive Regressor is a linear model that fits data using the Passive Aggressive algorithm. It allows for setting various parameters such as the maximum step size, whether to estimate the intercept, the number of passes over the training data, the stopping criterion, early stopping, shuffling of training data, and more. The model can be fitted, coefficients can be converted to dense or sparse format, predictions can be made, and the coefficient of determination can be calculated. Metadata routing can be used for various parameters, and the estimator parameters can be set or retrieved. Additionally, the model supports warm-starting the optimization process and averaging SGD weights. The model also provides information on the number of weight updates performed during training and the number of iterations to reach the stopping criterion. The LARS algorithm is used to compute the Least Angle Regression or Lasso path. It involves optimizing the objective function based on the specified method, either 'lar' or 'lasso'. Input data must be provided, with options for precomputed Gram matrix and maximum number of iterations. The regularization parameter alpha in the Lasso corresponds to the minimum correlation along the path. The model can be selected as 'lar' for Least Angle Regression or 'lasso' for the Lasso. The algorithm includes machine-precision regularization and controls for output verbosity. The coefficients are restricted to be >= 0 with the 'lasso' method. The algorithm iterates to find the maximum of covariances and returns the indices of active variables, coefficients along the path, and the number of iterations. Additionally, the algorithm can be used for sparse coding and cross-validated Lasso and Least Angle Regression models. References to further reading on Least Angle Regression and Lasso are provided. The Lasso optimization function can compute paths with coordinate descent for both mono and multi-output tasks. It involves training data, target values, and a specified length of the path. The function allows for setting the number of alphas along the regularization path and whether to use a precomputed Gram matrix. It also provides options for setting initial coefficient values, verbosity, and positive coefficients. The function returns the alphas along the path, coefficients, dual gaps, and number of iterations. The Lasso model estimates sparse coefficients and can be fit using Least Angle Regression or LARS algorithm. Cross-validated Lasso can also be performed using the LARS algorithm. It is recommended to pass X as a Fortran-contiguous numpy array to avoid memory duplication. The Lars solver may be faster in certain cases, especially for linear interpolation to retrieve model coefficients. An example can be found in the User Guide. The Gram Orthogonal Matching Pursuit (OMP) function solves multiple OMP problems using the Gram matrix X.T * X and the product X.T * y. It allows for specifying the desired number of non-zero entries in the solution, the maximum squared norm of the residual, and whether to return every value of the nonzero coefficients along the forward path. The function also provides coefficients of the OMP solution and the number of active features across every target. Additionally, it can be used for computing the Least Angle Regression or Lasso path using the LARS algorithm and for generic sparse coding. The implementation of OMP is based on research by Mallat and Zhang, as well as Rubinstein, Zibulevsky, and Elad. The elastic net optimization function can be used for both mono and multi-output tasks, with different formulations for each. It involves passing training data directly as Fortran-contiguous data to avoid memory duplication. The target values should be between 0 and 1 to scale between l1 and l2 penalties, with l1_ratio=1 corresponding to the Lasso. The path length is determined by the number of alphas along the regularization path, with the option to use a precomputed Gram matrix for faster calculations. The initial coefficients, verbosity level, and other parameters can be specified. The function returns the coefficients along the path, dual gaps, and number of iterations taken by the optimizer. Additionally, there are related models such as Multi-task ElasticNet and Linear regression with combined L1 and L2 priors. An example can be found in the documentation. The lars_path function in the sufficient stats mode provides optimization objectives for both 'lasso' and 'lar' methods, with options for setting maximum iterations, minimum correlation, regularization parameters, and output verbosity. It allows for returning the entire path or just the last point, as well as the number of iterations and active variables. The function is useful for computing LARS and Lasso paths, fitting models with Least Angle Regression, and performing sparse coding. The coefficients along the path and the number of iterations run are also returned. The function is based on the Least Angle Regression model and the Lasso algorithm, with references available for further reading. Orthogonal Matching Pursuit (OMP) is a method that solves multiple OMP problems. The problem instances involve minimizing the error between the target values and the predicted values, subject to constraints on the number of non-zero coefficients. The input data is assumed to have unit norm, and the desired number of non-zero entries in the solution can be specified. The algorithm can also handle precomputations for improved performance with large datasets. Additionally, the design matrix X can be copied if necessary. The function can return the coefficients of the OMP solution, the number of active features, and the entire coefficient path if needed. OMP can be used to solve problems using the Gram matrix and the product X.T * y, as well as for computing the Lasso path using the LARS algorithm. Overall, OMP is a versatile method for sparse coding and was introduced in the literature by Mallat and Zhang in 1993. ",
    "sklearn.manifold": "Isomap Embedding is a non-linear dimensionality reduction technique that uses Isometric Mapping. It considers the number of neighbors for each point, limiting the distance of neighbors to return, and the number of coordinates for the manifold. The method to find the shortest path, algorithm for nearest neighbors search, and the metric used for calculating distances are also specified. The Isomap Embedding stores the embedding vectors, nearest neighbors instance, and geodesic distance matrix of training data. It can be used for manifold learning using multidimensional scaling, T-distributed Stochastic Neighbor Embedding, Locally Linear Embedding, and Spectral embedding. The reconstruction error for the embedding can be computed, and the output format can be configured. The Isomap Embedding can transform data into a new space by linking points into the graph of geodesic distances of the training data. Multidimensional scaling is a technique used to visualize the dissimilarities between data points in a lower-dimensional space. It can be performed as metric MDS or nonmetric MDS, with options for handling missing values and setting the number of dimensions. The algorithm can be run multiple times with different initializations to find the best output based on stress. Other parameters include the maximum number of iterations, verbosity level, relative tolerance, number of jobs for computation, and random number generator. The dissimilarity measure used can be pairwise Euclidean distances or pre-computed dissimilarities. The output includes the stress value, pairwise dissimilarities, and the position of the dataset in the embedding space. Additional options include returning normed stress values, storing feature names, and metadata routing. References are provided for further reading on multidimensional scaling and related techniques like PCA, t-SNE, Isometric Mapping, Locally Linear Embedding, and Spectral Embedding. T-distributed Stochastic Neighbor Embedding (t-SNE) is a tool used to visualize high-dimensional data by converting similarities between data points to joint probabilities and minimizing the Kullback-Leibler divergence. It has a non-convex cost function, so different initializations can lead to different results. It is recommended to use other dimensionality reduction methods like PCA or TruncatedSVD before applying t-SNE to reduce the number of dimensions. The perplexity parameter controls the number of nearest neighbors used and should be chosen between 5 and 50. The learning rate for t-SNE is typically in the range of 10.0 to 1000.0. The method can be run in approximate or exact mode, with the former being faster but less accurate. The angle parameter in Barnes-Hut t-SNE determines the trade-off between speed and accuracy. The number of parallel jobs can be specified for neighbor search. Other related methods include Principal Component Analysis, manifold learning, and spectral embedding. The t-SNE algorithm has been extensively studied and optimized for various applications, with references available for further reading. The SMACOF algorithm is a multidimensional scaling technique that minimizes stress using stress majorization, ensuring monotone convergence. It involves setting an initial configuration, computing stress, applying the Guttman Transform, and iterating until convergence. For metric MDS, pairwise dissimilarities are used, while nonmetric MDS includes a monotonic regression step. The algorithm can be run with different initializations, and the best output is chosen based on the smallest final stress. Various parameters such as number of dimensions, starting configuration, number of iterations, and verbosity can be adjusted. The final result includes coordinates in a specified space and the stress value, which indicates the fit quality. Additional options include returning the number of iterations and using normalized stress values. References to relevant literature are provided for further reading. The function allows for the embedding of training data into a low-dimensional space while retaining the local structure. The trustworthiness of the embedding is determined by the extent to which the local structure is preserved, with a value between 0 and 1. The number of neighbors considered should be less than half of the total samples to ensure trustworthiness falls within the specified range. The choice of metric for computing pairwise distances between samples is crucial, with options including precomputed matrices or a list of available metrics. The function penalizes unexpected nearest neighbors in the output space based on their rank in the input space. References to studies on neighborhood preservation in nonlinear projection methods are provided for further reading. Locally Linear Embedding is a technique for dimensionality reduction that considers the number of neighbors for each point, the number of coordinates for the manifold, a regularization constant, and the solver used to compute the eigenvectors. The available solver options include 'auto', 'arpack', and 'dense'. The method can be standard, Hessian, modified, or LTSA. Additional parameters include tolerance, maximum iterations, nearest neighbors search algorithm, random number generator, number of parallel jobs, reconstruction error, and more. The technique computes embedding vectors for data X and can transform X. It also provides methods for getting output feature names, metadata routing, parameters, setting output container, setting parameters, and transforming new points into the embedding space. It is recommended not to use this method with scale-invariant methods like SVMs due to scaling issues. References include various papers on nonlinear dimensionality reduction techniques. The Spectral embedding function is used for non-linear dimensionality reduction. It involves forming an affinity matrix based on specified functions and applying spectral decomposition to the graph laplacian. The resulting transformation is determined by the eigenvectors for each data point. The algorithm implemented is Laplacian Eigenmaps. Different options are available for constructing the affinity matrix, such as using nearest neighbors or radial basis function kernel. The function also allows for custom affinity functions. Other parameters include the kernel coefficient for the RBF kernel, the eigenvalue decomposition strategy, stopping criterion for eigendecomposition, number of nearest neighbors, and the number of parallel jobs to run. The function can fit the model from data and transform it, with options for precomputed adjacency graphs. Additionally, it provides methods for getting metadata routing, getting and setting parameters for the estimator. References to spectral clustering and image segmentation are also included. Locally Linear Embedding (LLE) is a method used for nonlinear dimensionality reduction. It analyzes data in the form of a numpy array or a NearestNeighbors object by considering a specified number of neighbors for each point and determining the number of coordinates for the manifold. The regularization constant multiplies the trace of the local covariance matrix of the distances. The algorithm can automatically choose the best method for the input data, but it is recommended to try several random seeds to check results as ARPACK can be unstable for some problems. The method can use a dense matrix, sparse matrix, or general linear operator, but it should be avoided for large problems. The tolerance for the 'arpack' method and the maximum number of iterations for the arpack solver can be specified. The number of neighbors should be greater than the number of components multiplied by (1 + (number of components + 1) / 2). Different tolerances are available for specific methods like 'hessian' and 'modified'. The random number generator can be determined for reproducible results, and the number of parallel jobs for neighbors search can be specified. The output includes embedding vectors and the reconstruction error for the embedding vectors. References for LLE include papers by Roweis & Saul, Donoho & Grimes, Zhang & Wang, and Zhang & Zha. ",
    "sklearn.metrics": "The function is used to determine the scorer from user options. It can handle different types of scoring methods, including single score, multiple scores, and custom scorers. If no scoring is specified, the estimator object's score method is used. The function also provides the ability to get the names of all available scorers and retrieve a specific scorer object by name. It is important to note that when passed a string, the function always returns a copy of the scorer object, resulting in separate scorer objects if called multiple times for the same scorer. The function descriptions provided explain how to create a scorer from a performance metric or loss function in scikit-learn. This scorer acts as a wrapper around the metric or loss function and is used with the signature scorer(estimator, X, y_true, **kwargs). It is compatible with all scikit-learn estimators and functions that accept a scoring parameter. The response_method parameter allows for specifying the method of the estimator to use for feeding the scoring/loss function. The score_func function has the signature score_func(y, y_pred, **kwargs) and determines whether the function is a score function (high is good) or a loss function (low is good). It also specifies if predict_proba is required to get probability estimates from a classifier. Additionally, it can handle continuous decision certainty for binary classification. Some parameters have been deprecated in version 1.4 and users are advised to use alternative methods. Overall, the function allows for creating a callable object that returns a scalar score, with higher values indicating better performance. The accuracy classification score function in multilabel classification computes subset accuracy, where the predicted labels must exactly match the true labels. It can return either the number or fraction of correctly classified samples, depending on the parameters. Other related functions include computing balanced accuracy for imbalanced datasets, Jaccard similarity coefficient score, average Hamming loss, and zero-one classification loss. Additionally, the function can calculate the average precision (AP) from prediction scores, which summarizes a precision-recall curve. The function takes into account different types of target scores and can perform various types of averaging on the data. The precision-recall pairs for different probability thresholds are also computed, with a change in recall since the last operating point used to weight the precisions. The Brier score loss is a measure that calculates the mean squared difference between predicted probabilities and actual outcomes. It always falls between zero and one, with lower values indicating better performance. The score can be broken down into refinement loss and calibration loss. It is suitable for binary and categorical outcomes but not for ordinal variables with three or more values. The positive label can be specified using the pos_label parameter, which defaults to the greater label unless all values are 0 or -1. Deprecated features include y_prob, which should be replaced with y_proba. The Brier score is a useful metric for evaluating the accuracy of predictions in classification tasks. The function allows for the creation of a text report displaying main classification metrics, such as precision, recall, and F1 score for each class. It also provides the option to include label indices, display names, sample weights, and set the number of digits for formatting output floating point values. The function can return output as a dictionary and allows for customization of the value to return in case of zero division. Additionally, it computes a confusion matrix to evaluate the accuracy of a classification, providing insights into true negatives, false negatives, true positives, and false positives. The confusion matrix can be normalized over the true or predicted conditions, and can be visualized through plotting. This function is a comprehensive tool for evaluating classification performance and understanding the distribution of predictions across different classes. The function computes Discounted Cumulative Gain by summing the true scores ranked based on predicted scores with a logarithmic discount. This metric is useful for ranking true labels high. It is recommended to use Normalized Discounted Cumulative Gain (NDCG) for multilabel classification or ranking entities. The function considers the highest k scores in the ranking and allows for specifying the base of the logarithm for discount. Sample weights can be provided for different weighting. The function assumes no ties in y_score for efficiency. It calculates the averaged sample DCG scores and can be normalized to have a score between 0 and 1. References to relevant literature on Discounted Cumulative Gain are provided for further reading. The F1 score, also known as the balanced F-score or F-measure, is a metric that can be interpreted as a harmonic mean of precision and recall. It reaches its best value at 1 and worst score at 0. The formula for the F1 score involves true positives, false negatives, and false positives. Support for multiclass and multilabel data is achieved by treating them as a collection of binary problems. The F1 score can be calculated for specific labels, and the type of averaging can be specified. There are options to handle cases where there are no true positives, false negatives, or false positives. The F1 score can be used for binary classification or multiclass tasks. Other related metrics include precision, recall, F-beta score, Jaccard similarity coefficient score, and confusion matrix. It's important to note that when a class is completely absent from the true or predicted labels, the F-score is undefined, and the zero_division parameter can be set to modify this behavior. The functions provided are used to compute different evaluation metrics for multilabel classification tasks. These include the average Hamming loss, which measures the fraction of incorrectly predicted labels, the Jaccard similarity coefficient score, and the Zero-one classification loss. The Hamming loss is more forgiving than the zero-one loss as it penalizes only individual labels, while the zero-one loss considers the entire set of labels incorrect if it does not match the true set exactly. The Hamming loss is always between 0 and 1, with lower values indicating better performance. These functions are useful for assessing the accuracy and performance of multilabel classifiers. The Jaccard similarity coefficient score, also known as the Jaccard index, is used to compare the set of predicted labels for a sample to the corresponding set of labels in y_true. It calculates the size of the intersection divided by the size of the union of two label sets. This score can be used for binary, multiclass, and multilabel data by treating them as a collection of binary problems. The average parameter determines whether scores for both classes are computed, then averaged, or both returned. The labels parameter specifies the set of labels to calculate the score for. Ground truth labels and predicted labels are required inputs. The function can report metrics globally, for each label, or for each instance. It also allows for setting a value to return when there is a zero division. The Jaccard score is returned as a single scalar when average is not None. It is important to note that the Jaccard score may not be a suitable metric if there are no positives for some samples or classes. The Matthews correlation coefficient (MCC) is a measure used in machine learning to assess the quality of binary and multiclass classifications. It considers true and false positives and negatives, providing a balanced measure even for classes of different sizes. The MCC ranges from -1 to +1, with +1 indicating a perfect prediction, 0 an average random prediction, and -1 an inverse prediction. It is also known as the phi coefficient. Normalized Discounted Cumulative Gain is a ranking metric that sums true scores based on predicted scores, normalized by the best possible score. This metric returns a high value when true labels are ranked high. It is applicable to multilabel classification and ranking entities. The NDCG score ranges from 0 to 1 and is calculated by considering the highest k scores in the ranking. Sample weights can be applied, and ties in y_score are assumed to be absent for efficiency. References for both MCC and NDCG are provided for further reading and understanding. The function computes precision, recall, F-measure, and support for each class. Precision is the ability of the classifier not to label a negative sample as positive, while recall is the ability to find all positive samples. The F-beta score combines precision and recall, with beta determining the weight. Support is the number of occurrences of each class. Different averaging options are available, such as 'binary' for binary targets and 'macro' to account for label imbalance. The function can also calculate metrics globally or for each label individually. It is important to note that precision, recall, and F-score may be undefined in certain cases, with the option to modify behavior using zero_division. The function also provides references to additional resources for further reading. The function descriptions provided cover the computation of recall in various scenarios. Recall is defined as the ratio of true positives to the sum of true positives and false negatives. It represents the ability of a classifier to identify all positive samples. The function supports binary targets as well as multiclass and multilabel data by treating them as a collection of binary problems. Different parameters such as average, pos_label, and labels can be specified to customize the recall calculation. The function can calculate recall globally, for each label, or provide a weighted average based on support. It also allows for the handling of zero divisions by setting a specific value or raising a warning. Additionally, the function can be used to compute balanced accuracy, confusion matrices, and plot precision-recall curves. Overall, the recall function provides a comprehensive tool for evaluating the performance of classifiers in various classification tasks. The functions described include computing the Receiver Operating Characteristic (ROC) curve for binary classification tasks, handling true binary labels, target scores, sample weights, and different probability thresholds. The ROC curve can be plotted with various parameters such as false positive rates, true positive rates, and error rates. The area under the ROC curve can also be computed. Additionally, there is a function for calculating the zero-one classification loss, which can be normalized to return the fraction of misclassifications. Other functions include computing the average Hamming loss, Jaccard similarity coefficient score, and accuracy score. These functions are useful for evaluating the performance of classifiers in machine learning tasks. The functions provided include computing the Area Under the Curve (AUC) using the trapezoidal rule for general curves, computing the area under the ROC curve, computing average precision from prediction scores, computing precision-recall pairs for different probability thresholds, and computing the balanced accuracy in binary and multiclass classification problems to handle imbalanced datasets. The balanced accuracy is defined as the average recall obtained on each class, with a best value of 1 and a worst value of 0. The functions also involve working with ground truth target values, estimated targets from a classifier, and sample weights for adjusting the results. Additionally, there are functions for computing precision score, recall score, and Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores. The functions are based on established literature and provide a comprehensive set of tools for evaluating classification models. The function computes binary classification positive and negative likelihood ratios. The positive likelihood ratio (LR+) is calculated using sensitivity and specificity, while the negative likelihood ratio (LR-) is calculated using sensitivity and specificity as well. These class likelihood ratios can be used to determine post-test probabilities based on pre-test probabilities. LR+ ranges from 1 to infinity, with higher values indicating a higher likelihood of a positive prediction being true. LR- ranges from 0 to 1, with lower values indicating a lower probability of a false negative. The function also handles ground truth target values, estimated targets, labels for indexing the matrix, sample weights, and zero division warnings. The output is a tuple containing the Positive likelihood ratio and the Negative likelihood ratio. This function is commonly used in medical applications to diagnose the presence or absence of a disease. The summary covers two different functions. \n\nThe first function computes Cohen\u2019s kappa, a statistic that measures inter-annotator agreement. It calculates a score that expresses the level of agreement between two annotators on a classification problem. The kappa statistic is a number between -1 and 1, where the maximum value means complete agreement and zero or lower means chance agreement. The function takes into account labels assigned by two annotators, a weighting type to calculate the score, and sample weights. References to the original papers by Cohen and Artstein & Poesio are provided.\n\nThe second function is the \\(D^2\\) score function, which is the fraction of log loss explained. The best possible score is 1.0, and it can be negative. A model that always predicts the per-class proportions of the true labels gets a D^2 score of 0.0. The function requires the actual labels for the samples, predicted probabilities from a classifier, and sample weights. It is noted that the D^2 score may be negative and is not well-defined for a single sample. The function computes error rates for different probability thresholds, which is used for evaluating ranking and error tradeoffs in a binary classification task. It requires true binary labels and target scores, which can be probability estimates, confidence values, or decision measures. The positive class label needs to be specified if labels are not {-1, 1} or {0, 1}. It also considers sample weights, false positive rate, false negative rate, and decreasing score values. Additionally, it can plot DET curves, ROC curves, and precision-recall curves for visualization purposes. The F-beta score is a metric that combines precision and recall, with the beta parameter determining the importance of each. It reaches its best value at 1 and worst at 0. The score can be computed for binary, multiclass, and multilabel data, with options for averaging and label selection. The function also allows for setting the weight of recall, handling zero divisions, and reporting metrics for specific classes. It is based on the number of true positives, false positives, and false negatives, and can be used to evaluate classification models. The F-beta score is related to precision, recall, F-score, and support, and can be used to calculate confusion matrices. The average hinge loss function is used for both binary and multiclass classification cases, providing an upper bound on the number of mistakes made by the classifier. In the binary class case, the margin is calculated based on the true labels and predicted decisions. In the multiclass case, the multilabel margin is calculated using Crammer-Singer's method. The log loss function, also known as logistic loss or cross-entropy loss, is used in logistic regression and neural networks for models with two or more labels. It calculates the negative log-likelihood of the model's predictions. The function requires ground truth labels and predicted probabilities, with the option to provide sample weights. The logarithm used in the log loss function is the natural logarithm. References for further reading include Wikipedia on Hinge loss and various academic papers on the topic. The function computes a confusion matrix for each class or sample. It was added in version 0.21. It can compute class-wise (default) or sample-wise (samplewise=True) multilabel confusion matrix to evaluate the accuracy of a classification, and output confusion matrices for each class or sample. In the multilabel confusion matrix, the count of true negatives, false negatives, true positives, and false positives are specified. Multiclass data will be treated as if binarized under a one-vs-rest transformation. The returned confusion matrices will be in the order of sorted unique labels in the union of (y_true, y_pred). It requires ground truth target values, estimated targets as returned by a classifier, sample weights, and a list of classes or column indices to select some. In the multilabel case, it calculates a confusion matrix per sample. The function returns a 2x2 confusion matrix corresponding to each output in the input. When calculating class-wise multi_confusion (default), n_outputs = n_labels; when calculating sample-wise multi_confusion (samplewise=True), n_outputs = n_samples. If labels are defined, the results will be returned in the order specified in labels, otherwise, the results will be returned in sorted order by default. The function is useful for evaluating the accuracy of a classifier. It should be noted that the multilabel_confusion_matrix calculates class-wise or sample-wise multilabel confusion matrices, and in multiclass tasks, labels are binarized under a one-vs-rest way; while confusion_matrix calculates one confusion matrix for confusion between every two classes. The function computes precision-recall pairs for different probability thresholds in a binary classification task. Precision is the ability of the classifier not to label a negative sample as positive, while recall is the ability to find all positive samples. The graph starts at precision=class balance and recall=1.0 for a classifier that always predicts the positive class. True binary labels are required, and pos_label should be explicitly given if labels are not {-1, 1} or {0, 1}. Sample weights can be used, and suboptimal thresholds can be dropped to create lighter precision-recall curves. The function also computes average precision from prediction scores, error rates for different probability thresholds, and Receiver Operating Characteristic (ROC) curves. Note that probas_pred is deprecated and should be replaced with y_score. The precision function computes the ratio of true positives to the sum of true positives and false positives, indicating the classifier's ability to correctly identify positive samples. It can handle binary, multiclass, and multilabel data, with options for different averaging methods. The function also allows for specifying labels, handling label imbalance, and setting a value for zero division cases. Additionally, it can calculate precision for individual classes, provide a weighted average, and generate confusion matrices. The precision-recall curve can be plotted for binary class predictions, and the function also calculates precision for the positive class in binary classification or the weighted average for multiclass tasks. The function computes the Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores. It can be used with binary, multiclass, and multilabel classification, with some restrictions. True labels or binary label indicators are expected in different shapes depending on the case. Probability estimates and non-thresholded decision values can be provided. Different types of averaging can be performed on the data, such as 'macro' and 'weighted' averages. The function also supports sample weights and different types of configurations, such as 'ovr' (One-vs-rest) and 'ovo' (One-vs-one). The Gini Coefficient, which is a summary measure of the ranking ability of binary classifiers, can be calculated using the ROC-AUC score. References for further reading on ROC analysis and the Gini coefficient are provided. The summary covers two main functions: Top-k Accuracy classification score and \\(D^2\\) regression score function. \n\nThe Top-k Accuracy classification score calculates the number of times the correct label is among the top k predicted labels. It requires true labels, target scores, the number of most likely outcomes considered, sample weights, and a list of labels. The best performance is 1 with normalization. In cases of equal predicted scores for multiple labels, the label with the highest index is chosen first.\n\nThe \\(D^2\\) regression score function measures the fraction of absolute error explained, with a best possible score of 1.0. It can be negative, and a constant prediction model receives a score of 0.0. It requires ground truth target values, estimated target values, sample weights, and can handle multiple output values. The score may be negative and is not well-defined for single samples. References to further reading are provided. The \\(D^2\\) regression score function is a metric that measures the fraction of Tweedie deviance explained by a model, with a best possible score of 1.0. The score can be negative, indicating a worse model. Different power parameters are used for different distributions, such as normal, Poisson, compound Poisson, gamma, inverse Gaussian, and positive stable distributions. The max_error metric calculates the maximum residual error between ground truth and estimated target values. The \\(D^2\\) score is not symmetric and may be negative, similar to R^2. It is not well-defined for single samples and will return NaN if the number of samples is less than two. The functions described include Mean Absolute Percentage Error (MAPE) regression loss, Pinball loss for quantile regression, and Mean Squared Error regression loss. \n\nMAPE is a metric that calculates the percentage error between the ground truth and estimated target values. It is important to note that the output is not a percentage in the range [0, 100], and a value of 100 does not mean 100%, but 1e2. The output can be arbitrarily high when y_true is small or when the absolute difference between y_true and y_pred is large. MAPE output is a non-negative floating point, with the best value being 0.0. However, bad predictions can lead to arbitrarily large MAPE values, especially if some y_true values are very close to zero.\n\nPinball loss is used for quantile regression and is equivalent to Mean Absolute Error when alpha=0.5. It is minimized by estimators of the 95th percentile. The output is a non-negative floating point, with the best value being 0.0.\n\nMean Squared Error (MSE) regression loss calculates the squared error between the ground truth and estimated target values. It returns a non-negative floating point value, with the best value being 0.0. It is important to note that the squared function is deprecated and will be removed in future versions, and root_mean_squared_error should be used instead to calculate the root mean squared error. The Mean Tweedie deviance regression loss function is used to calculate the deviation between true and predicted target values, with different power parameters corresponding to different distributions. The \\(R^2\\) regression score function calculates the coefficient of determination, with a perfect score of 1.0 and the possibility of negative scores. It handles cases where the true y values are non-constant or constant, replacing non-finite numbers with 1.0 or 0.0 respectively by default. The function also allows for weighting of scores for multiple outputs and can handle NaN and -Inf scores resulting from constant data. It is important to note that the \\(R^2\\) score may be negative and is not well-defined for single samples. The functions described include the Root Mean Squared Logarithmic Error regression loss and the \\(D^2\\) regression score function. The Root Mean Squared Logarithmic Error regression loss calculates errors between ground truth and estimated target values, with the option to define sample weights. It returns a full set of errors for multioutput format inputs and averages errors with uniform weight. On the other hand, the \\(D^2\\) regression score function explains the fraction of pinball loss and can be negative. It is optimal at a certain quantile level alpha, with the default being 0.5. The function also allows for defining weights for averaging scores and returns a full set of errors for multioutput inputs. The \\(D^2\\) score may be negative and is not well-defined for a single point. References for these functions include works by Koenker and Machado, as well as Hastie, Tibshirani, and Wainwright. The functions described include the Explained Variance regression score function, Mean Absolute Error regression loss, Mean Gamma deviance regression loss, and Mean Poisson deviance regression loss. \n\nThe Explained Variance score measures the proportion of variance in the dependent variable that is predictable from the independent variables. It is similar to the R^2 score but does not account for systematic offsets in the prediction. The Mean Absolute Error calculates the average absolute difference between the predicted values and the actual values. The Mean Gamma deviance regression loss is equivalent to the Tweedie deviance with a power parameter of 2, measuring relative errors and being invariant to scaling of the target variable. The Mean Poisson deviance regression loss is equivalent to the Tweedie deviance with a power parameter of 1, specifically for Poisson distributed data.\n\nEach function requires ground truth target values, estimated target values, and sample weights. They may also involve aggregating multiple output scores or errors, with options for different weighting schemes. The best value for each function is 0.0, indicating perfect predictions or minimal error. These functions are useful for evaluating the performance of regression models in different contexts. The functions described include Mean Squared Logarithmic Error regression loss, Median Absolute Error regression loss, Root Mean Squared Error regression loss, and Coverage Error measure. \n\nThe Mean Squared Logarithmic Error function calculates the average error between ground truth and estimated target values, with the option to return either MSLE or RMSLE values. The Median Absolute Error function calculates the median error between ground truth and estimated target values. The Root Mean Squared Error function calculates the square root of the average squared error between ground truth and estimated target values. \n\nThe Coverage Error measure calculates how far one needs to go through ranked scores to cover all true labels, with the best value being equal to the average number of labels in the true values per sample. This function handles ties in scores and can handle instances with 0 true labels. \n\nAll functions take into account sample weights and can handle multioutput input. The Coverage Error function requires true binary labels in binary indicator format and target scores. References for the Coverage Error function are provided. The functions provided compute ranking loss measure and ranking-based average precision. The ranking loss measure calculates the average number of label pairs that are incorrectly ordered given the target scores, weighted by the size of the label set and the number of labels not in the label set. This measure is useful for evaluating the performance of models in multi-label classification tasks. On the other hand, the ranking-based average precision calculates the average over each ground truth label assigned to each sample, of the ratio of true vs. total labels with lower score. This metric is particularly useful in multilabel ranking problems where the goal is to give better rank to the labels associated with each sample. Both functions require true binary labels, target scores, and sample weights as inputs. The best performance is achieved with a ranking loss of zero and a ranking-based average precision score of 1. These functions are valuable tools for assessing the quality of predictions in multi-label classification tasks. The Adjusted Mutual Information (AMI) function is used to measure the agreement between two clusterings by adjusting the Mutual Information (MI) score to account for chance. It is symmetric and independent of the absolute values of the labels. The AMI returns a value of 1 for identical partitions and can be negative for random partitions. The function is slower compared to other metrics like the Adjusted Rand Index. The Calinski and Harabasz score, also known as the Variance Ratio Criterion, is used to compute the dispersion between and within clusters. It is based on a list of n_features-dimensional data points and predicted labels for each sample. Perfect labelings have a score of 1.0. References for both functions are provided for further reading. The pair confusion matrix is used to compute a 2 by 2 similarity matrix between two clusterings by considering all pairs of samples and counting pairs that are assigned into the same or different clusters under the true and predicted clusterings. It involves true negatives, false negatives, true positives, and false positives. Ground truth class labels are used as a reference, along with cluster labels to evaluate and the contingency matrix. The Davies-Bouldin score is calculated as the average similarity measure of each cluster with its most similar cluster, where lower values indicate better clustering. This score is based on the ratio of within-cluster distances to between-cluster distances. Perfectly matching labelings have all non-zero entries on the diagonal, while labelings that assign all class members to the same clusters are complete but may not always be pure. The matrix is not symmetric. References include works by Hubert and Arabie in 1985, as well as Davies and Bouldin in 1979. The function computes homogeneity, completeness, and V-Measure scores simultaneously. Homogeneity is satisfied when clusters contain only data points from a single class, while completeness is satisfied when all data points from a class are in the same cluster. The scores range from 0.0 to 1.0, with higher values being better. The metrics are independent of label values permutations. V-Measure is symmetric, unlike homogeneity and completeness. It is equivalent to normalized_mutual_info_score with arithmetic averaging. Mutual Information measures similarity between labels, with a formula based on cluster sizes. It is symmetric and independent of label permutations. The function requires ground truth class labels, cluster labels, and a weight ratio for homogeneity vs completeness. The output is a score between 0.0 and 1.0, with 1.0 indicating perfect labeling. The Rand Index is a similarity measure between two clusterings that counts pairs assigned in the same or different clusters in predicted and true clusterings. It provides a similarity score between 0.0 and 1.0, with 1.0 indicating a perfect match. The Adjusted Rand Score and Adjusted Mutual Information are related metrics. The Silhouette Coefficient calculates the mean intra-cluster distance and mean nearest-cluster distance for each sample to determine how well samples are clustered. A value of 1 is ideal, -1 indicates a sample is in the wrong cluster, and values near 0 suggest overlapping clusters. The Silhouette Coefficient requires pairwise distances between samples or a feature array, predicted labels, and a specified metric for distance calculation. The mean Silhouette Coefficient is returned, with further parameters passed to the distance function. References for these metrics include works by Hubert and Arabie, Rousseeuw, and Wikipedia entries. The Adjusted Rand Index (ARI) is a similarity measure between two clusterings that takes into account pairs of samples assigned to the same or different clusters in both the predicted and true clusterings. The raw RI score is adjusted for chance to produce the ARI score, which ranges from -0.5 to 1.0. A score of 1.0 indicates a perfect match between clusterings, while values close to 0.0 represent random labeling. The ARI penalizes labelings that assign all class members to the same clusters or have unnecessary splits. It may also take negative values for discordant labelings. To calculate the ARI, a contingency matrix is built to describe the relationship between ground truth class labels and cluster labels. The output can be adjusted by adding a float value to all matrix entries or returning a sparse matrix. The ARI calculation is symmetric and ensures a value close to 0.0 for random labeling and 1.0 for identical clusterings. References for the ARI include works by Hubert and Arabie (1985) and Steinley (2004). The functions described involve computing completeness metrics and similarity measures for cluster labeling. The completeness metric evaluates if all data points of a class are in the same cluster, while the Fowlkes-Mallows index measures the similarity between two clusterings. Perfect labelings are both homogeneous and complete, resulting in a score of 1.0. The FMI is null if class members are completely split across different clusters. These functions provide valuable tools for evaluating clustering results and comparing different clusterings. The functions described include the Homogeneity metric, which evaluates the homogeneity of a cluster labeling based on ground truth class labels. It measures how well each cluster contains only data points from a single class. The V-Measure is also discussed, which is a normalized mutual information metric that evaluates the agreement between two clusterings. It normalizes the mutual information score to a range between 0 and 1. The Adjusted Rand Index is another function mentioned, which is an adjusted mutual information metric that takes chance into account. Perfect labelings have a score of 1.0 for both homogeneity and completeness. The functions are independent of the absolute values of the labels and provide a way to evaluate the quality of clusterings. The Silhouette Coefficient is a measure used to evaluate how well samples are clustered based on their similarity to each other. It calculates the mean intra-cluster distance and the mean nearest-cluster distance for each sample, then computes the Silhouette Coefficient as (b - a) / max(a, b). This function is applicable when the number of labels falls within a certain range. A high Silhouette Coefficient indicates dense and well-separated clusters, while values near 0 suggest overlapping clusters. The best value is 1 and the worst is -1. The function takes pairwise distances or a feature array as input, along with label values and the metric for calculating distances. The output is the Silhouette Coefficient for each sample. References to the original paper by Peter J. Rousseeuw and the Wikipedia entry on the Silhouette Coefficient are provided for further reading. The V-measure function is used for cluster labeling evaluation based on a ground truth, providing a score that combines homogeneity and completeness. It is independent of label values and symmetric. The function allows for comparing different label assignment strategies when the ground truth is unknown. Perfect labelings have a score of 1.0, while incomplete or unbalanced labelings are penalized. The function also includes references to related metrics and research. Another function calculates the similarity between sets of biclusters using the Hungarian algorithm, providing a consensus score based on the sum of similarities. This function is useful for comparing bicluster sets and can use different similarity metrics. References to relevant research are also provided. The DistanceMetric class provides a uniform interface for fast distance metric functions, allowing for the computation of pairwise distances between samples. It supports various distance metrics such as Euclidean distance, Manhattan distance, Chebyshev distance, Minkowski distance, SEuclidean distance, Mahalanobis distance, Haversine distance, Hamming distance, Canberra distance, BrayCurtis distance, Jaccard distance, Matching distance, Dice distance, Kulsinski distance, RogersTanimoto distance, RussellRao distance, SokalMichener distance, SokalSneath distance, and PyFunc distance. These metrics cover real-valued vector spaces, two-dimensional vector spaces, integer-valued vector spaces, and boolean-valued vector spaces. Additionally, user-defined distance metrics can be implemented using the PyFuncDistance class. Each metric has a specific distance function that calculates the distance between samples based on the given input data. The DistanceMetric class allows for the retrieval of a specific metric using its string identifier or class name, with the option to customize the behavior of the metric using additional keyword arguments. The precision of the computed distances can be affected by the data type of the input, which is set to np.float64 by default. It is important to note that user-defined distance functions must satisfy certain properties to be used within the BallTree, such as non-negativity, identity, symmetry, and the triangle inequality. The functions provided include computing the additive chi-squared kernel between observations in X and Y, computing cosine distance between samples in X and Y, returning valid metrics for pairwise distances, computing the Haversine distance between samples in X and Y, and computing the Laplacian kernel between X and Y. The chi-squared kernel is most commonly applied to histograms and can be interpreted as a weighted difference per entry. The cosine distance is defined as 1.0 minus the cosine similarity. The Haversine distance is the angular distance between two points on the surface of a sphere. The Laplacian kernel is defined for each pair of rows in X and Y. These functions provide different ways to measure distances and similarities between samples or observations. The functions provided compute various distances between vectors. The first function calculates the L1 distances between vectors in X and Y, with an option to use Y=X if needed. The second function computes the cosine distances between X and Y, returning the distances between row vectors. The third function calculates the paired euclidean distances between X and Y, providing an output array with the results. Additionally, the functions handle sparse matrices and normalize samples to unit norm when necessary. The function computes the kernel between arrays X and an optional array Y. It can take a vector array or a kernel matrix as input and returns a kernel matrix. If Y is provided, the returned matrix is the pairwise kernel between the arrays from both X and Y. The function supports various kernel types such as 'additive_chi2', 'chi2', 'linear', 'poly', 'polynomial', 'rbf', 'laplacian', 'sigmoid', and 'cosine'. The shape of the array should be (n_samples_X, n_samples_X) if the metric is \"precomputed\" and (n_samples_X, n_features) otherwise. The function allows for parallel computation by specifying the number of jobs to use. Additional parameters can be passed directly to the kernel function. If the metric is 'precomputed', Y is ignored, and X is returned. The function also computes the RBF (gaussian) kernel between X and Y using the formula K(x, y) = exp(-gamma ||x-y||^2) for each pair of rows x in X and y in Y. The function computes the distance matrix from a vector array X and optional Y. It can take either a vector array or a distance matrix as input and returns a distance matrix. If the input is a vector array, distances are computed, and if it is a distances matrix, it is returned. Custom metrics can be passed for non-numeric data. The method supports various metrics from scikit-learn and scipy.spatial.distance, with options for sparse matrix inputs. It also allows for pairwise distance calculation between arrays from X and Y. The function handles different metrics, number of jobs for computation, and handling of infinite or NaN values in the array. The output is a distance matrix D where D_{i, j} represents the distance between the ith and jth vectors of the given matrix X, or between arrays from X and Y if Y is not None. Additionally, there is a related function that returns a generator of chunks of the distance matrix to limit memory usage. The first function computes the minimum distances between one point and a set of points. It calculates the closest row in Y for each row in X based on a specified distance metric. This function is more memory-efficient and faster for large arrays compared to pairwise_distances. The valid distance metrics include options from scikit-learn and scipy.spatial.distance libraries. The function also returns the array of minimum distances and the distances between each pair of points. The second function computes the exponential chi-squared kernel between two non-negative feature arrays, commonly used for histograms. The kernel matrix is returned as the output. This kernel can be interpreted as a weighted difference per entry and is useful for classification tasks. The functions provided include computing cosine similarity between samples in X and Y, computing the distance matrix between each pair from a vector array X and Y, returning valid metrics for pairwise kernels, and computing the linear kernel between X and Y. The cosine similarity function calculates similarity as the normalized dot product of X and Y, while the distance matrix function computes the Euclidean distance between pairs of row vectors efficiently. The valid metrics function lists the valid pairwise distance metrics available. The linear kernel function computes the Gram matrix of the linear kernel between X and Y. These functions provide essential tools for calculating similarities and distances between samples and feature arrays. The function calculates the Euclidean distances between pairs of samples in X and Y, with Y=X assumed if Y=None. It ignores feature coordinates with missing values and scales up the weight of the remaining coordinates. If all coordinates are missing or there are no common present coordinates, NaN is returned. The function returns squared Euclidean distances and makes a deep copy of X and Y. It computes the distances between row vectors of X and Y, using a specified metric such as \"euclidean\" or \"manhattan\". Additionally, it computes paired L1 distances between X and Y. Another function computes the polynomial kernel between X and Y, with options for kernel degree, coefficient of the vector inner product, and constant offset. References to relevant literature are provided for further reading. The functions provided include computing the sigmoid kernel between two arrays, as well as finding the minimum distances between a point and a set of points. The sigmoid kernel function calculates the kernel between X and Y using a specified formula. The minimum distances function determines the closest row in Y for each row in X based on a specified distance metric. It works with dense 2D arrays and allows for various distance metrics to be used. Additionally, it is more memory-efficient and faster for large arrays compared to other methods. The functions offer flexibility in choosing the metric and provide options for passing keyword arguments to the specified metric function. The function allows for the generation of a distance matrix chunk by chunk with optional reduction. It calculates pairwise distances in working_memory-sized chunks and can apply a specified function on each chunk to reduce it to needed values. The output is an array of pairwise distances between samples or a feature array, with the shape of the array dependent on the metric used. The metric can be a string specifying a distance calculation method or a callable function. The computation can be parallelized using the number of jobs parameter, and the maximum memory for temporary distance matrix chunks can be specified. Additional parameters are passed directly to the distance function. Without reduction, the function can retrieve all neighbors and average distance within a specified radius, or force row-by-row generation by reducing working_memory. The Confusion Matrix visualization function allows for the creation of a ConfusionMatrixDisplay using either from_estimator or from_predictions. This function provides the ability to display labels for the plot, includes values in the confusion matrix, and allows for customization such as rotation of xtick labels and colormap selection. It can be used to evaluate the accuracy of a classification by plotting the confusion matrix given an estimator, data, and labels. Additionally, it supports the normalization of counts in the matrix and the use of sample weights. The function requires input values, target values, and a list of labels to index the confusion matrix. It also allows for the specification of target names for plotting. The function returns a ConfusionMatrixDisplay instance that contains all the necessary information to plot the confusion matrix effectively. The Precision Recall visualization function allows for the creation of precision-recall curves using either an estimator or predictions from a binary classifier. It provides options to customize the plot, such as specifying the positive class, labeling the curve, and plotting the chance level. The function also includes notes on how the average precision is computed and plotted without interpolation to maintain consistency with the metric. Additional features added in version 1.3 include the ability to drop suboptimal thresholds for lighter curves and choose between predict_proba and decision_function for target response. Overall, the function offers a comprehensive tool for visualizing precision-recall curves in scikit-learn. The ROC Curve visualization function allows for the creation of ROC curves using either an estimator or predictions. It includes parameters such as false positive rate, true positive rate, area under the ROC curve, estimator name, positive class designation, chance level line, axes with ROC curve, and more. The function can be used to plot ROC curves, compute the area under the curve, and create visualizations based on probabilities or true/predicted values. Additional options include specifying the positive class label, dropping suboptimal thresholds, and customizing the plot appearance. The function is versatile and provides detailed insights into classifier performance. The DET curve visualization function allows for the plotting of Detection Error Tradeoff (DET) curves. It is recommended to use the from_estimator or from_predictions methods to create a visualizer. All parameters are stored as attributes and include the false positive rate, false negative rate, name of the estimator, label of the positive class, input values, target values, sample weights, and more. The function can plot the DET curve given an estimator and some data, true and predicted labels, or just an estimator and data. It requires a fitted classifier or Pipeline where the last estimator is a classifier. The target scores can be probability estimates, confidence values, or non-thresholded decisions. Additional parameters can be passed for customization, and the function also provides options for labeling the DET curve. This function is useful for visualizing error rates at different probability thresholds. ",
    "sklearn.mixture": "The Variational Bayesian estimation of a Gaussian mixture is a class that allows for inferring an approximate posterior distribution over the parameters of a Gaussian mixture distribution. It implements two types of prior for the weights distribution: a finite mixture model with a Dirichlet distribution and an infinite mixture model with the Dirichlet Process. The number of components used can be inferred from the data, and the model can decide not to use all components based on the data and weight concentration prior. The convergence threshold, regularization, number of EM iterations, and initializations can be specified. The method used to initialize weights, means, and covariances can be set. The weight concentration prior, precision prior on the mean distribution, and other priors can be adjusted. The model can be fitted using the EM algorithm, and parameters can be set and predicted using the trained model. Random samples can be generated, and the log-likelihood of the data under the model can be computed. The model also allows for evaluating component density, computing log-likelihood, and setting parameters. The class provides a comprehensive framework for fitting Gaussian mixture models and making predictions based on the data. ",
    "sklearn.model_selection": "The K-fold iterator variant with non-overlapping groups ensures that each group appears exactly once in the test set across all folds, with approximately balanced folds in terms of sample numbers. The number of folds must be at least 2, with the default value changed to 5 in version 0.22. This function takes class information into account to avoid imbalanced class proportions when splitting data for binary or multiclass classification tasks. Groups appear in an arbitrary order throughout the folds. Metadata routing can be requested for this object, with options to specify how metadata is handled. This function is relevant when used as a sub-estimator of a meta-estimator, such as inside a Pipeline. The function also generates indices to split data into training and test sets, considering the target variable and group labels. The K-Fold cross-validator function provides train/test indices to split data into train/test sets by splitting the dataset into k consecutive folds. Each fold is used once as a validation set while the remaining folds form the training set. The number of folds must be at least 2, with the default value changed from 3 to 5 in version 0.22. The function can shuffle the data before splitting into batches, with the option to set a random state for reproducible output. It takes class information into account to avoid imbalanced class distributions and has a variant for non-overlapping groups. The function also generates indices to split data into training and test sets, with options for metadata routing. Randomized CV splitters may return different results, but setting a random state integer can make the results identical. The Leave-One-Out cross-validator provides train/test indices to split data into train/test sets, where each sample is used once as a test set while the remaining samples form the training set. It is equivalent to KFold(n_splits=n) and LeavePOut(p=1) where n is the number of samples. However, due to the high number of test sets, which is the same as the number of samples, this method can be costly for large datasets. For such cases, it is recommended to use KFold, ShuffleSplit, or StratifiedKFold. \n\nOn the other hand, the Leave-P-Out cross-validator also provides train/test indices to split data into train/test sets, resulting in testing on all distinct samples of size p while the remaining n - p samples form the training set in each iteration. It is important to note that LeavePOut(p) is not equivalent to KFold(n_splits=n_samples // p) as it creates non-overlapping test sets. Similar to Leave-One-Out, this method can be costly for large datasets, and it is advised to use KFold, StratifiedKFold, or ShuffleSplit instead. \n\nBoth cross-validators return the number of splitting iterations, generate indices to split data, and provide metadata routing information. The training data includes the number of samples and features, while the target variable is for supervised learning problems. The training set indices and testing set indices are also returned for each split. The Repeated K-Fold cross validator function repeats K-Fold n times with different randomization in each repetition. It requires a minimum of 2 folds and allows for control over the randomness of each repetition. It can also be used with a random state parameter for reproducible output. The function can also be used with Stratified K-Fold and provides metadata routing information. Additionally, it returns the number of splitting iterations in the cross-validator and generates indices to split data into training and test sets, considering group labels and the target variable for supervised learning problems. It also provides training and testing set indices for each split. The random permutation cross-validator function yields indices to split data into training and test sets. It does not guarantee that all folds will be different, but this is likely for sizeable datasets. The function allows for specifying the number of re-shuffling and splitting iterations, as well as controlling the randomness of the training and testing indices. Additionally, it provides metadata routing information and the number of splitting iterations. The function generates indices for splitting data into training and test sets, considering the number of samples and features, as well as the target variable for supervised learning. It returns the training and testing set indices for each split. The Stratified K-Fold cross-validator is a variation of KFold that returns stratified folds, preserving the percentage of samples for each class. It provides train/test indices to split data and is designed to generate test sets with the same distribution of classes, be invariant to class label changes, preserve order dependencies, and ensure that the smallest and largest test sets differ by at most one sample. The implementation is now updated to follow this constraint. The object also allows for metadata routing and returns the number of splitting iterations. It generates indices to split data into training and test sets based on the target variable for supervised learning problems, with stratification done based on the y labels. Randomized CV splitters may return different results, but setting random_state to an integer can make the results identical. The Time Series cross-validator is a variation of KFold that provides train/test indices to split time series data samples observed at fixed time intervals. In each split, the test indices must be higher than before, making shuffling inappropriate. The cross-validation object returns the first k folds as the train set and the (k+1)th fold as the test set. Successive training sets are supersets of those that come before them. The number of splits must be at least 2, with the default value changed from 3 to 5 in version 0.22. The maximum size for a single training set can be limited to the size of the test set. The training set size in each split is determined by the number of samples and splits. The object also provides metadata routing information and the ability to generate indices to split data into training and test sets based on the number of samples and features. The function `train_test_split` allows for the splitting of arrays or matrices into random train and test subsets. It provides a quick utility that includes input validation, shuffling, and application to input data in a single call. The function can handle various input types such as lists, numpy arrays, scipy-sparse matrices, or pandas dataframes. Users can specify the proportion or absolute number of samples for the test and train splits. Additionally, the function allows for control over shuffling and stratification of the data. The output will be a list containing the train-test split of inputs, with the option for the output to be a sparse matrix if the input is sparse. The Shuffle-Group(s)-Out cross-validation iterator provides randomized train/test indices for splitting data based on a third-party provided group. This allows for encoding domain-specific stratifications of samples. The difference between LeavePGroupsOut and GroupShuffleSplit is that the former generates splits using all subsets of a specified size p unique groups, while the latter generates a user-determined number of random test splits with a user-determined fraction of unique groups. The parameters test_size and train_size refer to groups, not samples. The number of re-shuffling and splitting iterations can be controlled. Metadata routing can be enabled for passing metadata to the split method. The object can generate indices to split data into training and test sets, with options for training data, target variables, group labels, training set indices, and testing set indices. Randomized CV splitters may return different results, but setting random_state to an integer can make the results identical. The Leave One Group Out cross-validator provides train/test indices to split data such that each training set includes all samples except those belonging to one specific group. This is useful for scenarios where domain-specific group information is available, such as the year of sample collection, allowing for time-based cross-validation. Splits are ordered based on the index of the group left out, with the first split having the testing set consisting of the group with the lowest index. The number of splitting iterations can be obtained, and metadata routing can be enabled to pass metadata to the split method. The options for metadata routing include requesting metadata, not requesting it, or specifying an alias for the metadata. This method is relevant when the estimator is used as a sub-estimator of a meta-estimator, such as inside a Pipeline. The object can be updated, and indices can be generated to split data into training and test sets, with the training set including the target variable for supervised learning problems and group labels for the samples used in the split. The Leave P Group(s) Out cross-validator provides train/test indices to split data based on a third-party provided group, allowing for domain-specific stratifications. It differs from LeaveOneGroupOut by building test sets with samples assigned to p different values of the groups. The number of groups to leave out in the test split can be specified. Metadata routing can be enabled to pass metadata to the split method. This method is relevant when the estimator is used as a sub-estimator of a meta-estimator. The function generates indices to split data into training and test sets, considering group labels for the samples. The training set and testing set indices for each split are returned. The functions described include a Predefined split cross-validator, which provides train/test indices based on a predefined scheme specified by the user. It allows for excluding samples from test sets and includes metadata routing information. There is also a Repeated Stratified K-Fold cross validator, which repeats the Stratified K-Fold process multiple times with different randomization. It requires a minimum of 2 folds and allows for controlling random states for reproducibility. The functions also involve generating indices for splitting data into training and test sets, as well as handling group labels and target variables for supervised learning. Compatibility placeholders are mentioned, along with the option to make results identical by setting a random state integer. The StratifiedGroupKFold is a cross-validation object that creates non-overlapping folds with stratified sampling based on group labels. It aims to preserve the percentage of samples for each class while ensuring that each group appears exactly once in the test set across all folds. This variant is different from GroupKFold as it focuses on maintaining class distributions within folds. The implementation is designed to mimic the behavior of StratifiedKFold for trivial groups and is invariant to class label relabeling. It takes into account class information to build folds and retains class distributions. The method also allows for metadata routing and enables the generation of indices to split data into training and test sets based on group labels. Overall, the StratifiedGroupKFold is a useful tool for cross-validation in scenarios where maintaining class distributions and group integrity is important. The Stratified ShuffleSplit cross-validator is a combination of StratifiedKFold and ShuffleSplit, providing train/test indices for splitting data into sets while preserving the percentage of samples for each class. It does not guarantee different folds each time, but is likely for large datasets. The number of re-shuffling and splitting iterations can be controlled, with options for test and train split proportions or absolute numbers. Randomness can be controlled for reproducible output. Metadata routing information can be accessed, and the number of splitting iterations can be returned. Indices are generated for training and testing sets based on the target variable, with stratification based on the labels. Randomized CV splitters may return different results, but setting a random_state integer can make the results identical. The input checker utility for building a cross-validator determines the cross-validation splitting strategy. Possible inputs for cv include None for the default 5-fold cross-validation, an integer to specify the number of folds, a CV splitter, or an iterable that generates (train, test) splits as arrays of indices. If the input is an integer or None and the classifier is True with a binary or multiclass target variable, StratifiedKFold is used; otherwise, KFold is used. The return value is a cross-validator that generates the train/test splits via the split method. The default value for cv changed from 3-fold to 5-fold in version 0.22. Refer to the User Guide for more information on the various cross-validation strategies available. GridSearchCV is a function that performs an exhaustive search over specified parameter values for an estimator. It implements methods like fit, predict, predict_proba, decision_function, transform, and inverse_transform. The parameters of the estimator are optimized by cross-validated grid-search over a parameter grid. It evaluates the performance of the cross-validated model on the test set using a specified scoring strategy. The number of jobs to run in parallel can be controlled, and the best found parameters can be used to refit the estimator on the whole dataset. The function also provides information on the best estimator, mean cross-validated score, best parameter setting, and scorer function used. It supports multiple metric evaluation and provides detailed results in a dictionary format. Additionally, it allows for custom refit strategies and provides options for controlling verbosity and job dispatching during parallel execution. The function also handles errors that may occur during fitting and provides insights on overfitting/underfitting trade-offs. It offers various options for splitting the data, making a scorer, and getting metadata routing information. Overall, GridSearchCV is a comprehensive tool for hyperparameter tuning and model evaluation. The HalvingRandomSearchCV function performs a randomized search on hyperparameters by evaluating candidates with increasing resources. Candidates are sampled randomly from the parameter space, with the number of candidates determined by n_candidates. The search strategy iteratively selects the best candidates using more resources. The function is experimental and may change without deprecation. To use it, enable_halving_search_cv must be explicitly imported. The function requires a dictionary with parameter names and distributions or lists of parameters to try. The 'halving' parameter determines the proportion of candidates selected for each iteration. The function also defines the resources that increase with each iteration and the maximum and minimum resources allowed for each candidate. The cross-validation splitting strategy, scoring, and number of jobs to run in parallel can also be specified. The function provides information on the best estimator, mean cross-validated score, best parameter setting, and more. Additionally, it allows for decision making, prediction, and transformation based on the best found parameters. The function is a generator that samples parameters from given distributions for hyper-parameter search. It can handle both lists and distributions for parameters, with the option for sampling with or without replacement. Continuous distributions are recommended for continuous parameters. The function yields dictionaries mapping each estimator parameter to a sampled value, with the ability to control the random number generator state for reproducible output. It is important to read more in the User Guide for detailed information on how to use this function effectively. The HalvingGridSearchCV function allows for searching over specified parameter values with successive halving, starting with a small amount of resources and iteratively selecting the best candidates. This process involves defining parameters, resource allocation, cross-validation splitting strategy, scoring, refitting, and various other options. The function provides detailed information on the search process, the selected estimator, cross-validated scores, best parameter settings, and more. It also allows for predicting, scoring, transforming, and accessing metadata of the estimator with the best found parameters. The function aims to maximize the score of the held-out data based on the specified scoring parameter. It is important to note that some features may be deprecated or removed in future versions, so it is recommended to refer to the User Guide for the most up-to-date information. The Grid function allows for the creation of a grid of parameters with specific values for each parameter. This grid can be used to iterate over different combinations of parameter values using the iter function in Python. The order of the generated parameter combinations is deterministic. The function takes in a dictionary mapping estimator parameters to sequences of allowed values. An empty dictionary signifies default parameters, while a sequence of dictionaries signifies a sequence of grids to search. This can be useful to avoid exploring parameter combinations that are not meaningful. The function also utilizes ParameterGrid to perform a full parallelized parameter search. RandomizedSearchCV is a function that implements a randomized search on hyperparameters. It optimizes the parameters of the estimator used by cross-validated search over parameter settings. Unlike GridSearchCV, it samples a fixed number of parameter settings from specified distributions instead of trying out all values. It is recommended to use continuous distributions for continuous parameters. The function provides methods such as fit, score, score_samples, predict, predict_proba, decision_function, transform, and inverse_transform. It allows for parallel execution, refitting the estimator using the best parameters, and evaluating the performance of the cross-validated model on the test set. The function also supports multiple metric evaluation, provides information on the best estimator, mean cross-validated score, best parameter setting, and more. Additionally, it offers options for controlling verbosity, number of jobs dispatched during parallel execution, and setting a random number generator state for reproducibility. It handles errors during estimator fitting and provides insights on overfitting/underfitting trade-offs. The function outputs a dictionary with parameter settings and performance metrics that can be imported into a pandas DataFrame for analysis. It also allows for decision-making based on the best model, prediction, transformation, and scoring on new data. The Binary classifier allows manual setting of the decision threshold, which can be used to convert posterior probability estimates or decision scores into class labels. The threshold can be set to a constant value and is not optimized. The positive class label can be specified, and the classifier estimator can be fitted to optimize the decision threshold. The classifier also provides methods for predicting, fitting, calibrating probabilities, and computing decision functions. Additionally, it offers functionality for retrieving metadata, setting parameters, and requesting metadata routing. The classifier can predict class labels, logarithm class probabilities, and class probabilities for new samples. It can also calculate the mean accuracy on test data and set parameters accordingly. The object can be updated with new parameters and metadata routing for sample weights in scoring. The TunedThresholdClassifierCV is a classifier that post-tunes the decision threshold using cross-validation. It optimizes a binary metric, potentially constrained by another metric, to convert posterior probability estimates or decision scores into class labels. The user can specify the classifier, objective metric, decision function method, number of thresholds, cross-validation strategy, number of parallel jobs, and randomness control. The classifier can be refit on the entire training set once the optimal threshold is found. The class also provides methods for fitting the classifier, predicting class labels, predicting logarithm class probabilities, predicting class probabilities, calculating mean accuracy, setting parameters, and requesting metadata. Additionally, it includes information on classes labels, decision functions, training data, target values, sample weights, and metadata routing. The function generates cross-validated estimates for each input data point by splitting the data according to the specified parameter. Each sample is assigned to a test set and its prediction is made using an estimator fitted on the corresponding training set. It is important to note that passing these predictions into an evaluation metric may not accurately measure generalization performance. The estimator instance used must implement a fit method and the specified method parameter. The data to fit can be in the form of a list or an array with at least 2 dimensions. The target variable for prediction in supervised learning should also be provided. Group labels can be used for splitting the dataset when working with a \"Group\" cv instance. The cross-validation splitting strategy can be determined by specifying the cv parameter, which can take various inputs such as None, an integer for the number of folds, or a CV splitter. The number of jobs to run in parallel can be controlled, with None meaning 1 job unless in a parallel context, and -1 using all available processors. The verbosity level and parameters to pass to the fit method of the estimator can also be specified. It is important to note that some parameters are deprecated and will be removed in future versions. The method to be invoked by the estimator should also be specified, with different shapes for different methods. Additionally, scores and timings can be calculated for each CV split. In cases where one or more classes are absent in a training portion, a default score needs to be assigned to all instances for that class. The cross_validate function in sklearn is used to evaluate metrics by cross-validation and record fit/score times. It requires the object to fit the data, the data itself, and the target variable to predict in supervised learning. Group labels can be used for splitting the dataset with a \"Group\" cv instance. The function allows for specifying the performance evaluation strategy, cross-validation splitting strategy, number of parallel jobs, verbosity level, and other parameters. It also provides options to include train scores, return estimators fitted on each split, return train-test indices, and handle errors during fitting. The function returns an array of scores for each run of cross-validation, including test scores, train scores, fitting times, and scoring times. Additionally, it can return estimator objects for each split and train/test positional indices. The function supports single metric evaluation as well as multiple metric evaluation. Refer to the User Guide for more information on the various cross-validation strategies available. The function evaluates the significance of a cross-validated score with permutations by permuting targets to generate 'randomized data' and computing the empirical p-value against the null hypothesis that features and targets are independent. The p-value indicates the fraction of randomized data sets where the estimator performed as well or better than in the original data, suggesting a real dependency between features and targets if small. The function allows for fitting data, specifying target variables, labels for permutation within groups, determining cross-validation splitting strategy, specifying the number of permutations, running jobs in parallel, setting verbosity level, defining scoring rules, passing parameters to the fit method, and obtaining the true score without permuting targets. The p-value is calculated based on the number of permutations whose score is greater than or equal to the true score. This function is based on Test 1 in Ojala and Garriga's Permutation Tests for Studying Classifier Performance. The function allows for evaluating a score by cross-validation, fitting the data using a specified object, and predicting a target variable in supervised learning. It also supports group labels for splitting the dataset, a specified scoring method, and various cross-validation splitting strategies. The number of jobs to run in parallel, verbosity level, and parameters to pass to the fit method are customizable. Additionally, it controls the number of jobs dispatched during parallel execution and handles errors that may occur during fitting. The function returns an array of scores for each run of cross-validation and allows for getting predictions from each split for diagnostic purposes. The Learning curve function determines cross-validated training and test scores for different training set sizes. It involves splitting the dataset into training and test data subsets, training the estimator with varying training set sizes, and computing scores for each size. The scores are then averaged over multiple runs. The function requires a training vector, target values for classification or regression, and group labels for splitting the dataset. It allows for specifying the number of training examples, the cross-validation strategy, and the number of parallel jobs. Additionally, it supports incremental learning and provides options for handling errors during fitting. The function can also return fit and score times. The Validation curve function allows for determining training and test scores for varying parameter values of an estimator. It is similar to grid search with one parameter but also computes training scores, making it a utility for plotting results. The function requires an object that is cloned for each validation and must implement \"predict\" unless scoring is a callable that doesn't rely on \"predict\" for scoring. It takes into account the training vector, target relative to X for classification or regression, the parameter to be varied, the values of the parameter to be evaluated, group labels for dataset splitting, and the cross-validation splitting strategy. The number of jobs to run in parallel can be specified, as well as the verbosity level and handling of errors during fitting. Additionally, parameters can be passed to the fit method of the estimator. The function provides scores on both training and test sets, and more information can be found in the User Guide under Plotting Validation Curves. The Learning Curve visualization function allows for the creation of a LearningCurveDisplay instance using an estimator. It provides information on the number of training examples used, scores on training and test sets, and the name of the score used. The function also allows for customization of axes and figure styles. It supports different cross-validation strategies, scoring parameters, and parallel execution. Additional parameters can be passed to the fit method of the estimator, and the function provides options for controlling verbosity and shuffling of training data. The function can plot the mean score and standard deviation, with options to customize the display style. Overall, the Learning Curve visualization function is a comprehensive tool for analyzing the performance of machine learning models. ",
    "sklearn.multiclass": "The One-vs-One multiclass strategy involves fitting one classifier per class pair and selecting the class with the most votes at prediction time. This method is slower than one-vs-the-rest due to the need to fit n_classes * (n_classes - 1) / 2 classifiers, but it can be advantageous for algorithms like kernel algorithms. The decision function for the OneVsOneClassifier computes decision values by adding the normalized sum of pair-wise classification confidence levels to the votes to resolve ties. The estimator can be used for both regression and classification tasks, with the number of jobs determining the parallel computation of OVO problems. The fit method trains the underlying estimators, while predict estimates the best class label for each sample. The score method returns the mean accuracy on test data, and set_params allows for updating the estimator parameters. Metadata routing can be requested for partial_fit and score methods if enable_metadata_routing is set to True. The (Error-Correcting) Output-Code multiclass strategy is a method where each class is represented by a binary code, with one binary classifier per bit in the code book fitted at training time. This strategy allows for control over the number of classifiers used, with options for compressing the model or making it more robust to errors. The strategy requires the percentage of classes to be used to create the code book, a generator for initializing the codebook, and the number of jobs to use for parallel computation. The strategy fits underlying estimators, predicts multi-class targets, and returns the mean accuracy on test data. It also allows for setting parameters of the estimator and requesting metadata passed to the score method. The strategy is based on research papers and can be further explored in the User Guide. ",
    "sklearn.multioutput": "The ClassifierChain is a multi-label model that arranges binary classifiers into a chain, with each model making predictions in the order specified by the chain. The order of the chain can be explicitly set, and cross validated predictions or true labels can be used for the results of previous estimators in the chain. The prediction method to be used by estimators in the chain can also be specified. The chain progress can be output as each model is completed. The decision function of the models in the chain can be evaluated, and the model can be fit to data matrix X and targets Y. Metadata routing can be enabled for this model, and parameters can be set for the estimator. The model can predict on input data, predict logarithm of probability estimates, predict probability estimates, and return the mean accuracy on the given test data and labels. The parameters of the estimator can be set, and metadata routing can be requested for the score method. The MultiOutputRegressor strategy involves fitting one regressor per target, making it a simple way to extend regressors that do not support multi-target regression. This strategy parallelizes the fit, predict, and partial_fit functions for each target, with the option to run in parallel using multiple jobs. The number of features seen during fit, as well as the names of features seen during fit, are also tracked. The model classifies each output independently rather than chaining them together. Sample weights can be used if the underlying regressor supports them. The coefficient of determination \\(R^2\\) is used to evaluate the prediction, with a score of 1.0 being the best possible. Metadata routing can be used to pass metadata to the fit, partial_fit, and score methods. This strategy is only relevant when the estimator is used as a sub-estimator of a meta-estimator, such as inside a Pipeline. Overall, the MultiOutputRegressor provides a flexible and efficient way to handle multi-output regression tasks. The MultiOutputClassifier strategy involves fitting one classifier per target, making it a simple strategy for extending classifiers that do not natively support multi-target classification. This strategy parallelizes the fit, predict, and partial_fit methods for each target, with the option to specify the number of jobs to run in parallel. The class labels, estimators used for predictions, number of features seen during fit, and names of features seen during fit are all important components of this strategy. Additionally, a MetadataRouter encapsulating routing information can be obtained, and parameters for the estimator can be retrieved. Incremental fitting of a separate model for each class output is supported, as well as predicting multi-output variables using models for each target variable. The mean accuracy on test data and labels can be calculated, and metadata can be requested and passed to the fit and partial_fit methods. This strategy also allows for setting parameters of the estimator and routing metadata for sample_weight and classes parameters in fit and partial_fit methods. ",
    "sklearn.naive_bayes": "The Naive Bayes classifier for multivariate Bernoulli models is suitable for discrete data with binary/boolean features. It uses additive smoothing and can handle class prior probabilities. The classifier can be trained incrementally on batches of samples and can perform classification and probability estimation on test data. It also provides methods for metadata routing and parameter setting. Additionally, it references other Naive Bayes classifiers such as GaussianNB and Complement Naive Bayes. The model is based on research by Manning, Raghavan, Schuetze, McCallum, Nigam, Metsis, Androutsopoulos, and Paliouras. The classifier is designed for text classification and spam filtering applications. The Complement Naive Bayes classifier is a variant of the standard Multinomial Naive Bayes classifier designed to handle imbalanced data sets by correcting the assumptions made by the standard classifier. It includes an additive smoothing parameter for Laplace/Lidstone smoothing, with the option to force alpha to a minimum value to avoid numerical errors. The classifier also considers prior probabilities of classes, weights normalization, and empirical log probabilities for each class. It keeps track of the number of samples and features encountered during fitting, as well as the names of features. The classifier can be incrementally fit on batches of samples and used for classification and probability estimation. It also provides methods for metadata routing, parameter setting, and scoring. The implementation follows the algorithm described in a paper by Rennie et al. (2003) and is available in scikit-learn starting from version 0.20. The Naive Bayes classifier for multinomial models is suitable for classification with discrete features, such as word counts for text classification. It can handle fractional counts like tf-idf. The classifier supports additive smoothing with the Laplace/Lidstone parameter. Prior probabilities of classes can be learned or set to a uniform prior. The classifier can be fit according to training data, and incremental fitting is supported for out-of-core or online learning. Classification and probability estimation methods are available, along with metadata routing options. The classifier also supports setting and getting parameters, as well as requesting metadata for fitting, partial fitting, and scoring. Other variations of Naive Bayes classifiers are also available, such as for multivariate Bernoulli models, categorical features, complement Naive Bayes, and Gaussian Naive Bayes. References to further reading on the topic are provided. The Naive Bayes classifier for categorical features is suitable for classification with discrete features that are categorically distributed. It includes options for additive smoothing, learning class prior probabilities, setting the minimum number of categories per feature, and providing empirical log probabilities for each class. The classifier can be fit according to training vectors and target values, and can also be incrementally fit on a batch of samples for out-of-core or online learning. Additionally, it offers methods for performing classification, returning probability estimates, and calculating accuracy on test data. Metadata routing can be requested for various parameters, and the estimator parameters can be set accordingly. This classifier is part of a family of Naive Bayes classifiers that includes models for multivariate Bernoulli, complement, Gaussian, and multinomial distributions. ",
    "sklearn.neighbors": "The BallTree function provides a fast solution for generalized N-point problems. It allows for efficient querying of nearest neighbors, kernel density estimation, auto-correlation functions, and more. The function supports various distance metrics, kernel types, and search strategies. Users can specify parameters such as leaf size, tolerance levels, and sorting preferences. Additionally, the function offers options for resetting computations and utilizing dual tree algorithms for improved performance on large datasets. The k-nearest neighbors classifier is a versatile algorithm that can be used for both classification and regression tasks. It works by finding the k-nearest neighbors to a given data point and using their labels or values to make predictions. The algorithm allows for customization through parameters such as the number of neighbors to consider, the weight function used in prediction, and the algorithm used to compute the nearest neighbors. Additionally, users can specify the distance metric to be used, the number of parallel jobs to run for neighbors search, and other optional keyword arguments for the metric function. The classifier also provides methods for fitting the model, finding the k-neighbors of a point, computing the (weighted) graph of neighbors for points in the dataset, predicting class labels, returning probability estimates, and evaluating the accuracy of the model. The algorithm supports metadata routing, enabling users to request and pass metadata to the score method. Overall, the k-nearest neighbors classifier is a powerful tool for machine learning tasks that require finding similar data points in a dataset. The KNeighborsTransformer function transforms data into a (weighted) graph of k nearest neighbors, returning a sparse graph. The number of neighbors for each sample can be specified, with an extra neighbor computed when mode is set to 'distance'. Various algorithms can be used to compute the nearest neighbors, such as BallTree or KDTree. The metric for distance computation can be customized, with options for additional keyword arguments. The function also allows for parallel jobs to be run for neighbor search. The transformed data includes features seen during fit, and the output feature names are prefixed by the class name. The function can also find the K-neighbors of a point, returning indices and distances to the neighbors. Additionally, the function can compute the (weighted) graph of neighbors for points in X, with options for different output formats such as 'pandas' or 'polars'. The parameters of the estimator can be set and the function can be used to fit and transform data. The Local Outlier Factor (LOF) is a method for unsupervised outlier detection. It calculates the anomaly score of each sample based on its local density compared to its neighbors. The number of neighbors used for calculations can be specified, as well as the algorithm used for nearest neighbor computation. The metric for distance computation can also be customized. Additionally, the amount of contamination in the dataset can be defined to set the threshold for outlier detection. The LOF score indicates the degree of abnormality of a sample, with higher scores indicating outliers. The LOF can be used for novelty detection by setting the novelty parameter to True. The opposite LOF score can also be calculated for novelty detection. The fit method trains the LOF detector, while the predict method assigns labels to new samples. The NearestNeighbors class can be used to find the k-nearest neighbors of a point. The LOF method can be used to predict labels for new data points, with negative scores indicating outliers and positive scores indicating inliers. The Nearest Neighbors module in scikit-learn provides functionality for implementing neighbor searches in an unsupervised manner. It allows for finding the nearest neighbors based on a specified algorithm such as 'ball_tree', 'kd_tree', or 'brute'. The number of neighbors and parameter space can be customized, along with the leaf size for the tree structure. Various metrics can be used for distance computation, with options for parallel processing and additional keyword arguments. The module also includes functions for fitting the estimator, finding K-neighbors of a point, computing the graph of neighbors, and identifying neighbors within a given radius. The results can include indices, distances, and connectivity information. Additionally, the module supports metadata routing, parameter retrieval, and parameter setting for the estimator. Overall, the Nearest Neighbors module offers a comprehensive set of tools for conducting neighbor searches and analyzing relationships within a dataset. The Radius Neighbors Classifier is a classifier that implements a vote among neighbors within a given radius. It uses a range of parameter space for radius_neighbors queries and a weight function for prediction, with options for uniform weights, distance-based weights, or a user-defined function. The algorithm used to compute the nearest neighbors can be specified, such as BallTree, KDTree, or brute force. Other parameters include leaf size, power parameter for the Minkowski metric, metric for distance computation, label for outlier samples, number of parallel jobs, class labels, distance metric used, number of features seen during fit, names of features seen during fit, number of samples in the fitted data, and more. The classifier can be used for regression based on neighbors within a fixed radius, regression based on k-nearest neighbors, and unsupervised learning for neighbor searches. Methods include fitting the classifier, getting metadata routing, getting parameters, predicting class labels, returning probability estimates, finding neighbors within a given radius, computing the graph of neighbors, and setting parameters. The classifier also allows for computing the graph of k-neighbors, returning the mean accuracy on test data, and setting parameters of the estimator. Additionally, metadata routing can be requested for the score method. The function allows for transforming data into a (weighted) graph of neighbors within a specified radius. The transformed data is returned as a sparse graph. The algorithm used to compute the nearest neighbors can be specified, with options including 'ball_tree', 'kd_tree', 'brute', or 'auto'. Additional parameters such as leaf size, metric for distance computation, number of parallel jobs, and feature names can also be specified. The function can find neighbors within a given radius of a point or points, returning the indices and distances of each point. The function also allows for setting output container and configuring output format. Additionally, the function can set parameters of the estimator and compute the (weighted) graph of neighbors for points in the data set. The function computes the (weighted) graph of neighbors for points in X, with neighborhoods restricted to points at a distance lower than a specified radius. The type of returned matrix can be either 'connectivity' or 'distance', with the option to specify the metric for distance computation. Additional parameters include the power parameter for the Minkowski metric, keyword arguments for the metric function, and the option to mark each sample as the first nearest neighbor to itself. The function also allows for parallel jobs to run for neighbor search. The resulting graph is represented as a matrix in CSR format. The KDTree function provides a fast generalized N-point solution for various problems. It allows for efficient querying of nearest neighbors, kernel density estimation, auto-correlation functions, and more. The function parameters include the number of points in the dataset, the dimension of the parameter space, the leaf size for switching to brute-force, and the distance metric for computation. Additional functionalities include pickling and unpickling the tree, querying for neighbors within a radius, computing the two-point correlation function, and resetting the number of distance computation calls. The function also offers options for specifying the kernel, absolute and relative tolerance, search strategy (breadth-first or depth-first), and sorting results. Overall, the KDTree function provides a versatile tool for various data analysis tasks. The k-nearest neighbors algorithm is used for regression based on local interpolation of targets associated with the nearest neighbors in the training set. The number of neighbors to consider, the weight function used in prediction, and the algorithm for computing nearest neighbors can all be specified. Different distance metrics can be used, such as Euclidean or Manhattan distance. The algorithm can also be used for classification tasks, where a vote is taken among neighbors. The fit method trains the regressor on the training data, and the predict method can be used to make predictions on test samples. The score method returns the coefficient of determination \\(R^2\\), which measures the goodness of fit of the model. Additional functionalities include finding the k-neighbors of a point, computing the graph of neighbors, and setting parameters of the estimator. Metadata routing can be used to request additional information during scoring. Kernel Density Estimation is a method used to estimate the probability density function of a random variable. It involves specifying the bandwidth of the kernel, the tree algorithm to use, the kernel type, and the metric for distance computation. The normalization of the density output is correct only for the Euclidean distance metric. Additional parameters can be passed to the tree for use with the metric. The algorithm can use a breadth-first or depth-first approach, and the leaf size of the underlying tree can be specified. The model can be fit on data points, and random samples can be generated using gaussian or tophat kernels. The total log-likelihood under the model can be computed, as well as the log-likelihood of each sample. Metadata routing can be requested for the fit method, and parameters of the estimator can be set. This method is relevant when the estimator is used as a sub-estimator of a meta-estimator, such as inside a Pipeline. The Nearest Centroid classifier is a classification algorithm where each class is represented by its centroid, and test samples are classified to the class with the nearest centroid. The centroid for each class can be computed using different metrics such as \"euclidean\" or \"manhattan\". In the latest versions, only \"euclidean\" and \"manhattan\" metrics are supported. The classifier can be used for text classification with tf-idf vectors, known as the Rocchio classifier. References for this classifier include a paper by Tibshirani et al. (2002) on cancer diagnosis using gene expression centroids. The model can be fitted to training data and used to predict classes for test samples. The accuracy of the model can be evaluated using the mean accuracy on test data. The parameters of the estimator can be set and retrieved, and metadata routing can be requested for the object. This classifier is not compatible with sparse matrices due to centroid shrinking. Neighborhood Component Analysis (NCA) is a machine learning algorithm for metric learning that improves classification accuracy by learning a linear transformation in a supervised manner. The preferred dimensionality of the projected space can be specified, and there are various options for the initialization of the linear transformation, such as 'auto', 'pca', 'lda', 'identity', 'random', or a numpy array. The number of principal components used for initialization depends on the specified number of components and classes. The optimization process has parameters for maximum iterations and convergence tolerance. The random state can be set for reproducibility. The learned linear transformation, number of features seen during fit, and number of iterations performed by the optimizer are available attributes. The algorithm can fit the model to training data, transform data, get output feature names, metadata routing, parameters, set output container, set estimator parameters, and apply the learned transformation to new data. References to related work and additional resources are provided. The Radius Neighbors Regressor is a regression model based on neighbors within a fixed radius. It predicts the target by interpolating the targets of the nearest neighbors in the training set. The algorithm used to compute the nearest neighbors can be specified, such as 'ball_tree', 'kd_tree', or 'brute'. The weight function used in prediction can be set to 'uniform', 'distance', or a user-defined function. Additional parameters like leaf size, power parameter for the Minkowski metric, and metric for distance computation can also be adjusted. The model can be fitted with training data and used to predict target values. The coefficient of determination (R^2) can be calculated to evaluate the model's performance. The model parameters can be set and metadata routing can be requested for the estimator. Overall, the Radius Neighbors Regressor provides a flexible and customizable approach to regression based on k-nearest neighbors within a specified radius. ",
    "sklearn.neural_network": "The Bernoulli Restricted Boltzmann Machine (RBM) is a model with binary visible and hidden units, estimated using Stochastic Maximum Likelihood (SML) or Persistent Contrastive Divergence (PCD). The time complexity is O(d ** 2) assuming d ~ n_features ~ n_components. It is recommended to tune hyper-parameters like the learning rate and number of hidden units. The model involves biases, weight matrix, and hidden activation sampling. It can be fit to data, transformed, and used for dimensionality reduction. The model also supports metadata routing, parameter retrieval, Gibbs sampling, and pseudo-likelihood computation. Additionally, there are options to set output format and update estimator parameters. The model computes hidden layer activation probabilities for transforming data into latent representations. References to deep belief nets and detailed examples are provided for further understanding. The Multi-layer Perceptron regressor is a model that optimizes the squared error using LBFGS or stochastic gradient descent. It allows for different activation functions for the hidden layers such as 'identity', 'logistic', 'tanh', and 'relu'. The solver for weight optimization can be 'lbfgs', 'sgd', or 'adam'. The model also includes parameters for L2 regularization, minibatch size, learning rate schedule, initial learning rate, momentum, early stopping, and more. It can be used for regression tasks and trains iteratively to update model parameters. References include works by Hinton, Glorot, Bengio, He, and Kingma. The model can be fitted to data and used for prediction, with the coefficient of determination (R2 score) indicating the quality of the predictions. Additional features include metadata routing, getting and setting parameters, and updating the model with new data. ",
    "sklearn.pipeline": "The FeatureUnion class in scikit-learn allows for the concatenation of results from multiple transformer objects. This is useful for combining various feature extraction mechanisms into a single transformer. Parameters of the transformers can be set using their names and specific parameter names separated by '__'. Transformers can be replaced entirely, removed, or disabled by setting specific parameters. The number of jobs to run in parallel can be specified, with -1 indicating the use of all processors. Multiplicative weights for features per transformer can also be defined. The FeatureUnion class provides various methods for fitting, transforming, and setting parameters for the estimator. Additionally, metadata routing can be enabled to safely route parameters to the fit and transform methods of sub-transformers. The class also allows for setting the output container format when transforming data. Overall, the FeatureUnion class in scikit-learn provides a flexible and powerful way to combine and process features from multiple transformer objects efficiently. The `Pipeline` function in scikit-learn allows for chaining together a list of estimators without the need to name them individually. The estimators are automatically named based on their types. Caching can be enabled to store the fitted transformers of the pipeline, except for the last step. Caching is useful when fitting is time-consuming. The `Pipeline` function returns a scikit-learn Pipeline object, which can be inspected using the `named_steps` or `steps` attributes. Additionally, if enabled, the time elapsed while fitting each step will be printed. This function is a convenient way to create a pipeline of transforms with a final estimator. The Pipeline class in scikit-learn allows you to create a sequence of data transformers with an optional final predictor. This enables you to preprocess the data by applying a list of transformers sequentially and then conclude the sequence with a final predictor for predictive modeling. The intermediate steps in the pipeline must be transformers that implement fit and transform methods, while the final estimator only needs to implement fit. The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters. Parameters of the various steps can be set using their names and the parameter name separated by a '__'. Steps can be replaced entirely by setting the parameter with its name to another estimator, or a transformer can be removed by setting it to 'passthrough' or None. The transformers in the pipeline can be cached using the memory argument, which is advantageous when fitting is time-consuming. The pipeline also allows for grid search on a pipeline using '__' as a separator in the parameter names. The pipeline can be used in combination with GridSearchCV for selecting dimensionality reduction. The pipeline class instance can be used to request metadata passed to the score method, and the metadata routing mechanism allows for configuring the output format of transform and fit_transform. The Pipeline class also provides methods for inverse_transform, fit_predict, predict, predict_log_proba, predict_proba, score, score_samples, set_output, set_params, and transform. ",
    "sklearn.preprocessing": "The Binarizer function allows for binarizing data by setting feature values to 0 or 1 based on a specified threshold. This is commonly used in text count data analysis to consider the presence or absence of a feature. The function can also be used as a pre-processing step for estimators that consider boolean random variables. The function can be performed inplace to avoid unnecessary copies. Additionally, the function can encode categorical features as a one-hot numeric array. The Binarizer class is stateless and does not need to be fitted, but it is recommended to call fit_transform for parameter validation. The function also allows for validating estimator's parameters and being consistent with the scikit-learn transformer API. The function can also retrieve output feature names for transformation and set output containers. It can also set the parameters of the estimator and request metadata passed to the transform method. The Binarize function can binarize each element of X individually, with the option to copy the input X or not. The KBinsDiscretizer function is used to bin continuous data into intervals. It allows for specifying the number of bins, encoding method, strategy for defining bin widths, output data type, maximum number of samples for computational efficiency, random number generation for subsampling, bin edges, number of bins per feature, and more. The function can be used to preprocess data and convert it back to the original feature space using inverse_transform. It is recommended to use feature selection algorithms to handle constant features that may be produced. The function also provides options for fitting the estimator, transforming data, getting output feature names, metadata routing, setting output container, configuring output format, setting parameters, and discretizing the data. The function returns the discretized data in the binned space, which can be a sparse matrix or ndarray depending on the encoding method used. The LabelBinarizer function in scikit-learn allows for the binarization of labels in a one-vs-all fashion, making it easier to extend regression and binary classification algorithms to multi-class classification. This involves converting multi-class labels to binary labels, fitting label binarizer, and transforming multi-class labels to binary labels. The output of transform is referred to as the 1-of-K coding scheme. The function also includes methods for encoding categorical features using a one-hot scheme, transforming binary labels back to multi-class labels, setting output containers, configuring output formats, and setting parameters for the estimator. Additionally, there are options for metadata routing and threshold parameters in the inverse_transform method. The LabelBinarizer function supports sparse matrices in various formats and is useful for multilabel classification tasks. The MaxAbsScaler function scales each feature by its maximum absolute value, ensuring that the maximal absolute value of each feature in the training set will be 1.0. This scaler does not shift or center the data, preserving sparsity, and can be applied to sparse matrices. It does not reduce the effect of outliers, only linearly scales them down. The scale_ attribute was added in version 0.17, providing per-feature relative scaling of the data. The function also includes the per-feature maximum absolute value, number of features seen during fit, and names of features seen during fit. NaNs are treated as missing values. The function can compute the maximum absolute value for later scaling and can perform online computation for cases with a large number of samples. Additionally, it includes methods to get output feature names, metadata routing, parameters, and to set output containers. The function can also set parameters and scale back the data to its original representation. The function descriptions provided cover the transformation between an iterable of iterables and a multilabel format. This transformer allows for converting between the intuitive format of a list of sets or tuples to a binary matrix format indicating the presence of class labels. It also includes methods for fitting the label sets binarizer, storing classes, transforming label sets, setting output containers, configuring output formats, setting parameters of the estimator, and more. The functions handle the processing and manipulation of multilabel data efficiently, ensuring unique entries and proper encoding of categorical features. Additionally, the functions support sparse matrix formats and provide options for different output formats such as DataFrame or Polars. The functions encapsulate routing information and provide a comprehensive set of tools for working with multilabel data efficiently. The OneHotEncoder function in scikit-learn is used to encode categorical features as a one-hot numeric array. It takes an array-like input of integers or strings representing the values of categorical features and encodes them using a one-hot encoding scheme. This creates a binary column for each category and returns a sparse matrix or dense array. The encoder can automatically derive categories from the unique values in each feature or manually specified categories can be used. The function also allows for dropping one of the categories per feature to handle collinearity issues. Unknown categories can be handled by raising an error, ignoring them, or mapping them to an infrequent category if it exists. Infrequent categories can be defined based on minimum frequency or maximum categories. The function also provides options for setting output format, transforming data back to the original representation, and setting parameters for the estimator. Overall, the OneHotEncoder function in scikit-learn is a versatile tool for encoding categorical data for machine learning models. The `Generate polynomial and interaction features` function allows for the creation of a new feature matrix consisting of all polynomial combinations of the input features with a specified degree. This function can generate interaction features, exclude certain terms, and include a bias column. The total number of output features is determined by iterating over all combinations of input features. The function can also compute the number of output features and provide feature names. Additionally, it allows for the setting of output containers and configuring the output format. The `Transform data to polynomial features` function transforms the input data row by row, preferring CSR over CSC for sparse input. It can handle different degrees efficiently and convert between sparse matrix formats as needed. The QuantileTransformer function transforms features to follow a uniform or normal distribution, reducing the impact of outliers and making variables measured at different scales more directly comparable. It is a non-linear transformation applied independently to each feature. The number of quantiles to be computed determines the number of landmarks used to discretize the cumulative distribution function. The choice of marginal distribution for the transformed data can be 'uniform' or 'normal'. The maximum number of samples used to estimate the quantiles can be set for computational efficiency. The function also allows for random number generation for subsampling and smoothing noise. NaNs are treated as missing values. The function provides options for performing mapping to a normal distribution, standardization, and robust standardization. It also includes methods for fitting the transformer to data, transforming it, and back-projecting to the original space. Additionally, the function allows for setting output containers and configuring the output format. The feature-wise transformation of the data is performed along the features axis. The SplineTransformer class generates univariate B-spline bases for features by creating a new feature matrix with a specified number of spline basis functions. The number of knots and polynomial degree can be set, with options for knot positions, extrapolation methods, and periodic splines. The output includes a bias term and can be in 'F' order for faster computation. The transformer can handle sparse matrices and provides information on the input and output features. High degrees and a high number of knots should be used with caution to avoid overfitting. The transformer can fit to data and transform it, with options for additional fit parameters. It can also provide output feature names, metadata routing, and estimator parameters. The set_output API allows for configuring the output format, including options for DataFrame or Polars output. The set_params method can be used to update the parameters of the estimator. Overall, the SplineTransformer class provides a flexible and powerful tool for generating B-splines for feature engineering. The TargetEncoder function is used for regression and classification targets, encoding categories based on the average target values for observations in each category. It mixes the global target mean with the conditional target mean. For multiclass targets, it uses conditional probability estimates. Missing values are treated as another category. The function considers the type of target, the amount of mixing of target means, and the number of folds in cross-fitting. It encodes categories based on the target values and stores the encodings for each feature. The function also performs ordinal and one-hot encodings for categorical features. Smooth parameter can be set to \"auto\" for an empirical Bayes estimate. The function fits the encoder to the data and transforms it, with options for different output formats. It can also retrieve metadata and parameters for the estimator. The functions described include Boolean thresholding of array-like or scipy.sparse matrix, scaling each feature to the [-1, 1] range without breaking sparsity, and warning against the use of maxabs_scale without proper understanding. The Boolean thresholding function replaces feature values below a certain threshold with 0 and above with 1, while the scaling function ensures that the maximal absolute value of each feature in the training set is 1.0. It can be applied to sparse matrices as well. The warning emphasizes the risk of data leakage when using maxabs_scale and recommends using it within a Pipeline. NaNs are treated as missing values in these functions. The function scales input vectors individually to unit norm, allowing for normalization of data element by element. It can handle scipy.sparse matrices in CSR format to avoid unnecessary copies. Users can specify the norm to use for normalization and the axis along which to normalize the data. The function can also avoid making a copy of the data if specified, although this is not guaranteed in all cases. Additionally, the function can return the computed norms and is part of the Transformer API for preprocessing data. However, when dealing with sparse data, certain norms may not be supported. For more information on the function and comparisons with other scalers, transformers, and normalizers, users can refer to the documentation. The QuantileTransformer function is used to transform features using quantiles information, resulting in a uniform or normal distribution. This preprocessing scheme spreads out frequent values and reduces the impact of outliers. The transformation is applied independently to each feature, mapping original values to a uniform distribution and then to the desired output distribution using quantile functions. It is non-linear and may distort linear correlations but makes variables measured at different scales more comparable. The function also allows for specifying the number of quantiles, the type of distribution, and subsampling options for computational efficiency. It is important to be cautious when using QuantileTransformer to avoid data leakage and it is recommended to use it within a Pipeline. The Standardize function is used to center a dataset along any axis, by scaling it to unit variance. It can be applied independently to each feature or each sample, with the option to center the data before scaling. The function also handles sparse matrices and treats NaNs as missing values. It is important to be cautious when using this function to avoid data leakage, especially when splitting data into training and test sets. It is recommended to use StandardScaler within a Pipeline to prevent data leakage and bias in model evaluation. The FunctionTransformer class constructs a transformer from an arbitrary callable, forwarding its arguments to a user-defined function and returning the result. It is useful for stateless transformations like custom scaling or taking the log of frequencies. The function can be specified for both the transformation and the inverse transformation. Input validation can be enabled, and the function can accept sparse matrices. The feature names can be customized, and additional keyword arguments can be passed to the function. The transformer can be fitted to data and transformed, with the option to specify fit parameters. The output format can be configured, with options for DataFrame or Polars output. The parameters of the estimator can be set or updated, and the input can be transformed using the forward function. The KernelCenterer class allows for centering an arbitrary kernel matrix \\(K\\) without explicitly computing the mapping \\(\\phi(\\cdot)\\). This is useful for algebraic computations like eigendecomposition for KernelPCA. The class also provides methods for fitting the KernelCenterer to data, transforming it, getting output feature names, setting output containers, and setting parameters. Additionally, metadata routing can be configured for the fit and transform methods. The centering of the kernel matrix can be performed in place by setting a parameter to False. The class also includes references to relevant literature on nonlinear component analysis as a kernel eigenvalue problem. The LabelEncoder transformer is used to encode target labels with values between 0 and n_classes-1. It can be used to encode target values, normalize labels, transform non-numerical labels to numerical labels, and transform labels back to their original encoding. The transformer also allows for setting output containers and configuring the output format. Additionally, it provides methods for getting metadata routing information, getting parameters for the estimator, setting parameters of the estimator, and transforming labels to normalized encoding. This transformer is a useful tool for encoding and transforming target values in machine learning tasks. The MinMaxScaler function transforms features by scaling each feature to a given range, such as between zero and one. This scaling is done individually for each feature and can be used as an alternative to zero mean, unit variance scaling. It does not reduce the effect of outliers but linearly scales them down into a fixed range. The function includes parameters for setting the desired range of transformed data, adjusting for minimum per feature, relative scaling of the data, and more. It also allows for online computation of min and max on the data for later scaling. Additionally, the function provides options for configuring output format and setting parameters of the estimator. Overall, MinMaxScaler is a versatile tool for scaling and transforming data efficiently. The Normalize function is used to scale each sample individually to unit norm, with options for l1, l2, or inf norms. This transformer can work with both dense numpy arrays and scipy.sparse matrices. Normalizing inputs to unit norms is commonly used in text classification and clustering. The function does not need to be fitted, but it is recommended to call fit_transform instead of transform for parameter validation. The function also allows for validation of estimator parameters and consistency with the scikit-learn transformer API. The function can be used to fit data and transform it, with options for input samples, target values, and additional fit parameters. The output feature names for transformation can be obtained, and metadata routing information can be accessed. The function also allows for setting parameters, requesting metadata, and configuring output format. The Normalize function scales each non-zero row of the input data to unit norm, with options to copy the input data or not. The OrdinalEncoder function encodes categorical features as an integer array, converting features to ordinal integers resulting in a single column of integers per feature. It allows for automatic determination of categories from training data, setting the dtype of output, handling unknown categories, encoding missing categories, and specifying minimum frequency and upper limit of output categories. Infrequent categories can be grouped together, and missing values can be encoded. The function is suitable for low to medium cardinality categorical variables and can be used in supervised and unsupervised settings. It can encode target labels with values between 0 and n_classes-1. The function is lenient towards missing values by default and can be fitted to data for transformation. It also provides options for setting output format, getting metadata routing, getting and setting parameters, and transforming data back to the original representation. The PowerTransformer function applies a power transform featurewise to make data more Gaussian-like. It supports both the Box-Cox transform and the Yeo-Johnson transform, with the optimal parameter estimated through maximum likelihood. The function also allows for zero-mean, unit-variance normalization by default. NaNs are treated as missing values. The function can estimate the optimal lambda parameter for each feature independently to minimize skewness. It can fit the transformer to the data and transform it, as well as apply the inverse power transformation using the fitted lambdas. Additionally, the function allows for setting the output container format and configuring the output of transform and fit_transform. The parameters of the estimator can be set and the power transform can be applied to each feature using the fitted lambdas. The RobustScaler function is used to scale features using statistics that are robust to outliers. It removes the median and scales the data according to the interquartile range (IQR). This is beneficial because outliers can negatively influence the sample mean and variance. The function can center the data before scaling and scale it to the interquartile range. It also allows for inplace scaling and scaling data so that normally distributed features have a variance of 1. The function computes the median and quantiles for scaling, fits the transformer to the data, and can scale back the data to its original representation. Additionally, it can remove linear correlation across features with the 'whiten=True' parameter. The function also provides options for configuring the output format of the transformation, setting parameters, and centering and scaling the data along a specified axis. StandardScaler is a function that standardizes features by removing the mean and scaling to unit variance. This is important for many machine learning estimators to ensure that all features are centered around 0 and have variance in the same order. StandardScaler is sensitive to outliers and can be applied to sparse matrices as well. It computes the mean and standard deviation for later use and can handle missing values. The function also supports online computation of mean and standard deviation for cases where fitting is not feasible. Additionally, StandardScaler allows for metadata routing and configuration of output formats. It can be used to transform data by centering and scaling it. The functions provided in the list include augmenting a dataset with a dummy feature for fitting an intercept term, binarizing labels in a one-vs-all fashion for multi-class classification, transforming features by scaling each feature to a given range using MinMaxScaler, and the warning against using minmax_scale without proper understanding to avoid data leakage. The functions also cover the use of the Transformer API and the recommendation to use MinMaxScaler within a Pipeline to prevent data leakage. It is important to understand the implications of using these functions, especially in the context of model evaluation and data preprocessing. The power transform function is a parametric, monotonic transformation used to make data more Gaussian-like. It includes the Box-Cox transform and the Yeo-Johnson transform, with the optimal parameter estimated through maximum likelihood. The method supports both positive and negative values, with the default being Yeo-Johnson. The function also includes zero-mean, unit-variance normalization by default. It is important to note that NaNs are treated as missing values. However, there is a warning about the risk of data leakage when using the power transform function, so it is recommended to use it within a Pipeline to prevent this issue. ",
    "sklearn.random_projection": "The RandomProjection class provides a method to reduce dimensionality through Gaussian random projection. The random matrix components are drawn from a normal distribution with mean 0 and variance 1 divided by the number of components. The number of components can be automatically adjusted based on the dataset size and the Johnson-Lindenstrauss lemma. The quality of the embedding can be controlled by the eps parameter. The Johnson-Lindenstrauss lemma provides a conservative estimate of the required number of components. The inverse transform can be learned by computing the pseudo-inverse of the components during fitting. The random matrix used for projection and the pseudo-inverse of the components can also be accessed. The class also allows for sparse random projection and provides methods for fitting, transforming, and inverse transforming data. Additionally, it offers options for setting output format and configuring the output of transformations. The class can also retrieve metadata routing information and estimator parameters. The function calculates the minimum number of components needed for a random projection to guarantee a certain distortion rate in a dataset. It is based on the Johnson-Lindenstrauss lemma and ensures that the distance between points is preserved within a certain factor. The number of components required depends on the number of samples in the dataset and the desired distortion rate. The function can be applied to individual arrays or arrays in a batch. References to the Johnson-Lindenstrauss lemma and related work are provided for further reading. ",
    "sklearn.semi_supervised": "The Label Propagation classifier is a semi-supervised model that assigns labels to unlabeled data points based on the information from labeled data points. It uses a kernel function, with options for 'rbf' and 'knn', to create a weight matrix. Parameters such as the convergence tolerance, maximum number of iterations, and number of parallel jobs can be adjusted. The model can be fitted to training data and used for inductive inference to make predictions. The accuracy of the model can be evaluated using the mean accuracy on test data. Additionally, the model parameters can be set and metadata routing can be requested for the estimator. The method also allows for metadata routing for the sample_weight parameter in the score method. The Label Propagation classifier is based on the work of Xiaojin Zhu and Zoubin Ghahramani, and more details can be found in their technical report. The Self-training classifier is a metaestimator that allows a supervised classifier to function as a semi-supervised classifier by learning from unlabeled data. It iteratively predicts pseudo-labels for unlabeled data and adds them to the training set until a maximum number of iterations is reached or no new pseudo-labels are added. The classifier can use different criteria for selecting labels to add, such as a threshold or selecting the k-best pseudo-labels. It also allows for verbose output and provides information on the labels used for the final fit, the iteration in which each sample was labeled, and the reason for stopping the fitting process. The Self-training classifier references the Label propagation classifier, which is a label spreading model for semi-supervised learning. Additionally, the classifier provides methods for fitting, predicting classes, predicting log probabilities, predicting probabilities, scoring, and setting parameters. However, it does not support metadata routing yet. ",
    "sklearn.svm": "Linear Support Vector Classification is a class that is similar to SVC with a linear kernel, but it is implemented in terms of liblinear instead of libsvm, providing more flexibility in penalties and loss functions. It can handle both dense and sparse input data and supports multiclass classification using a one-vs-the-rest scheme. The class allows for specifying the norm used in penalization, the loss function, the algorithm for optimization, the tolerance for stopping criteria, the regularization parameter, the multi-class strategy, whether or not to fit an intercept, and the class weights. The class also supports verbose output, controls for random number generation, and provides methods for predicting confidence scores, converting coefficient matrices, fitting the model, getting metadata routing, getting and setting parameters, predicting class labels, calculating accuracy, and converting coefficient matrices to sparse format. Additionally, the class has notes on differences from liblinear, predict output matching, and references to LIBLINEAR. It is mentioned that LinearSVC is more scalable than SVC for large datasets and that SGDClassifier can optimize the same cost function as LinearSVC with additional benefits. The Nu-Support Vector Classification function is similar to SVC but uses a parameter to control the number of support vectors. It is based on libsvm and has various parameters such as an upper bound on margin errors, kernel type specification, degree of polynomial kernel function, kernel coefficient, shrinking heuristic usage, probability estimates enabling, tolerance for stopping criterion, kernel cache size specification, class weight adjustment, decision function shape specification, and more. The function also includes parameters for controlling the pseudo random number generation, multipliers of parameter C for each class, dual coefficients of support vectors, and support vector indices. Additionally, it provides methods for evaluating the decision function, fitting the model, performing classification, computing log probabilities, and returning mean accuracy on test data. The function also supports metadata routing and parameter setting. The Unsupervised Outlier Detection function estimates the support of a high-dimensional distribution based on libsvm implementation. It allows for specifying the kernel type to be used, with default options available if none is given. Parameters such as the degree of the polynomial kernel function, kernel coefficient, tolerance for stopping criterion, and more can be adjusted. The function also supports the use of the shrinking heuristic, verbose output, and setting the size of the kernel cache. It provides information on the weights assigned to features, coefficients of support vectors, and the number of iterations run during optimization. Additionally, it offers functionality for detecting outliers using Local Outlier Factor (LOF) and the Isolation Forest Algorithm. The decision function, soft boundary detection, and classification on samples are also available, with the ability to return labels for inliers and outliers. Metadata routing and parameter settings can be customized, making this function versatile and comprehensive for outlier detection tasks. The Epsilon-Support Vector Regression function is a model with free parameters C and epsilon, based on libsvm. It has a fit time complexity that makes it hard to scale to large datasets, so LinearSVR or SGDRegressor may be better options for such cases. The function allows for specifying the kernel type, degree of the polynomial kernel function, kernel coefficient, and other parameters. It also includes options for regularization, epsilon in the epsilon-SVR model, and the shrinking heuristic. The function provides support for kernel cache size, verbose output, and other features. Additionally, it offers methods for fitting the model, getting metadata, setting parameters, and performing regression. The function can be used for regression tasks and provides options for requesting metadata and updating parameters. Linear Support Vector Regression is a class that is similar to SVR with a linear kernel, but it is implemented in terms of liblinear instead of libsvm, providing more flexibility in penalties and loss functions. It can handle both dense and sparse input data. The class includes parameters such as epsilon for the epsilon-insensitive loss function, tolerance for stopping criteria, regularization parameter C, and the choice of loss function (L1 or L2). It also allows for fitting an intercept and selecting the algorithm to solve the optimization problem. The class supports verbose output, controls for random number generation, and specifies the maximum number of iterations. Additionally, it provides methods for fitting the model, predicting values, calculating the coefficient of determination, and requesting metadata. Other related classes include Support Vector Machine classifier and regression implementations using different libraries, as well as SGDRegressor for optimizing the same cost function with additional features. The class also includes methods for getting and setting parameters, as well as metadata routing for sample weights. The Nu Support Vector Regression function is similar to NuSVC but for regression, using a parameter nu to control the number of support vectors. It replaces the epsilon parameter of epsilon-SVR. The implementation is based on libsvm. The function allows for specifying an upper bound on the fraction of training errors and a lower bound of the fraction of support vectors. The penalty parameter C of the error term can be adjusted, as well as the kernel type to be used in the algorithm. Other parameters include the degree of the polynomial kernel function, kernel coefficient, independent term in the kernel function, and more. The function also allows for setting the tolerance for stopping criterion, specifying the size of the kernel cache, enabling verbose output, and setting a hard limit on iterations within the solver. Additionally, the function provides information on the weights assigned to features, coefficients of the support vector, constants in the decision function, and more. It also includes methods for fitting the SVM model, performing regression, obtaining predicted values, and calculating the coefficient of determination. The function supports metadata routing, getting and setting parameters, and requesting metadata for the fit and score methods. The C-Support Vector Classification function is based on libsvm and has a fit time that scales at least quadratically with the number of samples. For large datasets, LinearSVC or SGDClassifier are recommended alternatives. The multiclass support is handled using a one-vs-one scheme. The regularization parameter C is inversely proportional to the strength of regularization and must be strictly positive. The penalty is a squared l2 penalty. The function allows for specifying the kernel type to be used, with 'rbf' being the default if none is given. Other parameters such as gamma, coef0, and degree affect each other and can be tuned for optimal performance. The function also supports various options such as enabling probability estimates, setting the kernel cache size, and controlling the pseudo-random number generation. Additionally, the function provides methods for evaluating the decision function, fitting the model, computing probabilities, and returning the mean accuracy on test data. Various parameters can be set and metadata can be requested for routing purposes. Overall, the function offers a comprehensive set of features for support vector classification. ",
    "sklearn.tree": "The DecisionTreeClassifier function in scikit-learn is a powerful tool for building decision tree models. It allows for various customization options such as choosing the quality measurement criteria (e.g., Gini impurity, entropy), the strategy for choosing splits (e.g., best, random), setting the maximum depth of the tree, specifying the minimum number of samples required to split a node, controlling the number of features considered at each split, and more. Additionally, it supports constraints such as monotonic increase or decrease for multiclass and multioutput classifications. The function also provides methods for feature importances, predicting classes or regression values, computing accuracy, and accessing metadata. It is important to note that the default parameters may lead to fully grown and unpruned trees, so it is recommended to control the size and complexity of the trees by adjusting the parameter values. The Extra-Trees classifier is a type of decision tree classifier that differs from classic decision trees by randomly selecting features and drawing random splits to find the best split for each node. It is recommended to use Extra-Trees within ensemble methods. The quality of a split is measured using criteria such as \"gini\" for Gini impurity, \"log_loss,\" and \"entropy\" for Shannon information gain. The strategy used to choose the split at each node can be \"best\" or \"random.\" Other parameters include the maximum depth of the tree, the minimum number of samples required to split an internal node, the minimum number of samples required to be at a leaf node, and the minimum weighted fraction of the sum total of weights required to be at a leaf node. The number of features to consider when looking for the best split can be specified, and the tree can be grown with a maximum number of leaf nodes in a best-first fashion. The class weights can be adjusted automatically based on class frequencies in the input data. The decision tree classifier can be used for multiclass classifications, multioutput classifications, and classifications trained on data with missing values. The feature importances, number of features seen during fit, and names of features seen during fit can also be returned. Additionally, the depth of the decision tree, number of leaves, and metadata routing information can be accessed. The decision tree classifier can be used to build a decision tree from training data, predict class or regression values, compute class log-probabilities and class probabilities, and calculate the mean accuracy on test data. The parameters of the estimator can be set and retrieved, and metadata can be requested for various methods. The DecisionTreeRegressor function in scikit-learn is used to build a decision tree regressor model from the training set. It supports various criteria for measuring the quality of a split, such as mean squared error, mean absolute error, and Poisson deviance. The function allows for controlling the maximum depth of the tree, the minimum number of samples required to split an internal node, and the minimum number of samples required to be at a leaf node. Additionally, it provides options for choosing the split strategy, the number of features to consider at each split, and controlling the randomness of the estimator. The function also supports multioutput regressions and training on data with missing values. Other features include returning feature importances, the depth of the decision tree, the number of leaves, and the coefficient of determination of the prediction. The function can also return the index of the leaf that each sample is predicted as, the decision path in the tree, and the feature importances. It allows for setting and getting parameters, as well as requesting metadata for fitting, predicting, and scoring. The default values for the parameters controlling the size of the trees can lead to fully grown and unpruned trees, so it is recommended to control the complexity and size of the trees by setting those parameter values. The Extra-Trees regressor is a type of decision tree regressor that differs from classic decision trees by using random splits for each of the randomly selected features to find the best split. It should only be used within ensemble methods. Different criteria are supported for measuring the quality of a split, such as squared error, Friedman mean squared error, absolute error, and Poisson deviance. Various strategies can be used to choose the split at each node, such as \"best\" or \"random\". The tree's maximum depth, minimum number of samples required to split an internal node, and minimum number of samples required to be at a leaf node can be specified. The minimum weighted fraction of the sum total of weights required to be at a leaf node can also be set. The number of features to consider when looking for the best split can be defined, as well as the impurity decrease threshold for splitting a node. The tree can be grown with a specified number of maximum leaf nodes and a complexity parameter for Minimal Cost-Complexity Pruning. Constraints can be applied for monotonic increase or decrease. The model can handle multioutput regressions and data with missing values. Feature importances, the number of outputs, and the underlying Tree object can be returned. The default values for tree size parameters can lead to large trees, so it's recommended to control the complexity and size of the trees by setting these parameters. The regressor can predict the leaf index for each sample, return the decision path in the tree, and provide the feature importances. The depth and number of leaves of the tree can also be obtained. The coefficient of determination \\(R^2\\) can be calculated for the prediction, and metadata routing can be requested for various methods. Additionally, parameters can be set and updated for the estimator. The function allows for the export of a decision tree in DOT format, generating a GraphViz representation of the decision tree. The exported tree can be written into an output file or returned as a string if no output file is specified. Various parameters can be set, such as the maximum depth of the tree, feature names, target class names, and display options for impurity and node information. Additional features include showing class names symbolically, painting nodes to indicate majority class or purity, and customizing the display of values and samples. The orientation of the tree can be adjusted, node boxes can have rounded corners, and font settings can be specified. The function also provides the option to show impurity values, node IDs, and customize the precision of floating point values. The output is a string representation of the input tree in GraphViz dot format. ",
    "sklearn.utils": "The functions described include creating a container object with keys as attributes, returning values from a dictionary based on a key or default value, removing and returning key-value pairs in LIFO order, inserting a key with a default value if not present, converting an array-like object to an array of floats with specified dtype and options, marking functions or classes as deprecated with warnings, and generating slices of batched elements from a sequence. Additionally, there is a function to make arrays indexable for cross-validation by ensuring consistent length and converting objects to arrays. The resample function allows for consistent resampling of arrays or sparse matrices, implementing resampling with replacement or random permutations. It can handle arrays, lists, dataframes, or scipy sparse matrices with a consistent first dimension. The function also allows for stratified resampling based on class labels. The element-wise squaring function operates on array-likes and sparse matrices, with the option to create a copy of the input or perform inplace computation. The function to sample rows, items, or columns of data supports various types of indices, including int, bool, and str. It can subsample along a specified axis and supports CSR, CSC, and LIL sparse matrices. The function throws a ValueError if the input data contains NaN or infinity, with an option to ignore NaN values. Additionally, there is a utility function to build a HTML representation of an estimator for visualization purposes. The functions provided include a generator to create evenly spaced slices up to a certain number, a function to compute the 32bit murmurhash3 of a key at a given seed, a function to return a mask safe to use on a given data set, a function to shuffle arrays or sparse matrices consistently, and a function to resample arrays or sparse matrices in a consistent way. The generator function allows for generating slices with a specified number of samples, the murmurhash3 function generates a low latency 32-bit hash, the mask function returns a safe mask for a given data set, the shuffle function shuffles arrays or matrices consistently, and the resample function allows for resampling arrays or matrices with the option to mix sparse and dense arrays. The function provides input validation for standard estimators by checking the consistency of the length of X and y, enforcing X to be 2D and y to be 1D. It also checks for non-empty and finite values in X, as well as for np.nan or np.inf targets in y. For multi-label y, setting multi_output=True allows for 2D and sparse y. If the dtype of X is object, it attempts to convert it to float. The function also handles sparse matrix formats, enforces data type consistency, array order, and copying behavior. It allows for customization regarding handling of np.inf, np.nan, and pd.NA values in X, as well as the dimensions and types of X and y. Additionally, it ensures a minimum number of samples and features in X, and can convert the dtype of y to float64 for regression algorithms. Warning messages can include the name of the estimator. Overall, the function converts and validates both X and y according to the specified criteria. The functions provided in the list include checking for consistent first dimensions in arrays, validating scalar parameters type and value, checking if memory is joblib.Memory-like, and raveling a column or 1D numpy array. The validation function checks for consistent length in objects, validates scalar parameters based on data types and value ranges, and ensures that memory is joblib.Memory-like. The ravel function converts input data into a 1D array or raises an error if the input is not compatible. Additionally, the functions provide options for controlling warnings and output data. The function provides input validation for arrays, lists, sparse matrices, or similar data structures. It checks for non-empty 2D arrays with finite values by default. If the array dtype is an object, it attempts to convert it to float and raises an error on failure. It also allows specifying allowed sparse matrix formats and handles conversion if the input format is not allowed. The function can preserve the dtype of the input or convert it to a specified type. It also provides options for memory layout, copying behavior, handling of special values like np.inf and np.nan, and enforcing minimum dimensions and features in the input data. Additionally, it allows including the estimator name in warning messages and customizing the error message construction. The function returns the converted and validated array after performing all the necessary checks and conversions. The functions provided in the list cover a range of functionalities. \n\n1. The first function described is responsible for turning a seed into a np.random.RandomState instance. It handles cases where the seed is None, an integer, or already a RandomState instance, and raises a ValueError for any other input.\n\n2. The second function performs is_fitted validation for an estimator. It checks if the estimator is fitted by looking for specific attributes and raises a NotFittedError if the conditions are not met. Custom error messages can be defined, and the function allows for flexibility in specifying attribute names and requirements.\n\n3. The third function ensures that an input array is 2D, square, and symmetric. If the array is not symmetric, it returns a symmetrized version. Options are available to raise warnings or exceptions based on the symmetry of the matrix.\n\n4. The fourth function checks whether an estimator's fit method supports a given parameter. It provides a way to inspect the compatibility of parameters with the fit method of an estimator, allowing for conditional availability of attributes based on the check results. The functions provided include estimating class weights for unbalanced datasets, estimating sample weights by class for unbalanced datasets, checking if the target values are in a multilabel format, and extracting an ordered array of unique labels. For estimating class weights, the options include using a \"balanced\" heuristic, providing a dictionary of class weights, or leaving it as None for uniform weights. The sample weights can be adjusted automatically based on class frequencies in the input data. For multilabel problems, weights should be defined for each class of every column. The functions also handle different types of target values, such as multilabel and multiclass targets, label indicator matrices, and mix of string and integer labels. The goal is to provide flexibility in handling various types of data and ensuring accurate weight adjustments for unbalanced datasets. The functions provided include determining the type of data indicated by the target, computing the density of a sparse vector, and computing an orthonormal matrix whose range approximates the range of a given input matrix. The function for determining data type specifies various categories such as 'continuous', 'binary', 'multiclass', 'multilabel-indicator', and 'unknown'. The function for computing density works with numpy ndarrays or sparse matrices and returns a value between 0 and 1. The function for computing an orthonormal matrix allows for customization in terms of size, number of power iterations, and normalization methods. Additionally, it mentions the use of a pseudo random number generator for reproducible results. Overall, these functions provide tools for data analysis and matrix operations with specific considerations for different data types and computational requirements. The function computes the logarithm of the determinant of a square matrix. It returns the natural logarithm of the determinant if it is non-negative and well defined. If the determinant is zero or negative, it returns -Inf. This function is equivalent to np.log(np.det(A)) but more robust. It returns log(det(A)) when det(A) is strictly positive and -inf when det(A) is non-positive or not defined. The function computes a truncated randomized SVD, which is a method used to solve the fixed-rank approximation problem. It decomposes a matrix into a specified number of singular values and vectors, with the option to sample additional random vectors for conditioning. The number of power iterations can be adjusted for noisy problems, and normalization options are available for accuracy. The algorithm can be applied to the transpose of the matrix as well. The output includes the singular values sorted in non-increasing order. The function is efficient for extracting a small number of components from large matrices, with options to balance speed and precision by adjusting parameters such as n_iter and n_oversamples. References to relevant literature are provided for further reading. The functions provided include one that returns an array of the weighted modal (most common) value in a passed array, with the option to specify the axis. Another function computes incremental mean and variance along an axis on a CSR or CSC matrix, updating means, variances, and weights. There is also a function for inplace column scaling of a CSR matrix, normalizing each feature by multiplying with a specific scale. Additionally, a function is available to swap two columns of a CSC/CSR matrix in-place. These functions offer a range of operations for handling arrays and matrices efficiently. The functions provided include computing mean and variance along an axis on a CSR or CSC matrix, normalizing rows of a CSR matrix or array by their L1 norm, inplace column scaling of a CSC/CSR matrix, scaling each feature of a data matrix, swapping two rows of a CSC/CSR matrix in-place, normalizing rows of a CSR matrix or array by their L2 norm, and returning the length of the shortest path from a source node to all reachable nodes in a graph. These functions cover a range of operations on matrices and arrays, including computation, normalization, scaling, and pathfinding. The functions provided include a function to sample integers without replacement from a given set, a function to find the minimum value of an array over positive values, a function to contain metadata request info of a consumer, a function to check whether given parameters are consumed by a specific method, and a function to store the mapping between caller and callee methods for a router. The sampling function allows for different methods of selection based on the ratio of samples to population size. The function to find the minimum value of an array returns the maximum representable value of the input dtype if no positive values are found. The metadata request function contains information about consumer requests and methods. The function to check parameters consumed by a method returns a set of parameters consumed. The function to store method mappings is used in routers to define the mapping between sub-objects and router methods. The function \"process_routing\" is used to validate and route input parameters within a router's method, such as \"fit\". It handles the metadata and routing, and can be called with specific parameters. If routing is not enabled and kwargs is empty, it returns an empty routing. This function is typically used by an object implementing get_metadata_routing, like a meta-estimator. The metadata to be routed is in the form of a Bunch, which contains object names, method names, and parameters. This function was added in version 1.3. The function handles metadata routing for a router object by storing routing information in a dictionary. It allows for adding named objects with their corresponding method mapping, checking parameters consumed by a method, returning input parameters requested by child objects, validating metadata for a method, and getting a MetadataRouter or MetadataRequest instance from an input object. Additionally, it provides a list of all displays from sklearn, including the display class name and actual class type. The functions described include checking if an estimator adheres to scikit-learn conventions by running extensive tests for input validation, shapes, etc. Additional tests are run for classifiers, regressors, clustering, or transformers. There is a specific function for tweaking joblib.Parallel to propagate the scikit-learn configuration to parallel workers. Another function dispatches tasks for parallel processing, prefetching tasks for the next batch, and displaying the process of parallel execution. These functions ensure proper validation and execution of estimators while maintaining scikit-learn conventions and configurations. ",
    "Recently Deprecated": "The function \"Get a list of all estimators from sklearn\" crawls the module and retrieves all classes that inherit from BaseEstimator, excluding classes defined in test-modules. It allows for filtering by estimator type such as 'classifier', 'regressor', 'cluster', or 'transformer', or a list of these types. The function returns a list of (name, class) pairs where name is the class name as a string and class is the actual type of the class. Additionally, there is a function to \"Get a list of all functions from sklearn\" which returns a list of (name, function) pairs where name is the function name as a string and function is the actual function. "
}