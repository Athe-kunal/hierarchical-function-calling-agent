{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "base_url = \"https://pandas.pydata.org/docs/reference/index.html\"\n",
    "response = requests.get(base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, \"lxml\")\n",
    "navbar = soup.find_all(attrs={\"class\": \"reference internal\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://pandas.pydata.org/docs/reference/io.html'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_url = \"https://pandas.pydata.org/docs/reference/\"\n",
    "ref_url+ navbar[0]['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_level = {}\n",
    "for nbar in navbar:\n",
    "    text_val = nbar.text\n",
    "    href = nbar['href']\n",
    "    full_url = ref_url+ href\n",
    "    if  \"#\" not in href:\n",
    "        first_level.update({href:{\"functions\":[],\"name\":text_val,\"url\":full_url}})\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nbar in navbar:\n",
    "    text_val = nbar.text\n",
    "    href = nbar['href']\n",
    "    full_url = ref_url+ href\n",
    "    if \"#\" in href:\n",
    "        parent_html = href.split(\"#\")[0]\n",
    "        if parent_html in first_level:\n",
    "            first_level[parent_html]['functions'].append({\"name\":text_val,\"url\":full_url})\n",
    "        else:\n",
    "            print(text_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_level['io.html']['functions']\n",
    "# https://pandas.pydata.org/docs/reference/io.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRACTING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parent_url = first_level['io.html']['url']\n",
    "\n",
    "# parent_soup = BeautifulSoup(requests.get(parent_url).text,'lxml')\n",
    "# url_id = \"pickling\"\n",
    "# s1 = parent_soup.find(attrs={\"id\":url_id})\n",
    "# s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object is not subscriptable\n",
      "'NoneType' object is not subscriptable\n"
     ]
    }
   ],
   "source": [
    "def get_links(id_elem,base_func_url,class_name):\n",
    "    curr_urls = []\n",
    "    try:\n",
    "        func_urls = id_elem.find_all(attrs={\"class\":class_name})\n",
    "        for odd_url in func_urls:\n",
    "            func_url = odd_url.find('a')['href']\n",
    "            curr_urls.append(base_func_url+func_url)\n",
    "        return curr_urls\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        func_urls = id_elem.find(attrs={\"class\":class_name}).find('a')['href']\n",
    "        curr_urls.append(base_func_url+func_url)\n",
    "        return curr_urls\n",
    "    finally:\n",
    "        return curr_urls\n",
    "    \n",
    "base_func_url = \"https://pandas.pydata.org/docs/reference/\"\n",
    "for first_level_name in first_level:\n",
    "    parent_url = first_level[first_level_name]['url']\n",
    "    parent_soup = BeautifulSoup(requests.get(parent_url).text,'lxml')\n",
    "    all_urls = []\n",
    "    for func in first_level[first_level_name]['functions']:\n",
    "        url_id = func['url'].split(\"/\")[-1].split(\"#\")[-1]\n",
    "        id_elem = parent_soup.find(attrs={\"id\":url_id})\n",
    "        odd_urls = get_links(id_elem,base_func_url,\"row-odd\")     \n",
    "        even_urls = get_links(id_elem,base_func_url,\"row-even\")     \n",
    "        all_urls.extend(odd_urls)\n",
    "        all_urls.extend(even_urls)\n",
    "    first_level[first_level_name]['function_urls'] = all_urls\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# def get_param_data(first_level):\n",
    "#     for parent, values in first_level.items():\n",
    "#         first_level[parent].update({\"function_definitions\":[]})\n",
    "#         for func_url in tqdm(values['function_urls']):\n",
    "#             func_response = requests.get(func_url)\n",
    "#             func_soup = BeautifulSoup(func_response.content, \"lxml\",from_encoding=\"utf-8\")\n",
    "            \n",
    "#             func_name = func_soup.find(\"h1\").text.replace(\"#\",\"\") #remove #\n",
    "#             try:\n",
    "#                 elem = func_soup.find(attrs={\"class\":\"sig sig-object py\"})\n",
    "#                 full_function = elem.text.replace(\"[source]#\",\"\").replace(\"\\n\",\"\")\n",
    "#                 func_text = func_soup.find(\"dd\").find('p').text\n",
    "#                 em = func_soup.find_all(attrs={\"class\":\"field-odd\"})\n",
    "#                 param_names = em[-1].find_all(\"dt\")\n",
    "#                 desc_list = em[-1].find_all(\"dd\")\n",
    "\n",
    "#                 # if len(param_names)!=len(desc_list):\n",
    "#                 #     print(func_name)\n",
    "#                 #     print(f\"param_names={len(param_names)} and desc_list={len(desc_list)}\")\n",
    "#                 curr_dict = {\"function_name\":func_name,\"full_function\":full_function,\"function_text\":func_text,\"parameter_names_desc\":[]}\n",
    "#                 # first_level[parent]['function_definitions'].append()\n",
    "#                 for pn,dn in zip(param_names,desc_list):\n",
    "#                     param_name = pn.text\n",
    "#                     if param_name == \"**kwargs\": continue\n",
    "#                     param_desc = dn.text\n",
    "#                     curr_dict['parameter_names_desc'].append({\"param_name\":param_name,\"param_desc\":param_desc})\n",
    "#                 first_level[parent]['function_definitions'].append(curr_dict)\n",
    "#             except Exception as e:\n",
    "#                 print(e)\n",
    "#                 print(func_name,func_text)\n",
    "#     return first_level\n",
    "\n",
    "# function_def_dict = get_param_data(first_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(function_def_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully written to pandas_function.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "filename = \"pandas_function.json\"\n",
    "\n",
    "# Serialize the dictionary to a JSON string\n",
    "json_data = json.dumps(function_def_dict, ensure_ascii=False)\n",
    "\n",
    "# Write the JSON string to a file with UTF-8 encoding\n",
    "with open(filename, \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json_file.write(json_data)\n",
    "\n",
    "print(\"Data has been successfully written to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"pandas_function.json\"\n",
    "\n",
    "with open(filename, \"r\", encoding=\"utf-8\") as json_file:\n",
    "        # Load the JSON data from the file\n",
    "        data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_url = 'https://pandas.pydata.org/docs/reference/api/pandas.read_clipboard.html'\n",
    "func_url = 'https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.nanoseconds.html'\n",
    "func_response = requests.get(func_url)\n",
    "func_soup = BeautifulSoup(func_response.content, \"lxml\",from_encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_name = func_soup.find(\"h1\").text.replace(\"#\",\"\") #remove #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pandas.Series.dt.nanoseconds'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "elem = func_soup.find(attrs={\"class\":\"sig sig-object py\"})\n",
    "full_function = elem.text.replace(\"[source]#\",\"\").replace(\"\\n\",\"\")\n",
    "func_text = func_soup.find(\"dd\").find('p').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of nanoseconds (>= 0 and less than 1 microsecond) for each element.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = func_soup.find(attrs={\"class\":\"field-list\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "em = param_names.find_all(attrs={\"class\":\"field-odd\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<dt><strong>extra_args</strong><span class=\"classifier\">list[str], default None</span></dt>,\n",
       " <dt><strong>run_doctests</strong><span class=\"classifier\">bool, default False</span></dt>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(em[-1].find_all('dt'))\n",
    "em[-1].find_all('dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extra_argslist[str], default None\n",
      "Extra marks to run the tests.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "run_doctestsbool, default False\n",
      "Whether to only run the Python and Cython doctests. If you would like to run\n",
      "both doctests/regular tests, just append ââdoctest-modulesâ/ââdoctest-cythonâ\n",
      "to extra_args.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def remove_non_english(sentence):\n",
    "    # Define a regular expression pattern to match non-English characters\n",
    "    non_english_pattern = re.compile(r'[^a-zA-Z0-9\\s,.!?}(){]+\\\\')\n",
    "    \n",
    "    # Replace non-English characters with an empty string\n",
    "    cleaned_sentence = non_english_pattern.sub('', sentence)\n",
    "    # cleaned_sentence = re.sub('â','',sentence)\n",
    "    # cleaned_sentence = re.sub('â','',sentence)\n",
    "    return cleaned_sentence\n",
    "for pname,param_desc in zip(em[-1].find_all('dt'),em[-1].find_all('dd')):\n",
    "    # print('-'*100)\n",
    "    param_name_text = pname.text\n",
    "    desc_text = param_desc.text\n",
    "    if \"**kwargs\" in param_name_text: continue\n",
    "    process_param_name = remove_non_english(param_name_text)\n",
    "    process_desc_text = remove_non_english(desc_text)\n",
    "    # print(process_param_name)\n",
    "    # print(process_desc_text)\n",
    "    print(pname.text.strip())\n",
    "    print(param_desc.text.strip())\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"classifier\">str, default â\\s+â</span>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_soup.find(attrs={\"class\":\"field-list\"}).find(attrs={\"class\":\"classifier\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "em = func_soup.find_all(attrs={\"class\":\"field-odd\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<dt><strong>sep</strong><span class=\"classifier\">str, default â\\s+â</span></dt>,\n",
       " <dt><strong>dtype_backend</strong><span class=\"classifier\">{ânumpy_nullableâ, âpyarrowâ}, default ânumpy_nullableâ</span></dt>,\n",
       " <dt><strong>**kwargs</strong></dt>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em[-1].find_all(\"dt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A string or regex delimiter. The default of '\\\\s+' denotes\n",
      "one or more whitespace characters.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Back-end data type applied to the resultant DataFrame\n",
      "(still experimental). Behaviour is as follows:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\"numpy_nullable\": returns nullable-dtype-backed DataFrame\n",
      "(default).\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\n",
      "DataFrame.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "See read_csv() for the full argument list.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for p in em[-1].find_all(\"p\"):\n",
    "\n",
    "    if p.find(attrs={\"class\":\"versionmodified added\"}) is None and p.find(attrs={\"class\":\"versionmodified changed\"}) is None:\n",
    "        print(p.text)\n",
    "        print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openbb-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
