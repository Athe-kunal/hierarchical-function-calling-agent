{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "base_url = \"https://pandas.pydata.org/docs/reference/index.html\"\n",
    "response = requests.get(base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, \"lxml\")\n",
    "navbar = soup.find_all(attrs={\"class\": \"reference internal\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://pandas.pydata.org/docs/reference/io.html'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_url = \"https://pandas.pydata.org/docs/reference/\"\n",
    "ref_url+ navbar[0]['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_level = {}\n",
    "for nbar in navbar:\n",
    "    text_val = nbar.text\n",
    "    href = nbar['href']\n",
    "    full_url = ref_url+ href\n",
    "    if  \"#\" not in href:\n",
    "        first_level.update({href:{\"functions\":[],\"name\":text_val,\"url\":full_url}})\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nbar in navbar:\n",
    "    text_val = nbar.text\n",
    "    href = nbar['href']\n",
    "    full_url = ref_url+ href\n",
    "    if \"#\" in href:\n",
    "        parent_html = href.split(\"#\")[0]\n",
    "        if parent_html in first_level:\n",
    "            first_level[parent_html]['functions'].append({\"name\":text_val,\"url\":full_url})\n",
    "        else:\n",
    "            print(text_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://pandas.pydata.org/docs/reference/io.html'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_level['io.html']['url']\n",
    "# https://pandas.pydata.org/docs/reference/io.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRACTING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parent_url = first_level['io.html']['url']\n",
    "\n",
    "# parent_soup = BeautifulSoup(requests.get(parent_url).text,'lxml')\n",
    "# url_id = \"pickling\"\n",
    "# s1 = parent_soup.find(attrs={\"id\":url_id})\n",
    "# s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object is not subscriptable\n",
      "arrays.html objects\n"
     ]
    }
   ],
   "source": [
    "base_func_url = \"https://pandas.pydata.org/docs/reference/\"\n",
    "for first_level_name in first_level:\n",
    "    parent_url = first_level[first_level_name]['url']\n",
    "    parent_soup = BeautifulSoup(requests.get(parent_url).text,'lxml')\n",
    "    all_urls = []\n",
    "    for func in first_level[first_level_name]['functions']:\n",
    "        url_id = func['url'].split(\"/\")[-1].split(\"#\")[-1]\n",
    "        try:\n",
    "            func_url = parent_soup.find(attrs={\"id\":url_id}).find(attrs={\"class\":\"row-odd\"}).find('a')['href']\n",
    "            all_urls.append(base_func_url+func_url)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(first_level_name,url_id)\n",
    "    first_level[first_level_name]['function_urls'] = all_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:02<00:00,  7.19it/s]\n",
      "100%|██████████| 9/9 [00:01<00:00,  7.96it/s]\n",
      " 93%|█████████▎| 14/15 [00:01<00:00,  7.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n",
      "pandas.Series.str Vectorized string functions for Series and Index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:02<00:00,  7.14it/s]\n",
      " 82%|████████▏ | 14/17 [00:01<00:00,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n",
      "pandas.DataFrame.attrs Dictionary of global attributes of this dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:02<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n",
      "pandas.DataFrame.sparse.density Ratio of non-sparse points to total (dense) data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  7.60it/s]\n",
      "100%|██████████| 8/8 [00:01<00:00,  6.82it/s]\n",
      " 81%|████████  | 29/36 [00:04<00:01,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n",
      "pandas.tseries.offsets.Tick Attributes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:06<00:00,  5.93it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n",
      "pandas.api.indexers.BaseIndexer Base class for window bounds calculations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  8.41it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  8.65it/s]\n",
      " 60%|██████    | 3/5 [00:00<00:00,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'text'\n",
      "pandas.io.formats.style.Styler.env Helps style a DataFrame or Series according to the data with HTML and CSS.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.14it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  8.83it/s]\n",
      "0it [00:00, ?it/s]\n",
      " 75%|███████▌  | 3/4 [00:00<00:00,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n",
      "pandas.errors.AbstractMethodError Raise this error instead of NotImplementedError for abstract methods.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  7.38it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "def get_param_data(first_level):\n",
    "    for parent, values in first_level.items():\n",
    "        for func_url in tqdm(values['function_urls']):\n",
    "            func_response = requests.get(func_url)\n",
    "            func_soup = BeautifulSoup(func_response.text, \"lxml\")\n",
    "            \n",
    "            func_name = func_soup.find(\"h1\").text.replace(\"#\",\"\") #remove #\n",
    "            try:\n",
    "                elem = func_soup.find(attrs={\"class\":\"sig sig-object py\"})\n",
    "                full_function = elem.text.replace(\"[source]#\",\"\").replace(\"\\n\",\"\")\n",
    "                func_text = func_soup.find(\"dd\").find('p').text\n",
    "                em = func_soup.find_all(attrs={\"class\":\"field-odd\"})\n",
    "                param_names = em[-1].find_all(\"dt\")\n",
    "                desc_list = em[-1].find_all(\"dd\")\n",
    "\n",
    "                if len(param_names)!=len(desc_list):\n",
    "                    print(func_name)\n",
    "                    print(f\"param_names={len(param_names)} and desc_list={len(desc_list)}\")\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(func_name,func_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_url = 'https://pandas.pydata.org/docs/reference/api/pandas.read_clipboard.html'\n",
    "func_url = 'https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.nanoseconds.html'\n",
    "func_response = requests.get(func_url)\n",
    "func_soup = BeautifulSoup(func_response.content, \"lxml\",from_encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_name = func_soup.find(\"h1\").text.replace(\"#\",\"\") #remove #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pandas.Series.dt.nanoseconds'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "elem = func_soup.find(attrs={\"class\":\"sig sig-object py\"})\n",
    "full_function = elem.text.replace(\"[source]#\",\"\").replace(\"\\n\",\"\")\n",
    "func_text = func_soup.find(\"dd\").find('p').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of nanoseconds (>= 0 and less than 1 microsecond) for each element.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = func_soup.find(attrs={\"class\":\"field-list\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m em1 \u001b[38;5;241m=\u001b[39m \u001b[43mparam_names\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_all\u001b[49m(attrs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfield-odd\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "em1 = param_names.find_all(attrs={\"class\":\"field-odd\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<dt><strong>extra_args</strong><span class=\"classifier\">list[str], default None</span></dt>,\n",
       " <dt><strong>run_doctests</strong><span class=\"classifier\">bool, default False</span></dt>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(em[-1].find_all('dt'))\n",
    "em[-1].find_all('dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extra_argslist[str], default None\n",
      "Extra marks to run the tests.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "run_doctestsbool, default False\n",
      "Whether to only run the Python and Cython doctests. If you would like to run\n",
      "both doctests/regular tests, just append ââdoctest-modulesâ/ââdoctest-cythonâ\n",
      "to extra_args.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def remove_non_english(sentence):\n",
    "    # Define a regular expression pattern to match non-English characters\n",
    "    non_english_pattern = re.compile(r'[^a-zA-Z0-9\\s,.!?}(){]+\\\\')\n",
    "    \n",
    "    # Replace non-English characters with an empty string\n",
    "    cleaned_sentence = non_english_pattern.sub('', sentence)\n",
    "    # cleaned_sentence = re.sub('â','',sentence)\n",
    "    # cleaned_sentence = re.sub('â','',sentence)\n",
    "    return cleaned_sentence\n",
    "for pname,param_desc in zip(em[-1].find_all('dt'),em[-1].find_all('dd')):\n",
    "    # print('-'*100)\n",
    "    param_name_text = pname.text\n",
    "    desc_text = param_desc.text\n",
    "    if \"**kwargs\" in param_name_text: continue\n",
    "    process_param_name = remove_non_english(param_name_text)\n",
    "    process_desc_text = remove_non_english(desc_text)\n",
    "    # print(process_param_name)\n",
    "    # print(process_desc_text)\n",
    "    print(pname.text.strip())\n",
    "    print(param_desc.text.strip())\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"classifier\">str, default â\\s+â</span>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_soup.find(attrs={\"class\":\"field-list\"}).find(attrs={\"class\":\"classifier\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "em = func_soup.find_all(attrs={\"class\":\"field-odd\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<dt><strong>sep</strong><span class=\"classifier\">str, default â\\s+â</span></dt>,\n",
       " <dt><strong>dtype_backend</strong><span class=\"classifier\">{ânumpy_nullableâ, âpyarrowâ}, default ânumpy_nullableâ</span></dt>,\n",
       " <dt><strong>**kwargs</strong></dt>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em[-1].find_all(\"dt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A string or regex delimiter. The default of '\\\\s+' denotes\n",
      "one or more whitespace characters.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Back-end data type applied to the resultant DataFrame\n",
      "(still experimental). Behaviour is as follows:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\"numpy_nullable\": returns nullable-dtype-backed DataFrame\n",
      "(default).\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\n",
      "DataFrame.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "See read_csv() for the full argument list.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for p in em[-1].find_all(\"p\"):\n",
    "\n",
    "    if p.find(attrs={\"class\":\"versionmodified added\"}) is None and p.find(attrs={\"class\":\"versionmodified changed\"}) is None:\n",
    "        print(p.text)\n",
    "        print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openbb-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
