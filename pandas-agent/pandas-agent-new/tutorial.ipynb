{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object is not subscriptable\n",
      "<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">index_class</span></code></p></td>\n",
      "<td><p>The Index subclass to return from Index.__new__ when this dtype is encountered.</p></td>\n",
      "</tr>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'NoneType' object is not subscriptable\n",
      "<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">na_value</span></code></p></td>\n",
      "<td><p>Default NA value to use for this type.</p></td>\n",
      "</tr>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'NoneType' object is not subscriptable\n",
      "<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">names</span></code></p></td>\n",
      "<td><p>Ordered list of field names, or None if there are no fields.</p></td>\n",
      "</tr>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'NoneType' object is not subscriptable\n",
      "<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">kind</span></code></p></td>\n",
      "<td><p>A character code (one of 'biufcmMOSUV'), default 'O'</p></td>\n",
      "</tr>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'NoneType' object is not subscriptable\n",
      "<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">name</span></code></p></td>\n",
      "<td><p>A string identifying the data type.</p></td>\n",
      "</tr>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'NoneType' object is not subscriptable\n",
      "<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">type</span></code></p></td>\n",
      "<td><p>The scalar type for the array, e.g. <code class=\"docutils literal notranslate\"><span class=\"pre\">int</span></code>.</p></td>\n",
      "</tr>\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [15:55<00:00, 24.51s/it]  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'io.html': {'functions': [{'Pickling': [{'func_name': 'read_pickle(filepath_or_buffer[,\\xa0...])',\n",
       "      'func_desc': 'Load pickled pandas object (or any object) from file.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.read_pickle.html#pandas.read_pickle',\n",
       "      'function_definitions': {'function_name': 'pandas.read_pickle',\n",
       "       'full_function': \"pandas.read_pickle(filepath_or_buffer, compression='infer', storage_options=None)\",\n",
       "       'function_text': 'Load pickled pandas object (or any object) from file. Warning Loading pickled data received from untrusted sources can be\\nunsafe. See here.',\n",
       "       'parameter_names_desc': [{'param_name': 'filepath_or_buffer',\n",
       "         'param_type': 'str, path object, or file-like object',\n",
       "         'param_desc': 'String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a binary readlines() function.\\nAlso accepts URL. URL is not limited to S3 and GCS.\\n'},\n",
       "        {'param_name': 'compression',\n",
       "         'param_type': 'str or dict, default ‘infer’',\n",
       "         'param_desc': \"For on-the-fly decompression of on-disk data. If ‘infer’ and ‘filepath_or_buffer’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nIf using ‘zip’ or ‘tar’, the ZIP file must contain only one data file to be read in.\\nSet to None for no decompression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdDecompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for Zstandard decompression using a\\ncustom compression dictionary:\\ncompression={'method': 'zstd', 'dict_data': my_compression_dict}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\n\\n\\nChanged in version 1.4.0: Zstandard support.\\n\\n\"},\n",
       "        {'param_name': 'storage_options',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.read_pickle',\n",
       "       'descriptions': 'Load pickled pandas object (or any object) from file. Warning Loading pickled data received from untrusted sources can be\\nunsafe. See here.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'filepath_or_buffer': {'type': 'string',\n",
       "          'description': 'str, path object, or file-like object. String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a binary readlines() function.\\nAlso accepts URL. URL is not limited to S3 and GCS.\\n'},\n",
       "         'compression': {'type': 'string',\n",
       "          'description': \"str or dict, default ‘infer’. For on-the-fly decompression of on-disk data. If ‘infer’ and ‘filepath_or_buffer’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nIf using ‘zip’ or ‘tar’, the ZIP file must contain only one data file to be read in.\\nSet to None for no decompression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdDecompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for Zstandard decompression using a\\ncustom compression dictionary:\\ncompression={'method': 'zstd', 'dict_data': my_compression_dict}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\n\\n\\nChanged in version 1.4.0: Zstandard support.\\n\\n\"},\n",
       "         'storage_options': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.to_pickle(path,\\xa0*[,\\xa0compression,\\xa0...])',\n",
       "      'func_desc': 'Pickle (serialize) object to file.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_pickle.html#pandas.DataFrame.to_pickle',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_pickle',\n",
       "       'full_function': \"DataFrame.to_pickle(path, *, compression='infer', protocol=5, storage_options=None)\",\n",
       "       'function_text': 'Pickle (serialize) object to file.',\n",
       "       'parameter_names_desc': [{'param_name': 'path',\n",
       "         'param_type': 'str, path object, or file-like object',\n",
       "         'param_desc': 'String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a binary write() function. File path where\\nthe pickled object will be stored.\\n'},\n",
       "        {'param_name': 'compression',\n",
       "         'param_type': 'str or dict, default ‘infer’',\n",
       "         'param_desc': \"For on-the-fly compression of the output data. If ‘infer’ and ‘path’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nSet to None for no compression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for faster compression and to create\\na reproducible gzip archive:\\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\n\\n\"},\n",
       "        {'param_name': 'protocol',\n",
       "         'param_type': 'int',\n",
       "         'param_desc': 'Int which indicates which protocol should be used by the pickler,\\ndefault HIGHEST_PROTOCOL (see [1] paragraph 12.1.2). The possible\\nvalues are 0, 1, 2, 3, 4, 5. A negative value for the protocol\\nparameter is equivalent to setting its value to HIGHEST_PROTOCOL.\\n\\n\\n[1]\\nhttps://docs.python.org/3/library/pickle.html.\\n\\n\\n'},\n",
       "        {'param_name': 'storage_options',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.to_pickle',\n",
       "       'descriptions': 'Pickle (serialize) object to file.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'path': {'type': 'string',\n",
       "          'description': 'str, path object, or file-like object. String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a binary write() function. File path where\\nthe pickled object will be stored.\\n'},\n",
       "         'compression': {'type': 'string',\n",
       "          'description': \"str or dict, default ‘infer’. For on-the-fly compression of the output data. If ‘infer’ and ‘path’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nSet to None for no compression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for faster compression and to create\\na reproducible gzip archive:\\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\n\\n\"},\n",
       "         'protocol': {'type': 'integer',\n",
       "          'description': 'int. Int which indicates which protocol should be used by the pickler,\\ndefault HIGHEST_PROTOCOL (see [1] paragraph 12.1.2). The possible\\nvalues are 0, 1, 2, 3, 4, 5. A negative value for the protocol\\nparameter is equivalent to setting its value to HIGHEST_PROTOCOL.\\n\\n\\n[1]\\nhttps://docs.python.org/3/library/pickle.html.\\n\\n\\n'},\n",
       "         'storage_options': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'}},\n",
       "        'required': ['path']}}}]},\n",
       "   {'Flat file': [{'func_name': 'read_table(filepath_or_buffer,\\xa0*[,\\xa0sep,\\xa0...])',\n",
       "      'func_desc': 'Read general delimited file into DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.read_table.html#pandas.read_table',\n",
       "      'function_definitions': {'function_name': 'pandas.read_table',\n",
       "       'full_function': 'pandas.read_table(filepath_or_buffer, *, sep=_NoDefault.no_default, delimiter=None, header=\\'infer\\', names=_NoDefault.no_default, index_col=None, usecols=None, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skipinitialspace=False, skiprows=None, skipfooter=0, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=_NoDefault.no_default, skip_blank_lines=True, parse_dates=False, infer_datetime_format=_NoDefault.no_default, keep_date_col=_NoDefault.no_default, date_parser=_NoDefault.no_default, date_format=None, dayfirst=False, cache_dates=True, iterator=False, chunksize=None, compression=\\'infer\\', thousands=None, decimal=\\'.\\', lineterminator=None, quotechar=\\'\"\\', quoting=0, doublequote=True, escapechar=None, comment=None, encoding=None, encoding_errors=\\'strict\\', dialect=None, on_bad_lines=\\'error\\', delim_whitespace=_NoDefault.no_default, low_memory=True, memory_map=False, float_precision=None, storage_options=None, dtype_backend=_NoDefault.no_default)',\n",
       "       'function_text': 'Read general delimited file into DataFrame. Also supports optionally iterating or breaking of the file\\ninto chunks. Additional help can be found in the online docs for\\nIO Tools.',\n",
       "       'parameter_names_desc': [{'param_name': 'filepath_or_buffer',\n",
       "         'param_type': 'str, path object or file-like object',\n",
       "         'param_desc': 'Any valid string path is acceptable. The string could be a URL. Valid\\nURL schemes include http, ftp, s3, gs, and file. For file URLs, a host is\\nexpected. A local file could be: file://localhost/path/to/table.csv.\\nIf you want to pass in a path object, pandas accepts any os.PathLike.\\nBy file-like object, we refer to objects with a read() method, such as\\na file handle (e.g. via builtin open function) or StringIO.\\n'},\n",
       "        {'param_name': 'sep',\n",
       "         'param_type': 'str, default ‘\\\\t’ (tab-stop)',\n",
       "         'param_desc': \"Character or regex pattern to treat as the delimiter. If sep=None, the\\nC engine cannot automatically detect\\nthe separator, but the Python parsing engine can, meaning the latter will\\nbe used and automatically detect the separator from only the first valid\\nrow of the file by Python’s builtin sniffer tool, csv.Sniffer.\\nIn addition, separators longer than 1 character and different from\\n'\\\\s+' will be interpreted as regular expressions and will also force\\nthe use of the Python parsing engine. Note that regex delimiters are prone\\nto ignoring quoted data. Regex example: '\\\\r\\\\t'.\\n\"},\n",
       "        {'param_name': 'delimiter',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Alias for sep.\\n'},\n",
       "        {'param_name': 'header',\n",
       "         'param_type': 'int, Sequence of int, ‘infer’ or None, default ‘infer’',\n",
       "         'param_desc': 'Row number(s) containing column labels and marking the start of the\\ndata (zero-indexed). Default behavior is to infer the column names: if no names\\nare passed the behavior is identical to header=0 and column\\nnames are inferred from the first line of the file, if column\\nnames are passed explicitly to names then the behavior is identical to\\nheader=None. Explicitly pass header=0 to be able to\\nreplace existing names. The header can be a list of integers that\\nspecify row locations for a MultiIndex on the columns\\ne.g. [0, 1, 3]. Intervening rows that are not specified will be\\nskipped (e.g. 2 in this example is skipped). Note that this\\nparameter ignores commented lines and empty lines if\\nskip_blank_lines=True, so header=0 denotes the first line of\\ndata rather than the first line of the file.\\n'},\n",
       "        {'param_name': 'names',\n",
       "         'param_type': 'Sequence of Hashable, optional',\n",
       "         'param_desc': 'Sequence of column labels to apply. If the file contains a header row,\\nthen you should explicitly pass header=0 to override the column names.\\nDuplicates in this list are not allowed.\\n'},\n",
       "        {'param_name': 'index_col',\n",
       "         'param_type': 'Hashable, Sequence of Hashable or False, optional',\n",
       "         'param_desc': 'Column(s) to use as row label(s), denoted either by column labels or column\\nindices. If a sequence of labels or indices is given, MultiIndex\\nwill be formed for the row labels.\\nNote: index_col=False can be used to force pandas to not use the first\\ncolumn as the index, e.g., when you have a malformed file with delimiters at\\nthe end of each line.\\n'},\n",
       "        {'param_name': 'usecols',\n",
       "         'param_type': 'Sequence of Hashable or Callable, optional',\n",
       "         'param_desc': \"Subset of columns to select, denoted either by column labels or column indices.\\nIf list-like, all elements must either\\nbe positional (i.e. integer indices into the document columns) or strings\\nthat correspond to column names provided either by the user in names or\\ninferred from the document header row(s). If names are given, the document\\nheader row(s) are not taken into account. For example, a valid list-like\\nusecols parameter would be [0, 1, 2] or ['foo', 'bar', 'baz'].\\nElement order is ignored, so usecols=[0, 1] is the same as [1, 0].\\nTo instantiate a DataFrame from data with element order\\npreserved use pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]\\nfor columns in ['foo', 'bar'] order or\\npd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]\\nfor ['bar', 'foo'] order.\\nIf callable, the callable function will be evaluated against the column\\nnames, returning names where the callable function evaluates to True. An\\nexample of a valid callable argument would be lambda x: x.upper() in\\n['AAA', 'BBB', 'DDD']. Using this parameter results in much faster\\nparsing time and lower memory usage.\\n\"},\n",
       "        {'param_name': 'dtype',\n",
       "         'param_type': 'dtype or dict of {Hashable',\n",
       "         'param_desc': \"Data type(s) to apply to either the whole dataset or individual columns.\\nE.g., {'a': np.float64, 'b': np.int32, 'c': 'Int64'}\\nUse str or object together with suitable na_values settings\\nto preserve and not interpret dtype.\\nIf converters are specified, they will be applied INSTEAD\\nof dtype conversion.\\n\\nNew in version 1.5.0: Support for defaultdict was added. Specify a defaultdict as input where\\nthe default determines the dtype of the columns which are not explicitly\\nlisted.\\n\\n\"},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': '{‘c’, ‘python’, ‘pyarrow’}, optional',\n",
       "         'param_desc': 'Parser engine to use. The C and pyarrow engines are faster, while the python engine\\nis currently more feature-complete. Multithreading is currently only supported by\\nthe pyarrow engine.\\n\\nNew in version 1.4.0: The ‘pyarrow’ engine was added as an experimental engine, and some features\\nare unsupported, or may not work correctly, with this engine.\\n\\n'},\n",
       "        {'param_name': 'converters',\n",
       "         'param_type': 'dict of {Hashable',\n",
       "         'param_desc': 'Functions for converting values in specified columns. Keys can either\\nbe column labels or column indices.\\n'},\n",
       "        {'param_name': 'true_values',\n",
       "         'param_type': 'list, optional',\n",
       "         'param_desc': 'Values to consider as True in addition to case-insensitive variants of ‘True’.\\n'},\n",
       "        {'param_name': 'false_values',\n",
       "         'param_type': 'list, optional',\n",
       "         'param_desc': 'Values to consider as False in addition to case-insensitive variants of ‘False’.\\n'},\n",
       "        {'param_name': 'skipinitialspace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Skip spaces after delimiter.\\n'},\n",
       "        {'param_name': 'skiprows',\n",
       "         'param_type': 'int, list of int or Callable, optional',\n",
       "         'param_desc': 'Line numbers to skip (0-indexed) or number of lines to skip (int)\\nat the start of the file.\\nIf callable, the callable function will be evaluated against the row\\nindices, returning True if the row should be skipped and False otherwise.\\nAn example of a valid callable argument would be lambda x: x in [0, 2].\\n'},\n",
       "        {'param_name': 'skipfooter',\n",
       "         'param_type': 'int, default 0',\n",
       "         'param_desc': \"Number of lines at bottom of file to skip (Unsupported with engine='c').\\n\"},\n",
       "        {'param_name': 'nrows',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Number of rows of file to read. Useful for reading pieces of large files.\\n'},\n",
       "        {'param_name': 'na_values',\n",
       "         'param_type': 'Hashable, Iterable of Hashable or dict of {Hashable',\n",
       "         'param_desc': 'Additional strings to recognize as NA/NaN. If dict passed, specific\\nper-column NA values. By default the following values are interpreted as\\nNaN: “ “, “#N/A”, “#N/A N/A”, “#NA”, “-1.#IND”, “-1.#QNAN”, “-NaN”, “-nan”,\\n“1.#IND”, “1.#QNAN”, “<NA>”, “N/A”, “NA”, “NULL”, “NaN”, “None”,\\n“n/a”, “nan”, “null “.\\n'},\n",
       "        {'param_name': 'keep_default_na',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether or not to include the default NaN values when parsing the data.\\nDepending on whether na_values is passed in, the behavior is as follows:\\n\\nIf keep_default_na is True, and na_values are specified, na_values\\nis appended to the default NaN values used for parsing.\\nIf keep_default_na is True, and na_values are not specified, only\\nthe default NaN values are used for parsing.\\nIf keep_default_na is False, and na_values are specified, only\\nthe NaN values specified na_values are used for parsing.\\nIf keep_default_na is False, and na_values are not specified, no\\nstrings will be parsed as NaN.\\n\\nNote that if na_filter is passed in as False, the keep_default_na and\\nna_values parameters will be ignored.\\n'},\n",
       "        {'param_name': 'na_filter',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Detect missing value markers (empty strings and the value of na_values). In\\ndata without any NA values, passing na_filter=False can improve the\\nperformance of reading a large file.\\n'},\n",
       "        {'param_name': 'verbose',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Indicate number of NA values placed in non-numeric columns.\\n\\nDeprecated since version 2.2.0.\\n\\n'},\n",
       "        {'param_name': 'skip_blank_lines',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If True, skip over blank lines rather than interpreting as NaN values.\\n'},\n",
       "        {'param_name': 'parse_dates',\n",
       "         'param_type': 'bool, list of Hashable, list of lists or dict of {Hashable',\n",
       "         'param_desc': \"The behavior is as follows:\\n\\nbool. If True -> try parsing the index. Note: Automatically set to\\nTrue if date_format or date_parser arguments have been passed.\\nlist of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\\neach as a separate date column.\\nlist of list. e.g. If [[1, 3]] -> combine columns 1 and 3 and parse\\nas a single date column. Values are joined with a space before parsing.\\ndict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call\\nresult ‘foo’. Values are joined with a space before parsing.\\n\\nIf a column or index cannot be represented as an array of datetime,\\nsay because of an unparsable value or a mixture of timezones, the column\\nor index will be returned unaltered as an object data type. For\\nnon-standard datetime parsing, use to_datetime() after\\nread_csv().\\nNote: A fast-path exists for iso8601-formatted dates.\\n\"},\n",
       "        {'param_name': 'infer_datetime_format',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True and parse_dates is enabled, pandas will attempt to infer the\\nformat of the datetime strings in the columns, and if it can be inferred,\\nswitch to a faster method of parsing them. In some cases this can increase\\nthe parsing speed by 5-10x.\\n\\nDeprecated since version 2.0.0: A strict version of this argument is now the default, passing it has no effect.\\n\\n'},\n",
       "        {'param_name': 'keep_date_col',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True and parse_dates specifies combining multiple columns then\\nkeep the original columns.\\n'},\n",
       "        {'param_name': 'date_parser',\n",
       "         'param_type': 'Callable, optional',\n",
       "         'param_desc': 'Function to use for converting a sequence of string columns to an array of\\ndatetime instances. The default uses dateutil.parser.parser to do the\\nconversion. pandas will try to call date_parser in three different ways,\\nadvancing to the next if an exception occurs: 1) Pass one or more arrays\\n(as defined by parse_dates) as arguments; 2) concatenate (row-wise) the\\nstring values from the columns defined by parse_dates into a single array\\nand pass that; and 3) call date_parser once for each row using one or\\nmore strings (corresponding to the columns defined by parse_dates) as\\narguments.\\n\\nDeprecated since version 2.0.0: Use date_format instead, or read in as object and then apply\\nto_datetime() as-needed.\\n\\n'},\n",
       "        {'param_name': 'date_format',\n",
       "         'param_type': 'str or dict of column -> format, optional',\n",
       "         'param_desc': 'Format to use for parsing dates when used in conjunction with parse_dates.\\nThe strftime to parse time, e.g. \"%d/%m/%Y\". See\\nstrftime documentation for more information on choices, though\\nnote that \"%f\" will parse all the way up to nanoseconds.\\nYou can also pass:\\n\\n\\n“ISO8601”, to parse any ISO8601time string (not necessarily in exactly the same format);\\n\\n\\n\\n\\n“mixed”, to infer the format for each element individually. This is risky,and you should probably use it along with dayfirst.\\n\\n\\n\\n\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "        {'param_name': 'dayfirst',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'DD/MM format dates, international and European format.\\n'},\n",
       "        {'param_name': 'cache_dates',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If True, use a cache of unique, converted dates to apply the datetime\\nconversion. May produce significant speed-up when parsing duplicate\\ndate strings, especially ones with timezone offsets.\\n'},\n",
       "        {'param_name': 'iterator',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Return TextFileReader object for iteration or getting chunks with\\nget_chunk().\\n'},\n",
       "        {'param_name': 'chunksize',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Number of lines to read from the file per chunk. Passing a value will cause the\\nfunction to return a TextFileReader object for iteration.\\nSee the IO Tools docs\\nfor more information on iterator and chunksize.\\n'},\n",
       "        {'param_name': 'compression',\n",
       "         'param_type': 'str or dict, default ‘infer’',\n",
       "         'param_desc': \"For on-the-fly decompression of on-disk data. If ‘infer’ and ‘filepath_or_buffer’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nIf using ‘zip’ or ‘tar’, the ZIP file must contain only one data file to be read in.\\nSet to None for no decompression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdDecompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for Zstandard decompression using a\\ncustom compression dictionary:\\ncompression={'method': 'zstd', 'dict_data': my_compression_dict}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\n\\n\\nChanged in version 1.4.0: Zstandard support.\\n\\n\"},\n",
       "        {'param_name': 'thousands',\n",
       "         'param_type': 'str (length 1), optional',\n",
       "         'param_desc': 'Character acting as the thousands separator in numerical values.\\n'},\n",
       "        {'param_name': 'decimal',\n",
       "         'param_type': 'str (length 1), default ‘.’',\n",
       "         'param_desc': 'Character to recognize as decimal point (e.g., use ‘,’ for European data).\\n'},\n",
       "        {'param_name': 'lineterminator',\n",
       "         'param_type': 'str (length 1), optional',\n",
       "         'param_desc': 'Character used to denote a line break. Only valid with C parser.\\n'},\n",
       "        {'param_name': 'quotechar',\n",
       "         'param_type': 'str (length 1), optional',\n",
       "         'param_desc': 'Character used to denote the start and end of a quoted item. Quoted\\nitems can include the delimiter and it will be ignored.\\n'},\n",
       "        {'param_name': 'quoting',\n",
       "         'param_type': '{0 or csv.QUOTE_MINIMAL, 1 or csv.QUOTE_ALL, 2 or csv.QUOTE_NONNUMERIC, 3 or csv.QUOTE_NONE}, default csv.QUOTE_MINIMAL',\n",
       "         'param_desc': 'Control field quoting behavior per csv.QUOTE_* constants. Default is\\ncsv.QUOTE_MINIMAL (i.e., 0) which implies that only fields containing special\\ncharacters are quoted (e.g., characters defined in quotechar, delimiter,\\nor lineterminator.\\n'},\n",
       "        {'param_name': 'doublequote',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'When quotechar is specified and quoting is not QUOTE_NONE, indicate\\nwhether or not to interpret two consecutive quotechar elements INSIDE a\\nfield as a single quotechar element.\\n'},\n",
       "        {'param_name': 'escapechar',\n",
       "         'param_type': 'str (length 1), optional',\n",
       "         'param_desc': 'Character used to escape other characters.\\n'},\n",
       "        {'param_name': 'comment',\n",
       "         'param_type': 'str (length 1), optional',\n",
       "         'param_desc': \"Character indicating that the remainder of line should not be parsed.\\nIf found at the beginning\\nof a line, the line will be ignored altogether. This parameter must be a\\nsingle character. Like empty lines (as long as skip_blank_lines=True),\\nfully commented lines are ignored by the parameter header but not by\\nskiprows. For example, if comment='#', parsing\\n#empty\\\\na,b,c\\\\n1,2,3 with header=0 will result in 'a,b,c' being\\ntreated as the header.\\n\"},\n",
       "        {'param_name': 'encoding',\n",
       "         'param_type': 'str, optional, default ‘utf-8’',\n",
       "         'param_desc': \"Encoding to use for UTF when reading/writing (ex. 'utf-8'). List of Python\\nstandard encodings .\\n\"},\n",
       "        {'param_name': 'encoding_errors',\n",
       "         'param_type': 'str, optional, default ‘strict’',\n",
       "         'param_desc': 'How encoding errors are treated. List of possible values .\\n\\nNew in version 1.3.0.\\n\\n'},\n",
       "        {'param_name': 'dialect',\n",
       "         'param_type': 'str or csv.Dialect, optional',\n",
       "         'param_desc': 'If provided, this parameter will override values (default or not) for the\\nfollowing parameters: delimiter, doublequote, escapechar,\\nskipinitialspace, quotechar, and quoting. If it is necessary to\\noverride values, a ParserWarning will be issued. See csv.Dialect\\ndocumentation for more details.\\n'},\n",
       "        {'param_name': 'on_bad_lines',\n",
       "         'param_type': '{‘error’, ‘warn’, ‘skip’} or Callable, default ‘error’',\n",
       "         'param_desc': \"Specifies what to do upon encountering a bad line (a line with too many fields).\\nAllowed values are :\\n\\n'error', raise an Exception when a bad line is encountered.\\n'warn', raise a warning when a bad line is encountered and skip that line.\\n'skip', skip bad lines without raising or warning when they are encountered.\\n\\n\\nNew in version 1.3.0.\\n\\n\\nNew in version 1.4.0: \\n\\nCallable, function with signature\\n(bad_line: list[str]) -> list[str] | None that will process a single\\nbad line. bad_line is a list of strings split by the sep.\\nIf the function returns None, the bad line will be ignored.\\nIf the function returns a new list of strings with more elements than\\nexpected, a ParserWarning will be emitted while dropping extra elements.\\nOnly supported when engine='python'\\n\\n\\n\\nChanged in version 2.2.0: \\n\\nCallable, function with signature\\nas described in pyarrow documentation when engine='pyarrow'\\n\\n\\n\"},\n",
       "        {'param_name': 'delim_whitespace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Specifies whether or not whitespace (e.g. \\' \\' or \\'\\\\t\\') will be\\nused as the sep delimiter. Equivalent to setting sep=\\'\\\\s+\\'. If this option\\nis set to True, nothing should be passed in for the delimiter\\nparameter.\\n\\nDeprecated since version 2.2.0: Use sep=\"\\\\s+\" instead.\\n\\n'},\n",
       "        {'param_name': 'low_memory',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Internally process the file in chunks, resulting in lower memory use\\nwhile parsing, but possibly mixed type inference. To ensure no mixed\\ntypes either set False, or specify the type with the dtype parameter.\\nNote that the entire file is read into a single DataFrame\\nregardless, use the chunksize or iterator parameter to return the data in\\nchunks. (Only valid with C parser).\\n'},\n",
       "        {'param_name': 'memory_map',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If a filepath is provided for filepath_or_buffer, map the file object\\ndirectly onto memory and access the data directly from there. Using this\\noption can improve performance because there is no longer any I/O overhead.\\n'},\n",
       "        {'param_name': 'float_precision',\n",
       "         'param_type': '{‘high’, ‘legacy’, ‘round_trip’}, optional',\n",
       "         'param_desc': \"Specifies which converter the C engine should use for floating-point\\nvalues. The options are None or 'high' for the ordinary converter,\\n'legacy' for the original lower precision pandas converter, and\\n'round_trip' for the round-trip converter.\\n\"},\n",
       "        {'param_name': 'storage_options',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'},\n",
       "        {'param_name': 'dtype_backend',\n",
       "         'param_type': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’',\n",
       "         'param_desc': 'Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.read_table',\n",
       "       'descriptions': 'Read general delimited file into DataFrame. Also supports optionally iterating or breaking of the file\\ninto chunks. Additional help can be found in the online docs for\\nIO Tools.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'filepath_or_buffer': {'type': 'string',\n",
       "          'description': 'str, path object or file-like object. Any valid string path is acceptable. The string could be a URL. Valid\\nURL schemes include http, ftp, s3, gs, and file. For file URLs, a host is\\nexpected. A local file could be: file://localhost/path/to/table.csv.\\nIf you want to pass in a path object, pandas accepts any os.PathLike.\\nBy file-like object, we refer to objects with a read() method, such as\\na file handle (e.g. via builtin open function) or StringIO.\\n'},\n",
       "         'sep': {'type': 'string',\n",
       "          'description': \"str, default ‘\\\\t’ (tab-stop). Character or regex pattern to treat as the delimiter. If sep=None, the\\nC engine cannot automatically detect\\nthe separator, but the Python parsing engine can, meaning the latter will\\nbe used and automatically detect the separator from only the first valid\\nrow of the file by Python’s builtin sniffer tool, csv.Sniffer.\\nIn addition, separators longer than 1 character and different from\\n'\\\\s+' will be interpreted as regular expressions and will also force\\nthe use of the Python parsing engine. Note that regex delimiters are prone\\nto ignoring quoted data. Regex example: '\\\\r\\\\t'.\\n\"},\n",
       "         'delimiter': {'type': 'string',\n",
       "          'description': 'str, optional. Alias for sep.\\n'},\n",
       "         'header': {'type': 'integer',\n",
       "          'description': 'int, Sequence of int, ‘infer’ or None, default ‘infer’. Row number(s) containing column labels and marking the start of the\\ndata (zero-indexed). Default behavior is to infer the column names: if no names\\nare passed the behavior is identical to header=0 and column\\nnames are inferred from the first line of the file, if column\\nnames are passed explicitly to names then the behavior is identical to\\nheader=None. Explicitly pass header=0 to be able to\\nreplace existing names. The header can be a list of integers that\\nspecify row locations for a MultiIndex on the columns\\ne.g. [0, 1, 3]. Intervening rows that are not specified will be\\nskipped (e.g. 2 in this example is skipped). Note that this\\nparameter ignores commented lines and empty lines if\\nskip_blank_lines=True, so header=0 denotes the first line of\\ndata rather than the first line of the file.\\n'},\n",
       "         'names': {'type': 'Sequence of Hashable, optional',\n",
       "          'description': 'Sequence of Hashable, optional. Sequence of column labels to apply. If the file contains a header row,\\nthen you should explicitly pass header=0 to override the column names.\\nDuplicates in this list are not allowed.\\n'},\n",
       "         'index_col': {'type': 'Hashable, Sequence of Hashable or False, optional',\n",
       "          'description': 'Hashable, Sequence of Hashable or False, optional. Column(s) to use as row label(s), denoted either by column labels or column\\nindices. If a sequence of labels or indices is given, MultiIndex\\nwill be formed for the row labels.\\nNote: index_col=False can be used to force pandas to not use the first\\ncolumn as the index, e.g., when you have a malformed file with delimiters at\\nthe end of each line.\\n'},\n",
       "         'usecols': {'type': 'Sequence of Hashable or Callable, optional',\n",
       "          'description': \"Sequence of Hashable or Callable, optional. Subset of columns to select, denoted either by column labels or column indices.\\nIf list-like, all elements must either\\nbe positional (i.e. integer indices into the document columns) or strings\\nthat correspond to column names provided either by the user in names or\\ninferred from the document header row(s). If names are given, the document\\nheader row(s) are not taken into account. For example, a valid list-like\\nusecols parameter would be [0, 1, 2] or ['foo', 'bar', 'baz'].\\nElement order is ignored, so usecols=[0, 1] is the same as [1, 0].\\nTo instantiate a DataFrame from data with element order\\npreserved use pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]\\nfor columns in ['foo', 'bar'] order or\\npd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]\\nfor ['bar', 'foo'] order.\\nIf callable, the callable function will be evaluated against the column\\nnames, returning names where the callable function evaluates to True. An\\nexample of a valid callable argument would be lambda x: x.upper() in\\n['AAA', 'BBB', 'DDD']. Using this parameter results in much faster\\nparsing time and lower memory usage.\\n\"},\n",
       "         'dtype': {'type': 'dtype or dict of {Hashable',\n",
       "          'description': \"dtype or dict of {Hashable. Data type(s) to apply to either the whole dataset or individual columns.\\nE.g., {'a': np.float64, 'b': np.int32, 'c': 'Int64'}\\nUse str or object together with suitable na_values settings\\nto preserve and not interpret dtype.\\nIf converters are specified, they will be applied INSTEAD\\nof dtype conversion.\\n\\nNew in version 1.5.0: Support for defaultdict was added. Specify a defaultdict as input where\\nthe default determines the dtype of the columns which are not explicitly\\nlisted.\\n\\n\"},\n",
       "         'engine': {'type': 'string',\n",
       "          'enum': ['c', ' python', ' pyarrow'],\n",
       "          'description': '{‘c’, ‘python’, ‘pyarrow’}, optional. Parser engine to use. The C and pyarrow engines are faster, while the python engine\\nis currently more feature-complete. Multithreading is currently only supported by\\nthe pyarrow engine.\\n\\nNew in version 1.4.0: The ‘pyarrow’ engine was added as an experimental engine, and some features\\nare unsupported, or may not work correctly, with this engine.\\n\\n'},\n",
       "         'converters': {'type': 'dict of {Hashable',\n",
       "          'description': 'dict of {Hashable. Functions for converting values in specified columns. Keys can either\\nbe column labels or column indices.\\n'},\n",
       "         'true_values': {'type': 'array',\n",
       "          'description': 'list, optional. Values to consider as True in addition to case-insensitive variants of ‘True’.\\n'},\n",
       "         'false_values': {'type': 'array',\n",
       "          'description': 'list, optional. Values to consider as False in addition to case-insensitive variants of ‘False’.\\n'},\n",
       "         'skipinitialspace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Skip spaces after delimiter.\\n'},\n",
       "         'skiprows': {'type': 'integer',\n",
       "          'description': 'int, list of int or Callable, optional. Line numbers to skip (0-indexed) or number of lines to skip (int)\\nat the start of the file.\\nIf callable, the callable function will be evaluated against the row\\nindices, returning True if the row should be skipped and False otherwise.\\nAn example of a valid callable argument would be lambda x: x in [0, 2].\\n'},\n",
       "         'skipfooter': {'type': 'integer',\n",
       "          'description': \"int, default 0. Number of lines at bottom of file to skip (Unsupported with engine='c').\\n\"},\n",
       "         'nrows': {'type': 'integer',\n",
       "          'description': 'int, optional. Number of rows of file to read. Useful for reading pieces of large files.\\n'},\n",
       "         'na_values': {'type': 'Hashable, Iterable of Hashable or dict of {Hashable',\n",
       "          'description': 'Hashable, Iterable of Hashable or dict of {Hashable. Additional strings to recognize as NA/NaN. If dict passed, specific\\nper-column NA values. By default the following values are interpreted as\\nNaN: “ “, “#N/A”, “#N/A N/A”, “#NA”, “-1.#IND”, “-1.#QNAN”, “-NaN”, “-nan”,\\n“1.#IND”, “1.#QNAN”, “<NA>”, “N/A”, “NA”, “NULL”, “NaN”, “None”,\\n“n/a”, “nan”, “null “.\\n'},\n",
       "         'keep_default_na': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether or not to include the default NaN values when parsing the data.\\nDepending on whether na_values is passed in, the behavior is as follows:\\n\\nIf keep_default_na is True, and na_values are specified, na_values\\nis appended to the default NaN values used for parsing.\\nIf keep_default_na is True, and na_values are not specified, only\\nthe default NaN values are used for parsing.\\nIf keep_default_na is False, and na_values are specified, only\\nthe NaN values specified na_values are used for parsing.\\nIf keep_default_na is False, and na_values are not specified, no\\nstrings will be parsed as NaN.\\n\\nNote that if na_filter is passed in as False, the keep_default_na and\\nna_values parameters will be ignored.\\n'},\n",
       "         'na_filter': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Detect missing value markers (empty strings and the value of na_values). In\\ndata without any NA values, passing na_filter=False can improve the\\nperformance of reading a large file.\\n'},\n",
       "         'verbose': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Indicate number of NA values placed in non-numeric columns.\\n\\nDeprecated since version 2.2.0.\\n\\n'},\n",
       "         'skip_blank_lines': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If True, skip over blank lines rather than interpreting as NaN values.\\n'},\n",
       "         'parse_dates': {'type': 'boolean',\n",
       "          'description': \"bool, list of Hashable, list of lists or dict of {Hashable. The behavior is as follows:\\n\\nbool. If True -> try parsing the index. Note: Automatically set to\\nTrue if date_format or date_parser arguments have been passed.\\nlist of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\\neach as a separate date column.\\nlist of list. e.g. If [[1, 3]] -> combine columns 1 and 3 and parse\\nas a single date column. Values are joined with a space before parsing.\\ndict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call\\nresult ‘foo’. Values are joined with a space before parsing.\\n\\nIf a column or index cannot be represented as an array of datetime,\\nsay because of an unparsable value or a mixture of timezones, the column\\nor index will be returned unaltered as an object data type. For\\nnon-standard datetime parsing, use to_datetime() after\\nread_csv().\\nNote: A fast-path exists for iso8601-formatted dates.\\n\"},\n",
       "         'infer_datetime_format': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True and parse_dates is enabled, pandas will attempt to infer the\\nformat of the datetime strings in the columns, and if it can be inferred,\\nswitch to a faster method of parsing them. In some cases this can increase\\nthe parsing speed by 5-10x.\\n\\nDeprecated since version 2.0.0: A strict version of this argument is now the default, passing it has no effect.\\n\\n'},\n",
       "         'keep_date_col': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True and parse_dates specifies combining multiple columns then\\nkeep the original columns.\\n'},\n",
       "         'date_parser': {'type': 'Callable, optional',\n",
       "          'description': 'Callable, optional. Function to use for converting a sequence of string columns to an array of\\ndatetime instances. The default uses dateutil.parser.parser to do the\\nconversion. pandas will try to call date_parser in three different ways,\\nadvancing to the next if an exception occurs: 1) Pass one or more arrays\\n(as defined by parse_dates) as arguments; 2) concatenate (row-wise) the\\nstring values from the columns defined by parse_dates into a single array\\nand pass that; and 3) call date_parser once for each row using one or\\nmore strings (corresponding to the columns defined by parse_dates) as\\narguments.\\n\\nDeprecated since version 2.0.0: Use date_format instead, or read in as object and then apply\\nto_datetime() as-needed.\\n\\n'},\n",
       "         'date_format': {'type': 'string',\n",
       "          'description': 'str or dict of column -> format, optional. Format to use for parsing dates when used in conjunction with parse_dates.\\nThe strftime to parse time, e.g. \"%d/%m/%Y\". See\\nstrftime documentation for more information on choices, though\\nnote that \"%f\" will parse all the way up to nanoseconds.\\nYou can also pass:\\n\\n\\n“ISO8601”, to parse any ISO8601time string (not necessarily in exactly the same format);\\n\\n\\n\\n\\n“mixed”, to infer the format for each element individually. This is risky,and you should probably use it along with dayfirst.\\n\\n\\n\\n\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "         'dayfirst': {'type': 'boolean',\n",
       "          'description': 'bool, default False. DD/MM format dates, international and European format.\\n'},\n",
       "         'cache_dates': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If True, use a cache of unique, converted dates to apply the datetime\\nconversion. May produce significant speed-up when parsing duplicate\\ndate strings, especially ones with timezone offsets.\\n'},\n",
       "         'iterator': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Return TextFileReader object for iteration or getting chunks with\\nget_chunk().\\n'},\n",
       "         'chunksize': {'type': 'integer',\n",
       "          'description': 'int, optional. Number of lines to read from the file per chunk. Passing a value will cause the\\nfunction to return a TextFileReader object for iteration.\\nSee the IO Tools docs\\nfor more information on iterator and chunksize.\\n'},\n",
       "         'compression': {'type': 'string',\n",
       "          'description': \"str or dict, default ‘infer’. For on-the-fly decompression of on-disk data. If ‘infer’ and ‘filepath_or_buffer’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nIf using ‘zip’ or ‘tar’, the ZIP file must contain only one data file to be read in.\\nSet to None for no decompression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdDecompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for Zstandard decompression using a\\ncustom compression dictionary:\\ncompression={'method': 'zstd', 'dict_data': my_compression_dict}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\n\\n\\nChanged in version 1.4.0: Zstandard support.\\n\\n\"},\n",
       "         'thousands': {'type': 'string',\n",
       "          'description': 'str (length 1), optional. Character acting as the thousands separator in numerical values.\\n'},\n",
       "         'decimal': {'type': 'string',\n",
       "          'description': 'str (length 1), default ‘.’. Character to recognize as decimal point (e.g., use ‘,’ for European data).\\n'},\n",
       "         'lineterminator': {'type': 'string',\n",
       "          'description': 'str (length 1), optional. Character used to denote a line break. Only valid with C parser.\\n'},\n",
       "         'quotechar': {'type': 'string',\n",
       "          'description': 'str (length 1), optional. Character used to denote the start and end of a quoted item. Quoted\\nitems can include the delimiter and it will be ignored.\\n'},\n",
       "         'quoting': {'type': '{0 or csv.QUOTE_MINIMAL, 1 or csv.QUOTE_ALL, 2 or csv.QUOTE_NONNUMERIC, 3 or csv.QUOTE_NONE}, default csv.QUOTE_MINIMAL',\n",
       "          'description': '{0 or csv.QUOTE_MINIMAL, 1 or csv.QUOTE_ALL, 2 or csv.QUOTE_NONNUMERIC, 3 or csv.QUOTE_NONE}, default csv.QUOTE_MINIMAL. Control field quoting behavior per csv.QUOTE_* constants. Default is\\ncsv.QUOTE_MINIMAL (i.e., 0) which implies that only fields containing special\\ncharacters are quoted (e.g., characters defined in quotechar, delimiter,\\nor lineterminator.\\n'},\n",
       "         'doublequote': {'type': 'boolean',\n",
       "          'description': 'bool, default True. When quotechar is specified and quoting is not QUOTE_NONE, indicate\\nwhether or not to interpret two consecutive quotechar elements INSIDE a\\nfield as a single quotechar element.\\n'},\n",
       "         'escapechar': {'type': 'string',\n",
       "          'description': 'str (length 1), optional. Character used to escape other characters.\\n'},\n",
       "         'comment': {'type': 'string',\n",
       "          'description': \"str (length 1), optional. Character indicating that the remainder of line should not be parsed.\\nIf found at the beginning\\nof a line, the line will be ignored altogether. This parameter must be a\\nsingle character. Like empty lines (as long as skip_blank_lines=True),\\nfully commented lines are ignored by the parameter header but not by\\nskiprows. For example, if comment='#', parsing\\n#empty\\\\na,b,c\\\\n1,2,3 with header=0 will result in 'a,b,c' being\\ntreated as the header.\\n\"},\n",
       "         'encoding': {'type': 'string',\n",
       "          'description': \"str, optional, default ‘utf-8’. Encoding to use for UTF when reading/writing (ex. 'utf-8'). List of Python\\nstandard encodings .\\n\"},\n",
       "         'encoding_errors': {'type': 'string',\n",
       "          'description': 'str, optional, default ‘strict’. How encoding errors are treated. List of possible values .\\n\\nNew in version 1.3.0.\\n\\n'},\n",
       "         'dialect': {'type': 'string',\n",
       "          'description': 'str or csv.Dialect, optional. If provided, this parameter will override values (default or not) for the\\nfollowing parameters: delimiter, doublequote, escapechar,\\nskipinitialspace, quotechar, and quoting. If it is necessary to\\noverride values, a ParserWarning will be issued. See csv.Dialect\\ndocumentation for more details.\\n'},\n",
       "         'on_bad_lines': {'type': 'string',\n",
       "          'enum': ['error', ' warn', ' skip'],\n",
       "          'description': \"{‘error’, ‘warn’, ‘skip’} or Callable, default ‘error’. Specifies what to do upon encountering a bad line (a line with too many fields).\\nAllowed values are :\\n\\n'error', raise an Exception when a bad line is encountered.\\n'warn', raise a warning when a bad line is encountered and skip that line.\\n'skip', skip bad lines without raising or warning when they are encountered.\\n\\n\\nNew in version 1.3.0.\\n\\n\\nNew in version 1.4.0: \\n\\nCallable, function with signature\\n(bad_line: list[str]) -> list[str] | None that will process a single\\nbad line. bad_line is a list of strings split by the sep.\\nIf the function returns None, the bad line will be ignored.\\nIf the function returns a new list of strings with more elements than\\nexpected, a ParserWarning will be emitted while dropping extra elements.\\nOnly supported when engine='python'\\n\\n\\n\\nChanged in version 2.2.0: \\n\\nCallable, function with signature\\nas described in pyarrow documentation when engine='pyarrow'\\n\\n\\n\"},\n",
       "         'delim_whitespace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Specifies whether or not whitespace (e.g. \\' \\' or \\'\\\\t\\') will be\\nused as the sep delimiter. Equivalent to setting sep=\\'\\\\s+\\'. If this option\\nis set to True, nothing should be passed in for the delimiter\\nparameter.\\n\\nDeprecated since version 2.2.0: Use sep=\"\\\\s+\" instead.\\n\\n'},\n",
       "         'low_memory': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Internally process the file in chunks, resulting in lower memory use\\nwhile parsing, but possibly mixed type inference. To ensure no mixed\\ntypes either set False, or specify the type with the dtype parameter.\\nNote that the entire file is read into a single DataFrame\\nregardless, use the chunksize or iterator parameter to return the data in\\nchunks. (Only valid with C parser).\\n'},\n",
       "         'memory_map': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If a filepath is provided for filepath_or_buffer, map the file object\\ndirectly onto memory and access the data directly from there. Using this\\noption can improve performance because there is no longer any I/O overhead.\\n'},\n",
       "         'float_precision': {'type': 'string',\n",
       "          'enum': ['high', ' legacy', ' round_trip'],\n",
       "          'description': \"{‘high’, ‘legacy’, ‘round_trip’}, optional. Specifies which converter the C engine should use for floating-point\\nvalues. The options are None or 'high' for the ordinary converter,\\n'legacy' for the original lower precision pandas converter, and\\n'round_trip' for the round-trip converter.\\n\"},\n",
       "         'storage_options': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'},\n",
       "         'dtype_backend': {'type': 'string',\n",
       "          'enum': ['numpy_nullable', ' pyarrow'],\n",
       "          'description': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’. Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'}},\n",
       "        'required': ['filepath_or_buffer']}}},\n",
       "     {'func_name': 'DataFrame.to_csv([path_or_buf,\\xa0sep,\\xa0na_rep,\\xa0...])',\n",
       "      'func_desc': 'Write object to a comma-separated values (csv) file.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html#pandas.DataFrame.to_csv',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_csv',\n",
       "       'full_function': 'DataFrame.to_csv(path_or_buf=None, *, sep=\\',\\', na_rep=\\'\\', float_format=None, columns=None, header=True, index=True, index_label=None, mode=\\'w\\', encoding=None, compression=\\'infer\\', quoting=None, quotechar=\\'\"\\', lineterminator=None, chunksize=None, date_format=None, doublequote=True, escapechar=None, decimal=\\'.\\', errors=\\'strict\\', storage_options=None)',\n",
       "       'function_text': 'Write object to a comma-separated values (csv) file.',\n",
       "       'parameter_names_desc': [{'param_name': 'path_or_buf',\n",
       "         'param_type': 'str, path object, file-like object, or None, default None',\n",
       "         'param_desc': 'String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a write() function. If None, the result is\\nreturned as a string. If a non-binary file object is passed, it should\\nbe opened with newline=’’, disabling universal newlines. If a binary\\nfile object is passed, mode might need to contain a ‘b’.\\n'},\n",
       "        {'param_name': 'sep',\n",
       "         'param_type': 'str, default ‘,’',\n",
       "         'param_desc': 'String of length 1. Field delimiter for the output file.\\n'},\n",
       "        {'param_name': 'na_rep',\n",
       "         'param_type': 'str, default ‘’',\n",
       "         'param_desc': 'Missing data representation.\\n'},\n",
       "        {'param_name': 'float_format',\n",
       "         'param_type': 'str, Callable, default None',\n",
       "         'param_desc': 'Format string for floating point numbers. If a Callable is given, it takes\\nprecedence over other numeric formatting parameters, like decimal.\\n'},\n",
       "        {'param_name': 'columns',\n",
       "         'param_type': 'sequence, optional',\n",
       "         'param_desc': 'Columns to write.\\n'},\n",
       "        {'param_name': 'header',\n",
       "         'param_type': 'bool or list of str, default True',\n",
       "         'param_desc': 'Write out the column names. If a list of strings is given it is\\nassumed to be aliases for the column names.\\n'},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Write row names (index).\\n'},\n",
       "        {'param_name': 'index_label',\n",
       "         'param_type': 'str or sequence, or False, default None',\n",
       "         'param_desc': 'Column label for index column(s) if desired. If None is given, and\\nheader and index are True, then the index names are used. A\\nsequence should be given if the object uses MultiIndex. If\\nFalse do not print fields for index names. Use index_label=False\\nfor easier importing in R.\\n'},\n",
       "        {'param_name': 'mode',\n",
       "         'param_type': '{‘w’, ‘x’, ‘a’}, default ‘w’',\n",
       "         'param_desc': 'Forwarded to either open(mode=) or fsspec.open(mode=) to control\\nthe file opening. Typical values include:\\n\\n‘w’, truncate the file first.\\n‘x’, exclusive creation, failing if the file already exists.\\n‘a’, append to the end of file if it exists.\\n\\n'},\n",
       "        {'param_name': 'encoding',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'A string representing the encoding to use in the output file,\\ndefaults to ‘utf-8’. encoding is not supported if path_or_buf\\nis a non-binary file object.\\n'},\n",
       "        {'param_name': 'compression',\n",
       "         'param_type': 'str or dict, default ‘infer’',\n",
       "         'param_desc': \"For on-the-fly compression of the output data. If ‘infer’ and ‘path_or_buf’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nSet to None for no compression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for faster compression and to create\\na reproducible gzip archive:\\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\nMay be a dict with key ‘method’ as compression mode\\nand other entries as additional compression options if\\ncompression mode is ‘zip’.\\nPassing compression options as keys in dict is\\nsupported for compression modes ‘gzip’, ‘bz2’, ‘zstd’, and ‘zip’.\\n\\n\"},\n",
       "        {'param_name': 'quoting',\n",
       "         'param_type': 'optional constant from csv module',\n",
       "         'param_desc': 'Defaults to csv.QUOTE_MINIMAL. If you have set a float_format\\nthen floats are converted to strings and thus csv.QUOTE_NONNUMERIC\\nwill treat them as non-numeric.\\n'},\n",
       "        {'param_name': 'quotechar',\n",
       "         'param_type': 'str, default ‘\"’',\n",
       "         'param_desc': 'String of length 1. Character used to quote fields.\\n'},\n",
       "        {'param_name': 'lineterminator',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'The newline character or character sequence to use in the output\\nfile. Defaults to os.linesep, which depends on the OS in which\\nthis method is called (’\\\\n’ for linux, ‘\\\\r\\\\n’ for Windows, i.e.).\\n\\nChanged in version 1.5.0: Previously was line_terminator, changed for consistency with\\nread_csv and the standard library ‘csv’ module.\\n\\n'},\n",
       "        {'param_name': 'chunksize',\n",
       "         'param_type': 'int or None',\n",
       "         'param_desc': 'Rows to write at a time.\\n'},\n",
       "        {'param_name': 'date_format',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'Format string for datetime objects.\\n'},\n",
       "        {'param_name': 'doublequote',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Control quoting of quotechar inside a field.\\n'},\n",
       "        {'param_name': 'escapechar',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'String of length 1. Character used to escape sep and quotechar\\nwhen appropriate.\\n'},\n",
       "        {'param_name': 'decimal',\n",
       "         'param_type': 'str, default ‘.’',\n",
       "         'param_desc': 'Character recognized as decimal separator. E.g. use ‘,’ for\\nEuropean data.\\n'},\n",
       "        {'param_name': 'errors',\n",
       "         'param_type': 'str, default ‘strict’',\n",
       "         'param_desc': 'Specifies how encoding and decoding errors are to be handled.\\nSee the errors argument for open() for a full list\\nof options.\\n'},\n",
       "        {'param_name': 'storage_options',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.to_csv',\n",
       "       'descriptions': 'Write object to a comma-separated values (csv) file.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'path_or_buf': {'type': 'string',\n",
       "          'description': 'str, path object, file-like object, or None, default None. String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a write() function. If None, the result is\\nreturned as a string. If a non-binary file object is passed, it should\\nbe opened with newline=’’, disabling universal newlines. If a binary\\nfile object is passed, mode might need to contain a ‘b’.\\n'},\n",
       "         'sep': {'type': 'string',\n",
       "          'description': 'str, default ‘,’. String of length 1. Field delimiter for the output file.\\n'},\n",
       "         'na_rep': {'type': 'string',\n",
       "          'description': 'str, default ‘’. Missing data representation.\\n'},\n",
       "         'float_format': {'type': 'string',\n",
       "          'description': 'str, Callable, default None. Format string for floating point numbers. If a Callable is given, it takes\\nprecedence over other numeric formatting parameters, like decimal.\\n'},\n",
       "         'columns': {'type': 'sequence, optional',\n",
       "          'description': 'sequence, optional. Columns to write.\\n'},\n",
       "         'header': {'type': 'string',\n",
       "          'description': 'bool or list of str, default True. Write out the column names. If a list of strings is given it is\\nassumed to be aliases for the column names.\\n'},\n",
       "         'index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Write row names (index).\\n'},\n",
       "         'index_label': {'type': 'string',\n",
       "          'description': 'str or sequence, or False, default None. Column label for index column(s) if desired. If None is given, and\\nheader and index are True, then the index names are used. A\\nsequence should be given if the object uses MultiIndex. If\\nFalse do not print fields for index names. Use index_label=False\\nfor easier importing in R.\\n'},\n",
       "         'mode': {'type': 'string',\n",
       "          'enum': ['w', ' x', ' a'],\n",
       "          'description': '{‘w’, ‘x’, ‘a’}, default ‘w’. Forwarded to either open(mode=) or fsspec.open(mode=) to control\\nthe file opening. Typical values include:\\n\\n‘w’, truncate the file first.\\n‘x’, exclusive creation, failing if the file already exists.\\n‘a’, append to the end of file if it exists.\\n\\n'},\n",
       "         'encoding': {'type': 'string',\n",
       "          'description': 'str, optional. A string representing the encoding to use in the output file,\\ndefaults to ‘utf-8’. encoding is not supported if path_or_buf\\nis a non-binary file object.\\n'},\n",
       "         'compression': {'type': 'string',\n",
       "          'description': \"str or dict, default ‘infer’. For on-the-fly compression of the output data. If ‘infer’ and ‘path_or_buf’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nSet to None for no compression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for faster compression and to create\\na reproducible gzip archive:\\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\nMay be a dict with key ‘method’ as compression mode\\nand other entries as additional compression options if\\ncompression mode is ‘zip’.\\nPassing compression options as keys in dict is\\nsupported for compression modes ‘gzip’, ‘bz2’, ‘zstd’, and ‘zip’.\\n\\n\"},\n",
       "         'quoting': {'type': 'optional constant from csv module',\n",
       "          'description': 'optional constant from csv module. Defaults to csv.QUOTE_MINIMAL. If you have set a float_format\\nthen floats are converted to strings and thus csv.QUOTE_NONNUMERIC\\nwill treat them as non-numeric.\\n'},\n",
       "         'quotechar': {'type': 'string',\n",
       "          'description': 'str, default ‘\"’. String of length 1. Character used to quote fields.\\n'},\n",
       "         'lineterminator': {'type': 'string',\n",
       "          'description': 'str, optional. The newline character or character sequence to use in the output\\nfile. Defaults to os.linesep, which depends on the OS in which\\nthis method is called (’\\\\n’ for linux, ‘\\\\r\\\\n’ for Windows, i.e.).\\n\\nChanged in version 1.5.0: Previously was line_terminator, changed for consistency with\\nread_csv and the standard library ‘csv’ module.\\n\\n'},\n",
       "         'chunksize': {'type': 'integer',\n",
       "          'description': 'int or None. Rows to write at a time.\\n'},\n",
       "         'date_format': {'type': 'string',\n",
       "          'description': 'str, default None. Format string for datetime objects.\\n'},\n",
       "         'doublequote': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Control quoting of quotechar inside a field.\\n'},\n",
       "         'escapechar': {'type': 'string',\n",
       "          'description': 'str, default None. String of length 1. Character used to escape sep and quotechar\\nwhen appropriate.\\n'},\n",
       "         'decimal': {'type': 'string',\n",
       "          'description': 'str, default ‘.’. Character recognized as decimal separator. E.g. use ‘,’ for\\nEuropean data.\\n'},\n",
       "         'errors': {'type': 'string',\n",
       "          'description': 'str, default ‘strict’. Specifies how encoding and decoding errors are to be handled.\\nSee the errors argument for open() for a full list\\nof options.\\n'},\n",
       "         'storage_options': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'}},\n",
       "        'required': ['path_or_buf=None']}}},\n",
       "     {'func_name': 'read_csv(filepath_or_buffer,\\xa0*[,\\xa0sep,\\xa0...])',\n",
       "      'func_desc': 'Read a comma-separated values (csv) file into DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html#pandas.read_csv',\n",
       "      'function_definitions': {'function_name': 'pandas.read_csv',\n",
       "       'full_function': 'pandas.read_csv(filepath_or_buffer, *, sep=_NoDefault.no_default, delimiter=None, header=\\'infer\\', names=_NoDefault.no_default, index_col=None, usecols=None, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skipinitialspace=False, skiprows=None, skipfooter=0, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=_NoDefault.no_default, skip_blank_lines=True, parse_dates=None, infer_datetime_format=_NoDefault.no_default, keep_date_col=_NoDefault.no_default, date_parser=_NoDefault.no_default, date_format=None, dayfirst=False, cache_dates=True, iterator=False, chunksize=None, compression=\\'infer\\', thousands=None, decimal=\\'.\\', lineterminator=None, quotechar=\\'\"\\', quoting=0, doublequote=True, escapechar=None, comment=None, encoding=None, encoding_errors=\\'strict\\', dialect=None, on_bad_lines=\\'error\\', delim_whitespace=_NoDefault.no_default, low_memory=True, memory_map=False, float_precision=None, storage_options=None, dtype_backend=_NoDefault.no_default)',\n",
       "       'function_text': 'Read a comma-separated values (csv) file into DataFrame. Also supports optionally iterating or breaking of the file\\ninto chunks. Additional help can be found in the online docs for\\nIO Tools.',\n",
       "       'parameter_names_desc': [{'param_name': 'filepath_or_buffer',\n",
       "         'param_type': 'str, path object or file-like object',\n",
       "         'param_desc': 'Any valid string path is acceptable. The string could be a URL. Valid\\nURL schemes include http, ftp, s3, gs, and file. For file URLs, a host is\\nexpected. A local file could be: file://localhost/path/to/table.csv.\\nIf you want to pass in a path object, pandas accepts any os.PathLike.\\nBy file-like object, we refer to objects with a read() method, such as\\na file handle (e.g. via builtin open function) or StringIO.\\n'},\n",
       "        {'param_name': 'sep',\n",
       "         'param_type': 'str, default ‘,’',\n",
       "         'param_desc': \"Character or regex pattern to treat as the delimiter. If sep=None, the\\nC engine cannot automatically detect\\nthe separator, but the Python parsing engine can, meaning the latter will\\nbe used and automatically detect the separator from only the first valid\\nrow of the file by Python’s builtin sniffer tool, csv.Sniffer.\\nIn addition, separators longer than 1 character and different from\\n'\\\\s+' will be interpreted as regular expressions and will also force\\nthe use of the Python parsing engine. Note that regex delimiters are prone\\nto ignoring quoted data. Regex example: '\\\\r\\\\t'.\\n\"},\n",
       "        {'param_name': 'delimiter',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Alias for sep.\\n'},\n",
       "        {'param_name': 'header',\n",
       "         'param_type': 'int, Sequence of int, ‘infer’ or None, default ‘infer’',\n",
       "         'param_desc': 'Row number(s) containing column labels and marking the start of the\\ndata (zero-indexed). Default behavior is to infer the column names: if no names\\nare passed the behavior is identical to header=0 and column\\nnames are inferred from the first line of the file, if column\\nnames are passed explicitly to names then the behavior is identical to\\nheader=None. Explicitly pass header=0 to be able to\\nreplace existing names. The header can be a list of integers that\\nspecify row locations for a MultiIndex on the columns\\ne.g. [0, 1, 3]. Intervening rows that are not specified will be\\nskipped (e.g. 2 in this example is skipped). Note that this\\nparameter ignores commented lines and empty lines if\\nskip_blank_lines=True, so header=0 denotes the first line of\\ndata rather than the first line of the file.\\n'},\n",
       "        {'param_name': 'names',\n",
       "         'param_type': 'Sequence of Hashable, optional',\n",
       "         'param_desc': 'Sequence of column labels to apply. If the file contains a header row,\\nthen you should explicitly pass header=0 to override the column names.\\nDuplicates in this list are not allowed.\\n'},\n",
       "        {'param_name': 'index_col',\n",
       "         'param_type': 'Hashable, Sequence of Hashable or False, optional',\n",
       "         'param_desc': 'Column(s) to use as row label(s), denoted either by column labels or column\\nindices. If a sequence of labels or indices is given, MultiIndex\\nwill be formed for the row labels.\\nNote: index_col=False can be used to force pandas to not use the first\\ncolumn as the index, e.g., when you have a malformed file with delimiters at\\nthe end of each line.\\n'},\n",
       "        {'param_name': 'usecols',\n",
       "         'param_type': 'Sequence of Hashable or Callable, optional',\n",
       "         'param_desc': \"Subset of columns to select, denoted either by column labels or column indices.\\nIf list-like, all elements must either\\nbe positional (i.e. integer indices into the document columns) or strings\\nthat correspond to column names provided either by the user in names or\\ninferred from the document header row(s). If names are given, the document\\nheader row(s) are not taken into account. For example, a valid list-like\\nusecols parameter would be [0, 1, 2] or ['foo', 'bar', 'baz'].\\nElement order is ignored, so usecols=[0, 1] is the same as [1, 0].\\nTo instantiate a DataFrame from data with element order\\npreserved use pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]\\nfor columns in ['foo', 'bar'] order or\\npd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]\\nfor ['bar', 'foo'] order.\\nIf callable, the callable function will be evaluated against the column\\nnames, returning names where the callable function evaluates to True. An\\nexample of a valid callable argument would be lambda x: x.upper() in\\n['AAA', 'BBB', 'DDD']. Using this parameter results in much faster\\nparsing time and lower memory usage.\\n\"},\n",
       "        {'param_name': 'dtype',\n",
       "         'param_type': 'dtype or dict of {Hashable',\n",
       "         'param_desc': \"Data type(s) to apply to either the whole dataset or individual columns.\\nE.g., {'a': np.float64, 'b': np.int32, 'c': 'Int64'}\\nUse str or object together with suitable na_values settings\\nto preserve and not interpret dtype.\\nIf converters are specified, they will be applied INSTEAD\\nof dtype conversion.\\n\\nNew in version 1.5.0: Support for defaultdict was added. Specify a defaultdict as input where\\nthe default determines the dtype of the columns which are not explicitly\\nlisted.\\n\\n\"},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': '{‘c’, ‘python’, ‘pyarrow’}, optional',\n",
       "         'param_desc': 'Parser engine to use. The C and pyarrow engines are faster, while the python engine\\nis currently more feature-complete. Multithreading is currently only supported by\\nthe pyarrow engine.\\n\\nNew in version 1.4.0: The ‘pyarrow’ engine was added as an experimental engine, and some features\\nare unsupported, or may not work correctly, with this engine.\\n\\n'},\n",
       "        {'param_name': 'converters',\n",
       "         'param_type': 'dict of {Hashable',\n",
       "         'param_desc': 'Functions for converting values in specified columns. Keys can either\\nbe column labels or column indices.\\n'},\n",
       "        {'param_name': 'true_values',\n",
       "         'param_type': 'list, optional',\n",
       "         'param_desc': 'Values to consider as True in addition to case-insensitive variants of ‘True’.\\n'},\n",
       "        {'param_name': 'false_values',\n",
       "         'param_type': 'list, optional',\n",
       "         'param_desc': 'Values to consider as False in addition to case-insensitive variants of ‘False’.\\n'},\n",
       "        {'param_name': 'skipinitialspace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Skip spaces after delimiter.\\n'},\n",
       "        {'param_name': 'skiprows',\n",
       "         'param_type': 'int, list of int or Callable, optional',\n",
       "         'param_desc': 'Line numbers to skip (0-indexed) or number of lines to skip (int)\\nat the start of the file.\\nIf callable, the callable function will be evaluated against the row\\nindices, returning True if the row should be skipped and False otherwise.\\nAn example of a valid callable argument would be lambda x: x in [0, 2].\\n'},\n",
       "        {'param_name': 'skipfooter',\n",
       "         'param_type': 'int, default 0',\n",
       "         'param_desc': \"Number of lines at bottom of file to skip (Unsupported with engine='c').\\n\"},\n",
       "        {'param_name': 'nrows',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Number of rows of file to read. Useful for reading pieces of large files.\\n'},\n",
       "        {'param_name': 'na_values',\n",
       "         'param_type': 'Hashable, Iterable of Hashable or dict of {Hashable',\n",
       "         'param_desc': 'Additional strings to recognize as NA/NaN. If dict passed, specific\\nper-column NA values. By default the following values are interpreted as\\nNaN: “ “, “#N/A”, “#N/A N/A”, “#NA”, “-1.#IND”, “-1.#QNAN”, “-NaN”, “-nan”,\\n“1.#IND”, “1.#QNAN”, “<NA>”, “N/A”, “NA”, “NULL”, “NaN”, “None”,\\n“n/a”, “nan”, “null “.\\n'},\n",
       "        {'param_name': 'keep_default_na',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether or not to include the default NaN values when parsing the data.\\nDepending on whether na_values is passed in, the behavior is as follows:\\n\\nIf keep_default_na is True, and na_values are specified, na_values\\nis appended to the default NaN values used for parsing.\\nIf keep_default_na is True, and na_values are not specified, only\\nthe default NaN values are used for parsing.\\nIf keep_default_na is False, and na_values are specified, only\\nthe NaN values specified na_values are used for parsing.\\nIf keep_default_na is False, and na_values are not specified, no\\nstrings will be parsed as NaN.\\n\\nNote that if na_filter is passed in as False, the keep_default_na and\\nna_values parameters will be ignored.\\n'},\n",
       "        {'param_name': 'na_filter',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Detect missing value markers (empty strings and the value of na_values). In\\ndata without any NA values, passing na_filter=False can improve the\\nperformance of reading a large file.\\n'},\n",
       "        {'param_name': 'verbose',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Indicate number of NA values placed in non-numeric columns.\\n\\nDeprecated since version 2.2.0.\\n\\n'},\n",
       "        {'param_name': 'skip_blank_lines',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If True, skip over blank lines rather than interpreting as NaN values.\\n'},\n",
       "        {'param_name': 'parse_dates',\n",
       "         'param_type': 'bool, list of Hashable, list of lists or dict of {Hashable',\n",
       "         'param_desc': \"The behavior is as follows:\\n\\nbool. If True -> try parsing the index. Note: Automatically set to\\nTrue if date_format or date_parser arguments have been passed.\\nlist of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\\neach as a separate date column.\\nlist of list. e.g. If [[1, 3]] -> combine columns 1 and 3 and parse\\nas a single date column. Values are joined with a space before parsing.\\ndict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call\\nresult ‘foo’. Values are joined with a space before parsing.\\n\\nIf a column or index cannot be represented as an array of datetime,\\nsay because of an unparsable value or a mixture of timezones, the column\\nor index will be returned unaltered as an object data type. For\\nnon-standard datetime parsing, use to_datetime() after\\nread_csv().\\nNote: A fast-path exists for iso8601-formatted dates.\\n\"},\n",
       "        {'param_name': 'infer_datetime_format',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True and parse_dates is enabled, pandas will attempt to infer the\\nformat of the datetime strings in the columns, and if it can be inferred,\\nswitch to a faster method of parsing them. In some cases this can increase\\nthe parsing speed by 5-10x.\\n\\nDeprecated since version 2.0.0: A strict version of this argument is now the default, passing it has no effect.\\n\\n'},\n",
       "        {'param_name': 'keep_date_col',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True and parse_dates specifies combining multiple columns then\\nkeep the original columns.\\n'},\n",
       "        {'param_name': 'date_parser',\n",
       "         'param_type': 'Callable, optional',\n",
       "         'param_desc': 'Function to use for converting a sequence of string columns to an array of\\ndatetime instances. The default uses dateutil.parser.parser to do the\\nconversion. pandas will try to call date_parser in three different ways,\\nadvancing to the next if an exception occurs: 1) Pass one or more arrays\\n(as defined by parse_dates) as arguments; 2) concatenate (row-wise) the\\nstring values from the columns defined by parse_dates into a single array\\nand pass that; and 3) call date_parser once for each row using one or\\nmore strings (corresponding to the columns defined by parse_dates) as\\narguments.\\n\\nDeprecated since version 2.0.0: Use date_format instead, or read in as object and then apply\\nto_datetime() as-needed.\\n\\n'},\n",
       "        {'param_name': 'date_format',\n",
       "         'param_type': 'str or dict of column -> format, optional',\n",
       "         'param_desc': 'Format to use for parsing dates when used in conjunction with parse_dates.\\nThe strftime to parse time, e.g. \"%d/%m/%Y\". See\\nstrftime documentation for more information on choices, though\\nnote that \"%f\" will parse all the way up to nanoseconds.\\nYou can also pass:\\n\\n\\n“ISO8601”, to parse any ISO8601time string (not necessarily in exactly the same format);\\n\\n\\n\\n\\n“mixed”, to infer the format for each element individually. This is risky,and you should probably use it along with dayfirst.\\n\\n\\n\\n\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "        {'param_name': 'dayfirst',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'DD/MM format dates, international and European format.\\n'},\n",
       "        {'param_name': 'cache_dates',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If True, use a cache of unique, converted dates to apply the datetime\\nconversion. May produce significant speed-up when parsing duplicate\\ndate strings, especially ones with timezone offsets.\\n'},\n",
       "        {'param_name': 'iterator',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Return TextFileReader object for iteration or getting chunks with\\nget_chunk().\\n'},\n",
       "        {'param_name': 'chunksize',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Number of lines to read from the file per chunk. Passing a value will cause the\\nfunction to return a TextFileReader object for iteration.\\nSee the IO Tools docs\\nfor more information on iterator and chunksize.\\n'},\n",
       "        {'param_name': 'compression',\n",
       "         'param_type': 'str or dict, default ‘infer’',\n",
       "         'param_desc': \"For on-the-fly decompression of on-disk data. If ‘infer’ and ‘filepath_or_buffer’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nIf using ‘zip’ or ‘tar’, the ZIP file must contain only one data file to be read in.\\nSet to None for no decompression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdDecompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for Zstandard decompression using a\\ncustom compression dictionary:\\ncompression={'method': 'zstd', 'dict_data': my_compression_dict}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\n\\n\\nChanged in version 1.4.0: Zstandard support.\\n\\n\"},\n",
       "        {'param_name': 'thousands',\n",
       "         'param_type': 'str (length 1), optional',\n",
       "         'param_desc': 'Character acting as the thousands separator in numerical values.\\n'},\n",
       "        {'param_name': 'decimal',\n",
       "         'param_type': 'str (length 1), default ‘.’',\n",
       "         'param_desc': 'Character to recognize as decimal point (e.g., use ‘,’ for European data).\\n'},\n",
       "        {'param_name': 'lineterminator',\n",
       "         'param_type': 'str (length 1), optional',\n",
       "         'param_desc': 'Character used to denote a line break. Only valid with C parser.\\n'},\n",
       "        {'param_name': 'quotechar',\n",
       "         'param_type': 'str (length 1), optional',\n",
       "         'param_desc': 'Character used to denote the start and end of a quoted item. Quoted\\nitems can include the delimiter and it will be ignored.\\n'},\n",
       "        {'param_name': 'quoting',\n",
       "         'param_type': '{0 or csv.QUOTE_MINIMAL, 1 or csv.QUOTE_ALL, 2 or csv.QUOTE_NONNUMERIC, 3 or csv.QUOTE_NONE}, default csv.QUOTE_MINIMAL',\n",
       "         'param_desc': 'Control field quoting behavior per csv.QUOTE_* constants. Default is\\ncsv.QUOTE_MINIMAL (i.e., 0) which implies that only fields containing special\\ncharacters are quoted (e.g., characters defined in quotechar, delimiter,\\nor lineterminator.\\n'},\n",
       "        {'param_name': 'doublequote',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'When quotechar is specified and quoting is not QUOTE_NONE, indicate\\nwhether or not to interpret two consecutive quotechar elements INSIDE a\\nfield as a single quotechar element.\\n'},\n",
       "        {'param_name': 'escapechar',\n",
       "         'param_type': 'str (length 1), optional',\n",
       "         'param_desc': 'Character used to escape other characters.\\n'},\n",
       "        {'param_name': 'comment',\n",
       "         'param_type': 'str (length 1), optional',\n",
       "         'param_desc': \"Character indicating that the remainder of line should not be parsed.\\nIf found at the beginning\\nof a line, the line will be ignored altogether. This parameter must be a\\nsingle character. Like empty lines (as long as skip_blank_lines=True),\\nfully commented lines are ignored by the parameter header but not by\\nskiprows. For example, if comment='#', parsing\\n#empty\\\\na,b,c\\\\n1,2,3 with header=0 will result in 'a,b,c' being\\ntreated as the header.\\n\"},\n",
       "        {'param_name': 'encoding',\n",
       "         'param_type': 'str, optional, default ‘utf-8’',\n",
       "         'param_desc': \"Encoding to use for UTF when reading/writing (ex. 'utf-8'). List of Python\\nstandard encodings .\\n\"},\n",
       "        {'param_name': 'encoding_errors',\n",
       "         'param_type': 'str, optional, default ‘strict’',\n",
       "         'param_desc': 'How encoding errors are treated. List of possible values .\\n\\nNew in version 1.3.0.\\n\\n'},\n",
       "        {'param_name': 'dialect',\n",
       "         'param_type': 'str or csv.Dialect, optional',\n",
       "         'param_desc': 'If provided, this parameter will override values (default or not) for the\\nfollowing parameters: delimiter, doublequote, escapechar,\\nskipinitialspace, quotechar, and quoting. If it is necessary to\\noverride values, a ParserWarning will be issued. See csv.Dialect\\ndocumentation for more details.\\n'},\n",
       "        {'param_name': 'on_bad_lines',\n",
       "         'param_type': '{‘error’, ‘warn’, ‘skip’} or Callable, default ‘error’',\n",
       "         'param_desc': \"Specifies what to do upon encountering a bad line (a line with too many fields).\\nAllowed values are :\\n\\n'error', raise an Exception when a bad line is encountered.\\n'warn', raise a warning when a bad line is encountered and skip that line.\\n'skip', skip bad lines without raising or warning when they are encountered.\\n\\n\\nNew in version 1.3.0.\\n\\n\\nNew in version 1.4.0: \\n\\nCallable, function with signature\\n(bad_line: list[str]) -> list[str] | None that will process a single\\nbad line. bad_line is a list of strings split by the sep.\\nIf the function returns None, the bad line will be ignored.\\nIf the function returns a new list of strings with more elements than\\nexpected, a ParserWarning will be emitted while dropping extra elements.\\nOnly supported when engine='python'\\n\\n\\n\\nChanged in version 2.2.0: \\n\\nCallable, function with signature\\nas described in pyarrow documentation when engine='pyarrow'\\n\\n\\n\"},\n",
       "        {'param_name': 'delim_whitespace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Specifies whether or not whitespace (e.g. \\' \\' or \\'\\\\t\\') will be\\nused as the sep delimiter. Equivalent to setting sep=\\'\\\\s+\\'. If this option\\nis set to True, nothing should be passed in for the delimiter\\nparameter.\\n\\nDeprecated since version 2.2.0: Use sep=\"\\\\s+\" instead.\\n\\n'},\n",
       "        {'param_name': 'low_memory',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Internally process the file in chunks, resulting in lower memory use\\nwhile parsing, but possibly mixed type inference. To ensure no mixed\\ntypes either set False, or specify the type with the dtype parameter.\\nNote that the entire file is read into a single DataFrame\\nregardless, use the chunksize or iterator parameter to return the data in\\nchunks. (Only valid with C parser).\\n'},\n",
       "        {'param_name': 'memory_map',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If a filepath is provided for filepath_or_buffer, map the file object\\ndirectly onto memory and access the data directly from there. Using this\\noption can improve performance because there is no longer any I/O overhead.\\n'},\n",
       "        {'param_name': 'float_precision',\n",
       "         'param_type': '{‘high’, ‘legacy’, ‘round_trip’}, optional',\n",
       "         'param_desc': \"Specifies which converter the C engine should use for floating-point\\nvalues. The options are None or 'high' for the ordinary converter,\\n'legacy' for the original lower precision pandas converter, and\\n'round_trip' for the round-trip converter.\\n\"},\n",
       "        {'param_name': 'storage_options',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'},\n",
       "        {'param_name': 'dtype_backend',\n",
       "         'param_type': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’',\n",
       "         'param_desc': 'Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.read_csv',\n",
       "       'descriptions': 'Read a comma-separated values (csv) file into DataFrame. Also supports optionally iterating or breaking of the file\\ninto chunks. Additional help can be found in the online docs for\\nIO Tools.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'filepath_or_buffer': {'type': 'string',\n",
       "          'description': 'str, path object or file-like object. Any valid string path is acceptable. The string could be a URL. Valid\\nURL schemes include http, ftp, s3, gs, and file. For file URLs, a host is\\nexpected. A local file could be: file://localhost/path/to/table.csv.\\nIf you want to pass in a path object, pandas accepts any os.PathLike.\\nBy file-like object, we refer to objects with a read() method, such as\\na file handle (e.g. via builtin open function) or StringIO.\\n'},\n",
       "         'sep': {'type': 'string',\n",
       "          'description': \"str, default ‘,’. Character or regex pattern to treat as the delimiter. If sep=None, the\\nC engine cannot automatically detect\\nthe separator, but the Python parsing engine can, meaning the latter will\\nbe used and automatically detect the separator from only the first valid\\nrow of the file by Python’s builtin sniffer tool, csv.Sniffer.\\nIn addition, separators longer than 1 character and different from\\n'\\\\s+' will be interpreted as regular expressions and will also force\\nthe use of the Python parsing engine. Note that regex delimiters are prone\\nto ignoring quoted data. Regex example: '\\\\r\\\\t'.\\n\"},\n",
       "         'delimiter': {'type': 'string',\n",
       "          'description': 'str, optional. Alias for sep.\\n'},\n",
       "         'header': {'type': 'integer',\n",
       "          'description': 'int, Sequence of int, ‘infer’ or None, default ‘infer’. Row number(s) containing column labels and marking the start of the\\ndata (zero-indexed). Default behavior is to infer the column names: if no names\\nare passed the behavior is identical to header=0 and column\\nnames are inferred from the first line of the file, if column\\nnames are passed explicitly to names then the behavior is identical to\\nheader=None. Explicitly pass header=0 to be able to\\nreplace existing names. The header can be a list of integers that\\nspecify row locations for a MultiIndex on the columns\\ne.g. [0, 1, 3]. Intervening rows that are not specified will be\\nskipped (e.g. 2 in this example is skipped). Note that this\\nparameter ignores commented lines and empty lines if\\nskip_blank_lines=True, so header=0 denotes the first line of\\ndata rather than the first line of the file.\\n'},\n",
       "         'names': {'type': 'Sequence of Hashable, optional',\n",
       "          'description': 'Sequence of Hashable, optional. Sequence of column labels to apply. If the file contains a header row,\\nthen you should explicitly pass header=0 to override the column names.\\nDuplicates in this list are not allowed.\\n'},\n",
       "         'index_col': {'type': 'Hashable, Sequence of Hashable or False, optional',\n",
       "          'description': 'Hashable, Sequence of Hashable or False, optional. Column(s) to use as row label(s), denoted either by column labels or column\\nindices. If a sequence of labels or indices is given, MultiIndex\\nwill be formed for the row labels.\\nNote: index_col=False can be used to force pandas to not use the first\\ncolumn as the index, e.g., when you have a malformed file with delimiters at\\nthe end of each line.\\n'},\n",
       "         'usecols': {'type': 'Sequence of Hashable or Callable, optional',\n",
       "          'description': \"Sequence of Hashable or Callable, optional. Subset of columns to select, denoted either by column labels or column indices.\\nIf list-like, all elements must either\\nbe positional (i.e. integer indices into the document columns) or strings\\nthat correspond to column names provided either by the user in names or\\ninferred from the document header row(s). If names are given, the document\\nheader row(s) are not taken into account. For example, a valid list-like\\nusecols parameter would be [0, 1, 2] or ['foo', 'bar', 'baz'].\\nElement order is ignored, so usecols=[0, 1] is the same as [1, 0].\\nTo instantiate a DataFrame from data with element order\\npreserved use pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]\\nfor columns in ['foo', 'bar'] order or\\npd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]\\nfor ['bar', 'foo'] order.\\nIf callable, the callable function will be evaluated against the column\\nnames, returning names where the callable function evaluates to True. An\\nexample of a valid callable argument would be lambda x: x.upper() in\\n['AAA', 'BBB', 'DDD']. Using this parameter results in much faster\\nparsing time and lower memory usage.\\n\"},\n",
       "         'dtype': {'type': 'dtype or dict of {Hashable',\n",
       "          'description': \"dtype or dict of {Hashable. Data type(s) to apply to either the whole dataset or individual columns.\\nE.g., {'a': np.float64, 'b': np.int32, 'c': 'Int64'}\\nUse str or object together with suitable na_values settings\\nto preserve and not interpret dtype.\\nIf converters are specified, they will be applied INSTEAD\\nof dtype conversion.\\n\\nNew in version 1.5.0: Support for defaultdict was added. Specify a defaultdict as input where\\nthe default determines the dtype of the columns which are not explicitly\\nlisted.\\n\\n\"},\n",
       "         'engine': {'type': 'string',\n",
       "          'enum': ['c', ' python', ' pyarrow'],\n",
       "          'description': '{‘c’, ‘python’, ‘pyarrow’}, optional. Parser engine to use. The C and pyarrow engines are faster, while the python engine\\nis currently more feature-complete. Multithreading is currently only supported by\\nthe pyarrow engine.\\n\\nNew in version 1.4.0: The ‘pyarrow’ engine was added as an experimental engine, and some features\\nare unsupported, or may not work correctly, with this engine.\\n\\n'},\n",
       "         'converters': {'type': 'dict of {Hashable',\n",
       "          'description': 'dict of {Hashable. Functions for converting values in specified columns. Keys can either\\nbe column labels or column indices.\\n'},\n",
       "         'true_values': {'type': 'array',\n",
       "          'description': 'list, optional. Values to consider as True in addition to case-insensitive variants of ‘True’.\\n'},\n",
       "         'false_values': {'type': 'array',\n",
       "          'description': 'list, optional. Values to consider as False in addition to case-insensitive variants of ‘False’.\\n'},\n",
       "         'skipinitialspace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Skip spaces after delimiter.\\n'},\n",
       "         'skiprows': {'type': 'integer',\n",
       "          'description': 'int, list of int or Callable, optional. Line numbers to skip (0-indexed) or number of lines to skip (int)\\nat the start of the file.\\nIf callable, the callable function will be evaluated against the row\\nindices, returning True if the row should be skipped and False otherwise.\\nAn example of a valid callable argument would be lambda x: x in [0, 2].\\n'},\n",
       "         'skipfooter': {'type': 'integer',\n",
       "          'description': \"int, default 0. Number of lines at bottom of file to skip (Unsupported with engine='c').\\n\"},\n",
       "         'nrows': {'type': 'integer',\n",
       "          'description': 'int, optional. Number of rows of file to read. Useful for reading pieces of large files.\\n'},\n",
       "         'na_values': {'type': 'Hashable, Iterable of Hashable or dict of {Hashable',\n",
       "          'description': 'Hashable, Iterable of Hashable or dict of {Hashable. Additional strings to recognize as NA/NaN. If dict passed, specific\\nper-column NA values. By default the following values are interpreted as\\nNaN: “ “, “#N/A”, “#N/A N/A”, “#NA”, “-1.#IND”, “-1.#QNAN”, “-NaN”, “-nan”,\\n“1.#IND”, “1.#QNAN”, “<NA>”, “N/A”, “NA”, “NULL”, “NaN”, “None”,\\n“n/a”, “nan”, “null “.\\n'},\n",
       "         'keep_default_na': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether or not to include the default NaN values when parsing the data.\\nDepending on whether na_values is passed in, the behavior is as follows:\\n\\nIf keep_default_na is True, and na_values are specified, na_values\\nis appended to the default NaN values used for parsing.\\nIf keep_default_na is True, and na_values are not specified, only\\nthe default NaN values are used for parsing.\\nIf keep_default_na is False, and na_values are specified, only\\nthe NaN values specified na_values are used for parsing.\\nIf keep_default_na is False, and na_values are not specified, no\\nstrings will be parsed as NaN.\\n\\nNote that if na_filter is passed in as False, the keep_default_na and\\nna_values parameters will be ignored.\\n'},\n",
       "         'na_filter': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Detect missing value markers (empty strings and the value of na_values). In\\ndata without any NA values, passing na_filter=False can improve the\\nperformance of reading a large file.\\n'},\n",
       "         'verbose': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Indicate number of NA values placed in non-numeric columns.\\n\\nDeprecated since version 2.2.0.\\n\\n'},\n",
       "         'skip_blank_lines': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If True, skip over blank lines rather than interpreting as NaN values.\\n'},\n",
       "         'parse_dates': {'type': 'boolean',\n",
       "          'description': \"bool, list of Hashable, list of lists or dict of {Hashable. The behavior is as follows:\\n\\nbool. If True -> try parsing the index. Note: Automatically set to\\nTrue if date_format or date_parser arguments have been passed.\\nlist of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\\neach as a separate date column.\\nlist of list. e.g. If [[1, 3]] -> combine columns 1 and 3 and parse\\nas a single date column. Values are joined with a space before parsing.\\ndict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call\\nresult ‘foo’. Values are joined with a space before parsing.\\n\\nIf a column or index cannot be represented as an array of datetime,\\nsay because of an unparsable value or a mixture of timezones, the column\\nor index will be returned unaltered as an object data type. For\\nnon-standard datetime parsing, use to_datetime() after\\nread_csv().\\nNote: A fast-path exists for iso8601-formatted dates.\\n\"},\n",
       "         'infer_datetime_format': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True and parse_dates is enabled, pandas will attempt to infer the\\nformat of the datetime strings in the columns, and if it can be inferred,\\nswitch to a faster method of parsing them. In some cases this can increase\\nthe parsing speed by 5-10x.\\n\\nDeprecated since version 2.0.0: A strict version of this argument is now the default, passing it has no effect.\\n\\n'},\n",
       "         'keep_date_col': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True and parse_dates specifies combining multiple columns then\\nkeep the original columns.\\n'},\n",
       "         'date_parser': {'type': 'Callable, optional',\n",
       "          'description': 'Callable, optional. Function to use for converting a sequence of string columns to an array of\\ndatetime instances. The default uses dateutil.parser.parser to do the\\nconversion. pandas will try to call date_parser in three different ways,\\nadvancing to the next if an exception occurs: 1) Pass one or more arrays\\n(as defined by parse_dates) as arguments; 2) concatenate (row-wise) the\\nstring values from the columns defined by parse_dates into a single array\\nand pass that; and 3) call date_parser once for each row using one or\\nmore strings (corresponding to the columns defined by parse_dates) as\\narguments.\\n\\nDeprecated since version 2.0.0: Use date_format instead, or read in as object and then apply\\nto_datetime() as-needed.\\n\\n'},\n",
       "         'date_format': {'type': 'string',\n",
       "          'description': 'str or dict of column -> format, optional. Format to use for parsing dates when used in conjunction with parse_dates.\\nThe strftime to parse time, e.g. \"%d/%m/%Y\". See\\nstrftime documentation for more information on choices, though\\nnote that \"%f\" will parse all the way up to nanoseconds.\\nYou can also pass:\\n\\n\\n“ISO8601”, to parse any ISO8601time string (not necessarily in exactly the same format);\\n\\n\\n\\n\\n“mixed”, to infer the format for each element individually. This is risky,and you should probably use it along with dayfirst.\\n\\n\\n\\n\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "         'dayfirst': {'type': 'boolean',\n",
       "          'description': 'bool, default False. DD/MM format dates, international and European format.\\n'},\n",
       "         'cache_dates': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If True, use a cache of unique, converted dates to apply the datetime\\nconversion. May produce significant speed-up when parsing duplicate\\ndate strings, especially ones with timezone offsets.\\n'},\n",
       "         'iterator': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Return TextFileReader object for iteration or getting chunks with\\nget_chunk().\\n'},\n",
       "         'chunksize': {'type': 'integer',\n",
       "          'description': 'int, optional. Number of lines to read from the file per chunk. Passing a value will cause the\\nfunction to return a TextFileReader object for iteration.\\nSee the IO Tools docs\\nfor more information on iterator and chunksize.\\n'},\n",
       "         'compression': {'type': 'string',\n",
       "          'description': \"str or dict, default ‘infer’. For on-the-fly decompression of on-disk data. If ‘infer’ and ‘filepath_or_buffer’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nIf using ‘zip’ or ‘tar’, the ZIP file must contain only one data file to be read in.\\nSet to None for no decompression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdDecompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for Zstandard decompression using a\\ncustom compression dictionary:\\ncompression={'method': 'zstd', 'dict_data': my_compression_dict}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\n\\n\\nChanged in version 1.4.0: Zstandard support.\\n\\n\"},\n",
       "         'thousands': {'type': 'string',\n",
       "          'description': 'str (length 1), optional. Character acting as the thousands separator in numerical values.\\n'},\n",
       "         'decimal': {'type': 'string',\n",
       "          'description': 'str (length 1), default ‘.’. Character to recognize as decimal point (e.g., use ‘,’ for European data).\\n'},\n",
       "         'lineterminator': {'type': 'string',\n",
       "          'description': 'str (length 1), optional. Character used to denote a line break. Only valid with C parser.\\n'},\n",
       "         'quotechar': {'type': 'string',\n",
       "          'description': 'str (length 1), optional. Character used to denote the start and end of a quoted item. Quoted\\nitems can include the delimiter and it will be ignored.\\n'},\n",
       "         'quoting': {'type': '{0 or csv.QUOTE_MINIMAL, 1 or csv.QUOTE_ALL, 2 or csv.QUOTE_NONNUMERIC, 3 or csv.QUOTE_NONE}, default csv.QUOTE_MINIMAL',\n",
       "          'description': '{0 or csv.QUOTE_MINIMAL, 1 or csv.QUOTE_ALL, 2 or csv.QUOTE_NONNUMERIC, 3 or csv.QUOTE_NONE}, default csv.QUOTE_MINIMAL. Control field quoting behavior per csv.QUOTE_* constants. Default is\\ncsv.QUOTE_MINIMAL (i.e., 0) which implies that only fields containing special\\ncharacters are quoted (e.g., characters defined in quotechar, delimiter,\\nor lineterminator.\\n'},\n",
       "         'doublequote': {'type': 'boolean',\n",
       "          'description': 'bool, default True. When quotechar is specified and quoting is not QUOTE_NONE, indicate\\nwhether or not to interpret two consecutive quotechar elements INSIDE a\\nfield as a single quotechar element.\\n'},\n",
       "         'escapechar': {'type': 'string',\n",
       "          'description': 'str (length 1), optional. Character used to escape other characters.\\n'},\n",
       "         'comment': {'type': 'string',\n",
       "          'description': \"str (length 1), optional. Character indicating that the remainder of line should not be parsed.\\nIf found at the beginning\\nof a line, the line will be ignored altogether. This parameter must be a\\nsingle character. Like empty lines (as long as skip_blank_lines=True),\\nfully commented lines are ignored by the parameter header but not by\\nskiprows. For example, if comment='#', parsing\\n#empty\\\\na,b,c\\\\n1,2,3 with header=0 will result in 'a,b,c' being\\ntreated as the header.\\n\"},\n",
       "         'encoding': {'type': 'string',\n",
       "          'description': \"str, optional, default ‘utf-8’. Encoding to use for UTF when reading/writing (ex. 'utf-8'). List of Python\\nstandard encodings .\\n\"},\n",
       "         'encoding_errors': {'type': 'string',\n",
       "          'description': 'str, optional, default ‘strict’. How encoding errors are treated. List of possible values .\\n\\nNew in version 1.3.0.\\n\\n'},\n",
       "         'dialect': {'type': 'string',\n",
       "          'description': 'str or csv.Dialect, optional. If provided, this parameter will override values (default or not) for the\\nfollowing parameters: delimiter, doublequote, escapechar,\\nskipinitialspace, quotechar, and quoting. If it is necessary to\\noverride values, a ParserWarning will be issued. See csv.Dialect\\ndocumentation for more details.\\n'},\n",
       "         'on_bad_lines': {'type': 'string',\n",
       "          'enum': ['error', ' warn', ' skip'],\n",
       "          'description': \"{‘error’, ‘warn’, ‘skip’} or Callable, default ‘error’. Specifies what to do upon encountering a bad line (a line with too many fields).\\nAllowed values are :\\n\\n'error', raise an Exception when a bad line is encountered.\\n'warn', raise a warning when a bad line is encountered and skip that line.\\n'skip', skip bad lines without raising or warning when they are encountered.\\n\\n\\nNew in version 1.3.0.\\n\\n\\nNew in version 1.4.0: \\n\\nCallable, function with signature\\n(bad_line: list[str]) -> list[str] | None that will process a single\\nbad line. bad_line is a list of strings split by the sep.\\nIf the function returns None, the bad line will be ignored.\\nIf the function returns a new list of strings with more elements than\\nexpected, a ParserWarning will be emitted while dropping extra elements.\\nOnly supported when engine='python'\\n\\n\\n\\nChanged in version 2.2.0: \\n\\nCallable, function with signature\\nas described in pyarrow documentation when engine='pyarrow'\\n\\n\\n\"},\n",
       "         'delim_whitespace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Specifies whether or not whitespace (e.g. \\' \\' or \\'\\\\t\\') will be\\nused as the sep delimiter. Equivalent to setting sep=\\'\\\\s+\\'. If this option\\nis set to True, nothing should be passed in for the delimiter\\nparameter.\\n\\nDeprecated since version 2.2.0: Use sep=\"\\\\s+\" instead.\\n\\n'},\n",
       "         'low_memory': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Internally process the file in chunks, resulting in lower memory use\\nwhile parsing, but possibly mixed type inference. To ensure no mixed\\ntypes either set False, or specify the type with the dtype parameter.\\nNote that the entire file is read into a single DataFrame\\nregardless, use the chunksize or iterator parameter to return the data in\\nchunks. (Only valid with C parser).\\n'},\n",
       "         'memory_map': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If a filepath is provided for filepath_or_buffer, map the file object\\ndirectly onto memory and access the data directly from there. Using this\\noption can improve performance because there is no longer any I/O overhead.\\n'},\n",
       "         'float_precision': {'type': 'string',\n",
       "          'enum': ['high', ' legacy', ' round_trip'],\n",
       "          'description': \"{‘high’, ‘legacy’, ‘round_trip’}, optional. Specifies which converter the C engine should use for floating-point\\nvalues. The options are None or 'high' for the ordinary converter,\\n'legacy' for the original lower precision pandas converter, and\\n'round_trip' for the round-trip converter.\\n\"},\n",
       "         'storage_options': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'},\n",
       "         'dtype_backend': {'type': 'string',\n",
       "          'enum': ['numpy_nullable', ' pyarrow'],\n",
       "          'description': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’. Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'}},\n",
       "        'required': ['filepath_or_buffer']}}},\n",
       "     {'func_name': 'read_fwf(filepath_or_buffer,\\xa0*[,\\xa0colspecs,\\xa0...])',\n",
       "      'func_desc': 'Read a table of fixed-width formatted lines into DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.read_fwf.html#pandas.read_fwf',\n",
       "      'function_definitions': {'function_name': 'pandas.read_fwf',\n",
       "       'full_function': \"pandas.read_fwf(filepath_or_buffer, *, colspecs='infer', widths=None, infer_nrows=100, dtype_backend=_NoDefault.no_default, iterator=False, chunksize=None, **kwds)\",\n",
       "       'function_text': 'Read a table of fixed-width formatted lines into DataFrame. Also supports optionally iterating or breaking of the file\\ninto chunks. Additional help can be found in the online docs for IO Tools.',\n",
       "       'parameter_names_desc': [{'param_name': 'filepath_or_buffer',\n",
       "         'param_type': 'str, path object, or file-like object',\n",
       "         'param_desc': 'String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a text read() function.The string could be a URL.\\nValid URL schemes include http, ftp, s3, and file. For file URLs, a host is\\nexpected. A local file could be:\\nfile://localhost/path/to/table.csv.\\n'},\n",
       "        {'param_name': 'colspecs',\n",
       "         'param_type': 'list of tuple (int, int) or ‘infer’. optional',\n",
       "         'param_desc': 'A list of tuples giving the extents of the fixed-width\\nfields of each line as half-open intervals (i.e., [from, to[ ).\\nString value ‘infer’ can be used to instruct the parser to try\\ndetecting the column specifications from the first 100 rows of\\nthe data which are not being skipped via skiprows (default=’infer’).\\n'},\n",
       "        {'param_name': 'widths',\n",
       "         'param_type': 'list of int, optional',\n",
       "         'param_desc': 'A list of field widths which can be used instead of ‘colspecs’ if\\nthe intervals are contiguous.\\n'},\n",
       "        {'param_name': 'infer_nrows',\n",
       "         'param_type': 'int, default 100',\n",
       "         'param_desc': 'The number of rows to consider when letting the parser determine the\\ncolspecs.\\n'},\n",
       "        {'param_name': 'dtype_backend',\n",
       "         'param_type': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’',\n",
       "         'param_desc': 'Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'},\n",
       "        {'param_name': '**kwds',\n",
       "         'param_type': 'optional',\n",
       "         'param_desc': 'Optional keyword arguments can be passed to TextFileReader.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.read_fwf',\n",
       "       'descriptions': 'Read a table of fixed-width formatted lines into DataFrame. Also supports optionally iterating or breaking of the file\\ninto chunks. Additional help can be found in the online docs for IO Tools.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'filepath_or_buffer': {'type': 'string',\n",
       "          'description': 'str, path object, or file-like object. String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a text read() function.The string could be a URL.\\nValid URL schemes include http, ftp, s3, and file. For file URLs, a host is\\nexpected. A local file could be:\\nfile://localhost/path/to/table.csv.\\n'},\n",
       "         'colspecs': {'type': 'integer',\n",
       "          'description': 'list of tuple (int, int) or ‘infer’. optional. A list of tuples giving the extents of the fixed-width\\nfields of each line as half-open intervals (i.e., [from, to[ ).\\nString value ‘infer’ can be used to instruct the parser to try\\ndetecting the column specifications from the first 100 rows of\\nthe data which are not being skipped via skiprows (default=’infer’).\\n'},\n",
       "         'widths': {'type': 'integer',\n",
       "          'description': 'list of int, optional. A list of field widths which can be used instead of ‘colspecs’ if\\nthe intervals are contiguous.\\n'},\n",
       "         'infer_nrows': {'type': 'integer',\n",
       "          'description': 'int, default 100. The number of rows to consider when letting the parser determine the\\ncolspecs.\\n'},\n",
       "         'dtype_backend': {'type': 'string',\n",
       "          'enum': ['numpy_nullable', ' pyarrow'],\n",
       "          'description': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’. Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'},\n",
       "         '**kwds': {'type': 'optional',\n",
       "          'description': 'optional. Optional keyword arguments can be passed to TextFileReader.\\n'}},\n",
       "        'required': ['filepath_or_buffer']}}}]},\n",
       "   {'Clipboard': [{'func_name': 'read_clipboard([sep,\\xa0dtype_backend])',\n",
       "      'func_desc': 'Read text from clipboard and pass to read_csv().',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.read_clipboard.html#pandas.read_clipboard',\n",
       "      'function_definitions': {'function_name': 'pandas.read_clipboard',\n",
       "       'full_function': \"pandas.read_clipboard(sep='\\\\\\\\s+', dtype_backend=_NoDefault.no_default, **kwargs)\",\n",
       "       'function_text': 'Read text from clipboard and pass to read_csv(). Parses clipboard contents similar to how CSV files are parsed\\nusing read_csv().',\n",
       "       'parameter_names_desc': [{'param_name': 'sep',\n",
       "         'param_type': 'str, default ‘\\\\s+’',\n",
       "         'param_desc': \"A string or regex delimiter. The default of '\\\\\\\\s+' denotes\\none or more whitespace characters.\\n\"},\n",
       "        {'param_name': 'dtype_backend',\n",
       "         'param_type': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’',\n",
       "         'param_desc': 'Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.read_clipboard',\n",
       "       'descriptions': 'Read text from clipboard and pass to read_csv(). Parses clipboard contents similar to how CSV files are parsed\\nusing read_csv().',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'sep': {'type': 'string',\n",
       "          'description': \"str, default ‘\\\\s+’. A string or regex delimiter. The default of '\\\\\\\\s+' denotes\\none or more whitespace characters.\\n\"},\n",
       "         'dtype_backend': {'type': 'string',\n",
       "          'enum': ['numpy_nullable', ' pyarrow'],\n",
       "          'description': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’. Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.to_clipboard(*[,\\xa0excel,\\xa0sep])',\n",
       "      'func_desc': 'Copy object to the system clipboard.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_clipboard.html#pandas.DataFrame.to_clipboard',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_clipboard',\n",
       "       'full_function': 'DataFrame.to_clipboard(*, excel=True, sep=None, **kwargs)',\n",
       "       'function_text': 'Copy object to the system clipboard. Write a text representation of object to the system clipboard.\\nThis can be pasted into Excel, for example.',\n",
       "       'parameter_names_desc': [{'param_name': 'excel',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Produce output in a csv format for easy pasting into excel.\\n\\nTrue, use the provided separator for csv pasting.\\nFalse, write a string representation of the object to the clipboard.\\n\\n'},\n",
       "        {'param_name': 'sep',\n",
       "         'param_type': \"str, default '\\\\t'\",\n",
       "         'param_desc': 'Field delimiter.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.to_clipboard',\n",
       "       'descriptions': 'Copy object to the system clipboard. Write a text representation of object to the system clipboard.\\nThis can be pasted into Excel, for example.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'excel': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Produce output in a csv format for easy pasting into excel.\\n\\nTrue, use the provided separator for csv pasting.\\nFalse, write a string representation of the object to the clipboard.\\n\\n'},\n",
       "         'sep': {'type': 'string',\n",
       "          'description': \"str, default '\\\\t'. Field delimiter.\\n\"}},\n",
       "        'required': []}}}]},\n",
       "   {'Excel': [{'func_name': 'read_excel(io[,\\xa0sheet_name,\\xa0header,\\xa0names,\\xa0...])',\n",
       "      'func_desc': 'Read an Excel file into a pandas DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html#pandas.read_excel',\n",
       "      'function_definitions': {'function_name': 'pandas.read_excel',\n",
       "       'full_function': \"pandas.read_excel(io, sheet_name=0, *, header=0, names=None, index_col=None, usecols=None, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skiprows=None, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=False, parse_dates=False, date_parser=_NoDefault.no_default, date_format=None, thousands=None, decimal='.', comment=None, skipfooter=0, storage_options=None, dtype_backend=_NoDefault.no_default, engine_kwargs=None)\",\n",
       "       'function_text': 'Read an Excel file into a pandas DataFrame. Supports xls, xlsx, xlsm, xlsb, odf, ods and odt file extensions\\nread from a local filesystem or URL. Supports an option to read\\na single sheet or a list of sheets.',\n",
       "       'parameter_names_desc': [{'param_name': 'io',\n",
       "         'param_type': 'str, bytes, ExcelFile, xlrd.Book, path object, or file-like object',\n",
       "         'param_desc': 'Any valid string path is acceptable. The string could be a URL. Valid\\nURL schemes include http, ftp, s3, and file. For file URLs, a host is\\nexpected. A local file could be: file://localhost/path/to/table.xlsx.\\nIf you want to pass in a path object, pandas accepts any os.PathLike.\\nBy file-like object, we refer to objects with a read() method,\\nsuch as a file handle (e.g. via builtin open function)\\nor StringIO.\\n\\nDeprecated since version 2.1.0: Passing byte strings is deprecated. To read from a\\nbyte string, wrap it in a BytesIO object.\\n\\n'},\n",
       "        {'param_name': 'sheet_name',\n",
       "         'param_type': 'str, int, list, or None, default 0',\n",
       "         'param_desc': 'Strings are used for sheet names. Integers are used in zero-indexed\\nsheet positions (chart sheets do not count as a sheet position).\\nLists of strings/integers are used to request multiple sheets.\\nSpecify None to get all worksheets.\\nAvailable cases:\\n\\nDefaults to 0: 1st sheet as a DataFrame\\n1: 2nd sheet as a DataFrame\\n\"Sheet1\": Load sheet with name “Sheet1”\\n[0, 1, \"Sheet5\"]: Load first, second and sheet named “Sheet5”\\nas a dict of DataFrame\\nNone: All worksheets.\\n\\n'},\n",
       "        {'param_name': 'header',\n",
       "         'param_type': 'int, list of int, default 0',\n",
       "         'param_desc': 'Row (0-indexed) to use for the column labels of the parsed\\nDataFrame. If a list of integers is passed those row positions will\\nbe combined into a MultiIndex. Use None if there is no header.\\n'},\n",
       "        {'param_name': 'names',\n",
       "         'param_type': 'array-like, default None',\n",
       "         'param_desc': 'List of column names to use. If file contains no header row,\\nthen you should explicitly pass header=None.\\n'},\n",
       "        {'param_name': 'index_col',\n",
       "         'param_type': 'int, str, list of int, default None',\n",
       "         'param_desc': 'Column (0-indexed) to use as the row labels of the DataFrame.\\nPass None if there is no such column. If a list is passed,\\nthose columns will be combined into a MultiIndex. If a\\nsubset of data is selected with usecols, index_col\\nis based on the subset.\\nMissing values will be forward filled to allow roundtripping with\\nto_excel for merged_cells=True. To avoid forward filling the\\nmissing values use set_index after reading the data instead of\\nindex_col.\\n'},\n",
       "        {'param_name': 'usecols',\n",
       "         'param_type': 'str, list-like, or callable, default None',\n",
       "         'param_desc': '\\nIf None, then parse all columns.\\nIf str, then indicates comma separated list of Excel column letters\\nand column ranges (e.g. “A:E” or “A,C,E:F”). Ranges are inclusive of\\nboth sides.\\nIf list of int, then indicates list of column numbers to be parsed\\n(0-indexed).\\nIf list of string, then indicates list of column names to be parsed.\\nIf callable, then evaluate each column name against it and parse the\\ncolumn if the callable returns True.\\n\\nReturns a subset of the columns according to behavior above.\\n'},\n",
       "        {'param_name': 'dtype',\n",
       "         'param_type': 'Type name or dict of column -> type, default None',\n",
       "         'param_desc': 'Data type for data or columns. E.g. {‘a’: np.float64, ‘b’: np.int32}\\nUse object to preserve data as stored in Excel and not interpret dtype,\\nwhich will necessarily result in object dtype.\\nIf converters are specified, they will be applied INSTEAD\\nof dtype conversion.\\nIf you use None, it will infer the dtype of each column based on the data.\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': '{‘openpyxl’, ‘calamine’, ‘odf’, ‘pyxlsb’, ‘xlrd’}, default None',\n",
       "         'param_desc': 'If io is not a buffer or path, this must be set to identify io.\\nEngine compatibility :\\n\\nopenpyxl supports newer Excel file formats.\\ncalamine supports Excel (.xls, .xlsx, .xlsm, .xlsb)\\nand OpenDocument (.ods) file formats.\\nodf supports OpenDocument file formats (.odf, .ods, .odt).\\npyxlsb supports Binary Excel files.\\nxlrd supports old-style Excel files (.xls).\\n\\nWhen engine=None, the following logic will be used to determine the engine:\\n\\nIf path_or_buffer is an OpenDocument format (.odf, .ods, .odt),\\nthen odf will be used.\\nOtherwise if path_or_buffer is an xls format, xlrd will be used.\\nOtherwise if path_or_buffer is in xlsb format, pyxlsb will be used.\\nOtherwise openpyxl will be used.\\n\\n'},\n",
       "        {'param_name': 'converters',\n",
       "         'param_type': 'dict, default None',\n",
       "         'param_desc': 'Dict of functions for converting values in certain columns. Keys can\\neither be integers or column labels, values are functions that take one\\ninput argument, the Excel cell content, and return the transformed\\ncontent.\\n'},\n",
       "        {'param_name': 'true_values',\n",
       "         'param_type': 'list, default None',\n",
       "         'param_desc': 'Values to consider as True.\\n'},\n",
       "        {'param_name': 'false_values',\n",
       "         'param_type': 'list, default None',\n",
       "         'param_desc': 'Values to consider as False.\\n'},\n",
       "        {'param_name': 'skiprows',\n",
       "         'param_type': 'list-like, int, or callable, optional',\n",
       "         'param_desc': 'Line numbers to skip (0-indexed) or number of lines to skip (int) at the\\nstart of the file. If callable, the callable function will be evaluated\\nagainst the row indices, returning True if the row should be skipped and\\nFalse otherwise. An example of a valid callable argument would be lambda\\nx: x in [0, 2].\\n'},\n",
       "        {'param_name': 'nrows',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'Number of rows to parse.\\n'},\n",
       "        {'param_name': 'na_values',\n",
       "         'param_type': 'scalar, str, list-like, or dict, default None',\n",
       "         'param_desc': 'Additional strings to recognize as NA/NaN. If dict passed, specific\\nper-column NA values. By default the following values are interpreted\\nas NaN: ‘’, ‘#N/A’, ‘#N/A N/A’, ‘#NA’, ‘-1.#IND’, ‘-1.#QNAN’, ‘-NaN’, ‘-nan’,\\n‘1.#IND’, ‘1.#QNAN’, ‘<NA>’, ‘N/A’, ‘NA’, ‘NULL’, ‘NaN’, ‘None’,\\n‘n/a’, ‘nan’, ‘null’.\\n'},\n",
       "        {'param_name': 'keep_default_na',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether or not to include the default NaN values when parsing the data.\\nDepending on whether na_values is passed in, the behavior is as follows:\\n\\nIf keep_default_na is True, and na_values are specified,\\nna_values is appended to the default NaN values used for parsing.\\nIf keep_default_na is True, and na_values are not specified, only\\nthe default NaN values are used for parsing.\\nIf keep_default_na is False, and na_values are specified, only\\nthe NaN values specified na_values are used for parsing.\\nIf keep_default_na is False, and na_values are not specified, no\\nstrings will be parsed as NaN.\\n\\nNote that if na_filter is passed in as False, the keep_default_na and\\nna_values parameters will be ignored.\\n'},\n",
       "        {'param_name': 'na_filter',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Detect missing value markers (empty strings and the value of na_values). In\\ndata without any NAs, passing na_filter=False can improve the\\nperformance of reading a large file.\\n'},\n",
       "        {'param_name': 'verbose',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Indicate number of NA values placed in non-numeric columns.\\n'},\n",
       "        {'param_name': 'parse_dates',\n",
       "         'param_type': 'bool, list-like, or dict, default False',\n",
       "         'param_desc': 'The behavior is as follows:\\n\\nbool. If True -> try parsing the index.\\nlist of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\\neach as a separate date column.\\nlist of lists. e.g. If [[1, 3]] -> combine columns 1 and 3 and parse as\\na single date column.\\ndict, e.g. {‘foo’ : [1, 3]} -> parse columns 1, 3 as date and call\\nresult ‘foo’\\n\\nIf a column or index contains an unparsable date, the entire column or\\nindex will be returned unaltered as an object data type. If you don`t want to\\nparse some cells as date just change their type in Excel to “Text”.\\nFor non-standard datetime parsing, use pd.to_datetime after pd.read_excel.\\nNote: A fast-path exists for iso8601-formatted dates.\\n'},\n",
       "        {'param_name': 'date_parser',\n",
       "         'param_type': 'function, optional',\n",
       "         'param_desc': 'Function to use for converting a sequence of string columns to an array of\\ndatetime instances. The default uses dateutil.parser.parser to do the\\nconversion. Pandas will try to call date_parser in three different ways,\\nadvancing to the next if an exception occurs: 1) Pass one or more arrays\\n(as defined by parse_dates) as arguments; 2) concatenate (row-wise) the\\nstring values from the columns defined by parse_dates into a single array\\nand pass that; and 3) call date_parser once for each row using one or\\nmore strings (corresponding to the columns defined by parse_dates) as\\narguments.\\n\\nDeprecated since version 2.0.0: Use date_format instead, or read in as object and then apply\\nto_datetime() as-needed.\\n\\n'},\n",
       "        {'param_name': 'date_format',\n",
       "         'param_type': 'str or dict of column -> format, default None',\n",
       "         'param_desc': 'If used in conjunction with parse_dates, will parse dates according to this\\nformat. For anything more complex,\\nplease read in as object and then apply to_datetime() as-needed.\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "        {'param_name': 'thousands',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'Thousands separator for parsing string columns to numeric. Note that\\nthis parameter is only necessary for columns stored as TEXT in Excel,\\nany numeric columns will automatically be parsed, regardless of display\\nformat.\\n'},\n",
       "        {'param_name': 'decimal',\n",
       "         'param_type': 'str, default ‘.’',\n",
       "         'param_desc': 'Character to recognize as decimal point for parsing string columns to numeric.\\nNote that this parameter is only necessary for columns stored as TEXT in Excel,\\nany numeric columns will automatically be parsed, regardless of display\\nformat.(e.g. use ‘,’ for European data).\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "        {'param_name': 'comment',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'Comments out remainder of line. Pass a character or characters to this\\nargument to indicate comments in the input file. Any data between the\\ncomment string and the end of the current line is ignored.\\n'},\n",
       "        {'param_name': 'skipfooter',\n",
       "         'param_type': 'int, default 0',\n",
       "         'param_desc': 'Rows at the end to skip (0-indexed).\\n'},\n",
       "        {'param_name': 'storage_options',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'},\n",
       "        {'param_name': 'dtype_backend',\n",
       "         'param_type': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’',\n",
       "         'param_desc': 'Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Arbitrary keyword arguments passed to excel engine.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.read_excel',\n",
       "       'descriptions': 'Read an Excel file into a pandas DataFrame. Supports xls, xlsx, xlsm, xlsb, odf, ods and odt file extensions\\nread from a local filesystem or URL. Supports an option to read\\na single sheet or a list of sheets.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'io': {'type': 'string',\n",
       "          'description': 'str, bytes, ExcelFile, xlrd.Book, path object, or file-like object. Any valid string path is acceptable. The string could be a URL. Valid\\nURL schemes include http, ftp, s3, and file. For file URLs, a host is\\nexpected. A local file could be: file://localhost/path/to/table.xlsx.\\nIf you want to pass in a path object, pandas accepts any os.PathLike.\\nBy file-like object, we refer to objects with a read() method,\\nsuch as a file handle (e.g. via builtin open function)\\nor StringIO.\\n\\nDeprecated since version 2.1.0: Passing byte strings is deprecated. To read from a\\nbyte string, wrap it in a BytesIO object.\\n\\n'},\n",
       "         'sheet_name': {'type': 'integer',\n",
       "          'description': 'str, int, list, or None, default 0. Strings are used for sheet names. Integers are used in zero-indexed\\nsheet positions (chart sheets do not count as a sheet position).\\nLists of strings/integers are used to request multiple sheets.\\nSpecify None to get all worksheets.\\nAvailable cases:\\n\\nDefaults to 0: 1st sheet as a DataFrame\\n1: 2nd sheet as a DataFrame\\n\"Sheet1\": Load sheet with name “Sheet1”\\n[0, 1, \"Sheet5\"]: Load first, second and sheet named “Sheet5”\\nas a dict of DataFrame\\nNone: All worksheets.\\n\\n'},\n",
       "         'header': {'type': 'integer',\n",
       "          'description': 'int, list of int, default 0. Row (0-indexed) to use for the column labels of the parsed\\nDataFrame. If a list of integers is passed those row positions will\\nbe combined into a MultiIndex. Use None if there is no header.\\n'},\n",
       "         'names': {'type': 'array',\n",
       "          'description': 'array-like, default None. List of column names to use. If file contains no header row,\\nthen you should explicitly pass header=None.\\n'},\n",
       "         'index_col': {'type': 'integer',\n",
       "          'description': 'int, str, list of int, default None. Column (0-indexed) to use as the row labels of the DataFrame.\\nPass None if there is no such column. If a list is passed,\\nthose columns will be combined into a MultiIndex. If a\\nsubset of data is selected with usecols, index_col\\nis based on the subset.\\nMissing values will be forward filled to allow roundtripping with\\nto_excel for merged_cells=True. To avoid forward filling the\\nmissing values use set_index after reading the data instead of\\nindex_col.\\n'},\n",
       "         'usecols': {'type': 'string',\n",
       "          'description': 'str, list-like, or callable, default None. \\nIf None, then parse all columns.\\nIf str, then indicates comma separated list of Excel column letters\\nand column ranges (e.g. “A:E” or “A,C,E:F”). Ranges are inclusive of\\nboth sides.\\nIf list of int, then indicates list of column numbers to be parsed\\n(0-indexed).\\nIf list of string, then indicates list of column names to be parsed.\\nIf callable, then evaluate each column name against it and parse the\\ncolumn if the callable returns True.\\n\\nReturns a subset of the columns according to behavior above.\\n'},\n",
       "         'dtype': {'type': 'Type name or dict of column -> type, default None',\n",
       "          'description': 'Type name or dict of column -> type, default None. Data type for data or columns. E.g. {‘a’: np.float64, ‘b’: np.int32}\\nUse object to preserve data as stored in Excel and not interpret dtype,\\nwhich will necessarily result in object dtype.\\nIf converters are specified, they will be applied INSTEAD\\nof dtype conversion.\\nIf you use None, it will infer the dtype of each column based on the data.\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'enum': ['openpyxl', ' calamine', ' odf', ' pyxlsb', ' xlrd'],\n",
       "          'description': '{‘openpyxl’, ‘calamine’, ‘odf’, ‘pyxlsb’, ‘xlrd’}, default None. If io is not a buffer or path, this must be set to identify io.\\nEngine compatibility :\\n\\nopenpyxl supports newer Excel file formats.\\ncalamine supports Excel (.xls, .xlsx, .xlsm, .xlsb)\\nand OpenDocument (.ods) file formats.\\nodf supports OpenDocument file formats (.odf, .ods, .odt).\\npyxlsb supports Binary Excel files.\\nxlrd supports old-style Excel files (.xls).\\n\\nWhen engine=None, the following logic will be used to determine the engine:\\n\\nIf path_or_buffer is an OpenDocument format (.odf, .ods, .odt),\\nthen odf will be used.\\nOtherwise if path_or_buffer is an xls format, xlrd will be used.\\nOtherwise if path_or_buffer is in xlsb format, pyxlsb will be used.\\nOtherwise openpyxl will be used.\\n\\n'},\n",
       "         'converters': {'type': 'dict, default None',\n",
       "          'description': 'dict, default None. Dict of functions for converting values in certain columns. Keys can\\neither be integers or column labels, values are functions that take one\\ninput argument, the Excel cell content, and return the transformed\\ncontent.\\n'},\n",
       "         'true_values': {'type': 'array',\n",
       "          'description': 'list, default None. Values to consider as True.\\n'},\n",
       "         'false_values': {'type': 'array',\n",
       "          'description': 'list, default None. Values to consider as False.\\n'},\n",
       "         'skiprows': {'type': 'integer',\n",
       "          'description': 'list-like, int, or callable, optional. Line numbers to skip (0-indexed) or number of lines to skip (int) at the\\nstart of the file. If callable, the callable function will be evaluated\\nagainst the row indices, returning True if the row should be skipped and\\nFalse otherwise. An example of a valid callable argument would be lambda\\nx: x in [0, 2].\\n'},\n",
       "         'nrows': {'type': 'integer',\n",
       "          'description': 'int, default None. Number of rows to parse.\\n'},\n",
       "         'na_values': {'type': 'string',\n",
       "          'description': 'scalar, str, list-like, or dict, default None. Additional strings to recognize as NA/NaN. If dict passed, specific\\nper-column NA values. By default the following values are interpreted\\nas NaN: ‘’, ‘#N/A’, ‘#N/A N/A’, ‘#NA’, ‘-1.#IND’, ‘-1.#QNAN’, ‘-NaN’, ‘-nan’,\\n‘1.#IND’, ‘1.#QNAN’, ‘<NA>’, ‘N/A’, ‘NA’, ‘NULL’, ‘NaN’, ‘None’,\\n‘n/a’, ‘nan’, ‘null’.\\n'},\n",
       "         'keep_default_na': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether or not to include the default NaN values when parsing the data.\\nDepending on whether na_values is passed in, the behavior is as follows:\\n\\nIf keep_default_na is True, and na_values are specified,\\nna_values is appended to the default NaN values used for parsing.\\nIf keep_default_na is True, and na_values are not specified, only\\nthe default NaN values are used for parsing.\\nIf keep_default_na is False, and na_values are specified, only\\nthe NaN values specified na_values are used for parsing.\\nIf keep_default_na is False, and na_values are not specified, no\\nstrings will be parsed as NaN.\\n\\nNote that if na_filter is passed in as False, the keep_default_na and\\nna_values parameters will be ignored.\\n'},\n",
       "         'na_filter': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Detect missing value markers (empty strings and the value of na_values). In\\ndata without any NAs, passing na_filter=False can improve the\\nperformance of reading a large file.\\n'},\n",
       "         'verbose': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Indicate number of NA values placed in non-numeric columns.\\n'},\n",
       "         'parse_dates': {'type': 'boolean',\n",
       "          'description': 'bool, list-like, or dict, default False. The behavior is as follows:\\n\\nbool. If True -> try parsing the index.\\nlist of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\\neach as a separate date column.\\nlist of lists. e.g. If [[1, 3]] -> combine columns 1 and 3 and parse as\\na single date column.\\ndict, e.g. {‘foo’ : [1, 3]} -> parse columns 1, 3 as date and call\\nresult ‘foo’\\n\\nIf a column or index contains an unparsable date, the entire column or\\nindex will be returned unaltered as an object data type. If you don`t want to\\nparse some cells as date just change their type in Excel to “Text”.\\nFor non-standard datetime parsing, use pd.to_datetime after pd.read_excel.\\nNote: A fast-path exists for iso8601-formatted dates.\\n'},\n",
       "         'date_parser': {'type': 'function, optional',\n",
       "          'description': 'function, optional. Function to use for converting a sequence of string columns to an array of\\ndatetime instances. The default uses dateutil.parser.parser to do the\\nconversion. Pandas will try to call date_parser in three different ways,\\nadvancing to the next if an exception occurs: 1) Pass one or more arrays\\n(as defined by parse_dates) as arguments; 2) concatenate (row-wise) the\\nstring values from the columns defined by parse_dates into a single array\\nand pass that; and 3) call date_parser once for each row using one or\\nmore strings (corresponding to the columns defined by parse_dates) as\\narguments.\\n\\nDeprecated since version 2.0.0: Use date_format instead, or read in as object and then apply\\nto_datetime() as-needed.\\n\\n'},\n",
       "         'date_format': {'type': 'string',\n",
       "          'description': 'str or dict of column -> format, default None. If used in conjunction with parse_dates, will parse dates according to this\\nformat. For anything more complex,\\nplease read in as object and then apply to_datetime() as-needed.\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "         'thousands': {'type': 'string',\n",
       "          'description': 'str, default None. Thousands separator for parsing string columns to numeric. Note that\\nthis parameter is only necessary for columns stored as TEXT in Excel,\\nany numeric columns will automatically be parsed, regardless of display\\nformat.\\n'},\n",
       "         'decimal': {'type': 'string',\n",
       "          'description': 'str, default ‘.’. Character to recognize as decimal point for parsing string columns to numeric.\\nNote that this parameter is only necessary for columns stored as TEXT in Excel,\\nany numeric columns will automatically be parsed, regardless of display\\nformat.(e.g. use ‘,’ for European data).\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "         'comment': {'type': 'string',\n",
       "          'description': 'str, default None. Comments out remainder of line. Pass a character or characters to this\\nargument to indicate comments in the input file. Any data between the\\ncomment string and the end of the current line is ignored.\\n'},\n",
       "         'skipfooter': {'type': 'integer',\n",
       "          'description': 'int, default 0. Rows at the end to skip (0-indexed).\\n'},\n",
       "         'storage_options': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'},\n",
       "         'dtype_backend': {'type': 'string',\n",
       "          'enum': ['numpy_nullable', ' pyarrow'],\n",
       "          'description': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’. Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'},\n",
       "         'engine_kwargs': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Arbitrary keyword arguments passed to excel engine.\\n'}},\n",
       "        'required': ['io', 'sheet_name=0']}}},\n",
       "     {'func_name': 'ExcelFile(path_or_buffer[,\\xa0engine,\\xa0...])',\n",
       "      'func_desc': 'Class for parsing tabular Excel sheets into DataFrame objects.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.ExcelFile.html#pandas.ExcelFile',\n",
       "      'function_definitions': {'function_name': 'pandas.ExcelFile',\n",
       "       'full_function': 'class pandas.ExcelFile(path_or_buffer, engine=None, storage_options=None, engine_kwargs=None)',\n",
       "       'function_text': 'Class for parsing tabular Excel sheets into DataFrame objects. See read_excel for more documentation.',\n",
       "       'parameter_names_desc': [{'param_name': 'path_or_buffer',\n",
       "         'param_type': 'str, bytes, path object (pathlib.Path or py._path.local.LocalPath),',\n",
       "         'param_desc': 'A file-like object, xlrd workbook or openpyxl workbook.\\nIf a string or path object, expected to be a path to a\\n.xls, .xlsx, .xlsb, .xlsm, .odf, .ods, or .odt file.\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'If io is not a buffer or path, this must be set to identify io.\\nSupported engines: xlrd, openpyxl, odf, pyxlsb, calamine\\nEngine compatibility :\\n\\nxlrd supports old-style Excel files (.xls).\\nopenpyxl supports newer Excel file formats.\\nodf supports OpenDocument file formats (.odf, .ods, .odt).\\npyxlsb supports Binary Excel files.\\ncalamine supports Excel (.xls, .xlsx, .xlsm, .xlsb)\\nand OpenDocument (.ods) file formats.\\n\\n\\nChanged in version 1.2.0: The engine xlrd\\nnow only supports old-style .xls files.\\nWhen engine=None, the following logic will be\\nused to determine the engine:\\n\\nIf path_or_buffer is an OpenDocument format (.odf, .ods, .odt),\\nthen odf will be used.\\nOtherwise if path_or_buffer is an xls format,\\nxlrd will be used.\\nOtherwise if path_or_buffer is in xlsb format,\\npyxlsb will be used.\\n\\n\\nNew in version 1.3.0.\\n\\n\\nOtherwise if openpyxl is installed,\\nthen openpyxl will be used.\\nOtherwise if xlrd >= 2.0 is installed, a ValueError will be raised.\\n\\n\\nWarning\\nPlease do not report issues when using xlrd to read .xlsx files.\\nThis is not supported, switch to using openpyxl instead.\\n\\n\\n'},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Arbitrary keyword arguments passed to excel engine.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.ExcelFile',\n",
       "       'descriptions': 'Class for parsing tabular Excel sheets into DataFrame objects. See read_excel for more documentation.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'path_or_buffer': {'type': 'string',\n",
       "          'description': 'str, bytes, path object (pathlib.Path or py._path.local.LocalPath),. A file-like object, xlrd workbook or openpyxl workbook.\\nIf a string or path object, expected to be a path to a\\n.xls, .xlsx, .xlsb, .xlsm, .odf, .ods, or .odt file.\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': 'str, default None. If io is not a buffer or path, this must be set to identify io.\\nSupported engines: xlrd, openpyxl, odf, pyxlsb, calamine\\nEngine compatibility :\\n\\nxlrd supports old-style Excel files (.xls).\\nopenpyxl supports newer Excel file formats.\\nodf supports OpenDocument file formats (.odf, .ods, .odt).\\npyxlsb supports Binary Excel files.\\ncalamine supports Excel (.xls, .xlsx, .xlsm, .xlsb)\\nand OpenDocument (.ods) file formats.\\n\\n\\nChanged in version 1.2.0: The engine xlrd\\nnow only supports old-style .xls files.\\nWhen engine=None, the following logic will be\\nused to determine the engine:\\n\\nIf path_or_buffer is an OpenDocument format (.odf, .ods, .odt),\\nthen odf will be used.\\nOtherwise if path_or_buffer is an xls format,\\nxlrd will be used.\\nOtherwise if path_or_buffer is in xlsb format,\\npyxlsb will be used.\\n\\n\\nNew in version 1.3.0.\\n\\n\\nOtherwise if openpyxl is installed,\\nthen openpyxl will be used.\\nOtherwise if xlrd >= 2.0 is installed, a ValueError will be raised.\\n\\n\\nWarning\\nPlease do not report issues when using xlrd to read .xlsx files.\\nThis is not supported, switch to using openpyxl instead.\\n\\n\\n'},\n",
       "         'engine_kwargs': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Arbitrary keyword arguments passed to excel engine.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'ExcelFile.sheet_names',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.ExcelFile.sheet_names.html#pandas.ExcelFile.sheet_names',\n",
       "      'function_definitions': {'function_name': 'pandas.ExcelFile.sheet_names',\n",
       "       'full_function': 'property ExcelFile.sheet_names',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Styler.to_excel(excel_writer[,\\xa0sheet_name,\\xa0...])',\n",
       "      'func_desc': 'Write Styler to an Excel sheet.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_excel.html#pandas.io.formats.style.Styler.to_excel',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.to_excel',\n",
       "       'full_function': \"Styler.to_excel(excel_writer, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, encoding=None, inf_rep='inf', verbose=True, freeze_panes=None, storage_options=None)\",\n",
       "       'function_text': 'Write Styler to an Excel sheet. To write a single Styler to an Excel .xlsx file it is only necessary to\\nspecify a target file name. To write to multiple sheets it is necessary to\\ncreate an ExcelWriter object with a target file name, and specify a sheet\\nin the file to write to. Multiple sheets may be written to by specifying unique sheet_name.\\nWith all data written to the file it is necessary to save the changes.\\nNote that creating an ExcelWriter object with a file name that already\\nexists will result in the contents of the existing file being erased.',\n",
       "       'parameter_names_desc': [{'param_name': 'excel_writer',\n",
       "         'param_type': 'path-like, file-like, or ExcelWriter object',\n",
       "         'param_desc': 'File path or existing ExcelWriter.\\n'},\n",
       "        {'param_name': 'sheet_name',\n",
       "         'param_type': 'str, default ‘Sheet1’',\n",
       "         'param_desc': 'Name of sheet which will contain DataFrame.\\n'},\n",
       "        {'param_name': 'na_rep',\n",
       "         'param_type': 'str, default ‘’',\n",
       "         'param_desc': 'Missing data representation.\\n'},\n",
       "        {'param_name': 'float_format',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Format string for floating point numbers. For example\\nfloat_format=\"%.2f\" will format 0.1234 to 0.12.\\n'},\n",
       "        {'param_name': 'columns',\n",
       "         'param_type': 'sequence or list of str, optional',\n",
       "         'param_desc': 'Columns to write.\\n'},\n",
       "        {'param_name': 'header',\n",
       "         'param_type': 'bool or list of str, default True',\n",
       "         'param_desc': 'Write out the column names. If a list of string is given it is\\nassumed to be aliases for the column names.\\n'},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Write row names (index).\\n'},\n",
       "        {'param_name': 'index_label',\n",
       "         'param_type': 'str or sequence, optional',\n",
       "         'param_desc': 'Column label for index column(s) if desired. If not specified, and\\nheader and index are True, then the index names are used. A\\nsequence should be given if the DataFrame uses MultiIndex.\\n'},\n",
       "        {'param_name': 'startrow',\n",
       "         'param_type': 'int, default 0',\n",
       "         'param_desc': 'Upper left cell row to dump data frame.\\n'},\n",
       "        {'param_name': 'startcol',\n",
       "         'param_type': 'int, default 0',\n",
       "         'param_desc': 'Upper left cell column to dump data frame.\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Write engine to use, ‘openpyxl’ or ‘xlsxwriter’. You can also set this\\nvia the options io.excel.xlsx.writer or\\nio.excel.xlsm.writer.\\n'},\n",
       "        {'param_name': 'merge_cells',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Write MultiIndex and Hierarchical Rows as merged cells.\\n'},\n",
       "        {'param_name': 'inf_rep',\n",
       "         'param_type': 'str, default ‘inf’',\n",
       "         'param_desc': 'Representation for infinity (there is no native representation for\\ninfinity in Excel).\\n'},\n",
       "        {'param_name': 'freeze_panes',\n",
       "         'param_type': 'tuple of int (length 2), optional',\n",
       "         'param_desc': 'Specifies the one-based bottommost row and rightmost column that\\nis to be frozen.\\n'},\n",
       "        {'param_name': 'storage_options',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Arbitrary keyword arguments passed to excel engine.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.to_excel',\n",
       "       'descriptions': 'Write Styler to an Excel sheet. To write a single Styler to an Excel .xlsx file it is only necessary to\\nspecify a target file name. To write to multiple sheets it is necessary to\\ncreate an ExcelWriter object with a target file name, and specify a sheet\\nin the file to write to. Multiple sheets may be written to by specifying unique sheet_name.\\nWith all data written to the file it is necessary to save the changes.\\nNote that creating an ExcelWriter object with a file name that already\\nexists will result in the contents of the existing file being erased.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'excel_writer': {'type': 'object',\n",
       "          'description': 'path-like, file-like, or ExcelWriter object. File path or existing ExcelWriter.\\n'},\n",
       "         'sheet_name': {'type': 'string',\n",
       "          'description': 'str, default ‘Sheet1’. Name of sheet which will contain DataFrame.\\n'},\n",
       "         'na_rep': {'type': 'string',\n",
       "          'description': 'str, default ‘’. Missing data representation.\\n'},\n",
       "         'float_format': {'type': 'string',\n",
       "          'description': 'str, optional. Format string for floating point numbers. For example\\nfloat_format=\"%.2f\" will format 0.1234 to 0.12.\\n'},\n",
       "         'columns': {'type': 'string',\n",
       "          'description': 'sequence or list of str, optional. Columns to write.\\n'},\n",
       "         'header': {'type': 'string',\n",
       "          'description': 'bool or list of str, default True. Write out the column names. If a list of string is given it is\\nassumed to be aliases for the column names.\\n'},\n",
       "         'index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Write row names (index).\\n'},\n",
       "         'index_label': {'type': 'string',\n",
       "          'description': 'str or sequence, optional. Column label for index column(s) if desired. If not specified, and\\nheader and index are True, then the index names are used. A\\nsequence should be given if the DataFrame uses MultiIndex.\\n'},\n",
       "         'startrow': {'type': 'integer',\n",
       "          'description': 'int, default 0. Upper left cell row to dump data frame.\\n'},\n",
       "         'startcol': {'type': 'integer',\n",
       "          'description': 'int, default 0. Upper left cell column to dump data frame.\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': 'str, optional. Write engine to use, ‘openpyxl’ or ‘xlsxwriter’. You can also set this\\nvia the options io.excel.xlsx.writer or\\nio.excel.xlsm.writer.\\n'},\n",
       "         'merge_cells': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Write MultiIndex and Hierarchical Rows as merged cells.\\n'},\n",
       "         'inf_rep': {'type': 'string',\n",
       "          'description': 'str, default ‘inf’. Representation for infinity (there is no native representation for\\ninfinity in Excel).\\n'},\n",
       "         'freeze_panes': {'type': 'integer',\n",
       "          'description': 'tuple of int (length 2), optional. Specifies the one-based bottommost row and rightmost column that\\nis to be frozen.\\n'},\n",
       "         'storage_options': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "         'engine_kwargs': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Arbitrary keyword arguments passed to excel engine.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'ExcelWriter(path[,\\xa0engine,\\xa0date_format,\\xa0...])',\n",
       "      'func_desc': 'Class for writing DataFrame objects into excel sheets.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.ExcelWriter.html#pandas.ExcelWriter',\n",
       "      'function_definitions': {'function_name': 'pandas.ExcelWriter',\n",
       "       'full_function': \"class pandas.ExcelWriter(path, engine=None, date_format=None, datetime_format=None, mode='w', storage_options=None, if_sheet_exists=None, engine_kwargs=None)\",\n",
       "       'function_text': 'Class for writing DataFrame objects into excel sheets. Default is to use: xlsxwriter for xlsx files if xlsxwriter\\nis installed otherwise openpyxl odswriter for ods files See DataFrame.to_excel for typical usage. The writer should be used as a context manager. Otherwise, call close() to save\\nand close any opened file handles.',\n",
       "       'parameter_names_desc': [{'param_name': 'path',\n",
       "         'param_type': 'str or typing.BinaryIO',\n",
       "         'param_desc': 'Path to xls or xlsx or ods file.\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str (optional)',\n",
       "         'param_desc': 'Engine to use for writing. If None, defaults to\\nio.excel.<extension>.writer. NOTE: can only be passed as a keyword\\nargument.\\n'},\n",
       "        {'param_name': 'date_format',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'Format string for dates written into Excel files (e.g. ‘YYYY-MM-DD’).\\n'},\n",
       "        {'param_name': 'datetime_format',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'Format string for datetime objects written into Excel files.\\n(e.g. ‘YYYY-MM-DD HH:MM:SS’).\\n'},\n",
       "        {'param_name': 'mode',\n",
       "         'param_type': '{‘w’, ‘a’}, default ‘w’',\n",
       "         'param_desc': 'File mode to use (write or append). Append does not work with fsspec URLs.\\n'},\n",
       "        {'param_name': 'storage_options',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'},\n",
       "        {'param_name': 'if_sheet_exists',\n",
       "         'param_type': '{‘error’, ‘new’, ‘replace’, ‘overlay’}, default ‘error’',\n",
       "         'param_desc': 'How to behave when trying to write to a sheet that already\\nexists (append mode only).\\n\\nerror: raise a ValueError.\\nnew: Create a new sheet, with a name determined by the engine.\\nreplace: Delete the contents of the sheet before writing to it.\\noverlay: Write contents to the existing sheet without first removing,\\nbut possibly over top of, the existing contents.\\n\\n\\nNew in version 1.3.0.\\n\\n\\nChanged in version 1.4.0: Added overlay option\\n\\n'},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Keyword arguments to be passed into the engine. These will be passed to\\nthe following functions of the respective engines:\\n\\nxlsxwriter: xlsxwriter.Workbook(file, **engine_kwargs)\\nopenpyxl (write mode): openpyxl.Workbook(**engine_kwargs)\\nopenpyxl (append mode): openpyxl.load_workbook(file, **engine_kwargs)\\nodswriter: odf.opendocument.OpenDocumentSpreadsheet(**engine_kwargs)\\n\\n\\nNew in version 1.3.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.ExcelWriter',\n",
       "       'descriptions': 'Class for writing DataFrame objects into excel sheets. Default is to use: xlsxwriter for xlsx files if xlsxwriter\\nis installed otherwise openpyxl odswriter for ods files See DataFrame.to_excel for typical usage. The writer should be used as a context manager. Otherwise, call close() to save\\nand close any opened file handles.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'path': {'type': 'string',\n",
       "          'description': 'str or typing.BinaryIO. Path to xls or xlsx or ods file.\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': 'str (optional). Engine to use for writing. If None, defaults to\\nio.excel.<extension>.writer. NOTE: can only be passed as a keyword\\nargument.\\n'},\n",
       "         'date_format': {'type': 'string',\n",
       "          'description': 'str, default None. Format string for dates written into Excel files (e.g. ‘YYYY-MM-DD’).\\n'},\n",
       "         'datetime_format': {'type': 'string',\n",
       "          'description': 'str, default None. Format string for datetime objects written into Excel files.\\n(e.g. ‘YYYY-MM-DD HH:MM:SS’).\\n'},\n",
       "         'mode': {'type': 'string',\n",
       "          'enum': ['w', ' a'],\n",
       "          'description': '{‘w’, ‘a’}, default ‘w’. File mode to use (write or append). Append does not work with fsspec URLs.\\n'},\n",
       "         'storage_options': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'},\n",
       "         'if_sheet_exists': {'type': 'string',\n",
       "          'enum': ['error', ' new', ' replace', ' overlay'],\n",
       "          'description': '{‘error’, ‘new’, ‘replace’, ‘overlay’}, default ‘error’. How to behave when trying to write to a sheet that already\\nexists (append mode only).\\n\\nerror: raise a ValueError.\\nnew: Create a new sheet, with a name determined by the engine.\\nreplace: Delete the contents of the sheet before writing to it.\\noverlay: Write contents to the existing sheet without first removing,\\nbut possibly over top of, the existing contents.\\n\\n\\nNew in version 1.3.0.\\n\\n\\nChanged in version 1.4.0: Added overlay option\\n\\n'},\n",
       "         'engine_kwargs': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Keyword arguments to be passed into the engine. These will be passed to\\nthe following functions of the respective engines:\\n\\nxlsxwriter: xlsxwriter.Workbook(file, **engine_kwargs)\\nopenpyxl (write mode): openpyxl.Workbook(**engine_kwargs)\\nopenpyxl (append mode): openpyxl.load_workbook(file, **engine_kwargs)\\nodswriter: odf.opendocument.OpenDocumentSpreadsheet(**engine_kwargs)\\n\\n\\nNew in version 1.3.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.to_excel(excel_writer,\\xa0*[,\\xa0...])',\n",
       "      'func_desc': 'Write object to an Excel sheet.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_excel.html#pandas.DataFrame.to_excel',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_excel',\n",
       "       'full_function': \"DataFrame.to_excel(excel_writer, *, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, inf_rep='inf', freeze_panes=None, storage_options=None, engine_kwargs=None)\",\n",
       "       'function_text': 'Write object to an Excel sheet. To write a single object to an Excel .xlsx file it is only necessary to\\nspecify a target file name. To write to multiple sheets it is necessary to\\ncreate an ExcelWriter object with a target file name, and specify a sheet\\nin the file to write to. Multiple sheets may be written to by specifying unique sheet_name.\\nWith all data written to the file it is necessary to save the changes.\\nNote that creating an ExcelWriter object with a file name that already\\nexists will result in the contents of the existing file being erased.',\n",
       "       'parameter_names_desc': [{'param_name': 'excel_writer',\n",
       "         'param_type': 'path-like, file-like, or ExcelWriter object',\n",
       "         'param_desc': 'File path or existing ExcelWriter.\\n'},\n",
       "        {'param_name': 'sheet_name',\n",
       "         'param_type': 'str, default ‘Sheet1’',\n",
       "         'param_desc': 'Name of sheet which will contain DataFrame.\\n'},\n",
       "        {'param_name': 'na_rep',\n",
       "         'param_type': 'str, default ‘’',\n",
       "         'param_desc': 'Missing data representation.\\n'},\n",
       "        {'param_name': 'float_format',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Format string for floating point numbers. For example\\nfloat_format=\"%.2f\" will format 0.1234 to 0.12.\\n'},\n",
       "        {'param_name': 'columns',\n",
       "         'param_type': 'sequence or list of str, optional',\n",
       "         'param_desc': 'Columns to write.\\n'},\n",
       "        {'param_name': 'header',\n",
       "         'param_type': 'bool or list of str, default True',\n",
       "         'param_desc': 'Write out the column names. If a list of string is given it is\\nassumed to be aliases for the column names.\\n'},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Write row names (index).\\n'},\n",
       "        {'param_name': 'index_label',\n",
       "         'param_type': 'str or sequence, optional',\n",
       "         'param_desc': 'Column label for index column(s) if desired. If not specified, and\\nheader and index are True, then the index names are used. A\\nsequence should be given if the DataFrame uses MultiIndex.\\n'},\n",
       "        {'param_name': 'startrow',\n",
       "         'param_type': 'int, default 0',\n",
       "         'param_desc': 'Upper left cell row to dump data frame.\\n'},\n",
       "        {'param_name': 'startcol',\n",
       "         'param_type': 'int, default 0',\n",
       "         'param_desc': 'Upper left cell column to dump data frame.\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Write engine to use, ‘openpyxl’ or ‘xlsxwriter’. You can also set this\\nvia the options io.excel.xlsx.writer or\\nio.excel.xlsm.writer.\\n'},\n",
       "        {'param_name': 'merge_cells',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Write MultiIndex and Hierarchical Rows as merged cells.\\n'},\n",
       "        {'param_name': 'inf_rep',\n",
       "         'param_type': 'str, default ‘inf’',\n",
       "         'param_desc': 'Representation for infinity (there is no native representation for\\ninfinity in Excel).\\n'},\n",
       "        {'param_name': 'freeze_panes',\n",
       "         'param_type': 'tuple of int (length 2), optional',\n",
       "         'param_desc': 'Specifies the one-based bottommost row and rightmost column that\\nis to be frozen.\\n'},\n",
       "        {'param_name': 'storage_options',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n\\nNew in version 1.2.0.\\n\\n'},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Arbitrary keyword arguments passed to excel engine.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.to_excel',\n",
       "       'descriptions': 'Write object to an Excel sheet. To write a single object to an Excel .xlsx file it is only necessary to\\nspecify a target file name. To write to multiple sheets it is necessary to\\ncreate an ExcelWriter object with a target file name, and specify a sheet\\nin the file to write to. Multiple sheets may be written to by specifying unique sheet_name.\\nWith all data written to the file it is necessary to save the changes.\\nNote that creating an ExcelWriter object with a file name that already\\nexists will result in the contents of the existing file being erased.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'excel_writer': {'type': 'object',\n",
       "          'description': 'path-like, file-like, or ExcelWriter object. File path or existing ExcelWriter.\\n'},\n",
       "         'sheet_name': {'type': 'string',\n",
       "          'description': 'str, default ‘Sheet1’. Name of sheet which will contain DataFrame.\\n'},\n",
       "         'na_rep': {'type': 'string',\n",
       "          'description': 'str, default ‘’. Missing data representation.\\n'},\n",
       "         'float_format': {'type': 'string',\n",
       "          'description': 'str, optional. Format string for floating point numbers. For example\\nfloat_format=\"%.2f\" will format 0.1234 to 0.12.\\n'},\n",
       "         'columns': {'type': 'string',\n",
       "          'description': 'sequence or list of str, optional. Columns to write.\\n'},\n",
       "         'header': {'type': 'string',\n",
       "          'description': 'bool or list of str, default True. Write out the column names. If a list of string is given it is\\nassumed to be aliases for the column names.\\n'},\n",
       "         'index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Write row names (index).\\n'},\n",
       "         'index_label': {'type': 'string',\n",
       "          'description': 'str or sequence, optional. Column label for index column(s) if desired. If not specified, and\\nheader and index are True, then the index names are used. A\\nsequence should be given if the DataFrame uses MultiIndex.\\n'},\n",
       "         'startrow': {'type': 'integer',\n",
       "          'description': 'int, default 0. Upper left cell row to dump data frame.\\n'},\n",
       "         'startcol': {'type': 'integer',\n",
       "          'description': 'int, default 0. Upper left cell column to dump data frame.\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': 'str, optional. Write engine to use, ‘openpyxl’ or ‘xlsxwriter’. You can also set this\\nvia the options io.excel.xlsx.writer or\\nio.excel.xlsm.writer.\\n'},\n",
       "         'merge_cells': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Write MultiIndex and Hierarchical Rows as merged cells.\\n'},\n",
       "         'inf_rep': {'type': 'string',\n",
       "          'description': 'str, default ‘inf’. Representation for infinity (there is no native representation for\\ninfinity in Excel).\\n'},\n",
       "         'freeze_panes': {'type': 'integer',\n",
       "          'description': 'tuple of int (length 2), optional. Specifies the one-based bottommost row and rightmost column that\\nis to be frozen.\\n'},\n",
       "         'storage_options': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n\\nNew in version 1.2.0.\\n\\n'},\n",
       "         'engine_kwargs': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Arbitrary keyword arguments passed to excel engine.\\n'}},\n",
       "        'required': ['excel_writer']}}},\n",
       "     {'func_name': 'ExcelFile.book',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.ExcelFile.book.html#pandas.ExcelFile.book',\n",
       "      'function_definitions': {'function_name': 'pandas.ExcelFile.book',\n",
       "       'full_function': 'property ExcelFile.book',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'ExcelFile.parse([sheet_name,\\xa0header,\\xa0names,\\xa0...])',\n",
       "      'func_desc': 'Parse specified sheet(s) into a DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.ExcelFile.parse.html#pandas.ExcelFile.parse',\n",
       "      'function_definitions': {'function_name': 'pandas.ExcelFile.parse',\n",
       "       'full_function': 'ExcelFile.parse(sheet_name=0, header=0, names=None, index_col=None, usecols=None, converters=None, true_values=None, false_values=None, skiprows=None, nrows=None, na_values=None, parse_dates=False, date_parser=_NoDefault.no_default, date_format=None, thousands=None, comment=None, skipfooter=0, dtype_backend=_NoDefault.no_default, **kwds)',\n",
       "       'function_text': 'Parse specified sheet(s) into a DataFrame. Equivalent to read_excel(ExcelFile, …) See the read_excel\\ndocstring for more info on accepted parameters.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'JSON': [{'func_name': 'read_json(path_or_buf,\\xa0*[,\\xa0orient,\\xa0typ,\\xa0...])',\n",
       "      'func_desc': 'Convert a JSON string to pandas object.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.read_json.html#pandas.read_json',\n",
       "      'function_definitions': {'function_name': 'pandas.read_json',\n",
       "       'full_function': \"pandas.read_json(path_or_buf, *, orient=None, typ='frame', dtype=None, convert_axes=None, convert_dates=True, keep_default_dates=True, precise_float=False, date_unit=None, encoding=None, encoding_errors='strict', lines=False, chunksize=None, compression='infer', nrows=None, storage_options=None, dtype_backend=_NoDefault.no_default, engine='ujson')\",\n",
       "       'function_text': 'Convert a JSON string to pandas object.',\n",
       "       'parameter_names_desc': [{'param_name': 'path_or_buf',\n",
       "         'param_type': 'a valid JSON str, path object or file-like object',\n",
       "         'param_desc': 'Any valid string path is acceptable. The string could be a URL. Valid\\nURL schemes include http, ftp, s3, and file. For file URLs, a host is\\nexpected. A local file could be:\\nfile://localhost/path/to/table.json.\\nIf you want to pass in a path object, pandas accepts any\\nos.PathLike.\\nBy file-like object, we refer to objects with a read() method,\\nsuch as a file handle (e.g. via builtin open function)\\nor StringIO.\\n\\nDeprecated since version 2.1.0: Passing json literal strings is deprecated.\\n\\n'},\n",
       "        {'param_name': 'orient',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': \"Indication of expected JSON string format.\\nCompatible JSON strings can be produced by to_json() with a\\ncorresponding orient value.\\nThe set of possible orients is:\\n\\n'split' : dict like\\n{index -> [index], columns -> [columns], data -> [values]}\\n'records' : list like\\n[{column -> value}, ... , {column -> value}]\\n'index' : dict like {index -> {column -> value}}\\n'columns' : dict like {column -> {index -> value}}\\n'values' : just the values array\\n'table' : dict like {'schema': {schema}, 'data': {data}}\\n\\nThe allowed and default values depend on the value\\nof the typ parameter.\\n\\nwhen typ == 'series',\\n\\nallowed orients are {'split','records','index'}\\ndefault is 'index'\\nThe Series index must be unique for orient 'index'.\\n\\n\\nwhen typ == 'frame',\\n\\nallowed orients are {'split','records','index',\\n'columns','values', 'table'}\\ndefault is 'columns'\\nThe DataFrame index must be unique for orients 'index' and\\n'columns'.\\nThe DataFrame columns must be unique for orients 'index',\\n'columns', and 'records'.\\n\\n\\n\\n\"},\n",
       "        {'param_name': 'typ',\n",
       "         'param_type': '{‘frame’, ‘series’}, default ‘frame’',\n",
       "         'param_desc': 'The type of object to recover.\\n'},\n",
       "        {'param_name': 'dtype',\n",
       "         'param_type': 'bool or dict, default None',\n",
       "         'param_desc': \"If True, infer dtypes; if a dict of column to dtype, then use those;\\nif False, then don’t infer dtypes at all, applies only to the data.\\nFor all orient values except 'table', default is True.\\n\"},\n",
       "        {'param_name': 'convert_axes',\n",
       "         'param_type': 'bool, default None',\n",
       "         'param_desc': \"Try to convert the axes to the proper dtypes.\\nFor all orient values except 'table', default is True.\\n\"},\n",
       "        {'param_name': 'convert_dates',\n",
       "         'param_type': 'bool or list of str, default True',\n",
       "         'param_desc': 'If True then default datelike columns may be converted (depending on\\nkeep_default_dates).\\nIf False, no dates will be converted.\\nIf a list of column names, then those columns will be converted and\\ndefault datelike columns may also be converted (depending on\\nkeep_default_dates).\\n'},\n",
       "        {'param_name': 'keep_default_dates',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': \"If parsing dates (convert_dates is not False), then try to parse the\\ndefault datelike columns.\\nA column label is datelike if\\n\\nit ends with '_at',\\nit ends with '_time',\\nit begins with 'timestamp',\\nit is 'modified', or\\nit is 'date'.\\n\\n\"},\n",
       "        {'param_name': 'precise_float',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Set to enable usage of higher precision (strtod) function when\\ndecoding string to double values. Default (False) is to use fast but\\nless precise builtin functionality.\\n'},\n",
       "        {'param_name': 'date_unit',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'The timestamp unit to detect if converting dates. The default behaviour\\nis to try and detect the correct precision, but if this is not desired\\nthen pass one of ‘s’, ‘ms’, ‘us’ or ‘ns’ to force parsing only seconds,\\nmilliseconds, microseconds or nanoseconds respectively.\\n'},\n",
       "        {'param_name': 'encoding',\n",
       "         'param_type': 'str, default is ‘utf-8’',\n",
       "         'param_desc': 'The encoding to use to decode py3 bytes.\\n'},\n",
       "        {'param_name': 'encoding_errors',\n",
       "         'param_type': 'str, optional, default “strict”',\n",
       "         'param_desc': 'How encoding errors are treated. List of possible values .\\n\\nNew in version 1.3.0.\\n\\n'},\n",
       "        {'param_name': 'lines',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Read the file as a json object per line.\\n'},\n",
       "        {'param_name': 'chunksize',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Return JsonReader object for iteration.\\nSee the line-delimited json docs\\nfor more information on chunksize.\\nThis can only be passed if lines=True.\\nIf this is None, the file will be read into memory all at once.\\n'},\n",
       "        {'param_name': 'compression',\n",
       "         'param_type': 'str or dict, default ‘infer’',\n",
       "         'param_desc': \"For on-the-fly decompression of on-disk data. If ‘infer’ and ‘path_or_buf’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nIf using ‘zip’ or ‘tar’, the ZIP file must contain only one data file to be read in.\\nSet to None for no decompression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdDecompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for Zstandard decompression using a\\ncustom compression dictionary:\\ncompression={'method': 'zstd', 'dict_data': my_compression_dict}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\n\\n\\nChanged in version 1.4.0: Zstandard support.\\n\\n\"},\n",
       "        {'param_name': 'nrows',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'The number of lines from the line-delimited jsonfile that has to be read.\\nThis can only be passed if lines=True.\\nIf this is None, all the rows will be returned.\\n'},\n",
       "        {'param_name': 'storage_options',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'},\n",
       "        {'param_name': 'dtype_backend',\n",
       "         'param_type': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’',\n",
       "         'param_desc': 'Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': '{“ujson”, “pyarrow”}, default “ujson”',\n",
       "         'param_desc': 'Parser engine to use. The \"pyarrow\" engine is only available when\\nlines=True.\\n\\nNew in version 2.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.read_json',\n",
       "       'descriptions': 'Convert a JSON string to pandas object.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'path_or_buf': {'type': 'string',\n",
       "          'description': 'a valid JSON str, path object or file-like object. Any valid string path is acceptable. The string could be a URL. Valid\\nURL schemes include http, ftp, s3, and file. For file URLs, a host is\\nexpected. A local file could be:\\nfile://localhost/path/to/table.json.\\nIf you want to pass in a path object, pandas accepts any\\nos.PathLike.\\nBy file-like object, we refer to objects with a read() method,\\nsuch as a file handle (e.g. via builtin open function)\\nor StringIO.\\n\\nDeprecated since version 2.1.0: Passing json literal strings is deprecated.\\n\\n'},\n",
       "         'orient': {'type': 'string',\n",
       "          'description': \"str, optional. Indication of expected JSON string format.\\nCompatible JSON strings can be produced by to_json() with a\\ncorresponding orient value.\\nThe set of possible orients is:\\n\\n'split' : dict like\\n{index -> [index], columns -> [columns], data -> [values]}\\n'records' : list like\\n[{column -> value}, ... , {column -> value}]\\n'index' : dict like {index -> {column -> value}}\\n'columns' : dict like {column -> {index -> value}}\\n'values' : just the values array\\n'table' : dict like {'schema': {schema}, 'data': {data}}\\n\\nThe allowed and default values depend on the value\\nof the typ parameter.\\n\\nwhen typ == 'series',\\n\\nallowed orients are {'split','records','index'}\\ndefault is 'index'\\nThe Series index must be unique for orient 'index'.\\n\\n\\nwhen typ == 'frame',\\n\\nallowed orients are {'split','records','index',\\n'columns','values', 'table'}\\ndefault is 'columns'\\nThe DataFrame index must be unique for orients 'index' and\\n'columns'.\\nThe DataFrame columns must be unique for orients 'index',\\n'columns', and 'records'.\\n\\n\\n\\n\"},\n",
       "         'typ': {'type': 'string',\n",
       "          'enum': ['frame', ' series'],\n",
       "          'description': '{‘frame’, ‘series’}, default ‘frame’. The type of object to recover.\\n'},\n",
       "         'dtype': {'type': 'boolean',\n",
       "          'description': \"bool or dict, default None. If True, infer dtypes; if a dict of column to dtype, then use those;\\nif False, then don’t infer dtypes at all, applies only to the data.\\nFor all orient values except 'table', default is True.\\n\"},\n",
       "         'convert_axes': {'type': 'boolean',\n",
       "          'description': \"bool, default None. Try to convert the axes to the proper dtypes.\\nFor all orient values except 'table', default is True.\\n\"},\n",
       "         'convert_dates': {'type': 'string',\n",
       "          'description': 'bool or list of str, default True. If True then default datelike columns may be converted (depending on\\nkeep_default_dates).\\nIf False, no dates will be converted.\\nIf a list of column names, then those columns will be converted and\\ndefault datelike columns may also be converted (depending on\\nkeep_default_dates).\\n'},\n",
       "         'keep_default_dates': {'type': 'boolean',\n",
       "          'description': \"bool, default True. If parsing dates (convert_dates is not False), then try to parse the\\ndefault datelike columns.\\nA column label is datelike if\\n\\nit ends with '_at',\\nit ends with '_time',\\nit begins with 'timestamp',\\nit is 'modified', or\\nit is 'date'.\\n\\n\"},\n",
       "         'precise_float': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Set to enable usage of higher precision (strtod) function when\\ndecoding string to double values. Default (False) is to use fast but\\nless precise builtin functionality.\\n'},\n",
       "         'date_unit': {'type': 'string',\n",
       "          'description': 'str, default None. The timestamp unit to detect if converting dates. The default behaviour\\nis to try and detect the correct precision, but if this is not desired\\nthen pass one of ‘s’, ‘ms’, ‘us’ or ‘ns’ to force parsing only seconds,\\nmilliseconds, microseconds or nanoseconds respectively.\\n'},\n",
       "         'encoding': {'type': 'string',\n",
       "          'description': 'str, default is ‘utf-8’. The encoding to use to decode py3 bytes.\\n'},\n",
       "         'encoding_errors': {'type': 'string',\n",
       "          'description': 'str, optional, default “strict”. How encoding errors are treated. List of possible values .\\n\\nNew in version 1.3.0.\\n\\n'},\n",
       "         'lines': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Read the file as a json object per line.\\n'},\n",
       "         'chunksize': {'type': 'integer',\n",
       "          'description': 'int, optional. Return JsonReader object for iteration.\\nSee the line-delimited json docs\\nfor more information on chunksize.\\nThis can only be passed if lines=True.\\nIf this is None, the file will be read into memory all at once.\\n'},\n",
       "         'compression': {'type': 'string',\n",
       "          'description': \"str or dict, default ‘infer’. For on-the-fly decompression of on-disk data. If ‘infer’ and ‘path_or_buf’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nIf using ‘zip’ or ‘tar’, the ZIP file must contain only one data file to be read in.\\nSet to None for no decompression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdDecompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for Zstandard decompression using a\\ncustom compression dictionary:\\ncompression={'method': 'zstd', 'dict_data': my_compression_dict}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\n\\n\\nChanged in version 1.4.0: Zstandard support.\\n\\n\"},\n",
       "         'nrows': {'type': 'integer',\n",
       "          'description': 'int, optional. The number of lines from the line-delimited jsonfile that has to be read.\\nThis can only be passed if lines=True.\\nIf this is None, all the rows will be returned.\\n'},\n",
       "         'storage_options': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'},\n",
       "         'dtype_backend': {'type': 'string',\n",
       "          'enum': ['numpy_nullable', ' pyarrow'],\n",
       "          'description': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’. Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'},\n",
       "         'engine': {'type': '{“ujson”, “pyarrow”}, default “ujson”',\n",
       "          'description': '{“ujson”, “pyarrow”}, default “ujson”. Parser engine to use. The \"pyarrow\" engine is only available when\\nlines=True.\\n\\nNew in version 2.0.\\n\\n'}},\n",
       "        'required': ['path_or_buf']}}},\n",
       "     {'func_name': 'DataFrame.to_json([path_or_buf,\\xa0orient,\\xa0...])',\n",
       "      'func_desc': 'Convert the object to a JSON string.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_json.html#pandas.DataFrame.to_json',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_json',\n",
       "       'full_function': \"DataFrame.to_json(path_or_buf=None, *, orient=None, date_format=None, double_precision=10, force_ascii=True, date_unit='ms', default_handler=None, lines=False, compression='infer', index=None, indent=None, storage_options=None, mode='w')\",\n",
       "       'function_text': 'Convert the object to a JSON string. Note NaN’s and None will be converted to null and datetime objects\\nwill be converted to UNIX timestamps.',\n",
       "       'parameter_names_desc': [{'param_name': 'path_or_buf',\n",
       "         'param_type': 'str, path object, file-like object, or None, default None',\n",
       "         'param_desc': 'String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a write() function. If None, the result is\\nreturned as a string.\\n'},\n",
       "        {'param_name': 'orient',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': \"Indication of expected JSON string format.\\n\\nSeries:\\n\\n\\ndefault is ‘index’\\nallowed values are: {‘split’, ‘records’, ‘index’, ‘table’}.\\n\\n\\n\\nDataFrame:\\n\\n\\ndefault is ‘columns’\\nallowed values are: {‘split’, ‘records’, ‘index’, ‘columns’,\\n‘values’, ‘table’}.\\n\\n\\n\\nThe format of the JSON string:\\n\\n\\n‘split’ : dict like {‘index’ -> [index], ‘columns’ -> [columns],\\n‘data’ -> [values]}\\n‘records’ : list like [{column -> value}, … , {column -> value}]\\n‘index’ : dict like {index -> {column -> value}}\\n‘columns’ : dict like {column -> {index -> value}}\\n‘values’ : just the values array\\n‘table’ : dict like {‘schema’: {schema}, ‘data’: {data}}\\n\\nDescribing the data, where data component is like orient='records'.\\n\\n\\n\\n\"},\n",
       "        {'param_name': 'date_format',\n",
       "         'param_type': '{None, ‘epoch’, ‘iso’}',\n",
       "         'param_desc': \"Type of date conversion. ‘epoch’ = epoch milliseconds,\\n‘iso’ = ISO8601. The default depends on the orient. For\\norient='table', the default is ‘iso’. For all other orients,\\nthe default is ‘epoch’.\\n\"},\n",
       "        {'param_name': 'double_precision',\n",
       "         'param_type': 'int, default 10',\n",
       "         'param_desc': 'The number of decimal places to use when encoding\\nfloating point values. The possible maximal value is 15.\\nPassing double_precision greater than 15 will raise a ValueError.\\n'},\n",
       "        {'param_name': 'force_ascii',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Force encoded string to be ASCII.\\n'},\n",
       "        {'param_name': 'date_unit',\n",
       "         'param_type': 'str, default ‘ms’ (milliseconds)',\n",
       "         'param_desc': 'The time unit to encode to, governs timestamp and ISO8601\\nprecision. One of ‘s’, ‘ms’, ‘us’, ‘ns’ for second, millisecond,\\nmicrosecond, and nanosecond respectively.\\n'},\n",
       "        {'param_name': 'default_handler',\n",
       "         'param_type': 'callable, default None',\n",
       "         'param_desc': 'Handler to call if object cannot otherwise be converted to a\\nsuitable format for JSON. Should receive a single argument which is\\nthe object to convert and return a serialisable object.\\n'},\n",
       "        {'param_name': 'lines',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If ‘orient’ is ‘records’ write out line-delimited json format. Will\\nthrow ValueError if incorrect ‘orient’ since others are not\\nlist-like.\\n'},\n",
       "        {'param_name': 'compression',\n",
       "         'param_type': 'str or dict, default ‘infer’',\n",
       "         'param_desc': \"For on-the-fly compression of the output data. If ‘infer’ and ‘path_or_buf’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nSet to None for no compression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for faster compression and to create\\na reproducible gzip archive:\\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\n\\n\\nChanged in version 1.4.0: Zstandard support.\\n\\n\"},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'bool or None, default None',\n",
       "         'param_desc': 'The index is only used when ‘orient’ is ‘split’, ‘index’, ‘column’,\\nor ‘table’. Of these, ‘index’ and ‘column’ do not support\\nindex=False.\\n'},\n",
       "        {'param_name': 'indent',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Length of whitespace used to indent each record.\\n'},\n",
       "        {'param_name': 'storage_options',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'},\n",
       "        {'param_name': 'mode',\n",
       "         'param_type': 'str, default ‘w’ (writing)',\n",
       "         'param_desc': 'Specify the IO mode for output when supplying a path_or_buf.\\nAccepted args are ‘w’ (writing) and ‘a’ (append) only.\\nmode=’a’ is only supported when lines is True and orient is ‘records’.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.to_json',\n",
       "       'descriptions': 'Convert the object to a JSON string. Note NaN’s and None will be converted to null and datetime objects\\nwill be converted to UNIX timestamps.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'path_or_buf': {'type': 'string',\n",
       "          'description': 'str, path object, file-like object, or None, default None. String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a write() function. If None, the result is\\nreturned as a string.\\n'},\n",
       "         'orient': {'type': 'string',\n",
       "          'description': \"str. Indication of expected JSON string format.\\n\\nSeries:\\n\\n\\ndefault is ‘index’\\nallowed values are: {‘split’, ‘records’, ‘index’, ‘table’}.\\n\\n\\n\\nDataFrame:\\n\\n\\ndefault is ‘columns’\\nallowed values are: {‘split’, ‘records’, ‘index’, ‘columns’,\\n‘values’, ‘table’}.\\n\\n\\n\\nThe format of the JSON string:\\n\\n\\n‘split’ : dict like {‘index’ -> [index], ‘columns’ -> [columns],\\n‘data’ -> [values]}\\n‘records’ : list like [{column -> value}, … , {column -> value}]\\n‘index’ : dict like {index -> {column -> value}}\\n‘columns’ : dict like {column -> {index -> value}}\\n‘values’ : just the values array\\n‘table’ : dict like {‘schema’: {schema}, ‘data’: {data}}\\n\\nDescribing the data, where data component is like orient='records'.\\n\\n\\n\\n\"},\n",
       "         'date_format': {'type': 'string',\n",
       "          'enum': ['None', ' epoch', ' iso'],\n",
       "          'description': \"{None, ‘epoch’, ‘iso’}. Type of date conversion. ‘epoch’ = epoch milliseconds,\\n‘iso’ = ISO8601. The default depends on the orient. For\\norient='table', the default is ‘iso’. For all other orients,\\nthe default is ‘epoch’.\\n\"},\n",
       "         'double_precision': {'type': 'integer',\n",
       "          'description': 'int, default 10. The number of decimal places to use when encoding\\nfloating point values. The possible maximal value is 15.\\nPassing double_precision greater than 15 will raise a ValueError.\\n'},\n",
       "         'force_ascii': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Force encoded string to be ASCII.\\n'},\n",
       "         'date_unit': {'type': 'string',\n",
       "          'description': 'str, default ‘ms’ (milliseconds). The time unit to encode to, governs timestamp and ISO8601\\nprecision. One of ‘s’, ‘ms’, ‘us’, ‘ns’ for second, millisecond,\\nmicrosecond, and nanosecond respectively.\\n'},\n",
       "         'default_handler': {'type': 'object',\n",
       "          'description': 'callable, default None. Handler to call if object cannot otherwise be converted to a\\nsuitable format for JSON. Should receive a single argument which is\\nthe object to convert and return a serialisable object.\\n'},\n",
       "         'lines': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If ‘orient’ is ‘records’ write out line-delimited json format. Will\\nthrow ValueError if incorrect ‘orient’ since others are not\\nlist-like.\\n'},\n",
       "         'compression': {'type': 'string',\n",
       "          'description': \"str or dict, default ‘infer’. For on-the-fly compression of the output data. If ‘infer’ and ‘path_or_buf’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nSet to None for no compression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for faster compression and to create\\na reproducible gzip archive:\\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\n\\n\\nChanged in version 1.4.0: Zstandard support.\\n\\n\"},\n",
       "         'index': {'type': 'boolean',\n",
       "          'description': 'bool or None, default None. The index is only used when ‘orient’ is ‘split’, ‘index’, ‘column’,\\nor ‘table’. Of these, ‘index’ and ‘column’ do not support\\nindex=False.\\n'},\n",
       "         'indent': {'type': 'integer',\n",
       "          'description': 'int, optional. Length of whitespace used to indent each record.\\n'},\n",
       "         'storage_options': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'},\n",
       "         'mode': {'type': 'string',\n",
       "          'description': 'str, default ‘w’ (writing). Specify the IO mode for output when supplying a path_or_buf.\\nAccepted args are ‘w’ (writing) and ‘a’ (append) only.\\nmode=’a’ is only supported when lines is True and orient is ‘records’.\\n'}},\n",
       "        'required': ['path_or_buf=None']}}},\n",
       "     {'func_name': 'build_table_schema(data[,\\xa0index,\\xa0...])',\n",
       "      'func_desc': 'Create a Table schema from data.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.json.build_table_schema.html#pandas.io.json.build_table_schema',\n",
       "      'function_definitions': {'function_name': 'pandas.io.json.build_table_schema',\n",
       "       'full_function': 'pandas.io.json.build_table_schema(data, index=True, primary_key=None, version=True)',\n",
       "       'function_text': 'Create a Table schema from data.',\n",
       "       'parameter_names_desc': [{'param_name': 'data',\n",
       "         'param_type': 'Series, DataFrame',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to include data.index in the schema.\\n'},\n",
       "        {'param_name': 'primary_key',\n",
       "         'param_type': 'bool or None, default True',\n",
       "         'param_desc': 'Column names to designate as the primary key.\\nThe default None will set ‘primaryKey’ to the index\\nlevel or levels if the index is unique.\\n'},\n",
       "        {'param_name': 'version',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to include a field pandas_version with the version\\nof pandas that last revised the table schema. This version\\ncan be different from the installed pandas version.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.json.build_table_schema',\n",
       "       'descriptions': 'Create a Table schema from data.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'data': {'type': 'Series, DataFrame',\n",
       "          'description': 'Series, DataFrame. '},\n",
       "         'index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to include data.index in the schema.\\n'},\n",
       "         'primary_key': {'type': 'boolean',\n",
       "          'description': 'bool or None, default True. Column names to designate as the primary key.\\nThe default None will set ‘primaryKey’ to the index\\nlevel or levels if the index is unique.\\n'},\n",
       "         'version': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to include a field pandas_version with the version\\nof pandas that last revised the table schema. This version\\ncan be different from the installed pandas version.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'json_normalize(data[,\\xa0record_path,\\xa0meta,\\xa0...])',\n",
       "      'func_desc': 'Normalize semi-structured JSON data into a flat table.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.json_normalize.html#pandas.json_normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.json_normalize',\n",
       "       'full_function': \"pandas.json_normalize(data, record_path=None, meta=None, meta_prefix=None, record_prefix=None, errors='raise', sep='.', max_level=None)\",\n",
       "       'function_text': 'Normalize semi-structured JSON data into a flat table.',\n",
       "       'parameter_names_desc': [{'param_name': 'data',\n",
       "         'param_type': 'dict or list of dicts',\n",
       "         'param_desc': 'Unserialized JSON objects.\\n'},\n",
       "        {'param_name': 'record_path',\n",
       "         'param_type': 'str or list of str, default None',\n",
       "         'param_desc': 'Path in each object to list of records. If not passed, data will be\\nassumed to be an array of records.\\n'},\n",
       "        {'param_name': 'meta',\n",
       "         'param_type': 'list of paths (str or list of str), default None',\n",
       "         'param_desc': 'Fields to use as metadata for each record in resulting table.\\n'},\n",
       "        {'param_name': 'meta_prefix',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'If True, prefix records with dotted (?) path, e.g. foo.bar.field if\\nmeta is [‘foo’, ‘bar’].\\n'},\n",
       "        {'param_name': 'record_prefix',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'If True, prefix records with dotted (?) path, e.g. foo.bar.field if\\npath to records is [‘foo’, ‘bar’].\\n'},\n",
       "        {'param_name': 'errors',\n",
       "         'param_type': '{‘raise’, ‘ignore’}, default ‘raise’',\n",
       "         'param_desc': 'Configures error handling.\\n\\n‘ignore’ : will ignore KeyError if keys listed in meta are not\\nalways present.\\n‘raise’ : will raise KeyError if keys listed in meta are not\\nalways present.\\n\\n'},\n",
       "        {'param_name': 'sep',\n",
       "         'param_type': 'str, default ‘.’',\n",
       "         'param_desc': 'Nested records will generate names separated by sep.\\ne.g., for sep=’.’, {‘foo’: {‘bar’: 0}} -> foo.bar.\\n'},\n",
       "        {'param_name': 'max_level',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'Max number of levels(depth of dict) to normalize.\\nif None, normalizes all levels.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.json_normalize',\n",
       "       'descriptions': 'Normalize semi-structured JSON data into a flat table.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'data': {'type': 'array',\n",
       "          'description': 'dict or list of dicts. Unserialized JSON objects.\\n'},\n",
       "         'record_path': {'type': 'string',\n",
       "          'description': 'str or list of str, default None. Path in each object to list of records. If not passed, data will be\\nassumed to be an array of records.\\n'},\n",
       "         'meta': {'type': 'string',\n",
       "          'description': 'list of paths (str or list of str), default None. Fields to use as metadata for each record in resulting table.\\n'},\n",
       "         'meta_prefix': {'type': 'string',\n",
       "          'description': 'str, default None. If True, prefix records with dotted (?) path, e.g. foo.bar.field if\\nmeta is [‘foo’, ‘bar’].\\n'},\n",
       "         'record_prefix': {'type': 'string',\n",
       "          'description': 'str, default None. If True, prefix records with dotted (?) path, e.g. foo.bar.field if\\npath to records is [‘foo’, ‘bar’].\\n'},\n",
       "         'errors': {'type': 'string',\n",
       "          'enum': ['raise', ' ignore'],\n",
       "          'description': '{‘raise’, ‘ignore’}, default ‘raise’. Configures error handling.\\n\\n‘ignore’ : will ignore KeyError if keys listed in meta are not\\nalways present.\\n‘raise’ : will raise KeyError if keys listed in meta are not\\nalways present.\\n\\n'},\n",
       "         'sep': {'type': 'string',\n",
       "          'description': 'str, default ‘.’. Nested records will generate names separated by sep.\\ne.g., for sep=’.’, {‘foo’: {‘bar’: 0}} -> foo.bar.\\n'},\n",
       "         'max_level': {'type': 'integer',\n",
       "          'description': 'int, default None. Max number of levels(depth of dict) to normalize.\\nif None, normalizes all levels.\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'HTML': [{'func_name': 'read_html(io,\\xa0*[,\\xa0match,\\xa0flavor,\\xa0header,\\xa0...])',\n",
       "      'func_desc': 'Read HTML tables into a list of DataFrame objects.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.read_html.html#pandas.read_html',\n",
       "      'function_definitions': {'function_name': 'pandas.read_html',\n",
       "       'full_function': \"pandas.read_html(io, *, match='.+', flavor=None, header=None, index_col=None, skiprows=None, attrs=None, parse_dates=False, thousands=',', encoding=None, decimal='.', converters=None, na_values=None, keep_default_na=True, displayed_only=True, extract_links=None, dtype_backend=_NoDefault.no_default, storage_options=None)\",\n",
       "       'function_text': 'Read HTML tables into a list of DataFrame objects.',\n",
       "       'parameter_names_desc': [{'param_name': 'io',\n",
       "         'param_type': 'str, path object, or file-like object',\n",
       "         'param_desc': \"String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a string read() function.\\nThe string can represent a URL or the HTML itself. Note that\\nlxml only accepts the http, ftp and file url protocols. If you have a\\nURL that starts with 'https' you might try removing the 's'.\\n\\nDeprecated since version 2.1.0: Passing html literal strings is deprecated.\\nWrap literal string/bytes input in io.StringIO/io.BytesIO instead.\\n\\n\"},\n",
       "        {'param_name': 'match',\n",
       "         'param_type': 'str or compiled regular expression, optional',\n",
       "         'param_desc': 'The set of tables containing text matching this regex or string will be\\nreturned. Unless the HTML is extremely simple you will probably need to\\npass a non-empty string here. Defaults to ‘.+’ (match any non-empty\\nstring). The default value will return all tables contained on a page.\\nThis value is converted to a regular expression so that there is\\nconsistent behavior between Beautiful Soup and lxml.\\n'},\n",
       "        {'param_name': 'flavor',\n",
       "         'param_type': '{“lxml”, “html5lib”, “bs4”} or list-like, optional',\n",
       "         'param_desc': 'The parsing engine (or list of parsing engines) to use. ‘bs4’ and\\n‘html5lib’ are synonymous with each other, they are both there for\\nbackwards compatibility. The default of None tries to use lxml\\nto parse and if that fails it falls back on bs4 + html5lib.\\n'},\n",
       "        {'param_name': 'header',\n",
       "         'param_type': 'int or list-like, optional',\n",
       "         'param_desc': 'The row (or list of rows for a MultiIndex) to use to\\nmake the columns headers.\\n'},\n",
       "        {'param_name': 'index_col',\n",
       "         'param_type': 'int or list-like, optional',\n",
       "         'param_desc': 'The column (or list of columns) to use to create the index.\\n'},\n",
       "        {'param_name': 'skiprows',\n",
       "         'param_type': 'int, list-like or slice, optional',\n",
       "         'param_desc': 'Number of rows to skip after parsing the column integer. 0-based. If a\\nsequence of integers or a slice is given, will skip the rows indexed by\\nthat sequence. Note that a single element sequence means ‘skip the nth\\nrow’ whereas an integer means ‘skip n rows’.\\n'},\n",
       "        {'param_name': 'attrs',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': \"This is a dictionary of attributes that you can pass to use to identify\\nthe table in the HTML. These are not checked for validity before being\\npassed to lxml or Beautiful Soup. However, these attributes must be\\nvalid HTML table attributes to work correctly. For example,\\nattrs = {'id': 'table'}\\n\\n\\nis a valid attribute dictionary because the ‘id’ HTML tag attribute is\\na valid HTML attribute for any HTML tag as per this document.\\nattrs = {'asdf': 'table'}\\n\\n\\nis not a valid attribute dictionary because ‘asdf’ is not a valid\\nHTML attribute even if it is a valid XML attribute. Valid HTML 4.01\\ntable attributes can be found here. A\\nworking draft of the HTML 5 spec can be found here. It contains the\\nlatest information on table attributes for the modern web.\\n\"},\n",
       "        {'param_name': 'parse_dates',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'See read_csv() for more details.\\n'},\n",
       "        {'param_name': 'thousands',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': \"Separator to use to parse thousands. Defaults to ','.\\n\"},\n",
       "        {'param_name': 'encoding',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'The encoding used to decode the web page. Defaults to None.``None``\\npreserves the previous encoding behavior, which depends on the\\nunderlying parser library (e.g., the parser library will try to use\\nthe encoding provided by the document).\\n'},\n",
       "        {'param_name': 'decimal',\n",
       "         'param_type': 'str, default ‘.’',\n",
       "         'param_desc': 'Character to recognize as decimal point (e.g. use ‘,’ for European\\ndata).\\n'},\n",
       "        {'param_name': 'converters',\n",
       "         'param_type': 'dict, default None',\n",
       "         'param_desc': 'Dict of functions for converting values in certain columns. Keys can\\neither be integers or column labels, values are functions that take one\\ninput argument, the cell (not column) content, and return the\\ntransformed content.\\n'},\n",
       "        {'param_name': 'na_values',\n",
       "         'param_type': 'iterable, default None',\n",
       "         'param_desc': 'Custom NA values.\\n'},\n",
       "        {'param_name': 'keep_default_na',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If na_values are specified and keep_default_na is False the default NaN\\nvalues are overridden, otherwise they’re appended to.\\n'},\n",
       "        {'param_name': 'displayed_only',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether elements with “display: none” should be parsed.\\n'},\n",
       "        {'param_name': 'extract_links',\n",
       "         'param_type': '{None, “all”, “header”, “body”, “footer”}',\n",
       "         'param_desc': 'Table elements in the specified section(s) with <a> tags will have their\\nhref extracted.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "        {'param_name': 'dtype_backend',\n",
       "         'param_type': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’',\n",
       "         'param_desc': 'Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'},\n",
       "        {'param_name': 'storage_options',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n\\nNew in version 2.1.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.read_html',\n",
       "       'descriptions': 'Read HTML tables into a list of DataFrame objects.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'io': {'type': 'string',\n",
       "          'description': \"str, path object, or file-like object. String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a string read() function.\\nThe string can represent a URL or the HTML itself. Note that\\nlxml only accepts the http, ftp and file url protocols. If you have a\\nURL that starts with 'https' you might try removing the 's'.\\n\\nDeprecated since version 2.1.0: Passing html literal strings is deprecated.\\nWrap literal string/bytes input in io.StringIO/io.BytesIO instead.\\n\\n\"},\n",
       "         'match': {'type': 'string',\n",
       "          'description': 'str or compiled regular expression, optional. The set of tables containing text matching this regex or string will be\\nreturned. Unless the HTML is extremely simple you will probably need to\\npass a non-empty string here. Defaults to ‘.+’ (match any non-empty\\nstring). The default value will return all tables contained on a page.\\nThis value is converted to a regular expression so that there is\\nconsistent behavior between Beautiful Soup and lxml.\\n'},\n",
       "         'flavor': {'type': 'array',\n",
       "          'description': '{“lxml”, “html5lib”, “bs4”} or list-like, optional. The parsing engine (or list of parsing engines) to use. ‘bs4’ and\\n‘html5lib’ are synonymous with each other, they are both there for\\nbackwards compatibility. The default of None tries to use lxml\\nto parse and if that fails it falls back on bs4 + html5lib.\\n'},\n",
       "         'header': {'type': 'integer',\n",
       "          'description': 'int or list-like, optional. The row (or list of rows for a MultiIndex) to use to\\nmake the columns headers.\\n'},\n",
       "         'index_col': {'type': 'integer',\n",
       "          'description': 'int or list-like, optional. The column (or list of columns) to use to create the index.\\n'},\n",
       "         'skiprows': {'type': 'integer',\n",
       "          'description': 'int, list-like or slice, optional. Number of rows to skip after parsing the column integer. 0-based. If a\\nsequence of integers or a slice is given, will skip the rows indexed by\\nthat sequence. Note that a single element sequence means ‘skip the nth\\nrow’ whereas an integer means ‘skip n rows’.\\n'},\n",
       "         'attrs': {'type': 'dict, optional',\n",
       "          'description': \"dict, optional. This is a dictionary of attributes that you can pass to use to identify\\nthe table in the HTML. These are not checked for validity before being\\npassed to lxml or Beautiful Soup. However, these attributes must be\\nvalid HTML table attributes to work correctly. For example,\\nattrs = {'id': 'table'}\\n\\n\\nis a valid attribute dictionary because the ‘id’ HTML tag attribute is\\na valid HTML attribute for any HTML tag as per this document.\\nattrs = {'asdf': 'table'}\\n\\n\\nis not a valid attribute dictionary because ‘asdf’ is not a valid\\nHTML attribute even if it is a valid XML attribute. Valid HTML 4.01\\ntable attributes can be found here. A\\nworking draft of the HTML 5 spec can be found here. It contains the\\nlatest information on table attributes for the modern web.\\n\"},\n",
       "         'parse_dates': {'type': 'boolean',\n",
       "          'description': 'bool, optional. See read_csv() for more details.\\n'},\n",
       "         'thousands': {'type': 'string',\n",
       "          'description': \"str, optional. Separator to use to parse thousands. Defaults to ','.\\n\"},\n",
       "         'encoding': {'type': 'string',\n",
       "          'description': 'str, optional. The encoding used to decode the web page. Defaults to None.``None``\\npreserves the previous encoding behavior, which depends on the\\nunderlying parser library (e.g., the parser library will try to use\\nthe encoding provided by the document).\\n'},\n",
       "         'decimal': {'type': 'string',\n",
       "          'description': 'str, default ‘.’. Character to recognize as decimal point (e.g. use ‘,’ for European\\ndata).\\n'},\n",
       "         'converters': {'type': 'dict, default None',\n",
       "          'description': 'dict, default None. Dict of functions for converting values in certain columns. Keys can\\neither be integers or column labels, values are functions that take one\\ninput argument, the cell (not column) content, and return the\\ntransformed content.\\n'},\n",
       "         'na_values': {'type': 'iterable, default None',\n",
       "          'description': 'iterable, default None. Custom NA values.\\n'},\n",
       "         'keep_default_na': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If na_values are specified and keep_default_na is False the default NaN\\nvalues are overridden, otherwise they’re appended to.\\n'},\n",
       "         'displayed_only': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether elements with “display: none” should be parsed.\\n'},\n",
       "         'extract_links': {'type': '{None, “all”, “header”, “body”, “footer”}',\n",
       "          'description': '{None, “all”, “header”, “body”, “footer”}. Table elements in the specified section(s) with <a> tags will have their\\nhref extracted.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "         'dtype_backend': {'type': 'string',\n",
       "          'enum': ['numpy_nullable', ' pyarrow'],\n",
       "          'description': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’. Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'},\n",
       "         'storage_options': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n\\nNew in version 2.1.0.\\n\\n'}},\n",
       "        'required': ['io']}}},\n",
       "     {'func_name': 'Styler.to_html([buf,\\xa0table_uuid,\\xa0...])',\n",
       "      'func_desc': 'Write Styler to a file, buffer or string in HTML-CSS format.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_html.html#pandas.io.formats.style.Styler.to_html',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.to_html',\n",
       "       'full_function': 'Styler.to_html(buf=None, *, table_uuid=None, table_attributes=None, sparse_index=None, sparse_columns=None, bold_headers=False, caption=None, max_rows=None, max_columns=None, encoding=None, doctype_html=False, exclude_styles=False, **kwargs)',\n",
       "       'function_text': 'Write Styler to a file, buffer or string in HTML-CSS format. New in version 1.3.0.',\n",
       "       'parameter_names_desc': [{'param_name': 'buf',\n",
       "         'param_type': 'str, path object, file-like object, optional',\n",
       "         'param_desc': 'String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a string write() function. If None, the result is\\nreturned as a string.\\n'},\n",
       "        {'param_name': 'table_uuid',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Id attribute assigned to the <table> HTML element in the format:\\n<table id=\"T_<table_uuid>\" ..>\\nIf not given uses Styler’s initially assigned value.\\n'},\n",
       "        {'param_name': 'table_attributes',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Attributes to assign within the <table> HTML element in the format:\\n<table .. <table_attributes> >\\nIf not given defaults to Styler’s preexisting value.\\n'},\n",
       "        {'param_name': 'sparse_index',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'Whether to sparsify the display of a hierarchical index. Setting to False\\nwill display each explicit level element in a hierarchical key for each row.\\nDefaults to pandas.options.styler.sparse.index value.\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "        {'param_name': 'sparse_columns',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'Whether to sparsify the display of a hierarchical index. Setting to False\\nwill display each explicit level element in a hierarchical key for each\\ncolumn. Defaults to pandas.options.styler.sparse.columns value.\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "        {'param_name': 'bold_headers',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'Adds “font-weight: bold;” as a CSS property to table style header cells.\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "        {'param_name': 'caption',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Set, or overwrite, the caption on Styler before rendering.\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "        {'param_name': 'max_rows',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'The maximum number of rows that will be rendered. Defaults to\\npandas.options.styler.render.max_rows/max_columns.\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "        {'param_name': 'max_columns',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'The maximum number of columns that will be rendered. Defaults to\\npandas.options.styler.render.max_columns, which is None.\\nRows and columns may be reduced if the number of total elements is\\nlarge. This value is set to pandas.options.styler.render.max_elements,\\nwhich is 262144 (18 bit browser rendering).\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "        {'param_name': 'encoding',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Character encoding setting for file output (and meta tags if available).\\nDefaults to pandas.options.styler.render.encoding value of “utf-8”.\\n'},\n",
       "        {'param_name': 'doctype_html',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to output a fully structured HTML file including all\\nHTML elements, or just the core <style> and <table> elements.\\n'},\n",
       "        {'param_name': 'exclude_styles',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to include the <style> element and all associated element\\nclass and id identifiers, or solely the <table> element without\\nstyling identifiers.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.to_html',\n",
       "       'descriptions': 'Write Styler to a file, buffer or string in HTML-CSS format. New in version 1.3.0.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'buf': {'type': 'string',\n",
       "          'description': 'str, path object, file-like object, optional. String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a string write() function. If None, the result is\\nreturned as a string.\\n'},\n",
       "         'table_uuid': {'type': 'string',\n",
       "          'description': 'str, optional. Id attribute assigned to the <table> HTML element in the format:\\n<table id=\"T_<table_uuid>\" ..>\\nIf not given uses Styler’s initially assigned value.\\n'},\n",
       "         'table_attributes': {'type': 'string',\n",
       "          'description': 'str, optional. Attributes to assign within the <table> HTML element in the format:\\n<table .. <table_attributes> >\\nIf not given defaults to Styler’s preexisting value.\\n'},\n",
       "         'sparse_index': {'type': 'boolean',\n",
       "          'description': 'bool, optional. Whether to sparsify the display of a hierarchical index. Setting to False\\nwill display each explicit level element in a hierarchical key for each row.\\nDefaults to pandas.options.styler.sparse.index value.\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "         'sparse_columns': {'type': 'boolean',\n",
       "          'description': 'bool, optional. Whether to sparsify the display of a hierarchical index. Setting to False\\nwill display each explicit level element in a hierarchical key for each\\ncolumn. Defaults to pandas.options.styler.sparse.columns value.\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "         'bold_headers': {'type': 'boolean',\n",
       "          'description': 'bool, optional. Adds “font-weight: bold;” as a CSS property to table style header cells.\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "         'caption': {'type': 'string',\n",
       "          'description': 'str, optional. Set, or overwrite, the caption on Styler before rendering.\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "         'max_rows': {'type': 'integer',\n",
       "          'description': 'int, optional. The maximum number of rows that will be rendered. Defaults to\\npandas.options.styler.render.max_rows/max_columns.\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "         'max_columns': {'type': 'integer',\n",
       "          'description': 'int, optional. The maximum number of columns that will be rendered. Defaults to\\npandas.options.styler.render.max_columns, which is None.\\nRows and columns may be reduced if the number of total elements is\\nlarge. This value is set to pandas.options.styler.render.max_elements,\\nwhich is 262144 (18 bit browser rendering).\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "         'encoding': {'type': 'string',\n",
       "          'description': 'str, optional. Character encoding setting for file output (and meta tags if available).\\nDefaults to pandas.options.styler.render.encoding value of “utf-8”.\\n'},\n",
       "         'doctype_html': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to output a fully structured HTML file including all\\nHTML elements, or just the core <style> and <table> elements.\\n'},\n",
       "         'exclude_styles': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to include the <style> element and all associated element\\nclass and id identifiers, or solely the <table> element without\\nstyling identifiers.\\n'}},\n",
       "        'required': ['buf=None']}}},\n",
       "     {'func_name': 'DataFrame.to_html([buf,\\xa0columns,\\xa0col_space,\\xa0...])',\n",
       "      'func_desc': 'Render a DataFrame as an HTML table.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_html.html#pandas.DataFrame.to_html',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_html',\n",
       "       'full_function': \"DataFrame.to_html(buf=None, *, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, justify=None, max_rows=None, max_cols=None, show_dimensions=False, decimal='.', bold_rows=True, classes=None, escape=True, notebook=False, border=None, table_id=None, render_links=False, encoding=None)\",\n",
       "       'function_text': 'Render a DataFrame as an HTML table.',\n",
       "       'parameter_names_desc': [{'param_name': 'buf',\n",
       "         'param_type': 'str, Path or StringIO-like, optional, default None',\n",
       "         'param_desc': 'Buffer to write to. If None, the output is returned as a string.\\n'},\n",
       "        {'param_name': 'columns',\n",
       "         'param_type': 'array-like, optional, default None',\n",
       "         'param_desc': 'The subset of columns to write. Writes all columns by default.\\n'},\n",
       "        {'param_name': 'col_space',\n",
       "         'param_type': 'str or int, list or dict of int or str, optional',\n",
       "         'param_desc': 'The minimum width of each column in CSS length units. An int is assumed to be px units..\\n'},\n",
       "        {'param_name': 'header',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'Whether to print column labels, default True.\\n'},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'bool, optional, default True',\n",
       "         'param_desc': 'Whether to print index (row) labels.\\n'},\n",
       "        {'param_name': 'na_rep',\n",
       "         'param_type': 'str, optional, default ‘NaN’',\n",
       "         'param_desc': 'String representation of NaN to use.\\n'},\n",
       "        {'param_name': 'formatters',\n",
       "         'param_type': 'list, tuple or dict of one-param. functions, optional',\n",
       "         'param_desc': 'Formatter functions to apply to columns’ elements by position or\\nname.\\nThe result of each function must be a unicode string.\\nList/tuple must be of length equal to the number of columns.\\n'},\n",
       "        {'param_name': 'float_format',\n",
       "         'param_type': 'one-parameter function, optional, default None',\n",
       "         'param_desc': 'Formatter function to apply to columns’ elements if they are\\nfloats. This function must return a unicode string and will be\\napplied only to the non-NaN elements, with NaN being\\nhandled by na_rep.\\n'},\n",
       "        {'param_name': 'sparsify',\n",
       "         'param_type': 'bool, optional, default True',\n",
       "         'param_desc': 'Set to False for a DataFrame with a hierarchical index to print\\nevery multiindex key at each row.\\n'},\n",
       "        {'param_name': 'index_names',\n",
       "         'param_type': 'bool, optional, default True',\n",
       "         'param_desc': 'Prints the names of the indexes.\\n'},\n",
       "        {'param_name': 'justify',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'How to justify the column labels. If None uses the option from\\nthe print configuration (controlled by set_option), ‘right’ out\\nof the box. Valid values are\\n\\nleft\\nright\\ncenter\\njustify\\njustify-all\\nstart\\nend\\ninherit\\nmatch-parent\\ninitial\\nunset.\\n\\n'},\n",
       "        {'param_name': 'max_rows',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Maximum number of rows to display in the console.\\n'},\n",
       "        {'param_name': 'max_cols',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Maximum number of columns to display in the console.\\n'},\n",
       "        {'param_name': 'show_dimensions',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Display DataFrame dimensions (number of rows by number of columns).\\n'},\n",
       "        {'param_name': 'decimal',\n",
       "         'param_type': 'str, default ‘.’',\n",
       "         'param_desc': 'Character recognized as decimal separator, e.g. ‘,’ in Europe.\\n'},\n",
       "        {'param_name': 'bold_rows',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Make the row labels bold in the output.\\n'},\n",
       "        {'param_name': 'classes',\n",
       "         'param_type': 'str or list or tuple, default None',\n",
       "         'param_desc': 'CSS class(es) to apply to the resulting html table.\\n'},\n",
       "        {'param_name': 'escape',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Convert the characters <, >, and & to HTML-safe sequences.\\n'},\n",
       "        {'param_name': 'notebook',\n",
       "         'param_type': '{True, False}, default False',\n",
       "         'param_desc': 'Whether the generated HTML is for IPython Notebook.\\n'},\n",
       "        {'param_name': 'border',\n",
       "         'param_type': 'int',\n",
       "         'param_desc': 'A border=border attribute is included in the opening\\n<table> tag. Default pd.options.display.html.border.\\n'},\n",
       "        {'param_name': 'table_id',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'A css id is included in the opening <table> tag if specified.\\n'},\n",
       "        {'param_name': 'render_links',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Convert URLs to HTML links.\\n'},\n",
       "        {'param_name': 'encoding',\n",
       "         'param_type': 'str, default “utf-8”',\n",
       "         'param_desc': 'Set character encoding.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.to_html',\n",
       "       'descriptions': 'Render a DataFrame as an HTML table.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'buf': {'type': 'string',\n",
       "          'description': 'str, Path or StringIO-like, optional, default None. Buffer to write to. If None, the output is returned as a string.\\n'},\n",
       "         'columns': {'type': 'array',\n",
       "          'description': 'array-like, optional, default None. The subset of columns to write. Writes all columns by default.\\n'},\n",
       "         'col_space': {'type': 'integer',\n",
       "          'description': 'str or int, list or dict of int or str, optional. The minimum width of each column in CSS length units. An int is assumed to be px units..\\n'},\n",
       "         'header': {'type': 'boolean',\n",
       "          'description': 'bool, optional. Whether to print column labels, default True.\\n'},\n",
       "         'index': {'type': 'boolean',\n",
       "          'description': 'bool, optional, default True. Whether to print index (row) labels.\\n'},\n",
       "         'na_rep': {'type': 'string',\n",
       "          'description': 'str, optional, default ‘NaN’. String representation of NaN to use.\\n'},\n",
       "         'formatters': {'type': 'array',\n",
       "          'description': 'list, tuple or dict of one-param. functions, optional. Formatter functions to apply to columns’ elements by position or\\nname.\\nThe result of each function must be a unicode string.\\nList/tuple must be of length equal to the number of columns.\\n'},\n",
       "         'float_format': {'type': 'one-parameter function, optional, default None',\n",
       "          'description': 'one-parameter function, optional, default None. Formatter function to apply to columns’ elements if they are\\nfloats. This function must return a unicode string and will be\\napplied only to the non-NaN elements, with NaN being\\nhandled by na_rep.\\n'},\n",
       "         'sparsify': {'type': 'boolean',\n",
       "          'description': 'bool, optional, default True. Set to False for a DataFrame with a hierarchical index to print\\nevery multiindex key at each row.\\n'},\n",
       "         'index_names': {'type': 'boolean',\n",
       "          'description': 'bool, optional, default True. Prints the names of the indexes.\\n'},\n",
       "         'justify': {'type': 'string',\n",
       "          'description': 'str, default None. How to justify the column labels. If None uses the option from\\nthe print configuration (controlled by set_option), ‘right’ out\\nof the box. Valid values are\\n\\nleft\\nright\\ncenter\\njustify\\njustify-all\\nstart\\nend\\ninherit\\nmatch-parent\\ninitial\\nunset.\\n\\n'},\n",
       "         'max_rows': {'type': 'integer',\n",
       "          'description': 'int, optional. Maximum number of rows to display in the console.\\n'},\n",
       "         'max_cols': {'type': 'integer',\n",
       "          'description': 'int, optional. Maximum number of columns to display in the console.\\n'},\n",
       "         'show_dimensions': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Display DataFrame dimensions (number of rows by number of columns).\\n'},\n",
       "         'decimal': {'type': 'string',\n",
       "          'description': 'str, default ‘.’. Character recognized as decimal separator, e.g. ‘,’ in Europe.\\n'},\n",
       "         'bold_rows': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Make the row labels bold in the output.\\n'},\n",
       "         'classes': {'type': 'string',\n",
       "          'description': 'str or list or tuple, default None. CSS class(es) to apply to the resulting html table.\\n'},\n",
       "         'escape': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Convert the characters <, >, and & to HTML-safe sequences.\\n'},\n",
       "         'notebook': {'type': '{True, False}, default False',\n",
       "          'description': '{True, False}, default False. Whether the generated HTML is for IPython Notebook.\\n'},\n",
       "         'border': {'type': 'integer',\n",
       "          'description': 'int. A border=border attribute is included in the opening\\n<table> tag. Default pd.options.display.html.border.\\n'},\n",
       "         'table_id': {'type': 'string',\n",
       "          'description': 'str, optional. A css id is included in the opening <table> tag if specified.\\n'},\n",
       "         'render_links': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Convert URLs to HTML links.\\n'},\n",
       "         'encoding': {'type': 'string',\n",
       "          'description': 'str, default “utf-8”. Set character encoding.\\n'}},\n",
       "        'required': ['buf=None']}}}]},\n",
       "   {'XML': [{'func_name': 'read_xml(path_or_buffer,\\xa0*[,\\xa0xpath,\\xa0...])',\n",
       "      'func_desc': 'Read XML document into a DataFrame object.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.read_xml.html#pandas.read_xml',\n",
       "      'function_definitions': {'function_name': 'pandas.read_xml',\n",
       "       'full_function': \"pandas.read_xml(path_or_buffer, *, xpath='./*', namespaces=None, elems_only=False, attrs_only=False, names=None, dtype=None, converters=None, parse_dates=None, encoding='utf-8', parser='lxml', stylesheet=None, iterparse=None, compression='infer', storage_options=None, dtype_backend=_NoDefault.no_default)\",\n",
       "       'function_text': 'Read XML document into a DataFrame object. New in version 1.3.0.',\n",
       "       'parameter_names_desc': [{'param_name': 'path_or_buffer',\n",
       "         'param_type': 'str, path object, or file-like object',\n",
       "         'param_desc': 'String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a read() function. The string can be any valid XML\\nstring or a path. The string can further be a URL. Valid URL schemes\\ninclude http, ftp, s3, and file.\\n\\nDeprecated since version 2.1.0: Passing xml literal strings is deprecated.\\nWrap literal xml input in io.StringIO or io.BytesIO instead.\\n\\n'},\n",
       "        {'param_name': 'xpath',\n",
       "         'param_type': 'str, optional, default ‘./*’',\n",
       "         'param_desc': 'The XPath to parse required set of nodes for migration to\\nDataFrame.``XPath`` should return a collection of elements\\nand not a single element. Note: The etree parser supports limited XPath\\nexpressions. For more complex XPath, use lxml which requires\\ninstallation.\\n'},\n",
       "        {'param_name': 'namespaces',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'The namespaces defined in XML document as dicts with key being\\nnamespace prefix and value the URI. There is no need to include all\\nnamespaces in XML, only the ones used in xpath expression.\\nNote: if XML document uses default namespace denoted as\\nxmlns=’<URI>’ without a prefix, you must assign any temporary\\nnamespace prefix such as ‘doc’ to the URI in order to parse\\nunderlying nodes and/or attributes. For example,\\nnamespaces = {\"doc\": \"https://example.com\"}\\n\\n\\n'},\n",
       "        {'param_name': 'elems_only',\n",
       "         'param_type': 'bool, optional, default False',\n",
       "         'param_desc': 'Parse only the child elements at the specified xpath. By default,\\nall child elements and non-empty text nodes are returned.\\n'},\n",
       "        {'param_name': 'attrs_only',\n",
       "         'param_type': 'bool, optional, default False',\n",
       "         'param_desc': 'Parse only the attributes at the specified xpath.\\nBy default, all attributes are returned.\\n'},\n",
       "        {'param_name': 'names',\n",
       "         'param_type': 'list-like, optional',\n",
       "         'param_desc': 'Column names for DataFrame of parsed XML data. Use this parameter to\\nrename original element names and distinguish same named elements and\\nattributes.\\n'},\n",
       "        {'param_name': 'dtype',\n",
       "         'param_type': 'Type name or dict of column -> type, optional',\n",
       "         'param_desc': 'Data type for data or columns. E.g. {‘a’: np.float64, ‘b’: np.int32,\\n‘c’: ‘Int64’}\\nUse str or object together with suitable na_values settings\\nto preserve and not interpret dtype.\\nIf converters are specified, they will be applied INSTEAD\\nof dtype conversion.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "        {'param_name': 'converters',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Dict of functions for converting values in certain columns. Keys can either\\nbe integers or column labels.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "        {'param_name': 'parse_dates',\n",
       "         'param_type': 'bool or list of int or names or list of lists or dict, default False',\n",
       "         'param_desc': 'Identifiers to parse index or columns to datetime. The behavior is as follows:\\n\\nboolean. If True -> try parsing the index.\\nlist of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\\neach as a separate date column.\\nlist of lists. e.g. If [[1, 3]] -> combine columns 1 and 3 and parse as\\na single date column.\\ndict, e.g. {‘foo’ : [1, 3]} -> parse columns 1, 3 as date and call\\nresult ‘foo’\\n\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "        {'param_name': 'encoding',\n",
       "         'param_type': 'str, optional, default ‘utf-8’',\n",
       "         'param_desc': 'Encoding of XML document.\\n'},\n",
       "        {'param_name': 'parser',\n",
       "         'param_type': '{‘lxml’,’etree’}, default ‘lxml’',\n",
       "         'param_desc': 'Parser module to use for retrieval of data. Only ‘lxml’ and\\n‘etree’ are supported. With ‘lxml’ more complex XPath searches\\nand ability to use XSLT stylesheet are supported.\\n'},\n",
       "        {'param_name': 'stylesheet',\n",
       "         'param_type': 'str, path object or file-like object',\n",
       "         'param_desc': 'A URL, file-like object, or a raw string containing an XSLT script.\\nThis stylesheet should flatten complex, deeply nested XML documents\\nfor easier parsing. To use this feature you must have lxml module\\ninstalled and specify ‘lxml’ as parser. The xpath must\\nreference nodes of transformed XML document generated after XSLT\\ntransformation and not the original XML document. Only XSLT 1.0\\nscripts and not later versions is currently supported.\\n'},\n",
       "        {'param_name': 'iterparse',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'The nodes or attributes to retrieve in iterparsing of XML document\\nas a dict with key being the name of repeating element and value being\\nlist of elements or attribute names that are descendants of the repeated\\nelement. Note: If this option is used, it will replace xpath parsing\\nand unlike xpath, descendants do not need to relate to each other but can\\nexist any where in document under the repeating element. This memory-\\nefficient method should be used for very large XML files (500MB, 1GB, or 5GB+).\\nFor example,\\niterparse = {\"row_element\": [\"child_elem\", \"attr\", \"grandchild_elem\"]}\\n\\n\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "        {'param_name': 'compression',\n",
       "         'param_type': 'str or dict, default ‘infer’',\n",
       "         'param_desc': \"For on-the-fly decompression of on-disk data. If ‘infer’ and ‘path_or_buffer’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nIf using ‘zip’ or ‘tar’, the ZIP file must contain only one data file to be read in.\\nSet to None for no decompression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdDecompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for Zstandard decompression using a\\ncustom compression dictionary:\\ncompression={'method': 'zstd', 'dict_data': my_compression_dict}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\n\\n\\nChanged in version 1.4.0: Zstandard support.\\n\\n\"},\n",
       "        {'param_name': 'storage_options',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'},\n",
       "        {'param_name': 'dtype_backend',\n",
       "         'param_type': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’',\n",
       "         'param_desc': 'Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.read_xml',\n",
       "       'descriptions': 'Read XML document into a DataFrame object. New in version 1.3.0.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'path_or_buffer': {'type': 'string',\n",
       "          'description': 'str, path object, or file-like object. String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a read() function. The string can be any valid XML\\nstring or a path. The string can further be a URL. Valid URL schemes\\ninclude http, ftp, s3, and file.\\n\\nDeprecated since version 2.1.0: Passing xml literal strings is deprecated.\\nWrap literal xml input in io.StringIO or io.BytesIO instead.\\n\\n'},\n",
       "         'xpath': {'type': 'string',\n",
       "          'description': 'str, optional, default ‘./*’. The XPath to parse required set of nodes for migration to\\nDataFrame.``XPath`` should return a collection of elements\\nand not a single element. Note: The etree parser supports limited XPath\\nexpressions. For more complex XPath, use lxml which requires\\ninstallation.\\n'},\n",
       "         'namespaces': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. The namespaces defined in XML document as dicts with key being\\nnamespace prefix and value the URI. There is no need to include all\\nnamespaces in XML, only the ones used in xpath expression.\\nNote: if XML document uses default namespace denoted as\\nxmlns=’<URI>’ without a prefix, you must assign any temporary\\nnamespace prefix such as ‘doc’ to the URI in order to parse\\nunderlying nodes and/or attributes. For example,\\nnamespaces = {\"doc\": \"https://example.com\"}\\n\\n\\n'},\n",
       "         'elems_only': {'type': 'boolean',\n",
       "          'description': 'bool, optional, default False. Parse only the child elements at the specified xpath. By default,\\nall child elements and non-empty text nodes are returned.\\n'},\n",
       "         'attrs_only': {'type': 'boolean',\n",
       "          'description': 'bool, optional, default False. Parse only the attributes at the specified xpath.\\nBy default, all attributes are returned.\\n'},\n",
       "         'names': {'type': 'array',\n",
       "          'description': 'list-like, optional. Column names for DataFrame of parsed XML data. Use this parameter to\\nrename original element names and distinguish same named elements and\\nattributes.\\n'},\n",
       "         'dtype': {'type': 'Type name or dict of column -> type, optional',\n",
       "          'description': 'Type name or dict of column -> type, optional. Data type for data or columns. E.g. {‘a’: np.float64, ‘b’: np.int32,\\n‘c’: ‘Int64’}\\nUse str or object together with suitable na_values settings\\nto preserve and not interpret dtype.\\nIf converters are specified, they will be applied INSTEAD\\nof dtype conversion.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "         'converters': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Dict of functions for converting values in certain columns. Keys can either\\nbe integers or column labels.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "         'parse_dates': {'type': 'integer',\n",
       "          'description': 'bool or list of int or names or list of lists or dict, default False. Identifiers to parse index or columns to datetime. The behavior is as follows:\\n\\nboolean. If True -> try parsing the index.\\nlist of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\\neach as a separate date column.\\nlist of lists. e.g. If [[1, 3]] -> combine columns 1 and 3 and parse as\\na single date column.\\ndict, e.g. {‘foo’ : [1, 3]} -> parse columns 1, 3 as date and call\\nresult ‘foo’\\n\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "         'encoding': {'type': 'string',\n",
       "          'description': 'str, optional, default ‘utf-8’. Encoding of XML document.\\n'},\n",
       "         'parser': {'type': 'string',\n",
       "          'enum': ['lxml', 'etree'],\n",
       "          'description': '{‘lxml’,’etree’}, default ‘lxml’. Parser module to use for retrieval of data. Only ‘lxml’ and\\n‘etree’ are supported. With ‘lxml’ more complex XPath searches\\nand ability to use XSLT stylesheet are supported.\\n'},\n",
       "         'stylesheet': {'type': 'string',\n",
       "          'description': 'str, path object or file-like object. A URL, file-like object, or a raw string containing an XSLT script.\\nThis stylesheet should flatten complex, deeply nested XML documents\\nfor easier parsing. To use this feature you must have lxml module\\ninstalled and specify ‘lxml’ as parser. The xpath must\\nreference nodes of transformed XML document generated after XSLT\\ntransformation and not the original XML document. Only XSLT 1.0\\nscripts and not later versions is currently supported.\\n'},\n",
       "         'iterparse': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. The nodes or attributes to retrieve in iterparsing of XML document\\nas a dict with key being the name of repeating element and value being\\nlist of elements or attribute names that are descendants of the repeated\\nelement. Note: If this option is used, it will replace xpath parsing\\nand unlike xpath, descendants do not need to relate to each other but can\\nexist any where in document under the repeating element. This memory-\\nefficient method should be used for very large XML files (500MB, 1GB, or 5GB+).\\nFor example,\\niterparse = {\"row_element\": [\"child_elem\", \"attr\", \"grandchild_elem\"]}\\n\\n\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "         'compression': {'type': 'string',\n",
       "          'description': \"str or dict, default ‘infer’. For on-the-fly decompression of on-disk data. If ‘infer’ and ‘path_or_buffer’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nIf using ‘zip’ or ‘tar’, the ZIP file must contain only one data file to be read in.\\nSet to None for no decompression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdDecompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for Zstandard decompression using a\\ncustom compression dictionary:\\ncompression={'method': 'zstd', 'dict_data': my_compression_dict}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\n\\n\\nChanged in version 1.4.0: Zstandard support.\\n\\n\"},\n",
       "         'storage_options': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'},\n",
       "         'dtype_backend': {'type': 'string',\n",
       "          'enum': ['numpy_nullable', ' pyarrow'],\n",
       "          'description': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’. Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'}},\n",
       "        'required': ['path_or_buffer']}}},\n",
       "     {'func_name': 'DataFrame.to_xml([path_or_buffer,\\xa0index,\\xa0...])',\n",
       "      'func_desc': 'Render a DataFrame to an XML document.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_xml.html#pandas.DataFrame.to_xml',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_xml',\n",
       "       'full_function': \"DataFrame.to_xml(path_or_buffer=None, *, index=True, root_name='data', row_name='row', na_rep=None, attr_cols=None, elem_cols=None, namespaces=None, prefix=None, encoding='utf-8', xml_declaration=True, pretty_print=True, parser='lxml', stylesheet=None, compression='infer', storage_options=None)\",\n",
       "       'function_text': 'Render a DataFrame to an XML document. New in version 1.3.0.',\n",
       "       'parameter_names_desc': [{'param_name': 'path_or_buffer',\n",
       "         'param_type': 'str, path object, file-like object, or None, default None',\n",
       "         'param_desc': 'String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a write() function. If None, the result is returned\\nas a string.\\n'},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to include index in XML document.\\n'},\n",
       "        {'param_name': 'root_name',\n",
       "         'param_type': 'str, default ‘data’',\n",
       "         'param_desc': 'The name of root element in XML document.\\n'},\n",
       "        {'param_name': 'row_name',\n",
       "         'param_type': 'str, default ‘row’',\n",
       "         'param_desc': 'The name of row element in XML document.\\n'},\n",
       "        {'param_name': 'na_rep',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Missing data representation.\\n'},\n",
       "        {'param_name': 'attr_cols',\n",
       "         'param_type': 'list-like, optional',\n",
       "         'param_desc': 'List of columns to write as attributes in row element.\\nHierarchical columns will be flattened with underscore\\ndelimiting the different levels.\\n'},\n",
       "        {'param_name': 'elem_cols',\n",
       "         'param_type': 'list-like, optional',\n",
       "         'param_desc': 'List of columns to write as children in row element. By default,\\nall columns output as children of row element. Hierarchical\\ncolumns will be flattened with underscore delimiting the\\ndifferent levels.\\n'},\n",
       "        {'param_name': 'namespaces',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'All namespaces to be defined in root element. Keys of dict\\nshould be prefix names and values of dict corresponding URIs.\\nDefault namespaces should be given empty string key. For\\nexample,\\nnamespaces = {\"\": \"https://example.com\"}\\n\\n\\n'},\n",
       "        {'param_name': 'prefix',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Namespace prefix to be used for every element and/or attribute\\nin document. This should be one of the keys in namespaces\\ndict.\\n'},\n",
       "        {'param_name': 'encoding',\n",
       "         'param_type': 'str, default ‘utf-8’',\n",
       "         'param_desc': 'Encoding of the resulting document.\\n'},\n",
       "        {'param_name': 'xml_declaration',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to include the XML declaration at start of document.\\n'},\n",
       "        {'param_name': 'pretty_print',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether output should be pretty printed with indentation and\\nline breaks.\\n'},\n",
       "        {'param_name': 'parser',\n",
       "         'param_type': '{‘lxml’,’etree’}, default ‘lxml’',\n",
       "         'param_desc': 'Parser module to use for building of tree. Only ‘lxml’ and\\n‘etree’ are supported. With ‘lxml’, the ability to use XSLT\\nstylesheet is supported.\\n'},\n",
       "        {'param_name': 'stylesheet',\n",
       "         'param_type': 'str, path object or file-like object, optional',\n",
       "         'param_desc': 'A URL, file-like object, or a raw string containing an XSLT\\nscript used to transform the raw XML output. Script should use\\nlayout of elements and attributes from original output. This\\nargument requires lxml to be installed. Only XSLT 1.0\\nscripts and not later versions is currently supported.\\n'},\n",
       "        {'param_name': 'compression',\n",
       "         'param_type': 'str or dict, default ‘infer’',\n",
       "         'param_desc': \"For on-the-fly compression of the output data. If ‘infer’ and ‘path_or_buffer’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nSet to None for no compression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for faster compression and to create\\na reproducible gzip archive:\\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\n\\n\\nChanged in version 1.4.0: Zstandard support.\\n\\n\"},\n",
       "        {'param_name': 'storage_options',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.to_xml',\n",
       "       'descriptions': 'Render a DataFrame to an XML document. New in version 1.3.0.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'path_or_buffer': {'type': 'string',\n",
       "          'description': 'str, path object, file-like object, or None, default None. String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a write() function. If None, the result is returned\\nas a string.\\n'},\n",
       "         'index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to include index in XML document.\\n'},\n",
       "         'root_name': {'type': 'string',\n",
       "          'description': 'str, default ‘data’. The name of root element in XML document.\\n'},\n",
       "         'row_name': {'type': 'string',\n",
       "          'description': 'str, default ‘row’. The name of row element in XML document.\\n'},\n",
       "         'na_rep': {'type': 'string',\n",
       "          'description': 'str, optional. Missing data representation.\\n'},\n",
       "         'attr_cols': {'type': 'array',\n",
       "          'description': 'list-like, optional. List of columns to write as attributes in row element.\\nHierarchical columns will be flattened with underscore\\ndelimiting the different levels.\\n'},\n",
       "         'elem_cols': {'type': 'array',\n",
       "          'description': 'list-like, optional. List of columns to write as children in row element. By default,\\nall columns output as children of row element. Hierarchical\\ncolumns will be flattened with underscore delimiting the\\ndifferent levels.\\n'},\n",
       "         'namespaces': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. All namespaces to be defined in root element. Keys of dict\\nshould be prefix names and values of dict corresponding URIs.\\nDefault namespaces should be given empty string key. For\\nexample,\\nnamespaces = {\"\": \"https://example.com\"}\\n\\n\\n'},\n",
       "         'prefix': {'type': 'string',\n",
       "          'description': 'str, optional. Namespace prefix to be used for every element and/or attribute\\nin document. This should be one of the keys in namespaces\\ndict.\\n'},\n",
       "         'encoding': {'type': 'string',\n",
       "          'description': 'str, default ‘utf-8’. Encoding of the resulting document.\\n'},\n",
       "         'xml_declaration': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to include the XML declaration at start of document.\\n'},\n",
       "         'pretty_print': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether output should be pretty printed with indentation and\\nline breaks.\\n'},\n",
       "         'parser': {'type': 'string',\n",
       "          'enum': ['lxml', 'etree'],\n",
       "          'description': '{‘lxml’,’etree’}, default ‘lxml’. Parser module to use for building of tree. Only ‘lxml’ and\\n‘etree’ are supported. With ‘lxml’, the ability to use XSLT\\nstylesheet is supported.\\n'},\n",
       "         'stylesheet': {'type': 'string',\n",
       "          'description': 'str, path object or file-like object, optional. A URL, file-like object, or a raw string containing an XSLT\\nscript used to transform the raw XML output. Script should use\\nlayout of elements and attributes from original output. This\\nargument requires lxml to be installed. Only XSLT 1.0\\nscripts and not later versions is currently supported.\\n'},\n",
       "         'compression': {'type': 'string',\n",
       "          'description': \"str or dict, default ‘infer’. For on-the-fly compression of the output data. If ‘infer’ and ‘path_or_buffer’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nSet to None for no compression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for faster compression and to create\\na reproducible gzip archive:\\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\n\\n\\nChanged in version 1.4.0: Zstandard support.\\n\\n\"},\n",
       "         'storage_options': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'}},\n",
       "        'required': ['path_or_buffer=None']}}}]},\n",
       "   {'Latex': [{'func_name': 'DataFrame.to_latex([buf,\\xa0columns,\\xa0header,\\xa0...])',\n",
       "      'func_desc': 'Render object to a LaTeX tabular, longtable, or nested table.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_latex.html#pandas.DataFrame.to_latex',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_latex',\n",
       "       'full_function': \"DataFrame.to_latex(buf=None, *, columns=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, bold_rows=False, column_format=None, longtable=None, escape=None, encoding=None, decimal='.', multicolumn=None, multicolumn_format=None, multirow=None, caption=None, label=None, position=None)\",\n",
       "       'function_text': 'Render object to a LaTeX tabular, longtable, or nested table. Requires \\\\usepackage{{booktabs}}. The output can be copy/pasted\\ninto a main LaTeX document or read from an external file\\nwith \\\\input{{table.tex}}. Changed in version 2.0.0: Refactored to use the Styler implementation via jinja2 templating.',\n",
       "       'parameter_names_desc': [{'param_name': 'buf',\n",
       "         'param_type': 'str, Path or StringIO-like, optional, default None',\n",
       "         'param_desc': 'Buffer to write to. If None, the output is returned as a string.\\n'},\n",
       "        {'param_name': 'columns',\n",
       "         'param_type': 'list of label, optional',\n",
       "         'param_desc': 'The subset of columns to write. Writes all columns by default.\\n'},\n",
       "        {'param_name': 'header',\n",
       "         'param_type': 'bool or list of str, default True',\n",
       "         'param_desc': 'Write out the column names. If a list of strings is given,\\nit is assumed to be aliases for the column names.\\n'},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Write row names (index).\\n'},\n",
       "        {'param_name': 'na_rep',\n",
       "         'param_type': 'str, default ‘NaN’',\n",
       "         'param_desc': 'Missing data representation.\\n'},\n",
       "        {'param_name': 'formatters',\n",
       "         'param_type': 'list of functions or dict of {{str: function}}, optional',\n",
       "         'param_desc': 'Formatter functions to apply to columns’ elements by position or\\nname. The result of each function must be a unicode string.\\nList must be of length equal to the number of columns.\\n'},\n",
       "        {'param_name': 'float_format',\n",
       "         'param_type': 'one-parameter function or str, optional, default None',\n",
       "         'param_desc': 'Formatter for floating point numbers. For example\\nfloat_format=\"%.2f\" and float_format=\"{{:0.2f}}\".format will\\nboth result in 0.1234 being formatted as 0.12.\\n'},\n",
       "        {'param_name': 'sparsify',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'Set to False for a DataFrame with a hierarchical index to print\\nevery multiindex key at each row. By default, the value will be\\nread from the config module.\\n'},\n",
       "        {'param_name': 'index_names',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Prints the names of the indexes.\\n'},\n",
       "        {'param_name': 'bold_rows',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Make the row labels bold in the output.\\n'},\n",
       "        {'param_name': 'column_format',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'The columns format as specified in LaTeX table format e.g. ‘rcl’ for 3\\ncolumns. By default, ‘l’ will be used for all columns except\\ncolumns of numbers, which default to ‘r’.\\n'},\n",
       "        {'param_name': 'longtable',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'Use a longtable environment instead of tabular. Requires\\nadding a usepackage{{longtable}} to your LaTeX preamble.\\nBy default, the value will be read from the pandas config\\nmodule, and set to True if the option styler.latex.environment is\\n“longtable”.\\n\\nChanged in version 2.0.0: The pandas option affecting this argument has changed.\\n\\n'},\n",
       "        {'param_name': 'escape',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'By default, the value will be read from the pandas config\\nmodule and set to True if the option styler.format.escape is\\n“latex”. When set to False prevents from escaping latex special\\ncharacters in column names.\\n\\nChanged in version 2.0.0: The pandas option affecting this argument has changed, as has the\\ndefault value to False.\\n\\n'},\n",
       "        {'param_name': 'encoding',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'A string representing the encoding to use in the output file,\\ndefaults to ‘utf-8’.\\n'},\n",
       "        {'param_name': 'decimal',\n",
       "         'param_type': 'str, default ‘.’',\n",
       "         'param_desc': 'Character recognized as decimal separator, e.g. ‘,’ in Europe.\\n'},\n",
       "        {'param_name': 'multicolumn',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Use multicolumn to enhance MultiIndex columns.\\nThe default will be read from the config module, and is set\\nas the option styler.sparse.columns.\\n\\nChanged in version 2.0.0: The pandas option affecting this argument has changed.\\n\\n'},\n",
       "        {'param_name': 'multicolumn_format',\n",
       "         'param_type': 'str, default ‘r’',\n",
       "         'param_desc': 'The alignment for multicolumns, similar to column_format\\nThe default will be read from the config module, and is set as the option\\nstyler.latex.multicol_align.\\n\\nChanged in version 2.0.0: The pandas option affecting this argument has changed, as has the\\ndefault value to “r”.\\n\\n'},\n",
       "        {'param_name': 'multirow',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Use multirow to enhance MultiIndex rows. Requires adding a\\nusepackage{{multirow}} to your LaTeX preamble. Will print\\ncentered labels (instead of top-aligned) across the contained\\nrows, separating groups via clines. The default will be read\\nfrom the pandas config module, and is set as the option\\nstyler.sparse.index.\\n\\nChanged in version 2.0.0: The pandas option affecting this argument has changed, as has the\\ndefault value to True.\\n\\n'},\n",
       "        {'param_name': 'caption',\n",
       "         'param_type': 'str or tuple, optional',\n",
       "         'param_desc': 'Tuple (full_caption, short_caption),\\nwhich results in \\\\caption[short_caption]{{full_caption}};\\nif a single string is passed, no short caption will be set.\\n'},\n",
       "        {'param_name': 'label',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'The LaTeX label to be placed inside \\\\label{{}} in the output.\\nThis is used with \\\\ref{{}} in the main .tex file.\\n'},\n",
       "        {'param_name': 'position',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'The LaTeX positional argument for tables, to be placed after\\n\\\\begin{{}} in the output.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.to_latex',\n",
       "       'descriptions': 'Render object to a LaTeX tabular, longtable, or nested table. Requires \\\\usepackage{{booktabs}}. The output can be copy/pasted\\ninto a main LaTeX document or read from an external file\\nwith \\\\input{{table.tex}}. Changed in version 2.0.0: Refactored to use the Styler implementation via jinja2 templating.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'buf': {'type': 'string',\n",
       "          'description': 'str, Path or StringIO-like, optional, default None. Buffer to write to. If None, the output is returned as a string.\\n'},\n",
       "         'columns': {'type': 'array',\n",
       "          'description': 'list of label, optional. The subset of columns to write. Writes all columns by default.\\n'},\n",
       "         'header': {'type': 'string',\n",
       "          'description': 'bool or list of str, default True. Write out the column names. If a list of strings is given,\\nit is assumed to be aliases for the column names.\\n'},\n",
       "         'index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Write row names (index).\\n'},\n",
       "         'na_rep': {'type': 'string',\n",
       "          'description': 'str, default ‘NaN’. Missing data representation.\\n'},\n",
       "         'formatters': {'type': 'string',\n",
       "          'description': 'list of functions or dict of {{str: function}}, optional. Formatter functions to apply to columns’ elements by position or\\nname. The result of each function must be a unicode string.\\nList must be of length equal to the number of columns.\\n'},\n",
       "         'float_format': {'type': 'string',\n",
       "          'description': 'one-parameter function or str, optional, default None. Formatter for floating point numbers. For example\\nfloat_format=\"%.2f\" and float_format=\"{{:0.2f}}\".format will\\nboth result in 0.1234 being formatted as 0.12.\\n'},\n",
       "         'sparsify': {'type': 'boolean',\n",
       "          'description': 'bool, optional. Set to False for a DataFrame with a hierarchical index to print\\nevery multiindex key at each row. By default, the value will be\\nread from the config module.\\n'},\n",
       "         'index_names': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Prints the names of the indexes.\\n'},\n",
       "         'bold_rows': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Make the row labels bold in the output.\\n'},\n",
       "         'column_format': {'type': 'string',\n",
       "          'description': 'str, optional. The columns format as specified in LaTeX table format e.g. ‘rcl’ for 3\\ncolumns. By default, ‘l’ will be used for all columns except\\ncolumns of numbers, which default to ‘r’.\\n'},\n",
       "         'longtable': {'type': 'boolean',\n",
       "          'description': 'bool, optional. Use a longtable environment instead of tabular. Requires\\nadding a usepackage{{longtable}} to your LaTeX preamble.\\nBy default, the value will be read from the pandas config\\nmodule, and set to True if the option styler.latex.environment is\\n“longtable”.\\n\\nChanged in version 2.0.0: The pandas option affecting this argument has changed.\\n\\n'},\n",
       "         'escape': {'type': 'boolean',\n",
       "          'description': 'bool, optional. By default, the value will be read from the pandas config\\nmodule and set to True if the option styler.format.escape is\\n“latex”. When set to False prevents from escaping latex special\\ncharacters in column names.\\n\\nChanged in version 2.0.0: The pandas option affecting this argument has changed, as has the\\ndefault value to False.\\n\\n'},\n",
       "         'encoding': {'type': 'string',\n",
       "          'description': 'str, optional. A string representing the encoding to use in the output file,\\ndefaults to ‘utf-8’.\\n'},\n",
       "         'decimal': {'type': 'string',\n",
       "          'description': 'str, default ‘.’. Character recognized as decimal separator, e.g. ‘,’ in Europe.\\n'},\n",
       "         'multicolumn': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Use multicolumn to enhance MultiIndex columns.\\nThe default will be read from the config module, and is set\\nas the option styler.sparse.columns.\\n\\nChanged in version 2.0.0: The pandas option affecting this argument has changed.\\n\\n'},\n",
       "         'multicolumn_format': {'type': 'string',\n",
       "          'description': 'str, default ‘r’. The alignment for multicolumns, similar to column_format\\nThe default will be read from the config module, and is set as the option\\nstyler.latex.multicol_align.\\n\\nChanged in version 2.0.0: The pandas option affecting this argument has changed, as has the\\ndefault value to “r”.\\n\\n'},\n",
       "         'multirow': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Use multirow to enhance MultiIndex rows. Requires adding a\\nusepackage{{multirow}} to your LaTeX preamble. Will print\\ncentered labels (instead of top-aligned) across the contained\\nrows, separating groups via clines. The default will be read\\nfrom the pandas config module, and is set as the option\\nstyler.sparse.index.\\n\\nChanged in version 2.0.0: The pandas option affecting this argument has changed, as has the\\ndefault value to True.\\n\\n'},\n",
       "         'caption': {'type': 'string',\n",
       "          'description': 'str or tuple, optional. Tuple (full_caption, short_caption),\\nwhich results in \\\\caption[short_caption]{{full_caption}};\\nif a single string is passed, no short caption will be set.\\n'},\n",
       "         'label': {'type': 'string',\n",
       "          'description': 'str, optional. The LaTeX label to be placed inside \\\\label{{}} in the output.\\nThis is used with \\\\ref{{}} in the main .tex file.\\n'},\n",
       "         'position': {'type': 'string',\n",
       "          'description': 'str, optional. The LaTeX positional argument for tables, to be placed after\\n\\\\begin{{}} in the output.\\n'}},\n",
       "        'required': ['buf=None']}}},\n",
       "     {'func_name': 'Styler.to_latex([buf,\\xa0column_format,\\xa0...])',\n",
       "      'func_desc': 'Write Styler to a file, buffer or string in LaTeX format.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_latex.html#pandas.io.formats.style.Styler.to_latex',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.to_latex',\n",
       "       'full_function': 'Styler.to_latex(buf=None, *, column_format=None, position=None, position_float=None, hrules=None, clines=None, label=None, caption=None, sparse_index=None, sparse_columns=None, multirow_align=None, multicol_align=None, siunitx=False, environment=None, encoding=None, convert_css=False)',\n",
       "       'function_text': 'Write Styler to a file, buffer or string in LaTeX format. New in version 1.3.0.',\n",
       "       'parameter_names_desc': [{'param_name': 'buf',\n",
       "         'param_type': 'str, path object, file-like object, or None, default None',\n",
       "         'param_desc': 'String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a string write() function. If None, the result is\\nreturned as a string.\\n'},\n",
       "        {'param_name': 'column_format',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'The LaTeX column specification placed in location:\\n\\\\begin{tabular}{<column_format>}\\nDefaults to ‘l’ for index and\\nnon-numeric data columns, and, for numeric data columns,\\nto ‘r’ by default, or ‘S’ if siunitx is True.\\n'},\n",
       "        {'param_name': 'position',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'The LaTeX positional argument (e.g. ‘h!’) for tables, placed in location:\\n\\\\\\\\begin{table}[<position>].\\n'},\n",
       "        {'param_name': 'position_float',\n",
       "         'param_type': '{“centering”, “raggedleft”, “raggedright”}, optional',\n",
       "         'param_desc': 'The LaTeX float command placed in location:\\n\\\\begin{table}[<position>]\\n\\\\<position_float>\\nCannot be used if environment is “longtable”.\\n'},\n",
       "        {'param_name': 'hrules',\n",
       "         'param_type': 'bool',\n",
       "         'param_desc': 'Set to True to add \\\\toprule, \\\\midrule and \\\\bottomrule from the\\n{booktabs} LaTeX package.\\nDefaults to pandas.options.styler.latex.hrules, which is False.\\n\\nChanged in version 1.4.0.\\n\\n'},\n",
       "        {'param_name': 'clines',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Use to control adding \\\\cline commands for the index labels separation.\\nPossible values are:\\n\\n\\nNone: no cline commands are added (default).\\n“all;data”: a cline is added for every index value extending the\\nwidth of the table, including data entries.\\n“all;index”: as above with lines extending only the width of the\\nindex entries.\\n“skip-last;data”: a cline is added for each index value except the\\nlast level (which is never sparsified), extending the widtn of the\\ntable.\\n“skip-last;index”: as above with lines extending only the width of the\\nindex entries.\\n\\n\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "        {'param_name': 'label',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'The LaTeX label included as: \\\\label{<label>}.\\nThis is used with \\\\ref{<label>} in the main .tex file.\\n'},\n",
       "        {'param_name': 'caption',\n",
       "         'param_type': 'str, tuple, optional',\n",
       "         'param_desc': 'If string, the LaTeX table caption included as: \\\\caption{<caption>}.\\nIf tuple, i.e (“full caption”, “short caption”), the caption included\\nas: \\\\caption[<caption[1]>]{<caption[0]>}.\\n'},\n",
       "        {'param_name': 'sparse_index',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'Whether to sparsify the display of a hierarchical index. Setting to False\\nwill display each explicit level element in a hierarchical key for each row.\\nDefaults to pandas.options.styler.sparse.index, which is True.\\n'},\n",
       "        {'param_name': 'sparse_columns',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'Whether to sparsify the display of a hierarchical index. Setting to False\\nwill display each explicit level element in a hierarchical key for each\\ncolumn. Defaults to pandas.options.styler.sparse.columns, which\\nis True.\\n'},\n",
       "        {'param_name': 'multirow_align',\n",
       "         'param_type': '{“c”, “t”, “b”, “naive”}, optional',\n",
       "         'param_desc': 'If sparsifying hierarchical MultiIndexes whether to align text centrally,\\nat the top or bottom using the multirow package. If not given defaults to\\npandas.options.styler.latex.multirow_align, which is “c”.\\nIf “naive” is given renders without multirow.\\n\\nChanged in version 1.4.0.\\n\\n'},\n",
       "        {'param_name': 'multicol_align',\n",
       "         'param_type': '{“r”, “c”, “l”, “naive-l”, “naive-r”}, optional',\n",
       "         'param_desc': 'If sparsifying hierarchical MultiIndex columns whether to align text at\\nthe left, centrally, or at the right. If not given defaults to\\npandas.options.styler.latex.multicol_align, which is “r”.\\nIf a naive option is given renders without multicol.\\nPipe decorators can also be added to non-naive values to draw vertical\\nrules, e.g. “|r” will draw a rule on the left side of right aligned merged\\ncells.\\n\\nChanged in version 1.4.0.\\n\\n'},\n",
       "        {'param_name': 'siunitx',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Set to True to structure LaTeX compatible with the {siunitx} package.\\n'},\n",
       "        {'param_name': 'environment',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'If given, the environment that will replace ‘table’ in \\\\\\\\begin{table}.\\nIf ‘longtable’ is specified then a more suitable template is\\nrendered. If not given defaults to\\npandas.options.styler.latex.environment, which is None.\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "        {'param_name': 'encoding',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Character encoding setting. Defaults\\nto pandas.options.styler.render.encoding, which is “utf-8”.\\n'},\n",
       "        {'param_name': 'convert_css',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Convert simple cell-styles from CSS to LaTeX format. Any CSS not found in\\nconversion table is dropped. A style can be forced by adding option\\n–latex. See notes.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.to_latex',\n",
       "       'descriptions': 'Write Styler to a file, buffer or string in LaTeX format. New in version 1.3.0.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'buf': {'type': 'string',\n",
       "          'description': 'str, path object, file-like object, or None, default None. String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a string write() function. If None, the result is\\nreturned as a string.\\n'},\n",
       "         'column_format': {'type': 'string',\n",
       "          'description': 'str, optional. The LaTeX column specification placed in location:\\n\\\\begin{tabular}{<column_format>}\\nDefaults to ‘l’ for index and\\nnon-numeric data columns, and, for numeric data columns,\\nto ‘r’ by default, or ‘S’ if siunitx is True.\\n'},\n",
       "         'position': {'type': 'string',\n",
       "          'description': 'str, optional. The LaTeX positional argument (e.g. ‘h!’) for tables, placed in location:\\n\\\\\\\\begin{table}[<position>].\\n'},\n",
       "         'position_float': {'type': '{“centering”, “raggedleft”, “raggedright”}, optional',\n",
       "          'description': '{“centering”, “raggedleft”, “raggedright”}, optional. The LaTeX float command placed in location:\\n\\\\begin{table}[<position>]\\n\\\\<position_float>\\nCannot be used if environment is “longtable”.\\n'},\n",
       "         'hrules': {'type': 'boolean',\n",
       "          'description': 'bool. Set to True to add \\\\toprule, \\\\midrule and \\\\bottomrule from the\\n{booktabs} LaTeX package.\\nDefaults to pandas.options.styler.latex.hrules, which is False.\\n\\nChanged in version 1.4.0.\\n\\n'},\n",
       "         'clines': {'type': 'string',\n",
       "          'description': 'str, optional. Use to control adding \\\\cline commands for the index labels separation.\\nPossible values are:\\n\\n\\nNone: no cline commands are added (default).\\n“all;data”: a cline is added for every index value extending the\\nwidth of the table, including data entries.\\n“all;index”: as above with lines extending only the width of the\\nindex entries.\\n“skip-last;data”: a cline is added for each index value except the\\nlast level (which is never sparsified), extending the widtn of the\\ntable.\\n“skip-last;index”: as above with lines extending only the width of the\\nindex entries.\\n\\n\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "         'label': {'type': 'string',\n",
       "          'description': 'str, optional. The LaTeX label included as: \\\\label{<label>}.\\nThis is used with \\\\ref{<label>} in the main .tex file.\\n'},\n",
       "         'caption': {'type': 'string',\n",
       "          'description': 'str, tuple, optional. If string, the LaTeX table caption included as: \\\\caption{<caption>}.\\nIf tuple, i.e (“full caption”, “short caption”), the caption included\\nas: \\\\caption[<caption[1]>]{<caption[0]>}.\\n'},\n",
       "         'sparse_index': {'type': 'boolean',\n",
       "          'description': 'bool, optional. Whether to sparsify the display of a hierarchical index. Setting to False\\nwill display each explicit level element in a hierarchical key for each row.\\nDefaults to pandas.options.styler.sparse.index, which is True.\\n'},\n",
       "         'sparse_columns': {'type': 'boolean',\n",
       "          'description': 'bool, optional. Whether to sparsify the display of a hierarchical index. Setting to False\\nwill display each explicit level element in a hierarchical key for each\\ncolumn. Defaults to pandas.options.styler.sparse.columns, which\\nis True.\\n'},\n",
       "         'multirow_align': {'type': '{“c”, “t”, “b”, “naive”}, optional',\n",
       "          'description': '{“c”, “t”, “b”, “naive”}, optional. If sparsifying hierarchical MultiIndexes whether to align text centrally,\\nat the top or bottom using the multirow package. If not given defaults to\\npandas.options.styler.latex.multirow_align, which is “c”.\\nIf “naive” is given renders without multirow.\\n\\nChanged in version 1.4.0.\\n\\n'},\n",
       "         'multicol_align': {'type': '{“r”, “c”, “l”, “naive-l”, “naive-r”}, optional',\n",
       "          'description': '{“r”, “c”, “l”, “naive-l”, “naive-r”}, optional. If sparsifying hierarchical MultiIndex columns whether to align text at\\nthe left, centrally, or at the right. If not given defaults to\\npandas.options.styler.latex.multicol_align, which is “r”.\\nIf a naive option is given renders without multicol.\\nPipe decorators can also be added to non-naive values to draw vertical\\nrules, e.g. “|r” will draw a rule on the left side of right aligned merged\\ncells.\\n\\nChanged in version 1.4.0.\\n\\n'},\n",
       "         'siunitx': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Set to True to structure LaTeX compatible with the {siunitx} package.\\n'},\n",
       "         'environment': {'type': 'string',\n",
       "          'description': 'str, optional. If given, the environment that will replace ‘table’ in \\\\\\\\begin{table}.\\nIf ‘longtable’ is specified then a more suitable template is\\nrendered. If not given defaults to\\npandas.options.styler.latex.environment, which is None.\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "         'encoding': {'type': 'string',\n",
       "          'description': 'str, optional. Character encoding setting. Defaults\\nto pandas.options.styler.render.encoding, which is “utf-8”.\\n'},\n",
       "         'convert_css': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Convert simple cell-styles from CSS to LaTeX format. Any CSS not found in\\nconversion table is dropped. A style can be forced by adding option\\n–latex. See notes.\\n'}},\n",
       "        'required': ['buf=None']}}}]},\n",
       "   {'HDFStore: PyTables (HDF5)': [{'func_name': 'read_hdf(path_or_buf[,\\xa0key,\\xa0mode,\\xa0errors,\\xa0...])',\n",
       "      'func_desc': 'Read from the store, close it if we opened it.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.read_hdf.html#pandas.read_hdf',\n",
       "      'function_definitions': {'function_name': 'pandas.read_hdf',\n",
       "       'full_function': \"pandas.read_hdf(path_or_buf, key=None, mode='r', errors='strict', where=None, start=None, stop=None, columns=None, iterator=False, chunksize=None, **kwargs)\",\n",
       "       'function_text': 'Read from the store, close it if we opened it. Retrieve pandas object stored in file, optionally based on where\\ncriteria. Warning Pandas uses PyTables for reading and writing HDF5 files, which allows\\nserializing object-dtype data with pickle when using the “fixed” format.\\nLoading pickled data received from untrusted sources can be unsafe. See: https://docs.python.org/3/library/pickle.html for more.',\n",
       "       'parameter_names_desc': [{'param_name': 'path_or_buf',\n",
       "         'param_type': 'str, path object, pandas.HDFStore',\n",
       "         'param_desc': 'Any valid string path is acceptable. Only supports the local file system,\\nremote URLs and file-like objects are not supported.\\nIf you want to pass in a path object, pandas accepts any\\nos.PathLike.\\nAlternatively, pandas accepts an open pandas.HDFStore object.\\n'},\n",
       "        {'param_name': 'key',\n",
       "         'param_type': 'object, optional',\n",
       "         'param_desc': 'The group identifier in the store. Can be omitted if the HDF file\\ncontains a single pandas object.\\n'},\n",
       "        {'param_name': 'mode',\n",
       "         'param_type': '{‘r’, ‘r+’, ‘a’}, default ‘r’',\n",
       "         'param_desc': 'Mode to use when opening the file. Ignored if path_or_buf is a\\npandas.HDFStore. Default is ‘r’.\\n'},\n",
       "        {'param_name': 'errors',\n",
       "         'param_type': 'str, default ‘strict’',\n",
       "         'param_desc': 'Specifies how encoding and decoding errors are to be handled.\\nSee the errors argument for open() for a full list\\nof options.\\n'},\n",
       "        {'param_name': 'where',\n",
       "         'param_type': 'list, optional',\n",
       "         'param_desc': 'A list of Term (or convertible) objects.\\n'},\n",
       "        {'param_name': 'start',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Row number to start selection.\\n'},\n",
       "        {'param_name': 'stop',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Row number to stop selection.\\n'},\n",
       "        {'param_name': 'columns',\n",
       "         'param_type': 'list, optional',\n",
       "         'param_desc': 'A list of columns names to return.\\n'},\n",
       "        {'param_name': 'iterator',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'Return an iterator object.\\n'},\n",
       "        {'param_name': 'chunksize',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Number of rows to include in an iteration when using an iterator.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.read_hdf',\n",
       "       'descriptions': 'Read from the store, close it if we opened it. Retrieve pandas object stored in file, optionally based on where\\ncriteria. Warning Pandas uses PyTables for reading and writing HDF5 files, which allows\\nserializing object-dtype data with pickle when using the “fixed” format.\\nLoading pickled data received from untrusted sources can be unsafe. See: https://docs.python.org/3/library/pickle.html for more.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'path_or_buf': {'type': 'string',\n",
       "          'description': 'str, path object, pandas.HDFStore. Any valid string path is acceptable. Only supports the local file system,\\nremote URLs and file-like objects are not supported.\\nIf you want to pass in a path object, pandas accepts any\\nos.PathLike.\\nAlternatively, pandas accepts an open pandas.HDFStore object.\\n'},\n",
       "         'key': {'type': 'object',\n",
       "          'description': 'object, optional. The group identifier in the store. Can be omitted if the HDF file\\ncontains a single pandas object.\\n'},\n",
       "         'mode': {'type': 'string',\n",
       "          'enum': ['r', ' r+', ' a'],\n",
       "          'description': '{‘r’, ‘r+’, ‘a’}, default ‘r’. Mode to use when opening the file. Ignored if path_or_buf is a\\npandas.HDFStore. Default is ‘r’.\\n'},\n",
       "         'errors': {'type': 'string',\n",
       "          'description': 'str, default ‘strict’. Specifies how encoding and decoding errors are to be handled.\\nSee the errors argument for open() for a full list\\nof options.\\n'},\n",
       "         'where': {'type': 'array',\n",
       "          'description': 'list, optional. A list of Term (or convertible) objects.\\n'},\n",
       "         'start': {'type': 'integer',\n",
       "          'description': 'int, optional. Row number to start selection.\\n'},\n",
       "         'stop': {'type': 'integer',\n",
       "          'description': 'int, optional. Row number to stop selection.\\n'},\n",
       "         'columns': {'type': 'array',\n",
       "          'description': 'list, optional. A list of columns names to return.\\n'},\n",
       "         'iterator': {'type': 'boolean',\n",
       "          'description': 'bool, optional. Return an iterator object.\\n'},\n",
       "         'chunksize': {'type': 'integer',\n",
       "          'description': 'int, optional. Number of rows to include in an iteration when using an iterator.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'HDFStore.append(key,\\xa0value[,\\xa0format,\\xa0axes,\\xa0...])',\n",
       "      'func_desc': 'Append to Table in file.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.HDFStore.append.html#pandas.HDFStore.append',\n",
       "      'function_definitions': {'function_name': 'pandas.HDFStore.append',\n",
       "       'full_function': \"HDFStore.append(key, value, format=None, axes=None, index=True, append=True, complib=None, complevel=None, columns=None, min_itemsize=None, nan_rep=None, chunksize=None, expectedrows=None, dropna=None, data_columns=None, encoding=None, errors='strict')\",\n",
       "       'function_text': 'Append to Table in file. Node must already exist and be Table format.',\n",
       "       'parameter_names_desc': [{'param_name': 'key',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'value',\n",
       "         'param_type': '{Series, DataFrame}',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'format',\n",
       "         'param_type': '‘table’ is the default',\n",
       "         'param_desc': \"Format to use when storing object in HDFStore. Value can be one of:\\n\\n'table'Table format. Write as a PyTables Table structure which may perform\\nworse but allow more flexible operations like searching / selecting\\nsubsets of the data.\\n\\n\\n\"},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Write DataFrame index as a column.\\n'},\n",
       "        {'param_name': 'append',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Append the input data to the existing.\\n'},\n",
       "        {'param_name': 'data_columns',\n",
       "         'param_type': 'list of columns, or True, default None',\n",
       "         'param_desc': 'List of columns to create as indexed data columns for on-disk\\nqueries, or True to use all columns. By default only the axes\\nof the object are indexed. See here.\\n'},\n",
       "        {'param_name': 'min_itemsize',\n",
       "         'param_type': 'dict of columns that specify minimum str sizes',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'nan_rep',\n",
       "         'param_type': 'str to use as str nan representation',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'chunksize',\n",
       "         'param_type': 'size to chunk the writing',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'expectedrows',\n",
       "         'param_type': 'expected TOTAL row size of this table',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'encoding',\n",
       "         'param_type': 'default None, provide an encoding for str',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'dropna',\n",
       "         'param_type': 'bool, default False, optional',\n",
       "         'param_desc': 'Do not write an ALL nan row to the store settable\\nby the option ‘io.hdf.dropna_table’.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.HDFStore.append',\n",
       "       'descriptions': 'Append to Table in file. Node must already exist and be Table format.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'key': {'type': 'string', 'description': 'str. '},\n",
       "         'value': {'type': '{Series, DataFrame}',\n",
       "          'description': '{Series, DataFrame}. '},\n",
       "         'format': {'type': '‘table’ is the default',\n",
       "          'description': \"‘table’ is the default. Format to use when storing object in HDFStore. Value can be one of:\\n\\n'table'Table format. Write as a PyTables Table structure which may perform\\nworse but allow more flexible operations like searching / selecting\\nsubsets of the data.\\n\\n\\n\"},\n",
       "         'index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Write DataFrame index as a column.\\n'},\n",
       "         'append': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Append the input data to the existing.\\n'},\n",
       "         'data_columns': {'type': 'array',\n",
       "          'description': 'list of columns, or True, default None. List of columns to create as indexed data columns for on-disk\\nqueries, or True to use all columns. By default only the axes\\nof the object are indexed. See here.\\n'},\n",
       "         'min_itemsize': {'type': 'string',\n",
       "          'description': 'dict of columns that specify minimum str sizes. '},\n",
       "         'nan_rep': {'type': 'string',\n",
       "          'description': 'str to use as str nan representation. '},\n",
       "         'chunksize': {'type': 'size to chunk the writing',\n",
       "          'description': 'size to chunk the writing. '},\n",
       "         'expectedrows': {'type': 'expected TOTAL row size of this table',\n",
       "          'description': 'expected TOTAL row size of this table. '},\n",
       "         'encoding': {'type': 'string',\n",
       "          'description': 'default None, provide an encoding for str. '},\n",
       "         'dropna': {'type': 'boolean',\n",
       "          'description': 'bool, default False, optional. Do not write an ALL nan row to the store settable\\nby the option ‘io.hdf.dropna_table’.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'HDFStore.select(key[,\\xa0where,\\xa0start,\\xa0stop,\\xa0...])',\n",
       "      'func_desc': 'Retrieve pandas object stored in file, optionally based on where criteria.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.HDFStore.select.html#pandas.HDFStore.select',\n",
       "      'function_definitions': {'function_name': 'pandas.HDFStore.select',\n",
       "       'full_function': 'HDFStore.select(key, where=None, start=None, stop=None, columns=None, iterator=False, chunksize=None, auto_close=False)',\n",
       "       'function_text': 'Retrieve pandas object stored in file, optionally based on where criteria. Warning Pandas uses PyTables for reading and writing HDF5 files, which allows\\nserializing object-dtype data with pickle when using the “fixed” format.\\nLoading pickled data received from untrusted sources can be unsafe. See: https://docs.python.org/3/library/pickle.html for more.',\n",
       "       'parameter_names_desc': [{'param_name': 'key',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'Object being retrieved from file.\\n'},\n",
       "        {'param_name': 'where',\n",
       "         'param_type': 'list or None',\n",
       "         'param_desc': 'List of Term (or convertible) objects, optional.\\n'},\n",
       "        {'param_name': 'start',\n",
       "         'param_type': 'int or None',\n",
       "         'param_desc': 'Row number to start selection.\\n'},\n",
       "        {'param_name': 'stop',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'Row number to stop selection.\\n'},\n",
       "        {'param_name': 'columns',\n",
       "         'param_type': 'list or None',\n",
       "         'param_desc': 'A list of columns that if not None, will limit the return columns.\\n'},\n",
       "        {'param_name': 'iterator',\n",
       "         'param_type': 'bool or False',\n",
       "         'param_desc': 'Returns an iterator.\\n'},\n",
       "        {'param_name': 'chunksize',\n",
       "         'param_type': 'int or None',\n",
       "         'param_desc': 'Number or rows to include in iteration, return an iterator.\\n'},\n",
       "        {'param_name': 'auto_close',\n",
       "         'param_type': 'bool or False',\n",
       "         'param_desc': 'Should automatically close the store when finished.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.HDFStore.select',\n",
       "       'descriptions': 'Retrieve pandas object stored in file, optionally based on where criteria. Warning Pandas uses PyTables for reading and writing HDF5 files, which allows\\nserializing object-dtype data with pickle when using the “fixed” format.\\nLoading pickled data received from untrusted sources can be unsafe. See: https://docs.python.org/3/library/pickle.html for more.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'key': {'type': 'string',\n",
       "          'description': 'str. Object being retrieved from file.\\n'},\n",
       "         'where': {'type': 'array',\n",
       "          'description': 'list or None. List of Term (or convertible) objects, optional.\\n'},\n",
       "         'start': {'type': 'integer',\n",
       "          'description': 'int or None. Row number to start selection.\\n'},\n",
       "         'stop': {'type': 'integer',\n",
       "          'description': 'int, default None. Row number to stop selection.\\n'},\n",
       "         'columns': {'type': 'array',\n",
       "          'description': 'list or None. A list of columns that if not None, will limit the return columns.\\n'},\n",
       "         'iterator': {'type': 'boolean',\n",
       "          'description': 'bool or False. Returns an iterator.\\n'},\n",
       "         'chunksize': {'type': 'integer',\n",
       "          'description': 'int or None. Number or rows to include in iteration, return an iterator.\\n'},\n",
       "         'auto_close': {'type': 'boolean',\n",
       "          'description': 'bool or False. Should automatically close the store when finished.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'HDFStore.keys([include])',\n",
       "      'func_desc': 'Return a list of keys corresponding to objects stored in HDFStore.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.HDFStore.keys.html#pandas.HDFStore.keys',\n",
       "      'function_definitions': {'function_name': 'pandas.HDFStore.keys',\n",
       "       'full_function': \"HDFStore.keys(include='pandas')\",\n",
       "       'function_text': 'Return a list of keys corresponding to objects stored in HDFStore.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'HDFStore.walk([where])',\n",
       "      'func_desc': 'Walk the pytables group hierarchy for pandas objects.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.HDFStore.walk.html#pandas.HDFStore.walk',\n",
       "      'function_definitions': {'function_name': 'pandas.HDFStore.walk',\n",
       "       'full_function': \"HDFStore.walk(where='/')\",\n",
       "       'function_text': 'Walk the pytables group hierarchy for pandas objects. This generator will yield the group path, subgroups and pandas object\\nnames for each group. Any non-pandas PyTables objects that are not a group will be ignored. The where group itself is listed first (preorder), then each of its\\nchild groups (following an alphanumerical order) is also traversed,\\nfollowing the same procedure.',\n",
       "       'parameter_names_desc': [{'param_name': 'where',\n",
       "         'param_type': 'str, default “/”',\n",
       "         'param_desc': 'Group where to start walking.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.HDFStore.walk',\n",
       "       'descriptions': 'Walk the pytables group hierarchy for pandas objects. This generator will yield the group path, subgroups and pandas object\\nnames for each group. Any non-pandas PyTables objects that are not a group will be ignored. The where group itself is listed first (preorder), then each of its\\nchild groups (following an alphanumerical order) is also traversed,\\nfollowing the same procedure.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'where': {'type': 'string',\n",
       "          'description': 'str, default “/”. Group where to start walking.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'HDFStore.put(key,\\xa0value[,\\xa0format,\\xa0index,\\xa0...])',\n",
       "      'func_desc': 'Store object in HDFStore.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.HDFStore.put.html#pandas.HDFStore.put',\n",
       "      'function_definitions': {'function_name': 'pandas.HDFStore.put',\n",
       "       'full_function': \"HDFStore.put(key, value, format=None, index=True, append=False, complib=None, complevel=None, min_itemsize=None, nan_rep=None, data_columns=None, encoding=None, errors='strict', track_times=True, dropna=False)\",\n",
       "       'function_text': 'Store object in HDFStore.',\n",
       "       'parameter_names_desc': [{'param_name': 'key',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'value',\n",
       "         'param_type': '{Series, DataFrame}',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'format',\n",
       "         'param_type': '‘fixed(f)|table(t)’, default is ‘fixed’',\n",
       "         'param_desc': \"Format to use when storing object in HDFStore. Value can be one of:\\n\\n'fixed'Fixed format. Fast writing/reading. Not-appendable, nor searchable.\\n\\n'table'Table format. Write as a PyTables Table structure which may perform\\nworse but allow more flexible operations like searching / selecting\\nsubsets of the data.\\n\\n\\n\"},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Write DataFrame index as a column.\\n'},\n",
       "        {'param_name': 'append',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'This will force Table format, append the input data to the existing.\\n'},\n",
       "        {'param_name': 'data_columns',\n",
       "         'param_type': 'list of columns or True, default None',\n",
       "         'param_desc': 'List of columns to create as data columns, or True to use all columns.\\nSee here.\\n'},\n",
       "        {'param_name': 'encoding',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'Provide an encoding for strings.\\n'},\n",
       "        {'param_name': 'track_times',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Parameter is propagated to ‘create_table’ method of ‘PyTables’.\\nIf set to False it enables to have the same h5 files (same hashes)\\nindependent on creation time.\\n'},\n",
       "        {'param_name': 'dropna',\n",
       "         'param_type': 'bool, default False, optional',\n",
       "         'param_desc': 'Remove missing values.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.HDFStore.put',\n",
       "       'descriptions': 'Store object in HDFStore.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'key': {'type': 'string', 'description': 'str. '},\n",
       "         'value': {'type': '{Series, DataFrame}',\n",
       "          'description': '{Series, DataFrame}. '},\n",
       "         'format': {'type': '‘fixed(f)|table(t)’, default is ‘fixed’',\n",
       "          'description': \"‘fixed(f)|table(t)’, default is ‘fixed’. Format to use when storing object in HDFStore. Value can be one of:\\n\\n'fixed'Fixed format. Fast writing/reading. Not-appendable, nor searchable.\\n\\n'table'Table format. Write as a PyTables Table structure which may perform\\nworse but allow more flexible operations like searching / selecting\\nsubsets of the data.\\n\\n\\n\"},\n",
       "         'index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Write DataFrame index as a column.\\n'},\n",
       "         'append': {'type': 'boolean',\n",
       "          'description': 'bool, default False. This will force Table format, append the input data to the existing.\\n'},\n",
       "         'data_columns': {'type': 'array',\n",
       "          'description': 'list of columns or True, default None. List of columns to create as data columns, or True to use all columns.\\nSee here.\\n'},\n",
       "         'encoding': {'type': 'string',\n",
       "          'description': 'str, default None. Provide an encoding for strings.\\n'},\n",
       "         'track_times': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Parameter is propagated to ‘create_table’ method of ‘PyTables’.\\nIf set to False it enables to have the same h5 files (same hashes)\\nindependent on creation time.\\n'},\n",
       "         'dropna': {'type': 'boolean',\n",
       "          'description': 'bool, default False, optional. Remove missing values.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'HDFStore.get(key)',\n",
       "      'func_desc': 'Retrieve pandas object stored in file.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.HDFStore.get.html#pandas.HDFStore.get',\n",
       "      'function_definitions': {'function_name': 'pandas.HDFStore.get',\n",
       "       'full_function': 'HDFStore.get(key)',\n",
       "       'function_text': 'Retrieve pandas object stored in file.',\n",
       "       'parameter_names_desc': [{'param_name': 'key',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.HDFStore.get',\n",
       "       'descriptions': 'Retrieve pandas object stored in file.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'key': {'type': 'string', 'description': 'str. '}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'HDFStore.info()',\n",
       "      'func_desc': 'Print detailed information on the store.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.HDFStore.info.html#pandas.HDFStore.info',\n",
       "      'function_definitions': {'function_name': 'pandas.HDFStore.info',\n",
       "       'full_function': 'HDFStore.info()',\n",
       "       'function_text': 'Print detailed information on the store.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'HDFStore.groups()',\n",
       "      'func_desc': 'Return a list of all the top-level nodes.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.HDFStore.groups.html#pandas.HDFStore.groups',\n",
       "      'function_definitions': {'function_name': 'pandas.HDFStore.groups',\n",
       "       'full_function': 'HDFStore.groups()',\n",
       "       'function_text': 'Return a list of all the top-level nodes. Each node returned is not a pandas storage object.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'Feather': [{'func_name': 'read_feather(path[,\\xa0columns,\\xa0use_threads,\\xa0...])',\n",
       "      'func_desc': 'Load a feather-format object from the file path.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.read_feather.html#pandas.read_feather',\n",
       "      'function_definitions': {'function_name': 'pandas.read_feather',\n",
       "       'full_function': 'pandas.read_feather(path, columns=None, use_threads=True, storage_options=None, dtype_backend=_NoDefault.no_default)',\n",
       "       'function_text': 'Load a feather-format object from the file path.',\n",
       "       'parameter_names_desc': [{'param_name': 'path',\n",
       "         'param_type': 'str, path object, or file-like object',\n",
       "         'param_desc': 'String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a binary read() function. The string could be a URL.\\nValid URL schemes include http, ftp, s3, and file. For file URLs, a host is\\nexpected. A local file could be: file://localhost/path/to/table.feather.\\n'},\n",
       "        {'param_name': 'columns',\n",
       "         'param_type': 'sequence, default None',\n",
       "         'param_desc': 'If not provided, all columns are read.\\n'},\n",
       "        {'param_name': 'use_threads',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to parallelize reading using multiple threads.\\n'},\n",
       "        {'param_name': 'storage_options',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'},\n",
       "        {'param_name': 'dtype_backend',\n",
       "         'param_type': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’',\n",
       "         'param_desc': 'Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.read_feather',\n",
       "       'descriptions': 'Load a feather-format object from the file path.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'path': {'type': 'string',\n",
       "          'description': 'str, path object, or file-like object. String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a binary read() function. The string could be a URL.\\nValid URL schemes include http, ftp, s3, and file. For file URLs, a host is\\nexpected. A local file could be: file://localhost/path/to/table.feather.\\n'},\n",
       "         'columns': {'type': 'sequence, default None',\n",
       "          'description': 'sequence, default None. If not provided, all columns are read.\\n'},\n",
       "         'use_threads': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to parallelize reading using multiple threads.\\n'},\n",
       "         'storage_options': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'},\n",
       "         'dtype_backend': {'type': 'string',\n",
       "          'enum': ['numpy_nullable', ' pyarrow'],\n",
       "          'description': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’. Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.to_feather(path,\\xa0**kwargs)',\n",
       "      'func_desc': 'Write a DataFrame to the binary Feather format.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_feather.html#pandas.DataFrame.to_feather',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_feather',\n",
       "       'full_function': 'DataFrame.to_feather(path, **kwargs)',\n",
       "       'function_text': 'Write a DataFrame to the binary Feather format.',\n",
       "       'parameter_names_desc': [{'param_name': 'path',\n",
       "         'param_type': 'str, path object, file-like object',\n",
       "         'param_desc': 'String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a binary write() function. If a string or a path,\\nit will be used as Root Directory path when writing a partitioned dataset.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.to_feather',\n",
       "       'descriptions': 'Write a DataFrame to the binary Feather format.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'path': {'type': 'string',\n",
       "          'description': 'str, path object, file-like object. String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a binary write() function. If a string or a path,\\nit will be used as Root Directory path when writing a partitioned dataset.\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Parquet': [{'func_name': 'read_parquet(path[,\\xa0engine,\\xa0columns,\\xa0...])',\n",
       "      'func_desc': 'Load a parquet object from the file path, returning a DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.read_parquet.html#pandas.read_parquet',\n",
       "      'function_definitions': {'function_name': 'pandas.read_parquet',\n",
       "       'full_function': \"pandas.read_parquet(path, engine='auto', columns=None, storage_options=None, use_nullable_dtypes=_NoDefault.no_default, dtype_backend=_NoDefault.no_default, filesystem=None, filters=None, **kwargs)\",\n",
       "       'function_text': 'Load a parquet object from the file path, returning a DataFrame.',\n",
       "       'parameter_names_desc': [{'param_name': 'path',\n",
       "         'param_type': 'str, path object or file-like object',\n",
       "         'param_desc': 'String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a binary read() function.\\nThe string could be a URL. Valid URL schemes include http, ftp, s3,\\ngs, and file. For file URLs, a host is expected. A local file could be:\\nfile://localhost/path/to/table.parquet.\\nA file URL can also be a path to a directory that contains multiple\\npartitioned parquet files. Both pyarrow and fastparquet support\\npaths to directories as well as file URLs. A directory path could be:\\nfile://localhost/path/to/tables or s3://bucket/partition_dir.\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': '{‘auto’, ‘pyarrow’, ‘fastparquet’}, default ‘auto’',\n",
       "         'param_desc': \"Parquet library to use. If ‘auto’, then the option\\nio.parquet.engine is used. The default io.parquet.engine\\nbehavior is to try ‘pyarrow’, falling back to ‘fastparquet’ if\\n‘pyarrow’ is unavailable.\\nWhen using the 'pyarrow' engine and no storage options are provided\\nand a filesystem is implemented by both pyarrow.fs and fsspec\\n(e.g. “s3://”), then the pyarrow.fs filesystem is attempted first.\\nUse the filesystem keyword with an instantiated fsspec filesystem\\nif you wish to use its implementation.\\n\"},\n",
       "        {'param_name': 'columns',\n",
       "         'param_type': 'list, default=None',\n",
       "         'param_desc': 'If not None, only these columns will be read from the file.\\n'},\n",
       "        {'param_name': 'storage_options',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n\\nNew in version 1.3.0.\\n\\n'},\n",
       "        {'param_name': 'use_nullable_dtypes',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True, use dtypes that use pd.NA as missing value indicator\\nfor the resulting DataFrame. (only applicable for the pyarrow\\nengine)\\nAs new dtypes are added that support pd.NA in the future, the\\noutput with this option will change to use those dtypes.\\nNote: this is an experimental option, and behaviour (e.g. additional\\nsupport dtypes) may change without notice.\\n\\nDeprecated since version 2.0.\\n\\n'},\n",
       "        {'param_name': 'dtype_backend',\n",
       "         'param_type': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’',\n",
       "         'param_desc': 'Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'},\n",
       "        {'param_name': 'filesystem',\n",
       "         'param_type': 'fsspec or pyarrow filesystem, default None',\n",
       "         'param_desc': 'Filesystem object to use when reading the parquet file. Only implemented\\nfor engine=\"pyarrow\".\\n\\nNew in version 2.1.0.\\n\\n'},\n",
       "        {'param_name': 'filters',\n",
       "         'param_type': 'List[Tuple] or List[List[Tuple]], default None',\n",
       "         'param_desc': 'To filter out data.\\nFilter syntax: [[(column, op, val), …],…]\\nwhere op is [==, =, >, >=, <, <=, !=, in, not in]\\nThe innermost tuples are transposed into a set of filters applied\\nthrough an AND operation.\\nThe outer list combines these sets of filters through an OR\\noperation.\\nA single list of tuples can also be used, meaning that no OR\\noperation between set of filters is to be conducted.\\nUsing this argument will NOT result in row-wise filtering of the final\\npartitions unless engine=\"pyarrow\" is also specified. For\\nother engines, filtering is only performed at the partition level, that is,\\nto prevent the loading of some row-groups and/or files.\\n\\nNew in version 2.1.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.read_parquet',\n",
       "       'descriptions': 'Load a parquet object from the file path, returning a DataFrame.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'path': {'type': 'string',\n",
       "          'description': 'str, path object or file-like object. String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a binary read() function.\\nThe string could be a URL. Valid URL schemes include http, ftp, s3,\\ngs, and file. For file URLs, a host is expected. A local file could be:\\nfile://localhost/path/to/table.parquet.\\nA file URL can also be a path to a directory that contains multiple\\npartitioned parquet files. Both pyarrow and fastparquet support\\npaths to directories as well as file URLs. A directory path could be:\\nfile://localhost/path/to/tables or s3://bucket/partition_dir.\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'enum': ['auto', ' pyarrow', ' fastparquet'],\n",
       "          'description': \"{‘auto’, ‘pyarrow’, ‘fastparquet’}, default ‘auto’. Parquet library to use. If ‘auto’, then the option\\nio.parquet.engine is used. The default io.parquet.engine\\nbehavior is to try ‘pyarrow’, falling back to ‘fastparquet’ if\\n‘pyarrow’ is unavailable.\\nWhen using the 'pyarrow' engine and no storage options are provided\\nand a filesystem is implemented by both pyarrow.fs and fsspec\\n(e.g. “s3://”), then the pyarrow.fs filesystem is attempted first.\\nUse the filesystem keyword with an instantiated fsspec filesystem\\nif you wish to use its implementation.\\n\"},\n",
       "         'columns': {'type': 'array',\n",
       "          'description': 'list, default=None. If not None, only these columns will be read from the file.\\n'},\n",
       "         'storage_options': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n\\nNew in version 1.3.0.\\n\\n'},\n",
       "         'use_nullable_dtypes': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True, use dtypes that use pd.NA as missing value indicator\\nfor the resulting DataFrame. (only applicable for the pyarrow\\nengine)\\nAs new dtypes are added that support pd.NA in the future, the\\noutput with this option will change to use those dtypes.\\nNote: this is an experimental option, and behaviour (e.g. additional\\nsupport dtypes) may change without notice.\\n\\nDeprecated since version 2.0.\\n\\n'},\n",
       "         'dtype_backend': {'type': 'string',\n",
       "          'enum': ['numpy_nullable', ' pyarrow'],\n",
       "          'description': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’. Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'},\n",
       "         'filesystem': {'type': 'fsspec or pyarrow filesystem, default None',\n",
       "          'description': 'fsspec or pyarrow filesystem, default None. Filesystem object to use when reading the parquet file. Only implemented\\nfor engine=\"pyarrow\".\\n\\nNew in version 2.1.0.\\n\\n'},\n",
       "         'filters': {'type': 'List[Tuple] or List[List[Tuple]], default None',\n",
       "          'description': 'List[Tuple] or List[List[Tuple]], default None. To filter out data.\\nFilter syntax: [[(column, op, val), …],…]\\nwhere op is [==, =, >, >=, <, <=, !=, in, not in]\\nThe innermost tuples are transposed into a set of filters applied\\nthrough an AND operation.\\nThe outer list combines these sets of filters through an OR\\noperation.\\nA single list of tuples can also be used, meaning that no OR\\noperation between set of filters is to be conducted.\\nUsing this argument will NOT result in row-wise filtering of the final\\npartitions unless engine=\"pyarrow\" is also specified. For\\nother engines, filtering is only performed at the partition level, that is,\\nto prevent the loading of some row-groups and/or files.\\n\\nNew in version 2.1.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.to_parquet([path,\\xa0engine,\\xa0...])',\n",
       "      'func_desc': 'Write a DataFrame to the binary parquet format.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_parquet.html#pandas.DataFrame.to_parquet',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_parquet',\n",
       "       'full_function': \"DataFrame.to_parquet(path=None, *, engine='auto', compression='snappy', index=None, partition_cols=None, storage_options=None, **kwargs)\",\n",
       "       'function_text': 'Write a DataFrame to the binary parquet format. This function writes the dataframe as a parquet file. You can choose different parquet\\nbackends, and have the option of compression. See\\nthe user guide for more details.',\n",
       "       'parameter_names_desc': [{'param_name': 'path',\n",
       "         'param_type': 'str, path object, file-like object, or None, default None',\n",
       "         'param_desc': 'String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a binary write() function. If None, the result is\\nreturned as bytes. If a string or path, it will be used as Root Directory\\npath when writing a partitioned dataset.\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': '{‘auto’, ‘pyarrow’, ‘fastparquet’}, default ‘auto’',\n",
       "         'param_desc': 'Parquet library to use. If ‘auto’, then the option\\nio.parquet.engine is used. The default io.parquet.engine\\nbehavior is to try ‘pyarrow’, falling back to ‘fastparquet’ if\\n‘pyarrow’ is unavailable.\\n'},\n",
       "        {'param_name': 'compression',\n",
       "         'param_type': 'str or None, default ‘snappy’',\n",
       "         'param_desc': 'Name of the compression to use. Use None for no compression.\\nSupported options: ‘snappy’, ‘gzip’, ‘brotli’, ‘lz4’, ‘zstd’.\\n'},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'bool, default None',\n",
       "         'param_desc': 'If True, include the dataframe’s index(es) in the file output.\\nIf False, they will not be written to the file.\\nIf None, similar to True the dataframe’s index(es)\\nwill be saved. However, instead of being saved as values,\\nthe RangeIndex will be stored as a range in the metadata so it\\ndoesn’t require much space and is faster. Other indexes will\\nbe included as columns in the file output.\\n'},\n",
       "        {'param_name': 'partition_cols',\n",
       "         'param_type': 'list, optional, default None',\n",
       "         'param_desc': 'Column names by which to partition the dataset.\\nColumns are partitioned in the order they are given.\\nMust be None if path is not a string.\\n'},\n",
       "        {'param_name': 'storage_options',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.to_parquet',\n",
       "       'descriptions': 'Write a DataFrame to the binary parquet format. This function writes the dataframe as a parquet file. You can choose different parquet\\nbackends, and have the option of compression. See\\nthe user guide for more details.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'path': {'type': 'string',\n",
       "          'description': 'str, path object, file-like object, or None, default None. String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a binary write() function. If None, the result is\\nreturned as bytes. If a string or path, it will be used as Root Directory\\npath when writing a partitioned dataset.\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'enum': ['auto', ' pyarrow', ' fastparquet'],\n",
       "          'description': '{‘auto’, ‘pyarrow’, ‘fastparquet’}, default ‘auto’. Parquet library to use. If ‘auto’, then the option\\nio.parquet.engine is used. The default io.parquet.engine\\nbehavior is to try ‘pyarrow’, falling back to ‘fastparquet’ if\\n‘pyarrow’ is unavailable.\\n'},\n",
       "         'compression': {'type': 'string',\n",
       "          'description': 'str or None, default ‘snappy’. Name of the compression to use. Use None for no compression.\\nSupported options: ‘snappy’, ‘gzip’, ‘brotli’, ‘lz4’, ‘zstd’.\\n'},\n",
       "         'index': {'type': 'boolean',\n",
       "          'description': 'bool, default None. If True, include the dataframe’s index(es) in the file output.\\nIf False, they will not be written to the file.\\nIf None, similar to True the dataframe’s index(es)\\nwill be saved. However, instead of being saved as values,\\nthe RangeIndex will be stored as a range in the metadata so it\\ndoesn’t require much space and is faster. Other indexes will\\nbe included as columns in the file output.\\n'},\n",
       "         'partition_cols': {'type': 'array',\n",
       "          'description': 'list, optional, default None. Column names by which to partition the dataset.\\nColumns are partitioned in the order they are given.\\nMust be None if path is not a string.\\n'},\n",
       "         'storage_options': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'}},\n",
       "        'required': ['path=None']}}}]},\n",
       "   {'ORC': [{'func_name': 'read_orc(path[,\\xa0columns,\\xa0dtype_backend,\\xa0...])',\n",
       "      'func_desc': 'Load an ORC object from the file path, returning a DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.read_orc.html#pandas.read_orc',\n",
       "      'function_definitions': {'function_name': 'pandas.read_orc',\n",
       "       'full_function': 'pandas.read_orc(path, columns=None, dtype_backend=_NoDefault.no_default, filesystem=None, **kwargs)',\n",
       "       'function_text': 'Load an ORC object from the file path, returning a DataFrame.',\n",
       "       'parameter_names_desc': [{'param_name': 'path',\n",
       "         'param_type': 'str, path object, or file-like object',\n",
       "         'param_desc': 'String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a binary read() function. The string could be a URL.\\nValid URL schemes include http, ftp, s3, and file. For file URLs, a host is\\nexpected. A local file could be:\\nfile://localhost/path/to/table.orc.\\n'},\n",
       "        {'param_name': 'columns',\n",
       "         'param_type': 'list, default None',\n",
       "         'param_desc': 'If not None, only these columns will be read from the file.\\nOutput always follows the ordering of the file and not the columns list.\\nThis mirrors the original behaviour of\\npyarrow.orc.ORCFile.read().\\n'},\n",
       "        {'param_name': 'dtype_backend',\n",
       "         'param_type': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’',\n",
       "         'param_desc': 'Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'},\n",
       "        {'param_name': 'filesystem',\n",
       "         'param_type': 'fsspec or pyarrow filesystem, default None',\n",
       "         'param_desc': 'Filesystem object to use when reading the parquet file.\\n\\nNew in version 2.1.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.read_orc',\n",
       "       'descriptions': 'Load an ORC object from the file path, returning a DataFrame.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'path': {'type': 'string',\n",
       "          'description': 'str, path object, or file-like object. String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a binary read() function. The string could be a URL.\\nValid URL schemes include http, ftp, s3, and file. For file URLs, a host is\\nexpected. A local file could be:\\nfile://localhost/path/to/table.orc.\\n'},\n",
       "         'columns': {'type': 'array',\n",
       "          'description': 'list, default None. If not None, only these columns will be read from the file.\\nOutput always follows the ordering of the file and not the columns list.\\nThis mirrors the original behaviour of\\npyarrow.orc.ORCFile.read().\\n'},\n",
       "         'dtype_backend': {'type': 'string',\n",
       "          'enum': ['numpy_nullable', ' pyarrow'],\n",
       "          'description': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’. Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'},\n",
       "         'filesystem': {'type': 'fsspec or pyarrow filesystem, default None',\n",
       "          'description': 'fsspec or pyarrow filesystem, default None. Filesystem object to use when reading the parquet file.\\n\\nNew in version 2.1.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.to_orc([path,\\xa0engine,\\xa0index,\\xa0...])',\n",
       "      'func_desc': 'Write a DataFrame to the ORC format.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_orc.html#pandas.DataFrame.to_orc',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_orc',\n",
       "       'full_function': \"DataFrame.to_orc(path=None, *, engine='pyarrow', index=None, engine_kwargs=None)\",\n",
       "       'function_text': 'Write a DataFrame to the ORC format. New in version 1.5.0.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'SAS': [{'func_name': 'read_sas(filepath_or_buffer,\\xa0*[,\\xa0format,\\xa0...])',\n",
       "      'func_desc': 'Read SAS files stored as either XPORT or SAS7BDAT format files.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.read_sas.html#pandas.read_sas',\n",
       "      'function_definitions': {'function_name': 'pandas.read_sas',\n",
       "       'full_function': \"pandas.read_sas(filepath_or_buffer, *, format=None, index=None, encoding=None, chunksize=None, iterator=False, compression='infer')\",\n",
       "       'function_text': 'Read SAS files stored as either XPORT or SAS7BDAT format files.',\n",
       "       'parameter_names_desc': [{'param_name': 'filepath_or_buffer',\n",
       "         'param_type': 'str, path object, or file-like object',\n",
       "         'param_desc': 'String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a binary read() function. The string could be a URL.\\nValid URL schemes include http, ftp, s3, and file. For file URLs, a host is\\nexpected. A local file could be:\\nfile://localhost/path/to/table.sas7bdat.\\n'},\n",
       "        {'param_name': 'format',\n",
       "         'param_type': 'str {‘xport’, ‘sas7bdat’} or None',\n",
       "         'param_desc': 'If None, file format is inferred from file extension. If ‘xport’ or\\n‘sas7bdat’, uses the corresponding format.\\n'},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'identifier of index column, defaults to None',\n",
       "         'param_desc': 'Identifier of column that should be used as index of the DataFrame.\\n'},\n",
       "        {'param_name': 'encoding',\n",
       "         'param_type': 'str, default is None',\n",
       "         'param_desc': 'Encoding for text data. If None, text data are stored as raw bytes.\\n'},\n",
       "        {'param_name': 'chunksize',\n",
       "         'param_type': 'int',\n",
       "         'param_desc': 'Read file chunksize lines at a time, returns iterator.\\n'},\n",
       "        {'param_name': 'iterator',\n",
       "         'param_type': 'bool, defaults to False',\n",
       "         'param_desc': 'If True, returns an iterator for reading the file incrementally.\\n'},\n",
       "        {'param_name': 'compression',\n",
       "         'param_type': 'str or dict, default ‘infer’',\n",
       "         'param_desc': \"For on-the-fly decompression of on-disk data. If ‘infer’ and ‘filepath_or_buffer’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nIf using ‘zip’ or ‘tar’, the ZIP file must contain only one data file to be read in.\\nSet to None for no decompression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdDecompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for Zstandard decompression using a\\ncustom compression dictionary:\\ncompression={'method': 'zstd', 'dict_data': my_compression_dict}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.read_sas',\n",
       "       'descriptions': 'Read SAS files stored as either XPORT or SAS7BDAT format files.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'filepath_or_buffer': {'type': 'string',\n",
       "          'description': 'str, path object, or file-like object. String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a binary read() function. The string could be a URL.\\nValid URL schemes include http, ftp, s3, and file. For file URLs, a host is\\nexpected. A local file could be:\\nfile://localhost/path/to/table.sas7bdat.\\n'},\n",
       "         'format': {'type': 'string',\n",
       "          'description': 'str {‘xport’, ‘sas7bdat’} or None. If None, file format is inferred from file extension. If ‘xport’ or\\n‘sas7bdat’, uses the corresponding format.\\n'},\n",
       "         'index': {'type': 'identifier of index column, defaults to None',\n",
       "          'description': 'identifier of index column, defaults to None. Identifier of column that should be used as index of the DataFrame.\\n'},\n",
       "         'encoding': {'type': 'string',\n",
       "          'description': 'str, default is None. Encoding for text data. If None, text data are stored as raw bytes.\\n'},\n",
       "         'chunksize': {'type': 'integer',\n",
       "          'description': 'int. Read file chunksize lines at a time, returns iterator.\\n'},\n",
       "         'iterator': {'type': 'boolean',\n",
       "          'description': 'bool, defaults to False. If True, returns an iterator for reading the file incrementally.\\n'},\n",
       "         'compression': {'type': 'string',\n",
       "          'description': \"str or dict, default ‘infer’. For on-the-fly decompression of on-disk data. If ‘infer’ and ‘filepath_or_buffer’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nIf using ‘zip’ or ‘tar’, the ZIP file must contain only one data file to be read in.\\nSet to None for no decompression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdDecompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for Zstandard decompression using a\\ncustom compression dictionary:\\ncompression={'method': 'zstd', 'dict_data': my_compression_dict}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\n\\n\"}},\n",
       "        'required': ['filepath_or_buffer']}}}]},\n",
       "   {'SPSS': [{'func_name': 'read_spss(path[,\\xa0usecols,\\xa0...])',\n",
       "      'func_desc': 'Load an SPSS file from the file path, returning a DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.read_spss.html#pandas.read_spss',\n",
       "      'function_definitions': {'function_name': 'pandas.read_spss',\n",
       "       'full_function': 'pandas.read_spss(path, usecols=None, convert_categoricals=True, dtype_backend=_NoDefault.no_default)',\n",
       "       'function_text': 'Load an SPSS file from the file path, returning a DataFrame.',\n",
       "       'parameter_names_desc': [{'param_name': 'path',\n",
       "         'param_type': 'str or Path',\n",
       "         'param_desc': 'File path.\\n'},\n",
       "        {'param_name': 'usecols',\n",
       "         'param_type': 'list-like, optional',\n",
       "         'param_desc': 'Return a subset of the columns. If None, return all columns.\\n'},\n",
       "        {'param_name': 'convert_categoricals',\n",
       "         'param_type': 'bool, default is True',\n",
       "         'param_desc': 'Convert categorical columns into pd.Categorical.\\n'},\n",
       "        {'param_name': 'dtype_backend',\n",
       "         'param_type': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’',\n",
       "         'param_desc': 'Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.read_spss',\n",
       "       'descriptions': 'Load an SPSS file from the file path, returning a DataFrame.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'path': {'type': 'string',\n",
       "          'description': 'str or Path. File path.\\n'},\n",
       "         'usecols': {'type': 'array',\n",
       "          'description': 'list-like, optional. Return a subset of the columns. If None, return all columns.\\n'},\n",
       "         'convert_categoricals': {'type': 'boolean',\n",
       "          'description': 'bool, default is True. Convert categorical columns into pd.Categorical.\\n'},\n",
       "         'dtype_backend': {'type': 'string',\n",
       "          'enum': ['numpy_nullable', ' pyarrow'],\n",
       "          'description': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’. Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'SQL': [{'func_name': 'read_sql_table(table_name,\\xa0con[,\\xa0schema,\\xa0...])',\n",
       "      'func_desc': 'Read SQL database table into a DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.read_sql_table.html#pandas.read_sql_table',\n",
       "      'function_definitions': {'function_name': 'pandas.read_sql_table',\n",
       "       'full_function': 'pandas.read_sql_table(table_name, con, schema=None, index_col=None, coerce_float=True, parse_dates=None, columns=None, chunksize=None, dtype_backend=_NoDefault.no_default)',\n",
       "       'function_text': 'Read SQL database table into a DataFrame. Given a table name and a SQLAlchemy connectable, returns a DataFrame.\\nThis function does not support DBAPI connections.',\n",
       "       'parameter_names_desc': [{'param_name': 'table_name',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'Name of SQL table in database.\\n'},\n",
       "        {'param_name': 'con',\n",
       "         'param_type': 'SQLAlchemy connectable or str',\n",
       "         'param_desc': 'A database URI could be provided as str.\\nSQLite DBAPI connection mode not supported.\\n'},\n",
       "        {'param_name': 'schema',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'Name of SQL schema in database to query (if database flavor\\nsupports this). Uses default schema if None (default).\\n'},\n",
       "        {'param_name': 'index_col',\n",
       "         'param_type': 'str or list of str, optional, default: None',\n",
       "         'param_desc': 'Column(s) to set as index(MultiIndex).\\n'},\n",
       "        {'param_name': 'coerce_float',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Attempts to convert values of non-string, non-numeric objects (like\\ndecimal.Decimal) to floating point. Can result in loss of Precision.\\n'},\n",
       "        {'param_name': 'parse_dates',\n",
       "         'param_type': 'list or dict, default None',\n",
       "         'param_desc': '\\nList of column names to parse as dates.\\nDict of {column_name: format string} where format string is\\nstrftime compatible in case of parsing string times or is one of\\n(D, s, ns, ms, us) in case of parsing integer timestamps.\\nDict of {column_name: arg dict}, where the arg dict corresponds\\nto the keyword arguments of pandas.to_datetime()\\nEspecially useful with databases without native Datetime support,\\nsuch as SQLite.\\n\\n'},\n",
       "        {'param_name': 'columns',\n",
       "         'param_type': 'list, default None',\n",
       "         'param_desc': 'List of column names to select from SQL table.\\n'},\n",
       "        {'param_name': 'chunksize',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'If specified, returns an iterator where chunksize is the number of\\nrows to include in each chunk.\\n'},\n",
       "        {'param_name': 'dtype_backend',\n",
       "         'param_type': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’',\n",
       "         'param_desc': 'Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.read_sql_table',\n",
       "       'descriptions': 'Read SQL database table into a DataFrame. Given a table name and a SQLAlchemy connectable, returns a DataFrame.\\nThis function does not support DBAPI connections.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'table_name': {'type': 'string',\n",
       "          'description': 'str. Name of SQL table in database.\\n'},\n",
       "         'con': {'type': 'string',\n",
       "          'description': 'SQLAlchemy connectable or str. A database URI could be provided as str.\\nSQLite DBAPI connection mode not supported.\\n'},\n",
       "         'schema': {'type': 'string',\n",
       "          'description': 'str, default None. Name of SQL schema in database to query (if database flavor\\nsupports this). Uses default schema if None (default).\\n'},\n",
       "         'index_col': {'type': 'string',\n",
       "          'description': 'str or list of str, optional, default: None. Column(s) to set as index(MultiIndex).\\n'},\n",
       "         'coerce_float': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Attempts to convert values of non-string, non-numeric objects (like\\ndecimal.Decimal) to floating point. Can result in loss of Precision.\\n'},\n",
       "         'parse_dates': {'type': 'array',\n",
       "          'description': 'list or dict, default None. \\nList of column names to parse as dates.\\nDict of {column_name: format string} where format string is\\nstrftime compatible in case of parsing string times or is one of\\n(D, s, ns, ms, us) in case of parsing integer timestamps.\\nDict of {column_name: arg dict}, where the arg dict corresponds\\nto the keyword arguments of pandas.to_datetime()\\nEspecially useful with databases without native Datetime support,\\nsuch as SQLite.\\n\\n'},\n",
       "         'columns': {'type': 'array',\n",
       "          'description': 'list, default None. List of column names to select from SQL table.\\n'},\n",
       "         'chunksize': {'type': 'integer',\n",
       "          'description': 'int, default None. If specified, returns an iterator where chunksize is the number of\\nrows to include in each chunk.\\n'},\n",
       "         'dtype_backend': {'type': 'string',\n",
       "          'enum': ['numpy_nullable', ' pyarrow'],\n",
       "          'description': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’. Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'read_sql(sql,\\xa0con[,\\xa0index_col,\\xa0...])',\n",
       "      'func_desc': 'Read SQL query or database table into a DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.read_sql.html#pandas.read_sql',\n",
       "      'function_definitions': {'function_name': 'pandas.read_sql',\n",
       "       'full_function': 'pandas.read_sql(sql, con, index_col=None, coerce_float=True, params=None, parse_dates=None, columns=None, chunksize=None, dtype_backend=_NoDefault.no_default, dtype=None)',\n",
       "       'function_text': 'Read SQL query or database table into a DataFrame. This function is a convenience wrapper around read_sql_table and\\nread_sql_query (for backward compatibility). It will delegate\\nto the specific function depending on the provided input. A SQL query\\nwill be routed to read_sql_query, while a database table name will\\nbe routed to read_sql_table. Note that the delegated function might\\nhave more specific notes about their functionality not listed here.',\n",
       "       'parameter_names_desc': [{'param_name': 'sql',\n",
       "         'param_type': 'str or SQLAlchemy Selectable (select or text object)',\n",
       "         'param_desc': 'SQL query to be executed or a table name.\\n'},\n",
       "        {'param_name': 'con',\n",
       "         'param_type': 'ADBC Connection, SQLAlchemy connectable, str, or sqlite3 connection',\n",
       "         'param_desc': 'ADBC provides high performance I/O with native type support, where available.\\nUsing SQLAlchemy makes it possible to use any DB supported by that\\nlibrary. If a DBAPI2 object, only sqlite3 is supported. The user is responsible\\nfor engine disposal and connection closure for the ADBC connection and\\nSQLAlchemy connectable; str connections are closed automatically. See\\nhere.\\n'},\n",
       "        {'param_name': 'index_col',\n",
       "         'param_type': 'str or list of str, optional, default: None',\n",
       "         'param_desc': 'Column(s) to set as index(MultiIndex).\\n'},\n",
       "        {'param_name': 'coerce_float',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Attempts to convert values of non-string, non-numeric objects (like\\ndecimal.Decimal) to floating point, useful for SQL result sets.\\n'},\n",
       "        {'param_name': 'params',\n",
       "         'param_type': 'list, tuple or dict, optional, default: None',\n",
       "         'param_desc': 'List of parameters to pass to execute method. The syntax used\\nto pass parameters is database driver dependent. Check your\\ndatabase driver documentation for which of the five syntax styles,\\ndescribed in PEP 249’s paramstyle, is supported.\\nEg. for psycopg2, uses %(name)s so use params={‘name’ : ‘value’}.\\n'},\n",
       "        {'param_name': 'parse_dates',\n",
       "         'param_type': 'list or dict, default: None',\n",
       "         'param_desc': '\\nList of column names to parse as dates.\\nDict of {column_name: format string} where format string is\\nstrftime compatible in case of parsing string times, or is one of\\n(D, s, ns, ms, us) in case of parsing integer timestamps.\\nDict of {column_name: arg dict}, where the arg dict corresponds\\nto the keyword arguments of pandas.to_datetime()\\nEspecially useful with databases without native Datetime support,\\nsuch as SQLite.\\n\\n'},\n",
       "        {'param_name': 'columns',\n",
       "         'param_type': 'list, default: None',\n",
       "         'param_desc': 'List of column names to select from SQL table (only used when reading\\na table).\\n'},\n",
       "        {'param_name': 'chunksize',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'If specified, return an iterator where chunksize is the\\nnumber of rows to include in each chunk.\\n'},\n",
       "        {'param_name': 'dtype_backend',\n",
       "         'param_type': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’',\n",
       "         'param_desc': 'Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'},\n",
       "        {'param_name': 'dtype',\n",
       "         'param_type': 'Type name or dict of columns',\n",
       "         'param_desc': 'Data type for data or columns. E.g. np.float64 or\\n{‘a’: np.float64, ‘b’: np.int32, ‘c’: ‘Int64’}.\\nThe argument is ignored if a table is passed instead of a query.\\n\\nNew in version 2.0.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.read_sql',\n",
       "       'descriptions': 'Read SQL query or database table into a DataFrame. This function is a convenience wrapper around read_sql_table and\\nread_sql_query (for backward compatibility). It will delegate\\nto the specific function depending on the provided input. A SQL query\\nwill be routed to read_sql_query, while a database table name will\\nbe routed to read_sql_table. Note that the delegated function might\\nhave more specific notes about their functionality not listed here.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'sql': {'type': 'string',\n",
       "          'description': 'str or SQLAlchemy Selectable (select or text object). SQL query to be executed or a table name.\\n'},\n",
       "         'con': {'type': 'string',\n",
       "          'description': 'ADBC Connection, SQLAlchemy connectable, str, or sqlite3 connection. ADBC provides high performance I/O with native type support, where available.\\nUsing SQLAlchemy makes it possible to use any DB supported by that\\nlibrary. If a DBAPI2 object, only sqlite3 is supported. The user is responsible\\nfor engine disposal and connection closure for the ADBC connection and\\nSQLAlchemy connectable; str connections are closed automatically. See\\nhere.\\n'},\n",
       "         'index_col': {'type': 'string',\n",
       "          'description': 'str or list of str, optional, default: None. Column(s) to set as index(MultiIndex).\\n'},\n",
       "         'coerce_float': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Attempts to convert values of non-string, non-numeric objects (like\\ndecimal.Decimal) to floating point, useful for SQL result sets.\\n'},\n",
       "         'params': {'type': 'array',\n",
       "          'description': 'list, tuple or dict, optional, default: None. List of parameters to pass to execute method. The syntax used\\nto pass parameters is database driver dependent. Check your\\ndatabase driver documentation for which of the five syntax styles,\\ndescribed in PEP 249’s paramstyle, is supported.\\nEg. for psycopg2, uses %(name)s so use params={‘name’ : ‘value’}.\\n'},\n",
       "         'parse_dates': {'type': 'array',\n",
       "          'description': 'list or dict, default: None. \\nList of column names to parse as dates.\\nDict of {column_name: format string} where format string is\\nstrftime compatible in case of parsing string times, or is one of\\n(D, s, ns, ms, us) in case of parsing integer timestamps.\\nDict of {column_name: arg dict}, where the arg dict corresponds\\nto the keyword arguments of pandas.to_datetime()\\nEspecially useful with databases without native Datetime support,\\nsuch as SQLite.\\n\\n'},\n",
       "         'columns': {'type': 'array',\n",
       "          'description': 'list, default: None. List of column names to select from SQL table (only used when reading\\na table).\\n'},\n",
       "         'chunksize': {'type': 'integer',\n",
       "          'description': 'int, default None. If specified, return an iterator where chunksize is the\\nnumber of rows to include in each chunk.\\n'},\n",
       "         'dtype_backend': {'type': 'string',\n",
       "          'enum': ['numpy_nullable', ' pyarrow'],\n",
       "          'description': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’. Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'},\n",
       "         'dtype': {'type': 'Type name or dict of columns',\n",
       "          'description': 'Type name or dict of columns. Data type for data or columns. E.g. np.float64 or\\n{‘a’: np.float64, ‘b’: np.int32, ‘c’: ‘Int64’}.\\nThe argument is ignored if a table is passed instead of a query.\\n\\nNew in version 2.0.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'read_sql_query(sql,\\xa0con[,\\xa0index_col,\\xa0...])',\n",
       "      'func_desc': 'Read SQL query into a DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.read_sql_query.html#pandas.read_sql_query',\n",
       "      'function_definitions': {'function_name': 'pandas.read_sql_query',\n",
       "       'full_function': 'pandas.read_sql_query(sql, con, index_col=None, coerce_float=True, params=None, parse_dates=None, chunksize=None, dtype=None, dtype_backend=_NoDefault.no_default)',\n",
       "       'function_text': 'Read SQL query into a DataFrame. Returns a DataFrame corresponding to the result set of the query\\nstring. Optionally provide an index_col parameter to use one of the\\ncolumns as the index, otherwise default integer index will be used.',\n",
       "       'parameter_names_desc': [{'param_name': 'sql',\n",
       "         'param_type': 'str SQL query or SQLAlchemy Selectable (select or text object)',\n",
       "         'param_desc': 'SQL query to be executed.\\n'},\n",
       "        {'param_name': 'con',\n",
       "         'param_type': 'SQLAlchemy connectable, str, or sqlite3 connection',\n",
       "         'param_desc': 'Using SQLAlchemy makes it possible to use any DB supported by that\\nlibrary. If a DBAPI2 object, only sqlite3 is supported.\\n'},\n",
       "        {'param_name': 'index_col',\n",
       "         'param_type': 'str or list of str, optional, default: None',\n",
       "         'param_desc': 'Column(s) to set as index(MultiIndex).\\n'},\n",
       "        {'param_name': 'coerce_float',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Attempts to convert values of non-string, non-numeric objects (like\\ndecimal.Decimal) to floating point. Useful for SQL result sets.\\n'},\n",
       "        {'param_name': 'params',\n",
       "         'param_type': 'list, tuple or mapping, optional, default: None',\n",
       "         'param_desc': 'List of parameters to pass to execute method. The syntax used\\nto pass parameters is database driver dependent. Check your\\ndatabase driver documentation for which of the five syntax styles,\\ndescribed in PEP 249’s paramstyle, is supported.\\nEg. for psycopg2, uses %(name)s so use params={‘name’ : ‘value’}.\\n'},\n",
       "        {'param_name': 'parse_dates',\n",
       "         'param_type': 'list or dict, default: None',\n",
       "         'param_desc': '\\nList of column names to parse as dates.\\nDict of {column_name: format string} where format string is\\nstrftime compatible in case of parsing string times, or is one of\\n(D, s, ns, ms, us) in case of parsing integer timestamps.\\nDict of {column_name: arg dict}, where the arg dict corresponds\\nto the keyword arguments of pandas.to_datetime()\\nEspecially useful with databases without native Datetime support,\\nsuch as SQLite.\\n\\n'},\n",
       "        {'param_name': 'chunksize',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'If specified, return an iterator where chunksize is the number of\\nrows to include in each chunk.\\n'},\n",
       "        {'param_name': 'dtype',\n",
       "         'param_type': 'Type name or dict of columns',\n",
       "         'param_desc': 'Data type for data or columns. E.g. np.float64 or\\n{‘a’: np.float64, ‘b’: np.int32, ‘c’: ‘Int64’}.\\n\\nNew in version 1.3.0.\\n\\n'},\n",
       "        {'param_name': 'dtype_backend',\n",
       "         'param_type': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’',\n",
       "         'param_desc': 'Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.read_sql_query',\n",
       "       'descriptions': 'Read SQL query into a DataFrame. Returns a DataFrame corresponding to the result set of the query\\nstring. Optionally provide an index_col parameter to use one of the\\ncolumns as the index, otherwise default integer index will be used.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'sql': {'type': 'string',\n",
       "          'description': 'str SQL query or SQLAlchemy Selectable (select or text object). SQL query to be executed.\\n'},\n",
       "         'con': {'type': 'string',\n",
       "          'description': 'SQLAlchemy connectable, str, or sqlite3 connection. Using SQLAlchemy makes it possible to use any DB supported by that\\nlibrary. If a DBAPI2 object, only sqlite3 is supported.\\n'},\n",
       "         'index_col': {'type': 'string',\n",
       "          'description': 'str or list of str, optional, default: None. Column(s) to set as index(MultiIndex).\\n'},\n",
       "         'coerce_float': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Attempts to convert values of non-string, non-numeric objects (like\\ndecimal.Decimal) to floating point. Useful for SQL result sets.\\n'},\n",
       "         'params': {'type': 'array',\n",
       "          'description': 'list, tuple or mapping, optional, default: None. List of parameters to pass to execute method. The syntax used\\nto pass parameters is database driver dependent. Check your\\ndatabase driver documentation for which of the five syntax styles,\\ndescribed in PEP 249’s paramstyle, is supported.\\nEg. for psycopg2, uses %(name)s so use params={‘name’ : ‘value’}.\\n'},\n",
       "         'parse_dates': {'type': 'array',\n",
       "          'description': 'list or dict, default: None. \\nList of column names to parse as dates.\\nDict of {column_name: format string} where format string is\\nstrftime compatible in case of parsing string times, or is one of\\n(D, s, ns, ms, us) in case of parsing integer timestamps.\\nDict of {column_name: arg dict}, where the arg dict corresponds\\nto the keyword arguments of pandas.to_datetime()\\nEspecially useful with databases without native Datetime support,\\nsuch as SQLite.\\n\\n'},\n",
       "         'chunksize': {'type': 'integer',\n",
       "          'description': 'int, default None. If specified, return an iterator where chunksize is the number of\\nrows to include in each chunk.\\n'},\n",
       "         'dtype': {'type': 'Type name or dict of columns',\n",
       "          'description': 'Type name or dict of columns. Data type for data or columns. E.g. np.float64 or\\n{‘a’: np.float64, ‘b’: np.int32, ‘c’: ‘Int64’}.\\n\\nNew in version 1.3.0.\\n\\n'},\n",
       "         'dtype_backend': {'type': 'string',\n",
       "          'enum': ['numpy_nullable', ' pyarrow'],\n",
       "          'description': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’. Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.to_sql(name,\\xa0con,\\xa0*[,\\xa0schema,\\xa0...])',\n",
       "      'func_desc': 'Write records stored in a DataFrame to a SQL database.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_sql.html#pandas.DataFrame.to_sql',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_sql',\n",
       "       'full_function': \"DataFrame.to_sql(name, con, *, schema=None, if_exists='fail', index=True, index_label=None, chunksize=None, dtype=None, method=None)\",\n",
       "       'function_text': 'Write records stored in a DataFrame to a SQL database. Databases supported by SQLAlchemy [1] are supported. Tables can be\\nnewly created, appended to, or overwritten.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'Google BigQuery': [{'func_name': 'read_gbq(query[,\\xa0project_id,\\xa0index_col,\\xa0...])',\n",
       "      'func_desc': '(DEPRECATED) Load data from Google BigQuery.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.read_gbq.html#pandas.read_gbq',\n",
       "      'function_definitions': {'function_name': 'pandas.read_gbq',\n",
       "       'full_function': 'pandas.read_gbq(query, project_id=None, index_col=None, col_order=None, reauth=False, auth_local_webserver=True, dialect=None, location=None, configuration=None, credentials=None, use_bqstorage_api=None, max_results=None, progress_bar_type=None)',\n",
       "       'function_text': 'Load data from Google BigQuery. Deprecated since version 2.2.0: Please use pandas_gbq.read_gbq instead. This function requires the pandas-gbq package. See the How to authenticate with Google BigQuery\\nguide for authentication instructions.',\n",
       "       'parameter_names_desc': [{'param_name': 'query',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'SQL-Like Query to return data values.\\n'},\n",
       "        {'param_name': 'project_id',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Google BigQuery Account project ID. Optional when available from\\nthe environment.\\n'},\n",
       "        {'param_name': 'index_col',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Name of result column to use for index in results DataFrame.\\n'},\n",
       "        {'param_name': 'col_order',\n",
       "         'param_type': 'list(str), optional',\n",
       "         'param_desc': 'List of BigQuery column names in the desired order for results\\nDataFrame.\\n'},\n",
       "        {'param_name': 'reauth',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Force Google BigQuery to re-authenticate the user. This is useful\\nif multiple accounts are used.\\n'},\n",
       "        {'param_name': 'auth_local_webserver',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Use the local webserver flow instead of the console flow\\nwhen getting user credentials.\\nNew in version 0.2.0 of pandas-gbq.\\n\\nChanged in version 1.5.0: Default value is changed to True. Google has deprecated the\\nauth_local_webserver = False “out of band” (copy-paste)\\nflow.\\n\\n'},\n",
       "        {'param_name': 'dialect',\n",
       "         'param_type': 'str, default ‘legacy’',\n",
       "         'param_desc': \"Note: The default value is changing to ‘standard’ in a future version.\\nSQL syntax dialect to use. Value can be one of:\\n\\n'legacy'Use BigQuery’s legacy SQL dialect. For more information see\\nBigQuery Legacy SQL Reference.\\n\\n'standard'Use BigQuery’s standard SQL, which is\\ncompliant with the SQL 2011 standard. For more information\\nsee BigQuery Standard SQL Reference.\\n\\n\\n\"},\n",
       "        {'param_name': 'location',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Location where the query job should run. See the BigQuery locations\\ndocumentation for a\\nlist of available locations. The location must match that of any\\ndatasets used in the query.\\nNew in version 0.5.0 of pandas-gbq.\\n'},\n",
       "        {'param_name': 'configuration',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Query config parameters for job processing.\\nFor example:\\n\\nconfiguration = {‘query’: {‘useQueryCache’: False}}\\n\\nFor more information see BigQuery REST API Reference.\\n'},\n",
       "        {'param_name': 'credentials',\n",
       "         'param_type': 'google.auth.credentials.Credentials, optional',\n",
       "         'param_desc': 'Credentials for accessing Google APIs. Use this parameter to override\\ndefault credentials, such as to use Compute Engine\\ngoogle.auth.compute_engine.Credentials or Service Account\\ngoogle.oauth2.service_account.Credentials directly.\\nNew in version 0.8.0 of pandas-gbq.\\n'},\n",
       "        {'param_name': 'use_bqstorage_api',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Use the BigQuery Storage API to\\ndownload query results quickly, but at an increased cost. To use this\\nAPI, first enable it in the Cloud Console.\\nYou must also have the bigquery.readsessions.create\\npermission on the project you are billing queries to.\\nThis feature requires version 0.10.0 or later of the pandas-gbq\\npackage. It also requires the google-cloud-bigquery-storage and\\nfastavro packages.\\n'},\n",
       "        {'param_name': 'max_results',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'If set, limit the maximum number of rows to fetch from the query\\nresults.\\n'},\n",
       "        {'param_name': 'progress_bar_type',\n",
       "         'param_type': 'Optional, str',\n",
       "         'param_desc': \"If set, use the tqdm library to\\ndisplay a progress bar while the data downloads. Install the\\ntqdm package to use this feature.\\nPossible values of progress_bar_type include:\\n\\nNoneNo progress bar.\\n\\n'tqdm'Use the tqdm.tqdm() function to print a progress bar\\nto sys.stderr.\\n\\n'tqdm_notebook'Use the tqdm.tqdm_notebook() function to display a\\nprogress bar as a Jupyter notebook widget.\\n\\n'tqdm_gui'Use the tqdm.tqdm_gui() function to display a\\nprogress bar as a graphical dialog box.\\n\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.read_gbq',\n",
       "       'descriptions': 'Load data from Google BigQuery. Deprecated since version 2.2.0: Please use pandas_gbq.read_gbq instead. This function requires the pandas-gbq package. See the How to authenticate with Google BigQuery\\nguide for authentication instructions.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'query': {'type': 'string',\n",
       "          'description': 'str. SQL-Like Query to return data values.\\n'},\n",
       "         'project_id': {'type': 'string',\n",
       "          'description': 'str, optional. Google BigQuery Account project ID. Optional when available from\\nthe environment.\\n'},\n",
       "         'index_col': {'type': 'string',\n",
       "          'description': 'str, optional. Name of result column to use for index in results DataFrame.\\n'},\n",
       "         'col_order': {'type': 'string',\n",
       "          'description': 'list(str), optional. List of BigQuery column names in the desired order for results\\nDataFrame.\\n'},\n",
       "         'reauth': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Force Google BigQuery to re-authenticate the user. This is useful\\nif multiple accounts are used.\\n'},\n",
       "         'auth_local_webserver': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Use the local webserver flow instead of the console flow\\nwhen getting user credentials.\\nNew in version 0.2.0 of pandas-gbq.\\n\\nChanged in version 1.5.0: Default value is changed to True. Google has deprecated the\\nauth_local_webserver = False “out of band” (copy-paste)\\nflow.\\n\\n'},\n",
       "         'dialect': {'type': 'string',\n",
       "          'description': \"str, default ‘legacy’. Note: The default value is changing to ‘standard’ in a future version.\\nSQL syntax dialect to use. Value can be one of:\\n\\n'legacy'Use BigQuery’s legacy SQL dialect. For more information see\\nBigQuery Legacy SQL Reference.\\n\\n'standard'Use BigQuery’s standard SQL, which is\\ncompliant with the SQL 2011 standard. For more information\\nsee BigQuery Standard SQL Reference.\\n\\n\\n\"},\n",
       "         'location': {'type': 'string',\n",
       "          'description': 'str, optional. Location where the query job should run. See the BigQuery locations\\ndocumentation for a\\nlist of available locations. The location must match that of any\\ndatasets used in the query.\\nNew in version 0.5.0 of pandas-gbq.\\n'},\n",
       "         'configuration': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Query config parameters for job processing.\\nFor example:\\n\\nconfiguration = {‘query’: {‘useQueryCache’: False}}\\n\\nFor more information see BigQuery REST API Reference.\\n'},\n",
       "         'credentials': {'type': 'google.auth.credentials.Credentials, optional',\n",
       "          'description': 'google.auth.credentials.Credentials, optional. Credentials for accessing Google APIs. Use this parameter to override\\ndefault credentials, such as to use Compute Engine\\ngoogle.auth.compute_engine.Credentials or Service Account\\ngoogle.oauth2.service_account.Credentials directly.\\nNew in version 0.8.0 of pandas-gbq.\\n'},\n",
       "         'use_bqstorage_api': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Use the BigQuery Storage API to\\ndownload query results quickly, but at an increased cost. To use this\\nAPI, first enable it in the Cloud Console.\\nYou must also have the bigquery.readsessions.create\\npermission on the project you are billing queries to.\\nThis feature requires version 0.10.0 or later of the pandas-gbq\\npackage. It also requires the google-cloud-bigquery-storage and\\nfastavro packages.\\n'},\n",
       "         'max_results': {'type': 'integer',\n",
       "          'description': 'int, optional. If set, limit the maximum number of rows to fetch from the query\\nresults.\\n'},\n",
       "         'progress_bar_type': {'type': 'string',\n",
       "          'description': \"Optional, str. If set, use the tqdm library to\\ndisplay a progress bar while the data downloads. Install the\\ntqdm package to use this feature.\\nPossible values of progress_bar_type include:\\n\\nNoneNo progress bar.\\n\\n'tqdm'Use the tqdm.tqdm() function to print a progress bar\\nto sys.stderr.\\n\\n'tqdm_notebook'Use the tqdm.tqdm_notebook() function to display a\\nprogress bar as a Jupyter notebook widget.\\n\\n'tqdm_gui'Use the tqdm.tqdm_gui() function to display a\\nprogress bar as a graphical dialog box.\\n\\n\\n\"}},\n",
       "        'required': []}}}]},\n",
       "   {'STATA': [{'func_name': 'read_stata(filepath_or_buffer,\\xa0*[,\\xa0...])',\n",
       "      'func_desc': 'Read Stata file into DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.read_stata.html#pandas.read_stata',\n",
       "      'function_definitions': {'function_name': 'pandas.read_stata',\n",
       "       'full_function': \"pandas.read_stata(filepath_or_buffer, *, convert_dates=True, convert_categoricals=True, index_col=None, convert_missing=False, preserve_dtypes=True, columns=None, order_categoricals=True, chunksize=None, iterator=False, compression='infer', storage_options=None)\",\n",
       "       'function_text': 'Read Stata file into DataFrame.',\n",
       "       'parameter_names_desc': [{'param_name': 'filepath_or_buffer',\n",
       "         'param_type': 'str, path object or file-like object',\n",
       "         'param_desc': 'Any valid string path is acceptable. The string could be a URL. Valid\\nURL schemes include http, ftp, s3, and file. For file URLs, a host is\\nexpected. A local file could be: file://localhost/path/to/table.dta.\\nIf you want to pass in a path object, pandas accepts any os.PathLike.\\nBy file-like object, we refer to objects with a read() method,\\nsuch as a file handle (e.g. via builtin open function)\\nor StringIO.\\n'},\n",
       "        {'param_name': 'convert_dates',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Convert date variables to DataFrame time values.\\n'},\n",
       "        {'param_name': 'convert_categoricals',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Read value labels and convert columns to Categorical/Factor variables.\\n'},\n",
       "        {'param_name': 'index_col',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Column to set as index.\\n'},\n",
       "        {'param_name': 'convert_missing',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Flag indicating whether to convert missing values to their Stata\\nrepresentations. If False, missing values are replaced with nan.\\nIf True, columns containing missing values are returned with\\nobject data types and missing values are represented by\\nStataMissingValue objects.\\n'},\n",
       "        {'param_name': 'preserve_dtypes',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Preserve Stata datatypes. If False, numeric data are upcast to pandas\\ndefault types for foreign data (float64 or int64).\\n'},\n",
       "        {'param_name': 'columns',\n",
       "         'param_type': 'list or None',\n",
       "         'param_desc': 'Columns to retain. Columns will be returned in the given order. None\\nreturns all columns.\\n'},\n",
       "        {'param_name': 'order_categoricals',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Flag indicating whether converted categorical data are ordered.\\n'},\n",
       "        {'param_name': 'chunksize',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'Return StataReader object for iterations, returns chunks with\\ngiven number of lines.\\n'},\n",
       "        {'param_name': 'iterator',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Return StataReader object.\\n'},\n",
       "        {'param_name': 'compression',\n",
       "         'param_type': 'str or dict, default ‘infer’',\n",
       "         'param_desc': \"For on-the-fly decompression of on-disk data. If ‘infer’ and ‘filepath_or_buffer’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nIf using ‘zip’ or ‘tar’, the ZIP file must contain only one data file to be read in.\\nSet to None for no decompression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdDecompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for Zstandard decompression using a\\ncustom compression dictionary:\\ncompression={'method': 'zstd', 'dict_data': my_compression_dict}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\n\\n\"},\n",
       "        {'param_name': 'storage_options',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.read_stata',\n",
       "       'descriptions': 'Read Stata file into DataFrame.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'filepath_or_buffer': {'type': 'string',\n",
       "          'description': 'str, path object or file-like object. Any valid string path is acceptable. The string could be a URL. Valid\\nURL schemes include http, ftp, s3, and file. For file URLs, a host is\\nexpected. A local file could be: file://localhost/path/to/table.dta.\\nIf you want to pass in a path object, pandas accepts any os.PathLike.\\nBy file-like object, we refer to objects with a read() method,\\nsuch as a file handle (e.g. via builtin open function)\\nor StringIO.\\n'},\n",
       "         'convert_dates': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Convert date variables to DataFrame time values.\\n'},\n",
       "         'convert_categoricals': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Read value labels and convert columns to Categorical/Factor variables.\\n'},\n",
       "         'index_col': {'type': 'string',\n",
       "          'description': 'str, optional. Column to set as index.\\n'},\n",
       "         'convert_missing': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Flag indicating whether to convert missing values to their Stata\\nrepresentations. If False, missing values are replaced with nan.\\nIf True, columns containing missing values are returned with\\nobject data types and missing values are represented by\\nStataMissingValue objects.\\n'},\n",
       "         'preserve_dtypes': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Preserve Stata datatypes. If False, numeric data are upcast to pandas\\ndefault types for foreign data (float64 or int64).\\n'},\n",
       "         'columns': {'type': 'array',\n",
       "          'description': 'list or None. Columns to retain. Columns will be returned in the given order. None\\nreturns all columns.\\n'},\n",
       "         'order_categoricals': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Flag indicating whether converted categorical data are ordered.\\n'},\n",
       "         'chunksize': {'type': 'integer',\n",
       "          'description': 'int, default None. Return StataReader object for iterations, returns chunks with\\ngiven number of lines.\\n'},\n",
       "         'iterator': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Return StataReader object.\\n'},\n",
       "         'compression': {'type': 'string',\n",
       "          'description': \"str or dict, default ‘infer’. For on-the-fly decompression of on-disk data. If ‘infer’ and ‘filepath_or_buffer’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nIf using ‘zip’ or ‘tar’, the ZIP file must contain only one data file to be read in.\\nSet to None for no decompression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdDecompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for Zstandard decompression using a\\ncustom compression dictionary:\\ncompression={'method': 'zstd', 'dict_data': my_compression_dict}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\n\\n\"},\n",
       "         'storage_options': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'}},\n",
       "        'required': ['filepath_or_buffer']}}},\n",
       "     {'func_name': 'StataReader.data_label',\n",
       "      'func_desc': 'Return data label of Stata file.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.stata.StataReader.data_label.html#pandas.io.stata.StataReader.data_label',\n",
       "      'function_definitions': {'function_name': 'pandas.io.stata.StataReader.data_label',\n",
       "       'full_function': 'property StataReader.data_label',\n",
       "       'function_text': 'Return data label of Stata file. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'StataReader.variable_labels()',\n",
       "      'func_desc': 'Return a dict associating each variable name with corresponding label.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.stata.StataReader.variable_labels.html#pandas.io.stata.StataReader.variable_labels',\n",
       "      'function_definitions': {'function_name': 'pandas.io.stata.StataReader.variable_labels',\n",
       "       'full_function': 'StataReader.variable_labels()',\n",
       "       'function_text': 'Return a dict associating each variable name with corresponding label.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.to_stata(path,\\xa0*[,\\xa0convert_dates,\\xa0...])',\n",
       "      'func_desc': 'Export DataFrame object to Stata dta format.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_stata.html#pandas.DataFrame.to_stata',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_stata',\n",
       "       'full_function': \"DataFrame.to_stata(path, *, convert_dates=None, write_index=True, byteorder=None, time_stamp=None, data_label=None, variable_labels=None, version=114, convert_strl=None, compression='infer', storage_options=None, value_labels=None)\",\n",
       "       'function_text': 'Export DataFrame object to Stata dta format. Writes the DataFrame to a Stata dataset file.\\n“dta” files contain a Stata dataset.',\n",
       "       'parameter_names_desc': [{'param_name': 'path',\n",
       "         'param_type': 'str, path object, or buffer',\n",
       "         'param_desc': 'String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a binary write() function.\\n'},\n",
       "        {'param_name': 'convert_dates',\n",
       "         'param_type': 'dict',\n",
       "         'param_desc': 'Dictionary mapping columns containing datetime types to stata\\ninternal format to use when writing the dates. Options are ‘tc’,\\n‘td’, ‘tm’, ‘tw’, ‘th’, ‘tq’, ‘ty’. Column can be either an integer\\nor a name. Datetime columns that do not have a conversion type\\nspecified will be converted to ‘tc’. Raises NotImplementedError if\\na datetime column has timezone information.\\n'},\n",
       "        {'param_name': 'write_index',\n",
       "         'param_type': 'bool',\n",
       "         'param_desc': 'Write the index to Stata dataset.\\n'},\n",
       "        {'param_name': 'byteorder',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'Can be “>”, “<”, “little”, or “big”. default is sys.byteorder.\\n'},\n",
       "        {'param_name': 'time_stamp',\n",
       "         'param_type': 'datetime',\n",
       "         'param_desc': 'A datetime to use as file creation date. Default is the current\\ntime.\\n'},\n",
       "        {'param_name': 'data_label',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'A label for the data set. Must be 80 characters or smaller.\\n'},\n",
       "        {'param_name': 'variable_labels',\n",
       "         'param_type': 'dict',\n",
       "         'param_desc': 'Dictionary containing columns as keys and variable labels as\\nvalues. Each label must be 80 characters or smaller.\\n'},\n",
       "        {'param_name': 'version',\n",
       "         'param_type': '{114, 117, 118, 119, None}, default 114',\n",
       "         'param_desc': 'Version to use in the output dta file. Set to None to let pandas\\ndecide between 118 or 119 formats depending on the number of\\ncolumns in the frame. Version 114 can be read by Stata 10 and\\nlater. Version 117 can be read by Stata 13 or later. Version 118\\nis supported in Stata 14 and later. Version 119 is supported in\\nStata 15 and later. Version 114 limits string variables to 244\\ncharacters or fewer while versions 117 and later allow strings\\nwith lengths up to 2,000,000 characters. Versions 118 and 119\\nsupport Unicode characters, and version 119 supports more than\\n32,767 variables.\\nVersion 119 should usually only be used when the number of\\nvariables exceeds the capacity of dta format 118. Exporting\\nsmaller datasets in format 119 may have unintended consequences,\\nand, as of November 2020, Stata SE cannot read version 119 files.\\n'},\n",
       "        {'param_name': 'convert_strl',\n",
       "         'param_type': 'list, optional',\n",
       "         'param_desc': 'List of column names to convert to string columns to Stata StrL\\nformat. Only available if version is 117. Storing strings in the\\nStrL format can produce smaller dta files if strings have more than\\n8 characters and values are repeated.\\n'},\n",
       "        {'param_name': 'compression',\n",
       "         'param_type': 'str or dict, default ‘infer’',\n",
       "         'param_desc': \"For on-the-fly compression of the output data. If ‘infer’ and ‘path’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nSet to None for no compression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for faster compression and to create\\na reproducible gzip archive:\\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\n\\n\\nChanged in version 1.4.0: Zstandard support.\\n\\n\"},\n",
       "        {'param_name': 'storage_options',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'},\n",
       "        {'param_name': 'value_labels',\n",
       "         'param_type': 'dict of dicts',\n",
       "         'param_desc': 'Dictionary containing columns as keys and dictionaries of column value\\nto labels as values. Labels for a single variable must be 32,000\\ncharacters or smaller.\\n\\nNew in version 1.4.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.to_stata',\n",
       "       'descriptions': 'Export DataFrame object to Stata dta format. Writes the DataFrame to a Stata dataset file.\\n“dta” files contain a Stata dataset.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'path': {'type': 'string',\n",
       "          'description': 'str, path object, or buffer. String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a binary write() function.\\n'},\n",
       "         'convert_dates': {'type': 'dict',\n",
       "          'description': 'dict. Dictionary mapping columns containing datetime types to stata\\ninternal format to use when writing the dates. Options are ‘tc’,\\n‘td’, ‘tm’, ‘tw’, ‘th’, ‘tq’, ‘ty’. Column can be either an integer\\nor a name. Datetime columns that do not have a conversion type\\nspecified will be converted to ‘tc’. Raises NotImplementedError if\\na datetime column has timezone information.\\n'},\n",
       "         'write_index': {'type': 'boolean',\n",
       "          'description': 'bool. Write the index to Stata dataset.\\n'},\n",
       "         'byteorder': {'type': 'string',\n",
       "          'description': 'str. Can be “>”, “<”, “little”, or “big”. default is sys.byteorder.\\n'},\n",
       "         'time_stamp': {'type': 'datetime',\n",
       "          'description': 'datetime. A datetime to use as file creation date. Default is the current\\ntime.\\n'},\n",
       "         'data_label': {'type': 'string',\n",
       "          'description': 'str, optional. A label for the data set. Must be 80 characters or smaller.\\n'},\n",
       "         'variable_labels': {'type': 'dict',\n",
       "          'description': 'dict. Dictionary containing columns as keys and variable labels as\\nvalues. Each label must be 80 characters or smaller.\\n'},\n",
       "         'version': {'type': '{114, 117, 118, 119, None}, default 114',\n",
       "          'description': '{114, 117, 118, 119, None}, default 114. Version to use in the output dta file. Set to None to let pandas\\ndecide between 118 or 119 formats depending on the number of\\ncolumns in the frame. Version 114 can be read by Stata 10 and\\nlater. Version 117 can be read by Stata 13 or later. Version 118\\nis supported in Stata 14 and later. Version 119 is supported in\\nStata 15 and later. Version 114 limits string variables to 244\\ncharacters or fewer while versions 117 and later allow strings\\nwith lengths up to 2,000,000 characters. Versions 118 and 119\\nsupport Unicode characters, and version 119 supports more than\\n32,767 variables.\\nVersion 119 should usually only be used when the number of\\nvariables exceeds the capacity of dta format 118. Exporting\\nsmaller datasets in format 119 may have unintended consequences,\\nand, as of November 2020, Stata SE cannot read version 119 files.\\n'},\n",
       "         'convert_strl': {'type': 'array',\n",
       "          'description': 'list, optional. List of column names to convert to string columns to Stata StrL\\nformat. Only available if version is 117. Storing strings in the\\nStrL format can produce smaller dta files if strings have more than\\n8 characters and values are repeated.\\n'},\n",
       "         'compression': {'type': 'string',\n",
       "          'description': \"str or dict, default ‘infer’. For on-the-fly compression of the output data. If ‘infer’ and ‘path’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nSet to None for no compression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for faster compression and to create\\na reproducible gzip archive:\\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\n\\n\\nChanged in version 1.4.0: Zstandard support.\\n\\n\"},\n",
       "         'storage_options': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'},\n",
       "         'value_labels': {'type': 'dict of dicts',\n",
       "          'description': 'dict of dicts. Dictionary containing columns as keys and dictionaries of column value\\nto labels as values. Labels for a single variable must be 32,000\\ncharacters or smaller.\\n\\nNew in version 1.4.0.\\n\\n'}},\n",
       "        'required': ['path']}}},\n",
       "     {'func_name': 'StataReader.value_labels()',\n",
       "      'func_desc': 'Return a nested dict associating each variable name to its value and label.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.stata.StataReader.value_labels.html#pandas.io.stata.StataReader.value_labels',\n",
       "      'function_definitions': {'function_name': 'pandas.io.stata.StataReader.value_labels',\n",
       "       'full_function': 'StataReader.value_labels()',\n",
       "       'function_text': 'Return a nested dict associating each variable name to its value and label.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'StataWriter.write_file()',\n",
       "      'func_desc': 'Export DataFrame object to Stata dta format.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.stata.StataWriter.write_file.html#pandas.io.stata.StataWriter.write_file',\n",
       "      'function_definitions': {'function_name': 'pandas.io.stata.StataWriter.write_file',\n",
       "       'full_function': 'StataWriter.write_file()',\n",
       "       'function_text': 'Export DataFrame object to Stata dta format. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]}],\n",
       "  'name': 'Input/output',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/io.html'},\n",
       " 'general_functions.html': {'functions': [{'Data manipulations': [{'func_name': 'melt(frame[,\\xa0id_vars,\\xa0value_vars,\\xa0var_name,\\xa0...])',\n",
       "      'func_desc': 'Unpivot a DataFrame from wide to long format, optionally leaving identifiers set.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.melt.html#pandas.melt',\n",
       "      'function_definitions': {'function_name': 'pandas.melt',\n",
       "       'full_function': \"pandas.melt(frame, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None, ignore_index=True)\",\n",
       "       'function_text': 'Unpivot a DataFrame from wide to long format, optionally leaving identifiers set. This function is useful to massage a DataFrame into a format where one\\nor more columns are identifier variables (id_vars), while all other\\ncolumns, considered measured variables (value_vars), are “unpivoted” to\\nthe row axis, leaving just two non-identifier columns, ‘variable’ and\\n‘value’.',\n",
       "       'parameter_names_desc': [{'param_name': 'id_vars',\n",
       "         'param_type': 'scalar, tuple, list, or ndarray, optional',\n",
       "         'param_desc': 'Column(s) to use as identifier variables.\\n'},\n",
       "        {'param_name': 'value_vars',\n",
       "         'param_type': 'scalar, tuple, list, or ndarray, optional',\n",
       "         'param_desc': 'Column(s) to unpivot. If not specified, uses all columns that\\nare not set as id_vars.\\n'},\n",
       "        {'param_name': 'var_name',\n",
       "         'param_type': 'scalar, default None',\n",
       "         'param_desc': 'Name to use for the ‘variable’ column. If None it uses\\nframe.columns.name or ‘variable’.\\n'},\n",
       "        {'param_name': 'value_name',\n",
       "         'param_type': 'scalar, default ‘value’',\n",
       "         'param_desc': 'Name to use for the ‘value’ column, can’t be an existing column label.\\n'},\n",
       "        {'param_name': 'col_level',\n",
       "         'param_type': 'scalar, optional',\n",
       "         'param_desc': 'If columns are a MultiIndex then use this level to melt.\\n'},\n",
       "        {'param_name': 'ignore_index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If True, original index is ignored. If False, the original index is retained.\\nIndex labels will be repeated as necessary.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.melt',\n",
       "       'descriptions': 'Unpivot a DataFrame from wide to long format, optionally leaving identifiers set. This function is useful to massage a DataFrame into a format where one\\nor more columns are identifier variables (id_vars), while all other\\ncolumns, considered measured variables (value_vars), are “unpivoted” to\\nthe row axis, leaving just two non-identifier columns, ‘variable’ and\\n‘value’.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'id_vars': {'type': 'array',\n",
       "          'description': 'scalar, tuple, list, or ndarray, optional. Column(s) to use as identifier variables.\\n'},\n",
       "         'value_vars': {'type': 'array',\n",
       "          'description': 'scalar, tuple, list, or ndarray, optional. Column(s) to unpivot. If not specified, uses all columns that\\nare not set as id_vars.\\n'},\n",
       "         'var_name': {'type': 'scalar, default None',\n",
       "          'description': 'scalar, default None. Name to use for the ‘variable’ column. If None it uses\\nframe.columns.name or ‘variable’.\\n'},\n",
       "         'value_name': {'type': 'scalar, default ‘value’',\n",
       "          'description': 'scalar, default ‘value’. Name to use for the ‘value’ column, can’t be an existing column label.\\n'},\n",
       "         'col_level': {'type': 'scalar, optional',\n",
       "          'description': 'scalar, optional. If columns are a MultiIndex then use this level to melt.\\n'},\n",
       "         'ignore_index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If True, original index is ignored. If False, the original index is retained.\\nIndex labels will be repeated as necessary.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'pivot_table(data[,\\xa0values,\\xa0index,\\xa0columns,\\xa0...])',\n",
       "      'func_desc': 'Create a spreadsheet-style pivot table as a DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.pivot_table.html#pandas.pivot_table',\n",
       "      'function_definitions': {'function_name': 'pandas.pivot_table',\n",
       "       'full_function': \"pandas.pivot_table(data, values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All', observed=_NoDefault.no_default, sort=True)\",\n",
       "       'function_text': 'Create a spreadsheet-style pivot table as a DataFrame. The levels in the pivot table will be stored in MultiIndex objects\\n(hierarchical indexes) on the index and columns of the result DataFrame.',\n",
       "       'parameter_names_desc': [{'param_name': 'data',\n",
       "         'param_type': 'DataFrame',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'values',\n",
       "         'param_type': 'list-like or scalar, optional',\n",
       "         'param_desc': 'Column or columns to aggregate.\\n'},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'column, Grouper, array, or list of the previous',\n",
       "         'param_desc': 'Keys to group by on the pivot table index. If a list is passed,\\nit can contain any of the other types (except list). If an array is\\npassed, it must be the same length as the data and will be used in\\nthe same manner as column values.\\n'},\n",
       "        {'param_name': 'columns',\n",
       "         'param_type': 'column, Grouper, array, or list of the previous',\n",
       "         'param_desc': 'Keys to group by on the pivot table column. If a list is passed,\\nit can contain any of the other types (except list). If an array is\\npassed, it must be the same length as the data and will be used in\\nthe same manner as column values.\\n'},\n",
       "        {'param_name': 'aggfunc',\n",
       "         'param_type': 'function, list of functions, dict, default “mean”',\n",
       "         'param_desc': 'If a list of functions is passed, the resulting pivot table will have\\nhierarchical columns whose top level are the function names\\n(inferred from the function objects themselves).\\nIf a dict is passed, the key is column to aggregate and the value is\\nfunction or list of functions. If margin=True, aggfunc will be\\nused to calculate the partial aggregates.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'scalar, default None',\n",
       "         'param_desc': 'Value to replace missing values with (in the resulting pivot table,\\nafter aggregation).\\n'},\n",
       "        {'param_name': 'margins',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If margins=True, special All columns and rows\\nwill be added with partial group aggregates across the categories\\non the rows and columns.\\n'},\n",
       "        {'param_name': 'dropna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Do not include columns whose entries are all NaN. If True,\\nrows with a NaN value in any column will be omitted before\\ncomputing margins.\\n'},\n",
       "        {'param_name': 'margins_name',\n",
       "         'param_type': 'str, default ‘All’',\n",
       "         'param_desc': 'Name of the row / column that will contain the totals\\nwhen margins is True.\\n'},\n",
       "        {'param_name': 'observed',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'This only applies if any of the groupers are Categoricals.\\nIf True: only show observed values for categorical groupers.\\nIf False: show all values for categorical groupers.\\n\\nDeprecated since version 2.2.0: The default value of False is deprecated and will change to\\nTrue in a future version of pandas.\\n\\n'},\n",
       "        {'param_name': 'sort',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Specifies if the result should be sorted.\\n\\nNew in version 1.3.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.pivot_table',\n",
       "       'descriptions': 'Create a spreadsheet-style pivot table as a DataFrame. The levels in the pivot table will be stored in MultiIndex objects\\n(hierarchical indexes) on the index and columns of the result DataFrame.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'data': {'type': 'DataFrame',\n",
       "          'description': 'DataFrame. '},\n",
       "         'values': {'type': 'array',\n",
       "          'description': 'list-like or scalar, optional. Column or columns to aggregate.\\n'},\n",
       "         'index': {'type': 'array',\n",
       "          'description': 'column, Grouper, array, or list of the previous. Keys to group by on the pivot table index. If a list is passed,\\nit can contain any of the other types (except list). If an array is\\npassed, it must be the same length as the data and will be used in\\nthe same manner as column values.\\n'},\n",
       "         'columns': {'type': 'array',\n",
       "          'description': 'column, Grouper, array, or list of the previous. Keys to group by on the pivot table column. If a list is passed,\\nit can contain any of the other types (except list). If an array is\\npassed, it must be the same length as the data and will be used in\\nthe same manner as column values.\\n'},\n",
       "         'aggfunc': {'type': 'array',\n",
       "          'description': 'function, list of functions, dict, default “mean”. If a list of functions is passed, the resulting pivot table will have\\nhierarchical columns whose top level are the function names\\n(inferred from the function objects themselves).\\nIf a dict is passed, the key is column to aggregate and the value is\\nfunction or list of functions. If margin=True, aggfunc will be\\nused to calculate the partial aggregates.\\n'},\n",
       "         'fill_value': {'type': 'scalar, default None',\n",
       "          'description': 'scalar, default None. Value to replace missing values with (in the resulting pivot table,\\nafter aggregation).\\n'},\n",
       "         'margins': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If margins=True, special All columns and rows\\nwill be added with partial group aggregates across the categories\\non the rows and columns.\\n'},\n",
       "         'dropna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Do not include columns whose entries are all NaN. If True,\\nrows with a NaN value in any column will be omitted before\\ncomputing margins.\\n'},\n",
       "         'margins_name': {'type': 'string',\n",
       "          'description': 'str, default ‘All’. Name of the row / column that will contain the totals\\nwhen margins is True.\\n'},\n",
       "         'observed': {'type': 'boolean',\n",
       "          'description': 'bool, default False. This only applies if any of the groupers are Categoricals.\\nIf True: only show observed values for categorical groupers.\\nIf False: show all values for categorical groupers.\\n\\nDeprecated since version 2.2.0: The default value of False is deprecated and will change to\\nTrue in a future version of pandas.\\n\\n'},\n",
       "         'sort': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Specifies if the result should be sorted.\\n\\nNew in version 1.3.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'cut(x,\\xa0bins[,\\xa0right,\\xa0labels,\\xa0retbins,\\xa0...])',\n",
       "      'func_desc': 'Bin values into discrete intervals.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.cut.html#pandas.cut',\n",
       "      'function_definitions': {'function_name': 'pandas.cut',\n",
       "       'full_function': \"pandas.cut(x, bins, right=True, labels=None, retbins=False, precision=3, include_lowest=False, duplicates='raise', ordered=True)\",\n",
       "       'function_text': 'Bin values into discrete intervals. Use cut when you need to segment and sort data values into bins. This\\nfunction is also useful for going from a continuous variable to a\\ncategorical variable. For example, cut could convert ages to groups of\\nage ranges. Supports binning into an equal number of bins, or a\\npre-specified array of bins.',\n",
       "       'parameter_names_desc': [{'param_name': 'x',\n",
       "         'param_type': 'array-like',\n",
       "         'param_desc': 'The input array to be binned. Must be 1-dimensional.\\n'},\n",
       "        {'param_name': 'bins',\n",
       "         'param_type': 'int, sequence of scalars, or IntervalIndex',\n",
       "         'param_desc': 'The criteria to bin by.\\n\\nint : Defines the number of equal-width bins in the range of x. The\\nrange of x is extended by .1% on each side to include the minimum\\nand maximum values of x.\\nsequence of scalars : Defines the bin edges allowing for non-uniform\\nwidth. No extension of the range of x is done.\\nIntervalIndex : Defines the exact bins to be used. Note that\\nIntervalIndex for bins must be non-overlapping.\\n\\n'},\n",
       "        {'param_name': 'right',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Indicates whether bins includes the rightmost edge or not. If\\nright == True (the default), then the bins [1, 2, 3, 4]\\nindicate (1,2], (2,3], (3,4]. This argument is ignored when\\nbins is an IntervalIndex.\\n'},\n",
       "        {'param_name': 'labels',\n",
       "         'param_type': 'array or False, default None',\n",
       "         'param_desc': 'Specifies the labels for the returned bins. Must be the same length as\\nthe resulting bins. If False, returns only integer indicators of the\\nbins. This affects the type of the output container (see below).\\nThis argument is ignored when bins is an IntervalIndex. If True,\\nraises an error. When ordered=False, labels must be provided.\\n'},\n",
       "        {'param_name': 'retbins',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to return the bins or not. Useful when bins is provided\\nas a scalar.\\n'},\n",
       "        {'param_name': 'precision',\n",
       "         'param_type': 'int, default 3',\n",
       "         'param_desc': 'The precision at which to store and display the bins labels.\\n'},\n",
       "        {'param_name': 'include_lowest',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether the first interval should be left-inclusive or not.\\n'},\n",
       "        {'param_name': 'duplicates',\n",
       "         'param_type': '{default ‘raise’, ‘drop’}, optional',\n",
       "         'param_desc': 'If bin edges are not unique, raise ValueError or drop non-uniques.\\n'},\n",
       "        {'param_name': 'ordered',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether the labels are ordered or not. Applies to returned types\\nCategorical and Series (with Categorical dtype). If True,\\nthe resulting categorical will be ordered. If False, the resulting\\ncategorical will be unordered (labels must be provided).\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.cut',\n",
       "       'descriptions': 'Bin values into discrete intervals. Use cut when you need to segment and sort data values into bins. This\\nfunction is also useful for going from a continuous variable to a\\ncategorical variable. For example, cut could convert ages to groups of\\nage ranges. Supports binning into an equal number of bins, or a\\npre-specified array of bins.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'x': {'type': 'array',\n",
       "          'description': 'array-like. The input array to be binned. Must be 1-dimensional.\\n'},\n",
       "         'bins': {'type': 'integer',\n",
       "          'description': 'int, sequence of scalars, or IntervalIndex. The criteria to bin by.\\n\\nint : Defines the number of equal-width bins in the range of x. The\\nrange of x is extended by .1% on each side to include the minimum\\nand maximum values of x.\\nsequence of scalars : Defines the bin edges allowing for non-uniform\\nwidth. No extension of the range of x is done.\\nIntervalIndex : Defines the exact bins to be used. Note that\\nIntervalIndex for bins must be non-overlapping.\\n\\n'},\n",
       "         'right': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Indicates whether bins includes the rightmost edge or not. If\\nright == True (the default), then the bins [1, 2, 3, 4]\\nindicate (1,2], (2,3], (3,4]. This argument is ignored when\\nbins is an IntervalIndex.\\n'},\n",
       "         'labels': {'type': 'array',\n",
       "          'description': 'array or False, default None. Specifies the labels for the returned bins. Must be the same length as\\nthe resulting bins. If False, returns only integer indicators of the\\nbins. This affects the type of the output container (see below).\\nThis argument is ignored when bins is an IntervalIndex. If True,\\nraises an error. When ordered=False, labels must be provided.\\n'},\n",
       "         'retbins': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to return the bins or not. Useful when bins is provided\\nas a scalar.\\n'},\n",
       "         'precision': {'type': 'integer',\n",
       "          'description': 'int, default 3. The precision at which to store and display the bins labels.\\n'},\n",
       "         'include_lowest': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether the first interval should be left-inclusive or not.\\n'},\n",
       "         'duplicates': {'type': 'string',\n",
       "          'enum': ['default raise', ' drop'],\n",
       "          'description': '{default ‘raise’, ‘drop’}, optional. If bin edges are not unique, raise ValueError or drop non-uniques.\\n'},\n",
       "         'ordered': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether the labels are ordered or not. Applies to returned types\\nCategorical and Series (with Categorical dtype). If True,\\nthe resulting categorical will be ordered. If False, the resulting\\ncategorical will be unordered (labels must be provided).\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'merge(left,\\xa0right[,\\xa0how,\\xa0on,\\xa0left_on,\\xa0...])',\n",
       "      'func_desc': 'Merge DataFrame or named Series objects with a database-style join.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.merge.html#pandas.merge',\n",
       "      'function_definitions': {'function_name': 'pandas.merge',\n",
       "       'full_function': \"pandas.merge(left, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=None, indicator=False, validate=None)\",\n",
       "       'function_text': 'Merge DataFrame or named Series objects with a database-style join. A named Series object is treated as a DataFrame with a single named column. The join is done on columns or indexes. If joining columns on\\ncolumns, the DataFrame indexes will be ignored. Otherwise if joining indexes\\non indexes or indexes on a column or columns, the index will be passed on.\\nWhen performing a cross merge, no column specifications to merge on are\\nallowed. Warning If both key columns contain rows where the key is a null value, those\\nrows will be matched against each other. This is different from usual SQL\\njoin behaviour and can lead to unexpected results.',\n",
       "       'parameter_names_desc': [{'param_name': 'left',\n",
       "         'param_type': 'DataFrame or named Series',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'right',\n",
       "         'param_type': 'DataFrame or named Series',\n",
       "         'param_desc': 'Object to merge with.\\n'},\n",
       "        {'param_name': 'how',\n",
       "         'param_type': '{‘left’, ‘right’, ‘outer’, ‘inner’, ‘cross’}, default ‘inner’',\n",
       "         'param_desc': 'Type of merge to be performed.\\n\\nleft: use only keys from left frame, similar to a SQL left outer join;\\npreserve key order.\\nright: use only keys from right frame, similar to a SQL right outer join;\\npreserve key order.\\nouter: use union of keys from both frames, similar to a SQL full outer\\njoin; sort keys lexicographically.\\ninner: use intersection of keys from both frames, similar to a SQL inner\\njoin; preserve the order of the left keys.\\ncross: creates the cartesian product from both frames, preserves the order\\nof the left keys.\\n\\n'},\n",
       "        {'param_name': 'on',\n",
       "         'param_type': 'label or list',\n",
       "         'param_desc': 'Column or index level names to join on. These must be found in both\\nDataFrames. If on is None and not merging on indexes then this defaults\\nto the intersection of the columns in both DataFrames.\\n'},\n",
       "        {'param_name': 'left_on',\n",
       "         'param_type': 'label or list, or array-like',\n",
       "         'param_desc': 'Column or index level names to join on in the left DataFrame. Can also\\nbe an array or list of arrays of the length of the left DataFrame.\\nThese arrays are treated as if they are columns.\\n'},\n",
       "        {'param_name': 'right_on',\n",
       "         'param_type': 'label or list, or array-like',\n",
       "         'param_desc': 'Column or index level names to join on in the right DataFrame. Can also\\nbe an array or list of arrays of the length of the right DataFrame.\\nThese arrays are treated as if they are columns.\\n'},\n",
       "        {'param_name': 'left_index',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Use the index from the left DataFrame as the join key(s). If it is a\\nMultiIndex, the number of keys in the other DataFrame (either the index\\nor a number of columns) must match the number of levels.\\n'},\n",
       "        {'param_name': 'right_index',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Use the index from the right DataFrame as the join key. Same caveats as\\nleft_index.\\n'},\n",
       "        {'param_name': 'sort',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Sort the join keys lexicographically in the result DataFrame. If False,\\nthe order of the join keys depends on the join type (how keyword).\\n'},\n",
       "        {'param_name': 'suffixes',\n",
       "         'param_type': 'list-like, default is (“_x”, “_y”)',\n",
       "         'param_desc': 'A length-2 sequence where each element is optionally a string\\nindicating the suffix to add to overlapping column names in\\nleft and right respectively. Pass a value of None instead\\nof a string to indicate that the column name from left or\\nright should be left as-is, with no suffix. At least one of the\\nvalues must not be None.\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If False, avoid copy if possible.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'},\n",
       "        {'param_name': 'indicator',\n",
       "         'param_type': 'bool or str, default False',\n",
       "         'param_desc': 'If True, adds a column to the output DataFrame called “_merge” with\\ninformation on the source of each row. The column can be given a different\\nname by providing a string argument. The column will have a Categorical\\ntype with the value of “left_only” for observations whose merge key only\\nappears in the left DataFrame, “right_only” for observations\\nwhose merge key only appears in the right DataFrame, and “both”\\nif the observation’s merge key is found in both DataFrames.\\n'},\n",
       "        {'param_name': 'validate',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'If specified, checks if merge is of specified type.\\n\\n“one_to_one” or “1:1”: check if merge keys are unique in both\\nleft and right datasets.\\n“one_to_many” or “1:m”: check if merge keys are unique in left\\ndataset.\\n“many_to_one” or “m:1”: check if merge keys are unique in right\\ndataset.\\n“many_to_many” or “m:m”: allowed, but does not result in checks.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.merge',\n",
       "       'descriptions': 'Merge DataFrame or named Series objects with a database-style join. A named Series object is treated as a DataFrame with a single named column. The join is done on columns or indexes. If joining columns on\\ncolumns, the DataFrame indexes will be ignored. Otherwise if joining indexes\\non indexes or indexes on a column or columns, the index will be passed on.\\nWhen performing a cross merge, no column specifications to merge on are\\nallowed. Warning If both key columns contain rows where the key is a null value, those\\nrows will be matched against each other. This is different from usual SQL\\njoin behaviour and can lead to unexpected results.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'left': {'type': 'DataFrame or named Series',\n",
       "          'description': 'DataFrame or named Series. '},\n",
       "         'right': {'type': 'DataFrame or named Series',\n",
       "          'description': 'DataFrame or named Series. Object to merge with.\\n'},\n",
       "         'how': {'type': 'string',\n",
       "          'enum': ['left', ' right', ' outer', ' inner', ' cross'],\n",
       "          'description': '{‘left’, ‘right’, ‘outer’, ‘inner’, ‘cross’}, default ‘inner’. Type of merge to be performed.\\n\\nleft: use only keys from left frame, similar to a SQL left outer join;\\npreserve key order.\\nright: use only keys from right frame, similar to a SQL right outer join;\\npreserve key order.\\nouter: use union of keys from both frames, similar to a SQL full outer\\njoin; sort keys lexicographically.\\ninner: use intersection of keys from both frames, similar to a SQL inner\\njoin; preserve the order of the left keys.\\ncross: creates the cartesian product from both frames, preserves the order\\nof the left keys.\\n\\n'},\n",
       "         'on': {'type': 'array',\n",
       "          'description': 'label or list. Column or index level names to join on. These must be found in both\\nDataFrames. If on is None and not merging on indexes then this defaults\\nto the intersection of the columns in both DataFrames.\\n'},\n",
       "         'left_on': {'type': 'array',\n",
       "          'description': 'label or list, or array-like. Column or index level names to join on in the left DataFrame. Can also\\nbe an array or list of arrays of the length of the left DataFrame.\\nThese arrays are treated as if they are columns.\\n'},\n",
       "         'right_on': {'type': 'array',\n",
       "          'description': 'label or list, or array-like. Column or index level names to join on in the right DataFrame. Can also\\nbe an array or list of arrays of the length of the right DataFrame.\\nThese arrays are treated as if they are columns.\\n'},\n",
       "         'left_index': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Use the index from the left DataFrame as the join key(s). If it is a\\nMultiIndex, the number of keys in the other DataFrame (either the index\\nor a number of columns) must match the number of levels.\\n'},\n",
       "         'right_index': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Use the index from the right DataFrame as the join key. Same caveats as\\nleft_index.\\n'},\n",
       "         'sort': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Sort the join keys lexicographically in the result DataFrame. If False,\\nthe order of the join keys depends on the join type (how keyword).\\n'},\n",
       "         'suffixes': {'type': 'array',\n",
       "          'description': 'list-like, default is (“_x”, “_y”). A length-2 sequence where each element is optionally a string\\nindicating the suffix to add to overlapping column names in\\nleft and right respectively. Pass a value of None instead\\nof a string to indicate that the column name from left or\\nright should be left as-is, with no suffix. At least one of the\\nvalues must not be None.\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If False, avoid copy if possible.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'},\n",
       "         'indicator': {'type': 'string',\n",
       "          'description': 'bool or str, default False. If True, adds a column to the output DataFrame called “_merge” with\\ninformation on the source of each row. The column can be given a different\\nname by providing a string argument. The column will have a Categorical\\ntype with the value of “left_only” for observations whose merge key only\\nappears in the left DataFrame, “right_only” for observations\\nwhose merge key only appears in the right DataFrame, and “both”\\nif the observation’s merge key is found in both DataFrames.\\n'},\n",
       "         'validate': {'type': 'string',\n",
       "          'description': 'str, optional. If specified, checks if merge is of specified type.\\n\\n“one_to_one” or “1:1”: check if merge keys are unique in both\\nleft and right datasets.\\n“one_to_many” or “1:m”: check if merge keys are unique in left\\ndataset.\\n“many_to_one” or “m:1”: check if merge keys are unique in right\\ndataset.\\n“many_to_many” or “m:m”: allowed, but does not result in checks.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'merge_asof(left,\\xa0right[,\\xa0on,\\xa0left_on,\\xa0...])',\n",
       "      'func_desc': 'Perform a merge by key distance.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.merge_asof.html#pandas.merge_asof',\n",
       "      'function_definitions': {'function_name': 'pandas.merge_asof',\n",
       "       'full_function': \"pandas.merge_asof(left, right, on=None, left_on=None, right_on=None, left_index=False, right_index=False, by=None, left_by=None, right_by=None, suffixes=('_x', '_y'), tolerance=None, allow_exact_matches=True, direction='backward')\",\n",
       "       'function_text': 'Perform a merge by key distance. This is similar to a left-join except that we match on nearest\\nkey rather than equal keys. Both DataFrames must be sorted by the key. For each row in the left DataFrame: A “backward” search selects the last row in the right DataFrame whose\\n‘on’ key is less than or equal to the left’s key. A “forward” search selects the first row in the right DataFrame whose\\n‘on’ key is greater than or equal to the left’s key. A “nearest” search selects the row in the right DataFrame whose ‘on’\\nkey is closest in absolute distance to the left’s key. Optionally match on equivalent keys with ‘by’ before searching with ‘on’.',\n",
       "       'parameter_names_desc': [{'param_name': 'left',\n",
       "         'param_type': 'DataFrame or named Series',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'right',\n",
       "         'param_type': 'DataFrame or named Series',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'on',\n",
       "         'param_type': 'label',\n",
       "         'param_desc': 'Field name to join on. Must be found in both DataFrames.\\nThe data MUST be ordered. Furthermore this must be a numeric column,\\nsuch as datetimelike, integer, or float. On or left_on/right_on\\nmust be given.\\n'},\n",
       "        {'param_name': 'left_on',\n",
       "         'param_type': 'label',\n",
       "         'param_desc': 'Field name to join on in left DataFrame.\\n'},\n",
       "        {'param_name': 'right_on',\n",
       "         'param_type': 'label',\n",
       "         'param_desc': 'Field name to join on in right DataFrame.\\n'},\n",
       "        {'param_name': 'left_index',\n",
       "         'param_type': 'bool',\n",
       "         'param_desc': 'Use the index of the left DataFrame as the join key.\\n'},\n",
       "        {'param_name': 'right_index',\n",
       "         'param_type': 'bool',\n",
       "         'param_desc': 'Use the index of the right DataFrame as the join key.\\n'},\n",
       "        {'param_name': 'by',\n",
       "         'param_type': 'column name or list of column names',\n",
       "         'param_desc': 'Match on these columns before performing merge operation.\\n'},\n",
       "        {'param_name': 'left_by',\n",
       "         'param_type': 'column name',\n",
       "         'param_desc': 'Field names to match on in the left DataFrame.\\n'},\n",
       "        {'param_name': 'right_by',\n",
       "         'param_type': 'column name',\n",
       "         'param_desc': 'Field names to match on in the right DataFrame.\\n'},\n",
       "        {'param_name': 'suffixes',\n",
       "         'param_type': '2-length sequence (tuple, list, …)',\n",
       "         'param_desc': 'Suffix to apply to overlapping column names in the left and right\\nside, respectively.\\n'},\n",
       "        {'param_name': 'tolerance',\n",
       "         'param_type': 'int or Timedelta, optional, default None',\n",
       "         'param_desc': 'Select asof tolerance within this range; must be compatible\\nwith the merge index.\\n'},\n",
       "        {'param_name': 'allow_exact_matches',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': '\\nIf True, allow matching with the same ‘on’ value\\n(i.e. less-than-or-equal-to / greater-than-or-equal-to)\\nIf False, don’t match the same ‘on’ value\\n(i.e., strictly less-than / strictly greater-than).\\n\\n'},\n",
       "        {'param_name': 'direction',\n",
       "         'param_type': '‘backward’ (default), ‘forward’, or ‘nearest’',\n",
       "         'param_desc': 'Whether to search for prior, subsequent, or closest matches.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.merge_asof',\n",
       "       'descriptions': 'Perform a merge by key distance. This is similar to a left-join except that we match on nearest\\nkey rather than equal keys. Both DataFrames must be sorted by the key. For each row in the left DataFrame: A “backward” search selects the last row in the right DataFrame whose\\n‘on’ key is less than or equal to the left’s key. A “forward” search selects the first row in the right DataFrame whose\\n‘on’ key is greater than or equal to the left’s key. A “nearest” search selects the row in the right DataFrame whose ‘on’\\nkey is closest in absolute distance to the left’s key. Optionally match on equivalent keys with ‘by’ before searching with ‘on’.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'left': {'type': 'DataFrame or named Series',\n",
       "          'description': 'DataFrame or named Series. '},\n",
       "         'right': {'type': 'DataFrame or named Series',\n",
       "          'description': 'DataFrame or named Series. '},\n",
       "         'on': {'type': 'label',\n",
       "          'description': 'label. Field name to join on. Must be found in both DataFrames.\\nThe data MUST be ordered. Furthermore this must be a numeric column,\\nsuch as datetimelike, integer, or float. On or left_on/right_on\\nmust be given.\\n'},\n",
       "         'left_on': {'type': 'label',\n",
       "          'description': 'label. Field name to join on in left DataFrame.\\n'},\n",
       "         'right_on': {'type': 'label',\n",
       "          'description': 'label. Field name to join on in right DataFrame.\\n'},\n",
       "         'left_index': {'type': 'boolean',\n",
       "          'description': 'bool. Use the index of the left DataFrame as the join key.\\n'},\n",
       "         'right_index': {'type': 'boolean',\n",
       "          'description': 'bool. Use the index of the right DataFrame as the join key.\\n'},\n",
       "         'by': {'type': 'array',\n",
       "          'description': 'column name or list of column names. Match on these columns before performing merge operation.\\n'},\n",
       "         'left_by': {'type': 'column name',\n",
       "          'description': 'column name. Field names to match on in the left DataFrame.\\n'},\n",
       "         'right_by': {'type': 'column name',\n",
       "          'description': 'column name. Field names to match on in the right DataFrame.\\n'},\n",
       "         'suffixes': {'type': 'array',\n",
       "          'description': '2-length sequence (tuple, list, …). Suffix to apply to overlapping column names in the left and right\\nside, respectively.\\n'},\n",
       "         'tolerance': {'type': 'integer',\n",
       "          'description': 'int or Timedelta, optional, default None. Select asof tolerance within this range; must be compatible\\nwith the merge index.\\n'},\n",
       "         'allow_exact_matches': {'type': 'boolean',\n",
       "          'description': 'bool, default True. \\nIf True, allow matching with the same ‘on’ value\\n(i.e. less-than-or-equal-to / greater-than-or-equal-to)\\nIf False, don’t match the same ‘on’ value\\n(i.e., strictly less-than / strictly greater-than).\\n\\n'},\n",
       "         'direction': {'type': '‘backward’ (default), ‘forward’, or ‘nearest’',\n",
       "          'description': '‘backward’ (default), ‘forward’, or ‘nearest’. Whether to search for prior, subsequent, or closest matches.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'get_dummies(data[,\\xa0prefix,\\xa0prefix_sep,\\xa0...])',\n",
       "      'func_desc': 'Convert categorical variable into dummy/indicator variables.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html#pandas.get_dummies',\n",
       "      'function_definitions': {'function_name': 'pandas.get_dummies',\n",
       "       'full_function': \"pandas.get_dummies(data, prefix=None, prefix_sep='_', dummy_na=False, columns=None, sparse=False, drop_first=False, dtype=None)\",\n",
       "       'function_text': 'Convert categorical variable into dummy/indicator variables. Each variable is converted in as many 0/1 variables as there are different\\nvalues. Columns in the output are each named after a value; if the input is\\na DataFrame, the name of the original variable is prepended to the value.',\n",
       "       'parameter_names_desc': [{'param_name': 'data',\n",
       "         'param_type': 'array-like, Series, or DataFrame',\n",
       "         'param_desc': 'Data of which to get dummy indicators.\\n'},\n",
       "        {'param_name': 'prefix',\n",
       "         'param_type': 'str, list of str, or dict of str, default None',\n",
       "         'param_desc': 'String to append DataFrame column names.\\nPass a list with length equal to the number of columns\\nwhen calling get_dummies on a DataFrame. Alternatively, prefix\\ncan be a dictionary mapping column names to prefixes.\\n'},\n",
       "        {'param_name': 'prefix_sep',\n",
       "         'param_type': 'str, default ‘_’',\n",
       "         'param_desc': 'If appending prefix, separator/delimiter to use. Or pass a\\nlist or dictionary as with prefix.\\n'},\n",
       "        {'param_name': 'dummy_na',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Add a column to indicate NaNs, if False NaNs are ignored.\\n'},\n",
       "        {'param_name': 'columns',\n",
       "         'param_type': 'list-like, default None',\n",
       "         'param_desc': 'Column names in the DataFrame to be encoded.\\nIf columns is None then all the columns with\\nobject, string, or category dtype will be converted.\\n'},\n",
       "        {'param_name': 'sparse',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether the dummy-encoded columns should be backed by\\na SparseArray (True) or a regular NumPy array (False).\\n'},\n",
       "        {'param_name': 'drop_first',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to get k-1 dummies out of k categorical levels by removing the\\nfirst level.\\n'},\n",
       "        {'param_name': 'dtype',\n",
       "         'param_type': 'dtype, default bool',\n",
       "         'param_desc': 'Data type for new columns. Only a single dtype is allowed.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.get_dummies',\n",
       "       'descriptions': 'Convert categorical variable into dummy/indicator variables. Each variable is converted in as many 0/1 variables as there are different\\nvalues. Columns in the output are each named after a value; if the input is\\na DataFrame, the name of the original variable is prepended to the value.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'data': {'type': 'array',\n",
       "          'description': 'array-like, Series, or DataFrame. Data of which to get dummy indicators.\\n'},\n",
       "         'prefix': {'type': 'string',\n",
       "          'description': 'str, list of str, or dict of str, default None. String to append DataFrame column names.\\nPass a list with length equal to the number of columns\\nwhen calling get_dummies on a DataFrame. Alternatively, prefix\\ncan be a dictionary mapping column names to prefixes.\\n'},\n",
       "         'prefix_sep': {'type': 'string',\n",
       "          'description': 'str, default ‘_’. If appending prefix, separator/delimiter to use. Or pass a\\nlist or dictionary as with prefix.\\n'},\n",
       "         'dummy_na': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Add a column to indicate NaNs, if False NaNs are ignored.\\n'},\n",
       "         'columns': {'type': 'array',\n",
       "          'description': 'list-like, default None. Column names in the DataFrame to be encoded.\\nIf columns is None then all the columns with\\nobject, string, or category dtype will be converted.\\n'},\n",
       "         'sparse': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether the dummy-encoded columns should be backed by\\na SparseArray (True) or a regular NumPy array (False).\\n'},\n",
       "         'drop_first': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to get k-1 dummies out of k categorical levels by removing the\\nfirst level.\\n'},\n",
       "         'dtype': {'type': 'boolean',\n",
       "          'description': 'dtype, default bool. Data type for new columns. Only a single dtype is allowed.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'factorize(values[,\\xa0sort,\\xa0use_na_sentinel,\\xa0...])',\n",
       "      'func_desc': 'Encode the object as an enumerated type or categorical variable.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.factorize.html#pandas.factorize',\n",
       "      'function_definitions': {'function_name': 'pandas.factorize',\n",
       "       'full_function': 'pandas.factorize(values, sort=False, use_na_sentinel=True, size_hint=None)',\n",
       "       'function_text': 'Encode the object as an enumerated type or categorical variable. This method is useful for obtaining a numeric representation of an\\narray when all that matters is identifying distinct values. factorize\\nis available as both a top-level function pandas.factorize(),\\nand as a method Series.factorize() and Index.factorize().',\n",
       "       'parameter_names_desc': [{'param_name': 'values',\n",
       "         'param_type': 'sequence',\n",
       "         'param_desc': 'A 1-D sequence. Sequences that aren’t pandas objects are\\ncoerced to ndarrays before factorization.\\n'},\n",
       "        {'param_name': 'sort',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Sort uniques and shuffle codes to maintain the\\nrelationship.\\n'},\n",
       "        {'param_name': 'use_na_sentinel',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If True, the sentinel -1 will be used for NaN values. If False,\\nNaN values will be encoded as non-negative integers and will not drop the\\nNaN from the uniques of the values.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "        {'param_name': 'size_hint',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Hint to the hashtable sizer.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.factorize',\n",
       "       'descriptions': 'Encode the object as an enumerated type or categorical variable. This method is useful for obtaining a numeric representation of an\\narray when all that matters is identifying distinct values. factorize\\nis available as both a top-level function pandas.factorize(),\\nand as a method Series.factorize() and Index.factorize().',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'values': {'type': 'sequence',\n",
       "          'description': 'sequence. A 1-D sequence. Sequences that aren’t pandas objects are\\ncoerced to ndarrays before factorization.\\n'},\n",
       "         'sort': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Sort uniques and shuffle codes to maintain the\\nrelationship.\\n'},\n",
       "         'use_na_sentinel': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If True, the sentinel -1 will be used for NaN values. If False,\\nNaN values will be encoded as non-negative integers and will not drop the\\nNaN from the uniques of the values.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "         'size_hint': {'type': 'integer',\n",
       "          'description': 'int, optional. Hint to the hashtable sizer.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'lreshape(data,\\xa0groups[,\\xa0dropna])',\n",
       "      'func_desc': 'Reshape wide-format data to long.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.lreshape.html#pandas.lreshape',\n",
       "      'function_definitions': {'function_name': 'pandas.lreshape',\n",
       "       'full_function': 'pandas.lreshape(data, groups, dropna=True)',\n",
       "       'function_text': 'Reshape wide-format data to long. Generalized inverse of DataFrame.pivot. Accepts a dictionary, groups, in which each key is a new column name\\nand each value is a list of old column names that will be “melted” under\\nthe new column name as part of the reshape.',\n",
       "       'parameter_names_desc': [{'param_name': 'data',\n",
       "         'param_type': 'DataFrame',\n",
       "         'param_desc': 'The wide-format DataFrame.\\n'},\n",
       "        {'param_name': 'groups',\n",
       "         'param_type': 'dict',\n",
       "         'param_desc': '{new_name : list_of_columns}.\\n'},\n",
       "        {'param_name': 'dropna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Do not include columns whose entries are all NaN.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.lreshape',\n",
       "       'descriptions': 'Reshape wide-format data to long. Generalized inverse of DataFrame.pivot. Accepts a dictionary, groups, in which each key is a new column name\\nand each value is a list of old column names that will be “melted” under\\nthe new column name as part of the reshape.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'data': {'type': 'DataFrame',\n",
       "          'description': 'DataFrame. The wide-format DataFrame.\\n'},\n",
       "         'groups': {'type': 'dict',\n",
       "          'description': 'dict. {new_name : list_of_columns}.\\n'},\n",
       "         'dropna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Do not include columns whose entries are all NaN.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'pivot(data,\\xa0*,\\xa0columns[,\\xa0index,\\xa0values])',\n",
       "      'func_desc': 'Return reshaped DataFrame organized by given index / column values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.pivot.html#pandas.pivot',\n",
       "      'function_definitions': {'function_name': 'pandas.pivot',\n",
       "       'full_function': 'pandas.pivot(data, *, columns, index=_NoDefault.no_default, values=_NoDefault.no_default)',\n",
       "       'function_text': 'Return reshaped DataFrame organized by given index / column values. Reshape data (produce a “pivot” table) based on column values. Uses\\nunique values from specified index / columns to form axes of the\\nresulting DataFrame. This function does not support data\\naggregation, multiple values will result in a MultiIndex in the\\ncolumns. See the User Guide for more on reshaping.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'crosstab(index,\\xa0columns[,\\xa0values,\\xa0rownames,\\xa0...])',\n",
       "      'func_desc': 'Compute a simple cross tabulation of two (or more) factors.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.crosstab.html#pandas.crosstab',\n",
       "      'function_definitions': {'function_name': 'pandas.crosstab',\n",
       "       'full_function': \"pandas.crosstab(index, columns, values=None, rownames=None, colnames=None, aggfunc=None, margins=False, margins_name='All', dropna=True, normalize=False)\",\n",
       "       'function_text': 'Compute a simple cross tabulation of two (or more) factors. By default, computes a frequency table of the factors unless an\\narray of values and an aggregation function are passed.',\n",
       "       'parameter_names_desc': [{'param_name': 'index',\n",
       "         'param_type': 'array-like, Series, or list of arrays/Series',\n",
       "         'param_desc': 'Values to group by in the rows.\\n'},\n",
       "        {'param_name': 'columns',\n",
       "         'param_type': 'array-like, Series, or list of arrays/Series',\n",
       "         'param_desc': 'Values to group by in the columns.\\n'},\n",
       "        {'param_name': 'values',\n",
       "         'param_type': 'array-like, optional',\n",
       "         'param_desc': 'Array of values to aggregate according to the factors.\\nRequires aggfunc be specified.\\n'},\n",
       "        {'param_name': 'rownames',\n",
       "         'param_type': 'sequence, default None',\n",
       "         'param_desc': 'If passed, must match number of row arrays passed.\\n'},\n",
       "        {'param_name': 'colnames',\n",
       "         'param_type': 'sequence, default None',\n",
       "         'param_desc': 'If passed, must match number of column arrays passed.\\n'},\n",
       "        {'param_name': 'aggfunc',\n",
       "         'param_type': 'function, optional',\n",
       "         'param_desc': 'If specified, requires values be specified as well.\\n'},\n",
       "        {'param_name': 'margins',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Add row/column margins (subtotals).\\n'},\n",
       "        {'param_name': 'margins_name',\n",
       "         'param_type': 'str, default ‘All’',\n",
       "         'param_desc': 'Name of the row/column that will contain the totals\\nwhen margins is True.\\n'},\n",
       "        {'param_name': 'dropna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Do not include columns whose entries are all NaN.\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, {‘all’, ‘index’, ‘columns’}, or {0,1}, default False',\n",
       "         'param_desc': 'Normalize by dividing all values by the sum of values.\\n\\nIf passed ‘all’ or True, will normalize over all values.\\nIf passed ‘index’ will normalize over each row.\\nIf passed ‘columns’ will normalize over each column.\\nIf margins is True, will also normalize margin values.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.crosstab',\n",
       "       'descriptions': 'Compute a simple cross tabulation of two (or more) factors. By default, computes a frequency table of the factors unless an\\narray of values and an aggregation function are passed.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'index': {'type': 'array',\n",
       "          'description': 'array-like, Series, or list of arrays/Series. Values to group by in the rows.\\n'},\n",
       "         'columns': {'type': 'array',\n",
       "          'description': 'array-like, Series, or list of arrays/Series. Values to group by in the columns.\\n'},\n",
       "         'values': {'type': 'array',\n",
       "          'description': 'array-like, optional. Array of values to aggregate according to the factors.\\nRequires aggfunc be specified.\\n'},\n",
       "         'rownames': {'type': 'sequence, default None',\n",
       "          'description': 'sequence, default None. If passed, must match number of row arrays passed.\\n'},\n",
       "         'colnames': {'type': 'sequence, default None',\n",
       "          'description': 'sequence, default None. If passed, must match number of column arrays passed.\\n'},\n",
       "         'aggfunc': {'type': 'function, optional',\n",
       "          'description': 'function, optional. If specified, requires values be specified as well.\\n'},\n",
       "         'margins': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Add row/column margins (subtotals).\\n'},\n",
       "         'margins_name': {'type': 'string',\n",
       "          'description': 'str, default ‘All’. Name of the row/column that will contain the totals\\nwhen margins is True.\\n'},\n",
       "         'dropna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Do not include columns whose entries are all NaN.\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, {‘all’, ‘index’, ‘columns’}, or {0,1}, default False. Normalize by dividing all values by the sum of values.\\n\\nIf passed ‘all’ or True, will normalize over all values.\\nIf passed ‘index’ will normalize over each row.\\nIf passed ‘columns’ will normalize over each column.\\nIf margins is True, will also normalize margin values.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'qcut(x,\\xa0q[,\\xa0labels,\\xa0retbins,\\xa0precision,\\xa0...])',\n",
       "      'func_desc': 'Quantile-based discretization function.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.qcut.html#pandas.qcut',\n",
       "      'function_definitions': {'function_name': 'pandas.qcut',\n",
       "       'full_function': \"pandas.qcut(x, q, labels=None, retbins=False, precision=3, duplicates='raise')\",\n",
       "       'function_text': 'Quantile-based discretization function. Discretize variable into equal-sized buckets based on rank or based\\non sample quantiles. For example 1000 values for 10 quantiles would\\nproduce a Categorical object indicating quantile membership for each data point.',\n",
       "       'parameter_names_desc': [{'param_name': 'x',\n",
       "         'param_type': '1d ndarray or Series',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'q',\n",
       "         'param_type': 'int or list-like of float',\n",
       "         'param_desc': 'Number of quantiles. 10 for deciles, 4 for quartiles, etc. Alternately\\narray of quantiles, e.g. [0, .25, .5, .75, 1.] for quartiles.\\n'},\n",
       "        {'param_name': 'labels',\n",
       "         'param_type': 'array or False, default None',\n",
       "         'param_desc': 'Used as labels for the resulting bins. Must be of the same length as\\nthe resulting bins. If False, return only integer indicators of the\\nbins. If True, raises an error.\\n'},\n",
       "        {'param_name': 'retbins',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'Whether to return the (bins, labels) or not. Can be useful if bins\\nis given as a scalar.\\n'},\n",
       "        {'param_name': 'precision',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'The precision at which to store and display the bins labels.\\n'},\n",
       "        {'param_name': 'duplicates',\n",
       "         'param_type': '{default ‘raise’, ‘drop’}, optional',\n",
       "         'param_desc': 'If bin edges are not unique, raise ValueError or drop non-uniques.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.qcut',\n",
       "       'descriptions': 'Quantile-based discretization function. Discretize variable into equal-sized buckets based on rank or based\\non sample quantiles. For example 1000 values for 10 quantiles would\\nproduce a Categorical object indicating quantile membership for each data point.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'x': {'type': 'array',\n",
       "          'description': '1d ndarray or Series. '},\n",
       "         'q': {'type': 'integer',\n",
       "          'description': 'int or list-like of float. Number of quantiles. 10 for deciles, 4 for quartiles, etc. Alternately\\narray of quantiles, e.g. [0, .25, .5, .75, 1.] for quartiles.\\n'},\n",
       "         'labels': {'type': 'array',\n",
       "          'description': 'array or False, default None. Used as labels for the resulting bins. Must be of the same length as\\nthe resulting bins. If False, return only integer indicators of the\\nbins. If True, raises an error.\\n'},\n",
       "         'retbins': {'type': 'boolean',\n",
       "          'description': 'bool, optional. Whether to return the (bins, labels) or not. Can be useful if bins\\nis given as a scalar.\\n'},\n",
       "         'precision': {'type': 'integer',\n",
       "          'description': 'int, optional. The precision at which to store and display the bins labels.\\n'},\n",
       "         'duplicates': {'type': 'string',\n",
       "          'enum': ['default raise', ' drop'],\n",
       "          'description': '{default ‘raise’, ‘drop’}, optional. If bin edges are not unique, raise ValueError or drop non-uniques.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'merge_ordered(left,\\xa0right[,\\xa0on,\\xa0left_on,\\xa0...])',\n",
       "      'func_desc': 'Perform a merge for ordered data with optional filling/interpolation.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.merge_ordered.html#pandas.merge_ordered',\n",
       "      'function_definitions': {'function_name': 'pandas.merge_ordered',\n",
       "       'full_function': \"pandas.merge_ordered(left, right, on=None, left_on=None, right_on=None, left_by=None, right_by=None, fill_method=None, suffixes=('_x', '_y'), how='outer')\",\n",
       "       'function_text': 'Perform a merge for ordered data with optional filling/interpolation. Designed for ordered data like time series data. Optionally\\nperform group-wise merge (see examples).',\n",
       "       'parameter_names_desc': [{'param_name': 'left',\n",
       "         'param_type': 'DataFrame or named Series',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'right',\n",
       "         'param_type': 'DataFrame or named Series',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'on',\n",
       "         'param_type': 'label or list',\n",
       "         'param_desc': 'Field names to join on. Must be found in both DataFrames.\\n'},\n",
       "        {'param_name': 'left_on',\n",
       "         'param_type': 'label or list, or array-like',\n",
       "         'param_desc': 'Field names to join on in left DataFrame. Can be a vector or list of\\nvectors of the length of the DataFrame to use a particular vector as\\nthe join key instead of columns.\\n'},\n",
       "        {'param_name': 'right_on',\n",
       "         'param_type': 'label or list, or array-like',\n",
       "         'param_desc': 'Field names to join on in right DataFrame or vector/list of vectors per\\nleft_on docs.\\n'},\n",
       "        {'param_name': 'left_by',\n",
       "         'param_type': 'column name or list of column names',\n",
       "         'param_desc': 'Group left DataFrame by group columns and merge piece by piece with\\nright DataFrame. Must be None if either left or right are a Series.\\n'},\n",
       "        {'param_name': 'right_by',\n",
       "         'param_type': 'column name or list of column names',\n",
       "         'param_desc': 'Group right DataFrame by group columns and merge piece by piece with\\nleft DataFrame. Must be None if either left or right are a Series.\\n'},\n",
       "        {'param_name': 'fill_method',\n",
       "         'param_type': '{‘ffill’, None}, default None',\n",
       "         'param_desc': 'Interpolation method for data.\\n'},\n",
       "        {'param_name': 'suffixes',\n",
       "         'param_type': 'list-like, default is (“_x”, “_y”)',\n",
       "         'param_desc': 'A length-2 sequence where each element is optionally a string\\nindicating the suffix to add to overlapping column names in\\nleft and right respectively. Pass a value of None instead\\nof a string to indicate that the column name from left or\\nright should be left as-is, with no suffix. At least one of the\\nvalues must not be None.\\n'},\n",
       "        {'param_name': 'how',\n",
       "         'param_type': '{‘left’, ‘right’, ‘outer’, ‘inner’}, default ‘outer’',\n",
       "         'param_desc': '\\nleft: use only keys from left frame (SQL: left outer join)\\nright: use only keys from right frame (SQL: right outer join)\\nouter: use union of keys from both frames (SQL: full outer join)\\ninner: use intersection of keys from both frames (SQL: inner join).\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.merge_ordered',\n",
       "       'descriptions': 'Perform a merge for ordered data with optional filling/interpolation. Designed for ordered data like time series data. Optionally\\nperform group-wise merge (see examples).',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'left': {'type': 'DataFrame or named Series',\n",
       "          'description': 'DataFrame or named Series. '},\n",
       "         'right': {'type': 'DataFrame or named Series',\n",
       "          'description': 'DataFrame or named Series. '},\n",
       "         'on': {'type': 'array',\n",
       "          'description': 'label or list. Field names to join on. Must be found in both DataFrames.\\n'},\n",
       "         'left_on': {'type': 'array',\n",
       "          'description': 'label or list, or array-like. Field names to join on in left DataFrame. Can be a vector or list of\\nvectors of the length of the DataFrame to use a particular vector as\\nthe join key instead of columns.\\n'},\n",
       "         'right_on': {'type': 'array',\n",
       "          'description': 'label or list, or array-like. Field names to join on in right DataFrame or vector/list of vectors per\\nleft_on docs.\\n'},\n",
       "         'left_by': {'type': 'array',\n",
       "          'description': 'column name or list of column names. Group left DataFrame by group columns and merge piece by piece with\\nright DataFrame. Must be None if either left or right are a Series.\\n'},\n",
       "         'right_by': {'type': 'array',\n",
       "          'description': 'column name or list of column names. Group right DataFrame by group columns and merge piece by piece with\\nleft DataFrame. Must be None if either left or right are a Series.\\n'},\n",
       "         'fill_method': {'type': 'string',\n",
       "          'enum': ['ffill', ' None'],\n",
       "          'description': '{‘ffill’, None}, default None. Interpolation method for data.\\n'},\n",
       "         'suffixes': {'type': 'array',\n",
       "          'description': 'list-like, default is (“_x”, “_y”). A length-2 sequence where each element is optionally a string\\nindicating the suffix to add to overlapping column names in\\nleft and right respectively. Pass a value of None instead\\nof a string to indicate that the column name from left or\\nright should be left as-is, with no suffix. At least one of the\\nvalues must not be None.\\n'},\n",
       "         'how': {'type': 'string',\n",
       "          'enum': ['left', ' right', ' outer', ' inner'],\n",
       "          'description': '{‘left’, ‘right’, ‘outer’, ‘inner’}, default ‘outer’. \\nleft: use only keys from left frame (SQL: left outer join)\\nright: use only keys from right frame (SQL: right outer join)\\nouter: use union of keys from both frames (SQL: full outer join)\\ninner: use intersection of keys from both frames (SQL: inner join).\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'concat(objs,\\xa0*[,\\xa0axis,\\xa0join,\\xa0ignore_index,\\xa0...])',\n",
       "      'func_desc': 'Concatenate pandas objects along a particular axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.concat.html#pandas.concat',\n",
       "      'function_definitions': {'function_name': 'pandas.concat',\n",
       "       'full_function': \"pandas.concat(objs, *, axis=0, join='outer', ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, sort=False, copy=None)\",\n",
       "       'function_text': 'Concatenate pandas objects along a particular axis. Allows optional set logic along the other axes. Can also add a layer of hierarchical indexing on the concatenation axis,\\nwhich may be useful if the labels are the same (or overlapping) on\\nthe passed axis number.',\n",
       "       'parameter_names_desc': [{'param_name': 'objs',\n",
       "         'param_type': 'a sequence or mapping of Series or DataFrame objects',\n",
       "         'param_desc': 'If a mapping is passed, the sorted keys will be used as the keys\\nargument, unless it is passed, in which case the values will be\\nselected (see below). Any None objects will be dropped silently unless\\nthey are all None in which case a ValueError will be raised.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0/’index’, 1/’columns’}, default 0',\n",
       "         'param_desc': 'The axis to concatenate along.\\n'},\n",
       "        {'param_name': 'join',\n",
       "         'param_type': '{‘inner’, ‘outer’}, default ‘outer’',\n",
       "         'param_desc': 'How to handle indexes on other axis (or axes).\\n'},\n",
       "        {'param_name': 'ignore_index',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True, do not use the index values along the concatenation axis. The\\nresulting axis will be labeled 0, …, n - 1. This is useful if you are\\nconcatenating objects where the concatenation axis does not have\\nmeaningful indexing information. Note the index values on the other\\naxes are still respected in the join.\\n'},\n",
       "        {'param_name': 'keys',\n",
       "         'param_type': 'sequence, default None',\n",
       "         'param_desc': 'If multiple levels passed, should contain tuples. Construct\\nhierarchical index using the passed keys as the outermost level.\\n'},\n",
       "        {'param_name': 'levels',\n",
       "         'param_type': 'list of sequences, default None',\n",
       "         'param_desc': 'Specific levels (unique values) to use for constructing a\\nMultiIndex. Otherwise they will be inferred from the keys.\\n'},\n",
       "        {'param_name': 'names',\n",
       "         'param_type': 'list, default None',\n",
       "         'param_desc': 'Names for the levels in the resulting hierarchical index.\\n'},\n",
       "        {'param_name': 'verify_integrity',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Check whether the new concatenated axis contains duplicates. This can\\nbe very expensive relative to the actual data concatenation.\\n'},\n",
       "        {'param_name': 'sort',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Sort non-concatenation axis if it is not already aligned. One exception to\\nthis is when the non-concatentation axis is a DatetimeIndex and join=’outer’\\nand the axis is not already aligned. In that case, the non-concatenation\\naxis is always sorted lexicographically.\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If False, do not copy data unnecessarily.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.concat',\n",
       "       'descriptions': 'Concatenate pandas objects along a particular axis. Allows optional set logic along the other axes. Can also add a layer of hierarchical indexing on the concatenation axis,\\nwhich may be useful if the labels are the same (or overlapping) on\\nthe passed axis number.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'objs': {'type': 'object',\n",
       "          'description': 'a sequence or mapping of Series or DataFrame objects. If a mapping is passed, the sorted keys will be used as the keys\\nargument, unless it is passed, in which case the values will be\\nselected (see below). Any None objects will be dropped silently unless\\nthey are all None in which case a ValueError will be raised.\\n'},\n",
       "         'axis': {'type': '{0/’index’, 1/’columns’}, default 0',\n",
       "          'description': '{0/’index’, 1/’columns’}, default 0. The axis to concatenate along.\\n'},\n",
       "         'join': {'type': 'string',\n",
       "          'enum': ['inner', ' outer'],\n",
       "          'description': '{‘inner’, ‘outer’}, default ‘outer’. How to handle indexes on other axis (or axes).\\n'},\n",
       "         'ignore_index': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True, do not use the index values along the concatenation axis. The\\nresulting axis will be labeled 0, …, n - 1. This is useful if you are\\nconcatenating objects where the concatenation axis does not have\\nmeaningful indexing information. Note the index values on the other\\naxes are still respected in the join.\\n'},\n",
       "         'keys': {'type': 'sequence, default None',\n",
       "          'description': 'sequence, default None. If multiple levels passed, should contain tuples. Construct\\nhierarchical index using the passed keys as the outermost level.\\n'},\n",
       "         'levels': {'type': 'array',\n",
       "          'description': 'list of sequences, default None. Specific levels (unique values) to use for constructing a\\nMultiIndex. Otherwise they will be inferred from the keys.\\n'},\n",
       "         'names': {'type': 'array',\n",
       "          'description': 'list, default None. Names for the levels in the resulting hierarchical index.\\n'},\n",
       "         'verify_integrity': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Check whether the new concatenated axis contains duplicates. This can\\nbe very expensive relative to the actual data concatenation.\\n'},\n",
       "         'sort': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Sort non-concatenation axis if it is not already aligned. One exception to\\nthis is when the non-concatentation axis is a DatetimeIndex and join=’outer’\\nand the axis is not already aligned. In that case, the non-concatenation\\naxis is always sorted lexicographically.\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If False, do not copy data unnecessarily.\\n'}},\n",
       "        'required': ['objs']}}},\n",
       "     {'func_name': 'from_dummies(data[,\\xa0sep,\\xa0default_category])',\n",
       "      'func_desc': 'Create a categorical DataFrame from a DataFrame of dummy variables.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.from_dummies.html#pandas.from_dummies',\n",
       "      'function_definitions': {'function_name': 'pandas.from_dummies',\n",
       "       'full_function': 'pandas.from_dummies(data, sep=None, default_category=None)',\n",
       "       'function_text': 'Create a categorical DataFrame from a DataFrame of dummy variables. Inverts the operation performed by get_dummies(). New in version 1.5.0.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'unique(values)',\n",
       "      'func_desc': 'Return unique values based on a hash table.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.unique.html#pandas.unique',\n",
       "      'function_definitions': {'function_name': 'pandas.unique',\n",
       "       'full_function': 'pandas.unique(values)',\n",
       "       'function_text': 'Return unique values based on a hash table. Uniques are returned in order of appearance. This does NOT sort. Significantly faster than numpy.unique for long enough sequences.\\nIncludes NA values.',\n",
       "       'parameter_names_desc': [{'param_name': 'values',\n",
       "         'param_type': '1d array-like',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.unique',\n",
       "       'descriptions': 'Return unique values based on a hash table. Uniques are returned in order of appearance. This does NOT sort. Significantly faster than numpy.unique for long enough sequences.\\nIncludes NA values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'values': {'type': 'array',\n",
       "          'description': '1d array-like. '}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'wide_to_long(df,\\xa0stubnames,\\xa0i,\\xa0j[,\\xa0sep,\\xa0suffix])',\n",
       "      'func_desc': 'Unpivot a DataFrame from wide to long format.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.wide_to_long.html#pandas.wide_to_long',\n",
       "      'function_definitions': {'function_name': 'pandas.wide_to_long',\n",
       "       'full_function': \"pandas.wide_to_long(df, stubnames, i, j, sep='', suffix='\\\\\\\\d+')\",\n",
       "       'function_text': 'Unpivot a DataFrame from wide to long format. Less flexible but more user-friendly than melt. With stubnames [‘A’, ‘B’], this function expects to find one or more\\ngroup of columns with format\\nA-suffix1, A-suffix2,…, B-suffix1, B-suffix2,…\\nYou specify what you want to call this suffix in the resulting long format\\nwith j (for example j=’year’) Each row of these wide variables are assumed to be uniquely identified by\\ni (can be a single column name or a list of column names) All remaining variables in the data frame are left intact.',\n",
       "       'parameter_names_desc': [{'param_name': 'df',\n",
       "         'param_type': 'DataFrame',\n",
       "         'param_desc': 'The wide-format DataFrame.\\n'},\n",
       "        {'param_name': 'stubnames',\n",
       "         'param_type': 'str or list-like',\n",
       "         'param_desc': 'The stub name(s). The wide format variables are assumed to\\nstart with the stub names.\\n'},\n",
       "        {'param_name': 'i',\n",
       "         'param_type': 'str or list-like',\n",
       "         'param_desc': 'Column(s) to use as id variable(s).\\n'},\n",
       "        {'param_name': 'j',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'The name of the sub-observation variable. What you wish to name your\\nsuffix in the long format.\\n'},\n",
       "        {'param_name': 'sep',\n",
       "         'param_type': 'str, default “”',\n",
       "         'param_desc': 'A character indicating the separation of the variable names\\nin the wide format, to be stripped from the names in the long format.\\nFor example, if your column names are A-suffix1, A-suffix2, you\\ncan strip the hyphen by specifying sep=’-’.\\n'},\n",
       "        {'param_name': 'suffix',\n",
       "         'param_type': 'str, default ‘\\\\d+’',\n",
       "         'param_desc': 'A regular expression capturing the wanted suffixes. ‘\\\\d+’ captures\\nnumeric suffixes. Suffixes with no numbers could be specified with the\\nnegated character class ‘\\\\D+’. You can also further disambiguate\\nsuffixes, for example, if your wide variables are of the form A-one,\\nB-two,.., and you have an unrelated column A-rating, you can ignore the\\nlast one by specifying suffix=’(!?one|two)’. When all suffixes are\\nnumeric, they are cast to int64/float64.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.wide_to_long',\n",
       "       'descriptions': 'Unpivot a DataFrame from wide to long format. Less flexible but more user-friendly than melt. With stubnames [‘A’, ‘B’], this function expects to find one or more\\ngroup of columns with format\\nA-suffix1, A-suffix2,…, B-suffix1, B-suffix2,…\\nYou specify what you want to call this suffix in the resulting long format\\nwith j (for example j=’year’) Each row of these wide variables are assumed to be uniquely identified by\\ni (can be a single column name or a list of column names) All remaining variables in the data frame are left intact.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'df': {'type': 'DataFrame',\n",
       "          'description': 'DataFrame. The wide-format DataFrame.\\n'},\n",
       "         'stubnames': {'type': 'string',\n",
       "          'description': 'str or list-like. The stub name(s). The wide format variables are assumed to\\nstart with the stub names.\\n'},\n",
       "         'i': {'type': 'string',\n",
       "          'description': 'str or list-like. Column(s) to use as id variable(s).\\n'},\n",
       "         'j': {'type': 'string',\n",
       "          'description': 'str. The name of the sub-observation variable. What you wish to name your\\nsuffix in the long format.\\n'},\n",
       "         'sep': {'type': 'string',\n",
       "          'description': 'str, default “”. A character indicating the separation of the variable names\\nin the wide format, to be stripped from the names in the long format.\\nFor example, if your column names are A-suffix1, A-suffix2, you\\ncan strip the hyphen by specifying sep=’-’.\\n'},\n",
       "         'suffix': {'type': 'string',\n",
       "          'description': 'str, default ‘\\\\d+’. A regular expression capturing the wanted suffixes. ‘\\\\d+’ captures\\nnumeric suffixes. Suffixes with no numbers could be specified with the\\nnegated character class ‘\\\\D+’. You can also further disambiguate\\nsuffixes, for example, if your wide variables are of the form A-one,\\nB-two,.., and you have an unrelated column A-rating, you can ignore the\\nlast one by specifying suffix=’(!?one|two)’. When all suffixes are\\nnumeric, they are cast to int64/float64.\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Top-level missing data': [{'func_name': 'isna(obj)',\n",
       "      'func_desc': 'Detect missing values for an array-like object.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.isna.html#pandas.isna',\n",
       "      'function_definitions': {'function_name': 'pandas.isna',\n",
       "       'full_function': 'pandas.isna(obj)',\n",
       "       'function_text': 'Detect missing values for an array-like object. This function takes a scalar or array-like object and indicates\\nwhether values are missing (NaN in numeric arrays, None or NaN\\nin object arrays, NaT in datetimelike).',\n",
       "       'parameter_names_desc': [{'param_name': 'obj',\n",
       "         'param_type': 'scalar or array-like',\n",
       "         'param_desc': 'Object to check for null or missing values.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.isna',\n",
       "       'descriptions': 'Detect missing values for an array-like object. This function takes a scalar or array-like object and indicates\\nwhether values are missing (NaN in numeric arrays, None or NaN\\nin object arrays, NaT in datetimelike).',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'obj': {'type': 'array',\n",
       "          'description': 'scalar or array-like. Object to check for null or missing values.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'notna(obj)',\n",
       "      'func_desc': 'Detect non-missing values for an array-like object.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.notna.html#pandas.notna',\n",
       "      'function_definitions': {'function_name': 'pandas.notna',\n",
       "       'full_function': 'pandas.notna(obj)',\n",
       "       'function_text': 'Detect non-missing values for an array-like object. This function takes a scalar or array-like object and indicates\\nwhether values are valid (not missing, which is NaN in numeric\\narrays, None or NaN in object arrays, NaT in datetimelike).',\n",
       "       'parameter_names_desc': [{'param_name': 'obj',\n",
       "         'param_type': 'array-like or object value',\n",
       "         'param_desc': 'Object to check for not null or non-missing values.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.notna',\n",
       "       'descriptions': 'Detect non-missing values for an array-like object. This function takes a scalar or array-like object and indicates\\nwhether values are valid (not missing, which is NaN in numeric\\narrays, None or NaN in object arrays, NaT in datetimelike).',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'obj': {'type': 'object',\n",
       "          'description': 'array-like or object value. Object to check for not null or non-missing values.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'isnull(obj)',\n",
       "      'func_desc': 'Detect missing values for an array-like object.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.isnull.html#pandas.isnull',\n",
       "      'function_definitions': {'function_name': 'pandas.isnull',\n",
       "       'full_function': 'pandas.isnull(obj)',\n",
       "       'function_text': 'Detect missing values for an array-like object. This function takes a scalar or array-like object and indicates\\nwhether values are missing (NaN in numeric arrays, None or NaN\\nin object arrays, NaT in datetimelike).',\n",
       "       'parameter_names_desc': [{'param_name': 'obj',\n",
       "         'param_type': 'scalar or array-like',\n",
       "         'param_desc': 'Object to check for null or missing values.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.isnull',\n",
       "       'descriptions': 'Detect missing values for an array-like object. This function takes a scalar or array-like object and indicates\\nwhether values are missing (NaN in numeric arrays, None or NaN\\nin object arrays, NaT in datetimelike).',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'obj': {'type': 'array',\n",
       "          'description': 'scalar or array-like. Object to check for null or missing values.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'notnull(obj)',\n",
       "      'func_desc': 'Detect non-missing values for an array-like object.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.notnull.html#pandas.notnull',\n",
       "      'function_definitions': {'function_name': 'pandas.notnull',\n",
       "       'full_function': 'pandas.notnull(obj)',\n",
       "       'function_text': 'Detect non-missing values for an array-like object. This function takes a scalar or array-like object and indicates\\nwhether values are valid (not missing, which is NaN in numeric\\narrays, None or NaN in object arrays, NaT in datetimelike).',\n",
       "       'parameter_names_desc': [{'param_name': 'obj',\n",
       "         'param_type': 'array-like or object value',\n",
       "         'param_desc': 'Object to check for not null or non-missing values.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.notnull',\n",
       "       'descriptions': 'Detect non-missing values for an array-like object. This function takes a scalar or array-like object and indicates\\nwhether values are valid (not missing, which is NaN in numeric\\narrays, None or NaN in object arrays, NaT in datetimelike).',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'obj': {'type': 'object',\n",
       "          'description': 'array-like or object value. Object to check for not null or non-missing values.\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Top-level dealing with numeric data': [{'func_name': 'to_numeric(arg[,\\xa0errors,\\xa0downcast,\\xa0...])',\n",
       "      'func_desc': 'Convert argument to a numeric type.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.to_numeric.html#pandas.to_numeric',\n",
       "      'function_definitions': {'function_name': 'pandas.to_numeric',\n",
       "       'full_function': \"pandas.to_numeric(arg, errors='raise', downcast=None, dtype_backend=_NoDefault.no_default)\",\n",
       "       'function_text': 'Convert argument to a numeric type. The default return dtype is float64 or int64\\ndepending on the data supplied. Use the downcast parameter\\nto obtain other dtypes. Please note that precision loss may occur if really large numbers\\nare passed in. Due to the internal limitations of ndarray, if\\nnumbers smaller than -9223372036854775808 (np.iinfo(np.int64).min)\\nor larger than 18446744073709551615 (np.iinfo(np.uint64).max) are\\npassed in, it is very likely they will be converted to float so that\\nthey can be stored in an ndarray. These warnings apply similarly to\\nSeries since it internally leverages ndarray.',\n",
       "       'parameter_names_desc': [{'param_name': 'arg',\n",
       "         'param_type': 'scalar, list, tuple, 1-d array, or Series',\n",
       "         'param_desc': 'Argument to be converted.\\n'},\n",
       "        {'param_name': 'errors',\n",
       "         'param_type': '{‘ignore’, ‘raise’, ‘coerce’}, default ‘raise’',\n",
       "         'param_desc': '\\nIf ‘raise’, then invalid parsing will raise an exception.\\nIf ‘coerce’, then invalid parsing will be set as NaN.\\nIf ‘ignore’, then invalid parsing will return the input.\\n\\n\\nChanged in version 2.2.\\n\\n“ignore” is deprecated. Catch exceptions explicitly instead.\\n'},\n",
       "        {'param_name': 'downcast',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'Can be ‘integer’, ‘signed’, ‘unsigned’, or ‘float’.\\nIf not None, and if the data has been successfully cast to a\\nnumerical dtype (or if the data was numeric to begin with),\\ndowncast that resulting data to the smallest numerical dtype\\npossible according to the following rules:\\n\\n‘integer’ or ‘signed’: smallest signed int dtype (min.: np.int8)\\n‘unsigned’: smallest unsigned int dtype (min.: np.uint8)\\n‘float’: smallest float dtype (min.: np.float32)\\n\\nAs this behaviour is separate from the core conversion to\\nnumeric values, any errors raised during the downcasting\\nwill be surfaced regardless of the value of the ‘errors’ input.\\nIn addition, downcasting will only occur if the size\\nof the resulting data’s dtype is strictly larger than\\nthe dtype it is to be cast to, so if none of the dtypes\\nchecked satisfy that specification, no downcasting will be\\nperformed on the data.\\n'},\n",
       "        {'param_name': 'dtype_backend',\n",
       "         'param_type': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’',\n",
       "         'param_desc': 'Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.to_numeric',\n",
       "       'descriptions': 'Convert argument to a numeric type. The default return dtype is float64 or int64\\ndepending on the data supplied. Use the downcast parameter\\nto obtain other dtypes. Please note that precision loss may occur if really large numbers\\nare passed in. Due to the internal limitations of ndarray, if\\nnumbers smaller than -9223372036854775808 (np.iinfo(np.int64).min)\\nor larger than 18446744073709551615 (np.iinfo(np.uint64).max) are\\npassed in, it is very likely they will be converted to float so that\\nthey can be stored in an ndarray. These warnings apply similarly to\\nSeries since it internally leverages ndarray.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'arg': {'type': 'array',\n",
       "          'description': 'scalar, list, tuple, 1-d array, or Series. Argument to be converted.\\n'},\n",
       "         'errors': {'type': 'string',\n",
       "          'enum': ['ignore', ' raise', ' coerce'],\n",
       "          'description': '{‘ignore’, ‘raise’, ‘coerce’}, default ‘raise’. \\nIf ‘raise’, then invalid parsing will raise an exception.\\nIf ‘coerce’, then invalid parsing will be set as NaN.\\nIf ‘ignore’, then invalid parsing will return the input.\\n\\n\\nChanged in version 2.2.\\n\\n“ignore” is deprecated. Catch exceptions explicitly instead.\\n'},\n",
       "         'downcast': {'type': 'string',\n",
       "          'description': 'str, default None. Can be ‘integer’, ‘signed’, ‘unsigned’, or ‘float’.\\nIf not None, and if the data has been successfully cast to a\\nnumerical dtype (or if the data was numeric to begin with),\\ndowncast that resulting data to the smallest numerical dtype\\npossible according to the following rules:\\n\\n‘integer’ or ‘signed’: smallest signed int dtype (min.: np.int8)\\n‘unsigned’: smallest unsigned int dtype (min.: np.uint8)\\n‘float’: smallest float dtype (min.: np.float32)\\n\\nAs this behaviour is separate from the core conversion to\\nnumeric values, any errors raised during the downcasting\\nwill be surfaced regardless of the value of the ‘errors’ input.\\nIn addition, downcasting will only occur if the size\\nof the resulting data’s dtype is strictly larger than\\nthe dtype it is to be cast to, so if none of the dtypes\\nchecked satisfy that specification, no downcasting will be\\nperformed on the data.\\n'},\n",
       "         'dtype_backend': {'type': 'string',\n",
       "          'enum': ['numpy_nullable', ' pyarrow'],\n",
       "          'description': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’. Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Top-level dealing with datetimelike data': [{'func_name': 'to_datetime(arg[,\\xa0errors,\\xa0dayfirst,\\xa0...])',\n",
       "      'func_desc': 'Convert argument to datetime.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html#pandas.to_datetime',\n",
       "      'function_definitions': {'function_name': 'pandas.to_datetime',\n",
       "       'full_function': \"pandas.to_datetime(arg, errors='raise', dayfirst=False, yearfirst=False, utc=False, format=None, exact=_NoDefault.no_default, unit=None, infer_datetime_format=_NoDefault.no_default, origin='unix', cache=True)\",\n",
       "       'function_text': 'Convert argument to datetime. This function converts a scalar, array-like, Series or\\nDataFrame/dict-like to a pandas datetime object.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'date_range([start,\\xa0end,\\xa0periods,\\xa0freq,\\xa0tz,\\xa0...])',\n",
       "      'func_desc': 'Return a fixed frequency DatetimeIndex.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.date_range.html#pandas.date_range',\n",
       "      'function_definitions': {'function_name': 'pandas.date_range',\n",
       "       'full_function': \"pandas.date_range(start=None, end=None, periods=None, freq=None, tz=None, normalize=False, name=None, inclusive='both', *, unit=None, **kwargs)\",\n",
       "       'function_text': 'Return a fixed frequency DatetimeIndex. Returns the range of equally spaced time points (where the difference between any\\ntwo adjacent points is specified by the given frequency) such that they all\\nsatisfy start <[=] x <[=] end, where the first one and the last one are, resp.,\\nthe first and last time points in that range that fall on the boundary of freq\\n(if given as a frequency string) or that are valid for freq (if given as a\\npandas.tseries.offsets.DateOffset). (If exactly one of start,\\nend, or freq is not specified, this missing parameter can be computed\\ngiven periods, the number of timesteps in the range. See the note below.)',\n",
       "       'parameter_names_desc': [{'param_name': 'start',\n",
       "         'param_type': 'str or datetime-like, optional',\n",
       "         'param_desc': 'Left bound for generating dates.\\n'},\n",
       "        {'param_name': 'end',\n",
       "         'param_type': 'str or datetime-like, optional',\n",
       "         'param_desc': 'Right bound for generating dates.\\n'},\n",
       "        {'param_name': 'periods',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Number of periods to generate.\\n'},\n",
       "        {'param_name': 'freq',\n",
       "         'param_type': 'str, Timedelta, datetime.timedelta, or DateOffset, default ‘D’',\n",
       "         'param_desc': 'Frequency strings can have multiples, e.g. ‘5h’. See\\nhere for a list of\\nfrequency aliases.\\n'},\n",
       "        {'param_name': 'tz',\n",
       "         'param_type': 'str or tzinfo, optional',\n",
       "         'param_desc': 'Time zone name for returning localized DatetimeIndex, for example\\n‘Asia/Hong_Kong’. By default, the resulting DatetimeIndex is\\ntimezone-naive unless timezone-aware datetime-likes are passed.\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "        {'param_name': 'name',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'Name of the resulting DatetimeIndex.\\n'},\n",
       "        {'param_name': 'inclusive',\n",
       "         'param_type': '{“both”, “neither”, “left”, “right”}, default “both”',\n",
       "         'param_desc': 'Include boundaries; Whether to set each bound as closed or open.\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "        {'param_name': 'unit',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'Specify the desired resolution of the result.\\n\\nNew in version 2.0.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.date_range',\n",
       "       'descriptions': 'Return a fixed frequency DatetimeIndex. Returns the range of equally spaced time points (where the difference between any\\ntwo adjacent points is specified by the given frequency) such that they all\\nsatisfy start <[=] x <[=] end, where the first one and the last one are, resp.,\\nthe first and last time points in that range that fall on the boundary of freq\\n(if given as a frequency string) or that are valid for freq (if given as a\\npandas.tseries.offsets.DateOffset). (If exactly one of start,\\nend, or freq is not specified, this missing parameter can be computed\\ngiven periods, the number of timesteps in the range. See the note below.)',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'start': {'type': 'string',\n",
       "          'description': 'str or datetime-like, optional. Left bound for generating dates.\\n'},\n",
       "         'end': {'type': 'string',\n",
       "          'description': 'str or datetime-like, optional. Right bound for generating dates.\\n'},\n",
       "         'periods': {'type': 'integer',\n",
       "          'description': 'int, optional. Number of periods to generate.\\n'},\n",
       "         'freq': {'type': 'string',\n",
       "          'description': 'str, Timedelta, datetime.timedelta, or DateOffset, default ‘D’. Frequency strings can have multiples, e.g. ‘5h’. See\\nhere for a list of\\nfrequency aliases.\\n'},\n",
       "         'tz': {'type': 'string',\n",
       "          'description': 'str or tzinfo, optional. Time zone name for returning localized DatetimeIndex, for example\\n‘Asia/Hong_Kong’. By default, the resulting DatetimeIndex is\\ntimezone-naive unless timezone-aware datetime-likes are passed.\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "         'name': {'type': 'string',\n",
       "          'description': 'str, default None. Name of the resulting DatetimeIndex.\\n'},\n",
       "         'inclusive': {'type': '{“both”, “neither”, “left”, “right”}, default “both”',\n",
       "          'description': '{“both”, “neither”, “left”, “right”}, default “both”. Include boundaries; Whether to set each bound as closed or open.\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "         'unit': {'type': 'string',\n",
       "          'description': 'str, default None. Specify the desired resolution of the result.\\n\\nNew in version 2.0.0.\\n\\n'}},\n",
       "        'required': ['start=None',\n",
       "         'end=None',\n",
       "         'periods=None',\n",
       "         'freq=None',\n",
       "         'tz=None',\n",
       "         'normalize=False',\n",
       "         'name=None',\n",
       "         \"inclusive='both'\"]}}},\n",
       "     {'func_name': 'period_range([start,\\xa0end,\\xa0periods,\\xa0freq,\\xa0name])',\n",
       "      'func_desc': 'Return a fixed frequency PeriodIndex.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.period_range.html#pandas.period_range',\n",
       "      'function_definitions': {'function_name': 'pandas.period_range',\n",
       "       'full_function': 'pandas.period_range(start=None, end=None, periods=None, freq=None, name=None)',\n",
       "       'function_text': 'Return a fixed frequency PeriodIndex. The day (calendar) is the default frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'start',\n",
       "         'param_type': 'str, datetime, date, pandas.Timestamp, or period-like, default None',\n",
       "         'param_desc': 'Left bound for generating periods.\\n'},\n",
       "        {'param_name': 'end',\n",
       "         'param_type': 'str, datetime, date, pandas.Timestamp, or period-like, default None',\n",
       "         'param_desc': 'Right bound for generating periods.\\n'},\n",
       "        {'param_name': 'periods',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'Number of periods to generate.\\n'},\n",
       "        {'param_name': 'freq',\n",
       "         'param_type': 'str or DateOffset, optional',\n",
       "         'param_desc': 'Frequency alias. By default the freq is taken from start or end\\nif those are Period objects. Otherwise, the default is \"D\" for\\ndaily frequency.\\n'},\n",
       "        {'param_name': 'name',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'Name of the resulting PeriodIndex.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.period_range',\n",
       "       'descriptions': 'Return a fixed frequency PeriodIndex. The day (calendar) is the default frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'start': {'type': 'string',\n",
       "          'description': 'str, datetime, date, pandas.Timestamp, or period-like, default None. Left bound for generating periods.\\n'},\n",
       "         'end': {'type': 'string',\n",
       "          'description': 'str, datetime, date, pandas.Timestamp, or period-like, default None. Right bound for generating periods.\\n'},\n",
       "         'periods': {'type': 'integer',\n",
       "          'description': 'int, default None. Number of periods to generate.\\n'},\n",
       "         'freq': {'type': 'string',\n",
       "          'description': 'str or DateOffset, optional. Frequency alias. By default the freq is taken from start or end\\nif those are Period objects. Otherwise, the default is \"D\" for\\ndaily frequency.\\n'},\n",
       "         'name': {'type': 'string',\n",
       "          'description': 'str, default None. Name of the resulting PeriodIndex.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'infer_freq(index)',\n",
       "      'func_desc': 'Infer the most likely frequency given the input index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.infer_freq.html#pandas.infer_freq',\n",
       "      'function_definitions': {'function_name': 'pandas.infer_freq',\n",
       "       'full_function': 'pandas.infer_freq(index)',\n",
       "       'function_text': 'Infer the most likely frequency given the input index.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'to_timedelta(arg[,\\xa0unit,\\xa0errors])',\n",
       "      'func_desc': 'Convert argument to timedelta.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.to_timedelta.html#pandas.to_timedelta',\n",
       "      'function_definitions': {'function_name': 'pandas.to_timedelta',\n",
       "       'full_function': \"pandas.to_timedelta(arg, unit=None, errors='raise')\",\n",
       "       'function_text': 'Convert argument to timedelta. Timedeltas are absolute differences in times, expressed in difference\\nunits (e.g. days, hours, minutes, seconds). This method converts\\nan argument from a recognized timedelta format / value into\\na Timedelta type.',\n",
       "       'parameter_names_desc': [{'param_name': 'arg',\n",
       "         'param_type': 'str, timedelta, list-like or Series',\n",
       "         'param_desc': 'The data to be converted to timedelta.\\n\\nChanged in version 2.0: Strings with units ‘M’, ‘Y’ and ‘y’ do not represent\\nunambiguous timedelta values and will raise an exception.\\n\\n'},\n",
       "        {'param_name': 'unit',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Denotes the unit of the arg for numeric arg. Defaults to \"ns\".\\nPossible values:\\n\\n‘W’\\n‘D’ / ‘days’ / ‘day’\\n‘hours’ / ‘hour’ / ‘hr’ / ‘h’ / ‘H’\\n‘m’ / ‘minute’ / ‘min’ / ‘minutes’ / ‘T’\\n‘s’ / ‘seconds’ / ‘sec’ / ‘second’ / ‘S’\\n‘ms’ / ‘milliseconds’ / ‘millisecond’ / ‘milli’ / ‘millis’ / ‘L’\\n‘us’ / ‘microseconds’ / ‘microsecond’ / ‘micro’ / ‘micros’ / ‘U’\\n‘ns’ / ‘nanoseconds’ / ‘nano’ / ‘nanos’ / ‘nanosecond’ / ‘N’\\n\\nMust not be specified when arg contains strings and errors=\"raise\".\\n\\nDeprecated since version 2.2.0: Units ‘H’, ‘T’, ‘S’, ‘L’, ‘U’ and ‘N’ are deprecated and will be removed\\nin a future version. Please use ‘h’, ‘min’, ‘s’, ‘ms’, ‘us’, and ‘ns’\\ninstead of ‘H’, ‘T’, ‘S’, ‘L’, ‘U’ and ‘N’.\\n\\n'},\n",
       "        {'param_name': 'errors',\n",
       "         'param_type': '{‘ignore’, ‘raise’, ‘coerce’}, default ‘raise’',\n",
       "         'param_desc': '\\nIf ‘raise’, then invalid parsing will raise an exception.\\nIf ‘coerce’, then invalid parsing will be set as NaT.\\nIf ‘ignore’, then invalid parsing will return the input.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.to_timedelta',\n",
       "       'descriptions': 'Convert argument to timedelta. Timedeltas are absolute differences in times, expressed in difference\\nunits (e.g. days, hours, minutes, seconds). This method converts\\nan argument from a recognized timedelta format / value into\\na Timedelta type.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'arg': {'type': 'string',\n",
       "          'description': 'str, timedelta, list-like or Series. The data to be converted to timedelta.\\n\\nChanged in version 2.0: Strings with units ‘M’, ‘Y’ and ‘y’ do not represent\\nunambiguous timedelta values and will raise an exception.\\n\\n'},\n",
       "         'unit': {'type': 'string',\n",
       "          'description': 'str, optional. Denotes the unit of the arg for numeric arg. Defaults to \"ns\".\\nPossible values:\\n\\n‘W’\\n‘D’ / ‘days’ / ‘day’\\n‘hours’ / ‘hour’ / ‘hr’ / ‘h’ / ‘H’\\n‘m’ / ‘minute’ / ‘min’ / ‘minutes’ / ‘T’\\n‘s’ / ‘seconds’ / ‘sec’ / ‘second’ / ‘S’\\n‘ms’ / ‘milliseconds’ / ‘millisecond’ / ‘milli’ / ‘millis’ / ‘L’\\n‘us’ / ‘microseconds’ / ‘microsecond’ / ‘micro’ / ‘micros’ / ‘U’\\n‘ns’ / ‘nanoseconds’ / ‘nano’ / ‘nanos’ / ‘nanosecond’ / ‘N’\\n\\nMust not be specified when arg contains strings and errors=\"raise\".\\n\\nDeprecated since version 2.2.0: Units ‘H’, ‘T’, ‘S’, ‘L’, ‘U’ and ‘N’ are deprecated and will be removed\\nin a future version. Please use ‘h’, ‘min’, ‘s’, ‘ms’, ‘us’, and ‘ns’\\ninstead of ‘H’, ‘T’, ‘S’, ‘L’, ‘U’ and ‘N’.\\n\\n'},\n",
       "         'errors': {'type': 'string',\n",
       "          'enum': ['ignore', ' raise', ' coerce'],\n",
       "          'description': '{‘ignore’, ‘raise’, ‘coerce’}, default ‘raise’. \\nIf ‘raise’, then invalid parsing will raise an exception.\\nIf ‘coerce’, then invalid parsing will be set as NaT.\\nIf ‘ignore’, then invalid parsing will return the input.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'bdate_range([start,\\xa0end,\\xa0periods,\\xa0freq,\\xa0tz,\\xa0...])',\n",
       "      'func_desc': 'Return a fixed frequency DatetimeIndex with business day as the default.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.bdate_range.html#pandas.bdate_range',\n",
       "      'function_definitions': {'function_name': 'pandas.bdate_range',\n",
       "       'full_function': \"pandas.bdate_range(start=None, end=None, periods=None, freq='B', tz=None, normalize=True, name=None, weekmask=None, holidays=None, inclusive='both', **kwargs)\",\n",
       "       'function_text': 'Return a fixed frequency DatetimeIndex with business day as the default.',\n",
       "       'parameter_names_desc': [{'param_name': 'start',\n",
       "         'param_type': 'str or datetime-like, default None',\n",
       "         'param_desc': 'Left bound for generating dates.\\n'},\n",
       "        {'param_name': 'end',\n",
       "         'param_type': 'str or datetime-like, default None',\n",
       "         'param_desc': 'Right bound for generating dates.\\n'},\n",
       "        {'param_name': 'periods',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'Number of periods to generate.\\n'},\n",
       "        {'param_name': 'freq',\n",
       "         'param_type': 'str, Timedelta, datetime.timedelta, or DateOffset, default ‘B’',\n",
       "         'param_desc': 'Frequency strings can have multiples, e.g. ‘5h’. The default is\\nbusiness daily (‘B’).\\n'},\n",
       "        {'param_name': 'tz',\n",
       "         'param_type': 'str or None',\n",
       "         'param_desc': 'Time zone name for returning localized DatetimeIndex, for example\\nAsia/Beijing.\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "        {'param_name': 'name',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'Name of the resulting DatetimeIndex.\\n'},\n",
       "        {'param_name': 'weekmask',\n",
       "         'param_type': 'str or None, default None',\n",
       "         'param_desc': 'Weekmask of valid business days, passed to numpy.busdaycalendar,\\nonly used when custom frequency strings are passed. The default\\nvalue None is equivalent to ‘Mon Tue Wed Thu Fri’.\\n'},\n",
       "        {'param_name': 'holidays',\n",
       "         'param_type': 'list-like or None, default None',\n",
       "         'param_desc': 'Dates to exclude from the set of valid business days, passed to\\nnumpy.busdaycalendar, only used when custom frequency strings\\nare passed.\\n'},\n",
       "        {'param_name': 'inclusive',\n",
       "         'param_type': '{“both”, “neither”, “left”, “right”}, default “both”',\n",
       "         'param_desc': 'Include boundaries; Whether to set each bound as closed or open.\\n\\nNew in version 1.4.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.bdate_range',\n",
       "       'descriptions': 'Return a fixed frequency DatetimeIndex with business day as the default.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'start': {'type': 'string',\n",
       "          'description': 'str or datetime-like, default None. Left bound for generating dates.\\n'},\n",
       "         'end': {'type': 'string',\n",
       "          'description': 'str or datetime-like, default None. Right bound for generating dates.\\n'},\n",
       "         'periods': {'type': 'integer',\n",
       "          'description': 'int, default None. Number of periods to generate.\\n'},\n",
       "         'freq': {'type': 'string',\n",
       "          'description': 'str, Timedelta, datetime.timedelta, or DateOffset, default ‘B’. Frequency strings can have multiples, e.g. ‘5h’. The default is\\nbusiness daily (‘B’).\\n'},\n",
       "         'tz': {'type': 'string',\n",
       "          'description': 'str or None. Time zone name for returning localized DatetimeIndex, for example\\nAsia/Beijing.\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "         'name': {'type': 'string',\n",
       "          'description': 'str, default None. Name of the resulting DatetimeIndex.\\n'},\n",
       "         'weekmask': {'type': 'string',\n",
       "          'description': 'str or None, default None. Weekmask of valid business days, passed to numpy.busdaycalendar,\\nonly used when custom frequency strings are passed. The default\\nvalue None is equivalent to ‘Mon Tue Wed Thu Fri’.\\n'},\n",
       "         'holidays': {'type': 'array',\n",
       "          'description': 'list-like or None, default None. Dates to exclude from the set of valid business days, passed to\\nnumpy.busdaycalendar, only used when custom frequency strings\\nare passed.\\n'},\n",
       "         'inclusive': {'type': '{“both”, “neither”, “left”, “right”}, default “both”',\n",
       "          'description': '{“both”, “neither”, “left”, “right”}, default “both”. Include boundaries; Whether to set each bound as closed or open.\\n\\nNew in version 1.4.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'timedelta_range([start,\\xa0end,\\xa0periods,\\xa0freq,\\xa0...])',\n",
       "      'func_desc': 'Return a fixed frequency TimedeltaIndex with day as the default.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.timedelta_range.html#pandas.timedelta_range',\n",
       "      'function_definitions': {'function_name': 'pandas.timedelta_range',\n",
       "       'full_function': 'pandas.timedelta_range(start=None, end=None, periods=None, freq=None, name=None, closed=None, *, unit=None)',\n",
       "       'function_text': 'Return a fixed frequency TimedeltaIndex with day as the default.',\n",
       "       'parameter_names_desc': [{'param_name': 'start',\n",
       "         'param_type': 'str or timedelta-like, default None',\n",
       "         'param_desc': 'Left bound for generating timedeltas.\\n'},\n",
       "        {'param_name': 'end',\n",
       "         'param_type': 'str or timedelta-like, default None',\n",
       "         'param_desc': 'Right bound for generating timedeltas.\\n'},\n",
       "        {'param_name': 'periods',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'Number of periods to generate.\\n'},\n",
       "        {'param_name': 'freq',\n",
       "         'param_type': 'str, Timedelta, datetime.timedelta, or DateOffset, default ‘D’',\n",
       "         'param_desc': 'Frequency strings can have multiples, e.g. ‘5h’.\\n'},\n",
       "        {'param_name': 'name',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'Name of the resulting TimedeltaIndex.\\n'},\n",
       "        {'param_name': 'closed',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'Make the interval closed with respect to the given frequency to\\nthe ‘left’, ‘right’, or both sides (None).\\n'},\n",
       "        {'param_name': 'unit',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'Specify the desired resolution of the result.\\n\\nNew in version 2.0.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.timedelta_range',\n",
       "       'descriptions': 'Return a fixed frequency TimedeltaIndex with day as the default.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'start': {'type': 'string',\n",
       "          'description': 'str or timedelta-like, default None. Left bound for generating timedeltas.\\n'},\n",
       "         'end': {'type': 'string',\n",
       "          'description': 'str or timedelta-like, default None. Right bound for generating timedeltas.\\n'},\n",
       "         'periods': {'type': 'integer',\n",
       "          'description': 'int, default None. Number of periods to generate.\\n'},\n",
       "         'freq': {'type': 'string',\n",
       "          'description': 'str, Timedelta, datetime.timedelta, or DateOffset, default ‘D’. Frequency strings can have multiples, e.g. ‘5h’.\\n'},\n",
       "         'name': {'type': 'string',\n",
       "          'description': 'str, default None. Name of the resulting TimedeltaIndex.\\n'},\n",
       "         'closed': {'type': 'string',\n",
       "          'description': 'str, default None. Make the interval closed with respect to the given frequency to\\nthe ‘left’, ‘right’, or both sides (None).\\n'},\n",
       "         'unit': {'type': 'string',\n",
       "          'description': 'str, default None. Specify the desired resolution of the result.\\n\\nNew in version 2.0.0.\\n\\n'}},\n",
       "        'required': ['start=None',\n",
       "         'end=None',\n",
       "         'periods=None',\n",
       "         'freq=None',\n",
       "         'name=None',\n",
       "         'closed=None']}}}]},\n",
       "   {'Top-level dealing with Interval data': [{'func_name': 'interval_range([start,\\xa0end,\\xa0periods,\\xa0freq,\\xa0...])',\n",
       "      'func_desc': 'Return a fixed frequency IntervalIndex.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.interval_range.html#pandas.interval_range',\n",
       "      'function_definitions': {'function_name': 'pandas.interval_range',\n",
       "       'full_function': \"pandas.interval_range(start=None, end=None, periods=None, freq=None, name=None, closed='right')\",\n",
       "       'function_text': 'Return a fixed frequency IntervalIndex.',\n",
       "       'parameter_names_desc': [{'param_name': 'start',\n",
       "         'param_type': 'numeric or datetime-like, default None',\n",
       "         'param_desc': 'Left bound for generating intervals.\\n'},\n",
       "        {'param_name': 'end',\n",
       "         'param_type': 'numeric or datetime-like, default None',\n",
       "         'param_desc': 'Right bound for generating intervals.\\n'},\n",
       "        {'param_name': 'periods',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'Number of periods to generate.\\n'},\n",
       "        {'param_name': 'freq',\n",
       "         'param_type': 'numeric, str, Timedelta, datetime.timedelta, or DateOffset, default None',\n",
       "         'param_desc': 'The length of each interval. Must be consistent with the type of start\\nand end, e.g. 2 for numeric, or ‘5H’ for datetime-like. Default is 1\\nfor numeric and ‘D’ for datetime-like.\\n'},\n",
       "        {'param_name': 'name',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'Name of the resulting IntervalIndex.\\n'},\n",
       "        {'param_name': 'closed',\n",
       "         'param_type': '{‘left’, ‘right’, ‘both’, ‘neither’}, default ‘right’',\n",
       "         'param_desc': 'Whether the intervals are closed on the left-side, right-side, both\\nor neither.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.interval_range',\n",
       "       'descriptions': 'Return a fixed frequency IntervalIndex.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'start': {'type': 'numeric or datetime-like, default None',\n",
       "          'description': 'numeric or datetime-like, default None. Left bound for generating intervals.\\n'},\n",
       "         'end': {'type': 'numeric or datetime-like, default None',\n",
       "          'description': 'numeric or datetime-like, default None. Right bound for generating intervals.\\n'},\n",
       "         'periods': {'type': 'integer',\n",
       "          'description': 'int, default None. Number of periods to generate.\\n'},\n",
       "         'freq': {'type': 'string',\n",
       "          'description': 'numeric, str, Timedelta, datetime.timedelta, or DateOffset, default None. The length of each interval. Must be consistent with the type of start\\nand end, e.g. 2 for numeric, or ‘5H’ for datetime-like. Default is 1\\nfor numeric and ‘D’ for datetime-like.\\n'},\n",
       "         'name': {'type': 'string',\n",
       "          'description': 'str, default None. Name of the resulting IntervalIndex.\\n'},\n",
       "         'closed': {'type': 'string',\n",
       "          'enum': ['left', ' right', ' both', ' neither'],\n",
       "          'description': '{‘left’, ‘right’, ‘both’, ‘neither’}, default ‘right’. Whether the intervals are closed on the left-side, right-side, both\\nor neither.\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Top-level evaluation': [{'func_name': 'eval(expr[,\\xa0parser,\\xa0engine,\\xa0local_dict,\\xa0...])',\n",
       "      'func_desc': 'Evaluate a Python expression as a string using various backends.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.eval.html#pandas.eval',\n",
       "      'function_definitions': {'function_name': 'pandas.eval',\n",
       "       'full_function': \"pandas.eval(expr, parser='pandas', engine=None, local_dict=None, global_dict=None, resolvers=(), level=0, target=None, inplace=False)\",\n",
       "       'function_text': \"Evaluate a Python expression as a string using various backends. The following arithmetic operations are supported: +, -, *,\\n/, **, %, // (python engine only) along with the following\\nboolean operations: | (or), & (and), and ~ (not).\\nAdditionally, the 'pandas' parser allows the use of and,\\nor, and not with the same semantics as the\\ncorresponding bitwise operators. Series and\\nDataFrame objects are supported and behave as they would\\nwith plain ol’ Python evaluation.\",\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'Datetime formats': [{'func_name': 'tseries.api.guess_datetime_format(dt_str[,\\xa0...])',\n",
       "      'func_desc': 'Guess the datetime format of a given datetime string.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.api.guess_datetime_format.html#pandas.tseries.api.guess_datetime_format',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.api.guess_datetime_format',\n",
       "       'full_function': 'pandas.tseries.api.guess_datetime_format(dt_str, dayfirst=False)#',\n",
       "       'function_text': 'Guess the datetime format of a given datetime string.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt_str',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'Datetime string to guess the format of.\\n'},\n",
       "        {'param_name': 'dayfirst',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True parses dates with the day first, eg 20/01/2005\\n\\nWarning\\ndayfirst=True is not strict, but will prefer to parse\\nwith day first (this is a known bug).\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.api.guess_datetime_format',\n",
       "       'descriptions': 'Guess the datetime format of a given datetime string.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt_str': {'type': 'string',\n",
       "          'description': 'str. Datetime string to guess the format of.\\n'},\n",
       "         'dayfirst': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True parses dates with the day first, eg 20/01/2005\\n\\nWarning\\ndayfirst=True is not strict, but will prefer to parse\\nwith day first (this is a known bug).\\n\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Hashing': [{'func_name': 'util.hash_array(vals[,\\xa0encoding,\\xa0hash_key,\\xa0...])',\n",
       "      'func_desc': 'Given a 1d array, return an array of deterministic integers.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.util.hash_array.html#pandas.util.hash_array',\n",
       "      'function_definitions': {'function_name': 'pandas.util.hash_array',\n",
       "       'full_function': \"pandas.util.hash_array(vals, encoding='utf8', hash_key='0123456789123456', categorize=True)\",\n",
       "       'function_text': 'Given a 1d array, return an array of deterministic integers.',\n",
       "       'parameter_names_desc': [{'param_name': 'vals',\n",
       "         'param_type': 'ndarray or ExtensionArray',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'encoding',\n",
       "         'param_type': 'str, default ‘utf8’',\n",
       "         'param_desc': 'Encoding for data & key when strings.\\n'},\n",
       "        {'param_name': 'hash_key',\n",
       "         'param_type': 'str, default _default_hash_key',\n",
       "         'param_desc': 'Hash_key for string key to encode.\\n'},\n",
       "        {'param_name': 'categorize',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to first categorize object arrays before hashing. This is more\\nefficient when the array contains duplicate values.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.util.hash_array',\n",
       "       'descriptions': 'Given a 1d array, return an array of deterministic integers.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'vals': {'type': 'array',\n",
       "          'description': 'ndarray or ExtensionArray. '},\n",
       "         'encoding': {'type': 'string',\n",
       "          'description': 'str, default ‘utf8’. Encoding for data & key when strings.\\n'},\n",
       "         'hash_key': {'type': 'string',\n",
       "          'description': 'str, default _default_hash_key. Hash_key for string key to encode.\\n'},\n",
       "         'categorize': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to first categorize object arrays before hashing. This is more\\nefficient when the array contains duplicate values.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'util.hash_pandas_object(obj[,\\xa0index,\\xa0...])',\n",
       "      'func_desc': 'Return a data hash of the Index/Series/DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.util.hash_pandas_object.html#pandas.util.hash_pandas_object',\n",
       "      'function_definitions': {'function_name': 'pandas.util.hash_pandas_object',\n",
       "       'full_function': \"pandas.util.hash_pandas_object(obj, index=True, encoding='utf8', hash_key='0123456789123456', categorize=True)\",\n",
       "       'function_text': 'Return a data hash of the Index/Series/DataFrame.',\n",
       "       'parameter_names_desc': [{'param_name': 'obj',\n",
       "         'param_type': 'Index, Series, or DataFrame',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Include the index in the hash (if Series/DataFrame).\\n'},\n",
       "        {'param_name': 'encoding',\n",
       "         'param_type': 'str, default ‘utf8’',\n",
       "         'param_desc': 'Encoding for data & key when strings.\\n'},\n",
       "        {'param_name': 'hash_key',\n",
       "         'param_type': 'str, default _default_hash_key',\n",
       "         'param_desc': 'Hash_key for string key to encode.\\n'},\n",
       "        {'param_name': 'categorize',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to first categorize object arrays before hashing. This is more\\nefficient when the array contains duplicate values.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.util.hash_pandas_object',\n",
       "       'descriptions': 'Return a data hash of the Index/Series/DataFrame.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'obj': {'type': 'Index, Series, or DataFrame',\n",
       "          'description': 'Index, Series, or DataFrame. '},\n",
       "         'index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Include the index in the hash (if Series/DataFrame).\\n'},\n",
       "         'encoding': {'type': 'string',\n",
       "          'description': 'str, default ‘utf8’. Encoding for data & key when strings.\\n'},\n",
       "         'hash_key': {'type': 'string',\n",
       "          'description': 'str, default _default_hash_key. Hash_key for string key to encode.\\n'},\n",
       "         'categorize': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to first categorize object arrays before hashing. This is more\\nefficient when the array contains duplicate values.\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Importing from other DataFrame libraries': [{'func_name': 'api.interchange.from_dataframe(df[,\\xa0allow_copy])',\n",
       "      'func_desc': 'Build a pd.DataFrame from any DataFrame supporting the interchange protocol.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.interchange.from_dataframe.html#pandas.api.interchange.from_dataframe',\n",
       "      'function_definitions': {'function_name': 'pandas.api.interchange.from_dataframe',\n",
       "       'full_function': 'pandas.api.interchange.from_dataframe(df, allow_copy=True)',\n",
       "       'function_text': 'Build a pd.DataFrame from any DataFrame supporting the interchange protocol.',\n",
       "       'parameter_names_desc': [{'param_name': 'df',\n",
       "         'param_type': 'DataFrameXchg',\n",
       "         'param_desc': 'Object supporting the interchange protocol, i.e. __dataframe__ method.\\n'},\n",
       "        {'param_name': 'allow_copy',\n",
       "         'param_type': 'bool, default: True',\n",
       "         'param_desc': 'Whether to allow copying the memory to perform the conversion\\n(if false then zero-copy approach is requested).\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.api.interchange.from_dataframe',\n",
       "       'descriptions': 'Build a pd.DataFrame from any DataFrame supporting the interchange protocol.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'df': {'type': 'DataFrameXchg',\n",
       "          'description': 'DataFrameXchg. Object supporting the interchange protocol, i.e. __dataframe__ method.\\n'},\n",
       "         'allow_copy': {'type': 'boolean',\n",
       "          'description': 'bool, default: True. Whether to allow copying the memory to perform the conversion\\n(if false then zero-copy approach is requested).\\n'}},\n",
       "        'required': []}}}]}],\n",
       "  'name': 'General functions',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/general_functions.html'},\n",
       " 'series.html': {'functions': [{'Constructor': [{'func_name': 'Series([data,\\xa0index,\\xa0dtype,\\xa0name,\\xa0copy,\\xa0...])',\n",
       "      'func_desc': 'One-dimensional ndarray with axis labels (including time series).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.html#pandas.Series',\n",
       "      'function_definitions': {'function_name': 'pandas.Series',\n",
       "       'full_function': 'class pandas.Series(data=None, index=None, dtype=None, name=None, copy=None, fastpath=_NoDefault.no_default)',\n",
       "       'function_text': 'One-dimensional ndarray with axis labels (including time series). Labels need not be unique but must be a hashable type. The object\\nsupports both integer- and label-based indexing and provides a host of\\nmethods for performing operations involving the index. Statistical\\nmethods from ndarray have been overridden to automatically exclude\\nmissing data (currently represented as NaN). Operations between Series (+, -, /, *, **) align values based on their\\nassociated index values– they need not be the same length. The result\\nindex will be the sorted union of the two indexes.',\n",
       "       'parameter_names_desc': [{'param_name': 'data',\n",
       "         'param_type': 'array-like, Iterable, dict, or scalar value',\n",
       "         'param_desc': 'Contains data stored in Series. If data is a dict, argument order is\\nmaintained.\\n'},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'array-like or Index (1d)',\n",
       "         'param_desc': 'Values must be hashable and have the same length as data.\\nNon-unique index values are allowed. Will default to\\nRangeIndex (0, 1, 2, …, n) if not provided. If data is dict-like\\nand index is None, then the keys in the data are used as the index. If the\\nindex is not None, the resulting Series is reindexed with the index values.\\n'},\n",
       "        {'param_name': 'dtype',\n",
       "         'param_type': 'str, numpy.dtype, or ExtensionDtype, optional',\n",
       "         'param_desc': 'Data type for the output Series. If not specified, this will be\\ninferred from data.\\nSee the user guide for more usages.\\n'},\n",
       "        {'param_name': 'name',\n",
       "         'param_type': 'Hashable, default None',\n",
       "         'param_desc': 'The name to give to the Series.\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Copy input data. Only affects Series or 1d ndarray input. See examples.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series',\n",
       "       'descriptions': 'One-dimensional ndarray with axis labels (including time series). Labels need not be unique but must be a hashable type. The object\\nsupports both integer- and label-based indexing and provides a host of\\nmethods for performing operations involving the index. Statistical\\nmethods from ndarray have been overridden to automatically exclude\\nmissing data (currently represented as NaN). Operations between Series (+, -, /, *, **) align values based on their\\nassociated index values– they need not be the same length. The result\\nindex will be the sorted union of the two indexes.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'data': {'type': 'array',\n",
       "          'description': 'array-like, Iterable, dict, or scalar value. Contains data stored in Series. If data is a dict, argument order is\\nmaintained.\\n'},\n",
       "         'index': {'type': 'array',\n",
       "          'description': 'array-like or Index (1d). Values must be hashable and have the same length as data.\\nNon-unique index values are allowed. Will default to\\nRangeIndex (0, 1, 2, …, n) if not provided. If data is dict-like\\nand index is None, then the keys in the data are used as the index. If the\\nindex is not None, the resulting Series is reindexed with the index values.\\n'},\n",
       "         'dtype': {'type': 'string',\n",
       "          'description': 'str, numpy.dtype, or ExtensionDtype, optional. Data type for the output Series. If not specified, this will be\\ninferred from data.\\nSee the user guide for more usages.\\n'},\n",
       "         'name': {'type': 'Hashable, default None',\n",
       "          'description': 'Hashable, default None. The name to give to the Series.\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Copy input data. Only affects Series or 1d ndarray input. See examples.\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Attributes': [{'func_name': 'Series.index',\n",
       "      'func_desc': 'The index (axis labels) of the Series.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.index.html#pandas.Series.index',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.index',\n",
       "       'full_function': 'Series.index#',\n",
       "       'function_text': 'The index (axis labels) of the Series. The index of a Series is used to label and identify each element of the\\nunderlying data. The index can be thought of as an immutable ordered set\\n(technically a multi-set, as it may contain duplicate labels), and is\\nused to index and align data in pandas.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.values',\n",
       "      'func_desc': 'Return Series as ndarray or ndarray-like depending on the dtype.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.values.html#pandas.Series.values',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.values',\n",
       "       'full_function': 'property Series.values',\n",
       "       'function_text': 'Return Series as ndarray or ndarray-like depending on the dtype. Warning We recommend using Series.array or\\nSeries.to_numpy(), depending on whether you need\\na reference to the underlying data or a NumPy array.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.shape',\n",
       "      'func_desc': 'Return a tuple of the shape of the underlying data.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.shape.html#pandas.Series.shape',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.shape',\n",
       "       'full_function': 'property Series.shape',\n",
       "       'function_text': 'Return a tuple of the shape of the underlying data. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.ndim',\n",
       "      'func_desc': 'Number of dimensions of the underlying data, by definition 1.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.ndim.html#pandas.Series.ndim',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.ndim',\n",
       "       'full_function': 'property Series.ndim',\n",
       "       'function_text': 'Number of dimensions of the underlying data, by definition 1. Examples For Index:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.T',\n",
       "      'func_desc': 'Return the transpose, which is by definition self.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.T.html#pandas.Series.T',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.T',\n",
       "       'full_function': 'property Series.T',\n",
       "       'function_text': 'Return the transpose, which is by definition self. Examples For Series: For Index:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.hasnans',\n",
       "      'func_desc': 'Return True if there are any NaNs.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.hasnans.html#pandas.Series.hasnans',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.hasnans',\n",
       "       'full_function': 'property Series.hasnans',\n",
       "       'function_text': 'Return True if there are any NaNs. Enables various performance speedups.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.dtypes',\n",
       "      'func_desc': 'Return the dtype object of the underlying data.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.dtypes.html#pandas.Series.dtypes',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.dtypes',\n",
       "       'full_function': 'property Series.dtypes',\n",
       "       'function_text': 'Return the dtype object of the underlying data. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.flags',\n",
       "      'func_desc': 'Get the properties associated with this pandas object.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.flags.html#pandas.Series.flags',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.flags',\n",
       "       'full_function': 'property Series.flags',\n",
       "       'function_text': 'Get the properties associated with this pandas object. The available flags are Flags.allows_duplicate_labels See also Flags that apply to pandas objects. Global metadata applying to this dataset. Notes “Flags” differ from “metadata”. Flags reflect properties of the\\npandas object (the Series or DataFrame). Metadata refer to properties\\nof the dataset, and should be stored in DataFrame.attrs. Examples Flags can be get or set using . Or by slicing with a key',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.array',\n",
       "      'func_desc': 'The ExtensionArray of the data backing this Series or Index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.array.html#pandas.Series.array',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.array',\n",
       "       'full_function': 'property Series.array',\n",
       "       'function_text': 'The ExtensionArray of the data backing this Series or Index.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.dtype',\n",
       "      'func_desc': 'Return the dtype object of the underlying data.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.dtype.html#pandas.Series.dtype',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.dtype',\n",
       "       'full_function': 'property Series.dtype',\n",
       "       'function_text': 'Return the dtype object of the underlying data. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.nbytes',\n",
       "      'func_desc': 'Return the number of bytes in the underlying data.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.nbytes.html#pandas.Series.nbytes',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.nbytes',\n",
       "       'full_function': 'property Series.nbytes',\n",
       "       'function_text': 'Return the number of bytes in the underlying data. Examples For Series: For Index:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.size',\n",
       "      'func_desc': 'Return the number of elements in the underlying data.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.size.html#pandas.Series.size',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.size',\n",
       "       'full_function': 'property Series.size',\n",
       "       'function_text': 'Return the number of elements in the underlying data. Examples For Series: For Index:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.memory_usage([index,\\xa0deep])',\n",
       "      'func_desc': 'Return the memory usage of the Series.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.memory_usage.html#pandas.Series.memory_usage',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.memory_usage',\n",
       "       'full_function': 'Series.memory_usage(index=True, deep=False)',\n",
       "       'function_text': 'Return the memory usage of the Series. The memory usage can optionally include the contribution of\\nthe index and of elements of object dtype.',\n",
       "       'parameter_names_desc': [{'param_name': 'index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Specifies whether to include the memory usage of the Series index.\\n'},\n",
       "        {'param_name': 'deep',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True, introspect the data deeply by interrogating\\nobject dtypes for system-level memory consumption, and include\\nit in the returned value.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.memory_usage',\n",
       "       'descriptions': 'Return the memory usage of the Series. The memory usage can optionally include the contribution of\\nthe index and of elements of object dtype.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Specifies whether to include the memory usage of the Series index.\\n'},\n",
       "         'deep': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True, introspect the data deeply by interrogating\\nobject dtypes for system-level memory consumption, and include\\nit in the returned value.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.empty',\n",
       "      'func_desc': 'Indicator whether Series/DataFrame is empty.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.empty.html#pandas.Series.empty',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.empty',\n",
       "       'full_function': 'property Series.empty',\n",
       "       'function_text': 'Indicator whether Series/DataFrame is empty. True if Series/DataFrame is entirely empty (no items), meaning any of the\\naxes are of length 0.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.name',\n",
       "      'func_desc': 'Return the name of the Series.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.name.html#pandas.Series.name',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.name',\n",
       "       'full_function': 'property Series.name',\n",
       "       'function_text': 'Return the name of the Series. The name of a Series becomes its index or column name if it is used\\nto form a DataFrame. It is also used whenever displaying the Series\\nusing the interpreter.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.set_flags(*[,\\xa0copy,\\xa0...])',\n",
       "      'func_desc': 'Return a new object with updated flags.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.set_flags.html#pandas.Series.set_flags',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.set_flags',\n",
       "       'full_function': 'Series.set_flags(*, copy=False, allows_duplicate_labels=None)',\n",
       "       'function_text': 'Return a new object with updated flags.',\n",
       "       'parameter_names_desc': [{'param_name': 'copy',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Specify if a copy of the object should be made.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'},\n",
       "        {'param_name': 'allows_duplicate_labels',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'Whether the returned object allows duplicate labels.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.set_flags',\n",
       "       'descriptions': 'Return a new object with updated flags.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Specify if a copy of the object should be made.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'},\n",
       "         'allows_duplicate_labels': {'type': 'boolean',\n",
       "          'description': 'bool, optional. Whether the returned object allows duplicate labels.\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Conversion': [{'func_name': 'Series.astype(dtype[,\\xa0copy,\\xa0errors])',\n",
       "      'func_desc': 'Cast a pandas object to a specified dtype dtype.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.astype.html#pandas.Series.astype',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.astype',\n",
       "       'full_function': \"Series.astype(dtype, copy=None, errors='raise')\",\n",
       "       'function_text': 'Cast a pandas object to a specified dtype dtype.',\n",
       "       'parameter_names_desc': [{'param_name': 'dtype',\n",
       "         'param_type': 'str, data type, Series or Mapping of column name -> data type',\n",
       "         'param_desc': 'Use a str, numpy.dtype, pandas.ExtensionDtype or Python type to\\ncast entire pandas object to the same type. Alternatively, use a\\nmapping, e.g. {col: dtype, …}, where col is a column label and dtype is\\na numpy.dtype or Python type to cast one or more of the DataFrame’s\\ncolumns to column-specific types.\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Return a copy when copy=True (be very careful setting\\ncopy=False as changes to values then may propagate to other\\npandas objects).\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'},\n",
       "        {'param_name': 'errors',\n",
       "         'param_type': '{‘raise’, ‘ignore’}, default ‘raise’',\n",
       "         'param_desc': 'Control raising of exceptions on invalid data for provided dtype.\\n\\nraise : allow exceptions to be raised\\nignore : suppress exceptions. On error return original object.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.astype',\n",
       "       'descriptions': 'Cast a pandas object to a specified dtype dtype.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dtype': {'type': 'string',\n",
       "          'description': 'str, data type, Series or Mapping of column name -> data type. Use a str, numpy.dtype, pandas.ExtensionDtype or Python type to\\ncast entire pandas object to the same type. Alternatively, use a\\nmapping, e.g. {col: dtype, …}, where col is a column label and dtype is\\na numpy.dtype or Python type to cast one or more of the DataFrame’s\\ncolumns to column-specific types.\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Return a copy when copy=True (be very careful setting\\ncopy=False as changes to values then may propagate to other\\npandas objects).\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'},\n",
       "         'errors': {'type': 'string',\n",
       "          'enum': ['raise', ' ignore'],\n",
       "          'description': '{‘raise’, ‘ignore’}, default ‘raise’. Control raising of exceptions on invalid data for provided dtype.\\n\\nraise : allow exceptions to be raised\\nignore : suppress exceptions. On error return original object.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.infer_objects([copy])',\n",
       "      'func_desc': 'Attempt to infer better dtypes for object columns.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.infer_objects.html#pandas.Series.infer_objects',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.infer_objects',\n",
       "       'full_function': 'Series.infer_objects(copy=None)',\n",
       "       'function_text': 'Attempt to infer better dtypes for object columns. Attempts soft conversion of object-dtyped\\ncolumns, leaving non-object and unconvertible\\ncolumns unchanged. The inference rules are the\\nsame as during normal Series/DataFrame construction.',\n",
       "       'parameter_names_desc': [{'param_name': 'copy',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to make a copy for non-object or non-inferable columns\\nor Series.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.infer_objects',\n",
       "       'descriptions': 'Attempt to infer better dtypes for object columns. Attempts soft conversion of object-dtyped\\ncolumns, leaving non-object and unconvertible\\ncolumns unchanged. The inference rules are the\\nsame as during normal Series/DataFrame construction.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to make a copy for non-object or non-inferable columns\\nor Series.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.bool()',\n",
       "      'func_desc': '(DEPRECATED) Return the bool of a single element Series or DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.bool.html#pandas.Series.bool',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.bool',\n",
       "       'full_function': 'Series.bool()',\n",
       "       'function_text': 'Return the bool of a single element Series or DataFrame. Deprecated since version 2.1.0: bool is deprecated and will be removed in future version of pandas.\\nFor Series use pandas.Series.item. This must be a boolean scalar value, either True or False. It will raise a\\nValueError if the Series or DataFrame does not have exactly 1 element, or that\\nelement is not boolean (integer values 0 and 1 will also raise an exception).',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.to_period([freq,\\xa0copy])',\n",
       "      'func_desc': 'Convert Series from DatetimeIndex to PeriodIndex.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.to_period.html#pandas.Series.to_period',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.to_period',\n",
       "       'full_function': 'Series.to_period(freq=None, copy=None)',\n",
       "       'function_text': 'Convert Series from DatetimeIndex to PeriodIndex.',\n",
       "       'parameter_names_desc': [{'param_name': 'freq',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'Frequency associated with the PeriodIndex.\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether or not to return a copy.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.to_period',\n",
       "       'descriptions': 'Convert Series from DatetimeIndex to PeriodIndex.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'freq': {'type': 'string',\n",
       "          'description': 'str, default None. Frequency associated with the PeriodIndex.\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether or not to return a copy.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.to_list()',\n",
       "      'func_desc': 'Return a list of the values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.to_list.html#pandas.Series.to_list',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.to_list',\n",
       "       'full_function': 'Series.to_list()',\n",
       "       'function_text': 'Return a list of the values. These are each a scalar type, which is a Python scalar\\n(for str, int, float) or a pandas scalar\\n(for Timestamp/Timedelta/Interval/Period)',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.convert_dtypes([infer_objects,\\xa0...])',\n",
       "      'func_desc': 'Convert columns to the best possible dtypes using dtypes supporting pd.NA.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.convert_dtypes.html#pandas.Series.convert_dtypes',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.convert_dtypes',\n",
       "       'full_function': \"Series.convert_dtypes(infer_objects=True, convert_string=True, convert_integer=True, convert_boolean=True, convert_floating=True, dtype_backend='numpy_nullable')\",\n",
       "       'function_text': 'Convert columns to the best possible dtypes using dtypes supporting pd.NA.',\n",
       "       'parameter_names_desc': [{'param_name': 'infer_objects',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether object dtypes should be converted to the best possible types.\\n'},\n",
       "        {'param_name': 'convert_string',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether object dtypes should be converted to StringDtype().\\n'},\n",
       "        {'param_name': 'convert_integer',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether, if possible, conversion can be done to integer extension types.\\n'},\n",
       "        {'param_name': 'convert_boolean',\n",
       "         'param_type': 'bool, defaults True',\n",
       "         'param_desc': 'Whether object dtypes should be converted to BooleanDtypes().\\n'},\n",
       "        {'param_name': 'convert_floating',\n",
       "         'param_type': 'bool, defaults True',\n",
       "         'param_desc': 'Whether, if possible, conversion can be done to floating extension types.\\nIf convert_integer is also True, preference will be give to integer\\ndtypes if the floats can be faithfully casted to integers.\\n'},\n",
       "        {'param_name': 'dtype_backend',\n",
       "         'param_type': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’',\n",
       "         'param_desc': 'Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.convert_dtypes',\n",
       "       'descriptions': 'Convert columns to the best possible dtypes using dtypes supporting pd.NA.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'infer_objects': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether object dtypes should be converted to the best possible types.\\n'},\n",
       "         'convert_string': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether object dtypes should be converted to StringDtype().\\n'},\n",
       "         'convert_integer': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether, if possible, conversion can be done to integer extension types.\\n'},\n",
       "         'convert_boolean': {'type': 'boolean',\n",
       "          'description': 'bool, defaults True. Whether object dtypes should be converted to BooleanDtypes().\\n'},\n",
       "         'convert_floating': {'type': 'boolean',\n",
       "          'description': 'bool, defaults True. Whether, if possible, conversion can be done to floating extension types.\\nIf convert_integer is also True, preference will be give to integer\\ndtypes if the floats can be faithfully casted to integers.\\n'},\n",
       "         'dtype_backend': {'type': 'string',\n",
       "          'enum': ['numpy_nullable', ' pyarrow'],\n",
       "          'description': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’. Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.copy([deep])',\n",
       "      'func_desc': \"Make a copy of this object's indices and data.\",\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.copy.html#pandas.Series.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.copy',\n",
       "       'full_function': 'Series.copy(deep=True)',\n",
       "       'function_text': 'Make a copy of this object’s indices and data. When deep=True (default), a new object will be created with a\\ncopy of the calling object’s data and indices. Modifications to\\nthe data or indices of the copy will not be reflected in the\\noriginal object (see notes below). When deep=False, a new object will be created without copying\\nthe calling object’s data or index (only references to the data\\nand index are copied). Any changes to the data of the original\\nwill be reflected in the shallow copy (and vice versa). Note The deep=False behaviour as described above will change\\nin pandas 3.0. Copy-on-Write\\nwill be enabled by default, which means that the “shallow” copy\\nis that is returned with deep=False will still avoid making\\nan eager copy, but changes to the data of the original will no\\nlonger be reflected in the shallow copy (or vice versa). Instead,\\nit makes use of a lazy (deferred) copy mechanism that will copy\\nthe data only when any changes to the original or shallow copy is\\nmade. You can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True',\n",
       "       'parameter_names_desc': [{'param_name': 'deep',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Make a deep copy, including a copy of the data and the indices.\\nWith deep=False neither the indices nor the data are copied.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.copy',\n",
       "       'descriptions': 'Make a copy of this object’s indices and data. When deep=True (default), a new object will be created with a\\ncopy of the calling object’s data and indices. Modifications to\\nthe data or indices of the copy will not be reflected in the\\noriginal object (see notes below). When deep=False, a new object will be created without copying\\nthe calling object’s data or index (only references to the data\\nand index are copied). Any changes to the data of the original\\nwill be reflected in the shallow copy (and vice versa). Note The deep=False behaviour as described above will change\\nin pandas 3.0. Copy-on-Write\\nwill be enabled by default, which means that the “shallow” copy\\nis that is returned with deep=False will still avoid making\\nan eager copy, but changes to the data of the original will no\\nlonger be reflected in the shallow copy (or vice versa). Instead,\\nit makes use of a lazy (deferred) copy mechanism that will copy\\nthe data only when any changes to the original or shallow copy is\\nmade. You can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'deep': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Make a deep copy, including a copy of the data and the indices.\\nWith deep=False neither the indices nor the data are copied.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.to_numpy([dtype,\\xa0copy,\\xa0na_value])',\n",
       "      'func_desc': 'A NumPy ndarray representing the values in this Series or Index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.to_numpy.html#pandas.Series.to_numpy',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.to_numpy',\n",
       "       'full_function': 'Series.to_numpy(dtype=None, copy=False, na_value=_NoDefault.no_default, **kwargs)',\n",
       "       'function_text': 'A NumPy ndarray representing the values in this Series or Index.',\n",
       "       'parameter_names_desc': [{'param_name': 'dtype',\n",
       "         'param_type': 'str or numpy.dtype, optional',\n",
       "         'param_desc': 'The dtype to pass to numpy.asarray().\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to ensure that the returned value is not a view on\\nanother array. Note that copy=False does not ensure that\\nto_numpy() is no-copy. Rather, copy=True ensure that\\na copy is made, even if not strictly necessary.\\n'},\n",
       "        {'param_name': 'na_value',\n",
       "         'param_type': 'Any, optional',\n",
       "         'param_desc': 'The value to use for missing values. The default value depends\\non dtype and the type of the array.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.to_numpy',\n",
       "       'descriptions': 'A NumPy ndarray representing the values in this Series or Index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dtype': {'type': 'string',\n",
       "          'description': 'str or numpy.dtype, optional. The dtype to pass to numpy.asarray().\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to ensure that the returned value is not a view on\\nanother array. Note that copy=False does not ensure that\\nto_numpy() is no-copy. Rather, copy=True ensure that\\na copy is made, even if not strictly necessary.\\n'},\n",
       "         'na_value': {'type': 'Any, optional',\n",
       "          'description': 'Any, optional. The value to use for missing values. The default value depends\\non dtype and the type of the array.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.to_timestamp([freq,\\xa0how,\\xa0copy])',\n",
       "      'func_desc': 'Cast to DatetimeIndex of Timestamps, at beginning of period.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.to_timestamp.html#pandas.Series.to_timestamp',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.to_timestamp',\n",
       "       'full_function': \"Series.to_timestamp(freq=None, how='start', copy=None)\",\n",
       "       'function_text': 'Cast to DatetimeIndex of Timestamps, at beginning of period.',\n",
       "       'parameter_names_desc': [{'param_name': 'freq',\n",
       "         'param_type': 'str, default frequency of PeriodIndex',\n",
       "         'param_desc': 'Desired frequency.\\n'},\n",
       "        {'param_name': 'how',\n",
       "         'param_type': '{‘s’, ‘e’, ‘start’, ‘end’}',\n",
       "         'param_desc': 'Convention for converting period to timestamp; start of period\\nvs. end.\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether or not to return a copy.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.to_timestamp',\n",
       "       'descriptions': 'Cast to DatetimeIndex of Timestamps, at beginning of period.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'freq': {'type': 'string',\n",
       "          'description': 'str, default frequency of PeriodIndex. Desired frequency.\\n'},\n",
       "         'how': {'type': 'string',\n",
       "          'enum': ['s', ' e', ' start', ' end'],\n",
       "          'description': '{‘s’, ‘e’, ‘start’, ‘end’}. Convention for converting period to timestamp; start of period\\nvs. end.\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether or not to return a copy.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.__array__([dtype,\\xa0copy])',\n",
       "      'func_desc': 'Return the values as a NumPy array.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.__array__.html#pandas.Series.__array__',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.__array__',\n",
       "       'full_function': 'Series.__array__(dtype=None, copy=None)',\n",
       "       'function_text': 'Return the values as a NumPy array. Users should not call this directly. Rather, it is invoked by\\nnumpy.array() and numpy.asarray().',\n",
       "       'parameter_names_desc': [{'param_name': 'dtype',\n",
       "         'param_type': 'str or numpy.dtype, optional',\n",
       "         'param_desc': 'The dtype to use for the resulting NumPy array. By default,\\nthe dtype is inferred from the data.\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool or None, optional',\n",
       "         'param_desc': 'Unused.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.__array__',\n",
       "       'descriptions': 'Return the values as a NumPy array. Users should not call this directly. Rather, it is invoked by\\nnumpy.array() and numpy.asarray().',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dtype': {'type': 'string',\n",
       "          'description': 'str or numpy.dtype, optional. The dtype to use for the resulting NumPy array. By default,\\nthe dtype is inferred from the data.\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool or None, optional. Unused.\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Indexing, iteration': [{'func_name': 'Series.get(key[,\\xa0default])',\n",
       "      'func_desc': 'Get item from object for given key (ex: DataFrame column).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.get.html#pandas.Series.get',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.get',\n",
       "       'full_function': 'Series.get(key, default=None)',\n",
       "       'function_text': 'Get item from object for given key (ex: DataFrame column). Returns default value if not found.',\n",
       "       'parameter_names_desc': [{'param_name': 'key',\n",
       "         'param_type': 'object',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.Series.get',\n",
       "       'descriptions': 'Get item from object for given key (ex: DataFrame column). Returns default value if not found.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'key': {'type': 'object', 'description': 'object. '}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.iat',\n",
       "      'func_desc': 'Access a single value for a row/column pair by integer position.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.iat.html#pandas.Series.iat',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.iat',\n",
       "       'full_function': 'property Series.iat',\n",
       "       'function_text': 'Access a single value for a row/column pair by integer position. Similar to iloc, in that both provide integer-based lookups. Use\\niat if you only need to get or set a single value in a DataFrame\\nor Series.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.iloc',\n",
       "      'func_desc': '(DEPRECATED) Purely integer-location based indexing for selection by position.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.iloc.html#pandas.Series.iloc',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.iloc',\n",
       "       'full_function': 'property Series.iloc',\n",
       "       'function_text': 'Purely integer-location based indexing for selection by position. Deprecated since version 2.2.0: Returning a tuple from a callable is deprecated. .iloc[] is primarily integer position based (from 0 to\\nlength-1 of the axis), but may also be used with a boolean\\narray. Allowed inputs are: An integer, e.g. 5. A list or array of integers, e.g. [4, 3, 0]. A slice object with ints, e.g. 1:7. A boolean array. A callable function with one argument (the calling Series or\\nDataFrame) and that returns valid output for indexing (one of the above).\\nThis is useful in method chains, when you don’t have a reference to the\\ncalling object, but would like to base your selection on\\nsome value. A tuple of row and column indexes. The tuple elements consist of one of the\\nabove inputs, e.g. (0, 1). .iloc will raise IndexError if a requested indexer is\\nout-of-bounds, except slice indexers which allow out-of-bounds\\nindexing (this conforms with python/numpy slice semantics). See more at Selection by Position. See also Fast integer location scalar accessor. Purely label-location based indexer for selection by label. Purely integer-location based indexing for selection by position. Examples Indexing just the rows With a scalar integer. With a list of integers. With a slice object. With a boolean mask the same length as the index. With a callable, useful in method chains. The x passed\\nto the lambda is the DataFrame being sliced. This selects\\nthe rows whose index label even. Indexing both axes You can mix the indexer types for the index and columns. Use : to\\nselect the entire axis. With scalar integers. With lists of integers. With slice objects. With a boolean array whose length matches the columns. With a callable function that expects the Series or DataFrame.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.items()',\n",
       "      'func_desc': 'Lazily iterate over (index, value) tuples.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.items.html#pandas.Series.items',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.items',\n",
       "       'full_function': 'Series.items()',\n",
       "       'function_text': 'Lazily iterate over (index, value) tuples. This method returns an iterable tuple (index, value). This is\\nconvenient if you want to create a lazy iterator.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.pop(item)',\n",
       "      'func_desc': 'Return item and drops from series.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.pop.html#pandas.Series.pop',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.pop',\n",
       "       'full_function': 'Series.pop(item)',\n",
       "       'function_text': 'Return item and drops from series. Raise KeyError if not found.',\n",
       "       'parameter_names_desc': [{'param_name': 'item',\n",
       "         'param_type': 'label',\n",
       "         'param_desc': 'Index of the element that needs to be removed.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.pop',\n",
       "       'descriptions': 'Return item and drops from series. Raise KeyError if not found.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'item': {'type': 'label',\n",
       "          'description': 'label. Index of the element that needs to be removed.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.xs(key[,\\xa0axis,\\xa0level,\\xa0drop_level])',\n",
       "      'func_desc': 'Return cross-section from the Series/DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.xs.html#pandas.Series.xs',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.xs',\n",
       "       'full_function': 'Series.xs(key, axis=0, level=None, drop_level=True)',\n",
       "       'function_text': 'Return cross-section from the Series/DataFrame. This method takes a key argument to select data at a particular\\nlevel of a MultiIndex.',\n",
       "       'parameter_names_desc': [{'param_name': 'key',\n",
       "         'param_type': 'label or tuple of label',\n",
       "         'param_desc': 'Label contained in the index, or partially in a MultiIndex.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'Axis to retrieve cross-section on.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'object, defaults to first n levels (n=1 or len(key))',\n",
       "         'param_desc': 'In case of a key partially contained in a MultiIndex, indicate\\nwhich levels are used. Levels can be referred by label or position.\\n'},\n",
       "        {'param_name': 'drop_level',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If False, returns object with same levels as self.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.xs',\n",
       "       'descriptions': 'Return cross-section from the Series/DataFrame. This method takes a key argument to select data at a particular\\nlevel of a MultiIndex.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'key': {'type': 'label or tuple of label',\n",
       "          'description': 'label or tuple of label. Label contained in the index, or partially in a MultiIndex.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. Axis to retrieve cross-section on.\\n'},\n",
       "         'level': {'type': 'object',\n",
       "          'description': 'object, defaults to first n levels (n=1 or len(key)). In case of a key partially contained in a MultiIndex, indicate\\nwhich levels are used. Levels can be referred by label or position.\\n'},\n",
       "         'drop_level': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If False, returns object with same levels as self.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.at',\n",
       "      'func_desc': 'Access a single value for a row/column label pair.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.at.html#pandas.Series.at',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.at',\n",
       "       'full_function': 'property Series.at',\n",
       "       'function_text': 'Access a single value for a row/column label pair. Similar to loc, in that both provide label-based lookups. Use\\nat if you only need to get or set a single value in a DataFrame\\nor Series.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.loc',\n",
       "      'func_desc': 'Access a group of rows and columns by label(s) or a boolean array.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.loc.html#pandas.Series.loc',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.loc',\n",
       "       'full_function': 'property Series.loc',\n",
       "       'function_text': \"Access a group of rows and columns by label(s) or a boolean array. .loc[] is primarily label based, but may also be used with a\\nboolean array. Allowed inputs are: A single label, e.g. 5 or 'a', (note that 5 is\\ninterpreted as a label of the index, and never as an\\ninteger position along the index). A list or array of labels, e.g. ['a', 'b', 'c']. A slice object with labels, e.g. 'a':'f'. Warning Note that contrary to usual python slices, both the\\nstart and the stop are included A boolean array of the same length as the axis being sliced,\\ne.g. [True, False, True]. An alignable boolean Series. The index of the key will be aligned before\\nmasking. An alignable Index. The Index of the returned selection will be the input. A callable function with one argument (the calling Series or\\nDataFrame) and that returns valid output for indexing (one of the above) See more at Selection by Label.\",\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.__iter__()',\n",
       "      'func_desc': 'Return an iterator of the values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.__iter__.html#pandas.Series.__iter__',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.__iter__',\n",
       "       'full_function': 'Series.__iter__()',\n",
       "       'function_text': 'Return an iterator of the values. These are each a scalar type, which is a Python scalar\\n(for str, int, float) or a pandas scalar\\n(for Timestamp/Timedelta/Interval/Period)',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.keys()',\n",
       "      'func_desc': 'Return alias for index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.keys.html#pandas.Series.keys',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.keys',\n",
       "       'full_function': 'Series.keys()',\n",
       "       'function_text': 'Return alias for index.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.item()',\n",
       "      'func_desc': 'Return the first element of the underlying data as a Python scalar.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.item.html#pandas.Series.item',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.item',\n",
       "       'full_function': 'Series.item()',\n",
       "       'function_text': 'Return the first element of the underlying data as a Python scalar.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'Binary operator functions': [{'func_name': 'Series.add(other[,\\xa0level,\\xa0fill_value,\\xa0axis])',\n",
       "      'func_desc': 'Return Addition of series and other, element-wise (binary operator add).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.add.html#pandas.Series.add',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.add',\n",
       "       'full_function': 'Series.add(other, level=None, fill_value=None, axis=0)',\n",
       "       'function_text': 'Return Addition of series and other, element-wise (binary operator add). Equivalent to series + other, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series or scalar value',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or name',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'None or float value, default None (NaN)',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’}',\n",
       "         'param_desc': 'Unused. Parameter needed for compatibility with DataFrame.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.add',\n",
       "       'descriptions': 'Return Addition of series and other, element-wise (binary operator add). Equivalent to series + other, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series or scalar value',\n",
       "          'description': 'Series or scalar value. '},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or name. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'None or float value, default None (NaN). Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’}. Unused. Parameter needed for compatibility with DataFrame.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.mul(other[,\\xa0level,\\xa0fill_value,\\xa0axis])',\n",
       "      'func_desc': 'Return Multiplication of series and other, element-wise (binary operator mul).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.mul.html#pandas.Series.mul',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.mul',\n",
       "       'full_function': 'Series.mul(other, level=None, fill_value=None, axis=0)',\n",
       "       'function_text': 'Return Multiplication of series and other, element-wise (binary operator mul). Equivalent to series * other, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series or scalar value',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or name',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'None or float value, default None (NaN)',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’}',\n",
       "         'param_desc': 'Unused. Parameter needed for compatibility with DataFrame.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.mul',\n",
       "       'descriptions': 'Return Multiplication of series and other, element-wise (binary operator mul). Equivalent to series * other, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series or scalar value',\n",
       "          'description': 'Series or scalar value. '},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or name. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'None or float value, default None (NaN). Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’}. Unused. Parameter needed for compatibility with DataFrame.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.truediv(other[,\\xa0level,\\xa0fill_value,\\xa0axis])',\n",
       "      'func_desc': 'Return Floating division of series and other, element-wise (binary operator truediv).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.truediv.html#pandas.Series.truediv',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.truediv',\n",
       "       'full_function': 'Series.truediv(other, level=None, fill_value=None, axis=0)',\n",
       "       'function_text': 'Return Floating division of series and other, element-wise (binary operator truediv). Equivalent to series / other, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series or scalar value',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or name',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'None or float value, default None (NaN)',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’}',\n",
       "         'param_desc': 'Unused. Parameter needed for compatibility with DataFrame.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.truediv',\n",
       "       'descriptions': 'Return Floating division of series and other, element-wise (binary operator truediv). Equivalent to series / other, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series or scalar value',\n",
       "          'description': 'Series or scalar value. '},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or name. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'None or float value, default None (NaN). Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’}. Unused. Parameter needed for compatibility with DataFrame.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.mod(other[,\\xa0level,\\xa0fill_value,\\xa0axis])',\n",
       "      'func_desc': 'Return Modulo of series and other, element-wise (binary operator mod).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.mod.html#pandas.Series.mod',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.mod',\n",
       "       'full_function': 'Series.mod(other, level=None, fill_value=None, axis=0)',\n",
       "       'function_text': 'Return Modulo of series and other, element-wise (binary operator mod). Equivalent to series % other, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series or scalar value',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or name',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'None or float value, default None (NaN)',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’}',\n",
       "         'param_desc': 'Unused. Parameter needed for compatibility with DataFrame.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.mod',\n",
       "       'descriptions': 'Return Modulo of series and other, element-wise (binary operator mod). Equivalent to series % other, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series or scalar value',\n",
       "          'description': 'Series or scalar value. '},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or name. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'None or float value, default None (NaN). Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’}. Unused. Parameter needed for compatibility with DataFrame.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.radd(other[,\\xa0level,\\xa0fill_value,\\xa0axis])',\n",
       "      'func_desc': 'Return Addition of series and other, element-wise (binary operator radd).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.radd.html#pandas.Series.radd',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.radd',\n",
       "       'full_function': 'Series.radd(other, level=None, fill_value=None, axis=0)',\n",
       "       'function_text': 'Return Addition of series and other, element-wise (binary operator radd). Equivalent to other + series, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series or scalar value',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or name',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'None or float value, default None (NaN)',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’}',\n",
       "         'param_desc': 'Unused. Parameter needed for compatibility with DataFrame.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.radd',\n",
       "       'descriptions': 'Return Addition of series and other, element-wise (binary operator radd). Equivalent to other + series, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series or scalar value',\n",
       "          'description': 'Series or scalar value. '},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or name. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'None or float value, default None (NaN). Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’}. Unused. Parameter needed for compatibility with DataFrame.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.rmul(other[,\\xa0level,\\xa0fill_value,\\xa0axis])',\n",
       "      'func_desc': 'Return Multiplication of series and other, element-wise (binary operator rmul).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.rmul.html#pandas.Series.rmul',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.rmul',\n",
       "       'full_function': 'Series.rmul(other, level=None, fill_value=None, axis=0)',\n",
       "       'function_text': 'Return Multiplication of series and other, element-wise (binary operator rmul). Equivalent to other * series, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series or scalar value',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or name',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'None or float value, default None (NaN)',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’}',\n",
       "         'param_desc': 'Unused. Parameter needed for compatibility with DataFrame.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.rmul',\n",
       "       'descriptions': 'Return Multiplication of series and other, element-wise (binary operator rmul). Equivalent to other * series, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series or scalar value',\n",
       "          'description': 'Series or scalar value. '},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or name. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'None or float value, default None (NaN). Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’}. Unused. Parameter needed for compatibility with DataFrame.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.rtruediv(other[,\\xa0level,\\xa0fill_value,\\xa0axis])',\n",
       "      'func_desc': 'Return Floating division of series and other, element-wise (binary operator rtruediv).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.rtruediv.html#pandas.Series.rtruediv',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.rtruediv',\n",
       "       'full_function': 'Series.rtruediv(other, level=None, fill_value=None, axis=0)',\n",
       "       'function_text': 'Return Floating division of series and other, element-wise (binary operator rtruediv). Equivalent to other / series, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series or scalar value',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or name',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'None or float value, default None (NaN)',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’}',\n",
       "         'param_desc': 'Unused. Parameter needed for compatibility with DataFrame.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.rtruediv',\n",
       "       'descriptions': 'Return Floating division of series and other, element-wise (binary operator rtruediv). Equivalent to other / series, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series or scalar value',\n",
       "          'description': 'Series or scalar value. '},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or name. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'None or float value, default None (NaN). Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’}. Unused. Parameter needed for compatibility with DataFrame.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.rmod(other[,\\xa0level,\\xa0fill_value,\\xa0axis])',\n",
       "      'func_desc': 'Return Modulo of series and other, element-wise (binary operator rmod).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.rmod.html#pandas.Series.rmod',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.rmod',\n",
       "       'full_function': 'Series.rmod(other, level=None, fill_value=None, axis=0)',\n",
       "       'function_text': 'Return Modulo of series and other, element-wise (binary operator rmod). Equivalent to other % series, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series or scalar value',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or name',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'None or float value, default None (NaN)',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’}',\n",
       "         'param_desc': 'Unused. Parameter needed for compatibility with DataFrame.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.rmod',\n",
       "       'descriptions': 'Return Modulo of series and other, element-wise (binary operator rmod). Equivalent to other % series, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series or scalar value',\n",
       "          'description': 'Series or scalar value. '},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or name. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'None or float value, default None (NaN). Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’}. Unused. Parameter needed for compatibility with DataFrame.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.combine(other,\\xa0func[,\\xa0fill_value])',\n",
       "      'func_desc': 'Combine the Series with a Series or scalar according to func.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.combine.html#pandas.Series.combine',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.combine',\n",
       "       'full_function': 'Series.combine(other, func, fill_value=None)',\n",
       "       'function_text': 'Combine the Series with a Series or scalar according to func. Combine the Series and other using func to perform elementwise\\nselection for combined Series.\\nfill_value is assumed when value is missing at some index\\nfrom one of the two objects being combined.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series or scalar',\n",
       "         'param_desc': 'The value(s) to be combined with the Series.\\n'},\n",
       "        {'param_name': 'func',\n",
       "         'param_type': 'function',\n",
       "         'param_desc': 'Function that takes two scalars as inputs and returns an element.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'scalar, optional',\n",
       "         'param_desc': 'The value to assume when an index is missing from\\none Series or the other. The default specifies to use the\\nappropriate NaN value for the underlying dtype of the Series.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.combine',\n",
       "       'descriptions': 'Combine the Series with a Series or scalar according to func. Combine the Series and other using func to perform elementwise\\nselection for combined Series.\\nfill_value is assumed when value is missing at some index\\nfrom one of the two objects being combined.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series or scalar',\n",
       "          'description': 'Series or scalar. The value(s) to be combined with the Series.\\n'},\n",
       "         'func': {'type': 'function',\n",
       "          'description': 'function. Function that takes two scalars as inputs and returns an element.\\n'},\n",
       "         'fill_value': {'type': 'scalar, optional',\n",
       "          'description': 'scalar, optional. The value to assume when an index is missing from\\none Series or the other. The default specifies to use the\\nappropriate NaN value for the underlying dtype of the Series.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.round([decimals])',\n",
       "      'func_desc': 'Round each value in a Series to the given number of decimals.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.round.html#pandas.Series.round',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.round',\n",
       "       'full_function': 'Series.round(decimals=0, *args, **kwargs)',\n",
       "       'function_text': 'Round each value in a Series to the given number of decimals.',\n",
       "       'parameter_names_desc': [{'param_name': 'decimals',\n",
       "         'param_type': 'int, default 0',\n",
       "         'param_desc': 'Number of decimal places to round to. If decimals is negative,\\nit specifies the number of positions to the left of the decimal point.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.round',\n",
       "       'descriptions': 'Round each value in a Series to the given number of decimals.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'decimals': {'type': 'integer',\n",
       "          'description': 'int, default 0. Number of decimal places to round to. If decimals is negative,\\nit specifies the number of positions to the left of the decimal point.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.gt(other[,\\xa0level,\\xa0fill_value,\\xa0axis])',\n",
       "      'func_desc': 'Return Greater than of series and other, element-wise (binary operator gt).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.gt.html#pandas.Series.gt',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.gt',\n",
       "       'full_function': 'Series.gt(other, level=None, fill_value=None, axis=0)',\n",
       "       'function_text': 'Return Greater than of series and other, element-wise (binary operator gt). Equivalent to series > other, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series or scalar value',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or name',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'None or float value, default None (NaN)',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’}',\n",
       "         'param_desc': 'Unused. Parameter needed for compatibility with DataFrame.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.gt',\n",
       "       'descriptions': 'Return Greater than of series and other, element-wise (binary operator gt). Equivalent to series > other, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series or scalar value',\n",
       "          'description': 'Series or scalar value. '},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or name. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'None or float value, default None (NaN). Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’}. Unused. Parameter needed for compatibility with DataFrame.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.ge(other[,\\xa0level,\\xa0fill_value,\\xa0axis])',\n",
       "      'func_desc': 'Return Greater than or equal to of series and other, element-wise (binary operator ge).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.ge.html#pandas.Series.ge',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.ge',\n",
       "       'full_function': 'Series.ge(other, level=None, fill_value=None, axis=0)',\n",
       "       'function_text': 'Return Greater than or equal to of series and other, element-wise (binary operator ge). Equivalent to series >= other, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series or scalar value',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or name',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'None or float value, default None (NaN)',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’}',\n",
       "         'param_desc': 'Unused. Parameter needed for compatibility with DataFrame.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.ge',\n",
       "       'descriptions': 'Return Greater than or equal to of series and other, element-wise (binary operator ge). Equivalent to series >= other, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series or scalar value',\n",
       "          'description': 'Series or scalar value. '},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or name. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'None or float value, default None (NaN). Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’}. Unused. Parameter needed for compatibility with DataFrame.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.eq(other[,\\xa0level,\\xa0fill_value,\\xa0axis])',\n",
       "      'func_desc': 'Return Equal to of series and other, element-wise (binary operator eq).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.eq.html#pandas.Series.eq',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.eq',\n",
       "       'full_function': 'Series.eq(other, level=None, fill_value=None, axis=0)',\n",
       "       'function_text': 'Return Equal to of series and other, element-wise (binary operator eq). Equivalent to series == other, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series or scalar value',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or name',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'None or float value, default None (NaN)',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’}',\n",
       "         'param_desc': 'Unused. Parameter needed for compatibility with DataFrame.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.eq',\n",
       "       'descriptions': 'Return Equal to of series and other, element-wise (binary operator eq). Equivalent to series == other, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series or scalar value',\n",
       "          'description': 'Series or scalar value. '},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or name. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'None or float value, default None (NaN). Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’}. Unused. Parameter needed for compatibility with DataFrame.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.dot(other)',\n",
       "      'func_desc': 'Compute the dot product between the Series and the columns of other.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.dot.html#pandas.Series.dot',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.dot',\n",
       "       'full_function': 'Series.dot(other)',\n",
       "       'function_text': 'Compute the dot product between the Series and the columns of other. This method computes the dot product between the Series and another\\none, or the Series and each columns of a DataFrame, or the Series and\\neach columns of an array. It can also be called using self @ other.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series, DataFrame or array-like',\n",
       "         'param_desc': 'The other object to compute the dot product with its columns.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.dot',\n",
       "       'descriptions': 'Compute the dot product between the Series and the columns of other. This method computes the dot product between the Series and another\\none, or the Series and each columns of a DataFrame, or the Series and\\neach columns of an array. It can also be called using self @ other.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'array',\n",
       "          'description': 'Series, DataFrame or array-like. The other object to compute the dot product with its columns.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.sub(other[,\\xa0level,\\xa0fill_value,\\xa0axis])',\n",
       "      'func_desc': 'Return Subtraction of series and other, element-wise (binary operator sub).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.sub.html#pandas.Series.sub',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.sub',\n",
       "       'full_function': 'Series.sub(other, level=None, fill_value=None, axis=0)',\n",
       "       'function_text': 'Return Subtraction of series and other, element-wise (binary operator sub). Equivalent to series - other, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series or scalar value',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or name',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'None or float value, default None (NaN)',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’}',\n",
       "         'param_desc': 'Unused. Parameter needed for compatibility with DataFrame.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.sub',\n",
       "       'descriptions': 'Return Subtraction of series and other, element-wise (binary operator sub). Equivalent to series - other, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series or scalar value',\n",
       "          'description': 'Series or scalar value. '},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or name. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'None or float value, default None (NaN). Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’}. Unused. Parameter needed for compatibility with DataFrame.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.div(other[,\\xa0level,\\xa0fill_value,\\xa0axis])',\n",
       "      'func_desc': 'Return Floating division of series and other, element-wise (binary operator truediv).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.div.html#pandas.Series.div',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.div',\n",
       "       'full_function': 'Series.div(other, level=None, fill_value=None, axis=0)',\n",
       "       'function_text': 'Return Floating division of series and other, element-wise (binary operator truediv). Equivalent to series / other, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series or scalar value',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or name',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'None or float value, default None (NaN)',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’}',\n",
       "         'param_desc': 'Unused. Parameter needed for compatibility with DataFrame.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.div',\n",
       "       'descriptions': 'Return Floating division of series and other, element-wise (binary operator truediv). Equivalent to series / other, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series or scalar value',\n",
       "          'description': 'Series or scalar value. '},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or name. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'None or float value, default None (NaN). Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’}. Unused. Parameter needed for compatibility with DataFrame.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.floordiv(other[,\\xa0level,\\xa0fill_value,\\xa0axis])',\n",
       "      'func_desc': 'Return Integer division of series and other, element-wise (binary operator floordiv).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.floordiv.html#pandas.Series.floordiv',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.floordiv',\n",
       "       'full_function': 'Series.floordiv(other, level=None, fill_value=None, axis=0)',\n",
       "       'function_text': 'Return Integer division of series and other, element-wise (binary operator floordiv). Equivalent to series // other, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series or scalar value',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or name',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'None or float value, default None (NaN)',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’}',\n",
       "         'param_desc': 'Unused. Parameter needed for compatibility with DataFrame.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.floordiv',\n",
       "       'descriptions': 'Return Integer division of series and other, element-wise (binary operator floordiv). Equivalent to series // other, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series or scalar value',\n",
       "          'description': 'Series or scalar value. '},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or name. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'None or float value, default None (NaN). Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’}. Unused. Parameter needed for compatibility with DataFrame.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.pow(other[,\\xa0level,\\xa0fill_value,\\xa0axis])',\n",
       "      'func_desc': 'Return Exponential power of series and other, element-wise (binary operator pow).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.pow.html#pandas.Series.pow',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.pow',\n",
       "       'full_function': 'Series.pow(other, level=None, fill_value=None, axis=0)',\n",
       "       'function_text': 'Return Exponential power of series and other, element-wise (binary operator pow). Equivalent to series ** other, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series or scalar value',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or name',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'None or float value, default None (NaN)',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’}',\n",
       "         'param_desc': 'Unused. Parameter needed for compatibility with DataFrame.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.pow',\n",
       "       'descriptions': 'Return Exponential power of series and other, element-wise (binary operator pow). Equivalent to series ** other, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series or scalar value',\n",
       "          'description': 'Series or scalar value. '},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or name. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'None or float value, default None (NaN). Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’}. Unused. Parameter needed for compatibility with DataFrame.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.rsub(other[,\\xa0level,\\xa0fill_value,\\xa0axis])',\n",
       "      'func_desc': 'Return Subtraction of series and other, element-wise (binary operator rsub).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.rsub.html#pandas.Series.rsub',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.rsub',\n",
       "       'full_function': 'Series.rsub(other, level=None, fill_value=None, axis=0)',\n",
       "       'function_text': 'Return Subtraction of series and other, element-wise (binary operator rsub). Equivalent to other - series, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series or scalar value',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or name',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'None or float value, default None (NaN)',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’}',\n",
       "         'param_desc': 'Unused. Parameter needed for compatibility with DataFrame.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.rsub',\n",
       "       'descriptions': 'Return Subtraction of series and other, element-wise (binary operator rsub). Equivalent to other - series, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series or scalar value',\n",
       "          'description': 'Series or scalar value. '},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or name. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'None or float value, default None (NaN). Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’}. Unused. Parameter needed for compatibility with DataFrame.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.rdiv(other[,\\xa0level,\\xa0fill_value,\\xa0axis])',\n",
       "      'func_desc': 'Return Floating division of series and other, element-wise (binary operator rtruediv).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.rdiv.html#pandas.Series.rdiv',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.rdiv',\n",
       "       'full_function': 'Series.rdiv(other, level=None, fill_value=None, axis=0)',\n",
       "       'function_text': 'Return Floating division of series and other, element-wise (binary operator rtruediv). Equivalent to other / series, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series or scalar value',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or name',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'None or float value, default None (NaN)',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’}',\n",
       "         'param_desc': 'Unused. Parameter needed for compatibility with DataFrame.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.rdiv',\n",
       "       'descriptions': 'Return Floating division of series and other, element-wise (binary operator rtruediv). Equivalent to other / series, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series or scalar value',\n",
       "          'description': 'Series or scalar value. '},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or name. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'None or float value, default None (NaN). Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’}. Unused. Parameter needed for compatibility with DataFrame.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.rfloordiv(other[,\\xa0level,\\xa0fill_value,\\xa0...])',\n",
       "      'func_desc': 'Return Integer division of series and other, element-wise (binary operator rfloordiv).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.rfloordiv.html#pandas.Series.rfloordiv',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.rfloordiv',\n",
       "       'full_function': 'Series.rfloordiv(other, level=None, fill_value=None, axis=0)',\n",
       "       'function_text': 'Return Integer division of series and other, element-wise (binary operator rfloordiv). Equivalent to other // series, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series or scalar value',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or name',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'None or float value, default None (NaN)',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’}',\n",
       "         'param_desc': 'Unused. Parameter needed for compatibility with DataFrame.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.rfloordiv',\n",
       "       'descriptions': 'Return Integer division of series and other, element-wise (binary operator rfloordiv). Equivalent to other // series, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series or scalar value',\n",
       "          'description': 'Series or scalar value. '},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or name. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'None or float value, default None (NaN). Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’}. Unused. Parameter needed for compatibility with DataFrame.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.rpow(other[,\\xa0level,\\xa0fill_value,\\xa0axis])',\n",
       "      'func_desc': 'Return Exponential power of series and other, element-wise (binary operator rpow).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.rpow.html#pandas.Series.rpow',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.rpow',\n",
       "       'full_function': 'Series.rpow(other, level=None, fill_value=None, axis=0)',\n",
       "       'function_text': 'Return Exponential power of series and other, element-wise (binary operator rpow). Equivalent to other ** series, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series or scalar value',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or name',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'None or float value, default None (NaN)',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’}',\n",
       "         'param_desc': 'Unused. Parameter needed for compatibility with DataFrame.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.rpow',\n",
       "       'descriptions': 'Return Exponential power of series and other, element-wise (binary operator rpow). Equivalent to other ** series, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series or scalar value',\n",
       "          'description': 'Series or scalar value. '},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or name. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'None or float value, default None (NaN). Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’}. Unused. Parameter needed for compatibility with DataFrame.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.combine_first(other)',\n",
       "      'func_desc': \"Update null elements with value in the same location in 'other'.\",\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.combine_first.html#pandas.Series.combine_first',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.combine_first',\n",
       "       'full_function': 'Series.combine_first(other)',\n",
       "       'function_text': 'Update null elements with value in the same location in ‘other’. Combine two Series objects by filling null values in one Series with\\nnon-null values from the other Series. Result index will be the union\\nof the two indexes.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series',\n",
       "         'param_desc': 'The value(s) to be used for filling null values.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.combine_first',\n",
       "       'descriptions': 'Update null elements with value in the same location in ‘other’. Combine two Series objects by filling null values in one Series with\\nnon-null values from the other Series. Result index will be the union\\nof the two indexes.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series',\n",
       "          'description': 'Series. The value(s) to be used for filling null values.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.lt(other[,\\xa0level,\\xa0fill_value,\\xa0axis])',\n",
       "      'func_desc': 'Return Less than of series and other, element-wise (binary operator lt).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.lt.html#pandas.Series.lt',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.lt',\n",
       "       'full_function': 'Series.lt(other, level=None, fill_value=None, axis=0)',\n",
       "       'function_text': 'Return Less than of series and other, element-wise (binary operator lt). Equivalent to series < other, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series or scalar value',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or name',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'None or float value, default None (NaN)',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’}',\n",
       "         'param_desc': 'Unused. Parameter needed for compatibility with DataFrame.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.lt',\n",
       "       'descriptions': 'Return Less than of series and other, element-wise (binary operator lt). Equivalent to series < other, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series or scalar value',\n",
       "          'description': 'Series or scalar value. '},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or name. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'None or float value, default None (NaN). Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’}. Unused. Parameter needed for compatibility with DataFrame.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.le(other[,\\xa0level,\\xa0fill_value,\\xa0axis])',\n",
       "      'func_desc': 'Return Less than or equal to of series and other, element-wise (binary operator le).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.le.html#pandas.Series.le',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.le',\n",
       "       'full_function': 'Series.le(other, level=None, fill_value=None, axis=0)',\n",
       "       'function_text': 'Return Less than or equal to of series and other, element-wise (binary operator le). Equivalent to series <= other, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series or scalar value',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or name',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'None or float value, default None (NaN)',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’}',\n",
       "         'param_desc': 'Unused. Parameter needed for compatibility with DataFrame.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.le',\n",
       "       'descriptions': 'Return Less than or equal to of series and other, element-wise (binary operator le). Equivalent to series <= other, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series or scalar value',\n",
       "          'description': 'Series or scalar value. '},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or name. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'None or float value, default None (NaN). Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’}. Unused. Parameter needed for compatibility with DataFrame.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.ne(other[,\\xa0level,\\xa0fill_value,\\xa0axis])',\n",
       "      'func_desc': 'Return Not equal to of series and other, element-wise (binary operator ne).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.ne.html#pandas.Series.ne',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.ne',\n",
       "       'full_function': 'Series.ne(other, level=None, fill_value=None, axis=0)',\n",
       "       'function_text': 'Return Not equal to of series and other, element-wise (binary operator ne). Equivalent to series != other, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series or scalar value',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or name',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'None or float value, default None (NaN)',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’}',\n",
       "         'param_desc': 'Unused. Parameter needed for compatibility with DataFrame.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.ne',\n",
       "       'descriptions': 'Return Not equal to of series and other, element-wise (binary operator ne). Equivalent to series != other, but with support to substitute a fill_value for\\nmissing data in either one of the inputs.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series or scalar value',\n",
       "          'description': 'Series or scalar value. '},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or name. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'None or float value, default None (NaN). Fill existing missing (NaN) values, and any new element needed for\\nsuccessful Series alignment, with this value before computation.\\nIf data in both corresponding Series locations is missing\\nthe result of filling (at that location) will be missing.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’}. Unused. Parameter needed for compatibility with DataFrame.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.product([axis,\\xa0skipna,\\xa0numeric_only,\\xa0...])',\n",
       "      'func_desc': 'Return the product of the values over the requested axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.product.html#pandas.Series.product',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.product',\n",
       "       'full_function': 'Series.product(axis=None, skipna=True, numeric_only=False, min_count=0, **kwargs)',\n",
       "       'function_text': 'Return the product of the values over the requested axis.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{index (0)}',\n",
       "         'param_desc': 'Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\n\\nWarning\\nThe behavior of DataFrame.prod with axis=None is deprecated,\\nin a future version this will reduce over both axes and return a scalar\\nTo retain the old behavior, pass axis=0 (or do not pass axis).\\n\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values when computing the result.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns. Not implemented for Series.\\n'},\n",
       "        {'param_name': 'min_count',\n",
       "         'param_type': 'int, default 0',\n",
       "         'param_desc': 'The required number of valid values to perform the operation. If fewer than\\nmin_count non-NA values are present the result will be NA.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.product',\n",
       "       'descriptions': 'Return the product of the values over the requested axis.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': '{index (0)}',\n",
       "          'description': '{index (0)}. Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\n\\nWarning\\nThe behavior of DataFrame.prod with axis=None is deprecated,\\nin a future version this will reduce over both axes and return a scalar\\nTo retain the old behavior, pass axis=0 (or do not pass axis).\\n\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values when computing the result.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns. Not implemented for Series.\\n'},\n",
       "         'min_count': {'type': 'integer',\n",
       "          'description': 'int, default 0. The required number of valid values to perform the operation. If fewer than\\nmin_count non-NA values are present the result will be NA.\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Function application, GroupBy & window': [{'func_name': 'Series.apply(func[,\\xa0convert_dtype,\\xa0args,\\xa0by_row])',\n",
       "      'func_desc': 'Invoke function on values of Series.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.apply.html#pandas.Series.apply',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.apply',\n",
       "       'full_function': \"Series.apply(func, convert_dtype=_NoDefault.no_default, args=(), *, by_row='compat', **kwargs)\",\n",
       "       'function_text': 'Invoke function on values of Series. Can be ufunc (a NumPy function that applies to the entire Series)\\nor a Python function that only works on single values.',\n",
       "       'parameter_names_desc': [{'param_name': 'func',\n",
       "         'param_type': 'function',\n",
       "         'param_desc': 'Python function or NumPy ufunc to apply.\\n'},\n",
       "        {'param_name': 'convert_dtype',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Try to find better dtype for elementwise function results. If\\nFalse, leave as dtype=object. Note that the dtype is always\\npreserved for some extension array dtypes, such as Categorical.\\n\\nDeprecated since version 2.1.0: convert_dtype has been deprecated. Do ser.astype(object).apply()\\ninstead if you want convert_dtype=False.\\n\\n'},\n",
       "        {'param_name': 'args',\n",
       "         'param_type': 'tuple',\n",
       "         'param_desc': 'Positional arguments passed to func after the series value.\\n'},\n",
       "        {'param_name': 'by_row',\n",
       "         'param_type': 'False or “compat”, default “compat”',\n",
       "         'param_desc': 'If \"compat\" and func is a callable, func will be passed each element of\\nthe Series, like Series.map. If func is a list or dict of\\ncallables, will first try to translate each func into pandas methods. If\\nthat doesn’t work, will try call to apply again with by_row=\"compat\"\\nand if that fails, will call apply again with by_row=False\\n(backward compatible).\\nIf False, the func will be passed the whole Series at once.\\nby_row has no effect when func is a string.\\n\\nNew in version 2.1.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.apply',\n",
       "       'descriptions': 'Invoke function on values of Series. Can be ufunc (a NumPy function that applies to the entire Series)\\nor a Python function that only works on single values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'func': {'type': 'function',\n",
       "          'description': 'function. Python function or NumPy ufunc to apply.\\n'},\n",
       "         'convert_dtype': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Try to find better dtype for elementwise function results. If\\nFalse, leave as dtype=object. Note that the dtype is always\\npreserved for some extension array dtypes, such as Categorical.\\n\\nDeprecated since version 2.1.0: convert_dtype has been deprecated. Do ser.astype(object).apply()\\ninstead if you want convert_dtype=False.\\n\\n'},\n",
       "         'args': {'type': 'tuple',\n",
       "          'description': 'tuple. Positional arguments passed to func after the series value.\\n'},\n",
       "         'by_row': {'type': 'False or “compat”, default “compat”',\n",
       "          'description': 'False or “compat”, default “compat”. If \"compat\" and func is a callable, func will be passed each element of\\nthe Series, like Series.map. If func is a list or dict of\\ncallables, will first try to translate each func into pandas methods. If\\nthat doesn’t work, will try call to apply again with by_row=\"compat\"\\nand if that fails, will call apply again with by_row=False\\n(backward compatible).\\nIf False, the func will be passed the whole Series at once.\\nby_row has no effect when func is a string.\\n\\nNew in version 2.1.0.\\n\\n'}},\n",
       "        'required': ['func',\n",
       "         'convert_dtype=_NoDefault.no_default',\n",
       "         'args=()']}}},\n",
       "     {'func_name': 'Series.aggregate([func,\\xa0axis])',\n",
       "      'func_desc': 'Aggregate using one or more operations over the specified axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.aggregate.html#pandas.Series.aggregate',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.aggregate',\n",
       "       'full_function': 'Series.aggregate(func=None, axis=0, *args, **kwargs)',\n",
       "       'function_text': 'Aggregate using one or more operations over the specified axis.',\n",
       "       'parameter_names_desc': [{'param_name': 'func',\n",
       "         'param_type': 'function, str, list or dict',\n",
       "         'param_desc': \"Function to use for aggregating the data. If a function, must either\\nwork when passed a Series or when passed to Series.apply.\\nAccepted combinations are:\\n\\nfunction\\nstring function name\\nlist of functions and/or function names, e.g. [np.sum, 'mean']\\ndict of axis labels -> functions, function names or list of such.\\n\\n\"},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’}',\n",
       "         'param_desc': 'Unused. Parameter needed for compatibility with DataFrame.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.aggregate',\n",
       "       'descriptions': 'Aggregate using one or more operations over the specified axis.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'func': {'type': 'string',\n",
       "          'description': \"function, str, list or dict. Function to use for aggregating the data. If a function, must either\\nwork when passed a Series or when passed to Series.apply.\\nAccepted combinations are:\\n\\nfunction\\nstring function name\\nlist of functions and/or function names, e.g. [np.sum, 'mean']\\ndict of axis labels -> functions, function names or list of such.\\n\\n\"},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’}. Unused. Parameter needed for compatibility with DataFrame.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.map(arg[,\\xa0na_action])',\n",
       "      'func_desc': 'Map values of Series according to an input mapping or function.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.map.html#pandas.Series.map',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.map',\n",
       "       'full_function': 'Series.map(arg, na_action=None)',\n",
       "       'function_text': 'Map values of Series according to an input mapping or function. Used for substituting each value in a Series with another value,\\nthat may be derived from a function, a dict or\\na Series.',\n",
       "       'parameter_names_desc': [{'param_name': 'arg',\n",
       "         'param_type': 'function, collections.abc.Mapping subclass or Series',\n",
       "         'param_desc': 'Mapping correspondence.\\n'},\n",
       "        {'param_name': 'na_action',\n",
       "         'param_type': '{None, ‘ignore’}, default None',\n",
       "         'param_desc': 'If ‘ignore’, propagate NaN values, without passing them to the\\nmapping correspondence.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.map',\n",
       "       'descriptions': 'Map values of Series according to an input mapping or function. Used for substituting each value in a Series with another value,\\nthat may be derived from a function, a dict or\\na Series.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'arg': {'type': 'function, collections.abc.Mapping subclass or Series',\n",
       "          'description': 'function, collections.abc.Mapping subclass or Series. Mapping correspondence.\\n'},\n",
       "         'na_action': {'type': 'string',\n",
       "          'enum': ['None', ' ignore'],\n",
       "          'description': '{None, ‘ignore’}, default None. If ‘ignore’, propagate NaN values, without passing them to the\\nmapping correspondence.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.rolling(window[,\\xa0min_periods,\\xa0...])',\n",
       "      'func_desc': 'Provide rolling window calculations.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.rolling.html#pandas.Series.rolling',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.rolling',\n",
       "       'full_function': \"Series.rolling(window, min_periods=None, center=False, win_type=None, on=None, axis=_NoDefault.no_default, closed=None, step=None, method='single')\",\n",
       "       'function_text': 'Provide rolling window calculations.',\n",
       "       'parameter_names_desc': [{'param_name': 'window',\n",
       "         'param_type': 'int, timedelta, str, offset, or BaseIndexer subclass',\n",
       "         'param_desc': 'Size of the moving window.\\nIf an integer, the fixed number of observations used for\\neach window.\\nIf a timedelta, str, or offset, the time period of each window. Each\\nwindow will be a variable sized based on the observations included in\\nthe time-period. This is only valid for datetimelike indexes.\\nTo learn more about the offsets & frequency strings, please see this link.\\nIf a BaseIndexer subclass, the window boundaries\\nbased on the defined get_window_bounds method. Additional rolling\\nkeyword arguments, namely min_periods, center, closed and\\nstep will be passed to get_window_bounds.\\n'},\n",
       "        {'param_name': 'min_periods',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'Minimum number of observations in window required to have a value;\\notherwise, result is np.nan.\\nFor a window that is specified by an offset, min_periods will default to 1.\\nFor a window that is specified by an integer, min_periods will default\\nto the size of the window.\\n'},\n",
       "        {'param_name': 'center',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If False, set the window labels as the right edge of the window index.\\nIf True, set the window labels as the center of the window index.\\n'},\n",
       "        {'param_name': 'win_type',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'If None, all points are evenly weighted.\\nIf a string, it must be a valid scipy.signal window function.\\nCertain Scipy window types require additional parameters to be passed\\nin the aggregation function. The additional parameters must match\\nthe keywords specified in the Scipy window type method signature.\\n'},\n",
       "        {'param_name': 'on',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'For a DataFrame, a column label or Index level on which\\nto calculate the rolling window, rather than the DataFrame’s index.\\nProvided integer column is ignored and excluded from result since\\nan integer index is not used to calculate the rolling window.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': 'int or str, default 0',\n",
       "         'param_desc': \"If 0 or 'index', roll across the rows.\\nIf 1 or 'columns', roll across the columns.\\nFor Series this parameter is unused and defaults to 0.\\n\\nDeprecated since version 2.1.0: The axis keyword is deprecated. For axis=1,\\ntranspose the DataFrame first instead.\\n\\n\"},\n",
       "        {'param_name': 'closed',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': \"If 'right', the first point in the window is excluded from calculations.\\nIf 'left', the last point in the window is excluded from calculations.\\nIf 'both', the no points in the window are excluded from calculations.\\nIf 'neither', the first and last points in the window are excluded\\nfrom calculations.\\nDefault None ('right').\\n\"},\n",
       "        {'param_name': 'step',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': '\\nNew in version 1.5.0.\\n\\nEvaluate the window at every step result, equivalent to slicing as\\n[::step]. window must be an integer. Using a step argument other\\nthan None or 1 will produce a result with a different shape than the input.\\n'},\n",
       "        {'param_name': 'method',\n",
       "         'param_type': 'str {‘single’, ‘table’}, default ‘single’',\n",
       "         'param_desc': \"\\nNew in version 1.3.0.\\n\\nExecute the rolling operation per single column or row ('single')\\nor over the entire object ('table').\\nThis argument is only implemented when specifying engine='numba'\\nin the method call.\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.Series.rolling',\n",
       "       'descriptions': 'Provide rolling window calculations.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'window': {'type': 'integer',\n",
       "          'description': 'int, timedelta, str, offset, or BaseIndexer subclass. Size of the moving window.\\nIf an integer, the fixed number of observations used for\\neach window.\\nIf a timedelta, str, or offset, the time period of each window. Each\\nwindow will be a variable sized based on the observations included in\\nthe time-period. This is only valid for datetimelike indexes.\\nTo learn more about the offsets & frequency strings, please see this link.\\nIf a BaseIndexer subclass, the window boundaries\\nbased on the defined get_window_bounds method. Additional rolling\\nkeyword arguments, namely min_periods, center, closed and\\nstep will be passed to get_window_bounds.\\n'},\n",
       "         'min_periods': {'type': 'integer',\n",
       "          'description': 'int, default None. Minimum number of observations in window required to have a value;\\notherwise, result is np.nan.\\nFor a window that is specified by an offset, min_periods will default to 1.\\nFor a window that is specified by an integer, min_periods will default\\nto the size of the window.\\n'},\n",
       "         'center': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If False, set the window labels as the right edge of the window index.\\nIf True, set the window labels as the center of the window index.\\n'},\n",
       "         'win_type': {'type': 'string',\n",
       "          'description': 'str, default None. If None, all points are evenly weighted.\\nIf a string, it must be a valid scipy.signal window function.\\nCertain Scipy window types require additional parameters to be passed\\nin the aggregation function. The additional parameters must match\\nthe keywords specified in the Scipy window type method signature.\\n'},\n",
       "         'on': {'type': 'string',\n",
       "          'description': 'str, optional. For a DataFrame, a column label or Index level on which\\nto calculate the rolling window, rather than the DataFrame’s index.\\nProvided integer column is ignored and excluded from result since\\nan integer index is not used to calculate the rolling window.\\n'},\n",
       "         'axis': {'type': 'integer',\n",
       "          'description': \"int or str, default 0. If 0 or 'index', roll across the rows.\\nIf 1 or 'columns', roll across the columns.\\nFor Series this parameter is unused and defaults to 0.\\n\\nDeprecated since version 2.1.0: The axis keyword is deprecated. For axis=1,\\ntranspose the DataFrame first instead.\\n\\n\"},\n",
       "         'closed': {'type': 'string',\n",
       "          'description': \"str, default None. If 'right', the first point in the window is excluded from calculations.\\nIf 'left', the last point in the window is excluded from calculations.\\nIf 'both', the no points in the window are excluded from calculations.\\nIf 'neither', the first and last points in the window are excluded\\nfrom calculations.\\nDefault None ('right').\\n\"},\n",
       "         'step': {'type': 'integer',\n",
       "          'description': 'int, default None. \\nNew in version 1.5.0.\\n\\nEvaluate the window at every step result, equivalent to slicing as\\n[::step]. window must be an integer. Using a step argument other\\nthan None or 1 will produce a result with a different shape than the input.\\n'},\n",
       "         'method': {'type': 'string',\n",
       "          'description': \"str {‘single’, ‘table’}, default ‘single’. \\nNew in version 1.3.0.\\n\\nExecute the rolling operation per single column or row ('single')\\nor over the entire object ('table').\\nThis argument is only implemented when specifying engine='numba'\\nin the method call.\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.ewm([com,\\xa0span,\\xa0halflife,\\xa0alpha,\\xa0...])',\n",
       "      'func_desc': 'Provide exponentially weighted (EW) calculations.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.ewm.html#pandas.Series.ewm',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.ewm',\n",
       "       'full_function': \"Series.ewm(com=None, span=None, halflife=None, alpha=None, min_periods=0, adjust=True, ignore_na=False, axis=_NoDefault.no_default, times=None, method='single')\",\n",
       "       'function_text': 'Provide exponentially weighted (EW) calculations. Exactly one of com, span, halflife, or alpha must be\\nprovided if times is not provided. If times is provided,\\nhalflife and one of com, span or alpha may be provided.',\n",
       "       'parameter_names_desc': [{'param_name': 'com',\n",
       "         'param_type': 'float, optional',\n",
       "         'param_desc': 'Specify decay in terms of center of mass\\n\\\\(\\\\alpha = 1 / (1 + com)\\\\), for \\\\(com \\\\geq 0\\\\).\\n'},\n",
       "        {'param_name': 'span',\n",
       "         'param_type': 'float, optional',\n",
       "         'param_desc': 'Specify decay in terms of span\\n\\\\(\\\\alpha = 2 / (span + 1)\\\\), for \\\\(span \\\\geq 1\\\\).\\n'},\n",
       "        {'param_name': 'halflife',\n",
       "         'param_type': 'float, str, timedelta, optional',\n",
       "         'param_desc': 'Specify decay in terms of half-life\\n\\\\(\\\\alpha = 1 - \\\\exp\\\\left(-\\\\ln(2) / halflife\\\\right)\\\\), for\\n\\\\(halflife > 0\\\\).\\nIf times is specified, a timedelta convertible unit over which an\\nobservation decays to half its value. Only applicable to mean(),\\nand halflife value will not apply to the other functions.\\n'},\n",
       "        {'param_name': 'alpha',\n",
       "         'param_type': 'float, optional',\n",
       "         'param_desc': 'Specify smoothing factor \\\\(\\\\alpha\\\\) directly\\n\\\\(0 < \\\\alpha \\\\leq 1\\\\).\\n'},\n",
       "        {'param_name': 'min_periods',\n",
       "         'param_type': 'int, default 0',\n",
       "         'param_desc': 'Minimum number of observations in window required to have a value;\\notherwise, result is np.nan.\\n'},\n",
       "        {'param_name': 'adjust',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Divide by decaying adjustment factor in beginning periods to account\\nfor imbalance in relative weightings (viewing EWMA as a moving average).\\n\\nWhen adjust=True (default), the EW function is calculated using weights\\n\\\\(w_i = (1 - \\\\alpha)^i\\\\). For example, the EW moving average of the series\\n[\\\\(x_0, x_1, ..., x_t\\\\)] would be:\\n\\n\\n\\\\[y_t = \\\\frac{x_t + (1 - \\\\alpha)x_{t-1} + (1 - \\\\alpha)^2 x_{t-2} + ... + (1 -\\n\\\\alpha)^t x_0}{1 + (1 - \\\\alpha) + (1 - \\\\alpha)^2 + ... + (1 - \\\\alpha)^t}\\\\]\\n\\nWhen adjust=False, the exponentially weighted function is calculated\\nrecursively:\\n\\n\\n\\\\[\\\\begin{split}\\\\begin{split}\\ny_0 &= x_0\\\\\\\\\\ny_t &= (1 - \\\\alpha) y_{t-1} + \\\\alpha x_t,\\n\\\\end{split}\\\\end{split}\\\\]\\n'},\n",
       "        {'param_name': 'ignore_na',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Ignore missing values when calculating weights.\\n\\nWhen ignore_na=False (default), weights are based on absolute positions.\\nFor example, the weights of \\\\(x_0\\\\) and \\\\(x_2\\\\) used in calculating\\nthe final weighted average of [\\\\(x_0\\\\), None, \\\\(x_2\\\\)] are\\n\\\\((1-\\\\alpha)^2\\\\) and \\\\(1\\\\) if adjust=True, and\\n\\\\((1-\\\\alpha)^2\\\\) and \\\\(\\\\alpha\\\\) if adjust=False.\\nWhen ignore_na=True, weights are based\\non relative positions. For example, the weights of \\\\(x_0\\\\) and \\\\(x_2\\\\)\\nused in calculating the final weighted average of\\n[\\\\(x_0\\\\), None, \\\\(x_2\\\\)] are \\\\(1-\\\\alpha\\\\) and \\\\(1\\\\) if\\nadjust=True, and \\\\(1-\\\\alpha\\\\) and \\\\(\\\\alpha\\\\) if adjust=False.\\n\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0, 1}, default 0',\n",
       "         'param_desc': \"If 0 or 'index', calculate across the rows.\\nIf 1 or 'columns', calculate across the columns.\\nFor Series this parameter is unused and defaults to 0.\\n\"},\n",
       "        {'param_name': 'times',\n",
       "         'param_type': 'np.ndarray, Series, default None',\n",
       "         'param_desc': 'Only applicable to mean().\\nTimes corresponding to the observations. Must be monotonically increasing and\\ndatetime64[ns] dtype.\\nIf 1-D array like, a sequence with the same shape as the observations.\\n'},\n",
       "        {'param_name': 'method',\n",
       "         'param_type': 'str {‘single’, ‘table’}, default ‘single’',\n",
       "         'param_desc': \"\\nNew in version 1.4.0.\\n\\nExecute the rolling operation per single column or row ('single')\\nor over the entire object ('table').\\nThis argument is only implemented when specifying engine='numba'\\nin the method call.\\nOnly applicable to mean()\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.Series.ewm',\n",
       "       'descriptions': 'Provide exponentially weighted (EW) calculations. Exactly one of com, span, halflife, or alpha must be\\nprovided if times is not provided. If times is provided,\\nhalflife and one of com, span or alpha may be provided.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'com': {'type': 'float',\n",
       "          'description': 'float, optional. Specify decay in terms of center of mass\\n\\\\(\\\\alpha = 1 / (1 + com)\\\\), for \\\\(com \\\\geq 0\\\\).\\n'},\n",
       "         'span': {'type': 'float',\n",
       "          'description': 'float, optional. Specify decay in terms of span\\n\\\\(\\\\alpha = 2 / (span + 1)\\\\), for \\\\(span \\\\geq 1\\\\).\\n'},\n",
       "         'halflife': {'type': 'string',\n",
       "          'description': 'float, str, timedelta, optional. Specify decay in terms of half-life\\n\\\\(\\\\alpha = 1 - \\\\exp\\\\left(-\\\\ln(2) / halflife\\\\right)\\\\), for\\n\\\\(halflife > 0\\\\).\\nIf times is specified, a timedelta convertible unit over which an\\nobservation decays to half its value. Only applicable to mean(),\\nand halflife value will not apply to the other functions.\\n'},\n",
       "         'alpha': {'type': 'float',\n",
       "          'description': 'float, optional. Specify smoothing factor \\\\(\\\\alpha\\\\) directly\\n\\\\(0 < \\\\alpha \\\\leq 1\\\\).\\n'},\n",
       "         'min_periods': {'type': 'integer',\n",
       "          'description': 'int, default 0. Minimum number of observations in window required to have a value;\\notherwise, result is np.nan.\\n'},\n",
       "         'adjust': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Divide by decaying adjustment factor in beginning periods to account\\nfor imbalance in relative weightings (viewing EWMA as a moving average).\\n\\nWhen adjust=True (default), the EW function is calculated using weights\\n\\\\(w_i = (1 - \\\\alpha)^i\\\\). For example, the EW moving average of the series\\n[\\\\(x_0, x_1, ..., x_t\\\\)] would be:\\n\\n\\n\\\\[y_t = \\\\frac{x_t + (1 - \\\\alpha)x_{t-1} + (1 - \\\\alpha)^2 x_{t-2} + ... + (1 -\\n\\\\alpha)^t x_0}{1 + (1 - \\\\alpha) + (1 - \\\\alpha)^2 + ... + (1 - \\\\alpha)^t}\\\\]\\n\\nWhen adjust=False, the exponentially weighted function is calculated\\nrecursively:\\n\\n\\n\\\\[\\\\begin{split}\\\\begin{split}\\ny_0 &= x_0\\\\\\\\\\ny_t &= (1 - \\\\alpha) y_{t-1} + \\\\alpha x_t,\\n\\\\end{split}\\\\end{split}\\\\]\\n'},\n",
       "         'ignore_na': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Ignore missing values when calculating weights.\\n\\nWhen ignore_na=False (default), weights are based on absolute positions.\\nFor example, the weights of \\\\(x_0\\\\) and \\\\(x_2\\\\) used in calculating\\nthe final weighted average of [\\\\(x_0\\\\), None, \\\\(x_2\\\\)] are\\n\\\\((1-\\\\alpha)^2\\\\) and \\\\(1\\\\) if adjust=True, and\\n\\\\((1-\\\\alpha)^2\\\\) and \\\\(\\\\alpha\\\\) if adjust=False.\\nWhen ignore_na=True, weights are based\\non relative positions. For example, the weights of \\\\(x_0\\\\) and \\\\(x_2\\\\)\\nused in calculating the final weighted average of\\n[\\\\(x_0\\\\), None, \\\\(x_2\\\\)] are \\\\(1-\\\\alpha\\\\) and \\\\(1\\\\) if\\nadjust=True, and \\\\(1-\\\\alpha\\\\) and \\\\(\\\\alpha\\\\) if adjust=False.\\n\\n'},\n",
       "         'axis': {'type': '{0, 1}, default 0',\n",
       "          'description': \"{0, 1}, default 0. If 0 or 'index', calculate across the rows.\\nIf 1 or 'columns', calculate across the columns.\\nFor Series this parameter is unused and defaults to 0.\\n\"},\n",
       "         'times': {'type': 'array',\n",
       "          'description': 'np.ndarray, Series, default None. Only applicable to mean().\\nTimes corresponding to the observations. Must be monotonically increasing and\\ndatetime64[ns] dtype.\\nIf 1-D array like, a sequence with the same shape as the observations.\\n'},\n",
       "         'method': {'type': 'string',\n",
       "          'description': \"str {‘single’, ‘table’}, default ‘single’. \\nNew in version 1.4.0.\\n\\nExecute the rolling operation per single column or row ('single')\\nor over the entire object ('table').\\nThis argument is only implemented when specifying engine='numba'\\nin the method call.\\nOnly applicable to mean()\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.agg([func,\\xa0axis])',\n",
       "      'func_desc': 'Aggregate using one or more operations over the specified axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.agg.html#pandas.Series.agg',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.agg',\n",
       "       'full_function': 'Series.agg(func=None, axis=0, *args, **kwargs)',\n",
       "       'function_text': 'Aggregate using one or more operations over the specified axis.',\n",
       "       'parameter_names_desc': [{'param_name': 'func',\n",
       "         'param_type': 'function, str, list or dict',\n",
       "         'param_desc': \"Function to use for aggregating the data. If a function, must either\\nwork when passed a Series or when passed to Series.apply.\\nAccepted combinations are:\\n\\nfunction\\nstring function name\\nlist of functions and/or function names, e.g. [np.sum, 'mean']\\ndict of axis labels -> functions, function names or list of such.\\n\\n\"},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’}',\n",
       "         'param_desc': 'Unused. Parameter needed for compatibility with DataFrame.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.agg',\n",
       "       'descriptions': 'Aggregate using one or more operations over the specified axis.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'func': {'type': 'string',\n",
       "          'description': \"function, str, list or dict. Function to use for aggregating the data. If a function, must either\\nwork when passed a Series or when passed to Series.apply.\\nAccepted combinations are:\\n\\nfunction\\nstring function name\\nlist of functions and/or function names, e.g. [np.sum, 'mean']\\ndict of axis labels -> functions, function names or list of such.\\n\\n\"},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’}. Unused. Parameter needed for compatibility with DataFrame.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.transform(func[,\\xa0axis])',\n",
       "      'func_desc': 'Call func on self producing a Series with the same axis shape as self.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.transform.html#pandas.Series.transform',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.transform',\n",
       "       'full_function': 'Series.transform(func, axis=0, *args, **kwargs)',\n",
       "       'function_text': 'Call func on self producing a Series with the same axis shape as self.',\n",
       "       'parameter_names_desc': [{'param_name': 'ValueError',\n",
       "         'param_type': 'If the returned Series has a different length than self.',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.Series.transform',\n",
       "       'descriptions': 'Call func on self producing a Series with the same axis shape as self.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'ValueError': {'type': 'If the returned Series has a different length than self.',\n",
       "          'description': 'If the returned Series has a different length than self.. '}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.groupby([by,\\xa0axis,\\xa0level,\\xa0as_index,\\xa0...])',\n",
       "      'func_desc': 'Group Series using a mapper or by a Series of columns.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.groupby.html#pandas.Series.groupby',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.groupby',\n",
       "       'full_function': 'Series.groupby(by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, observed=_NoDefault.no_default, dropna=True)',\n",
       "       'function_text': 'Group Series using a mapper or by a Series of columns. A groupby operation involves some combination of splitting the\\nobject, applying a function, and combining the results. This can be\\nused to group large amounts of data and compute operations on these\\ngroups.',\n",
       "       'parameter_names_desc': [{'param_name': 'by',\n",
       "         'param_type': 'mapping, function, label, pd.Grouper or list of such',\n",
       "         'param_desc': 'Used to determine the groups for the groupby.\\nIf by is a function, it’s called on each value of the object’s\\nindex. If a dict or Series is passed, the Series or dict VALUES\\nwill be used to determine the groups (the Series’ values are first\\naligned; see .align() method). If a list or ndarray of length\\nequal to the selected axis is passed (see the groupby user guide),\\nthe values are used as-is to determine the groups. A label or list\\nof labels may be passed to group by the columns in self.\\nNotice that a tuple is interpreted as a (single) key.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'Split along rows (0) or columns (1). For Series this parameter\\nis unused and defaults to 0.\\n\\nDeprecated since version 2.1.0: Will be removed and behave like axis=0 in a future version.\\nFor axis=1, do frame.T.groupby(...) instead.\\n\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int, level name, or sequence of such, default None',\n",
       "         'param_desc': 'If the axis is a MultiIndex (hierarchical), group by a particular\\nlevel or levels. Do not specify both by and level.\\n'},\n",
       "        {'param_name': 'as_index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Return object with group labels as the\\nindex. Only relevant for DataFrame input. as_index=False is\\neffectively “SQL-style” grouped output. This argument has no effect\\non filtrations (see the filtrations in the user guide),\\nsuch as head(), tail(), nth() and in transformations\\n(see the transformations in the user guide).\\n'},\n",
       "        {'param_name': 'sort',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Sort group keys. Get better performance by turning this off.\\nNote this does not influence the order of observations within each\\ngroup. Groupby preserves the order of rows within each group. If False,\\nthe groups will appear in the same order as they did in the original DataFrame.\\nThis argument has no effect on filtrations (see the filtrations in the user guide),\\nsuch as head(), tail(), nth() and in transformations\\n(see the transformations in the user guide).\\n\\nChanged in version 2.0.0: Specifying sort=False with an ordered categorical grouper will no\\nlonger sort the values.\\n\\n'},\n",
       "        {'param_name': 'group_keys',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'When calling apply and the by argument produces a like-indexed\\n(i.e. a transform) result, add group keys to\\nindex to identify pieces. By default group keys are not included\\nwhen the result’s index (and column) labels match the inputs, and\\nare included otherwise.\\n\\nChanged in version 1.5.0: Warns that group_keys will no longer be ignored when the\\nresult from apply is a like-indexed Series or DataFrame.\\nSpecify group_keys explicitly to include the group keys or\\nnot.\\n\\n\\nChanged in version 2.0.0: group_keys now defaults to True.\\n\\n'},\n",
       "        {'param_name': 'observed',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'This only applies if any of the groupers are Categoricals.\\nIf True: only show observed values for categorical groupers.\\nIf False: show all values for categorical groupers.\\n\\nDeprecated since version 2.1.0: The default value will change to True in a future version of pandas.\\n\\n'},\n",
       "        {'param_name': 'dropna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If True, and if group keys contain NA values, NA values together\\nwith row/column will be dropped.\\nIf False, NA values will also be treated as the key in groups.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.groupby',\n",
       "       'descriptions': 'Group Series using a mapper or by a Series of columns. A groupby operation involves some combination of splitting the\\nobject, applying a function, and combining the results. This can be\\nused to group large amounts of data and compute operations on these\\ngroups.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'by': {'type': 'array',\n",
       "          'description': 'mapping, function, label, pd.Grouper or list of such. Used to determine the groups for the groupby.\\nIf by is a function, it’s called on each value of the object’s\\nindex. If a dict or Series is passed, the Series or dict VALUES\\nwill be used to determine the groups (the Series’ values are first\\naligned; see .align() method). If a list or ndarray of length\\nequal to the selected axis is passed (see the groupby user guide),\\nthe values are used as-is to determine the groups. A label or list\\nof labels may be passed to group by the columns in self.\\nNotice that a tuple is interpreted as a (single) key.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. Split along rows (0) or columns (1). For Series this parameter\\nis unused and defaults to 0.\\n\\nDeprecated since version 2.1.0: Will be removed and behave like axis=0 in a future version.\\nFor axis=1, do frame.T.groupby(...) instead.\\n\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int, level name, or sequence of such, default None. If the axis is a MultiIndex (hierarchical), group by a particular\\nlevel or levels. Do not specify both by and level.\\n'},\n",
       "         'as_index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Return object with group labels as the\\nindex. Only relevant for DataFrame input. as_index=False is\\neffectively “SQL-style” grouped output. This argument has no effect\\non filtrations (see the filtrations in the user guide),\\nsuch as head(), tail(), nth() and in transformations\\n(see the transformations in the user guide).\\n'},\n",
       "         'sort': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Sort group keys. Get better performance by turning this off.\\nNote this does not influence the order of observations within each\\ngroup. Groupby preserves the order of rows within each group. If False,\\nthe groups will appear in the same order as they did in the original DataFrame.\\nThis argument has no effect on filtrations (see the filtrations in the user guide),\\nsuch as head(), tail(), nth() and in transformations\\n(see the transformations in the user guide).\\n\\nChanged in version 2.0.0: Specifying sort=False with an ordered categorical grouper will no\\nlonger sort the values.\\n\\n'},\n",
       "         'group_keys': {'type': 'boolean',\n",
       "          'description': 'bool, default True. When calling apply and the by argument produces a like-indexed\\n(i.e. a transform) result, add group keys to\\nindex to identify pieces. By default group keys are not included\\nwhen the result’s index (and column) labels match the inputs, and\\nare included otherwise.\\n\\nChanged in version 1.5.0: Warns that group_keys will no longer be ignored when the\\nresult from apply is a like-indexed Series or DataFrame.\\nSpecify group_keys explicitly to include the group keys or\\nnot.\\n\\n\\nChanged in version 2.0.0: group_keys now defaults to True.\\n\\n'},\n",
       "         'observed': {'type': 'boolean',\n",
       "          'description': 'bool, default False. This only applies if any of the groupers are Categoricals.\\nIf True: only show observed values for categorical groupers.\\nIf False: show all values for categorical groupers.\\n\\nDeprecated since version 2.1.0: The default value will change to True in a future version of pandas.\\n\\n'},\n",
       "         'dropna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If True, and if group keys contain NA values, NA values together\\nwith row/column will be dropped.\\nIf False, NA values will also be treated as the key in groups.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.expanding([min_periods,\\xa0axis,\\xa0method])',\n",
       "      'func_desc': 'Provide expanding window calculations.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.expanding.html#pandas.Series.expanding',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.expanding',\n",
       "       'full_function': \"Series.expanding(min_periods=1, axis=_NoDefault.no_default, method='single')\",\n",
       "       'function_text': 'Provide expanding window calculations.',\n",
       "       'parameter_names_desc': [{'param_name': 'min_periods',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Minimum number of observations in window required to have a value;\\notherwise, result is np.nan.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': 'int or str, default 0',\n",
       "         'param_desc': \"If 0 or 'index', roll across the rows.\\nIf 1 or 'columns', roll across the columns.\\nFor Series this parameter is unused and defaults to 0.\\n\"},\n",
       "        {'param_name': 'method',\n",
       "         'param_type': 'str {‘single’, ‘table’}, default ‘single’',\n",
       "         'param_desc': \"Execute the rolling operation per single column or row ('single')\\nor over the entire object ('table').\\nThis argument is only implemented when specifying engine='numba'\\nin the method call.\\n\\nNew in version 1.3.0.\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.Series.expanding',\n",
       "       'descriptions': 'Provide expanding window calculations.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'min_periods': {'type': 'integer',\n",
       "          'description': 'int, default 1. Minimum number of observations in window required to have a value;\\notherwise, result is np.nan.\\n'},\n",
       "         'axis': {'type': 'integer',\n",
       "          'description': \"int or str, default 0. If 0 or 'index', roll across the rows.\\nIf 1 or 'columns', roll across the columns.\\nFor Series this parameter is unused and defaults to 0.\\n\"},\n",
       "         'method': {'type': 'string',\n",
       "          'description': \"str {‘single’, ‘table’}, default ‘single’. Execute the rolling operation per single column or row ('single')\\nor over the entire object ('table').\\nThis argument is only implemented when specifying engine='numba'\\nin the method call.\\n\\nNew in version 1.3.0.\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.pipe(func,\\xa0*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Apply chainable functions that expect Series or DataFrames.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.pipe.html#pandas.Series.pipe',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.pipe',\n",
       "       'full_function': 'Series.pipe(func, *args, **kwargs)',\n",
       "       'function_text': 'Apply chainable functions that expect Series or DataFrames.',\n",
       "       'parameter_names_desc': [{'param_name': 'func',\n",
       "         'param_type': 'function',\n",
       "         'param_desc': 'Function to apply to the Series/DataFrame.\\nargs, and kwargs are passed into func.\\nAlternatively a (callable, data_keyword) tuple where\\ndata_keyword is a string indicating the keyword of\\ncallable that expects the Series/DataFrame.\\n'},\n",
       "        {'param_name': '*args',\n",
       "         'param_type': 'iterable, optional',\n",
       "         'param_desc': 'Positional arguments passed into func.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.pipe',\n",
       "       'descriptions': 'Apply chainable functions that expect Series or DataFrames.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'func': {'type': 'function',\n",
       "          'description': 'function. Function to apply to the Series/DataFrame.\\nargs, and kwargs are passed into func.\\nAlternatively a (callable, data_keyword) tuple where\\ndata_keyword is a string indicating the keyword of\\ncallable that expects the Series/DataFrame.\\n'},\n",
       "         '*args': {'type': 'iterable, optional',\n",
       "          'description': 'iterable, optional. Positional arguments passed into func.\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Computations / descriptive stats': [{'func_name': 'Series.abs()',\n",
       "      'func_desc': 'Return a Series/DataFrame with absolute numeric value of each element.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.abs.html#pandas.Series.abs',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.abs',\n",
       "       'full_function': 'Series.abs()',\n",
       "       'function_text': 'Return a Series/DataFrame with absolute numeric value of each element. This function only applies to elements that are all numeric.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.any(*[,\\xa0axis,\\xa0bool_only,\\xa0skipna])',\n",
       "      'func_desc': 'Return whether any element is True, potentially over an axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.any.html#pandas.Series.any',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.any',\n",
       "       'full_function': 'Series.any(*, axis=0, bool_only=False, skipna=True, **kwargs)',\n",
       "       'function_text': 'Return whether any element is True, potentially over an axis. Returns False unless there is at least one element within a series or\\nalong a Dataframe axis that is True or equivalent (e.g. non-zero or\\nnon-empty).',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’, None}, default 0',\n",
       "         'param_desc': 'Indicate which axis or axes should be reduced. For Series this parameter\\nis unused and defaults to 0.\\n\\n0 / ‘index’ : reduce the index, return a Series whose index is the\\noriginal column labels.\\n1 / ‘columns’ : reduce the columns, return a Series whose index is the\\noriginal index.\\nNone : reduce all axes, return a scalar.\\n\\n'},\n",
       "        {'param_name': 'bool_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only boolean columns. Not implemented for Series.\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values. If the entire row/column is NA and skipna is\\nTrue, then the result will be False, as for an empty row/column.\\nIf skipna is False, then NA are treated as True, because these are not\\nequal to zero.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.any',\n",
       "       'descriptions': 'Return whether any element is True, potentially over an axis. Returns False unless there is at least one element within a series or\\nalong a Dataframe axis that is True or equivalent (e.g. non-zero or\\nnon-empty).',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns', ' None'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’, None}, default 0. Indicate which axis or axes should be reduced. For Series this parameter\\nis unused and defaults to 0.\\n\\n0 / ‘index’ : reduce the index, return a Series whose index is the\\noriginal column labels.\\n1 / ‘columns’ : reduce the columns, return a Series whose index is the\\noriginal index.\\nNone : reduce all axes, return a scalar.\\n\\n'},\n",
       "         'bool_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only boolean columns. Not implemented for Series.\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values. If the entire row/column is NA and skipna is\\nTrue, then the result will be False, as for an empty row/column.\\nIf skipna is False, then NA are treated as True, because these are not\\nequal to zero.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.between(left,\\xa0right[,\\xa0inclusive])',\n",
       "      'func_desc': 'Return boolean Series equivalent to left <= series <= right.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.between.html#pandas.Series.between',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.between',\n",
       "       'full_function': \"Series.between(left, right, inclusive='both')\",\n",
       "       'function_text': 'Return boolean Series equivalent to left <= series <= right. This function returns a boolean vector containing True wherever the\\ncorresponding Series element is between the boundary values left and\\nright. NA values are treated as False.',\n",
       "       'parameter_names_desc': [{'param_name': 'left',\n",
       "         'param_type': 'scalar or list-like',\n",
       "         'param_desc': 'Left boundary.\\n'},\n",
       "        {'param_name': 'right',\n",
       "         'param_type': 'scalar or list-like',\n",
       "         'param_desc': 'Right boundary.\\n'},\n",
       "        {'param_name': 'inclusive',\n",
       "         'param_type': '{“both”, “neither”, “left”, “right”}',\n",
       "         'param_desc': 'Include boundaries. Whether to set each bound as closed or open.\\n\\nChanged in version 1.3.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.between',\n",
       "       'descriptions': 'Return boolean Series equivalent to left <= series <= right. This function returns a boolean vector containing True wherever the\\ncorresponding Series element is between the boundary values left and\\nright. NA values are treated as False.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'left': {'type': 'array',\n",
       "          'description': 'scalar or list-like. Left boundary.\\n'},\n",
       "         'right': {'type': 'array',\n",
       "          'description': 'scalar or list-like. Right boundary.\\n'},\n",
       "         'inclusive': {'type': '{“both”, “neither”, “left”, “right”}',\n",
       "          'description': '{“both”, “neither”, “left”, “right”}. Include boundaries. Whether to set each bound as closed or open.\\n\\nChanged in version 1.3.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.corr(other[,\\xa0method,\\xa0min_periods])',\n",
       "      'func_desc': 'Compute correlation with other Series, excluding missing values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.corr.html#pandas.Series.corr',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.corr',\n",
       "       'full_function': \"Series.corr(other, method='pearson', min_periods=None)\",\n",
       "       'function_text': 'Compute correlation with other Series, excluding missing values. The two Series objects are not required to be the same length and will be\\naligned internally before the correlation function is applied.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series',\n",
       "         'param_desc': 'Series with which to compute the correlation.\\n'},\n",
       "        {'param_name': 'method',\n",
       "         'param_type': '{‘pearson’, ‘kendall’, ‘spearman’} or callable',\n",
       "         'param_desc': 'Method used to compute correlation:\\n\\npearson : Standard correlation coefficient\\nkendall : Kendall Tau correlation coefficient\\nspearman : Spearman rank correlation\\ncallable: Callable with input two 1d ndarrays and returning a float.\\n\\n\\nWarning\\nNote that the returned matrix from corr will have 1 along the\\ndiagonals and will be symmetric regardless of the callable’s\\nbehavior.\\n\\n'},\n",
       "        {'param_name': 'min_periods',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Minimum number of observations needed to have a valid result.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.corr',\n",
       "       'descriptions': 'Compute correlation with other Series, excluding missing values. The two Series objects are not required to be the same length and will be\\naligned internally before the correlation function is applied.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series',\n",
       "          'description': 'Series. Series with which to compute the correlation.\\n'},\n",
       "         'method': {'type': 'object',\n",
       "          'description': '{‘pearson’, ‘kendall’, ‘spearman’} or callable. Method used to compute correlation:\\n\\npearson : Standard correlation coefficient\\nkendall : Kendall Tau correlation coefficient\\nspearman : Spearman rank correlation\\ncallable: Callable with input two 1d ndarrays and returning a float.\\n\\n\\nWarning\\nNote that the returned matrix from corr will have 1 along the\\ndiagonals and will be symmetric regardless of the callable’s\\nbehavior.\\n\\n'},\n",
       "         'min_periods': {'type': 'integer',\n",
       "          'description': 'int, optional. Minimum number of observations needed to have a valid result.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.cov(other[,\\xa0min_periods,\\xa0ddof])',\n",
       "      'func_desc': 'Compute covariance with Series, excluding missing values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.cov.html#pandas.Series.cov',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.cov',\n",
       "       'full_function': 'Series.cov(other, min_periods=None, ddof=1)',\n",
       "       'function_text': 'Compute covariance with Series, excluding missing values. The two Series objects are not required to be the same length and\\nwill be aligned internally before the covariance is calculated.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series',\n",
       "         'param_desc': 'Series with which to compute the covariance.\\n'},\n",
       "        {'param_name': 'min_periods',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Minimum number of observations needed to have a valid result.\\n'},\n",
       "        {'param_name': 'ddof',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Delta degrees of freedom. The divisor used in calculations\\nis N - ddof, where N represents the number of elements.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.cov',\n",
       "       'descriptions': 'Compute covariance with Series, excluding missing values. The two Series objects are not required to be the same length and\\nwill be aligned internally before the covariance is calculated.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series',\n",
       "          'description': 'Series. Series with which to compute the covariance.\\n'},\n",
       "         'min_periods': {'type': 'integer',\n",
       "          'description': 'int, optional. Minimum number of observations needed to have a valid result.\\n'},\n",
       "         'ddof': {'type': 'integer',\n",
       "          'description': 'int, default 1. Delta degrees of freedom. The divisor used in calculations\\nis N - ddof, where N represents the number of elements.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.cummin([axis,\\xa0skipna])',\n",
       "      'func_desc': 'Return cumulative minimum over a DataFrame or Series axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.cummin.html#pandas.Series.cummin',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.cummin',\n",
       "       'full_function': 'Series.cummin(axis=None, skipna=True, *args, **kwargs)',\n",
       "       'function_text': 'Return cumulative minimum over a DataFrame or Series axis. Returns a DataFrame or Series of the same size containing the cumulative\\nminimum.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'The index or the name of the axis. 0 is equivalent to None or ‘index’.\\nFor Series this parameter is unused and defaults to 0.\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.cummin',\n",
       "       'descriptions': 'Return cumulative minimum over a DataFrame or Series axis. Returns a DataFrame or Series of the same size containing the cumulative\\nminimum.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. The index or the name of the axis. 0 is equivalent to None or ‘index’.\\nFor Series this parameter is unused and defaults to 0.\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.cumsum([axis,\\xa0skipna])',\n",
       "      'func_desc': 'Return cumulative sum over a DataFrame or Series axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.cumsum.html#pandas.Series.cumsum',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.cumsum',\n",
       "       'full_function': 'Series.cumsum(axis=None, skipna=True, *args, **kwargs)',\n",
       "       'function_text': 'Return cumulative sum over a DataFrame or Series axis. Returns a DataFrame or Series of the same size containing the cumulative\\nsum.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'The index or the name of the axis. 0 is equivalent to None or ‘index’.\\nFor Series this parameter is unused and defaults to 0.\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.cumsum',\n",
       "       'descriptions': 'Return cumulative sum over a DataFrame or Series axis. Returns a DataFrame or Series of the same size containing the cumulative\\nsum.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. The index or the name of the axis. 0 is equivalent to None or ‘index’.\\nFor Series this parameter is unused and defaults to 0.\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.diff([periods])',\n",
       "      'func_desc': 'First discrete difference of element.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.diff.html#pandas.Series.diff',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.diff',\n",
       "       'full_function': 'Series.diff(periods=1)',\n",
       "       'function_text': 'First discrete difference of element. Calculates the difference of a Series element compared with another\\nelement in the Series (default is element in previous row).',\n",
       "       'parameter_names_desc': [{'param_name': 'periods',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Periods to shift for calculating difference, accepts negative\\nvalues.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.diff',\n",
       "       'descriptions': 'First discrete difference of element. Calculates the difference of a Series element compared with another\\nelement in the Series (default is element in previous row).',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'periods': {'type': 'integer',\n",
       "          'description': 'int, default 1. Periods to shift for calculating difference, accepts negative\\nvalues.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.kurt([axis,\\xa0skipna,\\xa0numeric_only])',\n",
       "      'func_desc': 'Return unbiased kurtosis over requested axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.kurt.html#pandas.Series.kurt',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.kurt',\n",
       "       'full_function': 'Series.kurt(axis=0, skipna=True, numeric_only=False, **kwargs)',\n",
       "       'function_text': 'Return unbiased kurtosis over requested axis. Kurtosis obtained using Fisher’s definition of\\nkurtosis (kurtosis of normal == 0.0). Normalized by N-1.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{index (0)}',\n",
       "         'param_desc': 'Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\nFor DataFrames, specifying axis=None will apply the aggregation\\nacross both axes.\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values when computing the result.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns. Not implemented for Series.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.kurt',\n",
       "       'descriptions': 'Return unbiased kurtosis over requested axis. Kurtosis obtained using Fisher’s definition of\\nkurtosis (kurtosis of normal == 0.0). Normalized by N-1.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': '{index (0)}',\n",
       "          'description': '{index (0)}. Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\nFor DataFrames, specifying axis=None will apply the aggregation\\nacross both axes.\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values when computing the result.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns. Not implemented for Series.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.mean([axis,\\xa0skipna,\\xa0numeric_only])',\n",
       "      'func_desc': 'Return the mean of the values over the requested axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.mean.html#pandas.Series.mean',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.mean',\n",
       "       'full_function': 'Series.mean(axis=0, skipna=True, numeric_only=False, **kwargs)',\n",
       "       'function_text': 'Return the mean of the values over the requested axis.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{index (0)}',\n",
       "         'param_desc': 'Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\nFor DataFrames, specifying axis=None will apply the aggregation\\nacross both axes.\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values when computing the result.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns. Not implemented for Series.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.mean',\n",
       "       'descriptions': 'Return the mean of the values over the requested axis.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': '{index (0)}',\n",
       "          'description': '{index (0)}. Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\nFor DataFrames, specifying axis=None will apply the aggregation\\nacross both axes.\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values when computing the result.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns. Not implemented for Series.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.min([axis,\\xa0skipna,\\xa0numeric_only])',\n",
       "      'func_desc': 'Return the minimum of the values over the requested axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.min.html#pandas.Series.min',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.min',\n",
       "       'full_function': 'Series.min(axis=0, skipna=True, numeric_only=False, **kwargs)',\n",
       "       'function_text': 'Return the minimum of the values over the requested axis. If you want the index of the minimum, use idxmin. This is the equivalent of the numpy.ndarray method argmin.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{index (0)}',\n",
       "         'param_desc': 'Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\nFor DataFrames, specifying axis=None will apply the aggregation\\nacross both axes.\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values when computing the result.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns. Not implemented for Series.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.min',\n",
       "       'descriptions': 'Return the minimum of the values over the requested axis. If you want the index of the minimum, use idxmin. This is the equivalent of the numpy.ndarray method argmin.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': '{index (0)}',\n",
       "          'description': '{index (0)}. Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\nFor DataFrames, specifying axis=None will apply the aggregation\\nacross both axes.\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values when computing the result.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns. Not implemented for Series.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.nlargest([n,\\xa0keep])',\n",
       "      'func_desc': 'Return the largest n elements.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.nlargest.html#pandas.Series.nlargest',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.nlargest',\n",
       "       'full_function': \"Series.nlargest(n=5, keep='first')\",\n",
       "       'function_text': 'Return the largest n elements.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 5',\n",
       "         'param_desc': 'Return this many descending sorted values.\\n'},\n",
       "        {'param_name': 'keep',\n",
       "         'param_type': '{‘first’, ‘last’, ‘all’}, default ‘first’',\n",
       "         'param_desc': 'When there are duplicate values that cannot all fit in a\\nSeries of n elements:\\n\\nfirst : return the first n occurrences in order\\nof appearance.\\nlast : return the last n occurrences in reverse\\norder of appearance.\\nall : keep all occurrences. This can result in a Series of\\nsize larger than n.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.nlargest',\n",
       "       'descriptions': 'Return the largest n elements.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 5. Return this many descending sorted values.\\n'},\n",
       "         'keep': {'type': 'string',\n",
       "          'enum': ['first', ' last', ' all'],\n",
       "          'description': '{‘first’, ‘last’, ‘all’}, default ‘first’. When there are duplicate values that cannot all fit in a\\nSeries of n elements:\\n\\nfirst : return the first n occurrences in order\\nof appearance.\\nlast : return the last n occurrences in reverse\\norder of appearance.\\nall : keep all occurrences. This can result in a Series of\\nsize larger than n.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.pct_change([periods,\\xa0fill_method,\\xa0...])',\n",
       "      'func_desc': 'Fractional change between the current and a prior element.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.pct_change.html#pandas.Series.pct_change',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.pct_change',\n",
       "       'full_function': 'Series.pct_change(periods=1, fill_method=_NoDefault.no_default, limit=_NoDefault.no_default, freq=None, **kwargs)',\n",
       "       'function_text': 'Fractional change between the current and a prior element. Computes the fractional change from the immediately previous row by\\ndefault. This is useful in comparing the fraction of change in a time\\nseries of elements. Note Despite the name of this method, it calculates fractional change\\n(also known as per unit change or relative change) and not\\npercentage change. If you need the percentage change, multiply\\nthese values by 100.',\n",
       "       'parameter_names_desc': [{'param_name': 'periods',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Periods to shift for forming percent change.\\n'},\n",
       "        {'param_name': 'fill_method',\n",
       "         'param_type': '{‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}, default ‘pad’',\n",
       "         'param_desc': 'How to handle NAs before computing percent changes.\\n\\nDeprecated since version 2.1: All options of fill_method are deprecated except fill_method=None.\\n\\n'},\n",
       "        {'param_name': 'limit',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'The number of consecutive NAs to fill before stopping.\\n\\nDeprecated since version 2.1.\\n\\n'},\n",
       "        {'param_name': 'freq',\n",
       "         'param_type': 'DateOffset, timedelta, or str, optional',\n",
       "         'param_desc': 'Increment to use from time series API (e.g. ‘ME’ or BDay()).\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.pct_change',\n",
       "       'descriptions': 'Fractional change between the current and a prior element. Computes the fractional change from the immediately previous row by\\ndefault. This is useful in comparing the fraction of change in a time\\nseries of elements. Note Despite the name of this method, it calculates fractional change\\n(also known as per unit change or relative change) and not\\npercentage change. If you need the percentage change, multiply\\nthese values by 100.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'periods': {'type': 'integer',\n",
       "          'description': 'int, default 1. Periods to shift for forming percent change.\\n'},\n",
       "         'fill_method': {'type': 'string',\n",
       "          'enum': ['backfill', ' bfill', ' pad', ' ffill', ' None'],\n",
       "          'description': '{‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}, default ‘pad’. How to handle NAs before computing percent changes.\\n\\nDeprecated since version 2.1: All options of fill_method are deprecated except fill_method=None.\\n\\n'},\n",
       "         'limit': {'type': 'integer',\n",
       "          'description': 'int, default None. The number of consecutive NAs to fill before stopping.\\n\\nDeprecated since version 2.1.\\n\\n'},\n",
       "         'freq': {'type': 'string',\n",
       "          'description': 'DateOffset, timedelta, or str, optional. Increment to use from time series API (e.g. ‘ME’ or BDay()).\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.quantile([q,\\xa0interpolation])',\n",
       "      'func_desc': 'Return value at the given quantile.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.quantile.html#pandas.Series.quantile',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.quantile',\n",
       "       'full_function': \"Series.quantile(q=0.5, interpolation='linear')\",\n",
       "       'function_text': 'Return value at the given quantile.',\n",
       "       'parameter_names_desc': [{'param_name': 'q',\n",
       "         'param_type': 'float or array-like, default 0.5 (50% quantile)',\n",
       "         'param_desc': 'The quantile(s) to compute, which can lie in range: 0 <= q <= 1.\\n'},\n",
       "        {'param_name': 'interpolation',\n",
       "         'param_type': '{‘linear’, ‘lower’, ‘higher’, ‘midpoint’, ‘nearest’}',\n",
       "         'param_desc': 'This optional parameter specifies the interpolation method to use,\\nwhen the desired quantile lies between two data points i and j:\\n\\n\\nlinear: i + (j - i) * (x-i)/(j-i), where (x-i)/(j-i) is\\nthe fractional part of the index surrounded by i > j.\\nlower: i.\\nhigher: j.\\nnearest: i or j whichever is nearest.\\nmidpoint: (i + j) / 2.\\n\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.quantile',\n",
       "       'descriptions': 'Return value at the given quantile.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'q': {'type': 'float',\n",
       "          'description': 'float or array-like, default 0.5 (50% quantile). The quantile(s) to compute, which can lie in range: 0 <= q <= 1.\\n'},\n",
       "         'interpolation': {'type': 'integer',\n",
       "          'description': '{‘linear’, ‘lower’, ‘higher’, ‘midpoint’, ‘nearest’}. This optional parameter specifies the interpolation method to use,\\nwhen the desired quantile lies between two data points i and j:\\n\\n\\nlinear: i + (j - i) * (x-i)/(j-i), where (x-i)/(j-i) is\\nthe fractional part of the index surrounded by i > j.\\nlower: i.\\nhigher: j.\\nnearest: i or j whichever is nearest.\\nmidpoint: (i + j) / 2.\\n\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.sem([axis,\\xa0skipna,\\xa0ddof,\\xa0numeric_only])',\n",
       "      'func_desc': 'Return unbiased standard error of the mean over requested axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.sem.html#pandas.Series.sem',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.sem',\n",
       "       'full_function': 'Series.sem(axis=None, skipna=True, ddof=1, numeric_only=False, **kwargs)',\n",
       "       'function_text': 'Return unbiased standard error of the mean over requested axis. Normalized by N-1 by default. This can be changed using the ddof argument',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{index (0)}',\n",
       "         'param_desc': 'For Series this parameter is unused and defaults to 0.\\n\\nWarning\\nThe behavior of DataFrame.sem with axis=None is deprecated,\\nin a future version this will reduce over both axes and return a scalar\\nTo retain the old behavior, pass axis=0 (or do not pass axis).\\n\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n'},\n",
       "        {'param_name': 'ddof',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\\nwhere N represents the number of elements.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns. Not implemented for Series.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.sem',\n",
       "       'descriptions': 'Return unbiased standard error of the mean over requested axis. Normalized by N-1 by default. This can be changed using the ddof argument',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': '{index (0)}',\n",
       "          'description': '{index (0)}. For Series this parameter is unused and defaults to 0.\\n\\nWarning\\nThe behavior of DataFrame.sem with axis=None is deprecated,\\nin a future version this will reduce over both axes and return a scalar\\nTo retain the old behavior, pass axis=0 (or do not pass axis).\\n\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n'},\n",
       "         'ddof': {'type': 'integer',\n",
       "          'description': 'int, default 1. Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\\nwhere N represents the number of elements.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns. Not implemented for Series.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.std([axis,\\xa0skipna,\\xa0ddof,\\xa0numeric_only])',\n",
       "      'func_desc': 'Return sample standard deviation over requested axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.std.html#pandas.Series.std',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.std',\n",
       "       'full_function': 'Series.std(axis=None, skipna=True, ddof=1, numeric_only=False, **kwargs)',\n",
       "       'function_text': 'Return sample standard deviation over requested axis. Normalized by N-1 by default. This can be changed using the ddof argument.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{index (0)}',\n",
       "         'param_desc': 'For Series this parameter is unused and defaults to 0.\\n\\nWarning\\nThe behavior of DataFrame.std with axis=None is deprecated,\\nin a future version this will reduce over both axes and return a scalar\\nTo retain the old behavior, pass axis=0 (or do not pass axis).\\n\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n'},\n",
       "        {'param_name': 'ddof',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\\nwhere N represents the number of elements.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns. Not implemented for Series.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.std',\n",
       "       'descriptions': 'Return sample standard deviation over requested axis. Normalized by N-1 by default. This can be changed using the ddof argument.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': '{index (0)}',\n",
       "          'description': '{index (0)}. For Series this parameter is unused and defaults to 0.\\n\\nWarning\\nThe behavior of DataFrame.std with axis=None is deprecated,\\nin a future version this will reduce over both axes and return a scalar\\nTo retain the old behavior, pass axis=0 (or do not pass axis).\\n\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n'},\n",
       "         'ddof': {'type': 'integer',\n",
       "          'description': 'int, default 1. Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\\nwhere N represents the number of elements.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns. Not implemented for Series.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.var([axis,\\xa0skipna,\\xa0ddof,\\xa0numeric_only])',\n",
       "      'func_desc': 'Return unbiased variance over requested axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.var.html#pandas.Series.var',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.var',\n",
       "       'full_function': 'Series.var(axis=None, skipna=True, ddof=1, numeric_only=False, **kwargs)',\n",
       "       'function_text': 'Return unbiased variance over requested axis. Normalized by N-1 by default. This can be changed using the ddof argument.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{index (0)}',\n",
       "         'param_desc': 'For Series this parameter is unused and defaults to 0.\\n\\nWarning\\nThe behavior of DataFrame.var with axis=None is deprecated,\\nin a future version this will reduce over both axes and return a scalar\\nTo retain the old behavior, pass axis=0 (or do not pass axis).\\n\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n'},\n",
       "        {'param_name': 'ddof',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\\nwhere N represents the number of elements.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns. Not implemented for Series.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.var',\n",
       "       'descriptions': 'Return unbiased variance over requested axis. Normalized by N-1 by default. This can be changed using the ddof argument.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': '{index (0)}',\n",
       "          'description': '{index (0)}. For Series this parameter is unused and defaults to 0.\\n\\nWarning\\nThe behavior of DataFrame.var with axis=None is deprecated,\\nin a future version this will reduce over both axes and return a scalar\\nTo retain the old behavior, pass axis=0 (or do not pass axis).\\n\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n'},\n",
       "         'ddof': {'type': 'integer',\n",
       "          'description': 'int, default 1. Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\\nwhere N represents the number of elements.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns. Not implemented for Series.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.unique()',\n",
       "      'func_desc': 'Return unique values of Series object.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.unique.html#pandas.Series.unique',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.unique',\n",
       "       'full_function': 'Series.unique()',\n",
       "       'function_text': 'Return unique values of Series object. Uniques are returned in order of appearance. Hash table-based unique,\\ntherefore does NOT sort.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.is_unique',\n",
       "      'func_desc': 'Return boolean if values in the object are unique.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.is_unique.html#pandas.Series.is_unique',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.is_unique',\n",
       "       'full_function': 'property Series.is_unique',\n",
       "       'function_text': 'Return boolean if values in the object are unique.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.is_monotonic_decreasing',\n",
       "      'func_desc': 'Return boolean if values in the object are monotonically decreasing.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.is_monotonic_decreasing.html#pandas.Series.is_monotonic_decreasing',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.is_monotonic_decreasing',\n",
       "       'full_function': 'property Series.is_monotonic_decreasing',\n",
       "       'function_text': 'Return boolean if values in the object are monotonically decreasing.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.all([axis,\\xa0bool_only,\\xa0skipna])',\n",
       "      'func_desc': 'Return whether all elements are True, potentially over an axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.all.html#pandas.Series.all',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.all',\n",
       "       'full_function': 'Series.all(axis=0, bool_only=False, skipna=True, **kwargs)',\n",
       "       'function_text': 'Return whether all elements are True, potentially over an axis. Returns True unless there at least one element within a series or\\nalong a Dataframe axis that is False or equivalent (e.g. zero or\\nempty).',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’, None}, default 0',\n",
       "         'param_desc': 'Indicate which axis or axes should be reduced. For Series this parameter\\nis unused and defaults to 0.\\n\\n0 / ‘index’ : reduce the index, return a Series whose index is the\\noriginal column labels.\\n1 / ‘columns’ : reduce the columns, return a Series whose index is the\\noriginal index.\\nNone : reduce all axes, return a scalar.\\n\\n'},\n",
       "        {'param_name': 'bool_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only boolean columns. Not implemented for Series.\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values. If the entire row/column is NA and skipna is\\nTrue, then the result will be True, as for an empty row/column.\\nIf skipna is False, then NA are treated as True, because these are not\\nequal to zero.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.all',\n",
       "       'descriptions': 'Return whether all elements are True, potentially over an axis. Returns True unless there at least one element within a series or\\nalong a Dataframe axis that is False or equivalent (e.g. zero or\\nempty).',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns', ' None'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’, None}, default 0. Indicate which axis or axes should be reduced. For Series this parameter\\nis unused and defaults to 0.\\n\\n0 / ‘index’ : reduce the index, return a Series whose index is the\\noriginal column labels.\\n1 / ‘columns’ : reduce the columns, return a Series whose index is the\\noriginal index.\\nNone : reduce all axes, return a scalar.\\n\\n'},\n",
       "         'bool_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only boolean columns. Not implemented for Series.\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values. If the entire row/column is NA and skipna is\\nTrue, then the result will be True, as for an empty row/column.\\nIf skipna is False, then NA are treated as True, because these are not\\nequal to zero.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.autocorr([lag])',\n",
       "      'func_desc': 'Compute the lag-N autocorrelation.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.autocorr.html#pandas.Series.autocorr',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.autocorr',\n",
       "       'full_function': 'Series.autocorr(lag=1)',\n",
       "       'function_text': 'Compute the lag-N autocorrelation. This method computes the Pearson correlation between\\nthe Series and its shifted self.',\n",
       "       'parameter_names_desc': [{'param_name': 'lag',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Number of lags to apply before performing autocorrelation.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.autocorr',\n",
       "       'descriptions': 'Compute the lag-N autocorrelation. This method computes the Pearson correlation between\\nthe Series and its shifted self.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'lag': {'type': 'integer',\n",
       "          'description': 'int, default 1. Number of lags to apply before performing autocorrelation.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.clip([lower,\\xa0upper,\\xa0axis,\\xa0inplace])',\n",
       "      'func_desc': 'Trim values at input threshold(s).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.clip.html#pandas.Series.clip',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.clip',\n",
       "       'full_function': 'Series.clip(lower=None, upper=None, *, axis=None, inplace=False, **kwargs)',\n",
       "       'function_text': 'Trim values at input threshold(s). Assigns values outside boundary to boundary values. Thresholds\\ncan be singular values or array like, and in the latter case\\nthe clipping is performed element-wise in the specified axis.',\n",
       "       'parameter_names_desc': [{'param_name': 'lower',\n",
       "         'param_type': 'float or array-like, default None',\n",
       "         'param_desc': 'Minimum threshold value. All values below this\\nthreshold will be set to it. A missing\\nthreshold (e.g NA) will not clip the value.\\n'},\n",
       "        {'param_name': 'upper',\n",
       "         'param_type': 'float or array-like, default None',\n",
       "         'param_desc': 'Maximum threshold value. All values above this\\nthreshold will be set to it. A missing\\nthreshold (e.g NA) will not clip the value.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{{0 or ‘index’, 1 or ‘columns’, None}}, default None',\n",
       "         'param_desc': 'Align object with lower and upper along the given axis.\\nFor Series this parameter is unused and defaults to None.\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to perform the operation in place on the data.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.clip',\n",
       "       'descriptions': 'Trim values at input threshold(s). Assigns values outside boundary to boundary values. Thresholds\\ncan be singular values or array like, and in the latter case\\nthe clipping is performed element-wise in the specified axis.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'lower': {'type': 'float',\n",
       "          'description': 'float or array-like, default None. Minimum threshold value. All values below this\\nthreshold will be set to it. A missing\\nthreshold (e.g NA) will not clip the value.\\n'},\n",
       "         'upper': {'type': 'float',\n",
       "          'description': 'float or array-like, default None. Maximum threshold value. All values above this\\nthreshold will be set to it. A missing\\nthreshold (e.g NA) will not clip the value.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['{0 or index', ' 1 or columns', ' None'],\n",
       "          'description': '{{0 or ‘index’, 1 or ‘columns’, None}}, default None. Align object with lower and upper along the given axis.\\nFor Series this parameter is unused and defaults to None.\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to perform the operation in place on the data.\\n'}},\n",
       "        'required': ['lower=None', 'upper=None']}}},\n",
       "     {'func_name': 'Series.count()',\n",
       "      'func_desc': 'Return number of non-NA/null observations in the Series.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.count.html#pandas.Series.count',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.count',\n",
       "       'full_function': 'Series.count()',\n",
       "       'function_text': 'Return number of non-NA/null observations in the Series.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.cummax([axis,\\xa0skipna])',\n",
       "      'func_desc': 'Return cumulative maximum over a DataFrame or Series axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.cummax.html#pandas.Series.cummax',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.cummax',\n",
       "       'full_function': 'Series.cummax(axis=None, skipna=True, *args, **kwargs)',\n",
       "       'function_text': 'Return cumulative maximum over a DataFrame or Series axis. Returns a DataFrame or Series of the same size containing the cumulative\\nmaximum.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'The index or the name of the axis. 0 is equivalent to None or ‘index’.\\nFor Series this parameter is unused and defaults to 0.\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.cummax',\n",
       "       'descriptions': 'Return cumulative maximum over a DataFrame or Series axis. Returns a DataFrame or Series of the same size containing the cumulative\\nmaximum.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. The index or the name of the axis. 0 is equivalent to None or ‘index’.\\nFor Series this parameter is unused and defaults to 0.\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.cumprod([axis,\\xa0skipna])',\n",
       "      'func_desc': 'Return cumulative product over a DataFrame or Series axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.cumprod.html#pandas.Series.cumprod',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.cumprod',\n",
       "       'full_function': 'Series.cumprod(axis=None, skipna=True, *args, **kwargs)',\n",
       "       'function_text': 'Return cumulative product over a DataFrame or Series axis. Returns a DataFrame or Series of the same size containing the cumulative\\nproduct.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'The index or the name of the axis. 0 is equivalent to None or ‘index’.\\nFor Series this parameter is unused and defaults to 0.\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.cumprod',\n",
       "       'descriptions': 'Return cumulative product over a DataFrame or Series axis. Returns a DataFrame or Series of the same size containing the cumulative\\nproduct.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. The index or the name of the axis. 0 is equivalent to None or ‘index’.\\nFor Series this parameter is unused and defaults to 0.\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.describe([percentiles,\\xa0include,\\xa0exclude])',\n",
       "      'func_desc': 'Generate descriptive statistics.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.describe.html#pandas.Series.describe',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.describe',\n",
       "       'full_function': 'Series.describe(percentiles=None, include=None, exclude=None)',\n",
       "       'function_text': 'Generate descriptive statistics. Descriptive statistics include those that summarize the central\\ntendency, dispersion and shape of a\\ndataset’s distribution, excluding NaN values. Analyzes both numeric and object series, as well\\nas DataFrame column sets of mixed data types. The output\\nwill vary depending on what is provided. Refer to the notes\\nbelow for more detail.',\n",
       "       'parameter_names_desc': [{'param_name': 'percentiles',\n",
       "         'param_type': 'list-like of numbers, optional',\n",
       "         'param_desc': 'The percentiles to include in the output. All should\\nfall between 0 and 1. The default is\\n[.25, .5, .75], which returns the 25th, 50th, and\\n75th percentiles.\\n'},\n",
       "        {'param_name': 'include',\n",
       "         'param_type': '‘all’, list-like of dtypes or None (default), optional',\n",
       "         'param_desc': \"A white list of data types to include in the result. Ignored\\nfor Series. Here are the options:\\n\\n‘all’ : All columns of the input will be included in the output.\\nA list-like of dtypes : Limits the results to the\\nprovided data types.\\nTo limit the result to numeric types submit\\nnumpy.number. To limit it instead to object columns submit\\nthe numpy.object data type. Strings\\ncan also be used in the style of\\nselect_dtypes (e.g. df.describe(include=['O'])). To\\nselect pandas categorical columns, use 'category'\\nNone (default) : The result will include all numeric columns.\\n\\n\"},\n",
       "        {'param_name': 'exclude',\n",
       "         'param_type': 'list-like of dtypes or None (default), optional,',\n",
       "         'param_desc': \"A black list of data types to omit from the result. Ignored\\nfor Series. Here are the options:\\n\\nA list-like of dtypes : Excludes the provided data types\\nfrom the result. To exclude numeric types submit\\nnumpy.number. To exclude object columns submit the data\\ntype numpy.object. Strings can also be used in the style of\\nselect_dtypes (e.g. df.describe(exclude=['O'])). To\\nexclude pandas categorical columns, use 'category'\\nNone (default) : The result will exclude nothing.\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.Series.describe',\n",
       "       'descriptions': 'Generate descriptive statistics. Descriptive statistics include those that summarize the central\\ntendency, dispersion and shape of a\\ndataset’s distribution, excluding NaN values. Analyzes both numeric and object series, as well\\nas DataFrame column sets of mixed data types. The output\\nwill vary depending on what is provided. Refer to the notes\\nbelow for more detail.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'percentiles': {'type': 'array',\n",
       "          'description': 'list-like of numbers, optional. The percentiles to include in the output. All should\\nfall between 0 and 1. The default is\\n[.25, .5, .75], which returns the 25th, 50th, and\\n75th percentiles.\\n'},\n",
       "         'include': {'type': 'array',\n",
       "          'description': \"‘all’, list-like of dtypes or None (default), optional. A white list of data types to include in the result. Ignored\\nfor Series. Here are the options:\\n\\n‘all’ : All columns of the input will be included in the output.\\nA list-like of dtypes : Limits the results to the\\nprovided data types.\\nTo limit the result to numeric types submit\\nnumpy.number. To limit it instead to object columns submit\\nthe numpy.object data type. Strings\\ncan also be used in the style of\\nselect_dtypes (e.g. df.describe(include=['O'])). To\\nselect pandas categorical columns, use 'category'\\nNone (default) : The result will include all numeric columns.\\n\\n\"},\n",
       "         'exclude': {'type': 'array',\n",
       "          'description': \"list-like of dtypes or None (default), optional,. A black list of data types to omit from the result. Ignored\\nfor Series. Here are the options:\\n\\nA list-like of dtypes : Excludes the provided data types\\nfrom the result. To exclude numeric types submit\\nnumpy.number. To exclude object columns submit the data\\ntype numpy.object. Strings can also be used in the style of\\nselect_dtypes (e.g. df.describe(exclude=['O'])). To\\nexclude pandas categorical columns, use 'category'\\nNone (default) : The result will exclude nothing.\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.factorize([sort,\\xa0use_na_sentinel])',\n",
       "      'func_desc': 'Encode the object as an enumerated type or categorical variable.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.factorize.html#pandas.Series.factorize',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.factorize',\n",
       "       'full_function': 'Series.factorize(sort=False, use_na_sentinel=True)',\n",
       "       'function_text': 'Encode the object as an enumerated type or categorical variable. This method is useful for obtaining a numeric representation of an\\narray when all that matters is identifying distinct values. factorize\\nis available as both a top-level function pandas.factorize(),\\nand as a method Series.factorize() and Index.factorize().',\n",
       "       'parameter_names_desc': [{'param_name': 'sort',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Sort uniques and shuffle codes to maintain the\\nrelationship.\\n'},\n",
       "        {'param_name': 'use_na_sentinel',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If True, the sentinel -1 will be used for NaN values. If False,\\nNaN values will be encoded as non-negative integers and will not drop the\\nNaN from the uniques of the values.\\n\\nNew in version 1.5.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.factorize',\n",
       "       'descriptions': 'Encode the object as an enumerated type or categorical variable. This method is useful for obtaining a numeric representation of an\\narray when all that matters is identifying distinct values. factorize\\nis available as both a top-level function pandas.factorize(),\\nand as a method Series.factorize() and Index.factorize().',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'sort': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Sort uniques and shuffle codes to maintain the\\nrelationship.\\n'},\n",
       "         'use_na_sentinel': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If True, the sentinel -1 will be used for NaN values. If False,\\nNaN values will be encoded as non-negative integers and will not drop the\\nNaN from the uniques of the values.\\n\\nNew in version 1.5.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.max([axis,\\xa0skipna,\\xa0numeric_only])',\n",
       "      'func_desc': 'Return the maximum of the values over the requested axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.max.html#pandas.Series.max',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.max',\n",
       "       'full_function': 'Series.max(axis=0, skipna=True, numeric_only=False, **kwargs)',\n",
       "       'function_text': 'Return the maximum of the values over the requested axis. If you want the index of the maximum, use idxmax. This is the equivalent of the numpy.ndarray method argmax.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{index (0)}',\n",
       "         'param_desc': 'Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\nFor DataFrames, specifying axis=None will apply the aggregation\\nacross both axes.\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values when computing the result.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns. Not implemented for Series.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.max',\n",
       "       'descriptions': 'Return the maximum of the values over the requested axis. If you want the index of the maximum, use idxmax. This is the equivalent of the numpy.ndarray method argmax.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': '{index (0)}',\n",
       "          'description': '{index (0)}. Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\nFor DataFrames, specifying axis=None will apply the aggregation\\nacross both axes.\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values when computing the result.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns. Not implemented for Series.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.median([axis,\\xa0skipna,\\xa0numeric_only])',\n",
       "      'func_desc': 'Return the median of the values over the requested axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.median.html#pandas.Series.median',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.median',\n",
       "       'full_function': 'Series.median(axis=0, skipna=True, numeric_only=False, **kwargs)',\n",
       "       'function_text': 'Return the median of the values over the requested axis.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{index (0)}',\n",
       "         'param_desc': 'Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\nFor DataFrames, specifying axis=None will apply the aggregation\\nacross both axes.\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values when computing the result.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns. Not implemented for Series.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.median',\n",
       "       'descriptions': 'Return the median of the values over the requested axis.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': '{index (0)}',\n",
       "          'description': '{index (0)}. Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\nFor DataFrames, specifying axis=None will apply the aggregation\\nacross both axes.\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values when computing the result.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns. Not implemented for Series.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.mode([dropna])',\n",
       "      'func_desc': 'Return the mode(s) of the Series.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.mode.html#pandas.Series.mode',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.mode',\n",
       "       'full_function': 'Series.mode(dropna=True)',\n",
       "       'function_text': 'Return the mode(s) of the Series. The mode is the value that appears most often. There can be multiple modes. Always returns Series even if only one value is returned.',\n",
       "       'parameter_names_desc': [{'param_name': 'dropna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Don’t consider counts of NaN/NaT.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.mode',\n",
       "       'descriptions': 'Return the mode(s) of the Series. The mode is the value that appears most often. There can be multiple modes. Always returns Series even if only one value is returned.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dropna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Don’t consider counts of NaN/NaT.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.nsmallest([n,\\xa0keep])',\n",
       "      'func_desc': 'Return the smallest n elements.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.nsmallest.html#pandas.Series.nsmallest',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.nsmallest',\n",
       "       'full_function': \"Series.nsmallest(n=5, keep='first')\",\n",
       "       'function_text': 'Return the smallest n elements.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 5',\n",
       "         'param_desc': 'Return this many ascending sorted values.\\n'},\n",
       "        {'param_name': 'keep',\n",
       "         'param_type': '{‘first’, ‘last’, ‘all’}, default ‘first’',\n",
       "         'param_desc': 'When there are duplicate values that cannot all fit in a\\nSeries of n elements:\\n\\nfirst : return the first n occurrences in order\\nof appearance.\\nlast : return the last n occurrences in reverse\\norder of appearance.\\nall : keep all occurrences. This can result in a Series of\\nsize larger than n.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.nsmallest',\n",
       "       'descriptions': 'Return the smallest n elements.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 5. Return this many ascending sorted values.\\n'},\n",
       "         'keep': {'type': 'string',\n",
       "          'enum': ['first', ' last', ' all'],\n",
       "          'description': '{‘first’, ‘last’, ‘all’}, default ‘first’. When there are duplicate values that cannot all fit in a\\nSeries of n elements:\\n\\nfirst : return the first n occurrences in order\\nof appearance.\\nlast : return the last n occurrences in reverse\\norder of appearance.\\nall : keep all occurrences. This can result in a Series of\\nsize larger than n.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.prod([axis,\\xa0skipna,\\xa0numeric_only,\\xa0...])',\n",
       "      'func_desc': 'Return the product of the values over the requested axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.prod.html#pandas.Series.prod',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.prod',\n",
       "       'full_function': 'Series.prod(axis=None, skipna=True, numeric_only=False, min_count=0, **kwargs)',\n",
       "       'function_text': 'Return the product of the values over the requested axis.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{index (0)}',\n",
       "         'param_desc': 'Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\n\\nWarning\\nThe behavior of DataFrame.prod with axis=None is deprecated,\\nin a future version this will reduce over both axes and return a scalar\\nTo retain the old behavior, pass axis=0 (or do not pass axis).\\n\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values when computing the result.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns. Not implemented for Series.\\n'},\n",
       "        {'param_name': 'min_count',\n",
       "         'param_type': 'int, default 0',\n",
       "         'param_desc': 'The required number of valid values to perform the operation. If fewer than\\nmin_count non-NA values are present the result will be NA.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.prod',\n",
       "       'descriptions': 'Return the product of the values over the requested axis.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': '{index (0)}',\n",
       "          'description': '{index (0)}. Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\n\\nWarning\\nThe behavior of DataFrame.prod with axis=None is deprecated,\\nin a future version this will reduce over both axes and return a scalar\\nTo retain the old behavior, pass axis=0 (or do not pass axis).\\n\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values when computing the result.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns. Not implemented for Series.\\n'},\n",
       "         'min_count': {'type': 'integer',\n",
       "          'description': 'int, default 0. The required number of valid values to perform the operation. If fewer than\\nmin_count non-NA values are present the result will be NA.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.rank([axis,\\xa0method,\\xa0numeric_only,\\xa0...])',\n",
       "      'func_desc': 'Compute numerical data ranks (1 through n) along axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.rank.html#pandas.Series.rank',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.rank',\n",
       "       'full_function': \"Series.rank(axis=0, method='average', numeric_only=False, na_option='keep', ascending=True, pct=False)\",\n",
       "       'function_text': 'Compute numerical data ranks (1 through n) along axis. By default, equal values are assigned a rank that is the average of the\\nranks of those values.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'Index to direct ranking.\\nFor Series this parameter is unused and defaults to 0.\\n'},\n",
       "        {'param_name': 'method',\n",
       "         'param_type': '{‘average’, ‘min’, ‘max’, ‘first’, ‘dense’}, default ‘average’',\n",
       "         'param_desc': 'How to rank the group of records that have the same value (i.e. ties):\\n\\naverage: average rank of the group\\nmin: lowest rank in the group\\nmax: highest rank in the group\\nfirst: ranks assigned in order they appear in the array\\ndense: like ‘min’, but rank always increases by 1 between groups.\\n\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'For DataFrame objects, rank only numeric columns if set to True.\\n\\nChanged in version 2.0.0: The default value of numeric_only is now False.\\n\\n'},\n",
       "        {'param_name': 'na_option',\n",
       "         'param_type': '{‘keep’, ‘top’, ‘bottom’}, default ‘keep’',\n",
       "         'param_desc': 'How to rank NaN values:\\n\\nkeep: assign NaN rank to NaN values\\ntop: assign lowest rank to NaN values\\nbottom: assign highest rank to NaN values\\n\\n'},\n",
       "        {'param_name': 'ascending',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether or not the elements should be ranked in ascending order.\\n'},\n",
       "        {'param_name': 'pct',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether or not to display the returned rankings in percentile\\nform.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.rank',\n",
       "       'descriptions': 'Compute numerical data ranks (1 through n) along axis. By default, equal values are assigned a rank that is the average of the\\nranks of those values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. Index to direct ranking.\\nFor Series this parameter is unused and defaults to 0.\\n'},\n",
       "         'method': {'type': 'string',\n",
       "          'enum': ['average', ' min', ' max', ' first', ' dense'],\n",
       "          'description': '{‘average’, ‘min’, ‘max’, ‘first’, ‘dense’}, default ‘average’. How to rank the group of records that have the same value (i.e. ties):\\n\\naverage: average rank of the group\\nmin: lowest rank in the group\\nmax: highest rank in the group\\nfirst: ranks assigned in order they appear in the array\\ndense: like ‘min’, but rank always increases by 1 between groups.\\n\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. For DataFrame objects, rank only numeric columns if set to True.\\n\\nChanged in version 2.0.0: The default value of numeric_only is now False.\\n\\n'},\n",
       "         'na_option': {'type': 'string',\n",
       "          'enum': ['keep', ' top', ' bottom'],\n",
       "          'description': '{‘keep’, ‘top’, ‘bottom’}, default ‘keep’. How to rank NaN values:\\n\\nkeep: assign NaN rank to NaN values\\ntop: assign lowest rank to NaN values\\nbottom: assign highest rank to NaN values\\n\\n'},\n",
       "         'ascending': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether or not the elements should be ranked in ascending order.\\n'},\n",
       "         'pct': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether or not to display the returned rankings in percentile\\nform.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.skew([axis,\\xa0skipna,\\xa0numeric_only])',\n",
       "      'func_desc': 'Return unbiased skew over requested axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.skew.html#pandas.Series.skew',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.skew',\n",
       "       'full_function': 'Series.skew(axis=0, skipna=True, numeric_only=False, **kwargs)',\n",
       "       'function_text': 'Return unbiased skew over requested axis. Normalized by N-1.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{index (0)}',\n",
       "         'param_desc': 'Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\nFor DataFrames, specifying axis=None will apply the aggregation\\nacross both axes.\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values when computing the result.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns. Not implemented for Series.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.skew',\n",
       "       'descriptions': 'Return unbiased skew over requested axis. Normalized by N-1.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': '{index (0)}',\n",
       "          'description': '{index (0)}. Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\nFor DataFrames, specifying axis=None will apply the aggregation\\nacross both axes.\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values when computing the result.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns. Not implemented for Series.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.sum([axis,\\xa0skipna,\\xa0numeric_only,\\xa0...])',\n",
       "      'func_desc': 'Return the sum of the values over the requested axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.sum.html#pandas.Series.sum',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.sum',\n",
       "       'full_function': 'Series.sum(axis=None, skipna=True, numeric_only=False, min_count=0, **kwargs)',\n",
       "       'function_text': 'Return the sum of the values over the requested axis. This is equivalent to the method numpy.sum.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{index (0)}',\n",
       "         'param_desc': 'Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\n\\nWarning\\nThe behavior of DataFrame.sum with axis=None is deprecated,\\nin a future version this will reduce over both axes and return a scalar\\nTo retain the old behavior, pass axis=0 (or do not pass axis).\\n\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values when computing the result.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns. Not implemented for Series.\\n'},\n",
       "        {'param_name': 'min_count',\n",
       "         'param_type': 'int, default 0',\n",
       "         'param_desc': 'The required number of valid values to perform the operation. If fewer than\\nmin_count non-NA values are present the result will be NA.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.sum',\n",
       "       'descriptions': 'Return the sum of the values over the requested axis. This is equivalent to the method numpy.sum.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': '{index (0)}',\n",
       "          'description': '{index (0)}. Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\n\\nWarning\\nThe behavior of DataFrame.sum with axis=None is deprecated,\\nin a future version this will reduce over both axes and return a scalar\\nTo retain the old behavior, pass axis=0 (or do not pass axis).\\n\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values when computing the result.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns. Not implemented for Series.\\n'},\n",
       "         'min_count': {'type': 'integer',\n",
       "          'description': 'int, default 0. The required number of valid values to perform the operation. If fewer than\\nmin_count non-NA values are present the result will be NA.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.kurtosis([axis,\\xa0skipna,\\xa0numeric_only])',\n",
       "      'func_desc': 'Return unbiased kurtosis over requested axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.kurtosis.html#pandas.Series.kurtosis',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.kurtosis',\n",
       "       'full_function': 'Series.kurtosis(axis=0, skipna=True, numeric_only=False, **kwargs)',\n",
       "       'function_text': 'Return unbiased kurtosis over requested axis. Kurtosis obtained using Fisher’s definition of\\nkurtosis (kurtosis of normal == 0.0). Normalized by N-1.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{index (0)}',\n",
       "         'param_desc': 'Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\nFor DataFrames, specifying axis=None will apply the aggregation\\nacross both axes.\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values when computing the result.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns. Not implemented for Series.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.kurtosis',\n",
       "       'descriptions': 'Return unbiased kurtosis over requested axis. Kurtosis obtained using Fisher’s definition of\\nkurtosis (kurtosis of normal == 0.0). Normalized by N-1.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': '{index (0)}',\n",
       "          'description': '{index (0)}. Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\nFor DataFrames, specifying axis=None will apply the aggregation\\nacross both axes.\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values when computing the result.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns. Not implemented for Series.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.nunique([dropna])',\n",
       "      'func_desc': 'Return number of unique elements in the object.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.nunique.html#pandas.Series.nunique',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.nunique',\n",
       "       'full_function': 'Series.nunique(dropna=True)',\n",
       "       'function_text': 'Return number of unique elements in the object. Excludes NA values by default.',\n",
       "       'parameter_names_desc': [{'param_name': 'dropna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Don’t include NaN in the count.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.nunique',\n",
       "       'descriptions': 'Return number of unique elements in the object. Excludes NA values by default.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dropna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Don’t include NaN in the count.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.is_monotonic_increasing',\n",
       "      'func_desc': 'Return boolean if values in the object are monotonically increasing.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.is_monotonic_increasing.html#pandas.Series.is_monotonic_increasing',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.is_monotonic_increasing',\n",
       "       'full_function': 'property Series.is_monotonic_increasing',\n",
       "       'function_text': 'Return boolean if values in the object are monotonically increasing.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.value_counts([normalize,\\xa0sort,\\xa0...])',\n",
       "      'func_desc': 'Return a Series containing counts of unique values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html#pandas.Series.value_counts',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.value_counts',\n",
       "       'full_function': 'Series.value_counts(normalize=False, sort=True, ascending=False, bins=None, dropna=True)',\n",
       "       'function_text': 'Return a Series containing counts of unique values. The resulting object will be in descending order so that the\\nfirst element is the most frequently-occurring element.\\nExcludes NA values by default.',\n",
       "       'parameter_names_desc': [{'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True then the object returned will contain the relative\\nfrequencies of the unique values.\\n'},\n",
       "        {'param_name': 'sort',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Sort by frequencies when True. Preserve the order of the data when False.\\n'},\n",
       "        {'param_name': 'ascending',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Sort in ascending order.\\n'},\n",
       "        {'param_name': 'bins',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Rather than count values, group them into half-open bins,\\na convenience for pd.cut, only works with numeric data.\\n'},\n",
       "        {'param_name': 'dropna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Don’t include counts of NaN.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.value_counts',\n",
       "       'descriptions': 'Return a Series containing counts of unique values. The resulting object will be in descending order so that the\\nfirst element is the most frequently-occurring element.\\nExcludes NA values by default.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True then the object returned will contain the relative\\nfrequencies of the unique values.\\n'},\n",
       "         'sort': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Sort by frequencies when True. Preserve the order of the data when False.\\n'},\n",
       "         'ascending': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Sort in ascending order.\\n'},\n",
       "         'bins': {'type': 'integer',\n",
       "          'description': 'int, optional. Rather than count values, group them into half-open bins,\\na convenience for pd.cut, only works with numeric data.\\n'},\n",
       "         'dropna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Don’t include counts of NaN.\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Reindexing / selection / label manipulation': [{'func_name': 'Series.align(other[,\\xa0join,\\xa0axis,\\xa0level,\\xa0...])',\n",
       "      'func_desc': 'Align two objects on their axes with the specified join method.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.align.html#pandas.Series.align',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.align',\n",
       "       'full_function': \"Series.align(other, join='outer', axis=None, level=None, copy=None, fill_value=None, method=_NoDefault.no_default, limit=_NoDefault.no_default, fill_axis=_NoDefault.no_default, broadcast_axis=_NoDefault.no_default)\",\n",
       "       'function_text': 'Align two objects on their axes with the specified join method. Join method is specified for each axis Index.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'DataFrame or Series',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'join',\n",
       "         'param_type': '{‘outer’, ‘inner’, ‘left’, ‘right’}, default ‘outer’',\n",
       "         'param_desc': 'Type of alignment to be performed.\\n\\nleft: use only keys from left frame, preserve key order.\\nright: use only keys from right frame, preserve key order.\\nouter: use union of keys from both frames, sort keys lexicographically.\\ninner: use intersection of keys from both frames,\\npreserve the order of the left keys.\\n\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': 'allowed axis of the other object, default None',\n",
       "         'param_desc': 'Align on index (0), columns (1), or both (None).\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or level name, default None',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Always returns new objects. If copy=False and no reindexing is\\nrequired then original objects are returned.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'scalar, default np.nan',\n",
       "         'param_desc': 'Value to use for missing values. Defaults to NaN, but can be any\\n“compatible” value.\\n'},\n",
       "        {'param_name': 'method',\n",
       "         'param_type': '{‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}, default None',\n",
       "         'param_desc': 'Method to use for filling holes in reindexed Series:\\n\\npad / ffill: propagate last valid observation forward to next valid.\\nbackfill / bfill: use NEXT valid observation to fill gap.\\n\\n\\nDeprecated since version 2.1.\\n\\n'},\n",
       "        {'param_name': 'limit',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'If method is specified, this is the maximum number of consecutive\\nNaN values to forward/backward fill. In other words, if there is\\na gap with more than this number of consecutive NaNs, it will only\\nbe partially filled. If method is not specified, this is the\\nmaximum number of entries along the entire axis where NaNs will be\\nfilled. Must be greater than 0 if not None.\\n\\nDeprecated since version 2.1.\\n\\n'},\n",
       "        {'param_name': 'fill_axis',\n",
       "         'param_type': '{0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame, default 0',\n",
       "         'param_desc': 'Filling axis, method and limit.\\n\\nDeprecated since version 2.1.\\n\\n'},\n",
       "        {'param_name': 'broadcast_axis',\n",
       "         'param_type': '{0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame, default None',\n",
       "         'param_desc': 'Broadcast values along this axis, if aligning two objects of\\ndifferent dimensions.\\n\\nDeprecated since version 2.1.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.align',\n",
       "       'descriptions': 'Align two objects on their axes with the specified join method. Join method is specified for each axis Index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'DataFrame or Series',\n",
       "          'description': 'DataFrame or Series. '},\n",
       "         'join': {'type': 'string',\n",
       "          'enum': ['outer', ' inner', ' left', ' right'],\n",
       "          'description': '{‘outer’, ‘inner’, ‘left’, ‘right’}, default ‘outer’. Type of alignment to be performed.\\n\\nleft: use only keys from left frame, preserve key order.\\nright: use only keys from right frame, preserve key order.\\nouter: use union of keys from both frames, sort keys lexicographically.\\ninner: use intersection of keys from both frames,\\npreserve the order of the left keys.\\n\\n'},\n",
       "         'axis': {'type': 'object',\n",
       "          'description': 'allowed axis of the other object, default None. Align on index (0), columns (1), or both (None).\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or level name, default None. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Always returns new objects. If copy=False and no reindexing is\\nrequired then original objects are returned.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'},\n",
       "         'fill_value': {'type': 'scalar, default np.nan',\n",
       "          'description': 'scalar, default np.nan. Value to use for missing values. Defaults to NaN, but can be any\\n“compatible” value.\\n'},\n",
       "         'method': {'type': 'string',\n",
       "          'enum': ['backfill', ' bfill', ' pad', ' ffill', ' None'],\n",
       "          'description': '{‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}, default None. Method to use for filling holes in reindexed Series:\\n\\npad / ffill: propagate last valid observation forward to next valid.\\nbackfill / bfill: use NEXT valid observation to fill gap.\\n\\n\\nDeprecated since version 2.1.\\n\\n'},\n",
       "         'limit': {'type': 'integer',\n",
       "          'description': 'int, default None. If method is specified, this is the maximum number of consecutive\\nNaN values to forward/backward fill. In other words, if there is\\na gap with more than this number of consecutive NaNs, it will only\\nbe partially filled. If method is not specified, this is the\\nmaximum number of entries along the entire axis where NaNs will be\\nfilled. Must be greater than 0 if not None.\\n\\nDeprecated since version 2.1.\\n\\n'},\n",
       "         'fill_axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame, default 0. Filling axis, method and limit.\\n\\nDeprecated since version 2.1.\\n\\n'},\n",
       "         'broadcast_axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame, default None. Broadcast values along this axis, if aligning two objects of\\ndifferent dimensions.\\n\\nDeprecated since version 2.1.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.drop([labels,\\xa0axis,\\xa0index,\\xa0columns,\\xa0...])',\n",
       "      'func_desc': 'Return Series with specified index labels removed.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.drop.html#pandas.Series.drop',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.drop',\n",
       "       'full_function': \"Series.drop(labels=None, *, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')\",\n",
       "       'function_text': 'Return Series with specified index labels removed. Remove elements of a Series based on specifying the index labels.\\nWhen using a multi-index, labels on different levels can be removed\\nby specifying the level.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.drop_duplicates(*[,\\xa0keep,\\xa0inplace,\\xa0...])',\n",
       "      'func_desc': 'Return Series with duplicate values removed.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.drop_duplicates.html#pandas.Series.drop_duplicates',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.drop_duplicates',\n",
       "       'full_function': \"Series.drop_duplicates(*, keep='first', inplace=False, ignore_index=False)\",\n",
       "       'function_text': 'Return Series with duplicate values removed.',\n",
       "       'parameter_names_desc': [{'param_name': 'keep',\n",
       "         'param_type': '{‘first’, ‘last’, False}, default ‘first’',\n",
       "         'param_desc': 'Method to handle dropping duplicates:\\n\\n‘first’ : Drop duplicates except for the first occurrence.\\n‘last’ : Drop duplicates except for the last occurrence.\\nFalse : Drop all duplicates.\\n\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True, performs operation inplace and returns None.\\n'},\n",
       "        {'param_name': 'ignore_index',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True, the resulting axis will be labeled 0, 1, …, n - 1.\\n\\nNew in version 2.0.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.drop_duplicates',\n",
       "       'descriptions': 'Return Series with duplicate values removed.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'keep': {'type': 'string',\n",
       "          'enum': ['first', ' last', ' False'],\n",
       "          'description': '{‘first’, ‘last’, False}, default ‘first’. Method to handle dropping duplicates:\\n\\n‘first’ : Drop duplicates except for the first occurrence.\\n‘last’ : Drop duplicates except for the last occurrence.\\nFalse : Drop all duplicates.\\n\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True, performs operation inplace and returns None.\\n'},\n",
       "         'ignore_index': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True, the resulting axis will be labeled 0, 1, …, n - 1.\\n\\nNew in version 2.0.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.equals(other)',\n",
       "      'func_desc': 'Test whether two objects contain the same elements.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.equals.html#pandas.Series.equals',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.equals',\n",
       "       'full_function': 'Series.equals(other)',\n",
       "       'function_text': 'Test whether two objects contain the same elements. This function allows two Series or DataFrames to be compared against\\neach other to see if they have the same shape and elements. NaNs in\\nthe same location are considered equal. The row/column index do not need to have the same type, as long\\nas the values are considered equal. Corresponding columns and\\nindex must be of the same dtype.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series or DataFrame',\n",
       "         'param_desc': 'The other Series or DataFrame to be compared with the first.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.equals',\n",
       "       'descriptions': 'Test whether two objects contain the same elements. This function allows two Series or DataFrames to be compared against\\neach other to see if they have the same shape and elements. NaNs in\\nthe same location are considered equal. The row/column index do not need to have the same type, as long\\nas the values are considered equal. Corresponding columns and\\nindex must be of the same dtype.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series or DataFrame',\n",
       "          'description': 'Series or DataFrame. The other Series or DataFrame to be compared with the first.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.head([n])',\n",
       "      'func_desc': 'Return the first n rows.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.head.html#pandas.Series.head',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.head',\n",
       "       'full_function': 'Series.head(n=5)',\n",
       "       'function_text': 'Return the first n rows. This function returns the first n rows for the object based\\non position. It is useful for quickly testing if your object\\nhas the right type of data in it. For negative values of n, this function returns all rows except\\nthe last |n| rows, equivalent to df[:n]. If n is larger than the number of rows, this function returns all rows.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 5',\n",
       "         'param_desc': 'Number of rows to select.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.head',\n",
       "       'descriptions': 'Return the first n rows. This function returns the first n rows for the object based\\non position. It is useful for quickly testing if your object\\nhas the right type of data in it. For negative values of n, this function returns all rows except\\nthe last |n| rows, equivalent to df[:n]. If n is larger than the number of rows, this function returns all rows.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 5. Number of rows to select.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.idxmin([axis,\\xa0skipna])',\n",
       "      'func_desc': 'Return the row label of the minimum value.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.idxmin.html#pandas.Series.idxmin',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.idxmin',\n",
       "       'full_function': 'Series.idxmin(axis=0, skipna=True, *args, **kwargs)',\n",
       "       'function_text': 'Return the row label of the minimum value. If multiple values equal the minimum, the first row label with that\\nvalue is returned.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.last(offset)',\n",
       "      'func_desc': '(DEPRECATED) Select final periods of time series data based on a date offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.last.html#pandas.Series.last',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.last',\n",
       "       'full_function': 'Series.last(offset)',\n",
       "       'function_text': 'Select final periods of time series data based on a date offset. Deprecated since version 2.1: last() is deprecated and will be removed in a future version.\\nPlease create a mask and filter using .loc instead. For a DataFrame with a sorted DatetimeIndex, this function\\nselects the last few rows based on a date offset.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.reindex_like(other[,\\xa0method,\\xa0copy,\\xa0...])',\n",
       "      'func_desc': 'Return an object with matching indices as other object.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.reindex_like.html#pandas.Series.reindex_like',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.reindex_like',\n",
       "       'full_function': 'Series.reindex_like(other, method=None, copy=None, limit=None, tolerance=None)',\n",
       "       'function_text': 'Return an object with matching indices as other object. Conform the object to the same index on all axes. Optional\\nfilling logic, placing NaN in locations having no value\\nin the previous index. A new object is produced unless the\\nnew index is equivalent to the current one and copy=False.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Object of the same data type',\n",
       "         'param_desc': 'Its row and column indices are used to define the new indices\\nof this object.\\n'},\n",
       "        {'param_name': 'method',\n",
       "         'param_type': '{None, ‘backfill’/’bfill’, ‘pad’/’ffill’, ‘nearest’}',\n",
       "         'param_desc': 'Method to use for filling holes in reindexed DataFrame.\\nPlease note: this is only applicable to DataFrames/Series with a\\nmonotonically increasing/decreasing index.\\n\\nNone (default): don’t fill gaps\\npad / ffill: propagate last valid observation forward to next\\nvalid\\nbackfill / bfill: use next valid observation to fill gap\\nnearest: use nearest valid observations to fill gap.\\n\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Return a new object, even if the passed indexes are the same.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'},\n",
       "        {'param_name': 'limit',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'Maximum number of consecutive labels to fill for inexact matches.\\n'},\n",
       "        {'param_name': 'tolerance',\n",
       "         'param_type': 'optional',\n",
       "         'param_desc': 'Maximum distance between original and new labels for inexact\\nmatches. The values of the index at the matching locations must\\nsatisfy the equation abs(index[indexer] - target) <= tolerance.\\nTolerance may be a scalar value, which applies the same tolerance\\nto all values, or list-like, which applies variable tolerance per\\nelement. List-like includes list, tuple, array, Series, and must be\\nthe same size as the index and its dtype must exactly match the\\nindex’s type.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.reindex_like',\n",
       "       'descriptions': 'Return an object with matching indices as other object. Conform the object to the same index on all axes. Optional\\nfilling logic, placing NaN in locations having no value\\nin the previous index. A new object is produced unless the\\nnew index is equivalent to the current one and copy=False.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Object of the same data type',\n",
       "          'description': 'Object of the same data type. Its row and column indices are used to define the new indices\\nof this object.\\n'},\n",
       "         'method': {'type': 'string',\n",
       "          'enum': ['None', ' backfill/bfill', ' pad/ffill', ' nearest'],\n",
       "          'description': '{None, ‘backfill’/’bfill’, ‘pad’/’ffill’, ‘nearest’}. Method to use for filling holes in reindexed DataFrame.\\nPlease note: this is only applicable to DataFrames/Series with a\\nmonotonically increasing/decreasing index.\\n\\nNone (default): don’t fill gaps\\npad / ffill: propagate last valid observation forward to next\\nvalid\\nbackfill / bfill: use next valid observation to fill gap\\nnearest: use nearest valid observations to fill gap.\\n\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Return a new object, even if the passed indexes are the same.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'},\n",
       "         'limit': {'type': 'integer',\n",
       "          'description': 'int, default None. Maximum number of consecutive labels to fill for inexact matches.\\n'},\n",
       "         'tolerance': {'type': 'optional',\n",
       "          'description': 'optional. Maximum distance between original and new labels for inexact\\nmatches. The values of the index at the matching locations must\\nsatisfy the equation abs(index[indexer] - target) <= tolerance.\\nTolerance may be a scalar value, which applies the same tolerance\\nto all values, or list-like, which applies variable tolerance per\\nelement. List-like includes list, tuple, array, Series, and must be\\nthe same size as the index and its dtype must exactly match the\\nindex’s type.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.rename_axis([mapper,\\xa0index,\\xa0axis,\\xa0...])',\n",
       "      'func_desc': 'Set the name of the axis for the index or columns.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.rename_axis.html#pandas.Series.rename_axis',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.rename_axis',\n",
       "       'full_function': 'Series.rename_axis(mapper=_NoDefault.no_default, *, index=_NoDefault.no_default, axis=0, copy=True, inplace=False)',\n",
       "       'function_text': 'Set the name of the axis for the index or columns.',\n",
       "       'parameter_names_desc': [{'param_name': 'mapper',\n",
       "         'param_type': 'scalar, list-like, optional',\n",
       "         'param_desc': 'Value to set the axis name attribute.\\n'},\n",
       "        {'param_name': 'index, columns',\n",
       "         'param_type': 'scalar, list-like, dict-like or function, optional',\n",
       "         'param_desc': 'A scalar, list-like, dict-like or functions transformations to\\napply to that axis’ values.\\nNote that the columns parameter is not allowed if the\\nobject is a Series. This parameter only apply for DataFrame\\ntype objects.\\nUse either mapper and axis to\\nspecify the axis to target with mapper, or index\\nand/or columns.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'The axis to rename. For Series this parameter is unused and defaults to 0.\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default None',\n",
       "         'param_desc': 'Also copy underlying data.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Modifies the object directly, instead of creating a new Series\\nor DataFrame.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.rename_axis',\n",
       "       'descriptions': 'Set the name of the axis for the index or columns.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'mapper': {'type': 'array',\n",
       "          'description': 'scalar, list-like, optional. Value to set the axis name attribute.\\n'},\n",
       "         'index, columns': {'type': 'array',\n",
       "          'description': 'scalar, list-like, dict-like or function, optional. A scalar, list-like, dict-like or functions transformations to\\napply to that axis’ values.\\nNote that the columns parameter is not allowed if the\\nobject is a Series. This parameter only apply for DataFrame\\ntype objects.\\nUse either mapper and axis to\\nspecify the axis to target with mapper, or index\\nand/or columns.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. The axis to rename. For Series this parameter is unused and defaults to 0.\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default None. Also copy underlying data.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Modifies the object directly, instead of creating a new Series\\nor DataFrame.\\n'}},\n",
       "        'required': ['mapper=_NoDefault.no_default']}}},\n",
       "     {'func_name': 'Series.sample([n,\\xa0frac,\\xa0replace,\\xa0weights,\\xa0...])',\n",
       "      'func_desc': 'Return a random sample of items from an axis of object.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.sample.html#pandas.Series.sample',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.sample',\n",
       "       'full_function': 'Series.sample(n=None, frac=None, replace=False, weights=None, random_state=None, axis=None, ignore_index=False)',\n",
       "       'function_text': 'Return a random sample of items from an axis of object. You can use random_state for reproducibility.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Number of items from axis to return. Cannot be used with frac.\\nDefault = 1 if frac = None.\\n'},\n",
       "        {'param_name': 'frac',\n",
       "         'param_type': 'float, optional',\n",
       "         'param_desc': 'Fraction of axis items to return. Cannot be used with n.\\n'},\n",
       "        {'param_name': 'replace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Allow or disallow sampling of the same row more than once.\\n'},\n",
       "        {'param_name': 'weights',\n",
       "         'param_type': 'str or ndarray-like, optional',\n",
       "         'param_desc': 'Default ‘None’ results in equal probability weighting.\\nIf passed a Series, will align with target object on index. Index\\nvalues in weights not found in sampled object will be ignored and\\nindex values in sampled object not in weights will be assigned\\nweights of zero.\\nIf called on a DataFrame, will accept the name of a column\\nwhen axis = 0.\\nUnless weights are a Series, weights must be same length as axis\\nbeing sampled.\\nIf weights do not sum to 1, they will be normalized to sum to 1.\\nMissing values in the weights column will be treated as zero.\\nInfinite values not allowed.\\n'},\n",
       "        {'param_name': 'random_state',\n",
       "         'param_type': 'int, array-like, BitGenerator, np.random.RandomState, np.random.Generator, optional',\n",
       "         'param_desc': 'If int, array-like, or BitGenerator, seed for random number generator.\\nIf np.random.RandomState or np.random.Generator, use as given.\\n\\nChanged in version 1.4.0: np.random.Generator objects now accepted\\n\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’, None}, default None',\n",
       "         'param_desc': 'Axis to sample. Accepts axis number or name. Default is stat axis\\nfor given data type. For Series this parameter is unused and defaults to None.\\n'},\n",
       "        {'param_name': 'ignore_index',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True, the resulting index will be labeled 0, 1, …, n - 1.\\n\\nNew in version 1.3.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.sample',\n",
       "       'descriptions': 'Return a random sample of items from an axis of object. You can use random_state for reproducibility.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, optional. Number of items from axis to return. Cannot be used with frac.\\nDefault = 1 if frac = None.\\n'},\n",
       "         'frac': {'type': 'float',\n",
       "          'description': 'float, optional. Fraction of axis items to return. Cannot be used with n.\\n'},\n",
       "         'replace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Allow or disallow sampling of the same row more than once.\\n'},\n",
       "         'weights': {'type': 'string',\n",
       "          'description': 'str or ndarray-like, optional. Default ‘None’ results in equal probability weighting.\\nIf passed a Series, will align with target object on index. Index\\nvalues in weights not found in sampled object will be ignored and\\nindex values in sampled object not in weights will be assigned\\nweights of zero.\\nIf called on a DataFrame, will accept the name of a column\\nwhen axis = 0.\\nUnless weights are a Series, weights must be same length as axis\\nbeing sampled.\\nIf weights do not sum to 1, they will be normalized to sum to 1.\\nMissing values in the weights column will be treated as zero.\\nInfinite values not allowed.\\n'},\n",
       "         'random_state': {'type': 'integer',\n",
       "          'description': 'int, array-like, BitGenerator, np.random.RandomState, np.random.Generator, optional. If int, array-like, or BitGenerator, seed for random number generator.\\nIf np.random.RandomState or np.random.Generator, use as given.\\n\\nChanged in version 1.4.0: np.random.Generator objects now accepted\\n\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns', ' None'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’, None}, default None. Axis to sample. Accepts axis number or name. Default is stat axis\\nfor given data type. For Series this parameter is unused and defaults to None.\\n'},\n",
       "         'ignore_index': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True, the resulting index will be labeled 0, 1, …, n - 1.\\n\\nNew in version 1.3.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.take(indices[,\\xa0axis])',\n",
       "      'func_desc': 'Return the elements in the given positional indices along an axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.take.html#pandas.Series.take',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.take',\n",
       "       'full_function': 'Series.take(indices, axis=0, **kwargs)',\n",
       "       'function_text': 'Return the elements in the given positional indices along an axis. This means that we are not indexing according to actual values in\\nthe index attribute of the object. We are indexing according to the\\nactual position of the element in the object.',\n",
       "       'parameter_names_desc': [{'param_name': 'indices',\n",
       "         'param_type': 'array-like',\n",
       "         'param_desc': 'An array of ints indicating which positions to take.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’, None}, default 0',\n",
       "         'param_desc': 'The axis on which to select elements. 0 means that we are\\nselecting rows, 1 means that we are selecting columns.\\nFor Series this parameter is unused and defaults to 0.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.take',\n",
       "       'descriptions': 'Return the elements in the given positional indices along an axis. This means that we are not indexing according to actual values in\\nthe index attribute of the object. We are indexing according to the\\nactual position of the element in the object.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'indices': {'type': 'array',\n",
       "          'description': 'array-like. An array of ints indicating which positions to take.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns', ' None'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’, None}, default 0. The axis on which to select elements. 0 means that we are\\nselecting rows, 1 means that we are selecting columns.\\nFor Series this parameter is unused and defaults to 0.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.truncate([before,\\xa0after,\\xa0axis,\\xa0copy])',\n",
       "      'func_desc': 'Truncate a Series or DataFrame before and after some index value.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.truncate.html#pandas.Series.truncate',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.truncate',\n",
       "       'full_function': 'Series.truncate(before=None, after=None, axis=None, copy=None)',\n",
       "       'function_text': 'Truncate a Series or DataFrame before and after some index value. This is a useful shorthand for boolean indexing based on index\\nvalues above or below certain thresholds.',\n",
       "       'parameter_names_desc': [{'param_name': 'before',\n",
       "         'param_type': 'date, str, int',\n",
       "         'param_desc': 'Truncate all rows before this index value.\\n'},\n",
       "        {'param_name': 'after',\n",
       "         'param_type': 'date, str, int',\n",
       "         'param_desc': 'Truncate all rows after this index value.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, optional',\n",
       "         'param_desc': 'Axis to truncate. Truncates the index (rows) by default.\\nFor Series this parameter is unused and defaults to 0.\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default is True,',\n",
       "         'param_desc': 'Return a copy of the truncated section.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.truncate',\n",
       "       'descriptions': 'Truncate a Series or DataFrame before and after some index value. This is a useful shorthand for boolean indexing based on index\\nvalues above or below certain thresholds.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'before': {'type': 'integer',\n",
       "          'description': 'date, str, int. Truncate all rows before this index value.\\n'},\n",
       "         'after': {'type': 'integer',\n",
       "          'description': 'date, str, int. Truncate all rows after this index value.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, optional. Axis to truncate. Truncates the index (rows) by default.\\nFor Series this parameter is unused and defaults to 0.\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default is True,. Return a copy of the truncated section.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.mask(cond[,\\xa0other,\\xa0inplace,\\xa0axis,\\xa0level])',\n",
       "      'func_desc': 'Replace values where the condition is True.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.mask.html#pandas.Series.mask',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.mask',\n",
       "       'full_function': 'Series.mask(cond, other=_NoDefault.no_default, *, inplace=False, axis=None, level=None)',\n",
       "       'function_text': 'Replace values where the condition is True.',\n",
       "       'parameter_names_desc': [{'param_name': 'cond',\n",
       "         'param_type': 'bool Series/DataFrame, array-like, or callable',\n",
       "         'param_desc': 'Where cond is False, keep the original value. Where\\nTrue, replace with corresponding value from other.\\nIf cond is callable, it is computed on the Series/DataFrame and\\nshould return boolean Series/DataFrame or array. The callable must\\nnot change input Series/DataFrame (though pandas doesn’t check it).\\n'},\n",
       "        {'param_name': 'other',\n",
       "         'param_type': 'scalar, Series/DataFrame, or callable',\n",
       "         'param_desc': 'Entries where cond is True are replaced with\\ncorresponding value from other.\\nIf other is callable, it is computed on the Series/DataFrame and\\nshould return scalar or Series/DataFrame. The callable must not\\nchange input Series/DataFrame (though pandas doesn’t check it).\\nIf not specified, entries will be filled with the corresponding\\nNULL value (np.nan for numpy dtypes, pd.NA for extension\\ndtypes).\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to perform the operation in place on the data.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'Alignment axis if needed. For Series this parameter is\\nunused and defaults to 0.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'Alignment level if needed.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.mask',\n",
       "       'descriptions': 'Replace values where the condition is True.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'cond': {'type': 'boolean',\n",
       "          'description': 'bool Series/DataFrame, array-like, or callable. Where cond is False, keep the original value. Where\\nTrue, replace with corresponding value from other.\\nIf cond is callable, it is computed on the Series/DataFrame and\\nshould return boolean Series/DataFrame or array. The callable must\\nnot change input Series/DataFrame (though pandas doesn’t check it).\\n'},\n",
       "         'other': {'type': 'object',\n",
       "          'description': 'scalar, Series/DataFrame, or callable. Entries where cond is True are replaced with\\ncorresponding value from other.\\nIf other is callable, it is computed on the Series/DataFrame and\\nshould return scalar or Series/DataFrame. The callable must not\\nchange input Series/DataFrame (though pandas doesn’t check it).\\nIf not specified, entries will be filled with the corresponding\\nNULL value (np.nan for numpy dtypes, pd.NA for extension\\ndtypes).\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to perform the operation in place on the data.\\n'},\n",
       "         'axis': {'type': 'integer',\n",
       "          'description': 'int, default None. Alignment axis if needed. For Series this parameter is\\nunused and defaults to 0.\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int, default None. Alignment level if needed.\\n'}},\n",
       "        'required': ['cond', 'other=_NoDefault.no_default']}}},\n",
       "     {'func_name': 'Series.add_suffix(suffix[,\\xa0axis])',\n",
       "      'func_desc': 'Suffix labels with string suffix.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.add_suffix.html#pandas.Series.add_suffix',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.add_suffix',\n",
       "       'full_function': 'Series.add_suffix(suffix, axis=None)',\n",
       "       'function_text': 'Suffix labels with string suffix. For Series, the row labels are suffixed.\\nFor DataFrame, the column labels are suffixed.',\n",
       "       'parameter_names_desc': [{'param_name': 'suffix',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'The string to add after each label.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’, None}, default None',\n",
       "         'param_desc': 'Axis to add suffix on\\n\\nNew in version 2.0.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.add_suffix',\n",
       "       'descriptions': 'Suffix labels with string suffix. For Series, the row labels are suffixed.\\nFor DataFrame, the column labels are suffixed.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'suffix': {'type': 'string',\n",
       "          'description': 'str. The string to add after each label.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns', ' None'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’, None}, default None. Axis to add suffix on\\n\\nNew in version 2.0.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.case_when(caselist)',\n",
       "      'func_desc': 'Replace values where the conditions are True.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.case_when.html#pandas.Series.case_when',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.case_when',\n",
       "       'full_function': 'Series.case_when(caselist)',\n",
       "       'function_text': 'Replace values where the conditions are True.',\n",
       "       'parameter_names_desc': [{'param_name': 'caselist',\n",
       "         'param_type': 'A list of tuples of conditions and expected replacements',\n",
       "         'param_desc': 'Takes the form: (condition0, replacement0),\\n(condition1, replacement1), … .\\ncondition should be a 1-D boolean array-like object\\nor a callable. If condition is a callable,\\nit is computed on the Series\\nand should return a boolean Series or array.\\nThe callable must not change the input Series\\n(though pandas doesn`t check it). replacement should be a\\n1-D array-like object, a scalar or a callable.\\nIf replacement is a callable, it is computed on the Series\\nand should return a scalar or Series. The callable\\nmust not change the input Series\\n(though pandas doesn`t check it).\\n\\nNew in version 2.2.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.case_when',\n",
       "       'descriptions': 'Replace values where the conditions are True.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'caselist': {'type': 'array',\n",
       "          'description': 'A list of tuples of conditions and expected replacements. Takes the form: (condition0, replacement0),\\n(condition1, replacement1), … .\\ncondition should be a 1-D boolean array-like object\\nor a callable. If condition is a callable,\\nit is computed on the Series\\nand should return a boolean Series or array.\\nThe callable must not change the input Series\\n(though pandas doesn`t check it). replacement should be a\\n1-D array-like object, a scalar or a callable.\\nIf replacement is a callable, it is computed on the Series\\nand should return a scalar or Series. The callable\\nmust not change the input Series\\n(though pandas doesn`t check it).\\n\\nNew in version 2.2.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.droplevel(level[,\\xa0axis])',\n",
       "      'func_desc': 'Return Series/DataFrame with requested index / column level(s) removed.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.droplevel.html#pandas.Series.droplevel',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.droplevel',\n",
       "       'full_function': 'Series.droplevel(level, axis=0)',\n",
       "       'function_text': 'Return Series/DataFrame with requested index / column level(s) removed.',\n",
       "       'parameter_names_desc': [{'param_name': 'level',\n",
       "         'param_type': 'int, str, or list-like',\n",
       "         'param_desc': 'If a string is given, must be the name of a level\\nIf list-like, elements must be names or positional indexes\\nof levels.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'Axis along which the level(s) is removed:\\n\\n0 or ‘index’: remove level(s) in column.\\n1 or ‘columns’: remove level(s) in row.\\n\\nFor Series this parameter is unused and defaults to 0.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.droplevel',\n",
       "       'descriptions': 'Return Series/DataFrame with requested index / column level(s) removed.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'level': {'type': 'integer',\n",
       "          'description': 'int, str, or list-like. If a string is given, must be the name of a level\\nIf list-like, elements must be names or positional indexes\\nof levels.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. Axis along which the level(s) is removed:\\n\\n0 or ‘index’: remove level(s) in column.\\n1 or ‘columns’: remove level(s) in row.\\n\\nFor Series this parameter is unused and defaults to 0.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.duplicated([keep])',\n",
       "      'func_desc': 'Indicate duplicate Series values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.duplicated.html#pandas.Series.duplicated',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.duplicated',\n",
       "       'full_function': \"Series.duplicated(keep='first')\",\n",
       "       'function_text': 'Indicate duplicate Series values. Duplicated values are indicated as True values in the resulting\\nSeries. Either all duplicates, all except the first or all except the\\nlast occurrence of duplicates can be indicated.',\n",
       "       'parameter_names_desc': [{'param_name': 'keep',\n",
       "         'param_type': '{‘first’, ‘last’, False}, default ‘first’',\n",
       "         'param_desc': 'Method to handle dropping duplicates:\\n\\n‘first’ : Mark duplicates as True except for the first\\noccurrence.\\n‘last’ : Mark duplicates as True except for the last\\noccurrence.\\nFalse : Mark all duplicates as True.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.duplicated',\n",
       "       'descriptions': 'Indicate duplicate Series values. Duplicated values are indicated as True values in the resulting\\nSeries. Either all duplicates, all except the first or all except the\\nlast occurrence of duplicates can be indicated.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'keep': {'type': 'string',\n",
       "          'enum': ['first', ' last', ' False'],\n",
       "          'description': '{‘first’, ‘last’, False}, default ‘first’. Method to handle dropping duplicates:\\n\\n‘first’ : Mark duplicates as True except for the first\\noccurrence.\\n‘last’ : Mark duplicates as True except for the last\\noccurrence.\\nFalse : Mark all duplicates as True.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.first(offset)',\n",
       "      'func_desc': '(DEPRECATED) Select initial periods of time series data based on a date offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.first.html#pandas.Series.first',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.first',\n",
       "       'full_function': 'Series.first(offset)',\n",
       "       'function_text': 'Select initial periods of time series data based on a date offset. Deprecated since version 2.1: first() is deprecated and will be removed in a future version.\\nPlease create a mask and filter using .loc instead. For a DataFrame with a sorted DatetimeIndex, this function can\\nselect the first few rows based on a date offset.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.idxmax([axis,\\xa0skipna])',\n",
       "      'func_desc': 'Return the row label of the maximum value.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.idxmax.html#pandas.Series.idxmax',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.idxmax',\n",
       "       'full_function': 'Series.idxmax(axis=0, skipna=True, *args, **kwargs)',\n",
       "       'function_text': 'Return the row label of the maximum value. If multiple values equal the maximum, the first row label with that\\nvalue is returned.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.isin(values)',\n",
       "      'func_desc': 'Whether elements in Series are contained in values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.isin.html#pandas.Series.isin',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.isin',\n",
       "       'full_function': 'Series.isin(values)',\n",
       "       'function_text': 'Whether elements in Series are contained in values. Return a boolean Series showing whether each element in the Series\\nmatches an element in the passed sequence of values exactly.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.reindex([index,\\xa0axis,\\xa0method,\\xa0copy,\\xa0...])',\n",
       "      'func_desc': 'Conform Series to new index with optional filling logic.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.reindex.html#pandas.Series.reindex',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.reindex',\n",
       "       'full_function': 'Series.reindex(index=None, *, axis=None, method=None, copy=None, level=None, fill_value=None, limit=None, tolerance=None)',\n",
       "       'function_text': 'Conform Series to new index with optional filling logic. Places NA/NaN in locations having no value in the previous index. A new object\\nis produced unless the new index is equivalent to the current one and\\ncopy=False.',\n",
       "       'parameter_names_desc': [{'param_name': 'index',\n",
       "         'param_type': 'array-like, optional',\n",
       "         'param_desc': 'New labels for the index. Preferably an Index object to avoid\\nduplicating data.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': 'int or str, optional',\n",
       "         'param_desc': 'Unused.\\n'},\n",
       "        {'param_name': 'method',\n",
       "         'param_type': '{None, ‘backfill’/’bfill’, ‘pad’/’ffill’, ‘nearest’}',\n",
       "         'param_desc': 'Method to use for filling holes in reindexed DataFrame.\\nPlease note: this is only applicable to DataFrames/Series with a\\nmonotonically increasing/decreasing index.\\n\\nNone (default): don’t fill gaps\\npad / ffill: Propagate last valid observation forward to next\\nvalid.\\nbackfill / bfill: Use next valid observation to fill gap.\\nnearest: Use nearest valid observations to fill gap.\\n\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Return a new object, even if the passed indexes are the same.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or name',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'scalar, default np.nan',\n",
       "         'param_desc': 'Value to use for missing values. Defaults to NaN, but can be any\\n“compatible” value.\\n'},\n",
       "        {'param_name': 'limit',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'Maximum number of consecutive elements to forward or backward fill.\\n'},\n",
       "        {'param_name': 'tolerance',\n",
       "         'param_type': 'optional',\n",
       "         'param_desc': 'Maximum distance between original and new labels for inexact\\nmatches. The values of the index at the matching locations most\\nsatisfy the equation abs(index[indexer] - target) <= tolerance.\\nTolerance may be a scalar value, which applies the same tolerance\\nto all values, or list-like, which applies variable tolerance per\\nelement. List-like includes list, tuple, array, Series, and must be\\nthe same size as the index and its dtype must exactly match the\\nindex’s type.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.reindex',\n",
       "       'descriptions': 'Conform Series to new index with optional filling logic. Places NA/NaN in locations having no value in the previous index. A new object\\nis produced unless the new index is equivalent to the current one and\\ncopy=False.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'index': {'type': 'array',\n",
       "          'description': 'array-like, optional. New labels for the index. Preferably an Index object to avoid\\nduplicating data.\\n'},\n",
       "         'axis': {'type': 'integer',\n",
       "          'description': 'int or str, optional. Unused.\\n'},\n",
       "         'method': {'type': 'string',\n",
       "          'enum': ['None', ' backfill/bfill', ' pad/ffill', ' nearest'],\n",
       "          'description': '{None, ‘backfill’/’bfill’, ‘pad’/’ffill’, ‘nearest’}. Method to use for filling holes in reindexed DataFrame.\\nPlease note: this is only applicable to DataFrames/Series with a\\nmonotonically increasing/decreasing index.\\n\\nNone (default): don’t fill gaps\\npad / ffill: Propagate last valid observation forward to next\\nvalid.\\nbackfill / bfill: Use next valid observation to fill gap.\\nnearest: Use nearest valid observations to fill gap.\\n\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Return a new object, even if the passed indexes are the same.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or name. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'scalar, default np.nan',\n",
       "          'description': 'scalar, default np.nan. Value to use for missing values. Defaults to NaN, but can be any\\n“compatible” value.\\n'},\n",
       "         'limit': {'type': 'integer',\n",
       "          'description': 'int, default None. Maximum number of consecutive elements to forward or backward fill.\\n'},\n",
       "         'tolerance': {'type': 'optional',\n",
       "          'description': 'optional. Maximum distance between original and new labels for inexact\\nmatches. The values of the index at the matching locations most\\nsatisfy the equation abs(index[indexer] - target) <= tolerance.\\nTolerance may be a scalar value, which applies the same tolerance\\nto all values, or list-like, which applies variable tolerance per\\nelement. List-like includes list, tuple, array, Series, and must be\\nthe same size as the index and its dtype must exactly match the\\nindex’s type.\\n'}},\n",
       "        'required': ['index=None']}}},\n",
       "     {'func_name': 'Series.rename([index,\\xa0axis,\\xa0copy,\\xa0inplace,\\xa0...])',\n",
       "      'func_desc': 'Alter Series index labels or name.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.rename.html#pandas.Series.rename',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.rename',\n",
       "       'full_function': \"Series.rename(index=None, *, axis=None, copy=None, inplace=False, level=None, errors='ignore')\",\n",
       "       'function_text': 'Alter Series index labels or name. Function / dict values must be unique (1-to-1). Labels not contained in\\na dict / Series will be left as-is. Extra labels listed don’t throw an\\nerror. Alternatively, change Series.name with a scalar value. See the user guide for more.',\n",
       "       'parameter_names_desc': [{'param_name': 'index',\n",
       "         'param_type': 'scalar, hashable sequence, dict-like or function optional',\n",
       "         'param_desc': 'Functions or dict-like are transformations to apply to\\nthe index.\\nScalar or hashable sequence-like will alter the Series.name\\nattribute.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’}',\n",
       "         'param_desc': 'Unused. Parameter needed for compatibility with DataFrame.\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Also copy underlying data.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to return a new Series. If True the value of copy is ignored.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or level name, default None',\n",
       "         'param_desc': 'In case of MultiIndex, only rename labels in the specified level.\\n'},\n",
       "        {'param_name': 'errors',\n",
       "         'param_type': '{‘ignore’, ‘raise’}, default ‘ignore’',\n",
       "         'param_desc': 'If ‘raise’, raise KeyError when a dict-like mapper or\\nindex contains labels that are not present in the index being transformed.\\nIf ‘ignore’, existing keys will be renamed and extra keys will be ignored.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.rename',\n",
       "       'descriptions': 'Alter Series index labels or name. Function / dict values must be unique (1-to-1). Labels not contained in\\na dict / Series will be left as-is. Extra labels listed don’t throw an\\nerror. Alternatively, change Series.name with a scalar value. See the user guide for more.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'index': {'type': 'scalar, hashable sequence, dict-like or function optional',\n",
       "          'description': 'scalar, hashable sequence, dict-like or function optional. Functions or dict-like are transformations to apply to\\nthe index.\\nScalar or hashable sequence-like will alter the Series.name\\nattribute.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’}. Unused. Parameter needed for compatibility with DataFrame.\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Also copy underlying data.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to return a new Series. If True the value of copy is ignored.\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or level name, default None. In case of MultiIndex, only rename labels in the specified level.\\n'},\n",
       "         'errors': {'type': 'string',\n",
       "          'enum': ['ignore', ' raise'],\n",
       "          'description': '{‘ignore’, ‘raise’}, default ‘ignore’. If ‘raise’, raise KeyError when a dict-like mapper or\\nindex contains labels that are not present in the index being transformed.\\nIf ‘ignore’, existing keys will be renamed and extra keys will be ignored.\\n'}},\n",
       "        'required': ['index=None']}}},\n",
       "     {'func_name': 'Series.reset_index([level,\\xa0drop,\\xa0name,\\xa0...])',\n",
       "      'func_desc': 'Generate a new DataFrame or Series with the index reset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.reset_index.html#pandas.Series.reset_index',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.reset_index',\n",
       "       'full_function': 'Series.reset_index(level=None, *, drop=False, name=_NoDefault.no_default, inplace=False, allow_duplicates=False)',\n",
       "       'function_text': 'Generate a new DataFrame or Series with the index reset. This is useful when the index needs to be treated as a column, or\\nwhen the index is meaningless and needs to be reset to the default\\nbefore another operation.',\n",
       "       'parameter_names_desc': [{'param_name': 'level',\n",
       "         'param_type': 'int, str, tuple, or list, default optional',\n",
       "         'param_desc': 'For a Series with a MultiIndex, only remove the specified levels\\nfrom the index. Removes all levels by default.\\n'},\n",
       "        {'param_name': 'drop',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Just reset the index, without inserting it as a column in\\nthe new DataFrame.\\n'},\n",
       "        {'param_name': 'name',\n",
       "         'param_type': 'object, optional',\n",
       "         'param_desc': 'The name to use for the column containing the original Series\\nvalues. Uses self.name by default. This argument is ignored\\nwhen drop is True.\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Modify the Series in place (do not create a new object).\\n'},\n",
       "        {'param_name': 'allow_duplicates',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Allow duplicate column labels to be created.\\n\\nNew in version 1.5.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.reset_index',\n",
       "       'descriptions': 'Generate a new DataFrame or Series with the index reset. This is useful when the index needs to be treated as a column, or\\nwhen the index is meaningless and needs to be reset to the default\\nbefore another operation.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'level': {'type': 'integer',\n",
       "          'description': 'int, str, tuple, or list, default optional. For a Series with a MultiIndex, only remove the specified levels\\nfrom the index. Removes all levels by default.\\n'},\n",
       "         'drop': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Just reset the index, without inserting it as a column in\\nthe new DataFrame.\\n'},\n",
       "         'name': {'type': 'object',\n",
       "          'description': 'object, optional. The name to use for the column containing the original Series\\nvalues. Uses self.name by default. This argument is ignored\\nwhen drop is True.\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Modify the Series in place (do not create a new object).\\n'},\n",
       "         'allow_duplicates': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Allow duplicate column labels to be created.\\n\\nNew in version 1.5.0.\\n\\n'}},\n",
       "        'required': ['level=None']}}},\n",
       "     {'func_name': 'Series.set_axis(labels,\\xa0*[,\\xa0axis,\\xa0copy])',\n",
       "      'func_desc': 'Assign desired index to given axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.set_axis.html#pandas.Series.set_axis',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.set_axis',\n",
       "       'full_function': 'Series.set_axis(labels, *, axis=0, copy=None)',\n",
       "       'function_text': 'Assign desired index to given axis. Indexes for row labels can be changed by assigning\\na list-like or Index.',\n",
       "       'parameter_names_desc': [{'param_name': 'labels',\n",
       "         'param_type': 'list-like, Index',\n",
       "         'param_desc': 'The values for the new index.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’}, default 0',\n",
       "         'param_desc': 'The axis to update. The value 0 identifies the rows. For Series\\nthis parameter is unused and defaults to 0.\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to make a copy of the underlying data.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.set_axis',\n",
       "       'descriptions': 'Assign desired index to given axis. Indexes for row labels can be changed by assigning\\na list-like or Index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'labels': {'type': 'array',\n",
       "          'description': 'list-like, Index. The values for the new index.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’}, default 0. The axis to update. The value 0 identifies the rows. For Series\\nthis parameter is unused and defaults to 0.\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to make a copy of the underlying data.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'}},\n",
       "        'required': ['labels']}}},\n",
       "     {'func_name': 'Series.tail([n])',\n",
       "      'func_desc': 'Return the last n rows.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.tail.html#pandas.Series.tail',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.tail',\n",
       "       'full_function': 'Series.tail(n=5)',\n",
       "       'function_text': 'Return the last n rows. This function returns last n rows from the object based on\\nposition. It is useful for quickly verifying data, for example,\\nafter sorting or appending rows. For negative values of n, this function returns all rows except\\nthe first |n| rows, equivalent to df[|n|:]. If n is larger than the number of rows, this function returns all rows.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 5',\n",
       "         'param_desc': 'Number of rows to select.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.tail',\n",
       "       'descriptions': 'Return the last n rows. This function returns last n rows from the object based on\\nposition. It is useful for quickly verifying data, for example,\\nafter sorting or appending rows. For negative values of n, this function returns all rows except\\nthe first |n| rows, equivalent to df[|n|:]. If n is larger than the number of rows, this function returns all rows.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 5. Number of rows to select.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.where(cond[,\\xa0other,\\xa0inplace,\\xa0axis,\\xa0level])',\n",
       "      'func_desc': 'Replace values where the condition is False.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.where.html#pandas.Series.where',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.where',\n",
       "       'full_function': 'Series.where(cond, other=nan, *, inplace=False, axis=None, level=None)',\n",
       "       'function_text': 'Replace values where the condition is False.',\n",
       "       'parameter_names_desc': [{'param_name': 'cond',\n",
       "         'param_type': 'bool Series/DataFrame, array-like, or callable',\n",
       "         'param_desc': 'Where cond is True, keep the original value. Where\\nFalse, replace with corresponding value from other.\\nIf cond is callable, it is computed on the Series/DataFrame and\\nshould return boolean Series/DataFrame or array. The callable must\\nnot change input Series/DataFrame (though pandas doesn’t check it).\\n'},\n",
       "        {'param_name': 'other',\n",
       "         'param_type': 'scalar, Series/DataFrame, or callable',\n",
       "         'param_desc': 'Entries where cond is False are replaced with\\ncorresponding value from other.\\nIf other is callable, it is computed on the Series/DataFrame and\\nshould return scalar or Series/DataFrame. The callable must not\\nchange input Series/DataFrame (though pandas doesn’t check it).\\nIf not specified, entries will be filled with the corresponding\\nNULL value (np.nan for numpy dtypes, pd.NA for extension\\ndtypes).\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to perform the operation in place on the data.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'Alignment axis if needed. For Series this parameter is\\nunused and defaults to 0.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'Alignment level if needed.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.where',\n",
       "       'descriptions': 'Replace values where the condition is False.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'cond': {'type': 'boolean',\n",
       "          'description': 'bool Series/DataFrame, array-like, or callable. Where cond is True, keep the original value. Where\\nFalse, replace with corresponding value from other.\\nIf cond is callable, it is computed on the Series/DataFrame and\\nshould return boolean Series/DataFrame or array. The callable must\\nnot change input Series/DataFrame (though pandas doesn’t check it).\\n'},\n",
       "         'other': {'type': 'object',\n",
       "          'description': 'scalar, Series/DataFrame, or callable. Entries where cond is False are replaced with\\ncorresponding value from other.\\nIf other is callable, it is computed on the Series/DataFrame and\\nshould return scalar or Series/DataFrame. The callable must not\\nchange input Series/DataFrame (though pandas doesn’t check it).\\nIf not specified, entries will be filled with the corresponding\\nNULL value (np.nan for numpy dtypes, pd.NA for extension\\ndtypes).\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to perform the operation in place on the data.\\n'},\n",
       "         'axis': {'type': 'integer',\n",
       "          'description': 'int, default None. Alignment axis if needed. For Series this parameter is\\nunused and defaults to 0.\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int, default None. Alignment level if needed.\\n'}},\n",
       "        'required': ['cond', 'other=nan']}}},\n",
       "     {'func_name': 'Series.add_prefix(prefix[,\\xa0axis])',\n",
       "      'func_desc': 'Prefix labels with string prefix.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.add_prefix.html#pandas.Series.add_prefix',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.add_prefix',\n",
       "       'full_function': 'Series.add_prefix(prefix, axis=None)',\n",
       "       'function_text': 'Prefix labels with string prefix. For Series, the row labels are prefixed.\\nFor DataFrame, the column labels are prefixed.',\n",
       "       'parameter_names_desc': [{'param_name': 'prefix',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'The string to add before each label.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’, None}, default None',\n",
       "         'param_desc': 'Axis to add prefix on\\n\\nNew in version 2.0.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.add_prefix',\n",
       "       'descriptions': 'Prefix labels with string prefix. For Series, the row labels are prefixed.\\nFor DataFrame, the column labels are prefixed.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'prefix': {'type': 'string',\n",
       "          'description': 'str. The string to add before each label.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns', ' None'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’, None}, default None. Axis to add prefix on\\n\\nNew in version 2.0.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.filter([items,\\xa0like,\\xa0regex,\\xa0axis])',\n",
       "      'func_desc': 'Subset the dataframe rows or columns according to the specified index labels.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.filter.html#pandas.Series.filter',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.filter',\n",
       "       'full_function': 'Series.filter(items=None, like=None, regex=None, axis=None)',\n",
       "       'function_text': 'Subset the dataframe rows or columns according to the specified index labels. Note that this routine does not filter a dataframe on its\\ncontents. The filter is applied to the labels of the index.',\n",
       "       'parameter_names_desc': [{'param_name': 'items',\n",
       "         'param_type': 'list-like',\n",
       "         'param_desc': 'Keep labels from axis which are in items.\\n'},\n",
       "        {'param_name': 'like',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'Keep labels from axis for which “like in label == True”.\\n'},\n",
       "        {'param_name': 'regex',\n",
       "         'param_type': 'str (regular expression)',\n",
       "         'param_desc': 'Keep labels from axis for which re.search(regex, label) == True.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’, None}, default None',\n",
       "         'param_desc': 'The axis to filter on, expressed either as an index (int)\\nor axis name (str). By default this is the info axis, ‘columns’ for\\nDataFrame. For Series this parameter is unused and defaults to None.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.filter',\n",
       "       'descriptions': 'Subset the dataframe rows or columns according to the specified index labels. Note that this routine does not filter a dataframe on its\\ncontents. The filter is applied to the labels of the index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'items': {'type': 'array',\n",
       "          'description': 'list-like. Keep labels from axis which are in items.\\n'},\n",
       "         'like': {'type': 'string',\n",
       "          'description': 'str. Keep labels from axis for which “like in label == True”.\\n'},\n",
       "         'regex': {'type': 'string',\n",
       "          'description': 'str (regular expression). Keep labels from axis for which re.search(regex, label) == True.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns', ' None'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’, None}, default None. The axis to filter on, expressed either as an index (int)\\nor axis name (str). By default this is the info axis, ‘columns’ for\\nDataFrame. For Series this parameter is unused and defaults to None.\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Missing data handling': [{'func_name': 'Series.backfill(*[,\\xa0axis,\\xa0inplace,\\xa0limit,\\xa0...])',\n",
       "      'func_desc': '(DEPRECATED) Fill NA/NaN values by using the next valid observation to fill the gap.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.backfill.html#pandas.Series.backfill',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.backfill',\n",
       "       'full_function': 'Series.backfill(*, axis=None, inplace=False, limit=None, downcast=_NoDefault.no_default)',\n",
       "       'function_text': 'Fill NA/NaN values by using the next valid observation to fill the gap. Deprecated since version 2.0: Series/DataFrame.backfill is deprecated. Use Series/DataFrame.bfill instead.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.dropna(*[,\\xa0axis,\\xa0inplace,\\xa0how,\\xa0...])',\n",
       "      'func_desc': 'Return a new Series with missing values removed.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.dropna.html#pandas.Series.dropna',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.dropna',\n",
       "       'full_function': 'Series.dropna(*, axis=0, inplace=False, how=None, ignore_index=False)',\n",
       "       'function_text': 'Return a new Series with missing values removed. See the User Guide for more on which values are\\nconsidered missing, and how to work with missing data.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’}',\n",
       "         'param_desc': 'Unused. Parameter needed for compatibility with DataFrame.\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True, do operation inplace and return None.\\n'},\n",
       "        {'param_name': 'how',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Not in use. Kept for compatibility.\\n'},\n",
       "        {'param_name': 'ignore_index',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True, the resulting axis will be labeled 0, 1, …, n - 1.\\n\\nNew in version 2.0.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.dropna',\n",
       "       'descriptions': 'Return a new Series with missing values removed. See the User Guide for more on which values are\\nconsidered missing, and how to work with missing data.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’}. Unused. Parameter needed for compatibility with DataFrame.\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True, do operation inplace and return None.\\n'},\n",
       "         'how': {'type': 'string',\n",
       "          'description': 'str, optional. Not in use. Kept for compatibility.\\n'},\n",
       "         'ignore_index': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True, the resulting axis will be labeled 0, 1, …, n - 1.\\n\\nNew in version 2.0.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.fillna([value,\\xa0method,\\xa0axis,\\xa0...])',\n",
       "      'func_desc': 'Fill NA/NaN values using the specified method.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.fillna.html#pandas.Series.fillna',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.fillna',\n",
       "       'full_function': 'Series.fillna(value=None, *, method=None, axis=None, inplace=False, limit=None, downcast=_NoDefault.no_default)',\n",
       "       'function_text': 'Fill NA/NaN values using the specified method.',\n",
       "       'parameter_names_desc': [{'param_name': 'value',\n",
       "         'param_type': 'scalar, dict, Series, or DataFrame',\n",
       "         'param_desc': 'Value to use to fill holes (e.g. 0), alternately a\\ndict/Series/DataFrame of values specifying which value to use for\\neach index (for a Series) or column (for a DataFrame). Values not\\nin the dict/Series/DataFrame will not be filled. This value cannot\\nbe a list.\\n'},\n",
       "        {'param_name': 'method',\n",
       "         'param_type': '{‘backfill’, ‘bfill’, ‘ffill’, None}, default None',\n",
       "         'param_desc': 'Method to use for filling holes in reindexed Series:\\n\\nffill: propagate last valid observation forward to next valid.\\nbackfill / bfill: use next valid observation to fill gap.\\n\\n\\nDeprecated since version 2.1.0: Use ffill or bfill instead.\\n\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame',\n",
       "         'param_desc': 'Axis along which to fill missing values. For Series\\nthis parameter is unused and defaults to 0.\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True, fill in-place. Note: this will modify any\\nother views on this object (e.g., a no-copy slice for a column in a\\nDataFrame).\\n'},\n",
       "        {'param_name': 'limit',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'If method is specified, this is the maximum number of consecutive\\nNaN values to forward/backward fill. In other words, if there is\\na gap with more than this number of consecutive NaNs, it will only\\nbe partially filled. If method is not specified, this is the\\nmaximum number of entries along the entire axis where NaNs will be\\nfilled. Must be greater than 0 if not None.\\n'},\n",
       "        {'param_name': 'downcast',\n",
       "         'param_type': 'dict, default is None',\n",
       "         'param_desc': 'A dict of item->dtype of what to downcast if possible,\\nor the string ‘infer’ which will try to downcast to an appropriate\\nequal type (e.g. float64 to int64 if possible).\\n\\nDeprecated since version 2.2.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.fillna',\n",
       "       'descriptions': 'Fill NA/NaN values using the specified method.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'value': {'type': 'scalar, dict, Series, or DataFrame',\n",
       "          'description': 'scalar, dict, Series, or DataFrame. Value to use to fill holes (e.g. 0), alternately a\\ndict/Series/DataFrame of values specifying which value to use for\\neach index (for a Series) or column (for a DataFrame). Values not\\nin the dict/Series/DataFrame will not be filled. This value cannot\\nbe a list.\\n'},\n",
       "         'method': {'type': 'string',\n",
       "          'enum': ['backfill', ' bfill', ' ffill', ' None'],\n",
       "          'description': '{‘backfill’, ‘bfill’, ‘ffill’, None}, default None. Method to use for filling holes in reindexed Series:\\n\\nffill: propagate last valid observation forward to next valid.\\nbackfill / bfill: use next valid observation to fill gap.\\n\\n\\nDeprecated since version 2.1.0: Use ffill or bfill instead.\\n\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame. Axis along which to fill missing values. For Series\\nthis parameter is unused and defaults to 0.\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True, fill in-place. Note: this will modify any\\nother views on this object (e.g., a no-copy slice for a column in a\\nDataFrame).\\n'},\n",
       "         'limit': {'type': 'integer',\n",
       "          'description': 'int, default None. If method is specified, this is the maximum number of consecutive\\nNaN values to forward/backward fill. In other words, if there is\\na gap with more than this number of consecutive NaNs, it will only\\nbe partially filled. If method is not specified, this is the\\nmaximum number of entries along the entire axis where NaNs will be\\nfilled. Must be greater than 0 if not None.\\n'},\n",
       "         'downcast': {'type': 'dict, default is None',\n",
       "          'description': 'dict, default is None. A dict of item->dtype of what to downcast if possible,\\nor the string ‘infer’ which will try to downcast to an appropriate\\nequal type (e.g. float64 to int64 if possible).\\n\\nDeprecated since version 2.2.0.\\n\\n'}},\n",
       "        'required': ['value=None']}}},\n",
       "     {'func_name': 'Series.isna()',\n",
       "      'func_desc': 'Detect missing values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.isna.html#pandas.Series.isna',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.isna',\n",
       "       'full_function': 'Series.isna()',\n",
       "       'function_text': \"Detect missing values. Return a boolean same-sized object indicating if the values are NA.\\nNA values, such as None or numpy.NaN, gets mapped to True\\nvalues.\\nEverything else gets mapped to False values. Characters such as empty\\nstrings '' or numpy.inf are not considered NA values\\n(unless you set pandas.options.mode.use_inf_as_na = True).\",\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.notna()',\n",
       "      'func_desc': 'Detect existing (non-missing) values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.notna.html#pandas.Series.notna',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.notna',\n",
       "       'full_function': 'Series.notna()',\n",
       "       'function_text': \"Detect existing (non-missing) values. Return a boolean same-sized object indicating if the values are not NA.\\nNon-missing values get mapped to True. Characters such as empty\\nstrings '' or numpy.inf are not considered NA values\\n(unless you set pandas.options.mode.use_inf_as_na = True).\\nNA values, such as None or numpy.NaN, get mapped to False\\nvalues.\",\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.pad(*[,\\xa0axis,\\xa0inplace,\\xa0limit,\\xa0downcast])',\n",
       "      'func_desc': '(DEPRECATED) Fill NA/NaN values by propagating the last valid observation to next valid.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.pad.html#pandas.Series.pad',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.pad',\n",
       "       'full_function': 'Series.pad(*, axis=None, inplace=False, limit=None, downcast=_NoDefault.no_default)',\n",
       "       'function_text': 'Fill NA/NaN values by propagating the last valid observation to next valid. Deprecated since version 2.0: Series/DataFrame.pad is deprecated. Use Series/DataFrame.ffill instead.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.bfill(*[,\\xa0axis,\\xa0inplace,\\xa0limit,\\xa0...])',\n",
       "      'func_desc': 'Fill NA/NaN values by using the next valid observation to fill the gap.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.bfill.html#pandas.Series.bfill',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.bfill',\n",
       "       'full_function': 'Series.bfill(*, axis=None, inplace=False, limit=None, limit_area=None, downcast=_NoDefault.no_default)',\n",
       "       'function_text': 'Fill NA/NaN values by using the next valid observation to fill the gap.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame',\n",
       "         'param_desc': 'Axis along which to fill missing values. For Series\\nthis parameter is unused and defaults to 0.\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True, fill in-place. Note: this will modify any\\nother views on this object (e.g., a no-copy slice for a column in a\\nDataFrame).\\n'},\n",
       "        {'param_name': 'limit',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'If method is specified, this is the maximum number of consecutive\\nNaN values to forward/backward fill. In other words, if there is\\na gap with more than this number of consecutive NaNs, it will only\\nbe partially filled. If method is not specified, this is the\\nmaximum number of entries along the entire axis where NaNs will be\\nfilled. Must be greater than 0 if not None.\\n'},\n",
       "        {'param_name': 'limit_area',\n",
       "         'param_type': '{None, ‘inside’, ‘outside’}, default None',\n",
       "         'param_desc': 'If limit is specified, consecutive NaNs will be filled with this\\nrestriction.\\n\\nNone: No fill restriction.\\n‘inside’: Only fill NaNs surrounded by valid values\\n(interpolate).\\n‘outside’: Only fill NaNs outside valid values (extrapolate).\\n\\n\\nNew in version 2.2.0.\\n\\n'},\n",
       "        {'param_name': 'downcast',\n",
       "         'param_type': 'dict, default is None',\n",
       "         'param_desc': 'A dict of item->dtype of what to downcast if possible,\\nor the string ‘infer’ which will try to downcast to an appropriate\\nequal type (e.g. float64 to int64 if possible).\\n\\nDeprecated since version 2.2.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.bfill',\n",
       "       'descriptions': 'Fill NA/NaN values by using the next valid observation to fill the gap.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame. Axis along which to fill missing values. For Series\\nthis parameter is unused and defaults to 0.\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True, fill in-place. Note: this will modify any\\nother views on this object (e.g., a no-copy slice for a column in a\\nDataFrame).\\n'},\n",
       "         'limit': {'type': 'integer',\n",
       "          'description': 'int, default None. If method is specified, this is the maximum number of consecutive\\nNaN values to forward/backward fill. In other words, if there is\\na gap with more than this number of consecutive NaNs, it will only\\nbe partially filled. If method is not specified, this is the\\nmaximum number of entries along the entire axis where NaNs will be\\nfilled. Must be greater than 0 if not None.\\n'},\n",
       "         'limit_area': {'type': 'string',\n",
       "          'enum': ['None', ' inside', ' outside'],\n",
       "          'description': '{None, ‘inside’, ‘outside’}, default None. If limit is specified, consecutive NaNs will be filled with this\\nrestriction.\\n\\nNone: No fill restriction.\\n‘inside’: Only fill NaNs surrounded by valid values\\n(interpolate).\\n‘outside’: Only fill NaNs outside valid values (extrapolate).\\n\\n\\nNew in version 2.2.0.\\n\\n'},\n",
       "         'downcast': {'type': 'dict, default is None',\n",
       "          'description': 'dict, default is None. A dict of item->dtype of what to downcast if possible,\\nor the string ‘infer’ which will try to downcast to an appropriate\\nequal type (e.g. float64 to int64 if possible).\\n\\nDeprecated since version 2.2.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.ffill(*[,\\xa0axis,\\xa0inplace,\\xa0limit,\\xa0...])',\n",
       "      'func_desc': 'Fill NA/NaN values by propagating the last valid observation to next valid.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.ffill.html#pandas.Series.ffill',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.ffill',\n",
       "       'full_function': 'Series.ffill(*, axis=None, inplace=False, limit=None, limit_area=None, downcast=_NoDefault.no_default)',\n",
       "       'function_text': 'Fill NA/NaN values by propagating the last valid observation to next valid.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame',\n",
       "         'param_desc': 'Axis along which to fill missing values. For Series\\nthis parameter is unused and defaults to 0.\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True, fill in-place. Note: this will modify any\\nother views on this object (e.g., a no-copy slice for a column in a\\nDataFrame).\\n'},\n",
       "        {'param_name': 'limit',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'If method is specified, this is the maximum number of consecutive\\nNaN values to forward/backward fill. In other words, if there is\\na gap with more than this number of consecutive NaNs, it will only\\nbe partially filled. If method is not specified, this is the\\nmaximum number of entries along the entire axis where NaNs will be\\nfilled. Must be greater than 0 if not None.\\n'},\n",
       "        {'param_name': 'limit_area',\n",
       "         'param_type': '{None, ‘inside’, ‘outside’}, default None',\n",
       "         'param_desc': 'If limit is specified, consecutive NaNs will be filled with this\\nrestriction.\\n\\nNone: No fill restriction.\\n‘inside’: Only fill NaNs surrounded by valid values\\n(interpolate).\\n‘outside’: Only fill NaNs outside valid values (extrapolate).\\n\\n\\nNew in version 2.2.0.\\n\\n'},\n",
       "        {'param_name': 'downcast',\n",
       "         'param_type': 'dict, default is None',\n",
       "         'param_desc': 'A dict of item->dtype of what to downcast if possible,\\nor the string ‘infer’ which will try to downcast to an appropriate\\nequal type (e.g. float64 to int64 if possible).\\n\\nDeprecated since version 2.2.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.ffill',\n",
       "       'descriptions': 'Fill NA/NaN values by propagating the last valid observation to next valid.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame. Axis along which to fill missing values. For Series\\nthis parameter is unused and defaults to 0.\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True, fill in-place. Note: this will modify any\\nother views on this object (e.g., a no-copy slice for a column in a\\nDataFrame).\\n'},\n",
       "         'limit': {'type': 'integer',\n",
       "          'description': 'int, default None. If method is specified, this is the maximum number of consecutive\\nNaN values to forward/backward fill. In other words, if there is\\na gap with more than this number of consecutive NaNs, it will only\\nbe partially filled. If method is not specified, this is the\\nmaximum number of entries along the entire axis where NaNs will be\\nfilled. Must be greater than 0 if not None.\\n'},\n",
       "         'limit_area': {'type': 'string',\n",
       "          'enum': ['None', ' inside', ' outside'],\n",
       "          'description': '{None, ‘inside’, ‘outside’}, default None. If limit is specified, consecutive NaNs will be filled with this\\nrestriction.\\n\\nNone: No fill restriction.\\n‘inside’: Only fill NaNs surrounded by valid values\\n(interpolate).\\n‘outside’: Only fill NaNs outside valid values (extrapolate).\\n\\n\\nNew in version 2.2.0.\\n\\n'},\n",
       "         'downcast': {'type': 'dict, default is None',\n",
       "          'description': 'dict, default is None. A dict of item->dtype of what to downcast if possible,\\nor the string ‘infer’ which will try to downcast to an appropriate\\nequal type (e.g. float64 to int64 if possible).\\n\\nDeprecated since version 2.2.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.interpolate([method,\\xa0axis,\\xa0limit,\\xa0...])',\n",
       "      'func_desc': 'Fill NaN values using an interpolation method.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.interpolate.html#pandas.Series.interpolate',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.interpolate',\n",
       "       'full_function': \"Series.interpolate(method='linear', *, axis=0, limit=None, inplace=False, limit_direction=None, limit_area=None, downcast=_NoDefault.no_default, **kwargs)\",\n",
       "       'function_text': \"Fill NaN values using an interpolation method. Please note that only method='linear' is supported for\\nDataFrame/Series with a MultiIndex.\",\n",
       "       'parameter_names_desc': [{'param_name': 'method',\n",
       "         'param_type': 'str, default ‘linear’',\n",
       "         'param_desc': \"Interpolation technique to use. One of:\\n\\n‘linear’: Ignore the index and treat the values as equally\\nspaced. This is the only method supported on MultiIndexes.\\n‘time’: Works on daily and higher resolution data to interpolate\\ngiven length of interval.\\n‘index’, ‘values’: use the actual numerical values of the index.\\n‘pad’: Fill in NaNs using existing values.\\n‘nearest’, ‘zero’, ‘slinear’, ‘quadratic’, ‘cubic’,\\n‘barycentric’, ‘polynomial’: Passed to\\nscipy.interpolate.interp1d, whereas ‘spline’ is passed to\\nscipy.interpolate.UnivariateSpline. These methods use the numerical\\nvalues of the index. Both ‘polynomial’ and ‘spline’ require that\\nyou also specify an order (int), e.g.\\ndf.interpolate(method='polynomial', order=5). Note that,\\nslinear method in Pandas refers to the Scipy first order spline\\ninstead of Pandas first order spline.\\n‘krogh’, ‘piecewise_polynomial’, ‘spline’, ‘pchip’, ‘akima’,\\n‘cubicspline’: Wrappers around the SciPy interpolation methods of\\nsimilar names. See Notes.\\n‘from_derivatives’: Refers to\\nscipy.interpolate.BPoly.from_derivatives.\\n\\n\"},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{{0 or ‘index’, 1 or ‘columns’, None}}, default None',\n",
       "         'param_desc': 'Axis to interpolate along. For Series this parameter is unused\\nand defaults to 0.\\n'},\n",
       "        {'param_name': 'limit',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Maximum number of consecutive NaNs to fill. Must be greater than\\n0.\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Update the data in place if possible.\\n'},\n",
       "        {'param_name': 'limit_direction',\n",
       "         'param_type': '{{‘forward’, ‘backward’, ‘both’}}, Optional',\n",
       "         'param_desc': 'Consecutive NaNs will be filled in this direction.\\n\\nIf limit is specified:\\nIf ‘method’ is ‘pad’ or ‘ffill’, ‘limit_direction’ must be ‘forward’.\\nIf ‘method’ is ‘backfill’ or ‘bfill’, ‘limit_direction’ must be\\n‘backwards’.\\n\\n\\nIf ‘limit’ is not specified:\\nIf ‘method’ is ‘backfill’ or ‘bfill’, the default is ‘backward’\\nelse the default is ‘forward’\\n\\n\\nraises ValueError if limit_direction is ‘forward’ or ‘both’ andmethod is ‘backfill’ or ‘bfill’.\\n\\nraises ValueError if limit_direction is ‘backward’ or ‘both’ andmethod is ‘pad’ or ‘ffill’.\\n\\n\\n'},\n",
       "        {'param_name': 'limit_area',\n",
       "         'param_type': '{{None, ‘inside’, ‘outside’}}, default None',\n",
       "         'param_desc': 'If limit is specified, consecutive NaNs will be filled with this\\nrestriction.\\n\\nNone: No fill restriction.\\n‘inside’: Only fill NaNs surrounded by valid values\\n(interpolate).\\n‘outside’: Only fill NaNs outside valid values (extrapolate).\\n\\n'},\n",
       "        {'param_name': 'downcast',\n",
       "         'param_type': 'optional, ‘infer’ or None, defaults to None',\n",
       "         'param_desc': 'Downcast dtypes if possible.\\n\\nDeprecated since version 2.1.0.\\n\\n'},\n",
       "        {'param_name': '``**kwargs``',\n",
       "         'param_type': 'optional',\n",
       "         'param_desc': 'Keyword arguments to pass on to the interpolating function.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.interpolate',\n",
       "       'descriptions': \"Fill NaN values using an interpolation method. Please note that only method='linear' is supported for\\nDataFrame/Series with a MultiIndex.\",\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'method': {'type': 'string',\n",
       "          'description': \"str, default ‘linear’. Interpolation technique to use. One of:\\n\\n‘linear’: Ignore the index and treat the values as equally\\nspaced. This is the only method supported on MultiIndexes.\\n‘time’: Works on daily and higher resolution data to interpolate\\ngiven length of interval.\\n‘index’, ‘values’: use the actual numerical values of the index.\\n‘pad’: Fill in NaNs using existing values.\\n‘nearest’, ‘zero’, ‘slinear’, ‘quadratic’, ‘cubic’,\\n‘barycentric’, ‘polynomial’: Passed to\\nscipy.interpolate.interp1d, whereas ‘spline’ is passed to\\nscipy.interpolate.UnivariateSpline. These methods use the numerical\\nvalues of the index. Both ‘polynomial’ and ‘spline’ require that\\nyou also specify an order (int), e.g.\\ndf.interpolate(method='polynomial', order=5). Note that,\\nslinear method in Pandas refers to the Scipy first order spline\\ninstead of Pandas first order spline.\\n‘krogh’, ‘piecewise_polynomial’, ‘spline’, ‘pchip’, ‘akima’,\\n‘cubicspline’: Wrappers around the SciPy interpolation methods of\\nsimilar names. See Notes.\\n‘from_derivatives’: Refers to\\nscipy.interpolate.BPoly.from_derivatives.\\n\\n\"},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['{0 or index', ' 1 or columns', ' None'],\n",
       "          'description': '{{0 or ‘index’, 1 or ‘columns’, None}}, default None. Axis to interpolate along. For Series this parameter is unused\\nand defaults to 0.\\n'},\n",
       "         'limit': {'type': 'integer',\n",
       "          'description': 'int, optional. Maximum number of consecutive NaNs to fill. Must be greater than\\n0.\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Update the data in place if possible.\\n'},\n",
       "         'limit_direction': {'type': 'string',\n",
       "          'enum': ['{forward', ' backward', ' both'],\n",
       "          'description': '{{‘forward’, ‘backward’, ‘both’}}, Optional. Consecutive NaNs will be filled in this direction.\\n\\nIf limit is specified:\\nIf ‘method’ is ‘pad’ or ‘ffill’, ‘limit_direction’ must be ‘forward’.\\nIf ‘method’ is ‘backfill’ or ‘bfill’, ‘limit_direction’ must be\\n‘backwards’.\\n\\n\\nIf ‘limit’ is not specified:\\nIf ‘method’ is ‘backfill’ or ‘bfill’, the default is ‘backward’\\nelse the default is ‘forward’\\n\\n\\nraises ValueError if limit_direction is ‘forward’ or ‘both’ andmethod is ‘backfill’ or ‘bfill’.\\n\\nraises ValueError if limit_direction is ‘backward’ or ‘both’ andmethod is ‘pad’ or ‘ffill’.\\n\\n\\n'},\n",
       "         'limit_area': {'type': 'string',\n",
       "          'enum': ['{None', ' inside', ' outside'],\n",
       "          'description': '{{None, ‘inside’, ‘outside’}}, default None. If limit is specified, consecutive NaNs will be filled with this\\nrestriction.\\n\\nNone: No fill restriction.\\n‘inside’: Only fill NaNs surrounded by valid values\\n(interpolate).\\n‘outside’: Only fill NaNs outside valid values (extrapolate).\\n\\n'},\n",
       "         'downcast': {'type': 'optional, ‘infer’ or None, defaults to None',\n",
       "          'description': 'optional, ‘infer’ or None, defaults to None. Downcast dtypes if possible.\\n\\nDeprecated since version 2.1.0.\\n\\n'},\n",
       "         '``**kwargs``': {'type': 'optional',\n",
       "          'description': 'optional. Keyword arguments to pass on to the interpolating function.\\n'}},\n",
       "        'required': [\"method='linear'\"]}}},\n",
       "     {'func_name': 'Series.isnull()',\n",
       "      'func_desc': 'Series.isnull is an alias for Series.isna.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.isnull.html#pandas.Series.isnull',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.isnull',\n",
       "       'full_function': 'Series.isnull()',\n",
       "       'function_text': \"Series.isnull is an alias for Series.isna. Detect missing values. Return a boolean same-sized object indicating if the values are NA.\\nNA values, such as None or numpy.NaN, gets mapped to True\\nvalues.\\nEverything else gets mapped to False values. Characters such as empty\\nstrings '' or numpy.inf are not considered NA values\\n(unless you set pandas.options.mode.use_inf_as_na = True).\",\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.notnull()',\n",
       "      'func_desc': 'Series.notnull is an alias for Series.notna.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.notnull.html#pandas.Series.notnull',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.notnull',\n",
       "       'full_function': 'Series.notnull()',\n",
       "       'function_text': \"Series.notnull is an alias for Series.notna. Detect existing (non-missing) values. Return a boolean same-sized object indicating if the values are not NA.\\nNon-missing values get mapped to True. Characters such as empty\\nstrings '' or numpy.inf are not considered NA values\\n(unless you set pandas.options.mode.use_inf_as_na = True).\\nNA values, such as None or numpy.NaN, get mapped to False\\nvalues.\",\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.replace([to_replace,\\xa0value,\\xa0inplace,\\xa0...])',\n",
       "      'func_desc': 'Replace values given in to_replace with value.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.replace.html#pandas.Series.replace',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.replace',\n",
       "       'full_function': 'Series.replace(to_replace=None, value=_NoDefault.no_default, *, inplace=False, limit=None, regex=False, method=_NoDefault.no_default)',\n",
       "       'function_text': 'Replace values given in to_replace with value. Values of the Series/DataFrame are replaced with other values dynamically.\\nThis differs from updating with .loc or .iloc, which require\\nyou to specify a location to update with some value.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'Reshaping, sorting': [{'func_name': 'Series.argsort([axis,\\xa0kind,\\xa0order,\\xa0stable])',\n",
       "      'func_desc': 'Return the integer indices that would sort the Series values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.argsort.html#pandas.Series.argsort',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.argsort',\n",
       "       'full_function': \"Series.argsort(axis=0, kind='quicksort', order=None, stable=None)\",\n",
       "       'function_text': 'Return the integer indices that would sort the Series values. Override ndarray.argsort. Argsorts the value, omitting NA/null values,\\nand places the result in the same locations as the non-NA values.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’}',\n",
       "         'param_desc': 'Unused. Parameter needed for compatibility with DataFrame.\\n'},\n",
       "        {'param_name': 'kind',\n",
       "         'param_type': '{‘mergesort’, ‘quicksort’, ‘heapsort’, ‘stable’}, default ‘quicksort’',\n",
       "         'param_desc': 'Choice of sorting algorithm. See numpy.sort() for more\\ninformation. ‘mergesort’ and ‘stable’ are the only stable algorithms.\\n'},\n",
       "        {'param_name': 'order',\n",
       "         'param_type': 'None',\n",
       "         'param_desc': 'Has no effect but is accepted for compatibility with numpy.\\n'},\n",
       "        {'param_name': 'stable',\n",
       "         'param_type': 'None',\n",
       "         'param_desc': 'Has no effect but is accepted for compatibility with numpy.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.argsort',\n",
       "       'descriptions': 'Return the integer indices that would sort the Series values. Override ndarray.argsort. Argsorts the value, omitting NA/null values,\\nand places the result in the same locations as the non-NA values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’}. Unused. Parameter needed for compatibility with DataFrame.\\n'},\n",
       "         'kind': {'type': 'string',\n",
       "          'enum': ['mergesort', ' quicksort', ' heapsort', ' stable'],\n",
       "          'description': '{‘mergesort’, ‘quicksort’, ‘heapsort’, ‘stable’}, default ‘quicksort’. Choice of sorting algorithm. See numpy.sort() for more\\ninformation. ‘mergesort’ and ‘stable’ are the only stable algorithms.\\n'},\n",
       "         'order': {'type': 'None',\n",
       "          'description': 'None. Has no effect but is accepted for compatibility with numpy.\\n'},\n",
       "         'stable': {'type': 'None',\n",
       "          'description': 'None. Has no effect but is accepted for compatibility with numpy.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.argmax([axis,\\xa0skipna])',\n",
       "      'func_desc': 'Return int position of the largest value in the Series.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.argmax.html#pandas.Series.argmax',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.argmax',\n",
       "       'full_function': 'Series.argmax(axis=None, skipna=True, *args, **kwargs)',\n",
       "       'function_text': 'Return int position of the largest value in the Series. If the maximum is achieved in multiple locations,\\nthe first row position is returned.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{None}',\n",
       "         'param_desc': 'Unused. Parameter needed for compatibility with DataFrame.\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values when showing the result.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.argmax',\n",
       "       'descriptions': 'Return int position of the largest value in the Series. If the maximum is achieved in multiple locations,\\nthe first row position is returned.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': '{None}',\n",
       "          'description': '{None}. Unused. Parameter needed for compatibility with DataFrame.\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values when showing the result.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.sort_values(*[,\\xa0axis,\\xa0ascending,\\xa0...])',\n",
       "      'func_desc': 'Sort by the values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.sort_values.html#pandas.Series.sort_values',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.sort_values',\n",
       "       'full_function': \"Series.sort_values(*, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last', ignore_index=False, key=None)\",\n",
       "       'function_text': 'Sort by the values. Sort a Series in ascending or descending order by some\\ncriterion.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’}',\n",
       "         'param_desc': 'Unused. Parameter needed for compatibility with DataFrame.\\n'},\n",
       "        {'param_name': 'ascending',\n",
       "         'param_type': 'bool or list of bools, default True',\n",
       "         'param_desc': 'If True, sort values in ascending order, otherwise descending.\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True, perform operation in-place.\\n'},\n",
       "        {'param_name': 'kind',\n",
       "         'param_type': '{‘quicksort’, ‘mergesort’, ‘heapsort’, ‘stable’}, default ‘quicksort’',\n",
       "         'param_desc': 'Choice of sorting algorithm. See also numpy.sort() for more\\ninformation. ‘mergesort’ and ‘stable’ are the only stable algorithms.\\n'},\n",
       "        {'param_name': 'na_position',\n",
       "         'param_type': '{‘first’ or ‘last’}, default ‘last’',\n",
       "         'param_desc': 'Argument ‘first’ puts NaNs at the beginning, ‘last’ puts NaNs at\\nthe end.\\n'},\n",
       "        {'param_name': 'ignore_index',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True, the resulting axis will be labeled 0, 1, …, n - 1.\\n'},\n",
       "        {'param_name': 'key',\n",
       "         'param_type': 'callable, optional',\n",
       "         'param_desc': 'If not None, apply the key function to the series values\\nbefore sorting. This is similar to the key argument in the\\nbuiltin sorted() function, with the notable difference that\\nthis key function should be vectorized. It should expect a\\nSeries and return an array-like.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.sort_values',\n",
       "       'descriptions': 'Sort by the values. Sort a Series in ascending or descending order by some\\ncriterion.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’}. Unused. Parameter needed for compatibility with DataFrame.\\n'},\n",
       "         'ascending': {'type': 'boolean',\n",
       "          'description': 'bool or list of bools, default True. If True, sort values in ascending order, otherwise descending.\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True, perform operation in-place.\\n'},\n",
       "         'kind': {'type': 'string',\n",
       "          'enum': ['quicksort', ' mergesort', ' heapsort', ' stable'],\n",
       "          'description': '{‘quicksort’, ‘mergesort’, ‘heapsort’, ‘stable’}, default ‘quicksort’. Choice of sorting algorithm. See also numpy.sort() for more\\ninformation. ‘mergesort’ and ‘stable’ are the only stable algorithms.\\n'},\n",
       "         'na_position': {'type': 'string',\n",
       "          'enum': ['first or last'],\n",
       "          'description': '{‘first’ or ‘last’}, default ‘last’. Argument ‘first’ puts NaNs at the beginning, ‘last’ puts NaNs at\\nthe end.\\n'},\n",
       "         'ignore_index': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True, the resulting axis will be labeled 0, 1, …, n - 1.\\n'},\n",
       "         'key': {'type': 'object',\n",
       "          'description': 'callable, optional. If not None, apply the key function to the series values\\nbefore sorting. This is similar to the key argument in the\\nbuiltin sorted() function, with the notable difference that\\nthis key function should be vectorized. It should expect a\\nSeries and return an array-like.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.swaplevel([i,\\xa0j,\\xa0copy])',\n",
       "      'func_desc': 'Swap levels i and j in a MultiIndex.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.swaplevel.html#pandas.Series.swaplevel',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.swaplevel',\n",
       "       'full_function': 'Series.swaplevel(i=-2, j=-1, copy=None)',\n",
       "       'function_text': 'Swap levels i and j in a MultiIndex. Default is to swap the two innermost levels of the index.',\n",
       "       'parameter_names_desc': [{'param_name': 'i, j',\n",
       "         'param_type': 'int or str',\n",
       "         'param_desc': 'Levels of the indices to be swapped. Can pass level name as string.\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to copy underlying data.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.swaplevel',\n",
       "       'descriptions': 'Swap levels i and j in a MultiIndex. Default is to swap the two innermost levels of the index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'i, j': {'type': 'integer',\n",
       "          'description': 'int or str. Levels of the indices to be swapped. Can pass level name as string.\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to copy underlying data.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.explode([ignore_index])',\n",
       "      'func_desc': 'Transform each element of a list-like to a row.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.explode.html#pandas.Series.explode',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.explode',\n",
       "       'full_function': 'Series.explode(ignore_index=False)',\n",
       "       'function_text': 'Transform each element of a list-like to a row.',\n",
       "       'parameter_names_desc': [{'param_name': 'ignore_index',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True, the resulting index will be labeled 0, 1, …, n - 1.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.explode',\n",
       "       'descriptions': 'Transform each element of a list-like to a row.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'ignore_index': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True, the resulting index will be labeled 0, 1, …, n - 1.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.ravel([order])',\n",
       "      'func_desc': '(DEPRECATED) Return the flattened underlying data as an ndarray or ExtensionArray.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.ravel.html#pandas.Series.ravel',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.ravel',\n",
       "       'full_function': \"Series.ravel(order='C')\",\n",
       "       'function_text': 'Return the flattened underlying data as an ndarray or ExtensionArray. Deprecated since version 2.2.0: Series.ravel is deprecated. The underlying array is already 1D, so\\nravel is not necessary. Use to_numpy() for conversion to a numpy\\narray instead.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.squeeze([axis])',\n",
       "      'func_desc': 'Squeeze 1 dimensional axis objects into scalars.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.squeeze.html#pandas.Series.squeeze',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.squeeze',\n",
       "       'full_function': 'Series.squeeze(axis=None)',\n",
       "       'function_text': 'Squeeze 1 dimensional axis objects into scalars. Series or DataFrames with a single element are squeezed to a scalar.\\nDataFrames with a single column or a single row are squeezed to a\\nSeries. Otherwise the object is unchanged. This method is most useful when you don’t know if your\\nobject is a Series or DataFrame, but you do know it has just a single\\ncolumn. In that case you can safely call squeeze to ensure you have a\\nSeries.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’, None}, default None',\n",
       "         'param_desc': 'A specific axis to squeeze. By default, all length-1 axes are\\nsqueezed. For Series this parameter is unused and defaults to None.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.squeeze',\n",
       "       'descriptions': 'Squeeze 1 dimensional axis objects into scalars. Series or DataFrames with a single element are squeezed to a scalar.\\nDataFrames with a single column or a single row are squeezed to a\\nSeries. Otherwise the object is unchanged. This method is most useful when you don’t know if your\\nobject is a Series or DataFrame, but you do know it has just a single\\ncolumn. In that case you can safely call squeeze to ensure you have a\\nSeries.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns', ' None'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’, None}, default None. A specific axis to squeeze. By default, all length-1 axes are\\nsqueezed. For Series this parameter is unused and defaults to None.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.argmin([axis,\\xa0skipna])',\n",
       "      'func_desc': 'Return int position of the smallest value in the Series.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.argmin.html#pandas.Series.argmin',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.argmin',\n",
       "       'full_function': 'Series.argmin(axis=None, skipna=True, *args, **kwargs)',\n",
       "       'function_text': 'Return int position of the smallest value in the Series. If the minimum is achieved in multiple locations,\\nthe first row position is returned.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{None}',\n",
       "         'param_desc': 'Unused. Parameter needed for compatibility with DataFrame.\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values when showing the result.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.argmin',\n",
       "       'descriptions': 'Return int position of the smallest value in the Series. If the minimum is achieved in multiple locations,\\nthe first row position is returned.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': '{None}',\n",
       "          'description': '{None}. Unused. Parameter needed for compatibility with DataFrame.\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values when showing the result.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.reorder_levels(order)',\n",
       "      'func_desc': 'Rearrange index levels using input order.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.reorder_levels.html#pandas.Series.reorder_levels',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.reorder_levels',\n",
       "       'full_function': 'Series.reorder_levels(order)',\n",
       "       'function_text': 'Rearrange index levels using input order. May not drop or duplicate levels.',\n",
       "       'parameter_names_desc': [{'param_name': 'order',\n",
       "         'param_type': 'list of int representing new level order',\n",
       "         'param_desc': 'Reference level by number or key.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.reorder_levels',\n",
       "       'descriptions': 'Rearrange index levels using input order. May not drop or duplicate levels.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'order': {'type': 'integer',\n",
       "          'description': 'list of int representing new level order. Reference level by number or key.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.sort_index(*[,\\xa0axis,\\xa0level,\\xa0...])',\n",
       "      'func_desc': 'Sort Series by index labels.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.sort_index.html#pandas.Series.sort_index',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.sort_index',\n",
       "       'full_function': \"Series.sort_index(*, axis=0, level=None, ascending=True, inplace=False, kind='quicksort', na_position='last', sort_remaining=True, ignore_index=False, key=None)\",\n",
       "       'function_text': 'Sort Series by index labels. Returns a new Series sorted by label if inplace argument is\\nFalse, otherwise updates the original series and returns None.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’}',\n",
       "         'param_desc': 'Unused. Parameter needed for compatibility with DataFrame.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'If not None, sort on values in specified index level(s).\\n'},\n",
       "        {'param_name': 'ascending',\n",
       "         'param_type': 'bool or list-like of bools, default True',\n",
       "         'param_desc': 'Sort ascending vs. descending. When the index is a MultiIndex the\\nsort direction can be controlled for each level individually.\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True, perform operation in-place.\\n'},\n",
       "        {'param_name': 'kind',\n",
       "         'param_type': '{‘quicksort’, ‘mergesort’, ‘heapsort’, ‘stable’}, default ‘quicksort’',\n",
       "         'param_desc': 'Choice of sorting algorithm. See also numpy.sort() for more\\ninformation. ‘mergesort’ and ‘stable’ are the only stable algorithms. For\\nDataFrames, this option is only applied when sorting on a single\\ncolumn or label.\\n'},\n",
       "        {'param_name': 'na_position',\n",
       "         'param_type': '{‘first’, ‘last’}, default ‘last’',\n",
       "         'param_desc': 'If ‘first’ puts NaNs at the beginning, ‘last’ puts NaNs at the end.\\nNot implemented for MultiIndex.\\n'},\n",
       "        {'param_name': 'sort_remaining',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If True and sorting by level and index is multilevel, sort by other\\nlevels too (in order) after sorting by specified level.\\n'},\n",
       "        {'param_name': 'ignore_index',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True, the resulting axis will be labeled 0, 1, …, n - 1.\\n'},\n",
       "        {'param_name': 'key',\n",
       "         'param_type': 'callable, optional',\n",
       "         'param_desc': 'If not None, apply the key function to the index values\\nbefore sorting. This is similar to the key argument in the\\nbuiltin sorted() function, with the notable difference that\\nthis key function should be vectorized. It should expect an\\nIndex and return an Index of the same shape.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.sort_index',\n",
       "       'descriptions': 'Sort Series by index labels. Returns a new Series sorted by label if inplace argument is\\nFalse, otherwise updates the original series and returns None.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’}. Unused. Parameter needed for compatibility with DataFrame.\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int, optional. If not None, sort on values in specified index level(s).\\n'},\n",
       "         'ascending': {'type': 'boolean',\n",
       "          'description': 'bool or list-like of bools, default True. Sort ascending vs. descending. When the index is a MultiIndex the\\nsort direction can be controlled for each level individually.\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True, perform operation in-place.\\n'},\n",
       "         'kind': {'type': 'string',\n",
       "          'enum': ['quicksort', ' mergesort', ' heapsort', ' stable'],\n",
       "          'description': '{‘quicksort’, ‘mergesort’, ‘heapsort’, ‘stable’}, default ‘quicksort’. Choice of sorting algorithm. See also numpy.sort() for more\\ninformation. ‘mergesort’ and ‘stable’ are the only stable algorithms. For\\nDataFrames, this option is only applied when sorting on a single\\ncolumn or label.\\n'},\n",
       "         'na_position': {'type': 'string',\n",
       "          'enum': ['first', ' last'],\n",
       "          'description': '{‘first’, ‘last’}, default ‘last’. If ‘first’ puts NaNs at the beginning, ‘last’ puts NaNs at the end.\\nNot implemented for MultiIndex.\\n'},\n",
       "         'sort_remaining': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If True and sorting by level and index is multilevel, sort by other\\nlevels too (in order) after sorting by specified level.\\n'},\n",
       "         'ignore_index': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True, the resulting axis will be labeled 0, 1, …, n - 1.\\n'},\n",
       "         'key': {'type': 'object',\n",
       "          'description': 'callable, optional. If not None, apply the key function to the index values\\nbefore sorting. This is similar to the key argument in the\\nbuiltin sorted() function, with the notable difference that\\nthis key function should be vectorized. It should expect an\\nIndex and return an Index of the same shape.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.unstack([level,\\xa0fill_value,\\xa0sort])',\n",
       "      'func_desc': 'Unstack, also known as pivot, Series with MultiIndex to produce DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.unstack.html#pandas.Series.unstack',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.unstack',\n",
       "       'full_function': 'Series.unstack(level=-1, fill_value=None, sort=True)',\n",
       "       'function_text': 'Unstack, also known as pivot, Series with MultiIndex to produce DataFrame.',\n",
       "       'parameter_names_desc': [{'param_name': 'level',\n",
       "         'param_type': 'int, str, or list of these, default last level',\n",
       "         'param_desc': 'Level(s) to unstack, can pass level name.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'scalar value, default None',\n",
       "         'param_desc': 'Value to use when replacing NaN values.\\n'},\n",
       "        {'param_name': 'sort',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Sort the level(s) in the resulting MultiIndex columns.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.unstack',\n",
       "       'descriptions': 'Unstack, also known as pivot, Series with MultiIndex to produce DataFrame.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'level': {'type': 'integer',\n",
       "          'description': 'int, str, or list of these, default last level. Level(s) to unstack, can pass level name.\\n'},\n",
       "         'fill_value': {'type': 'scalar value, default None',\n",
       "          'description': 'scalar value, default None. Value to use when replacing NaN values.\\n'},\n",
       "         'sort': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Sort the level(s) in the resulting MultiIndex columns.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.searchsorted(value[,\\xa0side,\\xa0sorter])',\n",
       "      'func_desc': 'Find indices where elements should be inserted to maintain order.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.searchsorted.html#pandas.Series.searchsorted',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.searchsorted',\n",
       "       'full_function': \"Series.searchsorted(value, side='left', sorter=None)\",\n",
       "       'function_text': 'Find indices where elements should be inserted to maintain order. Find the indices into a sorted Series self such that, if the\\ncorresponding elements in value were inserted before the indices,\\nthe order of self would be preserved. Note The Series must be monotonically sorted, otherwise\\nwrong locations will likely be returned. Pandas does not\\ncheck this for you.',\n",
       "       'parameter_names_desc': [{'param_name': 'value',\n",
       "         'param_type': 'array-like or scalar',\n",
       "         'param_desc': 'Values to insert into self.\\n'},\n",
       "        {'param_name': 'side',\n",
       "         'param_type': '{‘left’, ‘right’}, optional',\n",
       "         'param_desc': 'If ‘left’, the index of the first suitable location found is given.\\nIf ‘right’, return the last such index. If there is no suitable\\nindex, return either 0 or N (where N is the length of self).\\n'},\n",
       "        {'param_name': 'sorter',\n",
       "         'param_type': '1-D array-like, optional',\n",
       "         'param_desc': 'Optional array of integer indices that sort self into ascending\\norder. They are typically the result of np.argsort.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.searchsorted',\n",
       "       'descriptions': 'Find indices where elements should be inserted to maintain order. Find the indices into a sorted Series self such that, if the\\ncorresponding elements in value were inserted before the indices,\\nthe order of self would be preserved. Note The Series must be monotonically sorted, otherwise\\nwrong locations will likely be returned. Pandas does not\\ncheck this for you.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'value': {'type': 'array',\n",
       "          'description': 'array-like or scalar. Values to insert into self.\\n'},\n",
       "         'side': {'type': 'string',\n",
       "          'enum': ['left', ' right'],\n",
       "          'description': '{‘left’, ‘right’}, optional. If ‘left’, the index of the first suitable location found is given.\\nIf ‘right’, return the last such index. If there is no suitable\\nindex, return either 0 or N (where N is the length of self).\\n'},\n",
       "         'sorter': {'type': 'array',\n",
       "          'description': '1-D array-like, optional. Optional array of integer indices that sort self into ascending\\norder. They are typically the result of np.argsort.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.repeat(repeats[,\\xa0axis])',\n",
       "      'func_desc': 'Repeat elements of a Series.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.repeat.html#pandas.Series.repeat',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.repeat',\n",
       "       'full_function': 'Series.repeat(repeats, axis=None)',\n",
       "       'function_text': 'Repeat elements of a Series. Returns a new Series where each element of the current Series\\nis repeated consecutively a given number of times.',\n",
       "       'parameter_names_desc': [{'param_name': 'repeats',\n",
       "         'param_type': 'int or array of ints',\n",
       "         'param_desc': 'The number of repetitions for each element. This should be a\\nnon-negative integer. Repeating 0 times will return an empty\\nSeries.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': 'None',\n",
       "         'param_desc': 'Unused. Parameter needed for compatibility with DataFrame.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.repeat',\n",
       "       'descriptions': 'Repeat elements of a Series. Returns a new Series where each element of the current Series\\nis repeated consecutively a given number of times.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'repeats': {'type': 'integer',\n",
       "          'description': 'int or array of ints. The number of repetitions for each element. This should be a\\nnon-negative integer. Repeating 0 times will return an empty\\nSeries.\\n'},\n",
       "         'axis': {'type': 'None',\n",
       "          'description': 'None. Unused. Parameter needed for compatibility with DataFrame.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.view([dtype])',\n",
       "      'func_desc': '(DEPRECATED) Create a new view of the Series.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.view.html#pandas.Series.view',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.view',\n",
       "       'full_function': 'Series.view(dtype=None)',\n",
       "       'function_text': 'Create a new view of the Series. Deprecated since version 2.2.0: Series.view is deprecated and will be removed in a future version.\\nUse Series.astype() as an alternative to change the dtype. This function will return a new Series with a view of the same\\nunderlying values in memory, optionally reinterpreted with a new data\\ntype. The new data type must preserve the same size in bytes as to not\\ncause index misalignment.',\n",
       "       'parameter_names_desc': [{'param_name': 'dtype',\n",
       "         'param_type': 'data type',\n",
       "         'param_desc': 'Data type object or one of their string representations.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.view',\n",
       "       'descriptions': 'Create a new view of the Series. Deprecated since version 2.2.0: Series.view is deprecated and will be removed in a future version.\\nUse Series.astype() as an alternative to change the dtype. This function will return a new Series with a view of the same\\nunderlying values in memory, optionally reinterpreted with a new data\\ntype. The new data type must preserve the same size in bytes as to not\\ncause index misalignment.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dtype': {'type': 'data type',\n",
       "          'description': 'data type. Data type object or one of their string representations.\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Combining / comparing / joining / merging': [{'func_name': 'Series.compare(other[,\\xa0align_axis,\\xa0...])',\n",
       "      'func_desc': 'Compare to another Series and show the differences.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.compare.html#pandas.Series.compare',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.compare',\n",
       "       'full_function': \"Series.compare(other, align_axis=1, keep_shape=False, keep_equal=False, result_names=('self', 'other'))\",\n",
       "       'function_text': 'Compare to another Series and show the differences.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series',\n",
       "         'param_desc': 'Object to compare with.\\n'},\n",
       "        {'param_name': 'align_axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 1',\n",
       "         'param_desc': 'Determine which axis to align the comparison on.\\n\\n\\n0, or ‘index’Resulting differences are stacked verticallywith rows drawn alternately from self and other.\\n\\n\\n\\n\\n1, or ‘columns’Resulting differences are aligned horizontallywith columns drawn alternately from self and other.\\n\\n\\n\\n\\n'},\n",
       "        {'param_name': 'keep_shape',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If true, all rows and columns are kept.\\nOtherwise, only the ones with different values are kept.\\n'},\n",
       "        {'param_name': 'keep_equal',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If true, the result keeps values that are equal.\\nOtherwise, equal values are shown as NaNs.\\n'},\n",
       "        {'param_name': 'result_names',\n",
       "         'param_type': 'tuple, default (‘self’, ‘other’)',\n",
       "         'param_desc': 'Set the dataframes names in the comparison.\\n\\nNew in version 1.5.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.compare',\n",
       "       'descriptions': 'Compare to another Series and show the differences.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series',\n",
       "          'description': 'Series. Object to compare with.\\n'},\n",
       "         'align_axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 1. Determine which axis to align the comparison on.\\n\\n\\n0, or ‘index’Resulting differences are stacked verticallywith rows drawn alternately from self and other.\\n\\n\\n\\n\\n1, or ‘columns’Resulting differences are aligned horizontallywith columns drawn alternately from self and other.\\n\\n\\n\\n\\n'},\n",
       "         'keep_shape': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If true, all rows and columns are kept.\\nOtherwise, only the ones with different values are kept.\\n'},\n",
       "         'keep_equal': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If true, the result keeps values that are equal.\\nOtherwise, equal values are shown as NaNs.\\n'},\n",
       "         'result_names': {'type': 'tuple, default (‘self’, ‘other’)',\n",
       "          'description': 'tuple, default (‘self’, ‘other’). Set the dataframes names in the comparison.\\n\\nNew in version 1.5.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.update(other)',\n",
       "      'func_desc': 'Modify Series in place using values from passed Series.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.update.html#pandas.Series.update',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.update',\n",
       "       'full_function': 'Series.update(other)',\n",
       "       'function_text': 'Modify Series in place using values from passed Series. Uses non-NA values from passed Series to make updates. Aligns\\non index.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series, or object coercible into Series',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.Series.update',\n",
       "       'descriptions': 'Modify Series in place using values from passed Series. Uses non-NA values from passed Series to make updates. Aligns\\non index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'integer',\n",
       "          'description': 'Series, or object coercible into Series. '}},\n",
       "        'required': []}}}]},\n",
       "   {'Time Series-related': [{'func_name': 'Series.asfreq(freq[,\\xa0method,\\xa0how,\\xa0...])',\n",
       "      'func_desc': 'Convert time series to specified frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.asfreq.html#pandas.Series.asfreq',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.asfreq',\n",
       "       'full_function': 'Series.asfreq(freq, method=None, how=None, normalize=False, fill_value=None)',\n",
       "       'function_text': 'Convert time series to specified frequency. Returns the original data conformed to a new index with the specified\\nfrequency. If the index of this Series/DataFrame is a PeriodIndex, the new index\\nis the result of transforming the original index with\\nPeriodIndex.asfreq (so the original index\\nwill map one-to-one to the new index). Otherwise, the new index will be equivalent to pd.date_range(start, end,\\nfreq=freq) where start and end are, respectively, the first and\\nlast entries in the original index (see pandas.date_range()). The\\nvalues corresponding to any timesteps in the new index which were not present\\nin the original index will be null (NaN), unless a method for filling\\nsuch unknowns is provided (see the method parameter below). The resample() method is more appropriate if an operation on each group of\\ntimesteps (such as an aggregate) is necessary to represent the data at the new\\nfrequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'freq',\n",
       "         'param_type': 'DateOffset or str',\n",
       "         'param_desc': 'Frequency DateOffset or string.\\n'},\n",
       "        {'param_name': 'method',\n",
       "         'param_type': '{‘backfill’/’bfill’, ‘pad’/’ffill’}, default None',\n",
       "         'param_desc': 'Method to use for filling holes in reindexed Series (note this\\ndoes not fill NaNs that already were present):\\n\\n‘pad’ / ‘ffill’: propagate last valid observation forward to next\\nvalid\\n‘backfill’ / ‘bfill’: use NEXT valid observation to fill.\\n\\n'},\n",
       "        {'param_name': 'how',\n",
       "         'param_type': '{‘start’, ‘end’}, default end',\n",
       "         'param_desc': 'For PeriodIndex only (see PeriodIndex.asfreq).\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to reset output index to midnight.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'scalar, optional',\n",
       "         'param_desc': 'Value to use for missing values, applied during upsampling (note\\nthis does not fill NaNs that already were present).\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.asfreq',\n",
       "       'descriptions': 'Convert time series to specified frequency. Returns the original data conformed to a new index with the specified\\nfrequency. If the index of this Series/DataFrame is a PeriodIndex, the new index\\nis the result of transforming the original index with\\nPeriodIndex.asfreq (so the original index\\nwill map one-to-one to the new index). Otherwise, the new index will be equivalent to pd.date_range(start, end,\\nfreq=freq) where start and end are, respectively, the first and\\nlast entries in the original index (see pandas.date_range()). The\\nvalues corresponding to any timesteps in the new index which were not present\\nin the original index will be null (NaN), unless a method for filling\\nsuch unknowns is provided (see the method parameter below). The resample() method is more appropriate if an operation on each group of\\ntimesteps (such as an aggregate) is necessary to represent the data at the new\\nfrequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'freq': {'type': 'string',\n",
       "          'description': 'DateOffset or str. Frequency DateOffset or string.\\n'},\n",
       "         'method': {'type': 'string',\n",
       "          'enum': ['backfill/bfill', ' pad/ffill'],\n",
       "          'description': '{‘backfill’/’bfill’, ‘pad’/’ffill’}, default None. Method to use for filling holes in reindexed Series (note this\\ndoes not fill NaNs that already were present):\\n\\n‘pad’ / ‘ffill’: propagate last valid observation forward to next\\nvalid\\n‘backfill’ / ‘bfill’: use NEXT valid observation to fill.\\n\\n'},\n",
       "         'how': {'type': 'string',\n",
       "          'enum': ['start', ' end'],\n",
       "          'description': '{‘start’, ‘end’}, default end. For PeriodIndex only (see PeriodIndex.asfreq).\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to reset output index to midnight.\\n'},\n",
       "         'fill_value': {'type': 'scalar, optional',\n",
       "          'description': 'scalar, optional. Value to use for missing values, applied during upsampling (note\\nthis does not fill NaNs that already were present).\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.shift([periods,\\xa0freq,\\xa0axis,\\xa0...])',\n",
       "      'func_desc': 'Shift index by desired number of periods with an optional time freq.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.shift.html#pandas.Series.shift',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.shift',\n",
       "       'full_function': 'Series.shift(periods=1, freq=None, axis=0, fill_value=_NoDefault.no_default, suffix=None)',\n",
       "       'function_text': 'Shift index by desired number of periods with an optional time freq. When freq is not passed, shift the index without realigning the data.\\nIf freq is passed (in this case, the index must be date or datetime,\\nor it will raise a NotImplementedError), the index will be\\nincreased using the periods and the freq. freq can be inferred\\nwhen specified as “infer” as long as either freq or inferred_freq\\nattribute is set in the index.',\n",
       "       'parameter_names_desc': [{'param_name': 'periods',\n",
       "         'param_type': 'int or Sequence',\n",
       "         'param_desc': 'Number of periods to shift. Can be positive or negative.\\nIf an iterable of ints, the data will be shifted once by each int.\\nThis is equivalent to shifting by one value at a time and\\nconcatenating all resulting frames. The resulting columns will have\\nthe shift suffixed to their column names. For multiple periods,\\naxis must not be 1.\\n'},\n",
       "        {'param_name': 'freq',\n",
       "         'param_type': 'DateOffset, tseries.offsets, timedelta, or str, optional',\n",
       "         'param_desc': 'Offset to use from the tseries module or time rule (e.g. ‘EOM’).\\nIf freq is specified then the index values are shifted but the\\ndata is not realigned. That is, use freq if you would like to\\nextend the index when shifting and preserve the original data.\\nIf freq is specified as “infer” then it will be inferred from\\nthe freq or inferred_freq attributes of the index. If neither of\\nthose attributes exist, a ValueError is thrown.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’, None}, default None',\n",
       "         'param_desc': 'Shift direction. For Series this parameter is unused and defaults to 0.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'object, optional',\n",
       "         'param_desc': 'The scalar value to use for newly introduced missing values.\\nthe default depends on the dtype of self.\\nFor numeric data, np.nan is used.\\nFor datetime, timedelta, or period data, etc. NaT is used.\\nFor extension dtypes, self.dtype.na_value is used.\\n'},\n",
       "        {'param_name': 'suffix',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'If str and periods is an iterable, this is added after the column\\nname and before the shift value for each shifted column name.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.shift',\n",
       "       'descriptions': 'Shift index by desired number of periods with an optional time freq. When freq is not passed, shift the index without realigning the data.\\nIf freq is passed (in this case, the index must be date or datetime,\\nor it will raise a NotImplementedError), the index will be\\nincreased using the periods and the freq. freq can be inferred\\nwhen specified as “infer” as long as either freq or inferred_freq\\nattribute is set in the index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'periods': {'type': 'integer',\n",
       "          'description': 'int or Sequence. Number of periods to shift. Can be positive or negative.\\nIf an iterable of ints, the data will be shifted once by each int.\\nThis is equivalent to shifting by one value at a time and\\nconcatenating all resulting frames. The resulting columns will have\\nthe shift suffixed to their column names. For multiple periods,\\naxis must not be 1.\\n'},\n",
       "         'freq': {'type': 'string',\n",
       "          'description': 'DateOffset, tseries.offsets, timedelta, or str, optional. Offset to use from the tseries module or time rule (e.g. ‘EOM’).\\nIf freq is specified then the index values are shifted but the\\ndata is not realigned. That is, use freq if you would like to\\nextend the index when shifting and preserve the original data.\\nIf freq is specified as “infer” then it will be inferred from\\nthe freq or inferred_freq attributes of the index. If neither of\\nthose attributes exist, a ValueError is thrown.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns', ' None'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’, None}, default None. Shift direction. For Series this parameter is unused and defaults to 0.\\n'},\n",
       "         'fill_value': {'type': 'object',\n",
       "          'description': 'object, optional. The scalar value to use for newly introduced missing values.\\nthe default depends on the dtype of self.\\nFor numeric data, np.nan is used.\\nFor datetime, timedelta, or period data, etc. NaT is used.\\nFor extension dtypes, self.dtype.na_value is used.\\n'},\n",
       "         'suffix': {'type': 'string',\n",
       "          'description': 'str, optional. If str and periods is an iterable, this is added after the column\\nname and before the shift value for each shifted column name.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.last_valid_index()',\n",
       "      'func_desc': 'Return index for last non-NA value or None, if no non-NA value is found.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.last_valid_index.html#pandas.Series.last_valid_index',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.last_valid_index',\n",
       "       'full_function': 'Series.last_valid_index()',\n",
       "       'function_text': 'Return index for last non-NA value or None, if no non-NA value is found.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.tz_convert(tz[,\\xa0axis,\\xa0level,\\xa0copy])',\n",
       "      'func_desc': 'Convert tz-aware axis to target time zone.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.tz_convert.html#pandas.Series.tz_convert',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.tz_convert',\n",
       "       'full_function': 'Series.tz_convert(tz, axis=0, level=None, copy=None)',\n",
       "       'function_text': 'Convert tz-aware axis to target time zone.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.at_time(time[,\\xa0asof,\\xa0axis])',\n",
       "      'func_desc': 'Select values at particular time of day (e.g., 9:30AM).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.at_time.html#pandas.Series.at_time',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.at_time',\n",
       "       'full_function': 'Series.at_time(time, asof=False, axis=None)',\n",
       "       'function_text': 'Select values at particular time of day (e.g., 9:30AM).',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.asof(where[,\\xa0subset])',\n",
       "      'func_desc': 'Return the last row(s) without any NaNs before where.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.asof.html#pandas.Series.asof',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.asof',\n",
       "       'full_function': 'Series.asof(where, subset=None)',\n",
       "       'function_text': 'Return the last row(s) without any NaNs before where. The last row (for each element in where, if list) without any\\nNaN is taken.\\nIn case of a DataFrame, the last row without NaN\\nconsidering only the subset of columns (if not None) If there is no good value, NaN is returned for a Series or\\na Series of NaN values for a DataFrame',\n",
       "       'parameter_names_desc': [{'param_name': 'where',\n",
       "         'param_type': 'date or array-like of dates',\n",
       "         'param_desc': 'Date(s) before which the last row(s) are returned.\\n'},\n",
       "        {'param_name': 'subset',\n",
       "         'param_type': 'str or array-like of str, default None',\n",
       "         'param_desc': 'For DataFrame, if not None, only use these columns to\\ncheck for NaNs.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.asof',\n",
       "       'descriptions': 'Return the last row(s) without any NaNs before where. The last row (for each element in where, if list) without any\\nNaN is taken.\\nIn case of a DataFrame, the last row without NaN\\nconsidering only the subset of columns (if not None) If there is no good value, NaN is returned for a Series or\\na Series of NaN values for a DataFrame',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'where': {'type': 'array',\n",
       "          'description': 'date or array-like of dates. Date(s) before which the last row(s) are returned.\\n'},\n",
       "         'subset': {'type': 'string',\n",
       "          'description': 'str or array-like of str, default None. For DataFrame, if not None, only use these columns to\\ncheck for NaNs.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.first_valid_index()',\n",
       "      'func_desc': 'Return index for first non-NA value or None, if no non-NA value is found.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.first_valid_index.html#pandas.Series.first_valid_index',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.first_valid_index',\n",
       "       'full_function': 'Series.first_valid_index()',\n",
       "       'function_text': 'Return index for first non-NA value or None, if no non-NA value is found.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.resample(rule[,\\xa0axis,\\xa0closed,\\xa0label,\\xa0...])',\n",
       "      'func_desc': 'Resample time-series data.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.resample.html#pandas.Series.resample',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.resample',\n",
       "       'full_function': \"Series.resample(rule, axis=_NoDefault.no_default, closed=None, label=None, convention=_NoDefault.no_default, kind=_NoDefault.no_default, on=None, level=None, origin='start_day', offset=None, group_keys=False)\",\n",
       "       'function_text': 'Resample time-series data. Convenience method for frequency conversion and resampling of time series.\\nThe object must have a datetime-like index (DatetimeIndex, PeriodIndex,\\nor TimedeltaIndex), or the caller must pass the label of a datetime-like\\nseries/index to the on/level keyword parameter.',\n",
       "       'parameter_names_desc': [{'param_name': 'rule',\n",
       "         'param_type': 'DateOffset, Timedelta or str',\n",
       "         'param_desc': 'The offset string or object representing target conversion.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'Which axis to use for up- or down-sampling. For Series this parameter\\nis unused and defaults to 0. Must be\\nDatetimeIndex, TimedeltaIndex or PeriodIndex.\\n\\nDeprecated since version 2.0.0: Use frame.T.resample(…) instead.\\n\\n'},\n",
       "        {'param_name': 'closed',\n",
       "         'param_type': '{‘right’, ‘left’}, default None',\n",
       "         'param_desc': 'Which side of bin interval is closed. The default is ‘left’\\nfor all frequency offsets except for ‘ME’, ‘YE’, ‘QE’, ‘BME’,\\n‘BA’, ‘BQE’, and ‘W’ which all have a default of ‘right’.\\n'},\n",
       "        {'param_name': 'label',\n",
       "         'param_type': '{‘right’, ‘left’}, default None',\n",
       "         'param_desc': 'Which bin edge label to label bucket with. The default is ‘left’\\nfor all frequency offsets except for ‘ME’, ‘YE’, ‘QE’, ‘BME’,\\n‘BA’, ‘BQE’, and ‘W’ which all have a default of ‘right’.\\n'},\n",
       "        {'param_name': 'convention',\n",
       "         'param_type': '{‘start’, ‘end’, ‘s’, ‘e’}, default ‘start’',\n",
       "         'param_desc': 'For PeriodIndex only, controls whether to use the start or\\nend of rule.\\n\\nDeprecated since version 2.2.0: Convert PeriodIndex to DatetimeIndex before resampling instead.\\n\\n'},\n",
       "        {'param_name': 'kind',\n",
       "         'param_type': '{‘timestamp’, ‘period’}, optional, default None',\n",
       "         'param_desc': 'Pass ‘timestamp’ to convert the resulting index to a\\nDateTimeIndex or ‘period’ to convert it to a PeriodIndex.\\nBy default the input representation is retained.\\n\\nDeprecated since version 2.2.0: Convert index to desired type explicitly instead.\\n\\n'},\n",
       "        {'param_name': 'on',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'For a DataFrame, column to use instead of index for resampling.\\nColumn must be datetime-like.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'str or int, optional',\n",
       "         'param_desc': 'For a MultiIndex, level (name or number) to use for\\nresampling. level must be datetime-like.\\n'},\n",
       "        {'param_name': 'origin',\n",
       "         'param_type': 'Timestamp or str, default ‘start_day’',\n",
       "         'param_desc': 'The timestamp on which to adjust the grouping. The timezone of origin\\nmust match the timezone of the index.\\nIf string, must be one of the following:\\n\\n‘epoch’: origin is 1970-01-01\\n‘start’: origin is the first value of the timeseries\\n‘start_day’: origin is the first day at midnight of the timeseries\\n‘end’: origin is the last value of the timeseries\\n‘end_day’: origin is the ceiling midnight of the last day\\n\\n\\nNew in version 1.3.0.\\n\\n\\nNote\\nOnly takes effect for Tick-frequencies (i.e. fixed frequencies like\\ndays, hours, and minutes, rather than months or quarters).\\n\\n'},\n",
       "        {'param_name': 'offset',\n",
       "         'param_type': 'Timedelta or str, default is None',\n",
       "         'param_desc': 'An offset timedelta added to the origin.\\n'},\n",
       "        {'param_name': 'group_keys',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to include the group keys in the result index when using\\n.apply() on the resampled object.\\n\\nNew in version 1.5.0: Not specifying group_keys will retain values-dependent behavior\\nfrom pandas 1.4 and earlier (see pandas 1.5.0 Release notes for examples).\\n\\n\\nChanged in version 2.0.0: group_keys now defaults to False.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.resample',\n",
       "       'descriptions': 'Resample time-series data. Convenience method for frequency conversion and resampling of time series.\\nThe object must have a datetime-like index (DatetimeIndex, PeriodIndex,\\nor TimedeltaIndex), or the caller must pass the label of a datetime-like\\nseries/index to the on/level keyword parameter.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'rule': {'type': 'string',\n",
       "          'description': 'DateOffset, Timedelta or str. The offset string or object representing target conversion.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. Which axis to use for up- or down-sampling. For Series this parameter\\nis unused and defaults to 0. Must be\\nDatetimeIndex, TimedeltaIndex or PeriodIndex.\\n\\nDeprecated since version 2.0.0: Use frame.T.resample(…) instead.\\n\\n'},\n",
       "         'closed': {'type': 'string',\n",
       "          'enum': ['right', ' left'],\n",
       "          'description': '{‘right’, ‘left’}, default None. Which side of bin interval is closed. The default is ‘left’\\nfor all frequency offsets except for ‘ME’, ‘YE’, ‘QE’, ‘BME’,\\n‘BA’, ‘BQE’, and ‘W’ which all have a default of ‘right’.\\n'},\n",
       "         'label': {'type': 'string',\n",
       "          'enum': ['right', ' left'],\n",
       "          'description': '{‘right’, ‘left’}, default None. Which bin edge label to label bucket with. The default is ‘left’\\nfor all frequency offsets except for ‘ME’, ‘YE’, ‘QE’, ‘BME’,\\n‘BA’, ‘BQE’, and ‘W’ which all have a default of ‘right’.\\n'},\n",
       "         'convention': {'type': 'string',\n",
       "          'enum': ['start', ' end', ' s', ' e'],\n",
       "          'description': '{‘start’, ‘end’, ‘s’, ‘e’}, default ‘start’. For PeriodIndex only, controls whether to use the start or\\nend of rule.\\n\\nDeprecated since version 2.2.0: Convert PeriodIndex to DatetimeIndex before resampling instead.\\n\\n'},\n",
       "         'kind': {'type': 'string',\n",
       "          'enum': ['timestamp', ' period'],\n",
       "          'description': '{‘timestamp’, ‘period’}, optional, default None. Pass ‘timestamp’ to convert the resulting index to a\\nDateTimeIndex or ‘period’ to convert it to a PeriodIndex.\\nBy default the input representation is retained.\\n\\nDeprecated since version 2.2.0: Convert index to desired type explicitly instead.\\n\\n'},\n",
       "         'on': {'type': 'string',\n",
       "          'description': 'str, optional. For a DataFrame, column to use instead of index for resampling.\\nColumn must be datetime-like.\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'str or int, optional. For a MultiIndex, level (name or number) to use for\\nresampling. level must be datetime-like.\\n'},\n",
       "         'origin': {'type': 'string',\n",
       "          'description': 'Timestamp or str, default ‘start_day’. The timestamp on which to adjust the grouping. The timezone of origin\\nmust match the timezone of the index.\\nIf string, must be one of the following:\\n\\n‘epoch’: origin is 1970-01-01\\n‘start’: origin is the first value of the timeseries\\n‘start_day’: origin is the first day at midnight of the timeseries\\n‘end’: origin is the last value of the timeseries\\n‘end_day’: origin is the ceiling midnight of the last day\\n\\n\\nNew in version 1.3.0.\\n\\n\\nNote\\nOnly takes effect for Tick-frequencies (i.e. fixed frequencies like\\ndays, hours, and minutes, rather than months or quarters).\\n\\n'},\n",
       "         'offset': {'type': 'string',\n",
       "          'description': 'Timedelta or str, default is None. An offset timedelta added to the origin.\\n'},\n",
       "         'group_keys': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to include the group keys in the result index when using\\n.apply() on the resampled object.\\n\\nNew in version 1.5.0: Not specifying group_keys will retain values-dependent behavior\\nfrom pandas 1.4 and earlier (see pandas 1.5.0 Release notes for examples).\\n\\n\\nChanged in version 2.0.0: group_keys now defaults to False.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.tz_localize(tz[,\\xa0axis,\\xa0level,\\xa0copy,\\xa0...])',\n",
       "      'func_desc': 'Localize tz-naive index of a Series or DataFrame to target time zone.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.tz_localize.html#pandas.Series.tz_localize',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.tz_localize',\n",
       "       'full_function': \"Series.tz_localize(tz, axis=0, level=None, copy=None, ambiguous='raise', nonexistent='raise')\",\n",
       "       'function_text': 'Localize tz-naive index of a Series or DataFrame to target time zone. This operation localizes the Index. To localize the values in a\\ntimezone-naive Series, use Series.dt.tz_localize().',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.between_time(start_time,\\xa0end_time[,\\xa0...])',\n",
       "      'func_desc': 'Select values between particular times of the day (e.g., 9:00-9:30 AM).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.between_time.html#pandas.Series.between_time',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.between_time',\n",
       "       'full_function': \"Series.between_time(start_time, end_time, inclusive='both', axis=None)\",\n",
       "       'function_text': 'Select values between particular times of the day (e.g., 9:00-9:30 AM). By setting start_time to be later than end_time,\\nyou can get the times that are not between the two times.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'Accessors': [{'func_name': 'Series.str',\n",
       "      'func_desc': 'alias of StringMethods',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.str.html#pandas.Series.str',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.str',\n",
       "       'full_function': 'Series.str()',\n",
       "       'function_text': 'Vectorized string functions for Series and Index. NAs stay NA unless handled otherwise by a particular method.\\nPatterned after Python’s string methods, with some inspiration from\\nR’s stringr package. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.dt',\n",
       "      'func_desc': 'alias of CombinedDatetimelikeProperties',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.html#pandas.Series.dt',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.dt',\n",
       "       'full_function': 'Series.dt()',\n",
       "       'function_text': 'Accessor object for datetimelike properties of the Series values. Examples Returns a Series indexed like the original Series.\\nRaises TypeError if the Series does not contain datetimelike values.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.sparse',\n",
       "      'func_desc': 'alias of SparseFrameAccessor',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sparse.html#pandas.DataFrame.sparse',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.sparse',\n",
       "       'full_function': 'DataFrame.sparse()',\n",
       "       'function_text': 'DataFrame accessor for sparse data. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.cat',\n",
       "      'func_desc': 'alias of CategoricalAccessor',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.html#pandas.Series.cat',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.cat',\n",
       "       'full_function': 'Series.cat()',\n",
       "       'function_text': 'Accessor object for categorical properties of the Series values.',\n",
       "       'parameter_names_desc': [{'param_name': 'data',\n",
       "         'param_type': 'Series or CategoricalIndex',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.Series.cat',\n",
       "       'descriptions': 'Accessor object for categorical properties of the Series values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'data': {'type': 'Series or CategoricalIndex',\n",
       "          'description': 'Series or CategoricalIndex. '}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.sparse',\n",
       "      'func_desc': 'alias of SparseAccessor',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.html#pandas.Series.sparse',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.sparse',\n",
       "       'full_function': 'Series.sparse()',\n",
       "       'function_text': 'Accessor for SparseSparse from other sparse matrix data types. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.str',\n",
       "      'func_desc': 'alias of StringMethods',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.str.html#pandas.Index.str',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.str',\n",
       "       'full_function': 'Index.str()',\n",
       "       'function_text': 'Vectorized string functions for Series and Index. NAs stay NA unless handled otherwise by a particular method.\\nPatterned after Python’s string methods, with some inspiration from\\nR’s stringr package. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Datetime, Timedelta, Period',\n",
       "      'func_desc': 'dt',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/#api-series-dt',\n",
       "      'function_definitions': {'function_name': '',\n",
       "       'full_function': '',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Categorical',\n",
       "      'func_desc': 'cat',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/#api-series-cat',\n",
       "      'function_definitions': {'function_name': '',\n",
       "       'full_function': '',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.dt.time',\n",
       "      'func_desc': 'Returns numpy array of datetime.time objects.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.time.html#pandas.Series.dt.time',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.dt.time',\n",
       "       'full_function': 'Series.dt.time',\n",
       "       'function_text': 'Returns numpy array of datetime.time objects. The time part of the Timestamps. Examples For Series: For DatetimeIndex:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.dt.year',\n",
       "      'func_desc': 'The year of the datetime.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.year.html#pandas.Series.dt.year',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.dt.year',\n",
       "       'full_function': 'Series.dt.year',\n",
       "       'function_text': 'The year of the datetime. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.dt.day',\n",
       "      'func_desc': 'The day of the datetime.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.day.html#pandas.Series.dt.day',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.dt.day',\n",
       "       'full_function': 'Series.dt.day',\n",
       "       'function_text': 'The day of the datetime. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.dt.minute',\n",
       "      'func_desc': 'The minutes of the datetime.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.minute.html#pandas.Series.dt.minute',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.dt.minute',\n",
       "       'full_function': 'Series.dt.minute',\n",
       "       'function_text': 'The minutes of the datetime. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.dt.microsecond',\n",
       "      'func_desc': 'The microseconds of the datetime.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.microsecond.html#pandas.Series.dt.microsecond',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.dt.microsecond',\n",
       "       'full_function': 'Series.dt.microsecond',\n",
       "       'function_text': 'The microseconds of the datetime. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.dt.dayofweek',\n",
       "      'func_desc': 'The day of the week with Monday=0, Sunday=6.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.dayofweek.html#pandas.Series.dt.dayofweek',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.dt.dayofweek',\n",
       "       'full_function': 'Series.dt.dayofweek',\n",
       "       'function_text': 'The day of the week with Monday=0, Sunday=6. Return the day of the week. It is assumed the week starts on\\nMonday, which is denoted by 0 and ends on Sunday which is denoted\\nby 6. This method is available on both Series with datetime\\nvalues (using the dt accessor) or DatetimeIndex.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.dt.weekday',\n",
       "      'func_desc': 'The day of the week with Monday=0, Sunday=6.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.weekday.html#pandas.Series.dt.weekday',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.dt.weekday',\n",
       "       'full_function': 'Series.dt.weekday',\n",
       "       'function_text': 'The day of the week with Monday=0, Sunday=6. Return the day of the week. It is assumed the week starts on\\nMonday, which is denoted by 0 and ends on Sunday which is denoted\\nby 6. This method is available on both Series with datetime\\nvalues (using the dt accessor) or DatetimeIndex.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.dt.day_of_year',\n",
       "      'func_desc': 'The ordinal day of the year.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.day_of_year.html#pandas.Series.dt.day_of_year',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.dt.day_of_year',\n",
       "       'full_function': 'Series.dt.day_of_year',\n",
       "       'function_text': 'The ordinal day of the year. Examples For Series: For DatetimeIndex:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.dt.quarter',\n",
       "      'func_desc': 'The quarter of the date.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.quarter.html#pandas.Series.dt.quarter',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.dt.quarter',\n",
       "       'full_function': 'Series.dt.quarter',\n",
       "       'function_text': 'The quarter of the date. Examples For Series: For DatetimeIndex:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.dt.is_month_end',\n",
       "      'func_desc': 'Indicates whether the date is the last day of the month.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_month_end.html#pandas.Series.dt.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.dt.is_month_end',\n",
       "       'full_function': 'Series.dt.is_month_end',\n",
       "       'function_text': 'Indicates whether the date is the last day of the month.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.dt.is_quarter_end',\n",
       "      'func_desc': 'Indicator for whether the date is the last day of a quarter.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_quarter_end.html#pandas.Series.dt.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.dt.is_quarter_end',\n",
       "       'full_function': 'Series.dt.is_quarter_end',\n",
       "       'function_text': 'Indicator for whether the date is the last day of a quarter.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.dt.is_year_end',\n",
       "      'func_desc': 'Indicate whether the date is the last day of the year.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_year_end.html#pandas.Series.dt.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.dt.is_year_end',\n",
       "       'full_function': 'Series.dt.is_year_end',\n",
       "       'function_text': 'Indicate whether the date is the last day of the year.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.dt.daysinmonth',\n",
       "      'func_desc': 'The number of days in the month.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.daysinmonth.html#pandas.Series.dt.daysinmonth',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.dt.daysinmonth',\n",
       "       'full_function': 'Series.dt.daysinmonth',\n",
       "       'function_text': 'The number of days in the month. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.dt.tz',\n",
       "      'func_desc': 'Return the timezone.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.tz.html#pandas.Series.dt.tz',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.dt.tz',\n",
       "       'full_function': 'Series.dt.tz',\n",
       "       'function_text': 'Return the timezone.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.dt.unit',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.unit.html#pandas.Series.dt.unit',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.dt.unit',\n",
       "       'full_function': 'Series.dt.unit',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.dt.to_period(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Cast to PeriodArray/PeriodIndex at a particular frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.to_period.html#pandas.Series.dt.to_period',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.dt.to_period',\n",
       "       'full_function': 'Series.dt.to_period(*args, **kwargs)',\n",
       "       'function_text': 'Cast to PeriodArray/PeriodIndex at a particular frequency. Converts DatetimeArray/Index to PeriodArray/PeriodIndex.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.dt.tz_localize(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Localize tz-naive Datetime Array/Index to tz-aware Datetime Array/Index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.tz_localize.html#pandas.Series.dt.tz_localize',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.dt.tz_localize',\n",
       "       'full_function': 'Series.dt.tz_localize(*args, **kwargs)',\n",
       "       'function_text': 'Localize tz-naive Datetime Array/Index to tz-aware Datetime Array/Index. This method takes a time zone (tz) naive Datetime Array/Index object\\nand makes this time zone aware. It does not move the time to another\\ntime zone. This method can also be used to do the inverse – to create a time\\nzone unaware object from an aware object. To that end, pass tz=None.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.dt.normalize(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Convert times to midnight.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.normalize.html#pandas.Series.dt.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.dt.normalize',\n",
       "       'full_function': 'Series.dt.normalize(*args, **kwargs)',\n",
       "       'function_text': 'Convert times to midnight. The time component of the date-time is converted to midnight i.e.\\n00:00:00. This is useful in cases, when the time does not matter.\\nLength is unaltered. The timezones are unaffected. This method is available on Series with datetime values under\\nthe .dt accessor, and directly on Datetime Array/Index.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.dt.round(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Perform round operation on the data to the specified freq.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.round.html#pandas.Series.dt.round',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.dt.round',\n",
       "       'full_function': 'Series.dt.round(*args, **kwargs)',\n",
       "       'function_text': 'Perform round operation on the data to the specified freq.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.dt.ceil(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Perform ceil operation on the data to the specified freq.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.ceil.html#pandas.Series.dt.ceil',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.dt.ceil',\n",
       "       'full_function': 'Series.dt.ceil(*args, **kwargs)',\n",
       "       'function_text': 'Perform ceil operation on the data to the specified freq.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.dt.day_name(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Return the day names with specified locale.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.day_name.html#pandas.Series.dt.day_name',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.dt.day_name',\n",
       "       'full_function': 'Series.dt.day_name(*args, **kwargs)',\n",
       "       'function_text': 'Return the day names with specified locale.',\n",
       "       'parameter_names_desc': [{'param_name': 'locale',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': \"Locale determining the language in which to return the day name.\\nDefault is English locale ('en_US.utf8'). Use the command\\nlocale -a on your terminal on Unix systems to find your locale\\nlanguage code.\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.Series.dt.day_name',\n",
       "       'descriptions': 'Return the day names with specified locale.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'locale': {'type': 'string',\n",
       "          'description': \"str, optional. Locale determining the language in which to return the day name.\\nDefault is English locale ('en_US.utf8'). Use the command\\nlocale -a on your terminal on Unix systems to find your locale\\nlanguage code.\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.dt.start_time',\n",
       "      'func_desc': 'Get the Timestamp for the start of the period.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.start_time.html#pandas.Series.dt.start_time',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.dt.start_time',\n",
       "       'full_function': 'Series.dt.start_time',\n",
       "       'function_text': 'Get the Timestamp for the start of the period.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.dt.seconds',\n",
       "      'func_desc': 'Number of seconds (>= 0 and less than 1 day) for each element.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.seconds.html#pandas.Series.dt.seconds',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.dt.seconds',\n",
       "       'full_function': 'Series.dt.seconds',\n",
       "       'function_text': 'Number of seconds (>= 0 and less than 1 day) for each element. Examples For Series: For TimedeltaIndex:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.dt.nanoseconds',\n",
       "      'func_desc': 'Number of nanoseconds (>= 0 and less than 1 microsecond) for each element.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.nanoseconds.html#pandas.Series.dt.nanoseconds',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.dt.nanoseconds',\n",
       "       'full_function': 'Series.dt.nanoseconds',\n",
       "       'function_text': 'Number of nanoseconds (>= 0 and less than 1 microsecond) for each element. Examples For Series: For TimedeltaIndex:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.dt.unit',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.unit.html#pandas.Series.dt.unit',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.dt.unit',\n",
       "       'full_function': 'Series.dt.unit',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.dt.total_seconds(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Return total duration of each element expressed in seconds.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.total_seconds.html#pandas.Series.dt.total_seconds',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.dt.total_seconds',\n",
       "       'full_function': 'Series.dt.total_seconds(*args, **kwargs)',\n",
       "       'function_text': 'Return total duration of each element expressed in seconds. This method is available directly on TimedeltaArray, TimedeltaIndex\\nand on Series containing timedelta values under the .dt namespace.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.str.casefold()',\n",
       "      'func_desc': 'Convert strings in the Series/Index to be casefolded.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.str.casefold.html#pandas.Series.str.casefold',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.str.casefold',\n",
       "       'full_function': 'Series.str.casefold()',\n",
       "       'function_text': 'Convert strings in the Series/Index to be casefolded. Equivalent to str.casefold().',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.str.center(width[,\\xa0fillchar])',\n",
       "      'func_desc': 'Pad left and right side of strings in the Series/Index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.str.center.html#pandas.Series.str.center',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.str.center',\n",
       "       'full_function': \"Series.str.center(width, fillchar=' ')\",\n",
       "       'function_text': 'Pad left and right side of strings in the Series/Index. Equivalent to str.center().',\n",
       "       'parameter_names_desc': [{'param_name': 'width',\n",
       "         'param_type': 'int',\n",
       "         'param_desc': 'Minimum width of resulting string; additional characters will be filled\\nwith fillchar.\\n'},\n",
       "        {'param_name': 'fillchar',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'Additional character for filling, default is whitespace.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.str.center',\n",
       "       'descriptions': 'Pad left and right side of strings in the Series/Index. Equivalent to str.center().',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'width': {'type': 'integer',\n",
       "          'description': 'int. Minimum width of resulting string; additional characters will be filled\\nwith fillchar.\\n'},\n",
       "         'fillchar': {'type': 'string',\n",
       "          'description': 'str. Additional character for filling, default is whitespace.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.str.count(pat[,\\xa0flags])',\n",
       "      'func_desc': 'Count occurrences of pattern in each string of the Series/Index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.str.count.html#pandas.Series.str.count',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.str.count',\n",
       "       'full_function': 'Series.str.count(pat, flags=0)',\n",
       "       'function_text': 'Count occurrences of pattern in each string of the Series/Index. This function is used to count the number of times a particular regex\\npattern is repeated in each of the string elements of the\\nSeries.',\n",
       "       'parameter_names_desc': [{'param_name': 'pat',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'Valid regular expression.\\n'},\n",
       "        {'param_name': 'flags',\n",
       "         'param_type': 'int, default 0, meaning no flags',\n",
       "         'param_desc': 'Flags for the re module. For a complete list, see here.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.str.count',\n",
       "       'descriptions': 'Count occurrences of pattern in each string of the Series/Index. This function is used to count the number of times a particular regex\\npattern is repeated in each of the string elements of the\\nSeries.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'pat': {'type': 'string',\n",
       "          'description': 'str. Valid regular expression.\\n'},\n",
       "         'flags': {'type': 'integer',\n",
       "          'description': 'int, default 0, meaning no flags. Flags for the re module. For a complete list, see here.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.str.encode(encoding[,\\xa0errors])',\n",
       "      'func_desc': 'Encode character string in the Series/Index using indicated encoding.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.str.encode.html#pandas.Series.str.encode',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.str.encode',\n",
       "       'full_function': \"Series.str.encode(encoding, errors='strict')\",\n",
       "       'function_text': 'Encode character string in the Series/Index using indicated encoding. Equivalent to str.encode().',\n",
       "       'parameter_names_desc': [{'param_name': 'encoding',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'errors',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.Series.str.encode',\n",
       "       'descriptions': 'Encode character string in the Series/Index using indicated encoding. Equivalent to str.encode().',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'encoding': {'type': 'string', 'description': 'str. '},\n",
       "         'errors': {'type': 'string', 'description': 'str, optional. '}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.str.extract(pat[,\\xa0flags,\\xa0expand])',\n",
       "      'func_desc': 'Extract capture groups in the regex pat as columns in a DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.str.extract.html#pandas.Series.str.extract',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.str.extract',\n",
       "       'full_function': 'Series.str.extract(pat, flags=0, expand=True)',\n",
       "       'function_text': 'Extract capture groups in the regex pat as columns in a DataFrame. For each subject string in the Series, extract groups from the\\nfirst match of regular expression pat.',\n",
       "       'parameter_names_desc': [{'param_name': 'pat',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'Regular expression pattern with capturing groups.\\n'},\n",
       "        {'param_name': 'flags',\n",
       "         'param_type': 'int, default 0 (no flags)',\n",
       "         'param_desc': 'Flags from the re module, e.g. re.IGNORECASE, that\\nmodify regular expression matching for things like case,\\nspaces, etc. For more details, see re.\\n'},\n",
       "        {'param_name': 'expand',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If True, return DataFrame with one column per capture group.\\nIf False, return a Series/Index if there is one capture group\\nor DataFrame if there are multiple capture groups.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.str.extract',\n",
       "       'descriptions': 'Extract capture groups in the regex pat as columns in a DataFrame. For each subject string in the Series, extract groups from the\\nfirst match of regular expression pat.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'pat': {'type': 'string',\n",
       "          'description': 'str. Regular expression pattern with capturing groups.\\n'},\n",
       "         'flags': {'type': 'integer',\n",
       "          'description': 'int, default 0 (no flags). Flags from the re module, e.g. re.IGNORECASE, that\\nmodify regular expression matching for things like case,\\nspaces, etc. For more details, see re.\\n'},\n",
       "         'expand': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If True, return DataFrame with one column per capture group.\\nIf False, return a Series/Index if there is one capture group\\nor DataFrame if there are multiple capture groups.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.str.find(sub[,\\xa0start,\\xa0end])',\n",
       "      'func_desc': 'Return lowest indexes in each strings in the Series/Index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.str.find.html#pandas.Series.str.find',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.str.find',\n",
       "       'full_function': 'Series.str.find(sub, start=0, end=None)',\n",
       "       'function_text': 'Return lowest indexes in each strings in the Series/Index. Each of returned indexes corresponds to the position where the\\nsubstring is fully contained between [start:end]. Return -1 on\\nfailure. Equivalent to standard str.find().',\n",
       "       'parameter_names_desc': [{'param_name': 'sub',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'Substring being searched.\\n'},\n",
       "        {'param_name': 'start',\n",
       "         'param_type': 'int',\n",
       "         'param_desc': 'Left edge index.\\n'},\n",
       "        {'param_name': 'end',\n",
       "         'param_type': 'int',\n",
       "         'param_desc': 'Right edge index.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.str.find',\n",
       "       'descriptions': 'Return lowest indexes in each strings in the Series/Index. Each of returned indexes corresponds to the position where the\\nsubstring is fully contained between [start:end]. Return -1 on\\nfailure. Equivalent to standard str.find().',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'sub': {'type': 'string',\n",
       "          'description': 'str. Substring being searched.\\n'},\n",
       "         'start': {'type': 'integer',\n",
       "          'description': 'int. Left edge index.\\n'},\n",
       "         'end': {'type': 'integer',\n",
       "          'description': 'int. Right edge index.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.str.fullmatch(pat[,\\xa0case,\\xa0flags,\\xa0na])',\n",
       "      'func_desc': 'Determine if each string entirely matches a regular expression.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.str.fullmatch.html#pandas.Series.str.fullmatch',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.str.fullmatch',\n",
       "       'full_function': 'Series.str.fullmatch(pat, case=True, flags=0, na=None)',\n",
       "       'function_text': 'Determine if each string entirely matches a regular expression.',\n",
       "       'parameter_names_desc': [{'param_name': 'pat',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'Character sequence or regular expression.\\n'},\n",
       "        {'param_name': 'case',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If True, case sensitive.\\n'},\n",
       "        {'param_name': 'flags',\n",
       "         'param_type': 'int, default 0 (no flags)',\n",
       "         'param_desc': 'Regex module flags, e.g. re.IGNORECASE.\\n'},\n",
       "        {'param_name': 'na',\n",
       "         'param_type': 'scalar, optional',\n",
       "         'param_desc': 'Fill value for missing values. The default depends on dtype of the\\narray. For object-dtype, numpy.nan is used. For StringDtype,\\npandas.NA is used.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.str.fullmatch',\n",
       "       'descriptions': 'Determine if each string entirely matches a regular expression.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'pat': {'type': 'string',\n",
       "          'description': 'str. Character sequence or regular expression.\\n'},\n",
       "         'case': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If True, case sensitive.\\n'},\n",
       "         'flags': {'type': 'integer',\n",
       "          'description': 'int, default 0 (no flags). Regex module flags, e.g. re.IGNORECASE.\\n'},\n",
       "         'na': {'type': 'scalar, optional',\n",
       "          'description': 'scalar, optional. Fill value for missing values. The default depends on dtype of the\\narray. For object-dtype, numpy.nan is used. For StringDtype,\\npandas.NA is used.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.str.index(sub[,\\xa0start,\\xa0end])',\n",
       "      'func_desc': 'Return lowest indexes in each string in Series/Index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.str.index.html#pandas.Series.str.index',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.str.index',\n",
       "       'full_function': 'Series.str.index(sub, start=0, end=None)',\n",
       "       'function_text': 'Return lowest indexes in each string in Series/Index. Each of the returned indexes corresponds to the position where the\\nsubstring is fully contained between [start:end]. This is the same\\nas str.find except instead of returning -1, it raises a\\nValueError when the substring is not found. Equivalent to standard\\nstr.index.',\n",
       "       'parameter_names_desc': [{'param_name': 'sub',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'Substring being searched.\\n'},\n",
       "        {'param_name': 'start',\n",
       "         'param_type': 'int',\n",
       "         'param_desc': 'Left edge index.\\n'},\n",
       "        {'param_name': 'end',\n",
       "         'param_type': 'int',\n",
       "         'param_desc': 'Right edge index.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.str.index',\n",
       "       'descriptions': 'Return lowest indexes in each string in Series/Index. Each of the returned indexes corresponds to the position where the\\nsubstring is fully contained between [start:end]. This is the same\\nas str.find except instead of returning -1, it raises a\\nValueError when the substring is not found. Equivalent to standard\\nstr.index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'sub': {'type': 'string',\n",
       "          'description': 'str. Substring being searched.\\n'},\n",
       "         'start': {'type': 'integer',\n",
       "          'description': 'int. Left edge index.\\n'},\n",
       "         'end': {'type': 'integer',\n",
       "          'description': 'int. Right edge index.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.str.len()',\n",
       "      'func_desc': 'Compute the length of each element in the Series/Index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.str.len.html#pandas.Series.str.len',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.str.len',\n",
       "       'full_function': 'Series.str.len()',\n",
       "       'function_text': 'Compute the length of each element in the Series/Index. The element may be a sequence (such as a string, tuple or list) or a collection\\n(such as a dictionary).',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.str.lower()',\n",
       "      'func_desc': 'Convert strings in the Series/Index to lowercase.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.str.lower.html#pandas.Series.str.lower',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.str.lower',\n",
       "       'full_function': 'Series.str.lower()',\n",
       "       'function_text': 'Convert strings in the Series/Index to lowercase. Equivalent to str.lower().',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.str.match(pat[,\\xa0case,\\xa0flags,\\xa0na])',\n",
       "      'func_desc': 'Determine if each string starts with a match of a regular expression.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.str.match.html#pandas.Series.str.match',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.str.match',\n",
       "       'full_function': 'Series.str.match(pat, case=True, flags=0, na=None)',\n",
       "       'function_text': 'Determine if each string starts with a match of a regular expression.',\n",
       "       'parameter_names_desc': [{'param_name': 'pat',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'Character sequence.\\n'},\n",
       "        {'param_name': 'case',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If True, case sensitive.\\n'},\n",
       "        {'param_name': 'flags',\n",
       "         'param_type': 'int, default 0 (no flags)',\n",
       "         'param_desc': 'Regex module flags, e.g. re.IGNORECASE.\\n'},\n",
       "        {'param_name': 'na',\n",
       "         'param_type': 'scalar, optional',\n",
       "         'param_desc': 'Fill value for missing values. The default depends on dtype of the\\narray. For object-dtype, numpy.nan is used. For StringDtype,\\npandas.NA is used.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.str.match',\n",
       "       'descriptions': 'Determine if each string starts with a match of a regular expression.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'pat': {'type': 'string',\n",
       "          'description': 'str. Character sequence.\\n'},\n",
       "         'case': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If True, case sensitive.\\n'},\n",
       "         'flags': {'type': 'integer',\n",
       "          'description': 'int, default 0 (no flags). Regex module flags, e.g. re.IGNORECASE.\\n'},\n",
       "         'na': {'type': 'scalar, optional',\n",
       "          'description': 'scalar, optional. Fill value for missing values. The default depends on dtype of the\\narray. For object-dtype, numpy.nan is used. For StringDtype,\\npandas.NA is used.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.str.pad(width[,\\xa0side,\\xa0fillchar])',\n",
       "      'func_desc': 'Pad strings in the Series/Index up to width.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.str.pad.html#pandas.Series.str.pad',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.str.pad',\n",
       "       'full_function': \"Series.str.pad(width, side='left', fillchar=' ')\",\n",
       "       'function_text': 'Pad strings in the Series/Index up to width.',\n",
       "       'parameter_names_desc': [{'param_name': 'width',\n",
       "         'param_type': 'int',\n",
       "         'param_desc': 'Minimum width of resulting string; additional characters will be filled\\nwith character defined in fillchar.\\n'},\n",
       "        {'param_name': 'side',\n",
       "         'param_type': '{‘left’, ‘right’, ‘both’}, default ‘left’',\n",
       "         'param_desc': 'Side from which to fill resulting string.\\n'},\n",
       "        {'param_name': 'fillchar',\n",
       "         'param_type': 'str, default ‘ ‘',\n",
       "         'param_desc': 'Additional character for filling, default is whitespace.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.str.pad',\n",
       "       'descriptions': 'Pad strings in the Series/Index up to width.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'width': {'type': 'integer',\n",
       "          'description': 'int. Minimum width of resulting string; additional characters will be filled\\nwith character defined in fillchar.\\n'},\n",
       "         'side': {'type': 'string',\n",
       "          'enum': ['left', ' right', ' both'],\n",
       "          'description': '{‘left’, ‘right’, ‘both’}, default ‘left’. Side from which to fill resulting string.\\n'},\n",
       "         'fillchar': {'type': 'string',\n",
       "          'description': 'str, default ‘ ‘. Additional character for filling, default is whitespace.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.str.removeprefix(prefix)',\n",
       "      'func_desc': 'Remove a prefix from an object series.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.str.removeprefix.html#pandas.Series.str.removeprefix',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.str.removeprefix',\n",
       "       'full_function': 'Series.str.removeprefix(prefix)',\n",
       "       'function_text': 'Remove a prefix from an object series. If the prefix is not present, the original string will be returned.',\n",
       "       'parameter_names_desc': [{'param_name': 'prefix',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'Remove the prefix of the string.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.str.removeprefix',\n",
       "       'descriptions': 'Remove a prefix from an object series. If the prefix is not present, the original string will be returned.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'prefix': {'type': 'string',\n",
       "          'description': 'str. Remove the prefix of the string.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.str.repeat(repeats)',\n",
       "      'func_desc': 'Duplicate each string in the Series or Index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.str.repeat.html#pandas.Series.str.repeat',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.str.repeat',\n",
       "       'full_function': 'Series.str.repeat(repeats)',\n",
       "       'function_text': 'Duplicate each string in the Series or Index.',\n",
       "       'parameter_names_desc': [{'param_name': 'repeats',\n",
       "         'param_type': 'int or sequence of int',\n",
       "         'param_desc': 'Same value for all (int) or different value per (sequence).\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.str.repeat',\n",
       "       'descriptions': 'Duplicate each string in the Series or Index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'repeats': {'type': 'integer',\n",
       "          'description': 'int or sequence of int. Same value for all (int) or different value per (sequence).\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.str.rfind(sub[,\\xa0start,\\xa0end])',\n",
       "      'func_desc': 'Return highest indexes in each strings in the Series/Index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rfind.html#pandas.Series.str.rfind',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.str.rfind',\n",
       "       'full_function': 'Series.str.rfind(sub, start=0, end=None)',\n",
       "       'function_text': 'Return highest indexes in each strings in the Series/Index. Each of returned indexes corresponds to the position where the\\nsubstring is fully contained between [start:end]. Return -1 on\\nfailure. Equivalent to standard str.rfind().',\n",
       "       'parameter_names_desc': [{'param_name': 'sub',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'Substring being searched.\\n'},\n",
       "        {'param_name': 'start',\n",
       "         'param_type': 'int',\n",
       "         'param_desc': 'Left edge index.\\n'},\n",
       "        {'param_name': 'end',\n",
       "         'param_type': 'int',\n",
       "         'param_desc': 'Right edge index.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.str.rfind',\n",
       "       'descriptions': 'Return highest indexes in each strings in the Series/Index. Each of returned indexes corresponds to the position where the\\nsubstring is fully contained between [start:end]. Return -1 on\\nfailure. Equivalent to standard str.rfind().',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'sub': {'type': 'string',\n",
       "          'description': 'str. Substring being searched.\\n'},\n",
       "         'start': {'type': 'integer',\n",
       "          'description': 'int. Left edge index.\\n'},\n",
       "         'end': {'type': 'integer',\n",
       "          'description': 'int. Right edge index.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.str.rjust(width[,\\xa0fillchar])',\n",
       "      'func_desc': 'Pad left side of strings in the Series/Index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rjust.html#pandas.Series.str.rjust',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.str.rjust',\n",
       "       'full_function': \"Series.str.rjust(width, fillchar=' ')\",\n",
       "       'function_text': 'Pad left side of strings in the Series/Index. Equivalent to str.rjust().',\n",
       "       'parameter_names_desc': [{'param_name': 'width',\n",
       "         'param_type': 'int',\n",
       "         'param_desc': 'Minimum width of resulting string; additional characters will be filled\\nwith fillchar.\\n'},\n",
       "        {'param_name': 'fillchar',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'Additional character for filling, default is whitespace.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.str.rjust',\n",
       "       'descriptions': 'Pad left side of strings in the Series/Index. Equivalent to str.rjust().',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'width': {'type': 'integer',\n",
       "          'description': 'int. Minimum width of resulting string; additional characters will be filled\\nwith fillchar.\\n'},\n",
       "         'fillchar': {'type': 'string',\n",
       "          'description': 'str. Additional character for filling, default is whitespace.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.str.rstrip([to_strip])',\n",
       "      'func_desc': 'Remove trailing characters.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rstrip.html#pandas.Series.str.rstrip',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.str.rstrip',\n",
       "       'full_function': 'Series.str.rstrip(to_strip=None)',\n",
       "       'function_text': 'Remove trailing characters. Strip whitespaces (including newlines) or a set of specified characters\\nfrom each string in the Series/Index from right side.\\nReplaces any non-strings in Series with NaNs.\\nEquivalent to str.rstrip().',\n",
       "       'parameter_names_desc': [{'param_name': 'to_strip',\n",
       "         'param_type': 'str or None, default None',\n",
       "         'param_desc': 'Specifying the set of characters to be removed.\\nAll combinations of this set of characters will be stripped.\\nIf None then whitespaces are removed.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.str.rstrip',\n",
       "       'descriptions': 'Remove trailing characters. Strip whitespaces (including newlines) or a set of specified characters\\nfrom each string in the Series/Index from right side.\\nReplaces any non-strings in Series with NaNs.\\nEquivalent to str.rstrip().',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'to_strip': {'type': 'string',\n",
       "          'description': 'str or None, default None. Specifying the set of characters to be removed.\\nAll combinations of this set of characters will be stripped.\\nIf None then whitespaces are removed.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.str.slice_replace([start,\\xa0stop,\\xa0repl])',\n",
       "      'func_desc': 'Replace a positional slice of a string with another value.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.str.slice_replace.html#pandas.Series.str.slice_replace',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.str.slice_replace',\n",
       "       'full_function': 'Series.str.slice_replace(start=None, stop=None, repl=None)',\n",
       "       'function_text': 'Replace a positional slice of a string with another value.',\n",
       "       'parameter_names_desc': [{'param_name': 'start',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Left index position to use for the slice. If not specified (None),\\nthe slice is unbounded on the left, i.e. slice from the start\\nof the string.\\n'},\n",
       "        {'param_name': 'stop',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Right index position to use for the slice. If not specified (None),\\nthe slice is unbounded on the right, i.e. slice until the\\nend of the string.\\n'},\n",
       "        {'param_name': 'repl',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'String for replacement. If not specified (None), the sliced region\\nis replaced with an empty string.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.str.slice_replace',\n",
       "       'descriptions': 'Replace a positional slice of a string with another value.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'start': {'type': 'integer',\n",
       "          'description': 'int, optional. Left index position to use for the slice. If not specified (None),\\nthe slice is unbounded on the left, i.e. slice from the start\\nof the string.\\n'},\n",
       "         'stop': {'type': 'integer',\n",
       "          'description': 'int, optional. Right index position to use for the slice. If not specified (None),\\nthe slice is unbounded on the right, i.e. slice until the\\nend of the string.\\n'},\n",
       "         'repl': {'type': 'string',\n",
       "          'description': 'str, optional. String for replacement. If not specified (None), the sliced region\\nis replaced with an empty string.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.str.rsplit([pat,\\xa0n,\\xa0expand])',\n",
       "      'func_desc': 'Split strings around given separator/delimiter.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rsplit.html#pandas.Series.str.rsplit',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.str.rsplit',\n",
       "       'full_function': 'Series.str.rsplit(pat=None, *, n=-1, expand=False)',\n",
       "       'function_text': 'Split strings around given separator/delimiter. Splits the string in the Series/Index from the end,\\nat the specified delimiter string.',\n",
       "       'parameter_names_desc': [{'param_name': 'pat',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'String to split on.\\nIf not specified, split on whitespace.\\n'},\n",
       "        {'param_name': 'n',\n",
       "         'param_type': 'int, default -1 (all)',\n",
       "         'param_desc': 'Limit number of splits in output.\\nNone, 0 and -1 will be interpreted as return all splits.\\n'},\n",
       "        {'param_name': 'expand',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Expand the split strings into separate columns.\\n\\nIf True, return DataFrame/MultiIndex expanding dimensionality.\\nIf False, return Series/Index, containing lists of strings.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.str.rsplit',\n",
       "       'descriptions': 'Split strings around given separator/delimiter. Splits the string in the Series/Index from the end,\\nat the specified delimiter string.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'pat': {'type': 'string',\n",
       "          'description': 'str, optional. String to split on.\\nIf not specified, split on whitespace.\\n'},\n",
       "         'n': {'type': 'integer',\n",
       "          'description': 'int, default -1 (all). Limit number of splits in output.\\nNone, 0 and -1 will be interpreted as return all splits.\\n'},\n",
       "         'expand': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Expand the split strings into separate columns.\\n\\nIf True, return DataFrame/MultiIndex expanding dimensionality.\\nIf False, return Series/Index, containing lists of strings.\\n\\n'}},\n",
       "        'required': ['pat=None']}}},\n",
       "     {'func_name': 'Series.str.strip([to_strip])',\n",
       "      'func_desc': 'Remove leading and trailing characters.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.str.strip.html#pandas.Series.str.strip',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.str.strip',\n",
       "       'full_function': 'Series.str.strip(to_strip=None)',\n",
       "       'function_text': 'Remove leading and trailing characters. Strip whitespaces (including newlines) or a set of specified characters\\nfrom each string in the Series/Index from left and right sides.\\nReplaces any non-strings in Series with NaNs.\\nEquivalent to str.strip().',\n",
       "       'parameter_names_desc': [{'param_name': 'to_strip',\n",
       "         'param_type': 'str or None, default None',\n",
       "         'param_desc': 'Specifying the set of characters to be removed.\\nAll combinations of this set of characters will be stripped.\\nIf None then whitespaces are removed.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.str.strip',\n",
       "       'descriptions': 'Remove leading and trailing characters. Strip whitespaces (including newlines) or a set of specified characters\\nfrom each string in the Series/Index from left and right sides.\\nReplaces any non-strings in Series with NaNs.\\nEquivalent to str.strip().',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'to_strip': {'type': 'string',\n",
       "          'description': 'str or None, default None. Specifying the set of characters to be removed.\\nAll combinations of this set of characters will be stripped.\\nIf None then whitespaces are removed.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.str.title()',\n",
       "      'func_desc': 'Convert strings in the Series/Index to titlecase.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.str.title.html#pandas.Series.str.title',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.str.title',\n",
       "       'full_function': 'Series.str.title()',\n",
       "       'function_text': 'Convert strings in the Series/Index to titlecase. Equivalent to str.title().',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.str.upper()',\n",
       "      'func_desc': 'Convert strings in the Series/Index to uppercase.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.str.upper.html#pandas.Series.str.upper',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.str.upper',\n",
       "       'full_function': 'Series.str.upper()',\n",
       "       'function_text': 'Convert strings in the Series/Index to uppercase. Equivalent to str.upper().',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.str.zfill(width)',\n",
       "      'func_desc': \"Pad strings in the Series/Index by prepending '0' characters.\",\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.str.zfill.html#pandas.Series.str.zfill',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.str.zfill',\n",
       "       'full_function': 'Series.str.zfill(width)',\n",
       "       'function_text': 'Pad strings in the Series/Index by prepending ‘0’ characters. Strings in the Series/Index are padded with ‘0’ characters on the\\nleft of the string to reach a total string length width. Strings\\nin the Series/Index with length greater or equal to width are\\nunchanged.',\n",
       "       'parameter_names_desc': [{'param_name': 'width',\n",
       "         'param_type': 'int',\n",
       "         'param_desc': 'Minimum length of resulting string; strings with length less\\nthan width be prepended with ‘0’ characters.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.str.zfill',\n",
       "       'descriptions': 'Pad strings in the Series/Index by prepending ‘0’ characters. Strings in the Series/Index are padded with ‘0’ characters on the\\nleft of the string to reach a total string length width. Strings\\nin the Series/Index with length greater or equal to width are\\nunchanged.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'width': {'type': 'integer',\n",
       "          'description': 'int. Minimum length of resulting string; strings with length less\\nthan width be prepended with ‘0’ characters.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.str.isalpha()',\n",
       "      'func_desc': 'Check whether all characters in each string are alphabetic.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalpha.html#pandas.Series.str.isalpha',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.str.isalpha',\n",
       "       'full_function': 'Series.str.isalpha()',\n",
       "       'function_text': 'Check whether all characters in each string are alphabetic. This is equivalent to running the Python string method\\nstr.isalpha() for each element of the Series/Index. If a string\\nhas zero characters, False is returned for that check.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.str.isspace()',\n",
       "      'func_desc': 'Check whether all characters in each string are whitespace.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isspace.html#pandas.Series.str.isspace',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.str.isspace',\n",
       "       'full_function': 'Series.str.isspace()',\n",
       "       'function_text': 'Check whether all characters in each string are whitespace. This is equivalent to running the Python string method\\nstr.isspace() for each element of the Series/Index. If a string\\nhas zero characters, False is returned for that check.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.str.isupper()',\n",
       "      'func_desc': 'Check whether all characters in each string are uppercase.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isupper.html#pandas.Series.str.isupper',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.str.isupper',\n",
       "       'full_function': 'Series.str.isupper()',\n",
       "       'function_text': 'Check whether all characters in each string are uppercase. This is equivalent to running the Python string method\\nstr.isupper() for each element of the Series/Index. If a string\\nhas zero characters, False is returned for that check.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.str.isnumeric()',\n",
       "      'func_desc': 'Check whether all characters in each string are numeric.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isnumeric.html#pandas.Series.str.isnumeric',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.str.isnumeric',\n",
       "       'full_function': 'Series.str.isnumeric()',\n",
       "       'function_text': 'Check whether all characters in each string are numeric. This is equivalent to running the Python string method\\nstr.isnumeric() for each element of the Series/Index. If a string\\nhas zero characters, False is returned for that check.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.str.get_dummies([sep])',\n",
       "      'func_desc': 'Return DataFrame of dummy/indicator variables for Series.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.str.get_dummies.html#pandas.Series.str.get_dummies',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.str.get_dummies',\n",
       "       'full_function': \"Series.str.get_dummies(sep='|')\",\n",
       "       'function_text': 'Return DataFrame of dummy/indicator variables for Series. Each string in Series is split by sep and returned as a DataFrame\\nof dummy/indicator variables.',\n",
       "       'parameter_names_desc': [{'param_name': 'sep',\n",
       "         'param_type': 'str, default “|”',\n",
       "         'param_desc': 'String to split on.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.str.get_dummies',\n",
       "       'descriptions': 'Return DataFrame of dummy/indicator variables for Series. Each string in Series is split by sep and returned as a DataFrame\\nof dummy/indicator variables.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'sep': {'type': 'string',\n",
       "          'description': 'str, default “|”. String to split on.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.cat.ordered',\n",
       "      'func_desc': 'Whether the categories have an ordered relationship.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.ordered.html#pandas.Series.cat.ordered',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.cat.ordered',\n",
       "       'full_function': 'Series.cat.ordered',\n",
       "       'function_text': 'Whether the categories have an ordered relationship. Examples For pandas.Series: For pandas.Categorical: For pandas.CategoricalIndex:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.cat.reorder_categories(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Reorder categories as specified in new_categories.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.reorder_categories.html#pandas.Series.cat.reorder_categories',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.cat.reorder_categories',\n",
       "       'full_function': 'Series.cat.reorder_categories(*args, **kwargs)',\n",
       "       'function_text': 'Reorder categories as specified in new_categories. new_categories need to include all old categories and no new category\\nitems.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.cat.remove_categories(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Remove the specified categories.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_categories.html#pandas.Series.cat.remove_categories',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.cat.remove_categories',\n",
       "       'full_function': 'Series.cat.remove_categories(*args, **kwargs)',\n",
       "       'function_text': 'Remove the specified categories. removals must be included in the old categories. Values which were in\\nthe removed categories will be set to NaN',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.cat.set_categories(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Set the categories to the specified new categories.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.set_categories.html#pandas.Series.cat.set_categories',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.cat.set_categories',\n",
       "       'full_function': 'Series.cat.set_categories(*args, **kwargs)',\n",
       "       'function_text': 'Set the categories to the specified new categories. new_categories can include new categories (which will result in\\nunused categories) or remove old categories (which results in values\\nset to NaN). If rename=True, the categories will simply be renamed\\n(less or more items than in old categories will result in values set to\\nNaN or in unused categories respectively). This method can be used to perform more than one action of adding,\\nremoving, and reordering simultaneously and is therefore faster than\\nperforming the individual steps via the more specialised methods. On the other hand this methods does not do checks (e.g., whether the\\nold categories are included in the new categories on a reorder), which\\ncan result in surprising changes, for example when using special string\\ndtypes, which does not considers a S1 string equal to a single char\\npython string.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.cat.as_unordered(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Set the Categorical to be unordered.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.as_unordered.html#pandas.Series.cat.as_unordered',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.cat.as_unordered',\n",
       "       'full_function': 'Series.cat.as_unordered(*args, **kwargs)',\n",
       "       'function_text': 'Set the Categorical to be unordered.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.sparse.density',\n",
       "      'func_desc': 'The percent of non- fill_value points, as decimal.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.density.html#pandas.Series.sparse.density',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.sparse.density',\n",
       "       'full_function': 'Series.sparse.density',\n",
       "       'function_text': 'The percent of non- fill_value points, as decimal. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.sparse.sp_values',\n",
       "      'func_desc': 'An ndarray containing the non- fill_value values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.sp_values.html#pandas.Series.sparse.sp_values',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.sparse.sp_values',\n",
       "       'full_function': 'Series.sparse.sp_values',\n",
       "       'function_text': 'An ndarray containing the non- fill_value values. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.sparse.to_coo([row_levels,\\xa0...])',\n",
       "      'func_desc': 'Create a scipy.sparse.coo_matrix from a Series with MultiIndex.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.to_coo.html#pandas.Series.sparse.to_coo',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.sparse.to_coo',\n",
       "       'full_function': 'Series.sparse.to_coo(row_levels=(0,), column_levels=(1,), sort_labels=False)',\n",
       "       'function_text': 'Create a scipy.sparse.coo_matrix from a Series with MultiIndex. Use row_levels and column_levels to determine the row and column\\ncoordinates respectively. row_levels and column_levels are the names\\n(labels) or numbers of the levels. {row_levels, column_levels} must be\\na partition of the MultiIndex level names (or numbers).',\n",
       "       'parameter_names_desc': [{'param_name': 'row_levels',\n",
       "         'param_type': 'tuple/list',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'column_levels',\n",
       "         'param_type': 'tuple/list',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'sort_labels',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Sort the row and column labels before forming the sparse matrix.\\nWhen row_levels and/or column_levels refer to a single level,\\nset to True for a faster execution.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.sparse.to_coo',\n",
       "       'descriptions': 'Create a scipy.sparse.coo_matrix from a Series with MultiIndex. Use row_levels and column_levels to determine the row and column\\ncoordinates respectively. row_levels and column_levels are the names\\n(labels) or numbers of the levels. {row_levels, column_levels} must be\\na partition of the MultiIndex level names (or numbers).',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'row_levels': {'type': 'array',\n",
       "          'description': 'tuple/list. '},\n",
       "         'column_levels': {'type': 'array', 'description': 'tuple/list. '},\n",
       "         'sort_labels': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Sort the row and column labels before forming the sparse matrix.\\nWhen row_levels and/or column_levels refer to a single level,\\nset to True for a faster execution.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.list.len()',\n",
       "      'func_desc': 'Return the length of each list in the Series.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.list.len.html#pandas.Series.list.len',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.list.len',\n",
       "       'full_function': 'Series.list.len()',\n",
       "       'function_text': 'Return the length of each list in the Series.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.struct.explode()',\n",
       "      'func_desc': 'Extract all child fields of a struct as a DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.struct.explode.html#pandas.Series.struct.explode',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.struct.explode',\n",
       "       'full_function': 'Series.struct.explode()',\n",
       "       'function_text': 'Extract all child fields of a struct as a DataFrame.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'Plotting': [{'func_name': 'Series.plot([kind,\\xa0ax,\\xa0figsize,\\xa0....])',\n",
       "      'func_desc': 'Series plotting accessor and method',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.html#pandas.Series.plot',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.plot',\n",
       "       'full_function': 'Series.plot(*args, **kwargs)',\n",
       "       'function_text': 'Make plots of Series or DataFrame. Uses the backend specified by the\\noption plotting.backend. By default, matplotlib is used.',\n",
       "       'parameter_names_desc': [{'param_name': 'data',\n",
       "         'param_type': 'Series or DataFrame',\n",
       "         'param_desc': 'The object for which the method is called.\\n'},\n",
       "        {'param_name': 'x',\n",
       "         'param_type': 'label or position, default None',\n",
       "         'param_desc': 'Only used if data is a DataFrame.\\n'},\n",
       "        {'param_name': 'y',\n",
       "         'param_type': 'label, position or list of label, positions, default None',\n",
       "         'param_desc': 'Allows plotting of one column versus another. Only used if data is a\\nDataFrame.\\n'},\n",
       "        {'param_name': 'kind',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'The kind of plot to produce:\\n\\n‘line’ : line plot (default)\\n‘bar’ : vertical bar plot\\n‘barh’ : horizontal bar plot\\n‘hist’ : histogram\\n‘box’ : boxplot\\n‘kde’ : Kernel Density Estimation plot\\n‘density’ : same as ‘kde’\\n‘area’ : area plot\\n‘pie’ : pie plot\\n‘scatter’ : scatter plot (DataFrame only)\\n‘hexbin’ : hexbin plot (DataFrame only)\\n\\n'},\n",
       "        {'param_name': 'ax',\n",
       "         'param_type': 'matplotlib axes object, default None',\n",
       "         'param_desc': 'An axes of the current figure.\\n'},\n",
       "        {'param_name': 'subplots',\n",
       "         'param_type': 'bool or sequence of iterables, default False',\n",
       "         'param_desc': 'Whether to group columns into subplots:\\n\\nFalse : No subplots will be used\\nTrue : Make separate subplots for each column.\\nsequence of iterables of column labels: Create a subplot for each\\ngroup of columns. For example [(‘a’, ‘c’), (‘b’, ‘d’)] will\\ncreate 2 subplots: one with columns ‘a’ and ‘c’, and one\\nwith columns ‘b’ and ‘d’. Remaining columns that aren’t specified\\nwill be plotted in additional subplots (one per column).\\n\\nNew in version 1.5.0.\\n\\n\\n\\n'},\n",
       "        {'param_name': 'sharex',\n",
       "         'param_type': 'bool, default True if ax is None else False',\n",
       "         'param_desc': 'In case subplots=True, share x axis and set some x axis labels\\nto invisible; defaults to True if ax is None otherwise False if\\nan ax is passed in; Be aware, that passing in both an ax and\\nsharex=True will alter all x axis labels for all axis in a figure.\\n'},\n",
       "        {'param_name': 'sharey',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'In case subplots=True, share y axis and set some y axis labels to invisible.\\n'},\n",
       "        {'param_name': 'layout',\n",
       "         'param_type': 'tuple, optional',\n",
       "         'param_desc': '(rows, columns) for the layout of subplots.\\n'},\n",
       "        {'param_name': 'figsize',\n",
       "         'param_type': 'a tuple (width, height) in inches',\n",
       "         'param_desc': 'Size of a figure object.\\n'},\n",
       "        {'param_name': 'use_index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Use index as ticks for x axis.\\n'},\n",
       "        {'param_name': 'title',\n",
       "         'param_type': 'str or list',\n",
       "         'param_desc': 'Title to use for the plot. If a string is passed, print the string\\nat the top of the figure. If a list is passed and subplots is\\nTrue, print each item in the list above the corresponding subplot.\\n'},\n",
       "        {'param_name': 'grid',\n",
       "         'param_type': 'bool, default None (matlab style default)',\n",
       "         'param_desc': 'Axis grid lines.\\n'},\n",
       "        {'param_name': 'legend',\n",
       "         'param_type': 'bool or {‘reverse’}',\n",
       "         'param_desc': 'Place legend on axis subplots.\\n'},\n",
       "        {'param_name': 'style',\n",
       "         'param_type': 'list or dict',\n",
       "         'param_desc': 'The matplotlib line style per column.\\n'},\n",
       "        {'param_name': 'logx',\n",
       "         'param_type': 'bool or ‘sym’, default False',\n",
       "         'param_desc': 'Use log scaling or symlog scaling on x axis.\\n'},\n",
       "        {'param_name': 'logy',\n",
       "         'param_type': 'bool or ‘sym’ default False',\n",
       "         'param_desc': 'Use log scaling or symlog scaling on y axis.\\n'},\n",
       "        {'param_name': 'loglog',\n",
       "         'param_type': 'bool or ‘sym’, default False',\n",
       "         'param_desc': 'Use log scaling or symlog scaling on both x and y axes.\\n'},\n",
       "        {'param_name': 'xticks',\n",
       "         'param_type': 'sequence',\n",
       "         'param_desc': 'Values to use for the xticks.\\n'},\n",
       "        {'param_name': 'yticks',\n",
       "         'param_type': 'sequence',\n",
       "         'param_desc': 'Values to use for the yticks.\\n'},\n",
       "        {'param_name': 'xlim',\n",
       "         'param_type': '2-tuple/list',\n",
       "         'param_desc': 'Set the x limits of the current axes.\\n'},\n",
       "        {'param_name': 'ylim',\n",
       "         'param_type': '2-tuple/list',\n",
       "         'param_desc': 'Set the y limits of the current axes.\\n'},\n",
       "        {'param_name': 'xlabel',\n",
       "         'param_type': 'label, optional',\n",
       "         'param_desc': 'Name to use for the xlabel on x-axis. Default uses index name as xlabel, or the\\nx-column name for planar plots.\\n\\nChanged in version 2.0.0: Now applicable to histograms.\\n\\n'},\n",
       "        {'param_name': 'ylabel',\n",
       "         'param_type': 'label, optional',\n",
       "         'param_desc': 'Name to use for the ylabel on y-axis. Default will show no ylabel, or the\\ny-column name for planar plots.\\n\\nChanged in version 2.0.0: Now applicable to histograms.\\n\\n'},\n",
       "        {'param_name': 'rot',\n",
       "         'param_type': 'float, default None',\n",
       "         'param_desc': 'Rotation for ticks (xticks for vertical, yticks for horizontal\\nplots).\\n'},\n",
       "        {'param_name': 'fontsize',\n",
       "         'param_type': 'float, default None',\n",
       "         'param_desc': 'Font size for xticks and yticks.\\n'},\n",
       "        {'param_name': 'colormap',\n",
       "         'param_type': 'str or matplotlib colormap object, default None',\n",
       "         'param_desc': 'Colormap to select colors from. If string, load colormap with that\\nname from matplotlib.\\n'},\n",
       "        {'param_name': 'colorbar',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'If True, plot colorbar (only relevant for ‘scatter’ and ‘hexbin’\\nplots).\\n'},\n",
       "        {'param_name': 'position',\n",
       "         'param_type': 'float',\n",
       "         'param_desc': 'Specify relative alignments for bar plot layout.\\nFrom 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\\n(center).\\n'},\n",
       "        {'param_name': 'table',\n",
       "         'param_type': 'bool, Series or DataFrame, default False',\n",
       "         'param_desc': 'If True, draw a table using the data in the DataFrame and the data\\nwill be transposed to meet matplotlib’s default layout.\\nIf a Series or DataFrame is passed, use passed data to draw a\\ntable.\\n'},\n",
       "        {'param_name': 'yerr',\n",
       "         'param_type': 'DataFrame, Series, array-like, dict and str',\n",
       "         'param_desc': 'See Plotting with Error Bars for\\ndetail.\\n'},\n",
       "        {'param_name': 'xerr',\n",
       "         'param_type': 'DataFrame, Series, array-like, dict and str',\n",
       "         'param_desc': 'Equivalent to yerr.\\n'},\n",
       "        {'param_name': 'stacked',\n",
       "         'param_type': 'bool, default False in line and bar plots, and True in area plot',\n",
       "         'param_desc': 'If True, create stacked plot.\\n'},\n",
       "        {'param_name': 'secondary_y',\n",
       "         'param_type': 'bool or sequence, default False',\n",
       "         'param_desc': 'Whether to plot on the secondary y-axis if a list/tuple, which\\ncolumns to plot on secondary y-axis.\\n'},\n",
       "        {'param_name': 'mark_right',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'When using a secondary_y axis, automatically mark the column\\nlabels with “(right)” in the legend.\\n'},\n",
       "        {'param_name': 'include_bool',\n",
       "         'param_type': 'bool, default is False',\n",
       "         'param_desc': 'If True, boolean values can be plotted.\\n'},\n",
       "        {'param_name': 'backend',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'Backend to use instead of the backend specified in the option\\nplotting.backend. For instance, ‘matplotlib’. Alternatively, to\\nspecify the plotting.backend for the whole session, set\\npd.options.plotting.backend.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.plot',\n",
       "       'descriptions': 'Make plots of Series or DataFrame. Uses the backend specified by the\\noption plotting.backend. By default, matplotlib is used.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'data': {'type': 'Series or DataFrame',\n",
       "          'description': 'Series or DataFrame. The object for which the method is called.\\n'},\n",
       "         'x': {'type': 'label or position, default None',\n",
       "          'description': 'label or position, default None. Only used if data is a DataFrame.\\n'},\n",
       "         'y': {'type': 'array',\n",
       "          'description': 'label, position or list of label, positions, default None. Allows plotting of one column versus another. Only used if data is a\\nDataFrame.\\n'},\n",
       "         'kind': {'type': 'string',\n",
       "          'description': 'str. The kind of plot to produce:\\n\\n‘line’ : line plot (default)\\n‘bar’ : vertical bar plot\\n‘barh’ : horizontal bar plot\\n‘hist’ : histogram\\n‘box’ : boxplot\\n‘kde’ : Kernel Density Estimation plot\\n‘density’ : same as ‘kde’\\n‘area’ : area plot\\n‘pie’ : pie plot\\n‘scatter’ : scatter plot (DataFrame only)\\n‘hexbin’ : hexbin plot (DataFrame only)\\n\\n'},\n",
       "         'ax': {'type': 'object',\n",
       "          'description': 'matplotlib axes object, default None. An axes of the current figure.\\n'},\n",
       "         'subplots': {'type': 'boolean',\n",
       "          'description': 'bool or sequence of iterables, default False. Whether to group columns into subplots:\\n\\nFalse : No subplots will be used\\nTrue : Make separate subplots for each column.\\nsequence of iterables of column labels: Create a subplot for each\\ngroup of columns. For example [(‘a’, ‘c’), (‘b’, ‘d’)] will\\ncreate 2 subplots: one with columns ‘a’ and ‘c’, and one\\nwith columns ‘b’ and ‘d’. Remaining columns that aren’t specified\\nwill be plotted in additional subplots (one per column).\\n\\nNew in version 1.5.0.\\n\\n\\n\\n'},\n",
       "         'sharex': {'type': 'boolean',\n",
       "          'description': 'bool, default True if ax is None else False. In case subplots=True, share x axis and set some x axis labels\\nto invisible; defaults to True if ax is None otherwise False if\\nan ax is passed in; Be aware, that passing in both an ax and\\nsharex=True will alter all x axis labels for all axis in a figure.\\n'},\n",
       "         'sharey': {'type': 'boolean',\n",
       "          'description': 'bool, default False. In case subplots=True, share y axis and set some y axis labels to invisible.\\n'},\n",
       "         'layout': {'type': 'tuple, optional',\n",
       "          'description': 'tuple, optional. (rows, columns) for the layout of subplots.\\n'},\n",
       "         'figsize': {'type': 'a tuple (width, height) in inches',\n",
       "          'description': 'a tuple (width, height) in inches. Size of a figure object.\\n'},\n",
       "         'use_index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Use index as ticks for x axis.\\n'},\n",
       "         'title': {'type': 'string',\n",
       "          'description': 'str or list. Title to use for the plot. If a string is passed, print the string\\nat the top of the figure. If a list is passed and subplots is\\nTrue, print each item in the list above the corresponding subplot.\\n'},\n",
       "         'grid': {'type': 'boolean',\n",
       "          'description': 'bool, default None (matlab style default). Axis grid lines.\\n'},\n",
       "         'legend': {'type': 'boolean',\n",
       "          'description': 'bool or {‘reverse’}. Place legend on axis subplots.\\n'},\n",
       "         'style': {'type': 'array',\n",
       "          'description': 'list or dict. The matplotlib line style per column.\\n'},\n",
       "         'logx': {'type': 'boolean',\n",
       "          'description': 'bool or ‘sym’, default False. Use log scaling or symlog scaling on x axis.\\n'},\n",
       "         'logy': {'type': 'boolean',\n",
       "          'description': 'bool or ‘sym’ default False. Use log scaling or symlog scaling on y axis.\\n'},\n",
       "         'loglog': {'type': 'boolean',\n",
       "          'description': 'bool or ‘sym’, default False. Use log scaling or symlog scaling on both x and y axes.\\n'},\n",
       "         'xticks': {'type': 'sequence',\n",
       "          'description': 'sequence. Values to use for the xticks.\\n'},\n",
       "         'yticks': {'type': 'sequence',\n",
       "          'description': 'sequence. Values to use for the yticks.\\n'},\n",
       "         'xlim': {'type': 'array',\n",
       "          'description': '2-tuple/list. Set the x limits of the current axes.\\n'},\n",
       "         'ylim': {'type': 'array',\n",
       "          'description': '2-tuple/list. Set the y limits of the current axes.\\n'},\n",
       "         'xlabel': {'type': 'label, optional',\n",
       "          'description': 'label, optional. Name to use for the xlabel on x-axis. Default uses index name as xlabel, or the\\nx-column name for planar plots.\\n\\nChanged in version 2.0.0: Now applicable to histograms.\\n\\n'},\n",
       "         'ylabel': {'type': 'label, optional',\n",
       "          'description': 'label, optional. Name to use for the ylabel on y-axis. Default will show no ylabel, or the\\ny-column name for planar plots.\\n\\nChanged in version 2.0.0: Now applicable to histograms.\\n\\n'},\n",
       "         'rot': {'type': 'float',\n",
       "          'description': 'float, default None. Rotation for ticks (xticks for vertical, yticks for horizontal\\nplots).\\n'},\n",
       "         'fontsize': {'type': 'float',\n",
       "          'description': 'float, default None. Font size for xticks and yticks.\\n'},\n",
       "         'colormap': {'type': 'string',\n",
       "          'description': 'str or matplotlib colormap object, default None. Colormap to select colors from. If string, load colormap with that\\nname from matplotlib.\\n'},\n",
       "         'colorbar': {'type': 'boolean',\n",
       "          'description': 'bool, optional. If True, plot colorbar (only relevant for ‘scatter’ and ‘hexbin’\\nplots).\\n'},\n",
       "         'position': {'type': 'float',\n",
       "          'description': 'float. Specify relative alignments for bar plot layout.\\nFrom 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\\n(center).\\n'},\n",
       "         'table': {'type': 'boolean',\n",
       "          'description': 'bool, Series or DataFrame, default False. If True, draw a table using the data in the DataFrame and the data\\nwill be transposed to meet matplotlib’s default layout.\\nIf a Series or DataFrame is passed, use passed data to draw a\\ntable.\\n'},\n",
       "         'yerr': {'type': 'string',\n",
       "          'description': 'DataFrame, Series, array-like, dict and str. See Plotting with Error Bars for\\ndetail.\\n'},\n",
       "         'xerr': {'type': 'string',\n",
       "          'description': 'DataFrame, Series, array-like, dict and str. Equivalent to yerr.\\n'},\n",
       "         'stacked': {'type': 'boolean',\n",
       "          'description': 'bool, default False in line and bar plots, and True in area plot. If True, create stacked plot.\\n'},\n",
       "         'secondary_y': {'type': 'boolean',\n",
       "          'description': 'bool or sequence, default False. Whether to plot on the secondary y-axis if a list/tuple, which\\ncolumns to plot on secondary y-axis.\\n'},\n",
       "         'mark_right': {'type': 'boolean',\n",
       "          'description': 'bool, default True. When using a secondary_y axis, automatically mark the column\\nlabels with “(right)” in the legend.\\n'},\n",
       "         'include_bool': {'type': 'boolean',\n",
       "          'description': 'bool, default is False. If True, boolean values can be plotted.\\n'},\n",
       "         'backend': {'type': 'string',\n",
       "          'description': 'str, default None. Backend to use instead of the backend specified in the option\\nplotting.backend. For instance, ‘matplotlib’. Alternatively, to\\nspecify the plotting.backend for the whole session, set\\npd.options.plotting.backend.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.plot.area([x,\\xa0y,\\xa0stacked])',\n",
       "      'func_desc': 'Draw a stacked area plot.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.area.html#pandas.Series.plot.area',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.plot.area',\n",
       "       'full_function': 'Series.plot.area(x=None, y=None, stacked=True, **kwargs)',\n",
       "       'function_text': 'Draw a stacked area plot. An area plot displays quantitative data visually.\\nThis function wraps the matplotlib area function.',\n",
       "       'parameter_names_desc': [{'param_name': 'x',\n",
       "         'param_type': 'label or position, optional',\n",
       "         'param_desc': 'Coordinates for the X axis. By default uses the index.\\n'},\n",
       "        {'param_name': 'y',\n",
       "         'param_type': 'label or position, optional',\n",
       "         'param_desc': 'Column to plot. By default uses all columns.\\n'},\n",
       "        {'param_name': 'stacked',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Area plots are stacked by default. Set to False to create a\\nunstacked plot.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.plot.area',\n",
       "       'descriptions': 'Draw a stacked area plot. An area plot displays quantitative data visually.\\nThis function wraps the matplotlib area function.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'x': {'type': 'label or position, optional',\n",
       "          'description': 'label or position, optional. Coordinates for the X axis. By default uses the index.\\n'},\n",
       "         'y': {'type': 'label or position, optional',\n",
       "          'description': 'label or position, optional. Column to plot. By default uses all columns.\\n'},\n",
       "         'stacked': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Area plots are stacked by default. Set to False to create a\\nunstacked plot.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.plot.barh([x,\\xa0y])',\n",
       "      'func_desc': 'Make a horizontal bar plot.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.barh.html#pandas.Series.plot.barh',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.plot.barh',\n",
       "       'full_function': 'Series.plot.barh(x=None, y=None, **kwargs)',\n",
       "       'function_text': 'Make a horizontal bar plot. A horizontal bar plot is a plot that presents quantitative data with\\nrectangular bars with lengths proportional to the values that they\\nrepresent. A bar plot shows comparisons among discrete categories. One\\naxis of the plot shows the specific categories being compared, and the\\nother axis represents a measured value.',\n",
       "       'parameter_names_desc': [{'param_name': 'x',\n",
       "         'param_type': 'label or position, optional',\n",
       "         'param_desc': 'Allows plotting of one column versus another. If not specified,\\nthe index of the DataFrame is used.\\n'},\n",
       "        {'param_name': 'y',\n",
       "         'param_type': 'label or position, optional',\n",
       "         'param_desc': 'Allows plotting of one column versus another. If not specified,\\nall numerical columns are used.\\n'},\n",
       "        {'param_name': 'color',\n",
       "         'param_type': 'str, array-like, or dict, optional',\n",
       "         'param_desc': 'The color for each of the DataFrame’s columns. Possible values are:\\n\\n\\nA single color string referred to by name, RGB or RGBA code,for instance ‘red’ or ‘#a98d19’.\\n\\n\\n\\n\\nA sequence of color strings referred to by name, RGB or RGBAcode, which will be used for each column recursively. For\\ninstance [‘green’,’yellow’] each column’s bar will be filled in\\ngreen or yellow, alternatively. If there is only a single column to\\nbe plotted, then only the first color from the color list will be\\nused.\\n\\n\\n\\n\\nA dict of the form {column namecolor}, so that each column will becolored accordingly. For example, if your columns are called a and\\nb, then passing {‘a’: ‘green’, ‘b’: ‘red’} will color bars for\\ncolumn a in green and bars for column b in red.\\n\\n\\n\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.plot.barh',\n",
       "       'descriptions': 'Make a horizontal bar plot. A horizontal bar plot is a plot that presents quantitative data with\\nrectangular bars with lengths proportional to the values that they\\nrepresent. A bar plot shows comparisons among discrete categories. One\\naxis of the plot shows the specific categories being compared, and the\\nother axis represents a measured value.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'x': {'type': 'label or position, optional',\n",
       "          'description': 'label or position, optional. Allows plotting of one column versus another. If not specified,\\nthe index of the DataFrame is used.\\n'},\n",
       "         'y': {'type': 'label or position, optional',\n",
       "          'description': 'label or position, optional. Allows plotting of one column versus another. If not specified,\\nall numerical columns are used.\\n'},\n",
       "         'color': {'type': 'string',\n",
       "          'description': 'str, array-like, or dict, optional. The color for each of the DataFrame’s columns. Possible values are:\\n\\n\\nA single color string referred to by name, RGB or RGBA code,for instance ‘red’ or ‘#a98d19’.\\n\\n\\n\\n\\nA sequence of color strings referred to by name, RGB or RGBAcode, which will be used for each column recursively. For\\ninstance [‘green’,’yellow’] each column’s bar will be filled in\\ngreen or yellow, alternatively. If there is only a single column to\\nbe plotted, then only the first color from the color list will be\\nused.\\n\\n\\n\\n\\nA dict of the form {column namecolor}, so that each column will becolored accordingly. For example, if your columns are called a and\\nb, then passing {‘a’: ‘green’, ‘b’: ‘red’} will color bars for\\ncolumn a in green and bars for column b in red.\\n\\n\\n\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.plot.density([bw_method,\\xa0ind])',\n",
       "      'func_desc': 'Generate Kernel Density Estimate plot using Gaussian kernels.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.density.html#pandas.Series.plot.density',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.plot.density',\n",
       "       'full_function': 'Series.plot.density(bw_method=None, ind=None, **kwargs)',\n",
       "       'function_text': 'Generate Kernel Density Estimate plot using Gaussian kernels. In statistics, kernel density estimation (KDE) is a non-parametric\\nway to estimate the probability density function (PDF) of a random\\nvariable. This function uses Gaussian kernels and includes automatic\\nbandwidth determination.',\n",
       "       'parameter_names_desc': [{'param_name': 'bw_method',\n",
       "         'param_type': 'str, scalar or callable, optional',\n",
       "         'param_desc': 'The method used to calculate the estimator bandwidth. This can be\\n‘scott’, ‘silverman’, a scalar constant or a callable.\\nIf None (default), ‘scott’ is used.\\nSee scipy.stats.gaussian_kde for more information.\\n'},\n",
       "        {'param_name': 'ind',\n",
       "         'param_type': 'NumPy array or int, optional',\n",
       "         'param_desc': 'Evaluation points for the estimated PDF. If None (default),\\n1000 equally spaced points are used. If ind is a NumPy array, the\\nKDE is evaluated at the points passed. If ind is an integer,\\nind number of equally spaced points are used.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.plot.density',\n",
       "       'descriptions': 'Generate Kernel Density Estimate plot using Gaussian kernels. In statistics, kernel density estimation (KDE) is a non-parametric\\nway to estimate the probability density function (PDF) of a random\\nvariable. This function uses Gaussian kernels and includes automatic\\nbandwidth determination.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'bw_method': {'type': 'string',\n",
       "          'description': 'str, scalar or callable, optional. The method used to calculate the estimator bandwidth. This can be\\n‘scott’, ‘silverman’, a scalar constant or a callable.\\nIf None (default), ‘scott’ is used.\\nSee scipy.stats.gaussian_kde for more information.\\n'},\n",
       "         'ind': {'type': 'integer',\n",
       "          'description': 'NumPy array or int, optional. Evaluation points for the estimated PDF. If None (default),\\n1000 equally spaced points are used. If ind is a NumPy array, the\\nKDE is evaluated at the points passed. If ind is an integer,\\nind number of equally spaced points are used.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.plot.kde([bw_method,\\xa0ind])',\n",
       "      'func_desc': 'Generate Kernel Density Estimate plot using Gaussian kernels.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.kde.html#pandas.Series.plot.kde',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.plot.kde',\n",
       "       'full_function': 'Series.plot.kde(bw_method=None, ind=None, **kwargs)',\n",
       "       'function_text': 'Generate Kernel Density Estimate plot using Gaussian kernels. In statistics, kernel density estimation (KDE) is a non-parametric\\nway to estimate the probability density function (PDF) of a random\\nvariable. This function uses Gaussian kernels and includes automatic\\nbandwidth determination.',\n",
       "       'parameter_names_desc': [{'param_name': 'bw_method',\n",
       "         'param_type': 'str, scalar or callable, optional',\n",
       "         'param_desc': 'The method used to calculate the estimator bandwidth. This can be\\n‘scott’, ‘silverman’, a scalar constant or a callable.\\nIf None (default), ‘scott’ is used.\\nSee scipy.stats.gaussian_kde for more information.\\n'},\n",
       "        {'param_name': 'ind',\n",
       "         'param_type': 'NumPy array or int, optional',\n",
       "         'param_desc': 'Evaluation points for the estimated PDF. If None (default),\\n1000 equally spaced points are used. If ind is a NumPy array, the\\nKDE is evaluated at the points passed. If ind is an integer,\\nind number of equally spaced points are used.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.plot.kde',\n",
       "       'descriptions': 'Generate Kernel Density Estimate plot using Gaussian kernels. In statistics, kernel density estimation (KDE) is a non-parametric\\nway to estimate the probability density function (PDF) of a random\\nvariable. This function uses Gaussian kernels and includes automatic\\nbandwidth determination.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'bw_method': {'type': 'string',\n",
       "          'description': 'str, scalar or callable, optional. The method used to calculate the estimator bandwidth. This can be\\n‘scott’, ‘silverman’, a scalar constant or a callable.\\nIf None (default), ‘scott’ is used.\\nSee scipy.stats.gaussian_kde for more information.\\n'},\n",
       "         'ind': {'type': 'integer',\n",
       "          'description': 'NumPy array or int, optional. Evaluation points for the estimated PDF. If None (default),\\n1000 equally spaced points are used. If ind is a NumPy array, the\\nKDE is evaluated at the points passed. If ind is an integer,\\nind number of equally spaced points are used.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.plot.pie(**kwargs)',\n",
       "      'func_desc': 'Generate a pie plot.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.pie.html#pandas.Series.plot.pie',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.plot.pie',\n",
       "       'full_function': 'Series.plot.pie(**kwargs)',\n",
       "       'function_text': 'Generate a pie plot. A pie plot is a proportional representation of the numerical data in a\\ncolumn. This function wraps matplotlib.pyplot.pie() for the\\nspecified column. If no column reference is passed and\\nsubplots=True a pie plot is drawn for each numerical column\\nindependently.',\n",
       "       'parameter_names_desc': [{'param_name': 'y',\n",
       "         'param_type': 'int or label, optional',\n",
       "         'param_desc': 'Label or position of the column to plot.\\nIf not provided, subplots=True argument must be passed.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.plot.pie',\n",
       "       'descriptions': 'Generate a pie plot. A pie plot is a proportional representation of the numerical data in a\\ncolumn. This function wraps matplotlib.pyplot.pie() for the\\nspecified column. If no column reference is passed and\\nsubplots=True a pie plot is drawn for each numerical column\\nindependently.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'y': {'type': 'integer',\n",
       "          'description': 'int or label, optional. Label or position of the column to plot.\\nIf not provided, subplots=True argument must be passed.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.hist([by,\\xa0ax,\\xa0grid,\\xa0xlabelsize,\\xa0...])',\n",
       "      'func_desc': 'Draw histogram of the input series using matplotlib.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.hist.html#pandas.Series.hist',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.hist',\n",
       "       'full_function': 'Series.hist(by=None, ax=None, grid=True, xlabelsize=None, xrot=None, ylabelsize=None, yrot=None, figsize=None, bins=10, backend=None, legend=False, **kwargs)',\n",
       "       'function_text': 'Draw histogram of the input series using matplotlib.',\n",
       "       'parameter_names_desc': [{'param_name': 'by',\n",
       "         'param_type': 'object, optional',\n",
       "         'param_desc': 'If passed, then used to form histograms for separate groups.\\n'},\n",
       "        {'param_name': 'ax',\n",
       "         'param_type': 'matplotlib axis object',\n",
       "         'param_desc': 'If not passed, uses gca().\\n'},\n",
       "        {'param_name': 'grid',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to show axis grid lines.\\n'},\n",
       "        {'param_name': 'xlabelsize',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'If specified changes the x-axis label size.\\n'},\n",
       "        {'param_name': 'xrot',\n",
       "         'param_type': 'float, default None',\n",
       "         'param_desc': 'Rotation of x axis labels.\\n'},\n",
       "        {'param_name': 'ylabelsize',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'If specified changes the y-axis label size.\\n'},\n",
       "        {'param_name': 'yrot',\n",
       "         'param_type': 'float, default None',\n",
       "         'param_desc': 'Rotation of y axis labels.\\n'},\n",
       "        {'param_name': 'figsize',\n",
       "         'param_type': 'tuple, default None',\n",
       "         'param_desc': 'Figure size in inches by default.\\n'},\n",
       "        {'param_name': 'bins',\n",
       "         'param_type': 'int or sequence, default 10',\n",
       "         'param_desc': 'Number of histogram bins to be used. If an integer is given, bins + 1\\nbin edges are calculated and returned. If bins is a sequence, gives\\nbin edges, including left edge of first bin and right edge of last\\nbin. In this case, bins is returned unmodified.\\n'},\n",
       "        {'param_name': 'backend',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'Backend to use instead of the backend specified in the option\\nplotting.backend. For instance, ‘matplotlib’. Alternatively, to\\nspecify the plotting.backend for the whole session, set\\npd.options.plotting.backend.\\n'},\n",
       "        {'param_name': 'legend',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to show the legend.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.hist',\n",
       "       'descriptions': 'Draw histogram of the input series using matplotlib.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'by': {'type': 'object',\n",
       "          'description': 'object, optional. If passed, then used to form histograms for separate groups.\\n'},\n",
       "         'ax': {'type': 'object',\n",
       "          'description': 'matplotlib axis object. If not passed, uses gca().\\n'},\n",
       "         'grid': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to show axis grid lines.\\n'},\n",
       "         'xlabelsize': {'type': 'integer',\n",
       "          'description': 'int, default None. If specified changes the x-axis label size.\\n'},\n",
       "         'xrot': {'type': 'float',\n",
       "          'description': 'float, default None. Rotation of x axis labels.\\n'},\n",
       "         'ylabelsize': {'type': 'integer',\n",
       "          'description': 'int, default None. If specified changes the y-axis label size.\\n'},\n",
       "         'yrot': {'type': 'float',\n",
       "          'description': 'float, default None. Rotation of y axis labels.\\n'},\n",
       "         'figsize': {'type': 'tuple, default None',\n",
       "          'description': 'tuple, default None. Figure size in inches by default.\\n'},\n",
       "         'bins': {'type': 'integer',\n",
       "          'description': 'int or sequence, default 10. Number of histogram bins to be used. If an integer is given, bins + 1\\nbin edges are calculated and returned. If bins is a sequence, gives\\nbin edges, including left edge of first bin and right edge of last\\nbin. In this case, bins is returned unmodified.\\n'},\n",
       "         'backend': {'type': 'string',\n",
       "          'description': 'str, default None. Backend to use instead of the backend specified in the option\\nplotting.backend. For instance, ‘matplotlib’. Alternatively, to\\nspecify the plotting.backend for the whole session, set\\npd.options.plotting.backend.\\n'},\n",
       "         'legend': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to show the legend.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.plot.bar([x,\\xa0y])',\n",
       "      'func_desc': 'Vertical bar plot.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.bar.html#pandas.Series.plot.bar',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.plot.bar',\n",
       "       'full_function': 'Series.plot.bar(x=None, y=None, **kwargs)',\n",
       "       'function_text': 'Vertical bar plot. A bar plot is a plot that presents categorical data with\\nrectangular bars with lengths proportional to the values that they\\nrepresent. A bar plot shows comparisons among discrete categories. One\\naxis of the plot shows the specific categories being compared, and the\\nother axis represents a measured value.',\n",
       "       'parameter_names_desc': [{'param_name': 'x',\n",
       "         'param_type': 'label or position, optional',\n",
       "         'param_desc': 'Allows plotting of one column versus another. If not specified,\\nthe index of the DataFrame is used.\\n'},\n",
       "        {'param_name': 'y',\n",
       "         'param_type': 'label or position, optional',\n",
       "         'param_desc': 'Allows plotting of one column versus another. If not specified,\\nall numerical columns are used.\\n'},\n",
       "        {'param_name': 'color',\n",
       "         'param_type': 'str, array-like, or dict, optional',\n",
       "         'param_desc': 'The color for each of the DataFrame’s columns. Possible values are:\\n\\n\\nA single color string referred to by name, RGB or RGBA code,for instance ‘red’ or ‘#a98d19’.\\n\\n\\n\\n\\nA sequence of color strings referred to by name, RGB or RGBAcode, which will be used for each column recursively. For\\ninstance [‘green’,’yellow’] each column’s bar will be filled in\\ngreen or yellow, alternatively. If there is only a single column to\\nbe plotted, then only the first color from the color list will be\\nused.\\n\\n\\n\\n\\nA dict of the form {column namecolor}, so that each column will becolored accordingly. For example, if your columns are called a and\\nb, then passing {‘a’: ‘green’, ‘b’: ‘red’} will color bars for\\ncolumn a in green and bars for column b in red.\\n\\n\\n\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.plot.bar',\n",
       "       'descriptions': 'Vertical bar plot. A bar plot is a plot that presents categorical data with\\nrectangular bars with lengths proportional to the values that they\\nrepresent. A bar plot shows comparisons among discrete categories. One\\naxis of the plot shows the specific categories being compared, and the\\nother axis represents a measured value.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'x': {'type': 'label or position, optional',\n",
       "          'description': 'label or position, optional. Allows plotting of one column versus another. If not specified,\\nthe index of the DataFrame is used.\\n'},\n",
       "         'y': {'type': 'label or position, optional',\n",
       "          'description': 'label or position, optional. Allows plotting of one column versus another. If not specified,\\nall numerical columns are used.\\n'},\n",
       "         'color': {'type': 'string',\n",
       "          'description': 'str, array-like, or dict, optional. The color for each of the DataFrame’s columns. Possible values are:\\n\\n\\nA single color string referred to by name, RGB or RGBA code,for instance ‘red’ or ‘#a98d19’.\\n\\n\\n\\n\\nA sequence of color strings referred to by name, RGB or RGBAcode, which will be used for each column recursively. For\\ninstance [‘green’,’yellow’] each column’s bar will be filled in\\ngreen or yellow, alternatively. If there is only a single column to\\nbe plotted, then only the first color from the color list will be\\nused.\\n\\n\\n\\n\\nA dict of the form {column namecolor}, so that each column will becolored accordingly. For example, if your columns are called a and\\nb, then passing {‘a’: ‘green’, ‘b’: ‘red’} will color bars for\\ncolumn a in green and bars for column b in red.\\n\\n\\n\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.plot.box([by])',\n",
       "      'func_desc': 'Make a box plot of the DataFrame columns.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.box.html#pandas.Series.plot.box',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.plot.box',\n",
       "       'full_function': 'Series.plot.box(by=None, **kwargs)',\n",
       "       'function_text': 'Make a box plot of the DataFrame columns. A box plot is a method for graphically depicting groups of numerical\\ndata through their quartiles.\\nThe box extends from the Q1 to Q3 quartile values of the data,\\nwith a line at the median (Q2). The whiskers extend from the edges\\nof box to show the range of the data. The position of the whiskers\\nis set by default to 1.5*IQR (IQR = Q3 - Q1) from the edges of the\\nbox. Outlier points are those past the end of the whiskers. For further details see Wikipedia’s\\nentry for boxplot. A consideration when using this chart is that the box and the whiskers\\ncan overlap, which is very common when plotting small sets of data.',\n",
       "       'parameter_names_desc': [{'param_name': 'by',\n",
       "         'param_type': 'str or sequence',\n",
       "         'param_desc': 'Column in the DataFrame to group by.\\n\\nChanged in version 1.4.0: Previously, by is silently ignore and makes no groupings\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.plot.box',\n",
       "       'descriptions': 'Make a box plot of the DataFrame columns. A box plot is a method for graphically depicting groups of numerical\\ndata through their quartiles.\\nThe box extends from the Q1 to Q3 quartile values of the data,\\nwith a line at the median (Q2). The whiskers extend from the edges\\nof box to show the range of the data. The position of the whiskers\\nis set by default to 1.5*IQR (IQR = Q3 - Q1) from the edges of the\\nbox. Outlier points are those past the end of the whiskers. For further details see Wikipedia’s\\nentry for boxplot. A consideration when using this chart is that the box and the whiskers\\ncan overlap, which is very common when plotting small sets of data.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'by': {'type': 'string',\n",
       "          'description': 'str or sequence. Column in the DataFrame to group by.\\n\\nChanged in version 1.4.0: Previously, by is silently ignore and makes no groupings\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.plot.hist([by,\\xa0bins])',\n",
       "      'func_desc': \"Draw one histogram of the DataFrame's columns.\",\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.hist.html#pandas.Series.plot.hist',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.plot.hist',\n",
       "       'full_function': 'Series.plot.hist(by=None, bins=10, **kwargs)',\n",
       "       'function_text': 'Draw one histogram of the DataFrame’s columns. A histogram is a representation of the distribution of data.\\nThis function groups the values of all given Series in the DataFrame\\ninto bins and draws all bins in one matplotlib.axes.Axes.\\nThis is useful when the DataFrame’s Series are in a similar scale.',\n",
       "       'parameter_names_desc': [{'param_name': 'by',\n",
       "         'param_type': 'str or sequence, optional',\n",
       "         'param_desc': 'Column in the DataFrame to group by.\\n\\nChanged in version 1.4.0: Previously, by is silently ignore and makes no groupings\\n\\n'},\n",
       "        {'param_name': 'bins',\n",
       "         'param_type': 'int, default 10',\n",
       "         'param_desc': 'Number of histogram bins to be used.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.plot.hist',\n",
       "       'descriptions': 'Draw one histogram of the DataFrame’s columns. A histogram is a representation of the distribution of data.\\nThis function groups the values of all given Series in the DataFrame\\ninto bins and draws all bins in one matplotlib.axes.Axes.\\nThis is useful when the DataFrame’s Series are in a similar scale.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'by': {'type': 'string',\n",
       "          'description': 'str or sequence, optional. Column in the DataFrame to group by.\\n\\nChanged in version 1.4.0: Previously, by is silently ignore and makes no groupings\\n\\n'},\n",
       "         'bins': {'type': 'integer',\n",
       "          'description': 'int, default 10. Number of histogram bins to be used.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.plot.line([x,\\xa0y])',\n",
       "      'func_desc': 'Plot Series or DataFrame as lines.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.line.html#pandas.Series.plot.line',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.plot.line',\n",
       "       'full_function': 'Series.plot.line(x=None, y=None, **kwargs)',\n",
       "       'function_text': 'Plot Series or DataFrame as lines. This function is useful to plot lines using DataFrame’s values\\nas coordinates.',\n",
       "       'parameter_names_desc': [{'param_name': 'x',\n",
       "         'param_type': 'label or position, optional',\n",
       "         'param_desc': 'Allows plotting of one column versus another. If not specified,\\nthe index of the DataFrame is used.\\n'},\n",
       "        {'param_name': 'y',\n",
       "         'param_type': 'label or position, optional',\n",
       "         'param_desc': 'Allows plotting of one column versus another. If not specified,\\nall numerical columns are used.\\n'},\n",
       "        {'param_name': 'color',\n",
       "         'param_type': 'str, array-like, or dict, optional',\n",
       "         'param_desc': 'The color for each of the DataFrame’s columns. Possible values are:\\n\\n\\nA single color string referred to by name, RGB or RGBA code,for instance ‘red’ or ‘#a98d19’.\\n\\n\\n\\n\\nA sequence of color strings referred to by name, RGB or RGBAcode, which will be used for each column recursively. For\\ninstance [‘green’,’yellow’] each column’s line will be filled in\\ngreen or yellow, alternatively. If there is only a single column to\\nbe plotted, then only the first color from the color list will be\\nused.\\n\\n\\n\\n\\nA dict of the form {column namecolor}, so that each column will becolored accordingly. For example, if your columns are called a and\\nb, then passing {‘a’: ‘green’, ‘b’: ‘red’} will color lines for\\ncolumn a in green and lines for column b in red.\\n\\n\\n\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.plot.line',\n",
       "       'descriptions': 'Plot Series or DataFrame as lines. This function is useful to plot lines using DataFrame’s values\\nas coordinates.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'x': {'type': 'label or position, optional',\n",
       "          'description': 'label or position, optional. Allows plotting of one column versus another. If not specified,\\nthe index of the DataFrame is used.\\n'},\n",
       "         'y': {'type': 'label or position, optional',\n",
       "          'description': 'label or position, optional. Allows plotting of one column versus another. If not specified,\\nall numerical columns are used.\\n'},\n",
       "         'color': {'type': 'string',\n",
       "          'description': 'str, array-like, or dict, optional. The color for each of the DataFrame’s columns. Possible values are:\\n\\n\\nA single color string referred to by name, RGB or RGBA code,for instance ‘red’ or ‘#a98d19’.\\n\\n\\n\\n\\nA sequence of color strings referred to by name, RGB or RGBAcode, which will be used for each column recursively. For\\ninstance [‘green’,’yellow’] each column’s line will be filled in\\ngreen or yellow, alternatively. If there is only a single column to\\nbe plotted, then only the first color from the color list will be\\nused.\\n\\n\\n\\n\\nA dict of the form {column namecolor}, so that each column will becolored accordingly. For example, if your columns are called a and\\nb, then passing {‘a’: ‘green’, ‘b’: ‘red’} will color lines for\\ncolumn a in green and lines for column b in red.\\n\\n\\n\\n\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Serialization / IO / conversion': [{'func_name': 'Series.to_pickle(path,\\xa0*[,\\xa0compression,\\xa0...])',\n",
       "      'func_desc': 'Pickle (serialize) object to file.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.to_pickle.html#pandas.Series.to_pickle',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.to_pickle',\n",
       "       'full_function': \"Series.to_pickle(path, *, compression='infer', protocol=5, storage_options=None)\",\n",
       "       'function_text': 'Pickle (serialize) object to file.',\n",
       "       'parameter_names_desc': [{'param_name': 'path',\n",
       "         'param_type': 'str, path object, or file-like object',\n",
       "         'param_desc': 'String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a binary write() function. File path where\\nthe pickled object will be stored.\\n'},\n",
       "        {'param_name': 'compression',\n",
       "         'param_type': 'str or dict, default ‘infer’',\n",
       "         'param_desc': \"For on-the-fly compression of the output data. If ‘infer’ and ‘path’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nSet to None for no compression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for faster compression and to create\\na reproducible gzip archive:\\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\n\\n\"},\n",
       "        {'param_name': 'protocol',\n",
       "         'param_type': 'int',\n",
       "         'param_desc': 'Int which indicates which protocol should be used by the pickler,\\ndefault HIGHEST_PROTOCOL (see [1] paragraph 12.1.2). The possible\\nvalues are 0, 1, 2, 3, 4, 5. A negative value for the protocol\\nparameter is equivalent to setting its value to HIGHEST_PROTOCOL.\\n\\n\\n[1]\\nhttps://docs.python.org/3/library/pickle.html.\\n\\n\\n'},\n",
       "        {'param_name': 'storage_options',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.to_pickle',\n",
       "       'descriptions': 'Pickle (serialize) object to file.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'path': {'type': 'string',\n",
       "          'description': 'str, path object, or file-like object. String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a binary write() function. File path where\\nthe pickled object will be stored.\\n'},\n",
       "         'compression': {'type': 'string',\n",
       "          'description': \"str or dict, default ‘infer’. For on-the-fly compression of the output data. If ‘infer’ and ‘path’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nSet to None for no compression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for faster compression and to create\\na reproducible gzip archive:\\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\n\\n\"},\n",
       "         'protocol': {'type': 'integer',\n",
       "          'description': 'int. Int which indicates which protocol should be used by the pickler,\\ndefault HIGHEST_PROTOCOL (see [1] paragraph 12.1.2). The possible\\nvalues are 0, 1, 2, 3, 4, 5. A negative value for the protocol\\nparameter is equivalent to setting its value to HIGHEST_PROTOCOL.\\n\\n\\n[1]\\nhttps://docs.python.org/3/library/pickle.html.\\n\\n\\n'},\n",
       "         'storage_options': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'}},\n",
       "        'required': ['path']}}},\n",
       "     {'func_name': 'Series.to_dict(*[,\\xa0into])',\n",
       "      'func_desc': 'Convert Series to {label -> value} dict or dict-like object.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.to_dict.html#pandas.Series.to_dict',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.to_dict',\n",
       "       'full_function': \"Series.to_dict(*, into=<class 'dict'>)\",\n",
       "       'function_text': 'Convert Series to {label -> value} dict or dict-like object.',\n",
       "       'parameter_names_desc': [{'param_name': 'into',\n",
       "         'param_type': 'class, default dict',\n",
       "         'param_desc': 'The collections.abc.MutableMapping subclass to use as the return\\nobject. Can be the actual class or an empty instance of the mapping\\ntype you want. If you want a collections.defaultdict, you must\\npass it initialized.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.to_dict',\n",
       "       'descriptions': 'Convert Series to {label -> value} dict or dict-like object.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'into': {'type': 'class, default dict',\n",
       "          'description': 'class, default dict. The collections.abc.MutableMapping subclass to use as the return\\nobject. Can be the actual class or an empty instance of the mapping\\ntype you want. If you want a collections.defaultdict, you must\\npass it initialized.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.to_frame([name])',\n",
       "      'func_desc': 'Convert Series to DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.to_frame.html#pandas.Series.to_frame',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.to_frame',\n",
       "       'full_function': 'Series.to_frame(name=_NoDefault.no_default)',\n",
       "       'function_text': 'Convert Series to DataFrame.',\n",
       "       'parameter_names_desc': [{'param_name': 'name',\n",
       "         'param_type': 'object, optional',\n",
       "         'param_desc': 'The passed name should substitute for the series name (if it has\\none).\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.to_frame',\n",
       "       'descriptions': 'Convert Series to DataFrame.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'name': {'type': 'object',\n",
       "          'description': 'object, optional. The passed name should substitute for the series name (if it has\\none).\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.to_hdf(path_or_buf,\\xa0*,\\xa0key[,\\xa0mode,\\xa0...])',\n",
       "      'func_desc': 'Write the contained data to an HDF5 file using HDFStore.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.to_hdf.html#pandas.Series.to_hdf',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.to_hdf',\n",
       "       'full_function': \"Series.to_hdf(path_or_buf, *, key, mode='a', complevel=None, complib=None, append=False, format=None, index=True, min_itemsize=None, nan_rep=None, dropna=None, data_columns=None, errors='strict', encoding='UTF-8')\",\n",
       "       'function_text': 'Write the contained data to an HDF5 file using HDFStore. Hierarchical Data Format (HDF) is self-describing, allowing an\\napplication to interpret the structure and contents of a file with\\nno outside information. One HDF file can hold a mix of related objects\\nwhich can be accessed as a group or as individual objects. In order to add another DataFrame or Series to an existing HDF file\\nplease use append mode and a different a key. Warning One can store a subclass of DataFrame or Series to HDF5,\\nbut the type of the subclass is lost upon storing. For more information see the user guide.',\n",
       "       'parameter_names_desc': [{'param_name': 'path_or_buf',\n",
       "         'param_type': 'str or pandas.HDFStore',\n",
       "         'param_desc': 'File path or HDFStore object.\\n'},\n",
       "        {'param_name': 'key',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'Identifier for the group in the store.\\n'},\n",
       "        {'param_name': 'mode',\n",
       "         'param_type': '{‘a’, ‘w’, ‘r+’}, default ‘a’',\n",
       "         'param_desc': 'Mode to open file:\\n\\n‘w’: write, a new file is created (an existing file with\\nthe same name would be deleted).\\n‘a’: append, an existing file is opened for reading and\\nwriting, and if the file does not exist it is created.\\n‘r+’: similar to ‘a’, but the file must already exist.\\n\\n'},\n",
       "        {'param_name': 'complevel',\n",
       "         'param_type': '{0-9}, default None',\n",
       "         'param_desc': 'Specifies a compression level for data.\\nA value of 0 or None disables compression.\\n'},\n",
       "        {'param_name': 'complib',\n",
       "         'param_type': '{‘zlib’, ‘lzo’, ‘bzip2’, ‘blosc’}, default ‘zlib’',\n",
       "         'param_desc': 'Specifies the compression library to be used.\\nThese additional compressors for Blosc are supported\\n(default if no compressor specified: ‘blosc:blosclz’):\\n{‘blosc:blosclz’, ‘blosc:lz4’, ‘blosc:lz4hc’, ‘blosc:snappy’,\\n‘blosc:zlib’, ‘blosc:zstd’}.\\nSpecifying a compression library which is not available issues\\na ValueError.\\n'},\n",
       "        {'param_name': 'append',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'For Table formats, append the input data to the existing.\\n'},\n",
       "        {'param_name': 'format',\n",
       "         'param_type': '{‘fixed’, ‘table’, None}, default ‘fixed’',\n",
       "         'param_desc': 'Possible values:\\n\\n‘fixed’: Fixed format. Fast writing/reading. Not-appendable,\\nnor searchable.\\n‘table’: Table format. Write as a PyTables Table structure\\nwhich may perform worse but allow more flexible operations\\nlike searching / selecting subsets of the data.\\nIf None, pd.get_option(‘io.hdf.default_format’) is checked,\\nfollowed by fallback to “fixed”.\\n\\n'},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Write DataFrame index as a column.\\n'},\n",
       "        {'param_name': 'min_itemsize',\n",
       "         'param_type': 'dict or int, optional',\n",
       "         'param_desc': 'Map column names to minimum string sizes for columns.\\n'},\n",
       "        {'param_name': 'nan_rep',\n",
       "         'param_type': 'Any, optional',\n",
       "         'param_desc': 'How to represent null values as str.\\nNot allowed with append=True.\\n'},\n",
       "        {'param_name': 'dropna',\n",
       "         'param_type': 'bool, default False, optional',\n",
       "         'param_desc': 'Remove missing values.\\n'},\n",
       "        {'param_name': 'data_columns',\n",
       "         'param_type': 'list of columns or True, optional',\n",
       "         'param_desc': 'List of columns to create as indexed data columns for on-disk\\nqueries, or True to use all columns. By default only the axes\\nof the object are indexed. See\\nQuery via data columns. for\\nmore information.\\nApplicable only to format=’table’.\\n'},\n",
       "        {'param_name': 'errors',\n",
       "         'param_type': 'str, default ‘strict’',\n",
       "         'param_desc': 'Specifies how encoding and decoding errors are to be handled.\\nSee the errors argument for open() for a full list\\nof options.\\n'},\n",
       "        {'param_name': 'encoding',\n",
       "         'param_type': 'str, default “UTF-8”',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.Series.to_hdf',\n",
       "       'descriptions': 'Write the contained data to an HDF5 file using HDFStore. Hierarchical Data Format (HDF) is self-describing, allowing an\\napplication to interpret the structure and contents of a file with\\nno outside information. One HDF file can hold a mix of related objects\\nwhich can be accessed as a group or as individual objects. In order to add another DataFrame or Series to an existing HDF file\\nplease use append mode and a different a key. Warning One can store a subclass of DataFrame or Series to HDF5,\\nbut the type of the subclass is lost upon storing. For more information see the user guide.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'path_or_buf': {'type': 'string',\n",
       "          'description': 'str or pandas.HDFStore. File path or HDFStore object.\\n'},\n",
       "         'key': {'type': 'string',\n",
       "          'description': 'str. Identifier for the group in the store.\\n'},\n",
       "         'mode': {'type': 'string',\n",
       "          'enum': ['a', ' w', ' r+'],\n",
       "          'description': '{‘a’, ‘w’, ‘r+’}, default ‘a’. Mode to open file:\\n\\n‘w’: write, a new file is created (an existing file with\\nthe same name would be deleted).\\n‘a’: append, an existing file is opened for reading and\\nwriting, and if the file does not exist it is created.\\n‘r+’: similar to ‘a’, but the file must already exist.\\n\\n'},\n",
       "         'complevel': {'type': '{0-9}, default None',\n",
       "          'description': '{0-9}, default None. Specifies a compression level for data.\\nA value of 0 or None disables compression.\\n'},\n",
       "         'complib': {'type': 'string',\n",
       "          'enum': ['zlib', ' lzo', ' bzip2', ' blosc'],\n",
       "          'description': '{‘zlib’, ‘lzo’, ‘bzip2’, ‘blosc’}, default ‘zlib’. Specifies the compression library to be used.\\nThese additional compressors for Blosc are supported\\n(default if no compressor specified: ‘blosc:blosclz’):\\n{‘blosc:blosclz’, ‘blosc:lz4’, ‘blosc:lz4hc’, ‘blosc:snappy’,\\n‘blosc:zlib’, ‘blosc:zstd’}.\\nSpecifying a compression library which is not available issues\\na ValueError.\\n'},\n",
       "         'append': {'type': 'boolean',\n",
       "          'description': 'bool, default False. For Table formats, append the input data to the existing.\\n'},\n",
       "         'format': {'type': 'string',\n",
       "          'enum': ['fixed', ' table', ' None'],\n",
       "          'description': '{‘fixed’, ‘table’, None}, default ‘fixed’. Possible values:\\n\\n‘fixed’: Fixed format. Fast writing/reading. Not-appendable,\\nnor searchable.\\n‘table’: Table format. Write as a PyTables Table structure\\nwhich may perform worse but allow more flexible operations\\nlike searching / selecting subsets of the data.\\nIf None, pd.get_option(‘io.hdf.default_format’) is checked,\\nfollowed by fallback to “fixed”.\\n\\n'},\n",
       "         'index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Write DataFrame index as a column.\\n'},\n",
       "         'min_itemsize': {'type': 'integer',\n",
       "          'description': 'dict or int, optional. Map column names to minimum string sizes for columns.\\n'},\n",
       "         'nan_rep': {'type': 'Any, optional',\n",
       "          'description': 'Any, optional. How to represent null values as str.\\nNot allowed with append=True.\\n'},\n",
       "         'dropna': {'type': 'boolean',\n",
       "          'description': 'bool, default False, optional. Remove missing values.\\n'},\n",
       "         'data_columns': {'type': 'array',\n",
       "          'description': 'list of columns or True, optional. List of columns to create as indexed data columns for on-disk\\nqueries, or True to use all columns. By default only the axes\\nof the object are indexed. See\\nQuery via data columns. for\\nmore information.\\nApplicable only to format=’table’.\\n'},\n",
       "         'errors': {'type': 'string',\n",
       "          'description': 'str, default ‘strict’. Specifies how encoding and decoding errors are to be handled.\\nSee the errors argument for open() for a full list\\nof options.\\n'},\n",
       "         'encoding': {'type': 'string',\n",
       "          'description': 'str, default “UTF-8”. '}},\n",
       "        'required': ['path_or_buf']}}},\n",
       "     {'func_name': 'Series.to_json([path_or_buf,\\xa0orient,\\xa0...])',\n",
       "      'func_desc': 'Convert the object to a JSON string.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.to_json.html#pandas.Series.to_json',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.to_json',\n",
       "       'full_function': \"Series.to_json(path_or_buf=None, *, orient=None, date_format=None, double_precision=10, force_ascii=True, date_unit='ms', default_handler=None, lines=False, compression='infer', index=None, indent=None, storage_options=None, mode='w')\",\n",
       "       'function_text': 'Convert the object to a JSON string. Note NaN’s and None will be converted to null and datetime objects\\nwill be converted to UNIX timestamps.',\n",
       "       'parameter_names_desc': [{'param_name': 'path_or_buf',\n",
       "         'param_type': 'str, path object, file-like object, or None, default None',\n",
       "         'param_desc': 'String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a write() function. If None, the result is\\nreturned as a string.\\n'},\n",
       "        {'param_name': 'orient',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': \"Indication of expected JSON string format.\\n\\nSeries:\\n\\n\\ndefault is ‘index’\\nallowed values are: {‘split’, ‘records’, ‘index’, ‘table’}.\\n\\n\\n\\nDataFrame:\\n\\n\\ndefault is ‘columns’\\nallowed values are: {‘split’, ‘records’, ‘index’, ‘columns’,\\n‘values’, ‘table’}.\\n\\n\\n\\nThe format of the JSON string:\\n\\n\\n‘split’ : dict like {‘index’ -> [index], ‘columns’ -> [columns],\\n‘data’ -> [values]}\\n‘records’ : list like [{column -> value}, … , {column -> value}]\\n‘index’ : dict like {index -> {column -> value}}\\n‘columns’ : dict like {column -> {index -> value}}\\n‘values’ : just the values array\\n‘table’ : dict like {‘schema’: {schema}, ‘data’: {data}}\\n\\nDescribing the data, where data component is like orient='records'.\\n\\n\\n\\n\"},\n",
       "        {'param_name': 'date_format',\n",
       "         'param_type': '{None, ‘epoch’, ‘iso’}',\n",
       "         'param_desc': \"Type of date conversion. ‘epoch’ = epoch milliseconds,\\n‘iso’ = ISO8601. The default depends on the orient. For\\norient='table', the default is ‘iso’. For all other orients,\\nthe default is ‘epoch’.\\n\"},\n",
       "        {'param_name': 'double_precision',\n",
       "         'param_type': 'int, default 10',\n",
       "         'param_desc': 'The number of decimal places to use when encoding\\nfloating point values. The possible maximal value is 15.\\nPassing double_precision greater than 15 will raise a ValueError.\\n'},\n",
       "        {'param_name': 'force_ascii',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Force encoded string to be ASCII.\\n'},\n",
       "        {'param_name': 'date_unit',\n",
       "         'param_type': 'str, default ‘ms’ (milliseconds)',\n",
       "         'param_desc': 'The time unit to encode to, governs timestamp and ISO8601\\nprecision. One of ‘s’, ‘ms’, ‘us’, ‘ns’ for second, millisecond,\\nmicrosecond, and nanosecond respectively.\\n'},\n",
       "        {'param_name': 'default_handler',\n",
       "         'param_type': 'callable, default None',\n",
       "         'param_desc': 'Handler to call if object cannot otherwise be converted to a\\nsuitable format for JSON. Should receive a single argument which is\\nthe object to convert and return a serialisable object.\\n'},\n",
       "        {'param_name': 'lines',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If ‘orient’ is ‘records’ write out line-delimited json format. Will\\nthrow ValueError if incorrect ‘orient’ since others are not\\nlist-like.\\n'},\n",
       "        {'param_name': 'compression',\n",
       "         'param_type': 'str or dict, default ‘infer’',\n",
       "         'param_desc': \"For on-the-fly compression of the output data. If ‘infer’ and ‘path_or_buf’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nSet to None for no compression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for faster compression and to create\\na reproducible gzip archive:\\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\n\\n\\nChanged in version 1.4.0: Zstandard support.\\n\\n\"},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'bool or None, default None',\n",
       "         'param_desc': 'The index is only used when ‘orient’ is ‘split’, ‘index’, ‘column’,\\nor ‘table’. Of these, ‘index’ and ‘column’ do not support\\nindex=False.\\n'},\n",
       "        {'param_name': 'indent',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Length of whitespace used to indent each record.\\n'},\n",
       "        {'param_name': 'storage_options',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'},\n",
       "        {'param_name': 'mode',\n",
       "         'param_type': 'str, default ‘w’ (writing)',\n",
       "         'param_desc': 'Specify the IO mode for output when supplying a path_or_buf.\\nAccepted args are ‘w’ (writing) and ‘a’ (append) only.\\nmode=’a’ is only supported when lines is True and orient is ‘records’.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.to_json',\n",
       "       'descriptions': 'Convert the object to a JSON string. Note NaN’s and None will be converted to null and datetime objects\\nwill be converted to UNIX timestamps.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'path_or_buf': {'type': 'string',\n",
       "          'description': 'str, path object, file-like object, or None, default None. String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a write() function. If None, the result is\\nreturned as a string.\\n'},\n",
       "         'orient': {'type': 'string',\n",
       "          'description': \"str. Indication of expected JSON string format.\\n\\nSeries:\\n\\n\\ndefault is ‘index’\\nallowed values are: {‘split’, ‘records’, ‘index’, ‘table’}.\\n\\n\\n\\nDataFrame:\\n\\n\\ndefault is ‘columns’\\nallowed values are: {‘split’, ‘records’, ‘index’, ‘columns’,\\n‘values’, ‘table’}.\\n\\n\\n\\nThe format of the JSON string:\\n\\n\\n‘split’ : dict like {‘index’ -> [index], ‘columns’ -> [columns],\\n‘data’ -> [values]}\\n‘records’ : list like [{column -> value}, … , {column -> value}]\\n‘index’ : dict like {index -> {column -> value}}\\n‘columns’ : dict like {column -> {index -> value}}\\n‘values’ : just the values array\\n‘table’ : dict like {‘schema’: {schema}, ‘data’: {data}}\\n\\nDescribing the data, where data component is like orient='records'.\\n\\n\\n\\n\"},\n",
       "         'date_format': {'type': 'string',\n",
       "          'enum': ['None', ' epoch', ' iso'],\n",
       "          'description': \"{None, ‘epoch’, ‘iso’}. Type of date conversion. ‘epoch’ = epoch milliseconds,\\n‘iso’ = ISO8601. The default depends on the orient. For\\norient='table', the default is ‘iso’. For all other orients,\\nthe default is ‘epoch’.\\n\"},\n",
       "         'double_precision': {'type': 'integer',\n",
       "          'description': 'int, default 10. The number of decimal places to use when encoding\\nfloating point values. The possible maximal value is 15.\\nPassing double_precision greater than 15 will raise a ValueError.\\n'},\n",
       "         'force_ascii': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Force encoded string to be ASCII.\\n'},\n",
       "         'date_unit': {'type': 'string',\n",
       "          'description': 'str, default ‘ms’ (milliseconds). The time unit to encode to, governs timestamp and ISO8601\\nprecision. One of ‘s’, ‘ms’, ‘us’, ‘ns’ for second, millisecond,\\nmicrosecond, and nanosecond respectively.\\n'},\n",
       "         'default_handler': {'type': 'object',\n",
       "          'description': 'callable, default None. Handler to call if object cannot otherwise be converted to a\\nsuitable format for JSON. Should receive a single argument which is\\nthe object to convert and return a serialisable object.\\n'},\n",
       "         'lines': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If ‘orient’ is ‘records’ write out line-delimited json format. Will\\nthrow ValueError if incorrect ‘orient’ since others are not\\nlist-like.\\n'},\n",
       "         'compression': {'type': 'string',\n",
       "          'description': \"str or dict, default ‘infer’. For on-the-fly compression of the output data. If ‘infer’ and ‘path_or_buf’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nSet to None for no compression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for faster compression and to create\\na reproducible gzip archive:\\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\n\\n\\nChanged in version 1.4.0: Zstandard support.\\n\\n\"},\n",
       "         'index': {'type': 'boolean',\n",
       "          'description': 'bool or None, default None. The index is only used when ‘orient’ is ‘split’, ‘index’, ‘column’,\\nor ‘table’. Of these, ‘index’ and ‘column’ do not support\\nindex=False.\\n'},\n",
       "         'indent': {'type': 'integer',\n",
       "          'description': 'int, optional. Length of whitespace used to indent each record.\\n'},\n",
       "         'storage_options': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'},\n",
       "         'mode': {'type': 'string',\n",
       "          'description': 'str, default ‘w’ (writing). Specify the IO mode for output when supplying a path_or_buf.\\nAccepted args are ‘w’ (writing) and ‘a’ (append) only.\\nmode=’a’ is only supported when lines is True and orient is ‘records’.\\n'}},\n",
       "        'required': ['path_or_buf=None']}}},\n",
       "     {'func_name': 'Series.to_clipboard(*[,\\xa0excel,\\xa0sep])',\n",
       "      'func_desc': 'Copy object to the system clipboard.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.to_clipboard.html#pandas.Series.to_clipboard',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.to_clipboard',\n",
       "       'full_function': 'Series.to_clipboard(*, excel=True, sep=None, **kwargs)',\n",
       "       'function_text': 'Copy object to the system clipboard. Write a text representation of object to the system clipboard.\\nThis can be pasted into Excel, for example.',\n",
       "       'parameter_names_desc': [{'param_name': 'excel',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Produce output in a csv format for easy pasting into excel.\\n\\nTrue, use the provided separator for csv pasting.\\nFalse, write a string representation of the object to the clipboard.\\n\\n'},\n",
       "        {'param_name': 'sep',\n",
       "         'param_type': \"str, default '\\\\t'\",\n",
       "         'param_desc': 'Field delimiter.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.to_clipboard',\n",
       "       'descriptions': 'Copy object to the system clipboard. Write a text representation of object to the system clipboard.\\nThis can be pasted into Excel, for example.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'excel': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Produce output in a csv format for easy pasting into excel.\\n\\nTrue, use the provided separator for csv pasting.\\nFalse, write a string representation of the object to the clipboard.\\n\\n'},\n",
       "         'sep': {'type': 'string',\n",
       "          'description': \"str, default '\\\\t'. Field delimiter.\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.to_markdown([buf,\\xa0mode,\\xa0index,\\xa0...])',\n",
       "      'func_desc': 'Print Series in Markdown-friendly format.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.to_markdown.html#pandas.Series.to_markdown',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.to_markdown',\n",
       "       'full_function': \"Series.to_markdown(buf=None, mode='wt', index=True, storage_options=None, **kwargs)\",\n",
       "       'function_text': 'Print Series in Markdown-friendly format.',\n",
       "       'parameter_names_desc': [{'param_name': 'buf',\n",
       "         'param_type': 'str, Path or StringIO-like, optional, default None',\n",
       "         'param_desc': 'Buffer to write to. If None, the output is returned as a string.\\n'},\n",
       "        {'param_name': 'mode',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Mode in which file is opened, “wt” by default.\\n'},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'bool, optional, default True',\n",
       "         'param_desc': 'Add index (row) labels.\\n'},\n",
       "        {'param_name': 'storage_options',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.to_markdown',\n",
       "       'descriptions': 'Print Series in Markdown-friendly format.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'buf': {'type': 'string',\n",
       "          'description': 'str, Path or StringIO-like, optional, default None. Buffer to write to. If None, the output is returned as a string.\\n'},\n",
       "         'mode': {'type': 'string',\n",
       "          'description': 'str, optional. Mode in which file is opened, “wt” by default.\\n'},\n",
       "         'index': {'type': 'boolean',\n",
       "          'description': 'bool, optional, default True. Add index (row) labels.\\n'},\n",
       "         'storage_options': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.to_csv([path_or_buf,\\xa0sep,\\xa0na_rep,\\xa0...])',\n",
       "      'func_desc': 'Write object to a comma-separated values (csv) file.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.to_csv.html#pandas.Series.to_csv',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.to_csv',\n",
       "       'full_function': 'Series.to_csv(path_or_buf=None, *, sep=\\',\\', na_rep=\\'\\', float_format=None, columns=None, header=True, index=True, index_label=None, mode=\\'w\\', encoding=None, compression=\\'infer\\', quoting=None, quotechar=\\'\"\\', lineterminator=None, chunksize=None, date_format=None, doublequote=True, escapechar=None, decimal=\\'.\\', errors=\\'strict\\', storage_options=None)',\n",
       "       'function_text': 'Write object to a comma-separated values (csv) file.',\n",
       "       'parameter_names_desc': [{'param_name': 'path_or_buf',\n",
       "         'param_type': 'str, path object, file-like object, or None, default None',\n",
       "         'param_desc': 'String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a write() function. If None, the result is\\nreturned as a string. If a non-binary file object is passed, it should\\nbe opened with newline=’’, disabling universal newlines. If a binary\\nfile object is passed, mode might need to contain a ‘b’.\\n'},\n",
       "        {'param_name': 'sep',\n",
       "         'param_type': 'str, default ‘,’',\n",
       "         'param_desc': 'String of length 1. Field delimiter for the output file.\\n'},\n",
       "        {'param_name': 'na_rep',\n",
       "         'param_type': 'str, default ‘’',\n",
       "         'param_desc': 'Missing data representation.\\n'},\n",
       "        {'param_name': 'float_format',\n",
       "         'param_type': 'str, Callable, default None',\n",
       "         'param_desc': 'Format string for floating point numbers. If a Callable is given, it takes\\nprecedence over other numeric formatting parameters, like decimal.\\n'},\n",
       "        {'param_name': 'columns',\n",
       "         'param_type': 'sequence, optional',\n",
       "         'param_desc': 'Columns to write.\\n'},\n",
       "        {'param_name': 'header',\n",
       "         'param_type': 'bool or list of str, default True',\n",
       "         'param_desc': 'Write out the column names. If a list of strings is given it is\\nassumed to be aliases for the column names.\\n'},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Write row names (index).\\n'},\n",
       "        {'param_name': 'index_label',\n",
       "         'param_type': 'str or sequence, or False, default None',\n",
       "         'param_desc': 'Column label for index column(s) if desired. If None is given, and\\nheader and index are True, then the index names are used. A\\nsequence should be given if the object uses MultiIndex. If\\nFalse do not print fields for index names. Use index_label=False\\nfor easier importing in R.\\n'},\n",
       "        {'param_name': 'mode',\n",
       "         'param_type': '{‘w’, ‘x’, ‘a’}, default ‘w’',\n",
       "         'param_desc': 'Forwarded to either open(mode=) or fsspec.open(mode=) to control\\nthe file opening. Typical values include:\\n\\n‘w’, truncate the file first.\\n‘x’, exclusive creation, failing if the file already exists.\\n‘a’, append to the end of file if it exists.\\n\\n'},\n",
       "        {'param_name': 'encoding',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'A string representing the encoding to use in the output file,\\ndefaults to ‘utf-8’. encoding is not supported if path_or_buf\\nis a non-binary file object.\\n'},\n",
       "        {'param_name': 'compression',\n",
       "         'param_type': 'str or dict, default ‘infer’',\n",
       "         'param_desc': \"For on-the-fly compression of the output data. If ‘infer’ and ‘path_or_buf’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nSet to None for no compression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for faster compression and to create\\na reproducible gzip archive:\\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\nMay be a dict with key ‘method’ as compression mode\\nand other entries as additional compression options if\\ncompression mode is ‘zip’.\\nPassing compression options as keys in dict is\\nsupported for compression modes ‘gzip’, ‘bz2’, ‘zstd’, and ‘zip’.\\n\\n\"},\n",
       "        {'param_name': 'quoting',\n",
       "         'param_type': 'optional constant from csv module',\n",
       "         'param_desc': 'Defaults to csv.QUOTE_MINIMAL. If you have set a float_format\\nthen floats are converted to strings and thus csv.QUOTE_NONNUMERIC\\nwill treat them as non-numeric.\\n'},\n",
       "        {'param_name': 'quotechar',\n",
       "         'param_type': 'str, default ‘\"’',\n",
       "         'param_desc': 'String of length 1. Character used to quote fields.\\n'},\n",
       "        {'param_name': 'lineterminator',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'The newline character or character sequence to use in the output\\nfile. Defaults to os.linesep, which depends on the OS in which\\nthis method is called (’\\\\n’ for linux, ‘\\\\r\\\\n’ for Windows, i.e.).\\n\\nChanged in version 1.5.0: Previously was line_terminator, changed for consistency with\\nread_csv and the standard library ‘csv’ module.\\n\\n'},\n",
       "        {'param_name': 'chunksize',\n",
       "         'param_type': 'int or None',\n",
       "         'param_desc': 'Rows to write at a time.\\n'},\n",
       "        {'param_name': 'date_format',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'Format string for datetime objects.\\n'},\n",
       "        {'param_name': 'doublequote',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Control quoting of quotechar inside a field.\\n'},\n",
       "        {'param_name': 'escapechar',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'String of length 1. Character used to escape sep and quotechar\\nwhen appropriate.\\n'},\n",
       "        {'param_name': 'decimal',\n",
       "         'param_type': 'str, default ‘.’',\n",
       "         'param_desc': 'Character recognized as decimal separator. E.g. use ‘,’ for\\nEuropean data.\\n'},\n",
       "        {'param_name': 'errors',\n",
       "         'param_type': 'str, default ‘strict’',\n",
       "         'param_desc': 'Specifies how encoding and decoding errors are to be handled.\\nSee the errors argument for open() for a full list\\nof options.\\n'},\n",
       "        {'param_name': 'storage_options',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.to_csv',\n",
       "       'descriptions': 'Write object to a comma-separated values (csv) file.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'path_or_buf': {'type': 'string',\n",
       "          'description': 'str, path object, file-like object, or None, default None. String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a write() function. If None, the result is\\nreturned as a string. If a non-binary file object is passed, it should\\nbe opened with newline=’’, disabling universal newlines. If a binary\\nfile object is passed, mode might need to contain a ‘b’.\\n'},\n",
       "         'sep': {'type': 'string',\n",
       "          'description': 'str, default ‘,’. String of length 1. Field delimiter for the output file.\\n'},\n",
       "         'na_rep': {'type': 'string',\n",
       "          'description': 'str, default ‘’. Missing data representation.\\n'},\n",
       "         'float_format': {'type': 'string',\n",
       "          'description': 'str, Callable, default None. Format string for floating point numbers. If a Callable is given, it takes\\nprecedence over other numeric formatting parameters, like decimal.\\n'},\n",
       "         'columns': {'type': 'sequence, optional',\n",
       "          'description': 'sequence, optional. Columns to write.\\n'},\n",
       "         'header': {'type': 'string',\n",
       "          'description': 'bool or list of str, default True. Write out the column names. If a list of strings is given it is\\nassumed to be aliases for the column names.\\n'},\n",
       "         'index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Write row names (index).\\n'},\n",
       "         'index_label': {'type': 'string',\n",
       "          'description': 'str or sequence, or False, default None. Column label for index column(s) if desired. If None is given, and\\nheader and index are True, then the index names are used. A\\nsequence should be given if the object uses MultiIndex. If\\nFalse do not print fields for index names. Use index_label=False\\nfor easier importing in R.\\n'},\n",
       "         'mode': {'type': 'string',\n",
       "          'enum': ['w', ' x', ' a'],\n",
       "          'description': '{‘w’, ‘x’, ‘a’}, default ‘w’. Forwarded to either open(mode=) or fsspec.open(mode=) to control\\nthe file opening. Typical values include:\\n\\n‘w’, truncate the file first.\\n‘x’, exclusive creation, failing if the file already exists.\\n‘a’, append to the end of file if it exists.\\n\\n'},\n",
       "         'encoding': {'type': 'string',\n",
       "          'description': 'str, optional. A string representing the encoding to use in the output file,\\ndefaults to ‘utf-8’. encoding is not supported if path_or_buf\\nis a non-binary file object.\\n'},\n",
       "         'compression': {'type': 'string',\n",
       "          'description': \"str or dict, default ‘infer’. For on-the-fly compression of the output data. If ‘infer’ and ‘path_or_buf’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nSet to None for no compression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for faster compression and to create\\na reproducible gzip archive:\\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\nMay be a dict with key ‘method’ as compression mode\\nand other entries as additional compression options if\\ncompression mode is ‘zip’.\\nPassing compression options as keys in dict is\\nsupported for compression modes ‘gzip’, ‘bz2’, ‘zstd’, and ‘zip’.\\n\\n\"},\n",
       "         'quoting': {'type': 'optional constant from csv module',\n",
       "          'description': 'optional constant from csv module. Defaults to csv.QUOTE_MINIMAL. If you have set a float_format\\nthen floats are converted to strings and thus csv.QUOTE_NONNUMERIC\\nwill treat them as non-numeric.\\n'},\n",
       "         'quotechar': {'type': 'string',\n",
       "          'description': 'str, default ‘\"’. String of length 1. Character used to quote fields.\\n'},\n",
       "         'lineterminator': {'type': 'string',\n",
       "          'description': 'str, optional. The newline character or character sequence to use in the output\\nfile. Defaults to os.linesep, which depends on the OS in which\\nthis method is called (’\\\\n’ for linux, ‘\\\\r\\\\n’ for Windows, i.e.).\\n\\nChanged in version 1.5.0: Previously was line_terminator, changed for consistency with\\nread_csv and the standard library ‘csv’ module.\\n\\n'},\n",
       "         'chunksize': {'type': 'integer',\n",
       "          'description': 'int or None. Rows to write at a time.\\n'},\n",
       "         'date_format': {'type': 'string',\n",
       "          'description': 'str, default None. Format string for datetime objects.\\n'},\n",
       "         'doublequote': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Control quoting of quotechar inside a field.\\n'},\n",
       "         'escapechar': {'type': 'string',\n",
       "          'description': 'str, default None. String of length 1. Character used to escape sep and quotechar\\nwhen appropriate.\\n'},\n",
       "         'decimal': {'type': 'string',\n",
       "          'description': 'str, default ‘.’. Character recognized as decimal separator. E.g. use ‘,’ for\\nEuropean data.\\n'},\n",
       "         'errors': {'type': 'string',\n",
       "          'description': 'str, default ‘strict’. Specifies how encoding and decoding errors are to be handled.\\nSee the errors argument for open() for a full list\\nof options.\\n'},\n",
       "         'storage_options': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'}},\n",
       "        'required': ['path_or_buf=None']}}},\n",
       "     {'func_name': 'Series.to_excel(excel_writer,\\xa0*[,\\xa0...])',\n",
       "      'func_desc': 'Write object to an Excel sheet.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.to_excel.html#pandas.Series.to_excel',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.to_excel',\n",
       "       'full_function': \"Series.to_excel(excel_writer, *, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, inf_rep='inf', freeze_panes=None, storage_options=None, engine_kwargs=None)\",\n",
       "       'function_text': 'Write object to an Excel sheet. To write a single object to an Excel .xlsx file it is only necessary to\\nspecify a target file name. To write to multiple sheets it is necessary to\\ncreate an ExcelWriter object with a target file name, and specify a sheet\\nin the file to write to. Multiple sheets may be written to by specifying unique sheet_name.\\nWith all data written to the file it is necessary to save the changes.\\nNote that creating an ExcelWriter object with a file name that already\\nexists will result in the contents of the existing file being erased.',\n",
       "       'parameter_names_desc': [{'param_name': 'excel_writer',\n",
       "         'param_type': 'path-like, file-like, or ExcelWriter object',\n",
       "         'param_desc': 'File path or existing ExcelWriter.\\n'},\n",
       "        {'param_name': 'sheet_name',\n",
       "         'param_type': 'str, default ‘Sheet1’',\n",
       "         'param_desc': 'Name of sheet which will contain DataFrame.\\n'},\n",
       "        {'param_name': 'na_rep',\n",
       "         'param_type': 'str, default ‘’',\n",
       "         'param_desc': 'Missing data representation.\\n'},\n",
       "        {'param_name': 'float_format',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Format string for floating point numbers. For example\\nfloat_format=\"%.2f\" will format 0.1234 to 0.12.\\n'},\n",
       "        {'param_name': 'columns',\n",
       "         'param_type': 'sequence or list of str, optional',\n",
       "         'param_desc': 'Columns to write.\\n'},\n",
       "        {'param_name': 'header',\n",
       "         'param_type': 'bool or list of str, default True',\n",
       "         'param_desc': 'Write out the column names. If a list of string is given it is\\nassumed to be aliases for the column names.\\n'},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Write row names (index).\\n'},\n",
       "        {'param_name': 'index_label',\n",
       "         'param_type': 'str or sequence, optional',\n",
       "         'param_desc': 'Column label for index column(s) if desired. If not specified, and\\nheader and index are True, then the index names are used. A\\nsequence should be given if the DataFrame uses MultiIndex.\\n'},\n",
       "        {'param_name': 'startrow',\n",
       "         'param_type': 'int, default 0',\n",
       "         'param_desc': 'Upper left cell row to dump data frame.\\n'},\n",
       "        {'param_name': 'startcol',\n",
       "         'param_type': 'int, default 0',\n",
       "         'param_desc': 'Upper left cell column to dump data frame.\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Write engine to use, ‘openpyxl’ or ‘xlsxwriter’. You can also set this\\nvia the options io.excel.xlsx.writer or\\nio.excel.xlsm.writer.\\n'},\n",
       "        {'param_name': 'merge_cells',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Write MultiIndex and Hierarchical Rows as merged cells.\\n'},\n",
       "        {'param_name': 'inf_rep',\n",
       "         'param_type': 'str, default ‘inf’',\n",
       "         'param_desc': 'Representation for infinity (there is no native representation for\\ninfinity in Excel).\\n'},\n",
       "        {'param_name': 'freeze_panes',\n",
       "         'param_type': 'tuple of int (length 2), optional',\n",
       "         'param_desc': 'Specifies the one-based bottommost row and rightmost column that\\nis to be frozen.\\n'},\n",
       "        {'param_name': 'storage_options',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n\\nNew in version 1.2.0.\\n\\n'},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Arbitrary keyword arguments passed to excel engine.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.to_excel',\n",
       "       'descriptions': 'Write object to an Excel sheet. To write a single object to an Excel .xlsx file it is only necessary to\\nspecify a target file name. To write to multiple sheets it is necessary to\\ncreate an ExcelWriter object with a target file name, and specify a sheet\\nin the file to write to. Multiple sheets may be written to by specifying unique sheet_name.\\nWith all data written to the file it is necessary to save the changes.\\nNote that creating an ExcelWriter object with a file name that already\\nexists will result in the contents of the existing file being erased.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'excel_writer': {'type': 'object',\n",
       "          'description': 'path-like, file-like, or ExcelWriter object. File path or existing ExcelWriter.\\n'},\n",
       "         'sheet_name': {'type': 'string',\n",
       "          'description': 'str, default ‘Sheet1’. Name of sheet which will contain DataFrame.\\n'},\n",
       "         'na_rep': {'type': 'string',\n",
       "          'description': 'str, default ‘’. Missing data representation.\\n'},\n",
       "         'float_format': {'type': 'string',\n",
       "          'description': 'str, optional. Format string for floating point numbers. For example\\nfloat_format=\"%.2f\" will format 0.1234 to 0.12.\\n'},\n",
       "         'columns': {'type': 'string',\n",
       "          'description': 'sequence or list of str, optional. Columns to write.\\n'},\n",
       "         'header': {'type': 'string',\n",
       "          'description': 'bool or list of str, default True. Write out the column names. If a list of string is given it is\\nassumed to be aliases for the column names.\\n'},\n",
       "         'index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Write row names (index).\\n'},\n",
       "         'index_label': {'type': 'string',\n",
       "          'description': 'str or sequence, optional. Column label for index column(s) if desired. If not specified, and\\nheader and index are True, then the index names are used. A\\nsequence should be given if the DataFrame uses MultiIndex.\\n'},\n",
       "         'startrow': {'type': 'integer',\n",
       "          'description': 'int, default 0. Upper left cell row to dump data frame.\\n'},\n",
       "         'startcol': {'type': 'integer',\n",
       "          'description': 'int, default 0. Upper left cell column to dump data frame.\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': 'str, optional. Write engine to use, ‘openpyxl’ or ‘xlsxwriter’. You can also set this\\nvia the options io.excel.xlsx.writer or\\nio.excel.xlsm.writer.\\n'},\n",
       "         'merge_cells': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Write MultiIndex and Hierarchical Rows as merged cells.\\n'},\n",
       "         'inf_rep': {'type': 'string',\n",
       "          'description': 'str, default ‘inf’. Representation for infinity (there is no native representation for\\ninfinity in Excel).\\n'},\n",
       "         'freeze_panes': {'type': 'integer',\n",
       "          'description': 'tuple of int (length 2), optional. Specifies the one-based bottommost row and rightmost column that\\nis to be frozen.\\n'},\n",
       "         'storage_options': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n\\nNew in version 1.2.0.\\n\\n'},\n",
       "         'engine_kwargs': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Arbitrary keyword arguments passed to excel engine.\\n'}},\n",
       "        'required': ['excel_writer']}}},\n",
       "     {'func_name': 'Series.to_xarray()',\n",
       "      'func_desc': 'Return an xarray object from the pandas object.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.to_xarray.html#pandas.Series.to_xarray',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.to_xarray',\n",
       "       'full_function': 'Series.to_xarray()',\n",
       "       'function_text': 'Return an xarray object from the pandas object.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.to_sql(name,\\xa0con,\\xa0*[,\\xa0schema,\\xa0...])',\n",
       "      'func_desc': 'Write records stored in a DataFrame to a SQL database.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.to_sql.html#pandas.Series.to_sql',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.to_sql',\n",
       "       'full_function': \"Series.to_sql(name, con, *, schema=None, if_exists='fail', index=True, index_label=None, chunksize=None, dtype=None, method=None)\",\n",
       "       'function_text': 'Write records stored in a DataFrame to a SQL database. Databases supported by SQLAlchemy [1] are supported. Tables can be\\nnewly created, appended to, or overwritten.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Series.to_string([buf,\\xa0na_rep,\\xa0...])',\n",
       "      'func_desc': 'Render a string representation of the Series.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.to_string.html#pandas.Series.to_string',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.to_string',\n",
       "       'full_function': \"Series.to_string(buf=None, na_rep='NaN', float_format=None, header=True, index=True, length=False, dtype=False, name=False, max_rows=None, min_rows=None)\",\n",
       "       'function_text': 'Render a string representation of the Series.',\n",
       "       'parameter_names_desc': [{'param_name': 'buf',\n",
       "         'param_type': 'StringIO-like, optional',\n",
       "         'param_desc': 'Buffer to write to.\\n'},\n",
       "        {'param_name': 'na_rep',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'String representation of NaN to use, default ‘NaN’.\\n'},\n",
       "        {'param_name': 'float_format',\n",
       "         'param_type': 'one-parameter function, optional',\n",
       "         'param_desc': 'Formatter function to apply to columns’ elements if they are\\nfloats, default None.\\n'},\n",
       "        {'param_name': 'header',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Add the Series header (index name).\\n'},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'Add index (row) labels, default True.\\n'},\n",
       "        {'param_name': 'length',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Add the Series length.\\n'},\n",
       "        {'param_name': 'dtype',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Add the Series dtype.\\n'},\n",
       "        {'param_name': 'name',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Add the Series name if not None.\\n'},\n",
       "        {'param_name': 'max_rows',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Maximum number of rows to show before truncating. If None, show\\nall.\\n'},\n",
       "        {'param_name': 'min_rows',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'The number of rows to display in a truncated repr (when number\\nof rows is above max_rows).\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.to_string',\n",
       "       'descriptions': 'Render a string representation of the Series.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'buf': {'type': 'StringIO-like, optional',\n",
       "          'description': 'StringIO-like, optional. Buffer to write to.\\n'},\n",
       "         'na_rep': {'type': 'string',\n",
       "          'description': 'str, optional. String representation of NaN to use, default ‘NaN’.\\n'},\n",
       "         'float_format': {'type': 'one-parameter function, optional',\n",
       "          'description': 'one-parameter function, optional. Formatter function to apply to columns’ elements if they are\\nfloats, default None.\\n'},\n",
       "         'header': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Add the Series header (index name).\\n'},\n",
       "         'index': {'type': 'boolean',\n",
       "          'description': 'bool, optional. Add index (row) labels, default True.\\n'},\n",
       "         'length': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Add the Series length.\\n'},\n",
       "         'dtype': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Add the Series dtype.\\n'},\n",
       "         'name': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Add the Series name if not None.\\n'},\n",
       "         'max_rows': {'type': 'integer',\n",
       "          'description': 'int, optional. Maximum number of rows to show before truncating. If None, show\\nall.\\n'},\n",
       "         'min_rows': {'type': 'integer',\n",
       "          'description': 'int, optional. The number of rows to display in a truncated repr (when number\\nof rows is above max_rows).\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Series.to_latex([buf,\\xa0columns,\\xa0header,\\xa0...])',\n",
       "      'func_desc': 'Render object to a LaTeX tabular, longtable, or nested table.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Series.to_latex.html#pandas.Series.to_latex',\n",
       "      'function_definitions': {'function_name': 'pandas.Series.to_latex',\n",
       "       'full_function': \"Series.to_latex(buf=None, *, columns=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, bold_rows=False, column_format=None, longtable=None, escape=None, encoding=None, decimal='.', multicolumn=None, multicolumn_format=None, multirow=None, caption=None, label=None, position=None)\",\n",
       "       'function_text': 'Render object to a LaTeX tabular, longtable, or nested table. Requires \\\\usepackage{{booktabs}}. The output can be copy/pasted\\ninto a main LaTeX document or read from an external file\\nwith \\\\input{{table.tex}}. Changed in version 2.0.0: Refactored to use the Styler implementation via jinja2 templating.',\n",
       "       'parameter_names_desc': [{'param_name': 'buf',\n",
       "         'param_type': 'str, Path or StringIO-like, optional, default None',\n",
       "         'param_desc': 'Buffer to write to. If None, the output is returned as a string.\\n'},\n",
       "        {'param_name': 'columns',\n",
       "         'param_type': 'list of label, optional',\n",
       "         'param_desc': 'The subset of columns to write. Writes all columns by default.\\n'},\n",
       "        {'param_name': 'header',\n",
       "         'param_type': 'bool or list of str, default True',\n",
       "         'param_desc': 'Write out the column names. If a list of strings is given,\\nit is assumed to be aliases for the column names.\\n'},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Write row names (index).\\n'},\n",
       "        {'param_name': 'na_rep',\n",
       "         'param_type': 'str, default ‘NaN’',\n",
       "         'param_desc': 'Missing data representation.\\n'},\n",
       "        {'param_name': 'formatters',\n",
       "         'param_type': 'list of functions or dict of {{str: function}}, optional',\n",
       "         'param_desc': 'Formatter functions to apply to columns’ elements by position or\\nname. The result of each function must be a unicode string.\\nList must be of length equal to the number of columns.\\n'},\n",
       "        {'param_name': 'float_format',\n",
       "         'param_type': 'one-parameter function or str, optional, default None',\n",
       "         'param_desc': 'Formatter for floating point numbers. For example\\nfloat_format=\"%.2f\" and float_format=\"{{:0.2f}}\".format will\\nboth result in 0.1234 being formatted as 0.12.\\n'},\n",
       "        {'param_name': 'sparsify',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'Set to False for a DataFrame with a hierarchical index to print\\nevery multiindex key at each row. By default, the value will be\\nread from the config module.\\n'},\n",
       "        {'param_name': 'index_names',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Prints the names of the indexes.\\n'},\n",
       "        {'param_name': 'bold_rows',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Make the row labels bold in the output.\\n'},\n",
       "        {'param_name': 'column_format',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'The columns format as specified in LaTeX table format e.g. ‘rcl’ for 3\\ncolumns. By default, ‘l’ will be used for all columns except\\ncolumns of numbers, which default to ‘r’.\\n'},\n",
       "        {'param_name': 'longtable',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'Use a longtable environment instead of tabular. Requires\\nadding a usepackage{{longtable}} to your LaTeX preamble.\\nBy default, the value will be read from the pandas config\\nmodule, and set to True if the option styler.latex.environment is\\n“longtable”.\\n\\nChanged in version 2.0.0: The pandas option affecting this argument has changed.\\n\\n'},\n",
       "        {'param_name': 'escape',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'By default, the value will be read from the pandas config\\nmodule and set to True if the option styler.format.escape is\\n“latex”. When set to False prevents from escaping latex special\\ncharacters in column names.\\n\\nChanged in version 2.0.0: The pandas option affecting this argument has changed, as has the\\ndefault value to False.\\n\\n'},\n",
       "        {'param_name': 'encoding',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'A string representing the encoding to use in the output file,\\ndefaults to ‘utf-8’.\\n'},\n",
       "        {'param_name': 'decimal',\n",
       "         'param_type': 'str, default ‘.’',\n",
       "         'param_desc': 'Character recognized as decimal separator, e.g. ‘,’ in Europe.\\n'},\n",
       "        {'param_name': 'multicolumn',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Use multicolumn to enhance MultiIndex columns.\\nThe default will be read from the config module, and is set\\nas the option styler.sparse.columns.\\n\\nChanged in version 2.0.0: The pandas option affecting this argument has changed.\\n\\n'},\n",
       "        {'param_name': 'multicolumn_format',\n",
       "         'param_type': 'str, default ‘r’',\n",
       "         'param_desc': 'The alignment for multicolumns, similar to column_format\\nThe default will be read from the config module, and is set as the option\\nstyler.latex.multicol_align.\\n\\nChanged in version 2.0.0: The pandas option affecting this argument has changed, as has the\\ndefault value to “r”.\\n\\n'},\n",
       "        {'param_name': 'multirow',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Use multirow to enhance MultiIndex rows. Requires adding a\\nusepackage{{multirow}} to your LaTeX preamble. Will print\\ncentered labels (instead of top-aligned) across the contained\\nrows, separating groups via clines. The default will be read\\nfrom the pandas config module, and is set as the option\\nstyler.sparse.index.\\n\\nChanged in version 2.0.0: The pandas option affecting this argument has changed, as has the\\ndefault value to True.\\n\\n'},\n",
       "        {'param_name': 'caption',\n",
       "         'param_type': 'str or tuple, optional',\n",
       "         'param_desc': 'Tuple (full_caption, short_caption),\\nwhich results in \\\\caption[short_caption]{{full_caption}};\\nif a single string is passed, no short caption will be set.\\n'},\n",
       "        {'param_name': 'label',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'The LaTeX label to be placed inside \\\\label{{}} in the output.\\nThis is used with \\\\ref{{}} in the main .tex file.\\n'},\n",
       "        {'param_name': 'position',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'The LaTeX positional argument for tables, to be placed after\\n\\\\begin{{}} in the output.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Series.to_latex',\n",
       "       'descriptions': 'Render object to a LaTeX tabular, longtable, or nested table. Requires \\\\usepackage{{booktabs}}. The output can be copy/pasted\\ninto a main LaTeX document or read from an external file\\nwith \\\\input{{table.tex}}. Changed in version 2.0.0: Refactored to use the Styler implementation via jinja2 templating.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'buf': {'type': 'string',\n",
       "          'description': 'str, Path or StringIO-like, optional, default None. Buffer to write to. If None, the output is returned as a string.\\n'},\n",
       "         'columns': {'type': 'array',\n",
       "          'description': 'list of label, optional. The subset of columns to write. Writes all columns by default.\\n'},\n",
       "         'header': {'type': 'string',\n",
       "          'description': 'bool or list of str, default True. Write out the column names. If a list of strings is given,\\nit is assumed to be aliases for the column names.\\n'},\n",
       "         'index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Write row names (index).\\n'},\n",
       "         'na_rep': {'type': 'string',\n",
       "          'description': 'str, default ‘NaN’. Missing data representation.\\n'},\n",
       "         'formatters': {'type': 'string',\n",
       "          'description': 'list of functions or dict of {{str: function}}, optional. Formatter functions to apply to columns’ elements by position or\\nname. The result of each function must be a unicode string.\\nList must be of length equal to the number of columns.\\n'},\n",
       "         'float_format': {'type': 'string',\n",
       "          'description': 'one-parameter function or str, optional, default None. Formatter for floating point numbers. For example\\nfloat_format=\"%.2f\" and float_format=\"{{:0.2f}}\".format will\\nboth result in 0.1234 being formatted as 0.12.\\n'},\n",
       "         'sparsify': {'type': 'boolean',\n",
       "          'description': 'bool, optional. Set to False for a DataFrame with a hierarchical index to print\\nevery multiindex key at each row. By default, the value will be\\nread from the config module.\\n'},\n",
       "         'index_names': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Prints the names of the indexes.\\n'},\n",
       "         'bold_rows': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Make the row labels bold in the output.\\n'},\n",
       "         'column_format': {'type': 'string',\n",
       "          'description': 'str, optional. The columns format as specified in LaTeX table format e.g. ‘rcl’ for 3\\ncolumns. By default, ‘l’ will be used for all columns except\\ncolumns of numbers, which default to ‘r’.\\n'},\n",
       "         'longtable': {'type': 'boolean',\n",
       "          'description': 'bool, optional. Use a longtable environment instead of tabular. Requires\\nadding a usepackage{{longtable}} to your LaTeX preamble.\\nBy default, the value will be read from the pandas config\\nmodule, and set to True if the option styler.latex.environment is\\n“longtable”.\\n\\nChanged in version 2.0.0: The pandas option affecting this argument has changed.\\n\\n'},\n",
       "         'escape': {'type': 'boolean',\n",
       "          'description': 'bool, optional. By default, the value will be read from the pandas config\\nmodule and set to True if the option styler.format.escape is\\n“latex”. When set to False prevents from escaping latex special\\ncharacters in column names.\\n\\nChanged in version 2.0.0: The pandas option affecting this argument has changed, as has the\\ndefault value to False.\\n\\n'},\n",
       "         'encoding': {'type': 'string',\n",
       "          'description': 'str, optional. A string representing the encoding to use in the output file,\\ndefaults to ‘utf-8’.\\n'},\n",
       "         'decimal': {'type': 'string',\n",
       "          'description': 'str, default ‘.’. Character recognized as decimal separator, e.g. ‘,’ in Europe.\\n'},\n",
       "         'multicolumn': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Use multicolumn to enhance MultiIndex columns.\\nThe default will be read from the config module, and is set\\nas the option styler.sparse.columns.\\n\\nChanged in version 2.0.0: The pandas option affecting this argument has changed.\\n\\n'},\n",
       "         'multicolumn_format': {'type': 'string',\n",
       "          'description': 'str, default ‘r’. The alignment for multicolumns, similar to column_format\\nThe default will be read from the config module, and is set as the option\\nstyler.latex.multicol_align.\\n\\nChanged in version 2.0.0: The pandas option affecting this argument has changed, as has the\\ndefault value to “r”.\\n\\n'},\n",
       "         'multirow': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Use multirow to enhance MultiIndex rows. Requires adding a\\nusepackage{{multirow}} to your LaTeX preamble. Will print\\ncentered labels (instead of top-aligned) across the contained\\nrows, separating groups via clines. The default will be read\\nfrom the pandas config module, and is set as the option\\nstyler.sparse.index.\\n\\nChanged in version 2.0.0: The pandas option affecting this argument has changed, as has the\\ndefault value to True.\\n\\n'},\n",
       "         'caption': {'type': 'string',\n",
       "          'description': 'str or tuple, optional. Tuple (full_caption, short_caption),\\nwhich results in \\\\caption[short_caption]{{full_caption}};\\nif a single string is passed, no short caption will be set.\\n'},\n",
       "         'label': {'type': 'string',\n",
       "          'description': 'str, optional. The LaTeX label to be placed inside \\\\label{{}} in the output.\\nThis is used with \\\\ref{{}} in the main .tex file.\\n'},\n",
       "         'position': {'type': 'string',\n",
       "          'description': 'str, optional. The LaTeX positional argument for tables, to be placed after\\n\\\\begin{{}} in the output.\\n'}},\n",
       "        'required': ['buf=None']}}}]}],\n",
       "  'name': 'Series',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/series.html'},\n",
       " 'frame.html': {'functions': [{'Constructor': [{'func_name': 'DataFrame([data,\\xa0index,\\xa0columns,\\xa0dtype,\\xa0copy])',\n",
       "      'func_desc': 'Two-dimensional, size-mutable, potentially heterogeneous tabular data.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html#pandas.DataFrame',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame',\n",
       "       'full_function': 'class pandas.DataFrame(data=None, index=None, columns=None, dtype=None, copy=None)',\n",
       "       'function_text': 'Two-dimensional, size-mutable, potentially heterogeneous tabular data. Data structure also contains labeled axes (rows and columns).\\nArithmetic operations align on both row and column labels. Can be\\nthought of as a dict-like container for Series objects. The primary\\npandas data structure.',\n",
       "       'parameter_names_desc': [{'param_name': 'data',\n",
       "         'param_type': 'ndarray (structured or homogeneous), Iterable, dict, or DataFrame',\n",
       "         'param_desc': 'Dict can contain Series, arrays, constants, dataclass or list-like objects. If\\ndata is a dict, column order follows insertion-order. If a dict contains Series\\nwhich have an index defined, it is aligned by its index. This alignment also\\noccurs if data is a Series or a DataFrame itself. Alignment is done on\\nSeries/DataFrame inputs.\\nIf data is a list of dicts, column order follows insertion-order.\\n'},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'Index or array-like',\n",
       "         'param_desc': 'Index to use for resulting frame. Will default to RangeIndex if\\nno indexing information part of input data and no index provided.\\n'},\n",
       "        {'param_name': 'columns',\n",
       "         'param_type': 'Index or array-like',\n",
       "         'param_desc': 'Column labels to use for resulting frame when data does not have them,\\ndefaulting to RangeIndex(0, 1, 2, …, n). If data contains column labels,\\nwill perform column selection instead.\\n'},\n",
       "        {'param_name': 'dtype',\n",
       "         'param_type': 'dtype, default None',\n",
       "         'param_desc': 'Data type to force. Only a single dtype is allowed. If None, infer.\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool or None, default None',\n",
       "         'param_desc': 'Copy data from inputs.\\nFor dict data, the default of None behaves like copy=True. For DataFrame\\nor 2d ndarray input, the default of None behaves like copy=False.\\nIf data is a dict containing one or more Series (possibly of different dtypes),\\ncopy=False will ensure that these inputs are not copied.\\n\\nChanged in version 1.3.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame',\n",
       "       'descriptions': 'Two-dimensional, size-mutable, potentially heterogeneous tabular data. Data structure also contains labeled axes (rows and columns).\\nArithmetic operations align on both row and column labels. Can be\\nthought of as a dict-like container for Series objects. The primary\\npandas data structure.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'data': {'type': 'string',\n",
       "          'description': 'ndarray (structured or homogeneous), Iterable, dict, or DataFrame. Dict can contain Series, arrays, constants, dataclass or list-like objects. If\\ndata is a dict, column order follows insertion-order. If a dict contains Series\\nwhich have an index defined, it is aligned by its index. This alignment also\\noccurs if data is a Series or a DataFrame itself. Alignment is done on\\nSeries/DataFrame inputs.\\nIf data is a list of dicts, column order follows insertion-order.\\n'},\n",
       "         'index': {'type': 'array',\n",
       "          'description': 'Index or array-like. Index to use for resulting frame. Will default to RangeIndex if\\nno indexing information part of input data and no index provided.\\n'},\n",
       "         'columns': {'type': 'array',\n",
       "          'description': 'Index or array-like. Column labels to use for resulting frame when data does not have them,\\ndefaulting to RangeIndex(0, 1, 2, …, n). If data contains column labels,\\nwill perform column selection instead.\\n'},\n",
       "         'dtype': {'type': 'dtype, default None',\n",
       "          'description': 'dtype, default None. Data type to force. Only a single dtype is allowed. If None, infer.\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool or None, default None. Copy data from inputs.\\nFor dict data, the default of None behaves like copy=True. For DataFrame\\nor 2d ndarray input, the default of None behaves like copy=False.\\nIf data is a dict containing one or more Series (possibly of different dtypes),\\ncopy=False will ensure that these inputs are not copied.\\n\\nChanged in version 1.3.0.\\n\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Attributes and underlying data': [{'func_name': 'DataFrame.index',\n",
       "      'func_desc': 'The index (row labels) of the DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.index.html#pandas.DataFrame.index',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.index',\n",
       "       'full_function': 'DataFrame.index#',\n",
       "       'function_text': 'The index (row labels) of the DataFrame. The index of a DataFrame is a series of labels that identify each row.\\nThe labels can be integers, strings, or any other hashable type. The index\\nis used for label-based access and alignment, and can be accessed or\\nmodified using this attribute.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.dtypes',\n",
       "      'func_desc': 'Return the dtypes in the DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dtypes.html#pandas.DataFrame.dtypes',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.dtypes',\n",
       "       'full_function': 'property DataFrame.dtypes',\n",
       "       'function_text': 'Return the dtypes in the DataFrame. This returns a Series with the data type of each column.\\nThe result’s index is the original DataFrame’s columns. Columns\\nwith mixed types are stored with the object dtype. See\\nthe User Guide for more.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.select_dtypes([include,\\xa0exclude])',\n",
       "      'func_desc': \"Return a subset of the DataFrame's columns based on the column dtypes.\",\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.select_dtypes.html#pandas.DataFrame.select_dtypes',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.select_dtypes',\n",
       "       'full_function': 'DataFrame.select_dtypes(include=None, exclude=None)',\n",
       "       'function_text': 'Return a subset of the DataFrame’s columns based on the column dtypes.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.axes',\n",
       "      'func_desc': 'Return a list representing the axes of the DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.axes.html#pandas.DataFrame.axes',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.axes',\n",
       "       'full_function': 'property DataFrame.axes',\n",
       "       'function_text': 'Return a list representing the axes of the DataFrame. It has the row axis labels and column axis labels as the only members.\\nThey are returned in that order. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.size',\n",
       "      'func_desc': 'Return an int representing the number of elements in this object.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.size.html#pandas.DataFrame.size',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.size',\n",
       "       'full_function': 'property DataFrame.size',\n",
       "       'function_text': 'Return an int representing the number of elements in this object. Return the number of rows if Series. Otherwise return the number of\\nrows times number of columns if DataFrame. See also Number of elements in the array. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.memory_usage([index,\\xa0deep])',\n",
       "      'func_desc': 'Return the memory usage of each column in bytes.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.memory_usage.html#pandas.DataFrame.memory_usage',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.memory_usage',\n",
       "       'full_function': 'DataFrame.memory_usage(index=True, deep=False)',\n",
       "       'function_text': 'Return the memory usage of each column in bytes. The memory usage can optionally include the contribution of\\nthe index and elements of object dtype. This value is displayed in DataFrame.info by default. This can be\\nsuppressed by setting pandas.options.display.memory_usage to False.',\n",
       "       'parameter_names_desc': [{'param_name': 'index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Specifies whether to include the memory usage of the DataFrame’s\\nindex in returned Series. If index=True, the memory usage of\\nthe index is the first item in the output.\\n'},\n",
       "        {'param_name': 'deep',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True, introspect the data deeply by interrogating\\nobject dtypes for system-level memory consumption, and include\\nit in the returned values.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.memory_usage',\n",
       "       'descriptions': 'Return the memory usage of each column in bytes. The memory usage can optionally include the contribution of\\nthe index and elements of object dtype. This value is displayed in DataFrame.info by default. This can be\\nsuppressed by setting pandas.options.display.memory_usage to False.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Specifies whether to include the memory usage of the DataFrame’s\\nindex in returned Series. If index=True, the memory usage of\\nthe index is the first item in the output.\\n'},\n",
       "         'deep': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True, introspect the data deeply by interrogating\\nobject dtypes for system-level memory consumption, and include\\nit in the returned values.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.set_flags(*[,\\xa0copy,\\xa0...])',\n",
       "      'func_desc': 'Return a new object with updated flags.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_flags.html#pandas.DataFrame.set_flags',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.set_flags',\n",
       "       'full_function': 'DataFrame.set_flags(*, copy=False, allows_duplicate_labels=None)',\n",
       "       'function_text': 'Return a new object with updated flags.',\n",
       "       'parameter_names_desc': [{'param_name': 'copy',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Specify if a copy of the object should be made.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'},\n",
       "        {'param_name': 'allows_duplicate_labels',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'Whether the returned object allows duplicate labels.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.set_flags',\n",
       "       'descriptions': 'Return a new object with updated flags.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Specify if a copy of the object should be made.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'},\n",
       "         'allows_duplicate_labels': {'type': 'boolean',\n",
       "          'description': 'bool, optional. Whether the returned object allows duplicate labels.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.columns',\n",
       "      'func_desc': 'The column labels of the DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.columns.html#pandas.DataFrame.columns',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.columns',\n",
       "       'full_function': 'DataFrame.columns#',\n",
       "       'function_text': 'The column labels of the DataFrame. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.info([verbose,\\xa0buf,\\xa0max_cols,\\xa0...])',\n",
       "      'func_desc': 'Print a concise summary of a DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html#pandas.DataFrame.info',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.info',\n",
       "       'full_function': 'DataFrame.info(verbose=None, buf=None, max_cols=None, memory_usage=None, show_counts=None)',\n",
       "       'function_text': 'Print a concise summary of a DataFrame. This method prints information about a DataFrame including\\nthe index dtype and columns, non-null values and memory usage.',\n",
       "       'parameter_names_desc': [{'param_name': 'verbose',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'Whether to print the full summary. By default, the setting in\\npandas.options.display.max_info_columns is followed.\\n'},\n",
       "        {'param_name': 'buf',\n",
       "         'param_type': 'writable buffer, defaults to sys.stdout',\n",
       "         'param_desc': 'Where to send the output. By default, the output is printed to\\nsys.stdout. Pass a writable buffer if you need to further process\\nthe output.\\n'},\n",
       "        {'param_name': 'max_cols',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'When to switch from the verbose to the truncated output. If the\\nDataFrame has more than max_cols columns, the truncated output\\nis used. By default, the setting in\\npandas.options.display.max_info_columns is used.\\n'},\n",
       "        {'param_name': 'memory_usage',\n",
       "         'param_type': 'bool, str, optional',\n",
       "         'param_desc': 'Specifies whether total memory usage of the DataFrame\\nelements (including the index) should be displayed. By default,\\nthis follows the pandas.options.display.memory_usage setting.\\nTrue always show memory usage. False never shows memory usage.\\nA value of ‘deep’ is equivalent to “True with deep introspection”.\\nMemory usage is shown in human-readable units (base-2\\nrepresentation). Without deep introspection a memory estimation is\\nmade based in column dtype and number of rows assuming values\\nconsume the same memory amount for corresponding dtypes. With deep\\nmemory introspection, a real memory usage calculation is performed\\nat the cost of computational resources. See the\\nFrequently Asked Questions for more\\ndetails.\\n'},\n",
       "        {'param_name': 'show_counts',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'Whether to show the non-null counts. By default, this is shown\\nonly if the DataFrame is smaller than\\npandas.options.display.max_info_rows and\\npandas.options.display.max_info_columns. A value of True always\\nshows the counts, and False never shows the counts.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.info',\n",
       "       'descriptions': 'Print a concise summary of a DataFrame. This method prints information about a DataFrame including\\nthe index dtype and columns, non-null values and memory usage.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'verbose': {'type': 'boolean',\n",
       "          'description': 'bool, optional. Whether to print the full summary. By default, the setting in\\npandas.options.display.max_info_columns is followed.\\n'},\n",
       "         'buf': {'type': 'writable buffer, defaults to sys.stdout',\n",
       "          'description': 'writable buffer, defaults to sys.stdout. Where to send the output. By default, the output is printed to\\nsys.stdout. Pass a writable buffer if you need to further process\\nthe output.\\n'},\n",
       "         'max_cols': {'type': 'integer',\n",
       "          'description': 'int, optional. When to switch from the verbose to the truncated output. If the\\nDataFrame has more than max_cols columns, the truncated output\\nis used. By default, the setting in\\npandas.options.display.max_info_columns is used.\\n'},\n",
       "         'memory_usage': {'type': 'string',\n",
       "          'description': 'bool, str, optional. Specifies whether total memory usage of the DataFrame\\nelements (including the index) should be displayed. By default,\\nthis follows the pandas.options.display.memory_usage setting.\\nTrue always show memory usage. False never shows memory usage.\\nA value of ‘deep’ is equivalent to “True with deep introspection”.\\nMemory usage is shown in human-readable units (base-2\\nrepresentation). Without deep introspection a memory estimation is\\nmade based in column dtype and number of rows assuming values\\nconsume the same memory amount for corresponding dtypes. With deep\\nmemory introspection, a real memory usage calculation is performed\\nat the cost of computational resources. See the\\nFrequently Asked Questions for more\\ndetails.\\n'},\n",
       "         'show_counts': {'type': 'boolean',\n",
       "          'description': 'bool, optional. Whether to show the non-null counts. By default, this is shown\\nonly if the DataFrame is smaller than\\npandas.options.display.max_info_rows and\\npandas.options.display.max_info_columns. A value of True always\\nshows the counts, and False never shows the counts.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.values',\n",
       "      'func_desc': 'Return a Numpy representation of the DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.values.html#pandas.DataFrame.values',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.values',\n",
       "       'full_function': 'property DataFrame.values',\n",
       "       'function_text': 'Return a Numpy representation of the DataFrame. Warning We recommend using DataFrame.to_numpy() instead. Only the values in the DataFrame will be returned, the axes labels\\nwill be removed.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.ndim',\n",
       "      'func_desc': 'Return an int representing the number of axes / array dimensions.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ndim.html#pandas.DataFrame.ndim',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.ndim',\n",
       "       'full_function': 'property DataFrame.ndim',\n",
       "       'function_text': 'Return an int representing the number of axes / array dimensions. Return 1 if Series. Otherwise return 2 if DataFrame. See also Number of array dimensions. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.shape',\n",
       "      'func_desc': 'Return a tuple representing the dimensionality of the DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shape.html#pandas.DataFrame.shape',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.shape',\n",
       "       'full_function': 'property DataFrame.shape',\n",
       "       'function_text': 'Return a tuple representing the dimensionality of the DataFrame. See also Tuple of array dimensions. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.empty',\n",
       "      'func_desc': 'Indicator whether Series/DataFrame is empty.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.empty.html#pandas.DataFrame.empty',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.empty',\n",
       "       'full_function': 'property DataFrame.empty',\n",
       "       'function_text': 'Indicator whether Series/DataFrame is empty. True if Series/DataFrame is entirely empty (no items), meaning any of the\\naxes are of length 0.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'Conversion': [{'func_name': 'DataFrame.astype(dtype[,\\xa0copy,\\xa0errors])',\n",
       "      'func_desc': 'Cast a pandas object to a specified dtype dtype.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html#pandas.DataFrame.astype',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.astype',\n",
       "       'full_function': \"DataFrame.astype(dtype, copy=None, errors='raise')\",\n",
       "       'function_text': 'Cast a pandas object to a specified dtype dtype.',\n",
       "       'parameter_names_desc': [{'param_name': 'dtype',\n",
       "         'param_type': 'str, data type, Series or Mapping of column name -> data type',\n",
       "         'param_desc': 'Use a str, numpy.dtype, pandas.ExtensionDtype or Python type to\\ncast entire pandas object to the same type. Alternatively, use a\\nmapping, e.g. {col: dtype, …}, where col is a column label and dtype is\\na numpy.dtype or Python type to cast one or more of the DataFrame’s\\ncolumns to column-specific types.\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Return a copy when copy=True (be very careful setting\\ncopy=False as changes to values then may propagate to other\\npandas objects).\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'},\n",
       "        {'param_name': 'errors',\n",
       "         'param_type': '{‘raise’, ‘ignore’}, default ‘raise’',\n",
       "         'param_desc': 'Control raising of exceptions on invalid data for provided dtype.\\n\\nraise : allow exceptions to be raised\\nignore : suppress exceptions. On error return original object.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.astype',\n",
       "       'descriptions': 'Cast a pandas object to a specified dtype dtype.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dtype': {'type': 'string',\n",
       "          'description': 'str, data type, Series or Mapping of column name -> data type. Use a str, numpy.dtype, pandas.ExtensionDtype or Python type to\\ncast entire pandas object to the same type. Alternatively, use a\\nmapping, e.g. {col: dtype, …}, where col is a column label and dtype is\\na numpy.dtype or Python type to cast one or more of the DataFrame’s\\ncolumns to column-specific types.\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Return a copy when copy=True (be very careful setting\\ncopy=False as changes to values then may propagate to other\\npandas objects).\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'},\n",
       "         'errors': {'type': 'string',\n",
       "          'enum': ['raise', ' ignore'],\n",
       "          'description': '{‘raise’, ‘ignore’}, default ‘raise’. Control raising of exceptions on invalid data for provided dtype.\\n\\nraise : allow exceptions to be raised\\nignore : suppress exceptions. On error return original object.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.infer_objects([copy])',\n",
       "      'func_desc': 'Attempt to infer better dtypes for object columns.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.infer_objects.html#pandas.DataFrame.infer_objects',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.infer_objects',\n",
       "       'full_function': 'DataFrame.infer_objects(copy=None)',\n",
       "       'function_text': 'Attempt to infer better dtypes for object columns. Attempts soft conversion of object-dtyped\\ncolumns, leaving non-object and unconvertible\\ncolumns unchanged. The inference rules are the\\nsame as during normal Series/DataFrame construction.',\n",
       "       'parameter_names_desc': [{'param_name': 'copy',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to make a copy for non-object or non-inferable columns\\nor Series.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.infer_objects',\n",
       "       'descriptions': 'Attempt to infer better dtypes for object columns. Attempts soft conversion of object-dtyped\\ncolumns, leaving non-object and unconvertible\\ncolumns unchanged. The inference rules are the\\nsame as during normal Series/DataFrame construction.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to make a copy for non-object or non-inferable columns\\nor Series.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.bool()',\n",
       "      'func_desc': '(DEPRECATED) Return the bool of a single element Series or DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.bool.html#pandas.DataFrame.bool',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.bool',\n",
       "       'full_function': 'DataFrame.bool()',\n",
       "       'function_text': 'Return the bool of a single element Series or DataFrame. Deprecated since version 2.1.0: bool is deprecated and will be removed in future version of pandas.\\nFor Series use pandas.Series.item. This must be a boolean scalar value, either True or False. It will raise a\\nValueError if the Series or DataFrame does not have exactly 1 element, or that\\nelement is not boolean (integer values 0 and 1 will also raise an exception).',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.convert_dtypes([infer_objects,\\xa0...])',\n",
       "      'func_desc': 'Convert columns to the best possible dtypes using dtypes supporting pd.NA.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.convert_dtypes.html#pandas.DataFrame.convert_dtypes',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.convert_dtypes',\n",
       "       'full_function': \"DataFrame.convert_dtypes(infer_objects=True, convert_string=True, convert_integer=True, convert_boolean=True, convert_floating=True, dtype_backend='numpy_nullable')\",\n",
       "       'function_text': 'Convert columns to the best possible dtypes using dtypes supporting pd.NA.',\n",
       "       'parameter_names_desc': [{'param_name': 'infer_objects',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether object dtypes should be converted to the best possible types.\\n'},\n",
       "        {'param_name': 'convert_string',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether object dtypes should be converted to StringDtype().\\n'},\n",
       "        {'param_name': 'convert_integer',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether, if possible, conversion can be done to integer extension types.\\n'},\n",
       "        {'param_name': 'convert_boolean',\n",
       "         'param_type': 'bool, defaults True',\n",
       "         'param_desc': 'Whether object dtypes should be converted to BooleanDtypes().\\n'},\n",
       "        {'param_name': 'convert_floating',\n",
       "         'param_type': 'bool, defaults True',\n",
       "         'param_desc': 'Whether, if possible, conversion can be done to floating extension types.\\nIf convert_integer is also True, preference will be give to integer\\ndtypes if the floats can be faithfully casted to integers.\\n'},\n",
       "        {'param_name': 'dtype_backend',\n",
       "         'param_type': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’',\n",
       "         'param_desc': 'Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.convert_dtypes',\n",
       "       'descriptions': 'Convert columns to the best possible dtypes using dtypes supporting pd.NA.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'infer_objects': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether object dtypes should be converted to the best possible types.\\n'},\n",
       "         'convert_string': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether object dtypes should be converted to StringDtype().\\n'},\n",
       "         'convert_integer': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether, if possible, conversion can be done to integer extension types.\\n'},\n",
       "         'convert_boolean': {'type': 'boolean',\n",
       "          'description': 'bool, defaults True. Whether object dtypes should be converted to BooleanDtypes().\\n'},\n",
       "         'convert_floating': {'type': 'boolean',\n",
       "          'description': 'bool, defaults True. Whether, if possible, conversion can be done to floating extension types.\\nIf convert_integer is also True, preference will be give to integer\\ndtypes if the floats can be faithfully casted to integers.\\n'},\n",
       "         'dtype_backend': {'type': 'string',\n",
       "          'enum': ['numpy_nullable', ' pyarrow'],\n",
       "          'description': '{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’. Back-end data type applied to the resultant DataFrame\\n(still experimental). Behaviour is as follows:\\n\\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\\n(default).\\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\\nDataFrame.\\n\\n\\nNew in version 2.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.copy([deep])',\n",
       "      'func_desc': \"Make a copy of this object's indices and data.\",\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.copy.html#pandas.DataFrame.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.copy',\n",
       "       'full_function': 'DataFrame.copy(deep=True)',\n",
       "       'function_text': 'Make a copy of this object’s indices and data. When deep=True (default), a new object will be created with a\\ncopy of the calling object’s data and indices. Modifications to\\nthe data or indices of the copy will not be reflected in the\\noriginal object (see notes below). When deep=False, a new object will be created without copying\\nthe calling object’s data or index (only references to the data\\nand index are copied). Any changes to the data of the original\\nwill be reflected in the shallow copy (and vice versa). Note The deep=False behaviour as described above will change\\nin pandas 3.0. Copy-on-Write\\nwill be enabled by default, which means that the “shallow” copy\\nis that is returned with deep=False will still avoid making\\nan eager copy, but changes to the data of the original will no\\nlonger be reflected in the shallow copy (or vice versa). Instead,\\nit makes use of a lazy (deferred) copy mechanism that will copy\\nthe data only when any changes to the original or shallow copy is\\nmade. You can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True',\n",
       "       'parameter_names_desc': [{'param_name': 'deep',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Make a deep copy, including a copy of the data and the indices.\\nWith deep=False neither the indices nor the data are copied.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.copy',\n",
       "       'descriptions': 'Make a copy of this object’s indices and data. When deep=True (default), a new object will be created with a\\ncopy of the calling object’s data and indices. Modifications to\\nthe data or indices of the copy will not be reflected in the\\noriginal object (see notes below). When deep=False, a new object will be created without copying\\nthe calling object’s data or index (only references to the data\\nand index are copied). Any changes to the data of the original\\nwill be reflected in the shallow copy (and vice versa). Note The deep=False behaviour as described above will change\\nin pandas 3.0. Copy-on-Write\\nwill be enabled by default, which means that the “shallow” copy\\nis that is returned with deep=False will still avoid making\\nan eager copy, but changes to the data of the original will no\\nlonger be reflected in the shallow copy (or vice versa). Instead,\\nit makes use of a lazy (deferred) copy mechanism that will copy\\nthe data only when any changes to the original or shallow copy is\\nmade. You can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'deep': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Make a deep copy, including a copy of the data and the indices.\\nWith deep=False neither the indices nor the data are copied.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.to_numpy([dtype,\\xa0copy,\\xa0na_value])',\n",
       "      'func_desc': 'Convert the DataFrame to a NumPy array.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_numpy.html#pandas.DataFrame.to_numpy',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_numpy',\n",
       "       'full_function': 'DataFrame.to_numpy(dtype=None, copy=False, na_value=_NoDefault.no_default)',\n",
       "       'function_text': 'Convert the DataFrame to a NumPy array. By default, the dtype of the returned array will be the common NumPy\\ndtype of all types in the DataFrame. For example, if the dtypes are\\nfloat16 and float32, the results dtype will be float32.\\nThis may require copying data and coercing values, which may be\\nexpensive.',\n",
       "       'parameter_names_desc': [{'param_name': 'dtype',\n",
       "         'param_type': 'str or numpy.dtype, optional',\n",
       "         'param_desc': 'The dtype to pass to numpy.asarray().\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to ensure that the returned value is not a view on\\nanother array. Note that copy=False does not ensure that\\nto_numpy() is no-copy. Rather, copy=True ensure that\\na copy is made, even if not strictly necessary.\\n'},\n",
       "        {'param_name': 'na_value',\n",
       "         'param_type': 'Any, optional',\n",
       "         'param_desc': 'The value to use for missing values. The default value depends\\non dtype and the dtypes of the DataFrame columns.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.to_numpy',\n",
       "       'descriptions': 'Convert the DataFrame to a NumPy array. By default, the dtype of the returned array will be the common NumPy\\ndtype of all types in the DataFrame. For example, if the dtypes are\\nfloat16 and float32, the results dtype will be float32.\\nThis may require copying data and coercing values, which may be\\nexpensive.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dtype': {'type': 'string',\n",
       "          'description': 'str or numpy.dtype, optional. The dtype to pass to numpy.asarray().\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to ensure that the returned value is not a view on\\nanother array. Note that copy=False does not ensure that\\nto_numpy() is no-copy. Rather, copy=True ensure that\\na copy is made, even if not strictly necessary.\\n'},\n",
       "         'na_value': {'type': 'Any, optional',\n",
       "          'description': 'Any, optional. The value to use for missing values. The default value depends\\non dtype and the dtypes of the DataFrame columns.\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Indexing, iteration': [{'func_name': 'DataFrame.head([n])',\n",
       "      'func_desc': 'Return the first n rows.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html#pandas.DataFrame.head',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.head',\n",
       "       'full_function': 'DataFrame.head(n=5)',\n",
       "       'function_text': 'Return the first n rows. This function returns the first n rows for the object based\\non position. It is useful for quickly testing if your object\\nhas the right type of data in it. For negative values of n, this function returns all rows except\\nthe last |n| rows, equivalent to df[:n]. If n is larger than the number of rows, this function returns all rows.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 5',\n",
       "         'param_desc': 'Number of rows to select.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.head',\n",
       "       'descriptions': 'Return the first n rows. This function returns the first n rows for the object based\\non position. It is useful for quickly testing if your object\\nhas the right type of data in it. For negative values of n, this function returns all rows except\\nthe last |n| rows, equivalent to df[:n]. If n is larger than the number of rows, this function returns all rows.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 5. Number of rows to select.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.iat',\n",
       "      'func_desc': 'Access a single value for a row/column pair by integer position.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iat.html#pandas.DataFrame.iat',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.iat',\n",
       "       'full_function': 'property DataFrame.iat',\n",
       "       'function_text': 'Access a single value for a row/column pair by integer position. Similar to iloc, in that both provide integer-based lookups. Use\\niat if you only need to get or set a single value in a DataFrame\\nor Series.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.iloc',\n",
       "      'func_desc': '(DEPRECATED) Purely integer-location based indexing for selection by position.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html#pandas.DataFrame.iloc',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.iloc',\n",
       "       'full_function': 'property DataFrame.iloc',\n",
       "       'function_text': 'Purely integer-location based indexing for selection by position. Deprecated since version 2.2.0: Returning a tuple from a callable is deprecated. .iloc[] is primarily integer position based (from 0 to\\nlength-1 of the axis), but may also be used with a boolean\\narray. Allowed inputs are: An integer, e.g. 5. A list or array of integers, e.g. [4, 3, 0]. A slice object with ints, e.g. 1:7. A boolean array. A callable function with one argument (the calling Series or\\nDataFrame) and that returns valid output for indexing (one of the above).\\nThis is useful in method chains, when you don’t have a reference to the\\ncalling object, but would like to base your selection on\\nsome value. A tuple of row and column indexes. The tuple elements consist of one of the\\nabove inputs, e.g. (0, 1). .iloc will raise IndexError if a requested indexer is\\nout-of-bounds, except slice indexers which allow out-of-bounds\\nindexing (this conforms with python/numpy slice semantics). See more at Selection by Position. See also Fast integer location scalar accessor. Purely label-location based indexer for selection by label. Purely integer-location based indexing for selection by position. Examples Indexing just the rows With a scalar integer. With a list of integers. With a slice object. With a boolean mask the same length as the index. With a callable, useful in method chains. The x passed\\nto the lambda is the DataFrame being sliced. This selects\\nthe rows whose index label even. Indexing both axes You can mix the indexer types for the index and columns. Use : to\\nselect the entire axis. With scalar integers. With lists of integers. With slice objects. With a boolean array whose length matches the columns. With a callable function that expects the Series or DataFrame.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.__iter__()',\n",
       "      'func_desc': 'Iterate over info axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.__iter__.html#pandas.DataFrame.__iter__',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.__iter__',\n",
       "       'full_function': 'DataFrame.__iter__()',\n",
       "       'function_text': 'Iterate over info axis.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.keys()',\n",
       "      'func_desc': \"Get the 'info axis' (see Indexing for more).\",\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.keys.html#pandas.DataFrame.keys',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.keys',\n",
       "       'full_function': 'DataFrame.keys()',\n",
       "       'function_text': 'Get the ‘info axis’ (see Indexing for more). This is index for Series, columns for DataFrame.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.itertuples([index,\\xa0name])',\n",
       "      'func_desc': 'Iterate over DataFrame rows as namedtuples.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.itertuples.html#pandas.DataFrame.itertuples',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.itertuples',\n",
       "       'full_function': \"DataFrame.itertuples(index=True, name='Pandas')\",\n",
       "       'function_text': 'Iterate over DataFrame rows as namedtuples.',\n",
       "       'parameter_names_desc': [{'param_name': 'index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If True, return the index as the first element of the tuple.\\n'},\n",
       "        {'param_name': 'name',\n",
       "         'param_type': 'str or None, default “Pandas”',\n",
       "         'param_desc': 'The name of the returned namedtuples or None to return regular\\ntuples.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.itertuples',\n",
       "       'descriptions': 'Iterate over DataFrame rows as namedtuples.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If True, return the index as the first element of the tuple.\\n'},\n",
       "         'name': {'type': 'string',\n",
       "          'description': 'str or None, default “Pandas”. The name of the returned namedtuples or None to return regular\\ntuples.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.tail([n])',\n",
       "      'func_desc': 'Return the last n rows.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tail.html#pandas.DataFrame.tail',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.tail',\n",
       "       'full_function': 'DataFrame.tail(n=5)',\n",
       "       'function_text': 'Return the last n rows. This function returns last n rows from the object based on\\nposition. It is useful for quickly verifying data, for example,\\nafter sorting or appending rows. For negative values of n, this function returns all rows except\\nthe first |n| rows, equivalent to df[|n|:]. If n is larger than the number of rows, this function returns all rows.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 5',\n",
       "         'param_desc': 'Number of rows to select.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.tail',\n",
       "       'descriptions': 'Return the last n rows. This function returns last n rows from the object based on\\nposition. It is useful for quickly verifying data, for example,\\nafter sorting or appending rows. For negative values of n, this function returns all rows except\\nthe first |n| rows, equivalent to df[|n|:]. If n is larger than the number of rows, this function returns all rows.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 5. Number of rows to select.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.get(key[,\\xa0default])',\n",
       "      'func_desc': 'Get item from object for given key (ex: DataFrame column).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.get.html#pandas.DataFrame.get',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.get',\n",
       "       'full_function': 'DataFrame.get(key, default=None)',\n",
       "       'function_text': 'Get item from object for given key (ex: DataFrame column). Returns default value if not found.',\n",
       "       'parameter_names_desc': [{'param_name': 'key',\n",
       "         'param_type': 'object',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.get',\n",
       "       'descriptions': 'Get item from object for given key (ex: DataFrame column). Returns default value if not found.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'key': {'type': 'object', 'description': 'object. '}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.where(cond[,\\xa0other,\\xa0inplace,\\xa0...])',\n",
       "      'func_desc': 'Replace values where the condition is False.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.where.html#pandas.DataFrame.where',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.where',\n",
       "       'full_function': 'DataFrame.where(cond, other=nan, *, inplace=False, axis=None, level=None)',\n",
       "       'function_text': 'Replace values where the condition is False.',\n",
       "       'parameter_names_desc': [{'param_name': 'cond',\n",
       "         'param_type': 'bool Series/DataFrame, array-like, or callable',\n",
       "         'param_desc': 'Where cond is True, keep the original value. Where\\nFalse, replace with corresponding value from other.\\nIf cond is callable, it is computed on the Series/DataFrame and\\nshould return boolean Series/DataFrame or array. The callable must\\nnot change input Series/DataFrame (though pandas doesn’t check it).\\n'},\n",
       "        {'param_name': 'other',\n",
       "         'param_type': 'scalar, Series/DataFrame, or callable',\n",
       "         'param_desc': 'Entries where cond is False are replaced with\\ncorresponding value from other.\\nIf other is callable, it is computed on the Series/DataFrame and\\nshould return scalar or Series/DataFrame. The callable must not\\nchange input Series/DataFrame (though pandas doesn’t check it).\\nIf not specified, entries will be filled with the corresponding\\nNULL value (np.nan for numpy dtypes, pd.NA for extension\\ndtypes).\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to perform the operation in place on the data.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'Alignment axis if needed. For Series this parameter is\\nunused and defaults to 0.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'Alignment level if needed.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.where',\n",
       "       'descriptions': 'Replace values where the condition is False.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'cond': {'type': 'boolean',\n",
       "          'description': 'bool Series/DataFrame, array-like, or callable. Where cond is True, keep the original value. Where\\nFalse, replace with corresponding value from other.\\nIf cond is callable, it is computed on the Series/DataFrame and\\nshould return boolean Series/DataFrame or array. The callable must\\nnot change input Series/DataFrame (though pandas doesn’t check it).\\n'},\n",
       "         'other': {'type': 'object',\n",
       "          'description': 'scalar, Series/DataFrame, or callable. Entries where cond is False are replaced with\\ncorresponding value from other.\\nIf other is callable, it is computed on the Series/DataFrame and\\nshould return scalar or Series/DataFrame. The callable must not\\nchange input Series/DataFrame (though pandas doesn’t check it).\\nIf not specified, entries will be filled with the corresponding\\nNULL value (np.nan for numpy dtypes, pd.NA for extension\\ndtypes).\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to perform the operation in place on the data.\\n'},\n",
       "         'axis': {'type': 'integer',\n",
       "          'description': 'int, default None. Alignment axis if needed. For Series this parameter is\\nunused and defaults to 0.\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int, default None. Alignment level if needed.\\n'}},\n",
       "        'required': ['cond', 'other=nan']}}},\n",
       "     {'func_name': 'DataFrame.query(expr,\\xa0*[,\\xa0inplace])',\n",
       "      'func_desc': 'Query the columns of a DataFrame with a boolean expression.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html#pandas.DataFrame.query',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.query',\n",
       "       'full_function': 'DataFrame.query(expr, *, inplace=False, **kwargs)',\n",
       "       'function_text': 'Query the columns of a DataFrame with a boolean expression.',\n",
       "       'parameter_names_desc': [{'param_name': 'expr',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'The query string to evaluate.\\nYou can refer to variables\\nin the environment by prefixing them with an ‘@’ character like\\n@a + b.\\nYou can refer to column names that are not valid Python variable names\\nby surrounding them in backticks. Thus, column names containing spaces\\nor punctuations (besides underscores) or starting with digits must be\\nsurrounded by backticks. (For example, a column named “Area (cm^2)” would\\nbe referenced as `Area (cm^2)`). Column names which are Python keywords\\n(like “list”, “for”, “import”, etc) cannot be used.\\nFor example, if one of your columns is called a a and you want\\nto sum it with b, your query should be `a a` + b.\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool',\n",
       "         'param_desc': 'Whether to modify the DataFrame rather than creating a new one.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.query',\n",
       "       'descriptions': 'Query the columns of a DataFrame with a boolean expression.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'expr': {'type': 'string',\n",
       "          'description': 'str. The query string to evaluate.\\nYou can refer to variables\\nin the environment by prefixing them with an ‘@’ character like\\n@a + b.\\nYou can refer to column names that are not valid Python variable names\\nby surrounding them in backticks. Thus, column names containing spaces\\nor punctuations (besides underscores) or starting with digits must be\\nsurrounded by backticks. (For example, a column named “Area (cm^2)” would\\nbe referenced as `Area (cm^2)`). Column names which are Python keywords\\n(like “list”, “for”, “import”, etc) cannot be used.\\nFor example, if one of your columns is called a a and you want\\nto sum it with b, your query should be `a a` + b.\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool. Whether to modify the DataFrame rather than creating a new one.\\n'}},\n",
       "        'required': ['expr']}}},\n",
       "     {'func_name': 'DataFrame.at',\n",
       "      'func_desc': 'Access a single value for a row/column label pair.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.at.html#pandas.DataFrame.at',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.at',\n",
       "       'full_function': 'property DataFrame.at',\n",
       "       'function_text': 'Access a single value for a row/column label pair. Similar to loc, in that both provide label-based lookups. Use\\nat if you only need to get or set a single value in a DataFrame\\nor Series.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.loc',\n",
       "      'func_desc': 'Access a group of rows and columns by label(s) or a boolean array.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.loc',\n",
       "       'full_function': 'property DataFrame.loc',\n",
       "       'function_text': \"Access a group of rows and columns by label(s) or a boolean array. .loc[] is primarily label based, but may also be used with a\\nboolean array. Allowed inputs are: A single label, e.g. 5 or 'a', (note that 5 is\\ninterpreted as a label of the index, and never as an\\ninteger position along the index). A list or array of labels, e.g. ['a', 'b', 'c']. A slice object with labels, e.g. 'a':'f'. Warning Note that contrary to usual python slices, both the\\nstart and the stop are included A boolean array of the same length as the axis being sliced,\\ne.g. [True, False, True]. An alignable boolean Series. The index of the key will be aligned before\\nmasking. An alignable Index. The Index of the returned selection will be the input. A callable function with one argument (the calling Series or\\nDataFrame) and that returns valid output for indexing (one of the above) See more at Selection by Label.\",\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.insert(loc,\\xa0column,\\xa0value[,\\xa0...])',\n",
       "      'func_desc': 'Insert column into DataFrame at specified location.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.insert.html#pandas.DataFrame.insert',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.insert',\n",
       "       'full_function': 'DataFrame.insert(loc, column, value, allow_duplicates=_NoDefault.no_default)',\n",
       "       'function_text': 'Insert column into DataFrame at specified location. Raises a ValueError if column is already contained in the DataFrame,\\nunless allow_duplicates is set to True.',\n",
       "       'parameter_names_desc': [{'param_name': 'loc',\n",
       "         'param_type': 'int',\n",
       "         'param_desc': 'Insertion index. Must verify 0 <= loc <= len(columns).\\n'},\n",
       "        {'param_name': 'column',\n",
       "         'param_type': 'str, number, or hashable object',\n",
       "         'param_desc': 'Label of the inserted column.\\n'},\n",
       "        {'param_name': 'value',\n",
       "         'param_type': 'Scalar, Series, or array-like',\n",
       "         'param_desc': 'Content of the inserted column.\\n'},\n",
       "        {'param_name': 'allow_duplicates',\n",
       "         'param_type': 'bool, optional, default lib.no_default',\n",
       "         'param_desc': 'Allow duplicate column labels to be created.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.insert',\n",
       "       'descriptions': 'Insert column into DataFrame at specified location. Raises a ValueError if column is already contained in the DataFrame,\\nunless allow_duplicates is set to True.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'loc': {'type': 'integer',\n",
       "          'description': 'int. Insertion index. Must verify 0 <= loc <= len(columns).\\n'},\n",
       "         'column': {'type': 'string',\n",
       "          'description': 'str, number, or hashable object. Label of the inserted column.\\n'},\n",
       "         'value': {'type': 'array',\n",
       "          'description': 'Scalar, Series, or array-like. Content of the inserted column.\\n'},\n",
       "         'allow_duplicates': {'type': 'boolean',\n",
       "          'description': 'bool, optional, default lib.no_default. Allow duplicate column labels to be created.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.items()',\n",
       "      'func_desc': 'Iterate over (column name, Series) pairs.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.items.html#pandas.DataFrame.items',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.items',\n",
       "       'full_function': 'DataFrame.items()',\n",
       "       'function_text': 'Iterate over (column name, Series) pairs. Iterates over the DataFrame columns, returning a tuple with\\nthe column name and the content as a Series.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.iterrows()',\n",
       "      'func_desc': 'Iterate over DataFrame rows as (index, Series) pairs.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iterrows.html#pandas.DataFrame.iterrows',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.iterrows',\n",
       "       'full_function': 'DataFrame.iterrows()',\n",
       "       'function_text': 'Iterate over DataFrame rows as (index, Series) pairs.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.pop(item)',\n",
       "      'func_desc': 'Return item and drop from frame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pop.html#pandas.DataFrame.pop',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.pop',\n",
       "       'full_function': 'DataFrame.pop(item)',\n",
       "       'function_text': 'Return item and drop from frame. Raise KeyError if not found.',\n",
       "       'parameter_names_desc': [{'param_name': 'item',\n",
       "         'param_type': 'label',\n",
       "         'param_desc': 'Label of column to be popped.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.pop',\n",
       "       'descriptions': 'Return item and drop from frame. Raise KeyError if not found.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'item': {'type': 'label',\n",
       "          'description': 'label. Label of column to be popped.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.xs(key[,\\xa0axis,\\xa0level,\\xa0drop_level])',\n",
       "      'func_desc': 'Return cross-section from the Series/DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.xs.html#pandas.DataFrame.xs',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.xs',\n",
       "       'full_function': 'DataFrame.xs(key, axis=0, level=None, drop_level=True)',\n",
       "       'function_text': 'Return cross-section from the Series/DataFrame. This method takes a key argument to select data at a particular\\nlevel of a MultiIndex.',\n",
       "       'parameter_names_desc': [{'param_name': 'key',\n",
       "         'param_type': 'label or tuple of label',\n",
       "         'param_desc': 'Label contained in the index, or partially in a MultiIndex.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'Axis to retrieve cross-section on.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'object, defaults to first n levels (n=1 or len(key))',\n",
       "         'param_desc': 'In case of a key partially contained in a MultiIndex, indicate\\nwhich levels are used. Levels can be referred by label or position.\\n'},\n",
       "        {'param_name': 'drop_level',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If False, returns object with same levels as self.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.xs',\n",
       "       'descriptions': 'Return cross-section from the Series/DataFrame. This method takes a key argument to select data at a particular\\nlevel of a MultiIndex.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'key': {'type': 'label or tuple of label',\n",
       "          'description': 'label or tuple of label. Label contained in the index, or partially in a MultiIndex.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. Axis to retrieve cross-section on.\\n'},\n",
       "         'level': {'type': 'object',\n",
       "          'description': 'object, defaults to first n levels (n=1 or len(key)). In case of a key partially contained in a MultiIndex, indicate\\nwhich levels are used. Levels can be referred by label or position.\\n'},\n",
       "         'drop_level': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If False, returns object with same levels as self.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.isin(values)',\n",
       "      'func_desc': 'Whether each element in the DataFrame is contained in values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isin.html#pandas.DataFrame.isin',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.isin',\n",
       "       'full_function': 'DataFrame.isin(values)',\n",
       "       'function_text': 'Whether each element in the DataFrame is contained in values.',\n",
       "       'parameter_names_desc': [{'param_name': 'values',\n",
       "         'param_type': 'iterable, Series, DataFrame or dict',\n",
       "         'param_desc': 'The result will only be true at a location if all the\\nlabels match. If values is a Series, that’s the index. If\\nvalues is a dict, the keys must be the column names,\\nwhich must match. If values is a DataFrame,\\nthen both the index and column labels must match.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.isin',\n",
       "       'descriptions': 'Whether each element in the DataFrame is contained in values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'values': {'type': 'iterable, Series, DataFrame or dict',\n",
       "          'description': 'iterable, Series, DataFrame or dict. The result will only be true at a location if all the\\nlabels match. If values is a Series, that’s the index. If\\nvalues is a dict, the keys must be the column names,\\nwhich must match. If values is a DataFrame,\\nthen both the index and column labels must match.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.mask(cond[,\\xa0other,\\xa0inplace,\\xa0axis,\\xa0...])',\n",
       "      'func_desc': 'Replace values where the condition is True.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mask.html#pandas.DataFrame.mask',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.mask',\n",
       "       'full_function': 'DataFrame.mask(cond, other=_NoDefault.no_default, *, inplace=False, axis=None, level=None)',\n",
       "       'function_text': 'Replace values where the condition is True.',\n",
       "       'parameter_names_desc': [{'param_name': 'cond',\n",
       "         'param_type': 'bool Series/DataFrame, array-like, or callable',\n",
       "         'param_desc': 'Where cond is False, keep the original value. Where\\nTrue, replace with corresponding value from other.\\nIf cond is callable, it is computed on the Series/DataFrame and\\nshould return boolean Series/DataFrame or array. The callable must\\nnot change input Series/DataFrame (though pandas doesn’t check it).\\n'},\n",
       "        {'param_name': 'other',\n",
       "         'param_type': 'scalar, Series/DataFrame, or callable',\n",
       "         'param_desc': 'Entries where cond is True are replaced with\\ncorresponding value from other.\\nIf other is callable, it is computed on the Series/DataFrame and\\nshould return scalar or Series/DataFrame. The callable must not\\nchange input Series/DataFrame (though pandas doesn’t check it).\\nIf not specified, entries will be filled with the corresponding\\nNULL value (np.nan for numpy dtypes, pd.NA for extension\\ndtypes).\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to perform the operation in place on the data.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'Alignment axis if needed. For Series this parameter is\\nunused and defaults to 0.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'Alignment level if needed.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.mask',\n",
       "       'descriptions': 'Replace values where the condition is True.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'cond': {'type': 'boolean',\n",
       "          'description': 'bool Series/DataFrame, array-like, or callable. Where cond is False, keep the original value. Where\\nTrue, replace with corresponding value from other.\\nIf cond is callable, it is computed on the Series/DataFrame and\\nshould return boolean Series/DataFrame or array. The callable must\\nnot change input Series/DataFrame (though pandas doesn’t check it).\\n'},\n",
       "         'other': {'type': 'object',\n",
       "          'description': 'scalar, Series/DataFrame, or callable. Entries where cond is True are replaced with\\ncorresponding value from other.\\nIf other is callable, it is computed on the Series/DataFrame and\\nshould return scalar or Series/DataFrame. The callable must not\\nchange input Series/DataFrame (though pandas doesn’t check it).\\nIf not specified, entries will be filled with the corresponding\\nNULL value (np.nan for numpy dtypes, pd.NA for extension\\ndtypes).\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to perform the operation in place on the data.\\n'},\n",
       "         'axis': {'type': 'integer',\n",
       "          'description': 'int, default None. Alignment axis if needed. For Series this parameter is\\nunused and defaults to 0.\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int, default None. Alignment level if needed.\\n'}},\n",
       "        'required': ['cond', 'other=_NoDefault.no_default']}}}]},\n",
       "   {'Binary operator functions': [{'func_name': 'DataFrame.__add__(other)',\n",
       "      'func_desc': 'Get Addition of DataFrame and other, column-wise.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.__add__.html#pandas.DataFrame.__add__',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.__add__',\n",
       "       'full_function': 'DataFrame.__add__(other)',\n",
       "       'function_text': 'Get Addition of DataFrame and other, column-wise. Equivalent to DataFrame.add(other).',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'scalar, sequence, Series, dict or DataFrame',\n",
       "         'param_desc': 'Object to be added to the DataFrame.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.__add__',\n",
       "       'descriptions': 'Get Addition of DataFrame and other, column-wise. Equivalent to DataFrame.add(other).',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'scalar, sequence, Series, dict or DataFrame',\n",
       "          'description': 'scalar, sequence, Series, dict or DataFrame. Object to be added to the DataFrame.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.sub(other[,\\xa0axis,\\xa0level,\\xa0fill_value])',\n",
       "      'func_desc': 'Get Subtraction of dataframe and other, element-wise (binary operator sub).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sub.html#pandas.DataFrame.sub',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.sub',\n",
       "       'full_function': \"DataFrame.sub(other, axis='columns', level=None, fill_value=None)\",\n",
       "       'function_text': 'Get Subtraction of dataframe and other, element-wise (binary operator sub). Equivalent to dataframe - other, but with support to substitute a fill_value\\nfor missing data in one of the inputs. With reverse version, rsub. Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to\\narithmetic operators: +, -, *, /, //, %, **.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'scalar, sequence, Series, dict or DataFrame',\n",
       "         'param_desc': 'Any single or multiple element data structure, or list-like object.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}',\n",
       "         'param_desc': 'Whether to compare by the index (0 or ‘index’) or columns.\\n(1 or ‘columns’). For Series input, axis to match Series index on.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or label',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'float or None, default None',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful DataFrame alignment, with this value before computation.\\nIf data in both corresponding DataFrame locations is missing\\nthe result will be missing.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.sub',\n",
       "       'descriptions': 'Get Subtraction of dataframe and other, element-wise (binary operator sub). Equivalent to dataframe - other, but with support to substitute a fill_value\\nfor missing data in one of the inputs. With reverse version, rsub. Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to\\narithmetic operators: +, -, *, /, //, %, **.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'scalar, sequence, Series, dict or DataFrame',\n",
       "          'description': 'scalar, sequence, Series, dict or DataFrame. Any single or multiple element data structure, or list-like object.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}. Whether to compare by the index (0 or ‘index’) or columns.\\n(1 or ‘columns’). For Series input, axis to match Series index on.\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or label. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'float or None, default None. Fill existing missing (NaN) values, and any new element needed for\\nsuccessful DataFrame alignment, with this value before computation.\\nIf data in both corresponding DataFrame locations is missing\\nthe result will be missing.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.div(other[,\\xa0axis,\\xa0level,\\xa0fill_value])',\n",
       "      'func_desc': 'Get Floating division of dataframe and other, element-wise (binary operator truediv).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.div.html#pandas.DataFrame.div',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.div',\n",
       "       'full_function': \"DataFrame.div(other, axis='columns', level=None, fill_value=None)\",\n",
       "       'function_text': 'Get Floating division of dataframe and other, element-wise (binary operator truediv). Equivalent to dataframe / other, but with support to substitute a fill_value\\nfor missing data in one of the inputs. With reverse version, rtruediv. Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to\\narithmetic operators: +, -, *, /, //, %, **.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'scalar, sequence, Series, dict or DataFrame',\n",
       "         'param_desc': 'Any single or multiple element data structure, or list-like object.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}',\n",
       "         'param_desc': 'Whether to compare by the index (0 or ‘index’) or columns.\\n(1 or ‘columns’). For Series input, axis to match Series index on.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or label',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'float or None, default None',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful DataFrame alignment, with this value before computation.\\nIf data in both corresponding DataFrame locations is missing\\nthe result will be missing.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.div',\n",
       "       'descriptions': 'Get Floating division of dataframe and other, element-wise (binary operator truediv). Equivalent to dataframe / other, but with support to substitute a fill_value\\nfor missing data in one of the inputs. With reverse version, rtruediv. Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to\\narithmetic operators: +, -, *, /, //, %, **.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'scalar, sequence, Series, dict or DataFrame',\n",
       "          'description': 'scalar, sequence, Series, dict or DataFrame. Any single or multiple element data structure, or list-like object.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}. Whether to compare by the index (0 or ‘index’) or columns.\\n(1 or ‘columns’). For Series input, axis to match Series index on.\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or label. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'float or None, default None. Fill existing missing (NaN) values, and any new element needed for\\nsuccessful DataFrame alignment, with this value before computation.\\nIf data in both corresponding DataFrame locations is missing\\nthe result will be missing.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.floordiv(other[,\\xa0axis,\\xa0level,\\xa0...])',\n",
       "      'func_desc': 'Get Integer division of dataframe and other, element-wise (binary operator floordiv).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.floordiv.html#pandas.DataFrame.floordiv',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.floordiv',\n",
       "       'full_function': \"DataFrame.floordiv(other, axis='columns', level=None, fill_value=None)\",\n",
       "       'function_text': 'Get Integer division of dataframe and other, element-wise (binary operator floordiv). Equivalent to dataframe // other, but with support to substitute a fill_value\\nfor missing data in one of the inputs. With reverse version, rfloordiv. Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to\\narithmetic operators: +, -, *, /, //, %, **.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'scalar, sequence, Series, dict or DataFrame',\n",
       "         'param_desc': 'Any single or multiple element data structure, or list-like object.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}',\n",
       "         'param_desc': 'Whether to compare by the index (0 or ‘index’) or columns.\\n(1 or ‘columns’). For Series input, axis to match Series index on.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or label',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'float or None, default None',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful DataFrame alignment, with this value before computation.\\nIf data in both corresponding DataFrame locations is missing\\nthe result will be missing.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.floordiv',\n",
       "       'descriptions': 'Get Integer division of dataframe and other, element-wise (binary operator floordiv). Equivalent to dataframe // other, but with support to substitute a fill_value\\nfor missing data in one of the inputs. With reverse version, rfloordiv. Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to\\narithmetic operators: +, -, *, /, //, %, **.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'scalar, sequence, Series, dict or DataFrame',\n",
       "          'description': 'scalar, sequence, Series, dict or DataFrame. Any single or multiple element data structure, or list-like object.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}. Whether to compare by the index (0 or ‘index’) or columns.\\n(1 or ‘columns’). For Series input, axis to match Series index on.\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or label. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'float or None, default None. Fill existing missing (NaN) values, and any new element needed for\\nsuccessful DataFrame alignment, with this value before computation.\\nIf data in both corresponding DataFrame locations is missing\\nthe result will be missing.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.pow(other[,\\xa0axis,\\xa0level,\\xa0fill_value])',\n",
       "      'func_desc': 'Get Exponential power of dataframe and other, element-wise (binary operator pow).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pow.html#pandas.DataFrame.pow',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.pow',\n",
       "       'full_function': \"DataFrame.pow(other, axis='columns', level=None, fill_value=None)\",\n",
       "       'function_text': 'Get Exponential power of dataframe and other, element-wise (binary operator pow). Equivalent to dataframe ** other, but with support to substitute a fill_value\\nfor missing data in one of the inputs. With reverse version, rpow. Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to\\narithmetic operators: +, -, *, /, //, %, **.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'scalar, sequence, Series, dict or DataFrame',\n",
       "         'param_desc': 'Any single or multiple element data structure, or list-like object.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}',\n",
       "         'param_desc': 'Whether to compare by the index (0 or ‘index’) or columns.\\n(1 or ‘columns’). For Series input, axis to match Series index on.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or label',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'float or None, default None',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful DataFrame alignment, with this value before computation.\\nIf data in both corresponding DataFrame locations is missing\\nthe result will be missing.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.pow',\n",
       "       'descriptions': 'Get Exponential power of dataframe and other, element-wise (binary operator pow). Equivalent to dataframe ** other, but with support to substitute a fill_value\\nfor missing data in one of the inputs. With reverse version, rpow. Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to\\narithmetic operators: +, -, *, /, //, %, **.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'scalar, sequence, Series, dict or DataFrame',\n",
       "          'description': 'scalar, sequence, Series, dict or DataFrame. Any single or multiple element data structure, or list-like object.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}. Whether to compare by the index (0 or ‘index’) or columns.\\n(1 or ‘columns’). For Series input, axis to match Series index on.\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or label. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'float or None, default None. Fill existing missing (NaN) values, and any new element needed for\\nsuccessful DataFrame alignment, with this value before computation.\\nIf data in both corresponding DataFrame locations is missing\\nthe result will be missing.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.radd(other[,\\xa0axis,\\xa0level,\\xa0fill_value])',\n",
       "      'func_desc': 'Get Addition of dataframe and other, element-wise (binary operator radd).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.radd.html#pandas.DataFrame.radd',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.radd',\n",
       "       'full_function': \"DataFrame.radd(other, axis='columns', level=None, fill_value=None)\",\n",
       "       'function_text': 'Get Addition of dataframe and other, element-wise (binary operator radd). Equivalent to other + dataframe, but with support to substitute a fill_value\\nfor missing data in one of the inputs. With reverse version, add. Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to\\narithmetic operators: +, -, *, /, //, %, **.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'scalar, sequence, Series, dict or DataFrame',\n",
       "         'param_desc': 'Any single or multiple element data structure, or list-like object.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}',\n",
       "         'param_desc': 'Whether to compare by the index (0 or ‘index’) or columns.\\n(1 or ‘columns’). For Series input, axis to match Series index on.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or label',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'float or None, default None',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful DataFrame alignment, with this value before computation.\\nIf data in both corresponding DataFrame locations is missing\\nthe result will be missing.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.radd',\n",
       "       'descriptions': 'Get Addition of dataframe and other, element-wise (binary operator radd). Equivalent to other + dataframe, but with support to substitute a fill_value\\nfor missing data in one of the inputs. With reverse version, add. Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to\\narithmetic operators: +, -, *, /, //, %, **.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'scalar, sequence, Series, dict or DataFrame',\n",
       "          'description': 'scalar, sequence, Series, dict or DataFrame. Any single or multiple element data structure, or list-like object.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}. Whether to compare by the index (0 or ‘index’) or columns.\\n(1 or ‘columns’). For Series input, axis to match Series index on.\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or label. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'float or None, default None. Fill existing missing (NaN) values, and any new element needed for\\nsuccessful DataFrame alignment, with this value before computation.\\nIf data in both corresponding DataFrame locations is missing\\nthe result will be missing.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.rmul(other[,\\xa0axis,\\xa0level,\\xa0fill_value])',\n",
       "      'func_desc': 'Get Multiplication of dataframe and other, element-wise (binary operator rmul).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rmul.html#pandas.DataFrame.rmul',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.rmul',\n",
       "       'full_function': \"DataFrame.rmul(other, axis='columns', level=None, fill_value=None)\",\n",
       "       'function_text': 'Get Multiplication of dataframe and other, element-wise (binary operator rmul). Equivalent to other * dataframe, but with support to substitute a fill_value\\nfor missing data in one of the inputs. With reverse version, mul. Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to\\narithmetic operators: +, -, *, /, //, %, **.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'scalar, sequence, Series, dict or DataFrame',\n",
       "         'param_desc': 'Any single or multiple element data structure, or list-like object.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}',\n",
       "         'param_desc': 'Whether to compare by the index (0 or ‘index’) or columns.\\n(1 or ‘columns’). For Series input, axis to match Series index on.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or label',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'float or None, default None',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful DataFrame alignment, with this value before computation.\\nIf data in both corresponding DataFrame locations is missing\\nthe result will be missing.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.rmul',\n",
       "       'descriptions': 'Get Multiplication of dataframe and other, element-wise (binary operator rmul). Equivalent to other * dataframe, but with support to substitute a fill_value\\nfor missing data in one of the inputs. With reverse version, mul. Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to\\narithmetic operators: +, -, *, /, //, %, **.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'scalar, sequence, Series, dict or DataFrame',\n",
       "          'description': 'scalar, sequence, Series, dict or DataFrame. Any single or multiple element data structure, or list-like object.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}. Whether to compare by the index (0 or ‘index’) or columns.\\n(1 or ‘columns’). For Series input, axis to match Series index on.\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or label. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'float or None, default None. Fill existing missing (NaN) values, and any new element needed for\\nsuccessful DataFrame alignment, with this value before computation.\\nIf data in both corresponding DataFrame locations is missing\\nthe result will be missing.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.rtruediv(other[,\\xa0axis,\\xa0level,\\xa0...])',\n",
       "      'func_desc': 'Get Floating division of dataframe and other, element-wise (binary operator rtruediv).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rtruediv.html#pandas.DataFrame.rtruediv',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.rtruediv',\n",
       "       'full_function': \"DataFrame.rtruediv(other, axis='columns', level=None, fill_value=None)\",\n",
       "       'function_text': 'Get Floating division of dataframe and other, element-wise (binary operator rtruediv). Equivalent to other / dataframe, but with support to substitute a fill_value\\nfor missing data in one of the inputs. With reverse version, truediv. Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to\\narithmetic operators: +, -, *, /, //, %, **.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'scalar, sequence, Series, dict or DataFrame',\n",
       "         'param_desc': 'Any single or multiple element data structure, or list-like object.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}',\n",
       "         'param_desc': 'Whether to compare by the index (0 or ‘index’) or columns.\\n(1 or ‘columns’). For Series input, axis to match Series index on.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or label',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'float or None, default None',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful DataFrame alignment, with this value before computation.\\nIf data in both corresponding DataFrame locations is missing\\nthe result will be missing.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.rtruediv',\n",
       "       'descriptions': 'Get Floating division of dataframe and other, element-wise (binary operator rtruediv). Equivalent to other / dataframe, but with support to substitute a fill_value\\nfor missing data in one of the inputs. With reverse version, truediv. Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to\\narithmetic operators: +, -, *, /, //, %, **.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'scalar, sequence, Series, dict or DataFrame',\n",
       "          'description': 'scalar, sequence, Series, dict or DataFrame. Any single or multiple element data structure, or list-like object.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}. Whether to compare by the index (0 or ‘index’) or columns.\\n(1 or ‘columns’). For Series input, axis to match Series index on.\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or label. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'float or None, default None. Fill existing missing (NaN) values, and any new element needed for\\nsuccessful DataFrame alignment, with this value before computation.\\nIf data in both corresponding DataFrame locations is missing\\nthe result will be missing.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.rmod(other[,\\xa0axis,\\xa0level,\\xa0fill_value])',\n",
       "      'func_desc': 'Get Modulo of dataframe and other, element-wise (binary operator rmod).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rmod.html#pandas.DataFrame.rmod',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.rmod',\n",
       "       'full_function': \"DataFrame.rmod(other, axis='columns', level=None, fill_value=None)\",\n",
       "       'function_text': 'Get Modulo of dataframe and other, element-wise (binary operator rmod). Equivalent to other % dataframe, but with support to substitute a fill_value\\nfor missing data in one of the inputs. With reverse version, mod. Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to\\narithmetic operators: +, -, *, /, //, %, **.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'scalar, sequence, Series, dict or DataFrame',\n",
       "         'param_desc': 'Any single or multiple element data structure, or list-like object.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}',\n",
       "         'param_desc': 'Whether to compare by the index (0 or ‘index’) or columns.\\n(1 or ‘columns’). For Series input, axis to match Series index on.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or label',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'float or None, default None',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful DataFrame alignment, with this value before computation.\\nIf data in both corresponding DataFrame locations is missing\\nthe result will be missing.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.rmod',\n",
       "       'descriptions': 'Get Modulo of dataframe and other, element-wise (binary operator rmod). Equivalent to other % dataframe, but with support to substitute a fill_value\\nfor missing data in one of the inputs. With reverse version, mod. Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to\\narithmetic operators: +, -, *, /, //, %, **.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'scalar, sequence, Series, dict or DataFrame',\n",
       "          'description': 'scalar, sequence, Series, dict or DataFrame. Any single or multiple element data structure, or list-like object.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}. Whether to compare by the index (0 or ‘index’) or columns.\\n(1 or ‘columns’). For Series input, axis to match Series index on.\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or label. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'float or None, default None. Fill existing missing (NaN) values, and any new element needed for\\nsuccessful DataFrame alignment, with this value before computation.\\nIf data in both corresponding DataFrame locations is missing\\nthe result will be missing.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.lt(other[,\\xa0axis,\\xa0level])',\n",
       "      'func_desc': 'Get Less than of dataframe and other, element-wise (binary operator lt).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.lt.html#pandas.DataFrame.lt',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.lt',\n",
       "       'full_function': \"DataFrame.lt(other, axis='columns', level=None)\",\n",
       "       'function_text': 'Get Less than of dataframe and other, element-wise (binary operator lt). Among flexible wrappers (eq, ne, le, lt, ge, gt) to comparison\\noperators. Equivalent to ==, !=, <=, <, >=, > with support to choose axis\\n(rows or columns) and level for comparison.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'scalar, sequence, Series, or DataFrame',\n",
       "         'param_desc': 'Any single or multiple element data structure, or list-like object.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default ‘columns’',\n",
       "         'param_desc': 'Whether to compare by the index (0 or ‘index’) or columns\\n(1 or ‘columns’).\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or label',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the passed\\nMultiIndex level.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.lt',\n",
       "       'descriptions': 'Get Less than of dataframe and other, element-wise (binary operator lt). Among flexible wrappers (eq, ne, le, lt, ge, gt) to comparison\\noperators. Equivalent to ==, !=, <=, <, >=, > with support to choose axis\\n(rows or columns) and level for comparison.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'scalar, sequence, Series, or DataFrame',\n",
       "          'description': 'scalar, sequence, Series, or DataFrame. Any single or multiple element data structure, or list-like object.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default ‘columns’. Whether to compare by the index (0 or ‘index’) or columns\\n(1 or ‘columns’).\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or label. Broadcast across a level, matching Index values on the passed\\nMultiIndex level.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.le(other[,\\xa0axis,\\xa0level])',\n",
       "      'func_desc': 'Get Less than or equal to of dataframe and other, element-wise (binary operator le).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.le.html#pandas.DataFrame.le',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.le',\n",
       "       'full_function': \"DataFrame.le(other, axis='columns', level=None)\",\n",
       "       'function_text': 'Get Less than or equal to of dataframe and other, element-wise (binary operator le). Among flexible wrappers (eq, ne, le, lt, ge, gt) to comparison\\noperators. Equivalent to ==, !=, <=, <, >=, > with support to choose axis\\n(rows or columns) and level for comparison.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'scalar, sequence, Series, or DataFrame',\n",
       "         'param_desc': 'Any single or multiple element data structure, or list-like object.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default ‘columns’',\n",
       "         'param_desc': 'Whether to compare by the index (0 or ‘index’) or columns\\n(1 or ‘columns’).\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or label',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the passed\\nMultiIndex level.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.le',\n",
       "       'descriptions': 'Get Less than or equal to of dataframe and other, element-wise (binary operator le). Among flexible wrappers (eq, ne, le, lt, ge, gt) to comparison\\noperators. Equivalent to ==, !=, <=, <, >=, > with support to choose axis\\n(rows or columns) and level for comparison.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'scalar, sequence, Series, or DataFrame',\n",
       "          'description': 'scalar, sequence, Series, or DataFrame. Any single or multiple element data structure, or list-like object.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default ‘columns’. Whether to compare by the index (0 or ‘index’) or columns\\n(1 or ‘columns’).\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or label. Broadcast across a level, matching Index values on the passed\\nMultiIndex level.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.ne(other[,\\xa0axis,\\xa0level])',\n",
       "      'func_desc': 'Get Not equal to of dataframe and other, element-wise (binary operator ne).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ne.html#pandas.DataFrame.ne',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.ne',\n",
       "       'full_function': \"DataFrame.ne(other, axis='columns', level=None)\",\n",
       "       'function_text': 'Get Not equal to of dataframe and other, element-wise (binary operator ne). Among flexible wrappers (eq, ne, le, lt, ge, gt) to comparison\\noperators. Equivalent to ==, !=, <=, <, >=, > with support to choose axis\\n(rows or columns) and level for comparison.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'scalar, sequence, Series, or DataFrame',\n",
       "         'param_desc': 'Any single or multiple element data structure, or list-like object.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default ‘columns’',\n",
       "         'param_desc': 'Whether to compare by the index (0 or ‘index’) or columns\\n(1 or ‘columns’).\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or label',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the passed\\nMultiIndex level.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.ne',\n",
       "       'descriptions': 'Get Not equal to of dataframe and other, element-wise (binary operator ne). Among flexible wrappers (eq, ne, le, lt, ge, gt) to comparison\\noperators. Equivalent to ==, !=, <=, <, >=, > with support to choose axis\\n(rows or columns) and level for comparison.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'scalar, sequence, Series, or DataFrame',\n",
       "          'description': 'scalar, sequence, Series, or DataFrame. Any single or multiple element data structure, or list-like object.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default ‘columns’. Whether to compare by the index (0 or ‘index’) or columns\\n(1 or ‘columns’).\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or label. Broadcast across a level, matching Index values on the passed\\nMultiIndex level.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.combine(other,\\xa0func[,\\xa0fill_value,\\xa0...])',\n",
       "      'func_desc': 'Perform column-wise combine with another DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.combine.html#pandas.DataFrame.combine',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.combine',\n",
       "       'full_function': 'DataFrame.combine(other, func, fill_value=None, overwrite=True)',\n",
       "       'function_text': 'Perform column-wise combine with another DataFrame. Combines a DataFrame with other DataFrame using func\\nto element-wise combine columns. The row and column indexes of the\\nresulting DataFrame will be the union of the two.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'DataFrame',\n",
       "         'param_desc': 'The DataFrame to merge column-wise.\\n'},\n",
       "        {'param_name': 'func',\n",
       "         'param_type': 'function',\n",
       "         'param_desc': 'Function that takes two series as inputs and return a Series or a\\nscalar. Used to merge the two dataframes column by columns.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'scalar value, default None',\n",
       "         'param_desc': 'The value to fill NaNs with prior to passing any column to the\\nmerge func.\\n'},\n",
       "        {'param_name': 'overwrite',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If True, columns in self that do not exist in other will be\\noverwritten with NaNs.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.combine',\n",
       "       'descriptions': 'Perform column-wise combine with another DataFrame. Combines a DataFrame with other DataFrame using func\\nto element-wise combine columns. The row and column indexes of the\\nresulting DataFrame will be the union of the two.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'DataFrame',\n",
       "          'description': 'DataFrame. The DataFrame to merge column-wise.\\n'},\n",
       "         'func': {'type': 'function',\n",
       "          'description': 'function. Function that takes two series as inputs and return a Series or a\\nscalar. Used to merge the two dataframes column by columns.\\n'},\n",
       "         'fill_value': {'type': 'scalar value, default None',\n",
       "          'description': 'scalar value, default None. The value to fill NaNs with prior to passing any column to the\\nmerge func.\\n'},\n",
       "         'overwrite': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If True, columns in self that do not exist in other will be\\noverwritten with NaNs.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.add(other[,\\xa0axis,\\xa0level,\\xa0fill_value])',\n",
       "      'func_desc': 'Get Addition of dataframe and other, element-wise (binary operator add).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add.html#pandas.DataFrame.add',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.add',\n",
       "       'full_function': \"DataFrame.add(other, axis='columns', level=None, fill_value=None)\",\n",
       "       'function_text': 'Get Addition of dataframe and other, element-wise (binary operator add). Equivalent to dataframe + other, but with support to substitute a fill_value\\nfor missing data in one of the inputs. With reverse version, radd. Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to\\narithmetic operators: +, -, *, /, //, %, **.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'scalar, sequence, Series, dict or DataFrame',\n",
       "         'param_desc': 'Any single or multiple element data structure, or list-like object.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}',\n",
       "         'param_desc': 'Whether to compare by the index (0 or ‘index’) or columns.\\n(1 or ‘columns’). For Series input, axis to match Series index on.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or label',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'float or None, default None',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful DataFrame alignment, with this value before computation.\\nIf data in both corresponding DataFrame locations is missing\\nthe result will be missing.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.add',\n",
       "       'descriptions': 'Get Addition of dataframe and other, element-wise (binary operator add). Equivalent to dataframe + other, but with support to substitute a fill_value\\nfor missing data in one of the inputs. With reverse version, radd. Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to\\narithmetic operators: +, -, *, /, //, %, **.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'scalar, sequence, Series, dict or DataFrame',\n",
       "          'description': 'scalar, sequence, Series, dict or DataFrame. Any single or multiple element data structure, or list-like object.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}. Whether to compare by the index (0 or ‘index’) or columns.\\n(1 or ‘columns’). For Series input, axis to match Series index on.\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or label. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'float or None, default None. Fill existing missing (NaN) values, and any new element needed for\\nsuccessful DataFrame alignment, with this value before computation.\\nIf data in both corresponding DataFrame locations is missing\\nthe result will be missing.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.mul(other[,\\xa0axis,\\xa0level,\\xa0fill_value])',\n",
       "      'func_desc': 'Get Multiplication of dataframe and other, element-wise (binary operator mul).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mul.html#pandas.DataFrame.mul',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.mul',\n",
       "       'full_function': \"DataFrame.mul(other, axis='columns', level=None, fill_value=None)\",\n",
       "       'function_text': 'Get Multiplication of dataframe and other, element-wise (binary operator mul). Equivalent to dataframe * other, but with support to substitute a fill_value\\nfor missing data in one of the inputs. With reverse version, rmul. Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to\\narithmetic operators: +, -, *, /, //, %, **.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'scalar, sequence, Series, dict or DataFrame',\n",
       "         'param_desc': 'Any single or multiple element data structure, or list-like object.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}',\n",
       "         'param_desc': 'Whether to compare by the index (0 or ‘index’) or columns.\\n(1 or ‘columns’). For Series input, axis to match Series index on.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or label',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'float or None, default None',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful DataFrame alignment, with this value before computation.\\nIf data in both corresponding DataFrame locations is missing\\nthe result will be missing.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.mul',\n",
       "       'descriptions': 'Get Multiplication of dataframe and other, element-wise (binary operator mul). Equivalent to dataframe * other, but with support to substitute a fill_value\\nfor missing data in one of the inputs. With reverse version, rmul. Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to\\narithmetic operators: +, -, *, /, //, %, **.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'scalar, sequence, Series, dict or DataFrame',\n",
       "          'description': 'scalar, sequence, Series, dict or DataFrame. Any single or multiple element data structure, or list-like object.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}. Whether to compare by the index (0 or ‘index’) or columns.\\n(1 or ‘columns’). For Series input, axis to match Series index on.\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or label. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'float or None, default None. Fill existing missing (NaN) values, and any new element needed for\\nsuccessful DataFrame alignment, with this value before computation.\\nIf data in both corresponding DataFrame locations is missing\\nthe result will be missing.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.truediv(other[,\\xa0axis,\\xa0level,\\xa0...])',\n",
       "      'func_desc': 'Get Floating division of dataframe and other, element-wise (binary operator truediv).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.truediv.html#pandas.DataFrame.truediv',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.truediv',\n",
       "       'full_function': \"DataFrame.truediv(other, axis='columns', level=None, fill_value=None)\",\n",
       "       'function_text': 'Get Floating division of dataframe and other, element-wise (binary operator truediv). Equivalent to dataframe / other, but with support to substitute a fill_value\\nfor missing data in one of the inputs. With reverse version, rtruediv. Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to\\narithmetic operators: +, -, *, /, //, %, **.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'scalar, sequence, Series, dict or DataFrame',\n",
       "         'param_desc': 'Any single or multiple element data structure, or list-like object.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}',\n",
       "         'param_desc': 'Whether to compare by the index (0 or ‘index’) or columns.\\n(1 or ‘columns’). For Series input, axis to match Series index on.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or label',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'float or None, default None',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful DataFrame alignment, with this value before computation.\\nIf data in both corresponding DataFrame locations is missing\\nthe result will be missing.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.truediv',\n",
       "       'descriptions': 'Get Floating division of dataframe and other, element-wise (binary operator truediv). Equivalent to dataframe / other, but with support to substitute a fill_value\\nfor missing data in one of the inputs. With reverse version, rtruediv. Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to\\narithmetic operators: +, -, *, /, //, %, **.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'scalar, sequence, Series, dict or DataFrame',\n",
       "          'description': 'scalar, sequence, Series, dict or DataFrame. Any single or multiple element data structure, or list-like object.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}. Whether to compare by the index (0 or ‘index’) or columns.\\n(1 or ‘columns’). For Series input, axis to match Series index on.\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or label. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'float or None, default None. Fill existing missing (NaN) values, and any new element needed for\\nsuccessful DataFrame alignment, with this value before computation.\\nIf data in both corresponding DataFrame locations is missing\\nthe result will be missing.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.mod(other[,\\xa0axis,\\xa0level,\\xa0fill_value])',\n",
       "      'func_desc': 'Get Modulo of dataframe and other, element-wise (binary operator mod).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mod.html#pandas.DataFrame.mod',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.mod',\n",
       "       'full_function': \"DataFrame.mod(other, axis='columns', level=None, fill_value=None)\",\n",
       "       'function_text': 'Get Modulo of dataframe and other, element-wise (binary operator mod). Equivalent to dataframe % other, but with support to substitute a fill_value\\nfor missing data in one of the inputs. With reverse version, rmod. Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to\\narithmetic operators: +, -, *, /, //, %, **.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'scalar, sequence, Series, dict or DataFrame',\n",
       "         'param_desc': 'Any single or multiple element data structure, or list-like object.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}',\n",
       "         'param_desc': 'Whether to compare by the index (0 or ‘index’) or columns.\\n(1 or ‘columns’). For Series input, axis to match Series index on.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or label',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'float or None, default None',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful DataFrame alignment, with this value before computation.\\nIf data in both corresponding DataFrame locations is missing\\nthe result will be missing.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.mod',\n",
       "       'descriptions': 'Get Modulo of dataframe and other, element-wise (binary operator mod). Equivalent to dataframe % other, but with support to substitute a fill_value\\nfor missing data in one of the inputs. With reverse version, rmod. Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to\\narithmetic operators: +, -, *, /, //, %, **.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'scalar, sequence, Series, dict or DataFrame',\n",
       "          'description': 'scalar, sequence, Series, dict or DataFrame. Any single or multiple element data structure, or list-like object.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}. Whether to compare by the index (0 or ‘index’) or columns.\\n(1 or ‘columns’). For Series input, axis to match Series index on.\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or label. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'float or None, default None. Fill existing missing (NaN) values, and any new element needed for\\nsuccessful DataFrame alignment, with this value before computation.\\nIf data in both corresponding DataFrame locations is missing\\nthe result will be missing.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.dot(other)',\n",
       "      'func_desc': 'Compute the matrix multiplication between the DataFrame and other.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dot.html#pandas.DataFrame.dot',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.dot',\n",
       "       'full_function': 'DataFrame.dot(other)',\n",
       "       'function_text': 'Compute the matrix multiplication between the DataFrame and other. This method computes the matrix product between the DataFrame and the\\nvalues of an other Series, DataFrame or a numpy array. It can also be called using self @ other.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series, DataFrame or array-like',\n",
       "         'param_desc': 'The other object to compute the matrix product with.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.dot',\n",
       "       'descriptions': 'Compute the matrix multiplication between the DataFrame and other. This method computes the matrix product between the DataFrame and the\\nvalues of an other Series, DataFrame or a numpy array. It can also be called using self @ other.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'array',\n",
       "          'description': 'Series, DataFrame or array-like. The other object to compute the matrix product with.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.rsub(other[,\\xa0axis,\\xa0level,\\xa0fill_value])',\n",
       "      'func_desc': 'Get Subtraction of dataframe and other, element-wise (binary operator rsub).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rsub.html#pandas.DataFrame.rsub',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.rsub',\n",
       "       'full_function': \"DataFrame.rsub(other, axis='columns', level=None, fill_value=None)\",\n",
       "       'function_text': 'Get Subtraction of dataframe and other, element-wise (binary operator rsub). Equivalent to other - dataframe, but with support to substitute a fill_value\\nfor missing data in one of the inputs. With reverse version, sub. Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to\\narithmetic operators: +, -, *, /, //, %, **.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'scalar, sequence, Series, dict or DataFrame',\n",
       "         'param_desc': 'Any single or multiple element data structure, or list-like object.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}',\n",
       "         'param_desc': 'Whether to compare by the index (0 or ‘index’) or columns.\\n(1 or ‘columns’). For Series input, axis to match Series index on.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or label',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'float or None, default None',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful DataFrame alignment, with this value before computation.\\nIf data in both corresponding DataFrame locations is missing\\nthe result will be missing.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.rsub',\n",
       "       'descriptions': 'Get Subtraction of dataframe and other, element-wise (binary operator rsub). Equivalent to other - dataframe, but with support to substitute a fill_value\\nfor missing data in one of the inputs. With reverse version, sub. Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to\\narithmetic operators: +, -, *, /, //, %, **.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'scalar, sequence, Series, dict or DataFrame',\n",
       "          'description': 'scalar, sequence, Series, dict or DataFrame. Any single or multiple element data structure, or list-like object.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}. Whether to compare by the index (0 or ‘index’) or columns.\\n(1 or ‘columns’). For Series input, axis to match Series index on.\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or label. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'float or None, default None. Fill existing missing (NaN) values, and any new element needed for\\nsuccessful DataFrame alignment, with this value before computation.\\nIf data in both corresponding DataFrame locations is missing\\nthe result will be missing.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.rdiv(other[,\\xa0axis,\\xa0level,\\xa0fill_value])',\n",
       "      'func_desc': 'Get Floating division of dataframe and other, element-wise (binary operator rtruediv).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rdiv.html#pandas.DataFrame.rdiv',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.rdiv',\n",
       "       'full_function': \"DataFrame.rdiv(other, axis='columns', level=None, fill_value=None)\",\n",
       "       'function_text': 'Get Floating division of dataframe and other, element-wise (binary operator rtruediv). Equivalent to other / dataframe, but with support to substitute a fill_value\\nfor missing data in one of the inputs. With reverse version, truediv. Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to\\narithmetic operators: +, -, *, /, //, %, **.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'scalar, sequence, Series, dict or DataFrame',\n",
       "         'param_desc': 'Any single or multiple element data structure, or list-like object.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}',\n",
       "         'param_desc': 'Whether to compare by the index (0 or ‘index’) or columns.\\n(1 or ‘columns’). For Series input, axis to match Series index on.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or label',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'float or None, default None',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful DataFrame alignment, with this value before computation.\\nIf data in both corresponding DataFrame locations is missing\\nthe result will be missing.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.rdiv',\n",
       "       'descriptions': 'Get Floating division of dataframe and other, element-wise (binary operator rtruediv). Equivalent to other / dataframe, but with support to substitute a fill_value\\nfor missing data in one of the inputs. With reverse version, truediv. Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to\\narithmetic operators: +, -, *, /, //, %, **.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'scalar, sequence, Series, dict or DataFrame',\n",
       "          'description': 'scalar, sequence, Series, dict or DataFrame. Any single or multiple element data structure, or list-like object.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}. Whether to compare by the index (0 or ‘index’) or columns.\\n(1 or ‘columns’). For Series input, axis to match Series index on.\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or label. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'float or None, default None. Fill existing missing (NaN) values, and any new element needed for\\nsuccessful DataFrame alignment, with this value before computation.\\nIf data in both corresponding DataFrame locations is missing\\nthe result will be missing.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.rfloordiv(other[,\\xa0axis,\\xa0level,\\xa0...])',\n",
       "      'func_desc': 'Get Integer division of dataframe and other, element-wise (binary operator rfloordiv).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rfloordiv.html#pandas.DataFrame.rfloordiv',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.rfloordiv',\n",
       "       'full_function': \"DataFrame.rfloordiv(other, axis='columns', level=None, fill_value=None)\",\n",
       "       'function_text': 'Get Integer division of dataframe and other, element-wise (binary operator rfloordiv). Equivalent to other // dataframe, but with support to substitute a fill_value\\nfor missing data in one of the inputs. With reverse version, floordiv. Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to\\narithmetic operators: +, -, *, /, //, %, **.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'scalar, sequence, Series, dict or DataFrame',\n",
       "         'param_desc': 'Any single or multiple element data structure, or list-like object.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}',\n",
       "         'param_desc': 'Whether to compare by the index (0 or ‘index’) or columns.\\n(1 or ‘columns’). For Series input, axis to match Series index on.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or label',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'float or None, default None',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful DataFrame alignment, with this value before computation.\\nIf data in both corresponding DataFrame locations is missing\\nthe result will be missing.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.rfloordiv',\n",
       "       'descriptions': 'Get Integer division of dataframe and other, element-wise (binary operator rfloordiv). Equivalent to other // dataframe, but with support to substitute a fill_value\\nfor missing data in one of the inputs. With reverse version, floordiv. Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to\\narithmetic operators: +, -, *, /, //, %, **.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'scalar, sequence, Series, dict or DataFrame',\n",
       "          'description': 'scalar, sequence, Series, dict or DataFrame. Any single or multiple element data structure, or list-like object.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}. Whether to compare by the index (0 or ‘index’) or columns.\\n(1 or ‘columns’). For Series input, axis to match Series index on.\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or label. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'float or None, default None. Fill existing missing (NaN) values, and any new element needed for\\nsuccessful DataFrame alignment, with this value before computation.\\nIf data in both corresponding DataFrame locations is missing\\nthe result will be missing.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.rpow(other[,\\xa0axis,\\xa0level,\\xa0fill_value])',\n",
       "      'func_desc': 'Get Exponential power of dataframe and other, element-wise (binary operator rpow).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rpow.html#pandas.DataFrame.rpow',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.rpow',\n",
       "       'full_function': \"DataFrame.rpow(other, axis='columns', level=None, fill_value=None)\",\n",
       "       'function_text': 'Get Exponential power of dataframe and other, element-wise (binary operator rpow). Equivalent to other ** dataframe, but with support to substitute a fill_value\\nfor missing data in one of the inputs. With reverse version, pow. Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to\\narithmetic operators: +, -, *, /, //, %, **.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'scalar, sequence, Series, dict or DataFrame',\n",
       "         'param_desc': 'Any single or multiple element data structure, or list-like object.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}',\n",
       "         'param_desc': 'Whether to compare by the index (0 or ‘index’) or columns.\\n(1 or ‘columns’). For Series input, axis to match Series index on.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or label',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'float or None, default None',\n",
       "         'param_desc': 'Fill existing missing (NaN) values, and any new element needed for\\nsuccessful DataFrame alignment, with this value before computation.\\nIf data in both corresponding DataFrame locations is missing\\nthe result will be missing.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.rpow',\n",
       "       'descriptions': 'Get Exponential power of dataframe and other, element-wise (binary operator rpow). Equivalent to other ** dataframe, but with support to substitute a fill_value\\nfor missing data in one of the inputs. With reverse version, pow. Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to\\narithmetic operators: +, -, *, /, //, %, **.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'scalar, sequence, Series, dict or DataFrame',\n",
       "          'description': 'scalar, sequence, Series, dict or DataFrame. Any single or multiple element data structure, or list-like object.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}. Whether to compare by the index (0 or ‘index’) or columns.\\n(1 or ‘columns’). For Series input, axis to match Series index on.\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or label. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'float',\n",
       "          'description': 'float or None, default None. Fill existing missing (NaN) values, and any new element needed for\\nsuccessful DataFrame alignment, with this value before computation.\\nIf data in both corresponding DataFrame locations is missing\\nthe result will be missing.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.gt(other[,\\xa0axis,\\xa0level])',\n",
       "      'func_desc': 'Get Greater than of dataframe and other, element-wise (binary operator gt).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.gt.html#pandas.DataFrame.gt',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.gt',\n",
       "       'full_function': \"DataFrame.gt(other, axis='columns', level=None)\",\n",
       "       'function_text': 'Get Greater than of dataframe and other, element-wise (binary operator gt). Among flexible wrappers (eq, ne, le, lt, ge, gt) to comparison\\noperators. Equivalent to ==, !=, <=, <, >=, > with support to choose axis\\n(rows or columns) and level for comparison.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'scalar, sequence, Series, or DataFrame',\n",
       "         'param_desc': 'Any single or multiple element data structure, or list-like object.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default ‘columns’',\n",
       "         'param_desc': 'Whether to compare by the index (0 or ‘index’) or columns\\n(1 or ‘columns’).\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or label',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the passed\\nMultiIndex level.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.gt',\n",
       "       'descriptions': 'Get Greater than of dataframe and other, element-wise (binary operator gt). Among flexible wrappers (eq, ne, le, lt, ge, gt) to comparison\\noperators. Equivalent to ==, !=, <=, <, >=, > with support to choose axis\\n(rows or columns) and level for comparison.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'scalar, sequence, Series, or DataFrame',\n",
       "          'description': 'scalar, sequence, Series, or DataFrame. Any single or multiple element data structure, or list-like object.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default ‘columns’. Whether to compare by the index (0 or ‘index’) or columns\\n(1 or ‘columns’).\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or label. Broadcast across a level, matching Index values on the passed\\nMultiIndex level.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.ge(other[,\\xa0axis,\\xa0level])',\n",
       "      'func_desc': 'Get Greater than or equal to of dataframe and other, element-wise (binary operator ge).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ge.html#pandas.DataFrame.ge',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.ge',\n",
       "       'full_function': \"DataFrame.ge(other, axis='columns', level=None)\",\n",
       "       'function_text': 'Get Greater than or equal to of dataframe and other, element-wise (binary operator ge). Among flexible wrappers (eq, ne, le, lt, ge, gt) to comparison\\noperators. Equivalent to ==, !=, <=, <, >=, > with support to choose axis\\n(rows or columns) and level for comparison.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'scalar, sequence, Series, or DataFrame',\n",
       "         'param_desc': 'Any single or multiple element data structure, or list-like object.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default ‘columns’',\n",
       "         'param_desc': 'Whether to compare by the index (0 or ‘index’) or columns\\n(1 or ‘columns’).\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or label',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the passed\\nMultiIndex level.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.ge',\n",
       "       'descriptions': 'Get Greater than or equal to of dataframe and other, element-wise (binary operator ge). Among flexible wrappers (eq, ne, le, lt, ge, gt) to comparison\\noperators. Equivalent to ==, !=, <=, <, >=, > with support to choose axis\\n(rows or columns) and level for comparison.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'scalar, sequence, Series, or DataFrame',\n",
       "          'description': 'scalar, sequence, Series, or DataFrame. Any single or multiple element data structure, or list-like object.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default ‘columns’. Whether to compare by the index (0 or ‘index’) or columns\\n(1 or ‘columns’).\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or label. Broadcast across a level, matching Index values on the passed\\nMultiIndex level.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.eq(other[,\\xa0axis,\\xa0level])',\n",
       "      'func_desc': 'Get Equal to of dataframe and other, element-wise (binary operator eq).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.eq.html#pandas.DataFrame.eq',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.eq',\n",
       "       'full_function': \"DataFrame.eq(other, axis='columns', level=None)\",\n",
       "       'function_text': 'Get Equal to of dataframe and other, element-wise (binary operator eq). Among flexible wrappers (eq, ne, le, lt, ge, gt) to comparison\\noperators. Equivalent to ==, !=, <=, <, >=, > with support to choose axis\\n(rows or columns) and level for comparison.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'scalar, sequence, Series, or DataFrame',\n",
       "         'param_desc': 'Any single or multiple element data structure, or list-like object.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default ‘columns’',\n",
       "         'param_desc': 'Whether to compare by the index (0 or ‘index’) or columns\\n(1 or ‘columns’).\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or label',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the passed\\nMultiIndex level.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.eq',\n",
       "       'descriptions': 'Get Equal to of dataframe and other, element-wise (binary operator eq). Among flexible wrappers (eq, ne, le, lt, ge, gt) to comparison\\noperators. Equivalent to ==, !=, <=, <, >=, > with support to choose axis\\n(rows or columns) and level for comparison.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'scalar, sequence, Series, or DataFrame',\n",
       "          'description': 'scalar, sequence, Series, or DataFrame. Any single or multiple element data structure, or list-like object.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default ‘columns’. Whether to compare by the index (0 or ‘index’) or columns\\n(1 or ‘columns’).\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or label. Broadcast across a level, matching Index values on the passed\\nMultiIndex level.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.combine_first(other)',\n",
       "      'func_desc': 'Update null elements with value in the same location in other.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.combine_first.html#pandas.DataFrame.combine_first',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.combine_first',\n",
       "       'full_function': 'DataFrame.combine_first(other)',\n",
       "       'function_text': 'Update null elements with value in the same location in other. Combine two DataFrame objects by filling null values in one DataFrame\\nwith non-null values from other DataFrame. The row and column indexes\\nof the resulting DataFrame will be the union of the two. The resulting\\ndataframe contains the ‘first’ dataframe values and overrides the\\nsecond one values where both first.loc[index, col] and\\nsecond.loc[index, col] are not missing values, upon calling\\nfirst.combine_first(second).',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'DataFrame',\n",
       "         'param_desc': 'Provided DataFrame to use to fill null values.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.combine_first',\n",
       "       'descriptions': 'Update null elements with value in the same location in other. Combine two DataFrame objects by filling null values in one DataFrame\\nwith non-null values from other DataFrame. The row and column indexes\\nof the resulting DataFrame will be the union of the two. The resulting\\ndataframe contains the ‘first’ dataframe values and overrides the\\nsecond one values where both first.loc[index, col] and\\nsecond.loc[index, col] are not missing values, upon calling\\nfirst.combine_first(second).',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'DataFrame',\n",
       "          'description': 'DataFrame. Provided DataFrame to use to fill null values.\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Function application, GroupBy & window': [{'func_name': 'DataFrame.apply(func[,\\xa0axis,\\xa0raw,\\xa0...])',\n",
       "      'func_desc': 'Apply a function along an axis of the DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html#pandas.DataFrame.apply',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.apply',\n",
       "       'full_function': \"DataFrame.apply(func, axis=0, raw=False, result_type=None, args=(), by_row='compat', engine='python', engine_kwargs=None, **kwargs)\",\n",
       "       'function_text': 'Apply a function along an axis of the DataFrame. Objects passed to the function are Series objects whose index is\\neither the DataFrame’s index (axis=0) or the DataFrame’s columns\\n(axis=1). By default (result_type=None), the final return type\\nis inferred from the return type of the applied function. Otherwise,\\nit depends on the result_type argument.',\n",
       "       'parameter_names_desc': [{'param_name': 'func',\n",
       "         'param_type': 'function',\n",
       "         'param_desc': 'Function to apply to each column or row.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'Axis along which the function is applied:\\n\\n0 or ‘index’: apply function to each column.\\n1 or ‘columns’: apply function to each row.\\n\\n'},\n",
       "        {'param_name': 'raw',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Determines if row or column is passed as a Series or ndarray object:\\n\\nFalse : passes each row or column as a Series to the\\nfunction.\\nTrue : the passed function will receive ndarray objects\\ninstead.\\nIf you are just applying a NumPy reduction function this will\\nachieve much better performance.\\n\\n'},\n",
       "        {'param_name': 'result_type',\n",
       "         'param_type': '{‘expand’, ‘reduce’, ‘broadcast’, None}, default None',\n",
       "         'param_desc': 'These only act when axis=1 (columns):\\n\\n‘expand’ : list-like results will be turned into columns.\\n‘reduce’ : returns a Series if possible rather than expanding\\nlist-like results. This is the opposite of ‘expand’.\\n‘broadcast’ : results will be broadcast to the original shape\\nof the DataFrame, the original index and columns will be\\nretained.\\n\\nThe default behaviour (None) depends on the return value of the\\napplied function: list-like results will be returned as a Series\\nof those. However if the apply function returns a Series these\\nare expanded to columns.\\n'},\n",
       "        {'param_name': 'args',\n",
       "         'param_type': 'tuple',\n",
       "         'param_desc': 'Positional arguments to pass to func in addition to the\\narray/series.\\n'},\n",
       "        {'param_name': 'by_row',\n",
       "         'param_type': 'False or “compat”, default “compat”',\n",
       "         'param_desc': 'Only has an effect when func is a listlike or dictlike of funcs\\nand the func isn’t a string.\\nIf “compat”, will if possible first translate the func into pandas\\nmethods (e.g. Series().apply(np.sum) will be translated to\\nSeries().sum()). If that doesn’t work, will try call to apply again with\\nby_row=True and if that fails, will call apply again with\\nby_row=False (backward compatible).\\nIf False, the funcs will be passed the whole Series at once.\\n\\nNew in version 2.1.0.\\n\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': '{‘python’, ‘numba’}, default ‘python’',\n",
       "         'param_desc': 'Choose between the python (default) engine or the numba engine in apply.\\nThe numba engine will attempt to JIT compile the passed function,\\nwhich may result in speedups for large DataFrames.\\nIt also supports the following engine_kwargs :\\n\\nnopython (compile the function in nopython mode)\\nnogil (release the GIL inside the JIT compiled function)\\nparallel (try to apply the function in parallel over the DataFrame)\\nNote: Due to limitations within numba/how pandas interfaces with numba,\\nyou should only use this if raw=True\\n\\n\\nNote: The numba compiler only supports a subset of\\nvalid Python/numpy operations.\\nPlease read more about the supported python features\\nand supported numpy features\\nin numba to learn what you can or cannot use in the passed function.\\n\\nNew in version 2.2.0.\\n\\n'},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict',\n",
       "         'param_desc': 'Pass keyword arguments to the engine.\\nThis is currently only used by the numba engine,\\nsee the documentation for the engine argument for more information.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.apply',\n",
       "       'descriptions': 'Apply a function along an axis of the DataFrame. Objects passed to the function are Series objects whose index is\\neither the DataFrame’s index (axis=0) or the DataFrame’s columns\\n(axis=1). By default (result_type=None), the final return type\\nis inferred from the return type of the applied function. Otherwise,\\nit depends on the result_type argument.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'func': {'type': 'function',\n",
       "          'description': 'function. Function to apply to each column or row.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. Axis along which the function is applied:\\n\\n0 or ‘index’: apply function to each column.\\n1 or ‘columns’: apply function to each row.\\n\\n'},\n",
       "         'raw': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Determines if row or column is passed as a Series or ndarray object:\\n\\nFalse : passes each row or column as a Series to the\\nfunction.\\nTrue : the passed function will receive ndarray objects\\ninstead.\\nIf you are just applying a NumPy reduction function this will\\nachieve much better performance.\\n\\n'},\n",
       "         'result_type': {'type': 'string',\n",
       "          'enum': ['expand', ' reduce', ' broadcast', ' None'],\n",
       "          'description': '{‘expand’, ‘reduce’, ‘broadcast’, None}, default None. These only act when axis=1 (columns):\\n\\n‘expand’ : list-like results will be turned into columns.\\n‘reduce’ : returns a Series if possible rather than expanding\\nlist-like results. This is the opposite of ‘expand’.\\n‘broadcast’ : results will be broadcast to the original shape\\nof the DataFrame, the original index and columns will be\\nretained.\\n\\nThe default behaviour (None) depends on the return value of the\\napplied function: list-like results will be returned as a Series\\nof those. However if the apply function returns a Series these\\nare expanded to columns.\\n'},\n",
       "         'args': {'type': 'tuple',\n",
       "          'description': 'tuple. Positional arguments to pass to func in addition to the\\narray/series.\\n'},\n",
       "         'by_row': {'type': 'False or “compat”, default “compat”',\n",
       "          'description': 'False or “compat”, default “compat”. Only has an effect when func is a listlike or dictlike of funcs\\nand the func isn’t a string.\\nIf “compat”, will if possible first translate the func into pandas\\nmethods (e.g. Series().apply(np.sum) will be translated to\\nSeries().sum()). If that doesn’t work, will try call to apply again with\\nby_row=True and if that fails, will call apply again with\\nby_row=False (backward compatible).\\nIf False, the funcs will be passed the whole Series at once.\\n\\nNew in version 2.1.0.\\n\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'enum': ['python', ' numba'],\n",
       "          'description': '{‘python’, ‘numba’}, default ‘python’. Choose between the python (default) engine or the numba engine in apply.\\nThe numba engine will attempt to JIT compile the passed function,\\nwhich may result in speedups for large DataFrames.\\nIt also supports the following engine_kwargs :\\n\\nnopython (compile the function in nopython mode)\\nnogil (release the GIL inside the JIT compiled function)\\nparallel (try to apply the function in parallel over the DataFrame)\\nNote: Due to limitations within numba/how pandas interfaces with numba,\\nyou should only use this if raw=True\\n\\n\\nNote: The numba compiler only supports a subset of\\nvalid Python/numpy operations.\\nPlease read more about the supported python features\\nand supported numpy features\\nin numba to learn what you can or cannot use in the passed function.\\n\\nNew in version 2.2.0.\\n\\n'},\n",
       "         'engine_kwargs': {'type': 'dict',\n",
       "          'description': 'dict. Pass keyword arguments to the engine.\\nThis is currently only used by the numba engine,\\nsee the documentation for the engine argument for more information.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.applymap(func[,\\xa0na_action])',\n",
       "      'func_desc': '(DEPRECATED) Apply a function to a Dataframe elementwise.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.applymap.html#pandas.DataFrame.applymap',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.applymap',\n",
       "       'full_function': 'DataFrame.applymap(func, na_action=None, **kwargs)',\n",
       "       'function_text': 'Apply a function to a Dataframe elementwise. Deprecated since version 2.1.0: DataFrame.applymap has been deprecated. Use DataFrame.map instead. This method applies a function that accepts and returns a scalar\\nto every element of a DataFrame.',\n",
       "       'parameter_names_desc': [{'param_name': 'func',\n",
       "         'param_type': 'callable',\n",
       "         'param_desc': 'Python function, returns a single value from a single value.\\n'},\n",
       "        {'param_name': 'na_action',\n",
       "         'param_type': '{None, ‘ignore’}, default None',\n",
       "         'param_desc': 'If ‘ignore’, propagate NaN values, without passing them to func.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.applymap',\n",
       "       'descriptions': 'Apply a function to a Dataframe elementwise. Deprecated since version 2.1.0: DataFrame.applymap has been deprecated. Use DataFrame.map instead. This method applies a function that accepts and returns a scalar\\nto every element of a DataFrame.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'func': {'type': 'object',\n",
       "          'description': 'callable. Python function, returns a single value from a single value.\\n'},\n",
       "         'na_action': {'type': 'string',\n",
       "          'enum': ['None', ' ignore'],\n",
       "          'description': '{None, ‘ignore’}, default None. If ‘ignore’, propagate NaN values, without passing them to func.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.agg([func,\\xa0axis])',\n",
       "      'func_desc': 'Aggregate using one or more operations over the specified axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.agg.html#pandas.DataFrame.agg',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.agg',\n",
       "       'full_function': 'DataFrame.agg(func=None, axis=0, *args, **kwargs)',\n",
       "       'function_text': 'Aggregate using one or more operations over the specified axis.',\n",
       "       'parameter_names_desc': [{'param_name': 'func',\n",
       "         'param_type': 'function, str, list or dict',\n",
       "         'param_desc': \"Function to use for aggregating the data. If a function, must either\\nwork when passed a DataFrame or when passed to DataFrame.apply.\\nAccepted combinations are:\\n\\nfunction\\nstring function name\\nlist of functions and/or function names, e.g. [np.sum, 'mean']\\ndict of axis labels -> functions, function names or list of such.\\n\\n\"},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'If 0 or ‘index’: apply function to each column.\\nIf 1 or ‘columns’: apply function to each row.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.agg',\n",
       "       'descriptions': 'Aggregate using one or more operations over the specified axis.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'func': {'type': 'string',\n",
       "          'description': \"function, str, list or dict. Function to use for aggregating the data. If a function, must either\\nwork when passed a DataFrame or when passed to DataFrame.apply.\\nAccepted combinations are:\\n\\nfunction\\nstring function name\\nlist of functions and/or function names, e.g. [np.sum, 'mean']\\ndict of axis labels -> functions, function names or list of such.\\n\\n\"},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. If 0 or ‘index’: apply function to each column.\\nIf 1 or ‘columns’: apply function to each row.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.transform(func[,\\xa0axis])',\n",
       "      'func_desc': 'Call func on self producing a DataFrame with the same axis shape as self.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.transform.html#pandas.DataFrame.transform',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.transform',\n",
       "       'full_function': 'DataFrame.transform(func, axis=0, *args, **kwargs)',\n",
       "       'function_text': 'Call func on self producing a DataFrame with the same axis shape as self.',\n",
       "       'parameter_names_desc': [{'param_name': 'ValueError',\n",
       "         'param_type': 'If the returned DataFrame has a different length than self.',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.transform',\n",
       "       'descriptions': 'Call func on self producing a DataFrame with the same axis shape as self.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'ValueError': {'type': 'If the returned DataFrame has a different length than self.',\n",
       "          'description': 'If the returned DataFrame has a different length than self.. '}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.rolling(window[,\\xa0min_periods,\\xa0...])',\n",
       "      'func_desc': 'Provide rolling window calculations.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html#pandas.DataFrame.rolling',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.rolling',\n",
       "       'full_function': \"DataFrame.rolling(window, min_periods=None, center=False, win_type=None, on=None, axis=_NoDefault.no_default, closed=None, step=None, method='single')\",\n",
       "       'function_text': 'Provide rolling window calculations.',\n",
       "       'parameter_names_desc': [{'param_name': 'window',\n",
       "         'param_type': 'int, timedelta, str, offset, or BaseIndexer subclass',\n",
       "         'param_desc': 'Size of the moving window.\\nIf an integer, the fixed number of observations used for\\neach window.\\nIf a timedelta, str, or offset, the time period of each window. Each\\nwindow will be a variable sized based on the observations included in\\nthe time-period. This is only valid for datetimelike indexes.\\nTo learn more about the offsets & frequency strings, please see this link.\\nIf a BaseIndexer subclass, the window boundaries\\nbased on the defined get_window_bounds method. Additional rolling\\nkeyword arguments, namely min_periods, center, closed and\\nstep will be passed to get_window_bounds.\\n'},\n",
       "        {'param_name': 'min_periods',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'Minimum number of observations in window required to have a value;\\notherwise, result is np.nan.\\nFor a window that is specified by an offset, min_periods will default to 1.\\nFor a window that is specified by an integer, min_periods will default\\nto the size of the window.\\n'},\n",
       "        {'param_name': 'center',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If False, set the window labels as the right edge of the window index.\\nIf True, set the window labels as the center of the window index.\\n'},\n",
       "        {'param_name': 'win_type',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'If None, all points are evenly weighted.\\nIf a string, it must be a valid scipy.signal window function.\\nCertain Scipy window types require additional parameters to be passed\\nin the aggregation function. The additional parameters must match\\nthe keywords specified in the Scipy window type method signature.\\n'},\n",
       "        {'param_name': 'on',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'For a DataFrame, a column label or Index level on which\\nto calculate the rolling window, rather than the DataFrame’s index.\\nProvided integer column is ignored and excluded from result since\\nan integer index is not used to calculate the rolling window.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': 'int or str, default 0',\n",
       "         'param_desc': \"If 0 or 'index', roll across the rows.\\nIf 1 or 'columns', roll across the columns.\\nFor Series this parameter is unused and defaults to 0.\\n\\nDeprecated since version 2.1.0: The axis keyword is deprecated. For axis=1,\\ntranspose the DataFrame first instead.\\n\\n\"},\n",
       "        {'param_name': 'closed',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': \"If 'right', the first point in the window is excluded from calculations.\\nIf 'left', the last point in the window is excluded from calculations.\\nIf 'both', the no points in the window are excluded from calculations.\\nIf 'neither', the first and last points in the window are excluded\\nfrom calculations.\\nDefault None ('right').\\n\"},\n",
       "        {'param_name': 'step',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': '\\nNew in version 1.5.0.\\n\\nEvaluate the window at every step result, equivalent to slicing as\\n[::step]. window must be an integer. Using a step argument other\\nthan None or 1 will produce a result with a different shape than the input.\\n'},\n",
       "        {'param_name': 'method',\n",
       "         'param_type': 'str {‘single’, ‘table’}, default ‘single’',\n",
       "         'param_desc': \"\\nNew in version 1.3.0.\\n\\nExecute the rolling operation per single column or row ('single')\\nor over the entire object ('table').\\nThis argument is only implemented when specifying engine='numba'\\nin the method call.\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.rolling',\n",
       "       'descriptions': 'Provide rolling window calculations.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'window': {'type': 'integer',\n",
       "          'description': 'int, timedelta, str, offset, or BaseIndexer subclass. Size of the moving window.\\nIf an integer, the fixed number of observations used for\\neach window.\\nIf a timedelta, str, or offset, the time period of each window. Each\\nwindow will be a variable sized based on the observations included in\\nthe time-period. This is only valid for datetimelike indexes.\\nTo learn more about the offsets & frequency strings, please see this link.\\nIf a BaseIndexer subclass, the window boundaries\\nbased on the defined get_window_bounds method. Additional rolling\\nkeyword arguments, namely min_periods, center, closed and\\nstep will be passed to get_window_bounds.\\n'},\n",
       "         'min_periods': {'type': 'integer',\n",
       "          'description': 'int, default None. Minimum number of observations in window required to have a value;\\notherwise, result is np.nan.\\nFor a window that is specified by an offset, min_periods will default to 1.\\nFor a window that is specified by an integer, min_periods will default\\nto the size of the window.\\n'},\n",
       "         'center': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If False, set the window labels as the right edge of the window index.\\nIf True, set the window labels as the center of the window index.\\n'},\n",
       "         'win_type': {'type': 'string',\n",
       "          'description': 'str, default None. If None, all points are evenly weighted.\\nIf a string, it must be a valid scipy.signal window function.\\nCertain Scipy window types require additional parameters to be passed\\nin the aggregation function. The additional parameters must match\\nthe keywords specified in the Scipy window type method signature.\\n'},\n",
       "         'on': {'type': 'string',\n",
       "          'description': 'str, optional. For a DataFrame, a column label or Index level on which\\nto calculate the rolling window, rather than the DataFrame’s index.\\nProvided integer column is ignored and excluded from result since\\nan integer index is not used to calculate the rolling window.\\n'},\n",
       "         'axis': {'type': 'integer',\n",
       "          'description': \"int or str, default 0. If 0 or 'index', roll across the rows.\\nIf 1 or 'columns', roll across the columns.\\nFor Series this parameter is unused and defaults to 0.\\n\\nDeprecated since version 2.1.0: The axis keyword is deprecated. For axis=1,\\ntranspose the DataFrame first instead.\\n\\n\"},\n",
       "         'closed': {'type': 'string',\n",
       "          'description': \"str, default None. If 'right', the first point in the window is excluded from calculations.\\nIf 'left', the last point in the window is excluded from calculations.\\nIf 'both', the no points in the window are excluded from calculations.\\nIf 'neither', the first and last points in the window are excluded\\nfrom calculations.\\nDefault None ('right').\\n\"},\n",
       "         'step': {'type': 'integer',\n",
       "          'description': 'int, default None. \\nNew in version 1.5.0.\\n\\nEvaluate the window at every step result, equivalent to slicing as\\n[::step]. window must be an integer. Using a step argument other\\nthan None or 1 will produce a result with a different shape than the input.\\n'},\n",
       "         'method': {'type': 'string',\n",
       "          'description': \"str {‘single’, ‘table’}, default ‘single’. \\nNew in version 1.3.0.\\n\\nExecute the rolling operation per single column or row ('single')\\nor over the entire object ('table').\\nThis argument is only implemented when specifying engine='numba'\\nin the method call.\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.ewm([com,\\xa0span,\\xa0halflife,\\xa0alpha,\\xa0...])',\n",
       "      'func_desc': 'Provide exponentially weighted (EW) calculations.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ewm.html#pandas.DataFrame.ewm',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.ewm',\n",
       "       'full_function': \"DataFrame.ewm(com=None, span=None, halflife=None, alpha=None, min_periods=0, adjust=True, ignore_na=False, axis=_NoDefault.no_default, times=None, method='single')\",\n",
       "       'function_text': 'Provide exponentially weighted (EW) calculations. Exactly one of com, span, halflife, or alpha must be\\nprovided if times is not provided. If times is provided,\\nhalflife and one of com, span or alpha may be provided.',\n",
       "       'parameter_names_desc': [{'param_name': 'com',\n",
       "         'param_type': 'float, optional',\n",
       "         'param_desc': 'Specify decay in terms of center of mass\\n\\\\(\\\\alpha = 1 / (1 + com)\\\\), for \\\\(com \\\\geq 0\\\\).\\n'},\n",
       "        {'param_name': 'span',\n",
       "         'param_type': 'float, optional',\n",
       "         'param_desc': 'Specify decay in terms of span\\n\\\\(\\\\alpha = 2 / (span + 1)\\\\), for \\\\(span \\\\geq 1\\\\).\\n'},\n",
       "        {'param_name': 'halflife',\n",
       "         'param_type': 'float, str, timedelta, optional',\n",
       "         'param_desc': 'Specify decay in terms of half-life\\n\\\\(\\\\alpha = 1 - \\\\exp\\\\left(-\\\\ln(2) / halflife\\\\right)\\\\), for\\n\\\\(halflife > 0\\\\).\\nIf times is specified, a timedelta convertible unit over which an\\nobservation decays to half its value. Only applicable to mean(),\\nand halflife value will not apply to the other functions.\\n'},\n",
       "        {'param_name': 'alpha',\n",
       "         'param_type': 'float, optional',\n",
       "         'param_desc': 'Specify smoothing factor \\\\(\\\\alpha\\\\) directly\\n\\\\(0 < \\\\alpha \\\\leq 1\\\\).\\n'},\n",
       "        {'param_name': 'min_periods',\n",
       "         'param_type': 'int, default 0',\n",
       "         'param_desc': 'Minimum number of observations in window required to have a value;\\notherwise, result is np.nan.\\n'},\n",
       "        {'param_name': 'adjust',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Divide by decaying adjustment factor in beginning periods to account\\nfor imbalance in relative weightings (viewing EWMA as a moving average).\\n\\nWhen adjust=True (default), the EW function is calculated using weights\\n\\\\(w_i = (1 - \\\\alpha)^i\\\\). For example, the EW moving average of the series\\n[\\\\(x_0, x_1, ..., x_t\\\\)] would be:\\n\\n\\n\\\\[y_t = \\\\frac{x_t + (1 - \\\\alpha)x_{t-1} + (1 - \\\\alpha)^2 x_{t-2} + ... + (1 -\\n\\\\alpha)^t x_0}{1 + (1 - \\\\alpha) + (1 - \\\\alpha)^2 + ... + (1 - \\\\alpha)^t}\\\\]\\n\\nWhen adjust=False, the exponentially weighted function is calculated\\nrecursively:\\n\\n\\n\\\\[\\\\begin{split}\\\\begin{split}\\ny_0 &= x_0\\\\\\\\\\ny_t &= (1 - \\\\alpha) y_{t-1} + \\\\alpha x_t,\\n\\\\end{split}\\\\end{split}\\\\]\\n'},\n",
       "        {'param_name': 'ignore_na',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Ignore missing values when calculating weights.\\n\\nWhen ignore_na=False (default), weights are based on absolute positions.\\nFor example, the weights of \\\\(x_0\\\\) and \\\\(x_2\\\\) used in calculating\\nthe final weighted average of [\\\\(x_0\\\\), None, \\\\(x_2\\\\)] are\\n\\\\((1-\\\\alpha)^2\\\\) and \\\\(1\\\\) if adjust=True, and\\n\\\\((1-\\\\alpha)^2\\\\) and \\\\(\\\\alpha\\\\) if adjust=False.\\nWhen ignore_na=True, weights are based\\non relative positions. For example, the weights of \\\\(x_0\\\\) and \\\\(x_2\\\\)\\nused in calculating the final weighted average of\\n[\\\\(x_0\\\\), None, \\\\(x_2\\\\)] are \\\\(1-\\\\alpha\\\\) and \\\\(1\\\\) if\\nadjust=True, and \\\\(1-\\\\alpha\\\\) and \\\\(\\\\alpha\\\\) if adjust=False.\\n\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0, 1}, default 0',\n",
       "         'param_desc': \"If 0 or 'index', calculate across the rows.\\nIf 1 or 'columns', calculate across the columns.\\nFor Series this parameter is unused and defaults to 0.\\n\"},\n",
       "        {'param_name': 'times',\n",
       "         'param_type': 'np.ndarray, Series, default None',\n",
       "         'param_desc': 'Only applicable to mean().\\nTimes corresponding to the observations. Must be monotonically increasing and\\ndatetime64[ns] dtype.\\nIf 1-D array like, a sequence with the same shape as the observations.\\n'},\n",
       "        {'param_name': 'method',\n",
       "         'param_type': 'str {‘single’, ‘table’}, default ‘single’',\n",
       "         'param_desc': \"\\nNew in version 1.4.0.\\n\\nExecute the rolling operation per single column or row ('single')\\nor over the entire object ('table').\\nThis argument is only implemented when specifying engine='numba'\\nin the method call.\\nOnly applicable to mean()\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.ewm',\n",
       "       'descriptions': 'Provide exponentially weighted (EW) calculations. Exactly one of com, span, halflife, or alpha must be\\nprovided if times is not provided. If times is provided,\\nhalflife and one of com, span or alpha may be provided.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'com': {'type': 'float',\n",
       "          'description': 'float, optional. Specify decay in terms of center of mass\\n\\\\(\\\\alpha = 1 / (1 + com)\\\\), for \\\\(com \\\\geq 0\\\\).\\n'},\n",
       "         'span': {'type': 'float',\n",
       "          'description': 'float, optional. Specify decay in terms of span\\n\\\\(\\\\alpha = 2 / (span + 1)\\\\), for \\\\(span \\\\geq 1\\\\).\\n'},\n",
       "         'halflife': {'type': 'string',\n",
       "          'description': 'float, str, timedelta, optional. Specify decay in terms of half-life\\n\\\\(\\\\alpha = 1 - \\\\exp\\\\left(-\\\\ln(2) / halflife\\\\right)\\\\), for\\n\\\\(halflife > 0\\\\).\\nIf times is specified, a timedelta convertible unit over which an\\nobservation decays to half its value. Only applicable to mean(),\\nand halflife value will not apply to the other functions.\\n'},\n",
       "         'alpha': {'type': 'float',\n",
       "          'description': 'float, optional. Specify smoothing factor \\\\(\\\\alpha\\\\) directly\\n\\\\(0 < \\\\alpha \\\\leq 1\\\\).\\n'},\n",
       "         'min_periods': {'type': 'integer',\n",
       "          'description': 'int, default 0. Minimum number of observations in window required to have a value;\\notherwise, result is np.nan.\\n'},\n",
       "         'adjust': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Divide by decaying adjustment factor in beginning periods to account\\nfor imbalance in relative weightings (viewing EWMA as a moving average).\\n\\nWhen adjust=True (default), the EW function is calculated using weights\\n\\\\(w_i = (1 - \\\\alpha)^i\\\\). For example, the EW moving average of the series\\n[\\\\(x_0, x_1, ..., x_t\\\\)] would be:\\n\\n\\n\\\\[y_t = \\\\frac{x_t + (1 - \\\\alpha)x_{t-1} + (1 - \\\\alpha)^2 x_{t-2} + ... + (1 -\\n\\\\alpha)^t x_0}{1 + (1 - \\\\alpha) + (1 - \\\\alpha)^2 + ... + (1 - \\\\alpha)^t}\\\\]\\n\\nWhen adjust=False, the exponentially weighted function is calculated\\nrecursively:\\n\\n\\n\\\\[\\\\begin{split}\\\\begin{split}\\ny_0 &= x_0\\\\\\\\\\ny_t &= (1 - \\\\alpha) y_{t-1} + \\\\alpha x_t,\\n\\\\end{split}\\\\end{split}\\\\]\\n'},\n",
       "         'ignore_na': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Ignore missing values when calculating weights.\\n\\nWhen ignore_na=False (default), weights are based on absolute positions.\\nFor example, the weights of \\\\(x_0\\\\) and \\\\(x_2\\\\) used in calculating\\nthe final weighted average of [\\\\(x_0\\\\), None, \\\\(x_2\\\\)] are\\n\\\\((1-\\\\alpha)^2\\\\) and \\\\(1\\\\) if adjust=True, and\\n\\\\((1-\\\\alpha)^2\\\\) and \\\\(\\\\alpha\\\\) if adjust=False.\\nWhen ignore_na=True, weights are based\\non relative positions. For example, the weights of \\\\(x_0\\\\) and \\\\(x_2\\\\)\\nused in calculating the final weighted average of\\n[\\\\(x_0\\\\), None, \\\\(x_2\\\\)] are \\\\(1-\\\\alpha\\\\) and \\\\(1\\\\) if\\nadjust=True, and \\\\(1-\\\\alpha\\\\) and \\\\(\\\\alpha\\\\) if adjust=False.\\n\\n'},\n",
       "         'axis': {'type': '{0, 1}, default 0',\n",
       "          'description': \"{0, 1}, default 0. If 0 or 'index', calculate across the rows.\\nIf 1 or 'columns', calculate across the columns.\\nFor Series this parameter is unused and defaults to 0.\\n\"},\n",
       "         'times': {'type': 'array',\n",
       "          'description': 'np.ndarray, Series, default None. Only applicable to mean().\\nTimes corresponding to the observations. Must be monotonically increasing and\\ndatetime64[ns] dtype.\\nIf 1-D array like, a sequence with the same shape as the observations.\\n'},\n",
       "         'method': {'type': 'string',\n",
       "          'description': \"str {‘single’, ‘table’}, default ‘single’. \\nNew in version 1.4.0.\\n\\nExecute the rolling operation per single column or row ('single')\\nor over the entire object ('table').\\nThis argument is only implemented when specifying engine='numba'\\nin the method call.\\nOnly applicable to mean()\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.map(func[,\\xa0na_action])',\n",
       "      'func_desc': 'Apply a function to a Dataframe elementwise.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.map.html#pandas.DataFrame.map',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.map',\n",
       "       'full_function': 'DataFrame.map(func, na_action=None, **kwargs)',\n",
       "       'function_text': 'Apply a function to a Dataframe elementwise. New in version 2.1.0: DataFrame.applymap was deprecated and renamed to DataFrame.map. This method applies a function that accepts and returns a scalar\\nto every element of a DataFrame.',\n",
       "       'parameter_names_desc': [{'param_name': 'func',\n",
       "         'param_type': 'callable',\n",
       "         'param_desc': 'Python function, returns a single value from a single value.\\n'},\n",
       "        {'param_name': 'na_action',\n",
       "         'param_type': '{None, ‘ignore’}, default None',\n",
       "         'param_desc': 'If ‘ignore’, propagate NaN values, without passing them to func.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.map',\n",
       "       'descriptions': 'Apply a function to a Dataframe elementwise. New in version 2.1.0: DataFrame.applymap was deprecated and renamed to DataFrame.map. This method applies a function that accepts and returns a scalar\\nto every element of a DataFrame.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'func': {'type': 'object',\n",
       "          'description': 'callable. Python function, returns a single value from a single value.\\n'},\n",
       "         'na_action': {'type': 'string',\n",
       "          'enum': ['None', ' ignore'],\n",
       "          'description': '{None, ‘ignore’}, default None. If ‘ignore’, propagate NaN values, without passing them to func.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.pipe(func,\\xa0*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Apply chainable functions that expect Series or DataFrames.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pipe.html#pandas.DataFrame.pipe',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.pipe',\n",
       "       'full_function': 'DataFrame.pipe(func, *args, **kwargs)',\n",
       "       'function_text': 'Apply chainable functions that expect Series or DataFrames.',\n",
       "       'parameter_names_desc': [{'param_name': 'func',\n",
       "         'param_type': 'function',\n",
       "         'param_desc': 'Function to apply to the Series/DataFrame.\\nargs, and kwargs are passed into func.\\nAlternatively a (callable, data_keyword) tuple where\\ndata_keyword is a string indicating the keyword of\\ncallable that expects the Series/DataFrame.\\n'},\n",
       "        {'param_name': '*args',\n",
       "         'param_type': 'iterable, optional',\n",
       "         'param_desc': 'Positional arguments passed into func.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.pipe',\n",
       "       'descriptions': 'Apply chainable functions that expect Series or DataFrames.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'func': {'type': 'function',\n",
       "          'description': 'function. Function to apply to the Series/DataFrame.\\nargs, and kwargs are passed into func.\\nAlternatively a (callable, data_keyword) tuple where\\ndata_keyword is a string indicating the keyword of\\ncallable that expects the Series/DataFrame.\\n'},\n",
       "         '*args': {'type': 'iterable, optional',\n",
       "          'description': 'iterable, optional. Positional arguments passed into func.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.aggregate([func,\\xa0axis])',\n",
       "      'func_desc': 'Aggregate using one or more operations over the specified axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.aggregate.html#pandas.DataFrame.aggregate',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.aggregate',\n",
       "       'full_function': 'DataFrame.aggregate(func=None, axis=0, *args, **kwargs)',\n",
       "       'function_text': 'Aggregate using one or more operations over the specified axis.',\n",
       "       'parameter_names_desc': [{'param_name': 'func',\n",
       "         'param_type': 'function, str, list or dict',\n",
       "         'param_desc': \"Function to use for aggregating the data. If a function, must either\\nwork when passed a DataFrame or when passed to DataFrame.apply.\\nAccepted combinations are:\\n\\nfunction\\nstring function name\\nlist of functions and/or function names, e.g. [np.sum, 'mean']\\ndict of axis labels -> functions, function names or list of such.\\n\\n\"},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'If 0 or ‘index’: apply function to each column.\\nIf 1 or ‘columns’: apply function to each row.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.aggregate',\n",
       "       'descriptions': 'Aggregate using one or more operations over the specified axis.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'func': {'type': 'string',\n",
       "          'description': \"function, str, list or dict. Function to use for aggregating the data. If a function, must either\\nwork when passed a DataFrame or when passed to DataFrame.apply.\\nAccepted combinations are:\\n\\nfunction\\nstring function name\\nlist of functions and/or function names, e.g. [np.sum, 'mean']\\ndict of axis labels -> functions, function names or list of such.\\n\\n\"},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. If 0 or ‘index’: apply function to each column.\\nIf 1 or ‘columns’: apply function to each row.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.groupby([by,\\xa0axis,\\xa0level,\\xa0...])',\n",
       "      'func_desc': 'Group DataFrame using a mapper or by a Series of columns.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html#pandas.DataFrame.groupby',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.groupby',\n",
       "       'full_function': 'DataFrame.groupby(by=None, axis=_NoDefault.no_default, level=None, as_index=True, sort=True, group_keys=True, observed=_NoDefault.no_default, dropna=True)',\n",
       "       'function_text': 'Group DataFrame using a mapper or by a Series of columns. A groupby operation involves some combination of splitting the\\nobject, applying a function, and combining the results. This can be\\nused to group large amounts of data and compute operations on these\\ngroups.',\n",
       "       'parameter_names_desc': [{'param_name': 'by',\n",
       "         'param_type': 'mapping, function, label, pd.Grouper or list of such',\n",
       "         'param_desc': 'Used to determine the groups for the groupby.\\nIf by is a function, it’s called on each value of the object’s\\nindex. If a dict or Series is passed, the Series or dict VALUES\\nwill be used to determine the groups (the Series’ values are first\\naligned; see .align() method). If a list or ndarray of length\\nequal to the selected axis is passed (see the groupby user guide),\\nthe values are used as-is to determine the groups. A label or list\\nof labels may be passed to group by the columns in self.\\nNotice that a tuple is interpreted as a (single) key.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'Split along rows (0) or columns (1). For Series this parameter\\nis unused and defaults to 0.\\n\\nDeprecated since version 2.1.0: Will be removed and behave like axis=0 in a future version.\\nFor axis=1, do frame.T.groupby(...) instead.\\n\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int, level name, or sequence of such, default None',\n",
       "         'param_desc': 'If the axis is a MultiIndex (hierarchical), group by a particular\\nlevel or levels. Do not specify both by and level.\\n'},\n",
       "        {'param_name': 'as_index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Return object with group labels as the\\nindex. Only relevant for DataFrame input. as_index=False is\\neffectively “SQL-style” grouped output. This argument has no effect\\non filtrations (see the filtrations in the user guide),\\nsuch as head(), tail(), nth() and in transformations\\n(see the transformations in the user guide).\\n'},\n",
       "        {'param_name': 'sort',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Sort group keys. Get better performance by turning this off.\\nNote this does not influence the order of observations within each\\ngroup. Groupby preserves the order of rows within each group. If False,\\nthe groups will appear in the same order as they did in the original DataFrame.\\nThis argument has no effect on filtrations (see the filtrations in the user guide),\\nsuch as head(), tail(), nth() and in transformations\\n(see the transformations in the user guide).\\n\\nChanged in version 2.0.0: Specifying sort=False with an ordered categorical grouper will no\\nlonger sort the values.\\n\\n'},\n",
       "        {'param_name': 'group_keys',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'When calling apply and the by argument produces a like-indexed\\n(i.e. a transform) result, add group keys to\\nindex to identify pieces. By default group keys are not included\\nwhen the result’s index (and column) labels match the inputs, and\\nare included otherwise.\\n\\nChanged in version 1.5.0: Warns that group_keys will no longer be ignored when the\\nresult from apply is a like-indexed Series or DataFrame.\\nSpecify group_keys explicitly to include the group keys or\\nnot.\\n\\n\\nChanged in version 2.0.0: group_keys now defaults to True.\\n\\n'},\n",
       "        {'param_name': 'observed',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'This only applies if any of the groupers are Categoricals.\\nIf True: only show observed values for categorical groupers.\\nIf False: show all values for categorical groupers.\\n\\nDeprecated since version 2.1.0: The default value will change to True in a future version of pandas.\\n\\n'},\n",
       "        {'param_name': 'dropna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If True, and if group keys contain NA values, NA values together\\nwith row/column will be dropped.\\nIf False, NA values will also be treated as the key in groups.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.groupby',\n",
       "       'descriptions': 'Group DataFrame using a mapper or by a Series of columns. A groupby operation involves some combination of splitting the\\nobject, applying a function, and combining the results. This can be\\nused to group large amounts of data and compute operations on these\\ngroups.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'by': {'type': 'array',\n",
       "          'description': 'mapping, function, label, pd.Grouper or list of such. Used to determine the groups for the groupby.\\nIf by is a function, it’s called on each value of the object’s\\nindex. If a dict or Series is passed, the Series or dict VALUES\\nwill be used to determine the groups (the Series’ values are first\\naligned; see .align() method). If a list or ndarray of length\\nequal to the selected axis is passed (see the groupby user guide),\\nthe values are used as-is to determine the groups. A label or list\\nof labels may be passed to group by the columns in self.\\nNotice that a tuple is interpreted as a (single) key.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. Split along rows (0) or columns (1). For Series this parameter\\nis unused and defaults to 0.\\n\\nDeprecated since version 2.1.0: Will be removed and behave like axis=0 in a future version.\\nFor axis=1, do frame.T.groupby(...) instead.\\n\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int, level name, or sequence of such, default None. If the axis is a MultiIndex (hierarchical), group by a particular\\nlevel or levels. Do not specify both by and level.\\n'},\n",
       "         'as_index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Return object with group labels as the\\nindex. Only relevant for DataFrame input. as_index=False is\\neffectively “SQL-style” grouped output. This argument has no effect\\non filtrations (see the filtrations in the user guide),\\nsuch as head(), tail(), nth() and in transformations\\n(see the transformations in the user guide).\\n'},\n",
       "         'sort': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Sort group keys. Get better performance by turning this off.\\nNote this does not influence the order of observations within each\\ngroup. Groupby preserves the order of rows within each group. If False,\\nthe groups will appear in the same order as they did in the original DataFrame.\\nThis argument has no effect on filtrations (see the filtrations in the user guide),\\nsuch as head(), tail(), nth() and in transformations\\n(see the transformations in the user guide).\\n\\nChanged in version 2.0.0: Specifying sort=False with an ordered categorical grouper will no\\nlonger sort the values.\\n\\n'},\n",
       "         'group_keys': {'type': 'boolean',\n",
       "          'description': 'bool, default True. When calling apply and the by argument produces a like-indexed\\n(i.e. a transform) result, add group keys to\\nindex to identify pieces. By default group keys are not included\\nwhen the result’s index (and column) labels match the inputs, and\\nare included otherwise.\\n\\nChanged in version 1.5.0: Warns that group_keys will no longer be ignored when the\\nresult from apply is a like-indexed Series or DataFrame.\\nSpecify group_keys explicitly to include the group keys or\\nnot.\\n\\n\\nChanged in version 2.0.0: group_keys now defaults to True.\\n\\n'},\n",
       "         'observed': {'type': 'boolean',\n",
       "          'description': 'bool, default False. This only applies if any of the groupers are Categoricals.\\nIf True: only show observed values for categorical groupers.\\nIf False: show all values for categorical groupers.\\n\\nDeprecated since version 2.1.0: The default value will change to True in a future version of pandas.\\n\\n'},\n",
       "         'dropna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If True, and if group keys contain NA values, NA values together\\nwith row/column will be dropped.\\nIf False, NA values will also be treated as the key in groups.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.expanding([min_periods,\\xa0axis,\\xa0method])',\n",
       "      'func_desc': 'Provide expanding window calculations.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.expanding.html#pandas.DataFrame.expanding',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.expanding',\n",
       "       'full_function': \"DataFrame.expanding(min_periods=1, axis=_NoDefault.no_default, method='single')\",\n",
       "       'function_text': 'Provide expanding window calculations.',\n",
       "       'parameter_names_desc': [{'param_name': 'min_periods',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Minimum number of observations in window required to have a value;\\notherwise, result is np.nan.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': 'int or str, default 0',\n",
       "         'param_desc': \"If 0 or 'index', roll across the rows.\\nIf 1 or 'columns', roll across the columns.\\nFor Series this parameter is unused and defaults to 0.\\n\"},\n",
       "        {'param_name': 'method',\n",
       "         'param_type': 'str {‘single’, ‘table’}, default ‘single’',\n",
       "         'param_desc': \"Execute the rolling operation per single column or row ('single')\\nor over the entire object ('table').\\nThis argument is only implemented when specifying engine='numba'\\nin the method call.\\n\\nNew in version 1.3.0.\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.expanding',\n",
       "       'descriptions': 'Provide expanding window calculations.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'min_periods': {'type': 'integer',\n",
       "          'description': 'int, default 1. Minimum number of observations in window required to have a value;\\notherwise, result is np.nan.\\n'},\n",
       "         'axis': {'type': 'integer',\n",
       "          'description': \"int or str, default 0. If 0 or 'index', roll across the rows.\\nIf 1 or 'columns', roll across the columns.\\nFor Series this parameter is unused and defaults to 0.\\n\"},\n",
       "         'method': {'type': 'string',\n",
       "          'description': \"str {‘single’, ‘table’}, default ‘single’. Execute the rolling operation per single column or row ('single')\\nor over the entire object ('table').\\nThis argument is only implemented when specifying engine='numba'\\nin the method call.\\n\\nNew in version 1.3.0.\\n\\n\"}},\n",
       "        'required': []}}}]},\n",
       "   {'Computations / descriptive stats': [{'func_name': 'DataFrame.abs()',\n",
       "      'func_desc': 'Return a Series/DataFrame with absolute numeric value of each element.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.abs.html#pandas.DataFrame.abs',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.abs',\n",
       "       'full_function': 'DataFrame.abs()',\n",
       "       'function_text': 'Return a Series/DataFrame with absolute numeric value of each element. This function only applies to elements that are all numeric.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.any(*[,\\xa0axis,\\xa0bool_only,\\xa0skipna])',\n",
       "      'func_desc': 'Return whether any element is True, potentially over an axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.any.html#pandas.DataFrame.any',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.any',\n",
       "       'full_function': 'DataFrame.any(*, axis=0, bool_only=False, skipna=True, **kwargs)',\n",
       "       'function_text': 'Return whether any element is True, potentially over an axis. Returns False unless there is at least one element within a series or\\nalong a Dataframe axis that is True or equivalent (e.g. non-zero or\\nnon-empty).',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’, None}, default 0',\n",
       "         'param_desc': 'Indicate which axis or axes should be reduced. For Series this parameter\\nis unused and defaults to 0.\\n\\n0 / ‘index’ : reduce the index, return a Series whose index is the\\noriginal column labels.\\n1 / ‘columns’ : reduce the columns, return a Series whose index is the\\noriginal index.\\nNone : reduce all axes, return a scalar.\\n\\n'},\n",
       "        {'param_name': 'bool_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only boolean columns. Not implemented for Series.\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values. If the entire row/column is NA and skipna is\\nTrue, then the result will be False, as for an empty row/column.\\nIf skipna is False, then NA are treated as True, because these are not\\nequal to zero.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.any',\n",
       "       'descriptions': 'Return whether any element is True, potentially over an axis. Returns False unless there is at least one element within a series or\\nalong a Dataframe axis that is True or equivalent (e.g. non-zero or\\nnon-empty).',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns', ' None'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’, None}, default 0. Indicate which axis or axes should be reduced. For Series this parameter\\nis unused and defaults to 0.\\n\\n0 / ‘index’ : reduce the index, return a Series whose index is the\\noriginal column labels.\\n1 / ‘columns’ : reduce the columns, return a Series whose index is the\\noriginal index.\\nNone : reduce all axes, return a scalar.\\n\\n'},\n",
       "         'bool_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only boolean columns. Not implemented for Series.\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values. If the entire row/column is NA and skipna is\\nTrue, then the result will be False, as for an empty row/column.\\nIf skipna is False, then NA are treated as True, because these are not\\nequal to zero.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.corr([method,\\xa0min_periods,\\xa0...])',\n",
       "      'func_desc': 'Compute pairwise correlation of columns, excluding NA/null values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html#pandas.DataFrame.corr',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.corr',\n",
       "       'full_function': \"DataFrame.corr(method='pearson', min_periods=1, numeric_only=False)\",\n",
       "       'function_text': 'Compute pairwise correlation of columns, excluding NA/null values.',\n",
       "       'parameter_names_desc': [{'param_name': 'method',\n",
       "         'param_type': '{‘pearson’, ‘kendall’, ‘spearman’} or callable',\n",
       "         'param_desc': 'Method of correlation:\\n\\npearson : standard correlation coefficient\\nkendall : Kendall Tau correlation coefficient\\nspearman : Spearman rank correlation\\n\\ncallable: callable with input two 1d ndarraysand returning a float. Note that the returned matrix from corr\\nwill have 1 along the diagonals and will be symmetric\\nregardless of the callable’s behavior.\\n\\n\\n\\n\\n'},\n",
       "        {'param_name': 'min_periods',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Minimum number of observations required per pair of columns\\nto have a valid result. Currently only available for Pearson\\nand Spearman correlation.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int or boolean data.\\n\\nNew in version 1.5.0.\\n\\n\\nChanged in version 2.0.0: The default value of numeric_only is now False.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.corr',\n",
       "       'descriptions': 'Compute pairwise correlation of columns, excluding NA/null values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'method': {'type': 'object',\n",
       "          'description': '{‘pearson’, ‘kendall’, ‘spearman’} or callable. Method of correlation:\\n\\npearson : standard correlation coefficient\\nkendall : Kendall Tau correlation coefficient\\nspearman : Spearman rank correlation\\n\\ncallable: callable with input two 1d ndarraysand returning a float. Note that the returned matrix from corr\\nwill have 1 along the diagonals and will be symmetric\\nregardless of the callable’s behavior.\\n\\n\\n\\n\\n'},\n",
       "         'min_periods': {'type': 'integer',\n",
       "          'description': 'int, optional. Minimum number of observations required per pair of columns\\nto have a valid result. Currently only available for Pearson\\nand Spearman correlation.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int or boolean data.\\n\\nNew in version 1.5.0.\\n\\n\\nChanged in version 2.0.0: The default value of numeric_only is now False.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.count([axis,\\xa0numeric_only])',\n",
       "      'func_desc': 'Count non-NA cells for each column or row.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.count.html#pandas.DataFrame.count',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.count',\n",
       "       'full_function': 'DataFrame.count(axis=0, numeric_only=False)',\n",
       "       'function_text': 'Count non-NA cells for each column or row. The values None, NaN, NaT, pandas.NA are considered NA.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'If 0 or ‘index’ counts are generated for each column.\\nIf 1 or ‘columns’ counts are generated for each row.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int or boolean data.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.count',\n",
       "       'descriptions': 'Count non-NA cells for each column or row. The values None, NaN, NaT, pandas.NA are considered NA.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. If 0 or ‘index’ counts are generated for each column.\\nIf 1 or ‘columns’ counts are generated for each row.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int or boolean data.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.cummax([axis,\\xa0skipna])',\n",
       "      'func_desc': 'Return cumulative maximum over a DataFrame or Series axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cummax.html#pandas.DataFrame.cummax',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.cummax',\n",
       "       'full_function': 'DataFrame.cummax(axis=None, skipna=True, *args, **kwargs)',\n",
       "       'function_text': 'Return cumulative maximum over a DataFrame or Series axis. Returns a DataFrame or Series of the same size containing the cumulative\\nmaximum.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'The index or the name of the axis. 0 is equivalent to None or ‘index’.\\nFor Series this parameter is unused and defaults to 0.\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.cummax',\n",
       "       'descriptions': 'Return cumulative maximum over a DataFrame or Series axis. Returns a DataFrame or Series of the same size containing the cumulative\\nmaximum.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. The index or the name of the axis. 0 is equivalent to None or ‘index’.\\nFor Series this parameter is unused and defaults to 0.\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.cumprod([axis,\\xa0skipna])',\n",
       "      'func_desc': 'Return cumulative product over a DataFrame or Series axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cumprod.html#pandas.DataFrame.cumprod',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.cumprod',\n",
       "       'full_function': 'DataFrame.cumprod(axis=None, skipna=True, *args, **kwargs)',\n",
       "       'function_text': 'Return cumulative product over a DataFrame or Series axis. Returns a DataFrame or Series of the same size containing the cumulative\\nproduct.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'The index or the name of the axis. 0 is equivalent to None or ‘index’.\\nFor Series this parameter is unused and defaults to 0.\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.cumprod',\n",
       "       'descriptions': 'Return cumulative product over a DataFrame or Series axis. Returns a DataFrame or Series of the same size containing the cumulative\\nproduct.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. The index or the name of the axis. 0 is equivalent to None or ‘index’.\\nFor Series this parameter is unused and defaults to 0.\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.describe([percentiles,\\xa0include,\\xa0...])',\n",
       "      'func_desc': 'Generate descriptive statistics.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html#pandas.DataFrame.describe',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.describe',\n",
       "       'full_function': 'DataFrame.describe(percentiles=None, include=None, exclude=None)',\n",
       "       'function_text': 'Generate descriptive statistics. Descriptive statistics include those that summarize the central\\ntendency, dispersion and shape of a\\ndataset’s distribution, excluding NaN values. Analyzes both numeric and object series, as well\\nas DataFrame column sets of mixed data types. The output\\nwill vary depending on what is provided. Refer to the notes\\nbelow for more detail.',\n",
       "       'parameter_names_desc': [{'param_name': 'percentiles',\n",
       "         'param_type': 'list-like of numbers, optional',\n",
       "         'param_desc': 'The percentiles to include in the output. All should\\nfall between 0 and 1. The default is\\n[.25, .5, .75], which returns the 25th, 50th, and\\n75th percentiles.\\n'},\n",
       "        {'param_name': 'include',\n",
       "         'param_type': '‘all’, list-like of dtypes or None (default), optional',\n",
       "         'param_desc': \"A white list of data types to include in the result. Ignored\\nfor Series. Here are the options:\\n\\n‘all’ : All columns of the input will be included in the output.\\nA list-like of dtypes : Limits the results to the\\nprovided data types.\\nTo limit the result to numeric types submit\\nnumpy.number. To limit it instead to object columns submit\\nthe numpy.object data type. Strings\\ncan also be used in the style of\\nselect_dtypes (e.g. df.describe(include=['O'])). To\\nselect pandas categorical columns, use 'category'\\nNone (default) : The result will include all numeric columns.\\n\\n\"},\n",
       "        {'param_name': 'exclude',\n",
       "         'param_type': 'list-like of dtypes or None (default), optional,',\n",
       "         'param_desc': \"A black list of data types to omit from the result. Ignored\\nfor Series. Here are the options:\\n\\nA list-like of dtypes : Excludes the provided data types\\nfrom the result. To exclude numeric types submit\\nnumpy.number. To exclude object columns submit the data\\ntype numpy.object. Strings can also be used in the style of\\nselect_dtypes (e.g. df.describe(exclude=['O'])). To\\nexclude pandas categorical columns, use 'category'\\nNone (default) : The result will exclude nothing.\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.describe',\n",
       "       'descriptions': 'Generate descriptive statistics. Descriptive statistics include those that summarize the central\\ntendency, dispersion and shape of a\\ndataset’s distribution, excluding NaN values. Analyzes both numeric and object series, as well\\nas DataFrame column sets of mixed data types. The output\\nwill vary depending on what is provided. Refer to the notes\\nbelow for more detail.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'percentiles': {'type': 'array',\n",
       "          'description': 'list-like of numbers, optional. The percentiles to include in the output. All should\\nfall between 0 and 1. The default is\\n[.25, .5, .75], which returns the 25th, 50th, and\\n75th percentiles.\\n'},\n",
       "         'include': {'type': 'array',\n",
       "          'description': \"‘all’, list-like of dtypes or None (default), optional. A white list of data types to include in the result. Ignored\\nfor Series. Here are the options:\\n\\n‘all’ : All columns of the input will be included in the output.\\nA list-like of dtypes : Limits the results to the\\nprovided data types.\\nTo limit the result to numeric types submit\\nnumpy.number. To limit it instead to object columns submit\\nthe numpy.object data type. Strings\\ncan also be used in the style of\\nselect_dtypes (e.g. df.describe(include=['O'])). To\\nselect pandas categorical columns, use 'category'\\nNone (default) : The result will include all numeric columns.\\n\\n\"},\n",
       "         'exclude': {'type': 'array',\n",
       "          'description': \"list-like of dtypes or None (default), optional,. A black list of data types to omit from the result. Ignored\\nfor Series. Here are the options:\\n\\nA list-like of dtypes : Excludes the provided data types\\nfrom the result. To exclude numeric types submit\\nnumpy.number. To exclude object columns submit the data\\ntype numpy.object. Strings can also be used in the style of\\nselect_dtypes (e.g. df.describe(exclude=['O'])). To\\nexclude pandas categorical columns, use 'category'\\nNone (default) : The result will exclude nothing.\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.eval(expr,\\xa0*[,\\xa0inplace])',\n",
       "      'func_desc': 'Evaluate a string describing operations on DataFrame columns.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.eval.html#pandas.DataFrame.eval',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.eval',\n",
       "       'full_function': 'DataFrame.eval(expr, *, inplace=False, **kwargs)',\n",
       "       'function_text': 'Evaluate a string describing operations on DataFrame columns. Operates on columns only, not specific rows or elements. This allows\\neval to run arbitrary code, which can make you vulnerable to code\\ninjection if you pass user input to this function.',\n",
       "       'parameter_names_desc': [{'param_name': 'expr',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'The expression string to evaluate.\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If the expression contains an assignment, whether to perform the\\noperation inplace and mutate the existing DataFrame. Otherwise,\\na new DataFrame is returned.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.eval',\n",
       "       'descriptions': 'Evaluate a string describing operations on DataFrame columns. Operates on columns only, not specific rows or elements. This allows\\neval to run arbitrary code, which can make you vulnerable to code\\ninjection if you pass user input to this function.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'expr': {'type': 'string',\n",
       "          'description': 'str. The expression string to evaluate.\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If the expression contains an assignment, whether to perform the\\noperation inplace and mutate the existing DataFrame. Otherwise,\\na new DataFrame is returned.\\n'}},\n",
       "        'required': ['expr']}}},\n",
       "     {'func_name': 'DataFrame.kurtosis([axis,\\xa0skipna,\\xa0numeric_only])',\n",
       "      'func_desc': 'Return unbiased kurtosis over requested axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.kurtosis.html#pandas.DataFrame.kurtosis',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.kurtosis',\n",
       "       'full_function': 'DataFrame.kurtosis(axis=0, skipna=True, numeric_only=False, **kwargs)',\n",
       "       'function_text': 'Return unbiased kurtosis over requested axis. Kurtosis obtained using Fisher’s definition of\\nkurtosis (kurtosis of normal == 0.0). Normalized by N-1.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{index (0), columns (1)}',\n",
       "         'param_desc': 'Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\nFor DataFrames, specifying axis=None will apply the aggregation\\nacross both axes.\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values when computing the result.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns. Not implemented for Series.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.kurtosis',\n",
       "       'descriptions': 'Return unbiased kurtosis over requested axis. Kurtosis obtained using Fisher’s definition of\\nkurtosis (kurtosis of normal == 0.0). Normalized by N-1.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': '{index (0), columns (1)}',\n",
       "          'description': '{index (0), columns (1)}. Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\nFor DataFrames, specifying axis=None will apply the aggregation\\nacross both axes.\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values when computing the result.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns. Not implemented for Series.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.mean([axis,\\xa0skipna,\\xa0numeric_only])',\n",
       "      'func_desc': 'Return the mean of the values over the requested axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mean.html#pandas.DataFrame.mean',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.mean',\n",
       "       'full_function': 'DataFrame.mean(axis=0, skipna=True, numeric_only=False, **kwargs)',\n",
       "       'function_text': 'Return the mean of the values over the requested axis.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{index (0), columns (1)}',\n",
       "         'param_desc': 'Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\nFor DataFrames, specifying axis=None will apply the aggregation\\nacross both axes.\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values when computing the result.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns. Not implemented for Series.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.mean',\n",
       "       'descriptions': 'Return the mean of the values over the requested axis.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': '{index (0), columns (1)}',\n",
       "          'description': '{index (0), columns (1)}. Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\nFor DataFrames, specifying axis=None will apply the aggregation\\nacross both axes.\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values when computing the result.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns. Not implemented for Series.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.min([axis,\\xa0skipna,\\xa0numeric_only])',\n",
       "      'func_desc': 'Return the minimum of the values over the requested axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.min.html#pandas.DataFrame.min',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.min',\n",
       "       'full_function': 'DataFrame.min(axis=0, skipna=True, numeric_only=False, **kwargs)',\n",
       "       'function_text': 'Return the minimum of the values over the requested axis. If you want the index of the minimum, use idxmin. This is the equivalent of the numpy.ndarray method argmin.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{index (0), columns (1)}',\n",
       "         'param_desc': 'Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\nFor DataFrames, specifying axis=None will apply the aggregation\\nacross both axes.\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values when computing the result.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns. Not implemented for Series.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.min',\n",
       "       'descriptions': 'Return the minimum of the values over the requested axis. If you want the index of the minimum, use idxmin. This is the equivalent of the numpy.ndarray method argmin.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': '{index (0), columns (1)}',\n",
       "          'description': '{index (0), columns (1)}. Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\nFor DataFrames, specifying axis=None will apply the aggregation\\nacross both axes.\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values when computing the result.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns. Not implemented for Series.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.pct_change([periods,\\xa0fill_method,\\xa0...])',\n",
       "      'func_desc': 'Fractional change between the current and a prior element.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pct_change.html#pandas.DataFrame.pct_change',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.pct_change',\n",
       "       'full_function': 'DataFrame.pct_change(periods=1, fill_method=_NoDefault.no_default, limit=_NoDefault.no_default, freq=None, **kwargs)',\n",
       "       'function_text': 'Fractional change between the current and a prior element. Computes the fractional change from the immediately previous row by\\ndefault. This is useful in comparing the fraction of change in a time\\nseries of elements. Note Despite the name of this method, it calculates fractional change\\n(also known as per unit change or relative change) and not\\npercentage change. If you need the percentage change, multiply\\nthese values by 100.',\n",
       "       'parameter_names_desc': [{'param_name': 'periods',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Periods to shift for forming percent change.\\n'},\n",
       "        {'param_name': 'fill_method',\n",
       "         'param_type': '{‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}, default ‘pad’',\n",
       "         'param_desc': 'How to handle NAs before computing percent changes.\\n\\nDeprecated since version 2.1: All options of fill_method are deprecated except fill_method=None.\\n\\n'},\n",
       "        {'param_name': 'limit',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'The number of consecutive NAs to fill before stopping.\\n\\nDeprecated since version 2.1.\\n\\n'},\n",
       "        {'param_name': 'freq',\n",
       "         'param_type': 'DateOffset, timedelta, or str, optional',\n",
       "         'param_desc': 'Increment to use from time series API (e.g. ‘ME’ or BDay()).\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.pct_change',\n",
       "       'descriptions': 'Fractional change between the current and a prior element. Computes the fractional change from the immediately previous row by\\ndefault. This is useful in comparing the fraction of change in a time\\nseries of elements. Note Despite the name of this method, it calculates fractional change\\n(also known as per unit change or relative change) and not\\npercentage change. If you need the percentage change, multiply\\nthese values by 100.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'periods': {'type': 'integer',\n",
       "          'description': 'int, default 1. Periods to shift for forming percent change.\\n'},\n",
       "         'fill_method': {'type': 'string',\n",
       "          'enum': ['backfill', ' bfill', ' pad', ' ffill', ' None'],\n",
       "          'description': '{‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}, default ‘pad’. How to handle NAs before computing percent changes.\\n\\nDeprecated since version 2.1: All options of fill_method are deprecated except fill_method=None.\\n\\n'},\n",
       "         'limit': {'type': 'integer',\n",
       "          'description': 'int, default None. The number of consecutive NAs to fill before stopping.\\n\\nDeprecated since version 2.1.\\n\\n'},\n",
       "         'freq': {'type': 'string',\n",
       "          'description': 'DateOffset, timedelta, or str, optional. Increment to use from time series API (e.g. ‘ME’ or BDay()).\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.product([axis,\\xa0skipna,\\xa0...])',\n",
       "      'func_desc': 'Return the product of the values over the requested axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.product.html#pandas.DataFrame.product',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.product',\n",
       "       'full_function': 'DataFrame.product(axis=0, skipna=True, numeric_only=False, min_count=0, **kwargs)',\n",
       "       'function_text': 'Return the product of the values over the requested axis.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{index (0), columns (1)}',\n",
       "         'param_desc': 'Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\n\\nWarning\\nThe behavior of DataFrame.prod with axis=None is deprecated,\\nin a future version this will reduce over both axes and return a scalar\\nTo retain the old behavior, pass axis=0 (or do not pass axis).\\n\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values when computing the result.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns. Not implemented for Series.\\n'},\n",
       "        {'param_name': 'min_count',\n",
       "         'param_type': 'int, default 0',\n",
       "         'param_desc': 'The required number of valid values to perform the operation. If fewer than\\nmin_count non-NA values are present the result will be NA.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.product',\n",
       "       'descriptions': 'Return the product of the values over the requested axis.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': '{index (0), columns (1)}',\n",
       "          'description': '{index (0), columns (1)}. Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\n\\nWarning\\nThe behavior of DataFrame.prod with axis=None is deprecated,\\nin a future version this will reduce over both axes and return a scalar\\nTo retain the old behavior, pass axis=0 (or do not pass axis).\\n\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values when computing the result.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns. Not implemented for Series.\\n'},\n",
       "         'min_count': {'type': 'integer',\n",
       "          'description': 'int, default 0. The required number of valid values to perform the operation. If fewer than\\nmin_count non-NA values are present the result will be NA.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.rank([axis,\\xa0method,\\xa0numeric_only,\\xa0...])',\n",
       "      'func_desc': 'Compute numerical data ranks (1 through n) along axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rank.html#pandas.DataFrame.rank',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.rank',\n",
       "       'full_function': \"DataFrame.rank(axis=0, method='average', numeric_only=False, na_option='keep', ascending=True, pct=False)\",\n",
       "       'function_text': 'Compute numerical data ranks (1 through n) along axis. By default, equal values are assigned a rank that is the average of the\\nranks of those values.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'Index to direct ranking.\\nFor Series this parameter is unused and defaults to 0.\\n'},\n",
       "        {'param_name': 'method',\n",
       "         'param_type': '{‘average’, ‘min’, ‘max’, ‘first’, ‘dense’}, default ‘average’',\n",
       "         'param_desc': 'How to rank the group of records that have the same value (i.e. ties):\\n\\naverage: average rank of the group\\nmin: lowest rank in the group\\nmax: highest rank in the group\\nfirst: ranks assigned in order they appear in the array\\ndense: like ‘min’, but rank always increases by 1 between groups.\\n\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'For DataFrame objects, rank only numeric columns if set to True.\\n\\nChanged in version 2.0.0: The default value of numeric_only is now False.\\n\\n'},\n",
       "        {'param_name': 'na_option',\n",
       "         'param_type': '{‘keep’, ‘top’, ‘bottom’}, default ‘keep’',\n",
       "         'param_desc': 'How to rank NaN values:\\n\\nkeep: assign NaN rank to NaN values\\ntop: assign lowest rank to NaN values\\nbottom: assign highest rank to NaN values\\n\\n'},\n",
       "        {'param_name': 'ascending',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether or not the elements should be ranked in ascending order.\\n'},\n",
       "        {'param_name': 'pct',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether or not to display the returned rankings in percentile\\nform.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.rank',\n",
       "       'descriptions': 'Compute numerical data ranks (1 through n) along axis. By default, equal values are assigned a rank that is the average of the\\nranks of those values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. Index to direct ranking.\\nFor Series this parameter is unused and defaults to 0.\\n'},\n",
       "         'method': {'type': 'string',\n",
       "          'enum': ['average', ' min', ' max', ' first', ' dense'],\n",
       "          'description': '{‘average’, ‘min’, ‘max’, ‘first’, ‘dense’}, default ‘average’. How to rank the group of records that have the same value (i.e. ties):\\n\\naverage: average rank of the group\\nmin: lowest rank in the group\\nmax: highest rank in the group\\nfirst: ranks assigned in order they appear in the array\\ndense: like ‘min’, but rank always increases by 1 between groups.\\n\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. For DataFrame objects, rank only numeric columns if set to True.\\n\\nChanged in version 2.0.0: The default value of numeric_only is now False.\\n\\n'},\n",
       "         'na_option': {'type': 'string',\n",
       "          'enum': ['keep', ' top', ' bottom'],\n",
       "          'description': '{‘keep’, ‘top’, ‘bottom’}, default ‘keep’. How to rank NaN values:\\n\\nkeep: assign NaN rank to NaN values\\ntop: assign lowest rank to NaN values\\nbottom: assign highest rank to NaN values\\n\\n'},\n",
       "         'ascending': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether or not the elements should be ranked in ascending order.\\n'},\n",
       "         'pct': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether or not to display the returned rankings in percentile\\nform.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.sem([axis,\\xa0skipna,\\xa0ddof,\\xa0numeric_only])',\n",
       "      'func_desc': 'Return unbiased standard error of the mean over requested axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sem.html#pandas.DataFrame.sem',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.sem',\n",
       "       'full_function': 'DataFrame.sem(axis=0, skipna=True, ddof=1, numeric_only=False, **kwargs)',\n",
       "       'function_text': 'Return unbiased standard error of the mean over requested axis. Normalized by N-1 by default. This can be changed using the ddof argument',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{index (0), columns (1)}',\n",
       "         'param_desc': 'For Series this parameter is unused and defaults to 0.\\n\\nWarning\\nThe behavior of DataFrame.sem with axis=None is deprecated,\\nin a future version this will reduce over both axes and return a scalar\\nTo retain the old behavior, pass axis=0 (or do not pass axis).\\n\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n'},\n",
       "        {'param_name': 'ddof',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\\nwhere N represents the number of elements.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns. Not implemented for Series.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.sem',\n",
       "       'descriptions': 'Return unbiased standard error of the mean over requested axis. Normalized by N-1 by default. This can be changed using the ddof argument',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': '{index (0), columns (1)}',\n",
       "          'description': '{index (0), columns (1)}. For Series this parameter is unused and defaults to 0.\\n\\nWarning\\nThe behavior of DataFrame.sem with axis=None is deprecated,\\nin a future version this will reduce over both axes and return a scalar\\nTo retain the old behavior, pass axis=0 (or do not pass axis).\\n\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n'},\n",
       "         'ddof': {'type': 'integer',\n",
       "          'description': 'int, default 1. Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\\nwhere N represents the number of elements.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns. Not implemented for Series.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.sum([axis,\\xa0skipna,\\xa0numeric_only,\\xa0...])',\n",
       "      'func_desc': 'Return the sum of the values over the requested axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sum.html#pandas.DataFrame.sum',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.sum',\n",
       "       'full_function': 'DataFrame.sum(axis=0, skipna=True, numeric_only=False, min_count=0, **kwargs)',\n",
       "       'function_text': 'Return the sum of the values over the requested axis. This is equivalent to the method numpy.sum.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{index (0), columns (1)}',\n",
       "         'param_desc': 'Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\n\\nWarning\\nThe behavior of DataFrame.sum with axis=None is deprecated,\\nin a future version this will reduce over both axes and return a scalar\\nTo retain the old behavior, pass axis=0 (or do not pass axis).\\n\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values when computing the result.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns. Not implemented for Series.\\n'},\n",
       "        {'param_name': 'min_count',\n",
       "         'param_type': 'int, default 0',\n",
       "         'param_desc': 'The required number of valid values to perform the operation. If fewer than\\nmin_count non-NA values are present the result will be NA.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.sum',\n",
       "       'descriptions': 'Return the sum of the values over the requested axis. This is equivalent to the method numpy.sum.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': '{index (0), columns (1)}',\n",
       "          'description': '{index (0), columns (1)}. Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\n\\nWarning\\nThe behavior of DataFrame.sum with axis=None is deprecated,\\nin a future version this will reduce over both axes and return a scalar\\nTo retain the old behavior, pass axis=0 (or do not pass axis).\\n\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values when computing the result.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns. Not implemented for Series.\\n'},\n",
       "         'min_count': {'type': 'integer',\n",
       "          'description': 'int, default 0. The required number of valid values to perform the operation. If fewer than\\nmin_count non-NA values are present the result will be NA.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.var([axis,\\xa0skipna,\\xa0ddof,\\xa0numeric_only])',\n",
       "      'func_desc': 'Return unbiased variance over requested axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.var.html#pandas.DataFrame.var',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.var',\n",
       "       'full_function': 'DataFrame.var(axis=0, skipna=True, ddof=1, numeric_only=False, **kwargs)',\n",
       "       'function_text': 'Return unbiased variance over requested axis. Normalized by N-1 by default. This can be changed using the ddof argument.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{index (0), columns (1)}',\n",
       "         'param_desc': 'For Series this parameter is unused and defaults to 0.\\n\\nWarning\\nThe behavior of DataFrame.var with axis=None is deprecated,\\nin a future version this will reduce over both axes and return a scalar\\nTo retain the old behavior, pass axis=0 (or do not pass axis).\\n\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n'},\n",
       "        {'param_name': 'ddof',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\\nwhere N represents the number of elements.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns. Not implemented for Series.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.var',\n",
       "       'descriptions': 'Return unbiased variance over requested axis. Normalized by N-1 by default. This can be changed using the ddof argument.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': '{index (0), columns (1)}',\n",
       "          'description': '{index (0), columns (1)}. For Series this parameter is unused and defaults to 0.\\n\\nWarning\\nThe behavior of DataFrame.var with axis=None is deprecated,\\nin a future version this will reduce over both axes and return a scalar\\nTo retain the old behavior, pass axis=0 (or do not pass axis).\\n\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n'},\n",
       "         'ddof': {'type': 'integer',\n",
       "          'description': 'int, default 1. Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\\nwhere N represents the number of elements.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns. Not implemented for Series.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.value_counts([subset,\\xa0normalize,\\xa0...])',\n",
       "      'func_desc': 'Return a Series containing the frequency of each distinct row in the Dataframe.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html#pandas.DataFrame.value_counts',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.value_counts',\n",
       "       'full_function': 'DataFrame.value_counts(subset=None, normalize=False, sort=True, ascending=False, dropna=True)',\n",
       "       'function_text': 'Return a Series containing the frequency of each distinct row in the Dataframe.',\n",
       "       'parameter_names_desc': [{'param_name': 'subset',\n",
       "         'param_type': 'label or list of labels, optional',\n",
       "         'param_desc': 'Columns to use when counting unique combinations.\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Return proportions rather than frequencies.\\n'},\n",
       "        {'param_name': 'sort',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Sort by frequencies when True. Sort by DataFrame column values when False.\\n'},\n",
       "        {'param_name': 'ascending',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Sort in ascending order.\\n'},\n",
       "        {'param_name': 'dropna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Don’t include counts of rows that contain NA values.\\n\\nNew in version 1.3.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.value_counts',\n",
       "       'descriptions': 'Return a Series containing the frequency of each distinct row in the Dataframe.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'subset': {'type': 'array',\n",
       "          'description': 'label or list of labels, optional. Columns to use when counting unique combinations.\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Return proportions rather than frequencies.\\n'},\n",
       "         'sort': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Sort by frequencies when True. Sort by DataFrame column values when False.\\n'},\n",
       "         'ascending': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Sort in ascending order.\\n'},\n",
       "         'dropna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Don’t include counts of rows that contain NA values.\\n\\nNew in version 1.3.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.all([axis,\\xa0bool_only,\\xa0skipna])',\n",
       "      'func_desc': 'Return whether all elements are True, potentially over an axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.all.html#pandas.DataFrame.all',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.all',\n",
       "       'full_function': 'DataFrame.all(axis=0, bool_only=False, skipna=True, **kwargs)',\n",
       "       'function_text': 'Return whether all elements are True, potentially over an axis. Returns True unless there at least one element within a series or\\nalong a Dataframe axis that is False or equivalent (e.g. zero or\\nempty).',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’, None}, default 0',\n",
       "         'param_desc': 'Indicate which axis or axes should be reduced. For Series this parameter\\nis unused and defaults to 0.\\n\\n0 / ‘index’ : reduce the index, return a Series whose index is the\\noriginal column labels.\\n1 / ‘columns’ : reduce the columns, return a Series whose index is the\\noriginal index.\\nNone : reduce all axes, return a scalar.\\n\\n'},\n",
       "        {'param_name': 'bool_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only boolean columns. Not implemented for Series.\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values. If the entire row/column is NA and skipna is\\nTrue, then the result will be True, as for an empty row/column.\\nIf skipna is False, then NA are treated as True, because these are not\\nequal to zero.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.all',\n",
       "       'descriptions': 'Return whether all elements are True, potentially over an axis. Returns True unless there at least one element within a series or\\nalong a Dataframe axis that is False or equivalent (e.g. zero or\\nempty).',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns', ' None'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’, None}, default 0. Indicate which axis or axes should be reduced. For Series this parameter\\nis unused and defaults to 0.\\n\\n0 / ‘index’ : reduce the index, return a Series whose index is the\\noriginal column labels.\\n1 / ‘columns’ : reduce the columns, return a Series whose index is the\\noriginal index.\\nNone : reduce all axes, return a scalar.\\n\\n'},\n",
       "         'bool_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only boolean columns. Not implemented for Series.\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values. If the entire row/column is NA and skipna is\\nTrue, then the result will be True, as for an empty row/column.\\nIf skipna is False, then NA are treated as True, because these are not\\nequal to zero.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.clip([lower,\\xa0upper,\\xa0axis,\\xa0inplace])',\n",
       "      'func_desc': 'Trim values at input threshold(s).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.clip.html#pandas.DataFrame.clip',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.clip',\n",
       "       'full_function': 'DataFrame.clip(lower=None, upper=None, *, axis=None, inplace=False, **kwargs)',\n",
       "       'function_text': 'Trim values at input threshold(s). Assigns values outside boundary to boundary values. Thresholds\\ncan be singular values or array like, and in the latter case\\nthe clipping is performed element-wise in the specified axis.',\n",
       "       'parameter_names_desc': [{'param_name': 'lower',\n",
       "         'param_type': 'float or array-like, default None',\n",
       "         'param_desc': 'Minimum threshold value. All values below this\\nthreshold will be set to it. A missing\\nthreshold (e.g NA) will not clip the value.\\n'},\n",
       "        {'param_name': 'upper',\n",
       "         'param_type': 'float or array-like, default None',\n",
       "         'param_desc': 'Maximum threshold value. All values above this\\nthreshold will be set to it. A missing\\nthreshold (e.g NA) will not clip the value.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{{0 or ‘index’, 1 or ‘columns’, None}}, default None',\n",
       "         'param_desc': 'Align object with lower and upper along the given axis.\\nFor Series this parameter is unused and defaults to None.\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to perform the operation in place on the data.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.clip',\n",
       "       'descriptions': 'Trim values at input threshold(s). Assigns values outside boundary to boundary values. Thresholds\\ncan be singular values or array like, and in the latter case\\nthe clipping is performed element-wise in the specified axis.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'lower': {'type': 'float',\n",
       "          'description': 'float or array-like, default None. Minimum threshold value. All values below this\\nthreshold will be set to it. A missing\\nthreshold (e.g NA) will not clip the value.\\n'},\n",
       "         'upper': {'type': 'float',\n",
       "          'description': 'float or array-like, default None. Maximum threshold value. All values above this\\nthreshold will be set to it. A missing\\nthreshold (e.g NA) will not clip the value.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['{0 or index', ' 1 or columns', ' None'],\n",
       "          'description': '{{0 or ‘index’, 1 or ‘columns’, None}}, default None. Align object with lower and upper along the given axis.\\nFor Series this parameter is unused and defaults to None.\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to perform the operation in place on the data.\\n'}},\n",
       "        'required': ['lower=None', 'upper=None']}}},\n",
       "     {'func_name': 'DataFrame.corrwith(other[,\\xa0axis,\\xa0drop,\\xa0...])',\n",
       "      'func_desc': 'Compute pairwise correlation.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corrwith.html#pandas.DataFrame.corrwith',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.corrwith',\n",
       "       'full_function': \"DataFrame.corrwith(other, axis=0, drop=False, method='pearson', numeric_only=False)\",\n",
       "       'function_text': 'Compute pairwise correlation. Pairwise correlation is computed between rows or columns of\\nDataFrame with rows or columns of Series or DataFrame. DataFrames\\nare first aligned along both axes before computing the\\ncorrelations.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'DataFrame, Series',\n",
       "         'param_desc': 'Object with which to compute correlations.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'The axis to use. 0 or ‘index’ to compute row-wise, 1 or ‘columns’ for\\ncolumn-wise.\\n'},\n",
       "        {'param_name': 'drop',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Drop missing indices from result.\\n'},\n",
       "        {'param_name': 'method',\n",
       "         'param_type': '{‘pearson’, ‘kendall’, ‘spearman’} or callable',\n",
       "         'param_desc': 'Method of correlation:\\n\\npearson : standard correlation coefficient\\nkendall : Kendall Tau correlation coefficient\\nspearman : Spearman rank correlation\\n\\ncallable: callable with input two 1d ndarraysand returning a float.\\n\\n\\n\\n\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int or boolean data.\\n\\nNew in version 1.5.0.\\n\\n\\nChanged in version 2.0.0: The default value of numeric_only is now False.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.corrwith',\n",
       "       'descriptions': 'Compute pairwise correlation. Pairwise correlation is computed between rows or columns of\\nDataFrame with rows or columns of Series or DataFrame. DataFrames\\nare first aligned along both axes before computing the\\ncorrelations.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'DataFrame, Series',\n",
       "          'description': 'DataFrame, Series. Object with which to compute correlations.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. The axis to use. 0 or ‘index’ to compute row-wise, 1 or ‘columns’ for\\ncolumn-wise.\\n'},\n",
       "         'drop': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Drop missing indices from result.\\n'},\n",
       "         'method': {'type': 'object',\n",
       "          'description': '{‘pearson’, ‘kendall’, ‘spearman’} or callable. Method of correlation:\\n\\npearson : standard correlation coefficient\\nkendall : Kendall Tau correlation coefficient\\nspearman : Spearman rank correlation\\n\\ncallable: callable with input two 1d ndarraysand returning a float.\\n\\n\\n\\n\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int or boolean data.\\n\\nNew in version 1.5.0.\\n\\n\\nChanged in version 2.0.0: The default value of numeric_only is now False.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.cov([min_periods,\\xa0ddof,\\xa0numeric_only])',\n",
       "      'func_desc': 'Compute pairwise covariance of columns, excluding NA/null values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cov.html#pandas.DataFrame.cov',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.cov',\n",
       "       'full_function': 'DataFrame.cov(min_periods=None, ddof=1, numeric_only=False)',\n",
       "       'function_text': 'Compute pairwise covariance of columns, excluding NA/null values. Compute the pairwise covariance among the series of a DataFrame.\\nThe returned data frame is the covariance matrix of the columns\\nof the DataFrame. Both NA and null values are automatically excluded from the\\ncalculation. (See the note below about bias from missing values.)\\nA threshold can be set for the minimum number of\\nobservations for each value created. Comparisons with observations\\nbelow this threshold will be returned as NaN. This method is generally used for the analysis of time series data to\\nunderstand the relationship between different measures\\nacross time.',\n",
       "       'parameter_names_desc': [{'param_name': 'min_periods',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Minimum number of observations required per pair of columns\\nto have a valid result.\\n'},\n",
       "        {'param_name': 'ddof',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Delta degrees of freedom. The divisor used in calculations\\nis N - ddof, where N represents the number of elements.\\nThis argument is applicable only when no nan is in the dataframe.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int or boolean data.\\n\\nNew in version 1.5.0.\\n\\n\\nChanged in version 2.0.0: The default value of numeric_only is now False.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.cov',\n",
       "       'descriptions': 'Compute pairwise covariance of columns, excluding NA/null values. Compute the pairwise covariance among the series of a DataFrame.\\nThe returned data frame is the covariance matrix of the columns\\nof the DataFrame. Both NA and null values are automatically excluded from the\\ncalculation. (See the note below about bias from missing values.)\\nA threshold can be set for the minimum number of\\nobservations for each value created. Comparisons with observations\\nbelow this threshold will be returned as NaN. This method is generally used for the analysis of time series data to\\nunderstand the relationship between different measures\\nacross time.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'min_periods': {'type': 'integer',\n",
       "          'description': 'int, optional. Minimum number of observations required per pair of columns\\nto have a valid result.\\n'},\n",
       "         'ddof': {'type': 'integer',\n",
       "          'description': 'int, default 1. Delta degrees of freedom. The divisor used in calculations\\nis N - ddof, where N represents the number of elements.\\nThis argument is applicable only when no nan is in the dataframe.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int or boolean data.\\n\\nNew in version 1.5.0.\\n\\n\\nChanged in version 2.0.0: The default value of numeric_only is now False.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.cummin([axis,\\xa0skipna])',\n",
       "      'func_desc': 'Return cumulative minimum over a DataFrame or Series axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cummin.html#pandas.DataFrame.cummin',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.cummin',\n",
       "       'full_function': 'DataFrame.cummin(axis=None, skipna=True, *args, **kwargs)',\n",
       "       'function_text': 'Return cumulative minimum over a DataFrame or Series axis. Returns a DataFrame or Series of the same size containing the cumulative\\nminimum.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'The index or the name of the axis. 0 is equivalent to None or ‘index’.\\nFor Series this parameter is unused and defaults to 0.\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.cummin',\n",
       "       'descriptions': 'Return cumulative minimum over a DataFrame or Series axis. Returns a DataFrame or Series of the same size containing the cumulative\\nminimum.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. The index or the name of the axis. 0 is equivalent to None or ‘index’.\\nFor Series this parameter is unused and defaults to 0.\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.cumsum([axis,\\xa0skipna])',\n",
       "      'func_desc': 'Return cumulative sum over a DataFrame or Series axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cumsum.html#pandas.DataFrame.cumsum',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.cumsum',\n",
       "       'full_function': 'DataFrame.cumsum(axis=None, skipna=True, *args, **kwargs)',\n",
       "       'function_text': 'Return cumulative sum over a DataFrame or Series axis. Returns a DataFrame or Series of the same size containing the cumulative\\nsum.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'The index or the name of the axis. 0 is equivalent to None or ‘index’.\\nFor Series this parameter is unused and defaults to 0.\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.cumsum',\n",
       "       'descriptions': 'Return cumulative sum over a DataFrame or Series axis. Returns a DataFrame or Series of the same size containing the cumulative\\nsum.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. The index or the name of the axis. 0 is equivalent to None or ‘index’.\\nFor Series this parameter is unused and defaults to 0.\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.diff([periods,\\xa0axis])',\n",
       "      'func_desc': 'First discrete difference of element.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.diff.html#pandas.DataFrame.diff',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.diff',\n",
       "       'full_function': 'DataFrame.diff(periods=1, axis=0)',\n",
       "       'function_text': 'First discrete difference of element. Calculates the difference of a DataFrame element compared with another\\nelement in the DataFrame (default is element in previous row).',\n",
       "       'parameter_names_desc': [{'param_name': 'periods',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Periods to shift for calculating difference, accepts negative\\nvalues.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'Take difference over rows (0) or columns (1).\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.diff',\n",
       "       'descriptions': 'First discrete difference of element. Calculates the difference of a DataFrame element compared with another\\nelement in the DataFrame (default is element in previous row).',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'periods': {'type': 'integer',\n",
       "          'description': 'int, default 1. Periods to shift for calculating difference, accepts negative\\nvalues.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. Take difference over rows (0) or columns (1).\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.kurt([axis,\\xa0skipna,\\xa0numeric_only])',\n",
       "      'func_desc': 'Return unbiased kurtosis over requested axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.kurt.html#pandas.DataFrame.kurt',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.kurt',\n",
       "       'full_function': 'DataFrame.kurt(axis=0, skipna=True, numeric_only=False, **kwargs)',\n",
       "       'function_text': 'Return unbiased kurtosis over requested axis. Kurtosis obtained using Fisher’s definition of\\nkurtosis (kurtosis of normal == 0.0). Normalized by N-1.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{index (0), columns (1)}',\n",
       "         'param_desc': 'Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\nFor DataFrames, specifying axis=None will apply the aggregation\\nacross both axes.\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values when computing the result.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns. Not implemented for Series.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.kurt',\n",
       "       'descriptions': 'Return unbiased kurtosis over requested axis. Kurtosis obtained using Fisher’s definition of\\nkurtosis (kurtosis of normal == 0.0). Normalized by N-1.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': '{index (0), columns (1)}',\n",
       "          'description': '{index (0), columns (1)}. Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\nFor DataFrames, specifying axis=None will apply the aggregation\\nacross both axes.\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values when computing the result.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns. Not implemented for Series.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.max([axis,\\xa0skipna,\\xa0numeric_only])',\n",
       "      'func_desc': 'Return the maximum of the values over the requested axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.max.html#pandas.DataFrame.max',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.max',\n",
       "       'full_function': 'DataFrame.max(axis=0, skipna=True, numeric_only=False, **kwargs)',\n",
       "       'function_text': 'Return the maximum of the values over the requested axis. If you want the index of the maximum, use idxmax. This is the equivalent of the numpy.ndarray method argmax.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{index (0), columns (1)}',\n",
       "         'param_desc': 'Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\nFor DataFrames, specifying axis=None will apply the aggregation\\nacross both axes.\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values when computing the result.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns. Not implemented for Series.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.max',\n",
       "       'descriptions': 'Return the maximum of the values over the requested axis. If you want the index of the maximum, use idxmax. This is the equivalent of the numpy.ndarray method argmax.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': '{index (0), columns (1)}',\n",
       "          'description': '{index (0), columns (1)}. Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\nFor DataFrames, specifying axis=None will apply the aggregation\\nacross both axes.\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values when computing the result.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns. Not implemented for Series.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.median([axis,\\xa0skipna,\\xa0numeric_only])',\n",
       "      'func_desc': 'Return the median of the values over the requested axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.median.html#pandas.DataFrame.median',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.median',\n",
       "       'full_function': 'DataFrame.median(axis=0, skipna=True, numeric_only=False, **kwargs)',\n",
       "       'function_text': 'Return the median of the values over the requested axis.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{index (0), columns (1)}',\n",
       "         'param_desc': 'Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\nFor DataFrames, specifying axis=None will apply the aggregation\\nacross both axes.\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values when computing the result.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns. Not implemented for Series.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.median',\n",
       "       'descriptions': 'Return the median of the values over the requested axis.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': '{index (0), columns (1)}',\n",
       "          'description': '{index (0), columns (1)}. Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\nFor DataFrames, specifying axis=None will apply the aggregation\\nacross both axes.\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values when computing the result.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns. Not implemented for Series.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.mode([axis,\\xa0numeric_only,\\xa0dropna])',\n",
       "      'func_desc': 'Get the mode(s) of each element along the selected axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mode.html#pandas.DataFrame.mode',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.mode',\n",
       "       'full_function': 'DataFrame.mode(axis=0, numeric_only=False, dropna=True)',\n",
       "       'function_text': 'Get the mode(s) of each element along the selected axis. The mode of a set of values is the value that appears most often.\\nIt can be multiple values.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'The axis to iterate over while searching for the mode:\\n\\n0 or ‘index’ : get mode of each column\\n1 or ‘columns’ : get mode of each row.\\n\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True, only apply to numeric columns.\\n'},\n",
       "        {'param_name': 'dropna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Don’t consider counts of NaN/NaT.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.mode',\n",
       "       'descriptions': 'Get the mode(s) of each element along the selected axis. The mode of a set of values is the value that appears most often.\\nIt can be multiple values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. The axis to iterate over while searching for the mode:\\n\\n0 or ‘index’ : get mode of each column\\n1 or ‘columns’ : get mode of each row.\\n\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True, only apply to numeric columns.\\n'},\n",
       "         'dropna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Don’t consider counts of NaN/NaT.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.prod([axis,\\xa0skipna,\\xa0numeric_only,\\xa0...])',\n",
       "      'func_desc': 'Return the product of the values over the requested axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.prod.html#pandas.DataFrame.prod',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.prod',\n",
       "       'full_function': 'DataFrame.prod(axis=0, skipna=True, numeric_only=False, min_count=0, **kwargs)',\n",
       "       'function_text': 'Return the product of the values over the requested axis.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{index (0), columns (1)}',\n",
       "         'param_desc': 'Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\n\\nWarning\\nThe behavior of DataFrame.prod with axis=None is deprecated,\\nin a future version this will reduce over both axes and return a scalar\\nTo retain the old behavior, pass axis=0 (or do not pass axis).\\n\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values when computing the result.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns. Not implemented for Series.\\n'},\n",
       "        {'param_name': 'min_count',\n",
       "         'param_type': 'int, default 0',\n",
       "         'param_desc': 'The required number of valid values to perform the operation. If fewer than\\nmin_count non-NA values are present the result will be NA.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.prod',\n",
       "       'descriptions': 'Return the product of the values over the requested axis.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': '{index (0), columns (1)}',\n",
       "          'description': '{index (0), columns (1)}. Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\n\\nWarning\\nThe behavior of DataFrame.prod with axis=None is deprecated,\\nin a future version this will reduce over both axes and return a scalar\\nTo retain the old behavior, pass axis=0 (or do not pass axis).\\n\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values when computing the result.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns. Not implemented for Series.\\n'},\n",
       "         'min_count': {'type': 'integer',\n",
       "          'description': 'int, default 0. The required number of valid values to perform the operation. If fewer than\\nmin_count non-NA values are present the result will be NA.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.quantile([q,\\xa0axis,\\xa0numeric_only,\\xa0...])',\n",
       "      'func_desc': 'Return values at the given quantile over requested axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.quantile.html#pandas.DataFrame.quantile',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.quantile',\n",
       "       'full_function': \"DataFrame.quantile(q=0.5, axis=0, numeric_only=False, interpolation='linear', method='single')\",\n",
       "       'function_text': 'Return values at the given quantile over requested axis.',\n",
       "       'parameter_names_desc': [{'param_name': 'q',\n",
       "         'param_type': 'float or array-like, default 0.5 (50% quantile)',\n",
       "         'param_desc': 'Value between 0 <= q <= 1, the quantile(s) to compute.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'Equals 0 or ‘index’ for row-wise, 1 or ‘columns’ for column-wise.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int or boolean data.\\n\\nChanged in version 2.0.0: The default value of numeric_only is now False.\\n\\n'},\n",
       "        {'param_name': 'interpolation',\n",
       "         'param_type': '{‘linear’, ‘lower’, ‘higher’, ‘midpoint’, ‘nearest’}',\n",
       "         'param_desc': 'This optional parameter specifies the interpolation method to use,\\nwhen the desired quantile lies between two data points i and j:\\n\\nlinear: i + (j - i) * fraction, where fraction is the\\nfractional part of the index surrounded by i and j.\\nlower: i.\\nhigher: j.\\nnearest: i or j whichever is nearest.\\nmidpoint: (i + j) / 2.\\n\\n'},\n",
       "        {'param_name': 'method',\n",
       "         'param_type': '{‘single’, ‘table’}, default ‘single’',\n",
       "         'param_desc': 'Whether to compute quantiles per-column (‘single’) or over all columns\\n(‘table’). When ‘table’, the only allowed interpolation methods are\\n‘nearest’, ‘lower’, and ‘higher’.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.quantile',\n",
       "       'descriptions': 'Return values at the given quantile over requested axis.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'q': {'type': 'float',\n",
       "          'description': 'float or array-like, default 0.5 (50% quantile). Value between 0 <= q <= 1, the quantile(s) to compute.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. Equals 0 or ‘index’ for row-wise, 1 or ‘columns’ for column-wise.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int or boolean data.\\n\\nChanged in version 2.0.0: The default value of numeric_only is now False.\\n\\n'},\n",
       "         'interpolation': {'type': 'integer',\n",
       "          'description': '{‘linear’, ‘lower’, ‘higher’, ‘midpoint’, ‘nearest’}. This optional parameter specifies the interpolation method to use,\\nwhen the desired quantile lies between two data points i and j:\\n\\nlinear: i + (j - i) * fraction, where fraction is the\\nfractional part of the index surrounded by i and j.\\nlower: i.\\nhigher: j.\\nnearest: i or j whichever is nearest.\\nmidpoint: (i + j) / 2.\\n\\n'},\n",
       "         'method': {'type': 'string',\n",
       "          'enum': ['single', ' table'],\n",
       "          'description': '{‘single’, ‘table’}, default ‘single’. Whether to compute quantiles per-column (‘single’) or over all columns\\n(‘table’). When ‘table’, the only allowed interpolation methods are\\n‘nearest’, ‘lower’, and ‘higher’.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.round([decimals])',\n",
       "      'func_desc': 'Round a DataFrame to a variable number of decimal places.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.round.html#pandas.DataFrame.round',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.round',\n",
       "       'full_function': 'DataFrame.round(decimals=0, *args, **kwargs)',\n",
       "       'function_text': 'Round a DataFrame to a variable number of decimal places.',\n",
       "       'parameter_names_desc': [{'param_name': 'decimals',\n",
       "         'param_type': 'int, dict, Series',\n",
       "         'param_desc': 'Number of decimal places to round each column to. If an int is\\ngiven, round each column to the same number of places.\\nOtherwise dict and Series round to variable numbers of places.\\nColumn names should be in the keys if decimals is a\\ndict-like, or in the index if decimals is a Series. Any\\ncolumns not included in decimals will be left as is. Elements\\nof decimals which are not columns of the input will be\\nignored.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.round',\n",
       "       'descriptions': 'Round a DataFrame to a variable number of decimal places.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'decimals': {'type': 'integer',\n",
       "          'description': 'int, dict, Series. Number of decimal places to round each column to. If an int is\\ngiven, round each column to the same number of places.\\nOtherwise dict and Series round to variable numbers of places.\\nColumn names should be in the keys if decimals is a\\ndict-like, or in the index if decimals is a Series. Any\\ncolumns not included in decimals will be left as is. Elements\\nof decimals which are not columns of the input will be\\nignored.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.skew([axis,\\xa0skipna,\\xa0numeric_only])',\n",
       "      'func_desc': 'Return unbiased skew over requested axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.skew.html#pandas.DataFrame.skew',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.skew',\n",
       "       'full_function': 'DataFrame.skew(axis=0, skipna=True, numeric_only=False, **kwargs)',\n",
       "       'function_text': 'Return unbiased skew over requested axis. Normalized by N-1.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{index (0), columns (1)}',\n",
       "         'param_desc': 'Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\nFor DataFrames, specifying axis=None will apply the aggregation\\nacross both axes.\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values when computing the result.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns. Not implemented for Series.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.skew',\n",
       "       'descriptions': 'Return unbiased skew over requested axis. Normalized by N-1.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': '{index (0), columns (1)}',\n",
       "          'description': '{index (0), columns (1)}. Axis for the function to be applied on.\\nFor Series this parameter is unused and defaults to 0.\\nFor DataFrames, specifying axis=None will apply the aggregation\\nacross both axes.\\n\\nNew in version 2.0.0.\\n\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values when computing the result.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns. Not implemented for Series.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.std([axis,\\xa0skipna,\\xa0ddof,\\xa0numeric_only])',\n",
       "      'func_desc': 'Return sample standard deviation over requested axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.std.html#pandas.DataFrame.std',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.std',\n",
       "       'full_function': 'DataFrame.std(axis=0, skipna=True, ddof=1, numeric_only=False, **kwargs)',\n",
       "       'function_text': 'Return sample standard deviation over requested axis. Normalized by N-1 by default. This can be changed using the ddof argument.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{index (0), columns (1)}',\n",
       "         'param_desc': 'For Series this parameter is unused and defaults to 0.\\n\\nWarning\\nThe behavior of DataFrame.std with axis=None is deprecated,\\nin a future version this will reduce over both axes and return a scalar\\nTo retain the old behavior, pass axis=0 (or do not pass axis).\\n\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n'},\n",
       "        {'param_name': 'ddof',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\\nwhere N represents the number of elements.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns. Not implemented for Series.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.std',\n",
       "       'descriptions': 'Return sample standard deviation over requested axis. Normalized by N-1 by default. This can be changed using the ddof argument.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': '{index (0), columns (1)}',\n",
       "          'description': '{index (0), columns (1)}. For Series this parameter is unused and defaults to 0.\\n\\nWarning\\nThe behavior of DataFrame.std with axis=None is deprecated,\\nin a future version this will reduce over both axes and return a scalar\\nTo retain the old behavior, pass axis=0 (or do not pass axis).\\n\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n'},\n",
       "         'ddof': {'type': 'integer',\n",
       "          'description': 'int, default 1. Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\\nwhere N represents the number of elements.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns. Not implemented for Series.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.nunique([axis,\\xa0dropna])',\n",
       "      'func_desc': 'Count number of distinct elements in specified axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nunique.html#pandas.DataFrame.nunique',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.nunique',\n",
       "       'full_function': 'DataFrame.nunique(axis=0, dropna=True)',\n",
       "       'function_text': 'Count number of distinct elements in specified axis. Return Series with number of distinct elements. Can ignore NaN\\nvalues.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'The axis to use. 0 or ‘index’ for row-wise, 1 or ‘columns’ for\\ncolumn-wise.\\n'},\n",
       "        {'param_name': 'dropna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Don’t include NaN in the counts.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.nunique',\n",
       "       'descriptions': 'Count number of distinct elements in specified axis. Return Series with number of distinct elements. Can ignore NaN\\nvalues.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. The axis to use. 0 or ‘index’ for row-wise, 1 or ‘columns’ for\\ncolumn-wise.\\n'},\n",
       "         'dropna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Don’t include NaN in the counts.\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Reindexing / selection / label manipulation': [{'func_name': 'DataFrame.add_prefix(prefix[,\\xa0axis])',\n",
       "      'func_desc': 'Prefix labels with string prefix.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add_prefix.html#pandas.DataFrame.add_prefix',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.add_prefix',\n",
       "       'full_function': 'DataFrame.add_prefix(prefix, axis=None)',\n",
       "       'function_text': 'Prefix labels with string prefix. For Series, the row labels are prefixed.\\nFor DataFrame, the column labels are prefixed.',\n",
       "       'parameter_names_desc': [{'param_name': 'prefix',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'The string to add before each label.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’, None}, default None',\n",
       "         'param_desc': 'Axis to add prefix on\\n\\nNew in version 2.0.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.add_prefix',\n",
       "       'descriptions': 'Prefix labels with string prefix. For Series, the row labels are prefixed.\\nFor DataFrame, the column labels are prefixed.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'prefix': {'type': 'string',\n",
       "          'description': 'str. The string to add before each label.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns', ' None'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’, None}, default None. Axis to add prefix on\\n\\nNew in version 2.0.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.align(other[,\\xa0join,\\xa0axis,\\xa0level,\\xa0...])',\n",
       "      'func_desc': 'Align two objects on their axes with the specified join method.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.align.html#pandas.DataFrame.align',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.align',\n",
       "       'full_function': \"DataFrame.align(other, join='outer', axis=None, level=None, copy=None, fill_value=None, method=_NoDefault.no_default, limit=_NoDefault.no_default, fill_axis=_NoDefault.no_default, broadcast_axis=_NoDefault.no_default)\",\n",
       "       'function_text': 'Align two objects on their axes with the specified join method. Join method is specified for each axis Index.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'DataFrame or Series',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'join',\n",
       "         'param_type': '{‘outer’, ‘inner’, ‘left’, ‘right’}, default ‘outer’',\n",
       "         'param_desc': 'Type of alignment to be performed.\\n\\nleft: use only keys from left frame, preserve key order.\\nright: use only keys from right frame, preserve key order.\\nouter: use union of keys from both frames, sort keys lexicographically.\\ninner: use intersection of keys from both frames,\\npreserve the order of the left keys.\\n\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': 'allowed axis of the other object, default None',\n",
       "         'param_desc': 'Align on index (0), columns (1), or both (None).\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or level name, default None',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Always returns new objects. If copy=False and no reindexing is\\nrequired then original objects are returned.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'scalar, default np.nan',\n",
       "         'param_desc': 'Value to use for missing values. Defaults to NaN, but can be any\\n“compatible” value.\\n'},\n",
       "        {'param_name': 'method',\n",
       "         'param_type': '{‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}, default None',\n",
       "         'param_desc': 'Method to use for filling holes in reindexed Series:\\n\\npad / ffill: propagate last valid observation forward to next valid.\\nbackfill / bfill: use NEXT valid observation to fill gap.\\n\\n\\nDeprecated since version 2.1.\\n\\n'},\n",
       "        {'param_name': 'limit',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'If method is specified, this is the maximum number of consecutive\\nNaN values to forward/backward fill. In other words, if there is\\na gap with more than this number of consecutive NaNs, it will only\\nbe partially filled. If method is not specified, this is the\\nmaximum number of entries along the entire axis where NaNs will be\\nfilled. Must be greater than 0 if not None.\\n\\nDeprecated since version 2.1.\\n\\n'},\n",
       "        {'param_name': 'fill_axis',\n",
       "         'param_type': '{0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame, default 0',\n",
       "         'param_desc': 'Filling axis, method and limit.\\n\\nDeprecated since version 2.1.\\n\\n'},\n",
       "        {'param_name': 'broadcast_axis',\n",
       "         'param_type': '{0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame, default None',\n",
       "         'param_desc': 'Broadcast values along this axis, if aligning two objects of\\ndifferent dimensions.\\n\\nDeprecated since version 2.1.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.align',\n",
       "       'descriptions': 'Align two objects on their axes with the specified join method. Join method is specified for each axis Index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'DataFrame or Series',\n",
       "          'description': 'DataFrame or Series. '},\n",
       "         'join': {'type': 'string',\n",
       "          'enum': ['outer', ' inner', ' left', ' right'],\n",
       "          'description': '{‘outer’, ‘inner’, ‘left’, ‘right’}, default ‘outer’. Type of alignment to be performed.\\n\\nleft: use only keys from left frame, preserve key order.\\nright: use only keys from right frame, preserve key order.\\nouter: use union of keys from both frames, sort keys lexicographically.\\ninner: use intersection of keys from both frames,\\npreserve the order of the left keys.\\n\\n'},\n",
       "         'axis': {'type': 'object',\n",
       "          'description': 'allowed axis of the other object, default None. Align on index (0), columns (1), or both (None).\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or level name, default None. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Always returns new objects. If copy=False and no reindexing is\\nrequired then original objects are returned.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'},\n",
       "         'fill_value': {'type': 'scalar, default np.nan',\n",
       "          'description': 'scalar, default np.nan. Value to use for missing values. Defaults to NaN, but can be any\\n“compatible” value.\\n'},\n",
       "         'method': {'type': 'string',\n",
       "          'enum': ['backfill', ' bfill', ' pad', ' ffill', ' None'],\n",
       "          'description': '{‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}, default None. Method to use for filling holes in reindexed Series:\\n\\npad / ffill: propagate last valid observation forward to next valid.\\nbackfill / bfill: use NEXT valid observation to fill gap.\\n\\n\\nDeprecated since version 2.1.\\n\\n'},\n",
       "         'limit': {'type': 'integer',\n",
       "          'description': 'int, default None. If method is specified, this is the maximum number of consecutive\\nNaN values to forward/backward fill. In other words, if there is\\na gap with more than this number of consecutive NaNs, it will only\\nbe partially filled. If method is not specified, this is the\\nmaximum number of entries along the entire axis where NaNs will be\\nfilled. Must be greater than 0 if not None.\\n\\nDeprecated since version 2.1.\\n\\n'},\n",
       "         'fill_axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame, default 0. Filling axis, method and limit.\\n\\nDeprecated since version 2.1.\\n\\n'},\n",
       "         'broadcast_axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame, default None. Broadcast values along this axis, if aligning two objects of\\ndifferent dimensions.\\n\\nDeprecated since version 2.1.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.between_time(start_time,\\xa0end_time)',\n",
       "      'func_desc': 'Select values between particular times of the day (e.g., 9:00-9:30 AM).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.between_time.html#pandas.DataFrame.between_time',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.between_time',\n",
       "       'full_function': \"DataFrame.between_time(start_time, end_time, inclusive='both', axis=None)\",\n",
       "       'function_text': 'Select values between particular times of the day (e.g., 9:00-9:30 AM). By setting start_time to be later than end_time,\\nyou can get the times that are not between the two times.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.drop_duplicates([subset,\\xa0keep,\\xa0...])',\n",
       "      'func_desc': 'Return DataFrame with duplicate rows removed.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html#pandas.DataFrame.drop_duplicates',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.drop_duplicates',\n",
       "       'full_function': \"DataFrame.drop_duplicates(subset=None, *, keep='first', inplace=False, ignore_index=False)\",\n",
       "       'function_text': 'Return DataFrame with duplicate rows removed. Considering certain columns is optional. Indexes, including time indexes\\nare ignored.',\n",
       "       'parameter_names_desc': [{'param_name': 'subset',\n",
       "         'param_type': 'column label or sequence of labels, optional',\n",
       "         'param_desc': 'Only consider certain columns for identifying duplicates, by\\ndefault use all of the columns.\\n'},\n",
       "        {'param_name': 'keep',\n",
       "         'param_type': '{‘first’, ‘last’, False}, default ‘first’',\n",
       "         'param_desc': 'Determines which duplicates (if any) to keep.\\n\\n‘first’ : Drop duplicates except for the first occurrence.\\n‘last’ : Drop duplicates except for the last occurrence.\\nFalse : Drop all duplicates.\\n\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to modify the DataFrame rather than creating a new one.\\n'},\n",
       "        {'param_name': 'ignore_index',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True, the resulting axis will be labeled 0, 1, …, n - 1.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.drop_duplicates',\n",
       "       'descriptions': 'Return DataFrame with duplicate rows removed. Considering certain columns is optional. Indexes, including time indexes\\nare ignored.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'subset': {'type': 'column label or sequence of labels, optional',\n",
       "          'description': 'column label or sequence of labels, optional. Only consider certain columns for identifying duplicates, by\\ndefault use all of the columns.\\n'},\n",
       "         'keep': {'type': 'string',\n",
       "          'enum': ['first', ' last', ' False'],\n",
       "          'description': '{‘first’, ‘last’, False}, default ‘first’. Determines which duplicates (if any) to keep.\\n\\n‘first’ : Drop duplicates except for the first occurrence.\\n‘last’ : Drop duplicates except for the last occurrence.\\nFalse : Drop all duplicates.\\n\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to modify the DataFrame rather than creating a new one.\\n'},\n",
       "         'ignore_index': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True, the resulting axis will be labeled 0, 1, …, n - 1.\\n'}},\n",
       "        'required': ['subset=None']}}},\n",
       "     {'func_name': 'DataFrame.equals(other)',\n",
       "      'func_desc': 'Test whether two objects contain the same elements.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.equals.html#pandas.DataFrame.equals',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.equals',\n",
       "       'full_function': 'DataFrame.equals(other)',\n",
       "       'function_text': 'Test whether two objects contain the same elements. This function allows two Series or DataFrames to be compared against\\neach other to see if they have the same shape and elements. NaNs in\\nthe same location are considered equal. The row/column index do not need to have the same type, as long\\nas the values are considered equal. Corresponding columns and\\nindex must be of the same dtype.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series or DataFrame',\n",
       "         'param_desc': 'The other Series or DataFrame to be compared with the first.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.equals',\n",
       "       'descriptions': 'Test whether two objects contain the same elements. This function allows two Series or DataFrames to be compared against\\neach other to see if they have the same shape and elements. NaNs in\\nthe same location are considered equal. The row/column index do not need to have the same type, as long\\nas the values are considered equal. Corresponding columns and\\nindex must be of the same dtype.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series or DataFrame',\n",
       "          'description': 'Series or DataFrame. The other Series or DataFrame to be compared with the first.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.first(offset)',\n",
       "      'func_desc': '(DEPRECATED) Select initial periods of time series data based on a date offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.first.html#pandas.DataFrame.first',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.first',\n",
       "       'full_function': 'DataFrame.first(offset)',\n",
       "       'function_text': 'Select initial periods of time series data based on a date offset. Deprecated since version 2.1: first() is deprecated and will be removed in a future version.\\nPlease create a mask and filter using .loc instead. For a DataFrame with a sorted DatetimeIndex, this function can\\nselect the first few rows based on a date offset.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.idxmax([axis,\\xa0skipna,\\xa0numeric_only])',\n",
       "      'func_desc': 'Return index of first occurrence of maximum over requested axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.idxmax.html#pandas.DataFrame.idxmax',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.idxmax',\n",
       "       'full_function': 'DataFrame.idxmax(axis=0, skipna=True, numeric_only=False)',\n",
       "       'function_text': 'Return index of first occurrence of maximum over requested axis. NA/null values are excluded.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.last(offset)',\n",
       "      'func_desc': '(DEPRECATED) Select final periods of time series data based on a date offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.last.html#pandas.DataFrame.last',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.last',\n",
       "       'full_function': 'DataFrame.last(offset)',\n",
       "       'function_text': 'Select final periods of time series data based on a date offset. Deprecated since version 2.1: last() is deprecated and will be removed in a future version.\\nPlease create a mask and filter using .loc instead. For a DataFrame with a sorted DatetimeIndex, this function\\nselects the last few rows based on a date offset.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.reindex_like(other[,\\xa0method,\\xa0...])',\n",
       "      'func_desc': 'Return an object with matching indices as other object.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reindex_like.html#pandas.DataFrame.reindex_like',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.reindex_like',\n",
       "       'full_function': 'DataFrame.reindex_like(other, method=None, copy=None, limit=None, tolerance=None)',\n",
       "       'function_text': 'Return an object with matching indices as other object. Conform the object to the same index on all axes. Optional\\nfilling logic, placing NaN in locations having no value\\nin the previous index. A new object is produced unless the\\nnew index is equivalent to the current one and copy=False.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Object of the same data type',\n",
       "         'param_desc': 'Its row and column indices are used to define the new indices\\nof this object.\\n'},\n",
       "        {'param_name': 'method',\n",
       "         'param_type': '{None, ‘backfill’/’bfill’, ‘pad’/’ffill’, ‘nearest’}',\n",
       "         'param_desc': 'Method to use for filling holes in reindexed DataFrame.\\nPlease note: this is only applicable to DataFrames/Series with a\\nmonotonically increasing/decreasing index.\\n\\nNone (default): don’t fill gaps\\npad / ffill: propagate last valid observation forward to next\\nvalid\\nbackfill / bfill: use next valid observation to fill gap\\nnearest: use nearest valid observations to fill gap.\\n\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Return a new object, even if the passed indexes are the same.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'},\n",
       "        {'param_name': 'limit',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'Maximum number of consecutive labels to fill for inexact matches.\\n'},\n",
       "        {'param_name': 'tolerance',\n",
       "         'param_type': 'optional',\n",
       "         'param_desc': 'Maximum distance between original and new labels for inexact\\nmatches. The values of the index at the matching locations must\\nsatisfy the equation abs(index[indexer] - target) <= tolerance.\\nTolerance may be a scalar value, which applies the same tolerance\\nto all values, or list-like, which applies variable tolerance per\\nelement. List-like includes list, tuple, array, Series, and must be\\nthe same size as the index and its dtype must exactly match the\\nindex’s type.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.reindex_like',\n",
       "       'descriptions': 'Return an object with matching indices as other object. Conform the object to the same index on all axes. Optional\\nfilling logic, placing NaN in locations having no value\\nin the previous index. A new object is produced unless the\\nnew index is equivalent to the current one and copy=False.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Object of the same data type',\n",
       "          'description': 'Object of the same data type. Its row and column indices are used to define the new indices\\nof this object.\\n'},\n",
       "         'method': {'type': 'string',\n",
       "          'enum': ['None', ' backfill/bfill', ' pad/ffill', ' nearest'],\n",
       "          'description': '{None, ‘backfill’/’bfill’, ‘pad’/’ffill’, ‘nearest’}. Method to use for filling holes in reindexed DataFrame.\\nPlease note: this is only applicable to DataFrames/Series with a\\nmonotonically increasing/decreasing index.\\n\\nNone (default): don’t fill gaps\\npad / ffill: propagate last valid observation forward to next\\nvalid\\nbackfill / bfill: use next valid observation to fill gap\\nnearest: use nearest valid observations to fill gap.\\n\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Return a new object, even if the passed indexes are the same.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'},\n",
       "         'limit': {'type': 'integer',\n",
       "          'description': 'int, default None. Maximum number of consecutive labels to fill for inexact matches.\\n'},\n",
       "         'tolerance': {'type': 'optional',\n",
       "          'description': 'optional. Maximum distance between original and new labels for inexact\\nmatches. The values of the index at the matching locations must\\nsatisfy the equation abs(index[indexer] - target) <= tolerance.\\nTolerance may be a scalar value, which applies the same tolerance\\nto all values, or list-like, which applies variable tolerance per\\nelement. List-like includes list, tuple, array, Series, and must be\\nthe same size as the index and its dtype must exactly match the\\nindex’s type.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.rename_axis([mapper,\\xa0index,\\xa0...])',\n",
       "      'func_desc': 'Set the name of the axis for the index or columns.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename_axis.html#pandas.DataFrame.rename_axis',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.rename_axis',\n",
       "       'full_function': 'DataFrame.rename_axis(mapper=_NoDefault.no_default, *, index=_NoDefault.no_default, columns=_NoDefault.no_default, axis=0, copy=None, inplace=False)',\n",
       "       'function_text': 'Set the name of the axis for the index or columns.',\n",
       "       'parameter_names_desc': [{'param_name': 'mapper',\n",
       "         'param_type': 'scalar, list-like, optional',\n",
       "         'param_desc': 'Value to set the axis name attribute.\\n'},\n",
       "        {'param_name': 'index, columns',\n",
       "         'param_type': 'scalar, list-like, dict-like or function, optional',\n",
       "         'param_desc': 'A scalar, list-like, dict-like or functions transformations to\\napply to that axis’ values.\\nNote that the columns parameter is not allowed if the\\nobject is a Series. This parameter only apply for DataFrame\\ntype objects.\\nUse either mapper and axis to\\nspecify the axis to target with mapper, or index\\nand/or columns.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'The axis to rename. For Series this parameter is unused and defaults to 0.\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default None',\n",
       "         'param_desc': 'Also copy underlying data.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Modifies the object directly, instead of creating a new Series\\nor DataFrame.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.rename_axis',\n",
       "       'descriptions': 'Set the name of the axis for the index or columns.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'mapper': {'type': 'array',\n",
       "          'description': 'scalar, list-like, optional. Value to set the axis name attribute.\\n'},\n",
       "         'index, columns': {'type': 'array',\n",
       "          'description': 'scalar, list-like, dict-like or function, optional. A scalar, list-like, dict-like or functions transformations to\\napply to that axis’ values.\\nNote that the columns parameter is not allowed if the\\nobject is a Series. This parameter only apply for DataFrame\\ntype objects.\\nUse either mapper and axis to\\nspecify the axis to target with mapper, or index\\nand/or columns.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. The axis to rename. For Series this parameter is unused and defaults to 0.\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default None. Also copy underlying data.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Modifies the object directly, instead of creating a new Series\\nor DataFrame.\\n'}},\n",
       "        'required': ['mapper=_NoDefault.no_default']}}},\n",
       "     {'func_name': 'DataFrame.sample([n,\\xa0frac,\\xa0replace,\\xa0...])',\n",
       "      'func_desc': 'Return a random sample of items from an axis of object.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html#pandas.DataFrame.sample',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.sample',\n",
       "       'full_function': 'DataFrame.sample(n=None, frac=None, replace=False, weights=None, random_state=None, axis=None, ignore_index=False)',\n",
       "       'function_text': 'Return a random sample of items from an axis of object. You can use random_state for reproducibility.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Number of items from axis to return. Cannot be used with frac.\\nDefault = 1 if frac = None.\\n'},\n",
       "        {'param_name': 'frac',\n",
       "         'param_type': 'float, optional',\n",
       "         'param_desc': 'Fraction of axis items to return. Cannot be used with n.\\n'},\n",
       "        {'param_name': 'replace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Allow or disallow sampling of the same row more than once.\\n'},\n",
       "        {'param_name': 'weights',\n",
       "         'param_type': 'str or ndarray-like, optional',\n",
       "         'param_desc': 'Default ‘None’ results in equal probability weighting.\\nIf passed a Series, will align with target object on index. Index\\nvalues in weights not found in sampled object will be ignored and\\nindex values in sampled object not in weights will be assigned\\nweights of zero.\\nIf called on a DataFrame, will accept the name of a column\\nwhen axis = 0.\\nUnless weights are a Series, weights must be same length as axis\\nbeing sampled.\\nIf weights do not sum to 1, they will be normalized to sum to 1.\\nMissing values in the weights column will be treated as zero.\\nInfinite values not allowed.\\n'},\n",
       "        {'param_name': 'random_state',\n",
       "         'param_type': 'int, array-like, BitGenerator, np.random.RandomState, np.random.Generator, optional',\n",
       "         'param_desc': 'If int, array-like, or BitGenerator, seed for random number generator.\\nIf np.random.RandomState or np.random.Generator, use as given.\\n\\nChanged in version 1.4.0: np.random.Generator objects now accepted\\n\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’, None}, default None',\n",
       "         'param_desc': 'Axis to sample. Accepts axis number or name. Default is stat axis\\nfor given data type. For Series this parameter is unused and defaults to None.\\n'},\n",
       "        {'param_name': 'ignore_index',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True, the resulting index will be labeled 0, 1, …, n - 1.\\n\\nNew in version 1.3.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.sample',\n",
       "       'descriptions': 'Return a random sample of items from an axis of object. You can use random_state for reproducibility.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, optional. Number of items from axis to return. Cannot be used with frac.\\nDefault = 1 if frac = None.\\n'},\n",
       "         'frac': {'type': 'float',\n",
       "          'description': 'float, optional. Fraction of axis items to return. Cannot be used with n.\\n'},\n",
       "         'replace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Allow or disallow sampling of the same row more than once.\\n'},\n",
       "         'weights': {'type': 'string',\n",
       "          'description': 'str or ndarray-like, optional. Default ‘None’ results in equal probability weighting.\\nIf passed a Series, will align with target object on index. Index\\nvalues in weights not found in sampled object will be ignored and\\nindex values in sampled object not in weights will be assigned\\nweights of zero.\\nIf called on a DataFrame, will accept the name of a column\\nwhen axis = 0.\\nUnless weights are a Series, weights must be same length as axis\\nbeing sampled.\\nIf weights do not sum to 1, they will be normalized to sum to 1.\\nMissing values in the weights column will be treated as zero.\\nInfinite values not allowed.\\n'},\n",
       "         'random_state': {'type': 'integer',\n",
       "          'description': 'int, array-like, BitGenerator, np.random.RandomState, np.random.Generator, optional. If int, array-like, or BitGenerator, seed for random number generator.\\nIf np.random.RandomState or np.random.Generator, use as given.\\n\\nChanged in version 1.4.0: np.random.Generator objects now accepted\\n\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns', ' None'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’, None}, default None. Axis to sample. Accepts axis number or name. Default is stat axis\\nfor given data type. For Series this parameter is unused and defaults to None.\\n'},\n",
       "         'ignore_index': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True, the resulting index will be labeled 0, 1, …, n - 1.\\n\\nNew in version 1.3.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.set_index(keys,\\xa0*[,\\xa0drop,\\xa0append,\\xa0...])',\n",
       "      'func_desc': 'Set the DataFrame index using existing columns.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_index.html#pandas.DataFrame.set_index',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.set_index',\n",
       "       'full_function': 'DataFrame.set_index(keys, *, drop=True, append=False, inplace=False, verify_integrity=False)',\n",
       "       'function_text': 'Set the DataFrame index using existing columns. Set the DataFrame index (row labels) using one or more existing\\ncolumns or arrays (of the correct length). The index can replace the\\nexisting index or expand on it.',\n",
       "       'parameter_names_desc': [{'param_name': 'keys',\n",
       "         'param_type': 'label or array-like or list of labels/arrays',\n",
       "         'param_desc': 'This parameter can be either a single column key, a single array of\\nthe same length as the calling DataFrame, or a list containing an\\narbitrary combination of column keys and arrays. Here, “array”\\nencompasses Series, Index, np.ndarray, and\\ninstances of Iterator.\\n'},\n",
       "        {'param_name': 'drop',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Delete columns to be used as the new index.\\n'},\n",
       "        {'param_name': 'append',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to append columns to existing index.\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to modify the DataFrame rather than creating a new one.\\n'},\n",
       "        {'param_name': 'verify_integrity',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Check the new index for duplicates. Otherwise defer the check until\\nnecessary. Setting to False will improve the performance of this\\nmethod.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.set_index',\n",
       "       'descriptions': 'Set the DataFrame index using existing columns. Set the DataFrame index (row labels) using one or more existing\\ncolumns or arrays (of the correct length). The index can replace the\\nexisting index or expand on it.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'keys': {'type': 'array',\n",
       "          'description': 'label or array-like or list of labels/arrays. This parameter can be either a single column key, a single array of\\nthe same length as the calling DataFrame, or a list containing an\\narbitrary combination of column keys and arrays. Here, “array”\\nencompasses Series, Index, np.ndarray, and\\ninstances of Iterator.\\n'},\n",
       "         'drop': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Delete columns to be used as the new index.\\n'},\n",
       "         'append': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to append columns to existing index.\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to modify the DataFrame rather than creating a new one.\\n'},\n",
       "         'verify_integrity': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Check the new index for duplicates. Otherwise defer the check until\\nnecessary. Setting to False will improve the performance of this\\nmethod.\\n'}},\n",
       "        'required': ['keys']}}},\n",
       "     {'func_name': 'DataFrame.take(indices[,\\xa0axis])',\n",
       "      'func_desc': 'Return the elements in the given positional indices along an axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.take.html#pandas.DataFrame.take',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.take',\n",
       "       'full_function': 'DataFrame.take(indices, axis=0, **kwargs)',\n",
       "       'function_text': 'Return the elements in the given positional indices along an axis. This means that we are not indexing according to actual values in\\nthe index attribute of the object. We are indexing according to the\\nactual position of the element in the object.',\n",
       "       'parameter_names_desc': [{'param_name': 'indices',\n",
       "         'param_type': 'array-like',\n",
       "         'param_desc': 'An array of ints indicating which positions to take.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’, None}, default 0',\n",
       "         'param_desc': 'The axis on which to select elements. 0 means that we are\\nselecting rows, 1 means that we are selecting columns.\\nFor Series this parameter is unused and defaults to 0.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.take',\n",
       "       'descriptions': 'Return the elements in the given positional indices along an axis. This means that we are not indexing according to actual values in\\nthe index attribute of the object. We are indexing according to the\\nactual position of the element in the object.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'indices': {'type': 'array',\n",
       "          'description': 'array-like. An array of ints indicating which positions to take.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns', ' None'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’, None}, default 0. The axis on which to select elements. 0 means that we are\\nselecting rows, 1 means that we are selecting columns.\\nFor Series this parameter is unused and defaults to 0.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.add_suffix(suffix[,\\xa0axis])',\n",
       "      'func_desc': 'Suffix labels with string suffix.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add_suffix.html#pandas.DataFrame.add_suffix',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.add_suffix',\n",
       "       'full_function': 'DataFrame.add_suffix(suffix, axis=None)',\n",
       "       'function_text': 'Suffix labels with string suffix. For Series, the row labels are suffixed.\\nFor DataFrame, the column labels are suffixed.',\n",
       "       'parameter_names_desc': [{'param_name': 'suffix',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'The string to add after each label.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’, None}, default None',\n",
       "         'param_desc': 'Axis to add suffix on\\n\\nNew in version 2.0.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.add_suffix',\n",
       "       'descriptions': 'Suffix labels with string suffix. For Series, the row labels are suffixed.\\nFor DataFrame, the column labels are suffixed.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'suffix': {'type': 'string',\n",
       "          'description': 'str. The string to add after each label.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns', ' None'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’, None}, default None. Axis to add suffix on\\n\\nNew in version 2.0.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.at_time(time[,\\xa0asof,\\xa0axis])',\n",
       "      'func_desc': 'Select values at particular time of day (e.g., 9:30AM).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.at_time.html#pandas.DataFrame.at_time',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.at_time',\n",
       "       'full_function': 'DataFrame.at_time(time, asof=False, axis=None)',\n",
       "       'function_text': 'Select values at particular time of day (e.g., 9:30AM).',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.drop([labels,\\xa0axis,\\xa0index,\\xa0...])',\n",
       "      'func_desc': 'Drop specified labels from rows or columns.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html#pandas.DataFrame.drop',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.drop',\n",
       "       'full_function': \"DataFrame.drop(labels=None, *, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')\",\n",
       "       'function_text': 'Drop specified labels from rows or columns. Remove rows or columns by specifying label names and corresponding\\naxis, or by directly specifying index or column names. When using a\\nmulti-index, labels on different levels can be removed by specifying\\nthe level. See the user guide\\nfor more information about the now unused levels.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.duplicated([subset,\\xa0keep])',\n",
       "      'func_desc': 'Return boolean Series denoting duplicate rows.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html#pandas.DataFrame.duplicated',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.duplicated',\n",
       "       'full_function': \"DataFrame.duplicated(subset=None, keep='first')\",\n",
       "       'function_text': 'Return boolean Series denoting duplicate rows. Considering certain columns is optional.',\n",
       "       'parameter_names_desc': [{'param_name': 'subset',\n",
       "         'param_type': 'column label or sequence of labels, optional',\n",
       "         'param_desc': 'Only consider certain columns for identifying duplicates, by\\ndefault use all of the columns.\\n'},\n",
       "        {'param_name': 'keep',\n",
       "         'param_type': '{‘first’, ‘last’, False}, default ‘first’',\n",
       "         'param_desc': 'Determines which duplicates (if any) to mark.\\n\\nfirst : Mark duplicates as True except for the first occurrence.\\nlast : Mark duplicates as True except for the last occurrence.\\nFalse : Mark all duplicates as True.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.duplicated',\n",
       "       'descriptions': 'Return boolean Series denoting duplicate rows. Considering certain columns is optional.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'subset': {'type': 'column label or sequence of labels, optional',\n",
       "          'description': 'column label or sequence of labels, optional. Only consider certain columns for identifying duplicates, by\\ndefault use all of the columns.\\n'},\n",
       "         'keep': {'type': 'string',\n",
       "          'enum': ['first', ' last', ' False'],\n",
       "          'description': '{‘first’, ‘last’, False}, default ‘first’. Determines which duplicates (if any) to mark.\\n\\nfirst : Mark duplicates as True except for the first occurrence.\\nlast : Mark duplicates as True except for the last occurrence.\\nFalse : Mark all duplicates as True.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.filter([items,\\xa0like,\\xa0regex,\\xa0axis])',\n",
       "      'func_desc': 'Subset the dataframe rows or columns according to the specified index labels.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.filter.html#pandas.DataFrame.filter',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.filter',\n",
       "       'full_function': 'DataFrame.filter(items=None, like=None, regex=None, axis=None)',\n",
       "       'function_text': 'Subset the dataframe rows or columns according to the specified index labels. Note that this routine does not filter a dataframe on its\\ncontents. The filter is applied to the labels of the index.',\n",
       "       'parameter_names_desc': [{'param_name': 'items',\n",
       "         'param_type': 'list-like',\n",
       "         'param_desc': 'Keep labels from axis which are in items.\\n'},\n",
       "        {'param_name': 'like',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'Keep labels from axis for which “like in label == True”.\\n'},\n",
       "        {'param_name': 'regex',\n",
       "         'param_type': 'str (regular expression)',\n",
       "         'param_desc': 'Keep labels from axis for which re.search(regex, label) == True.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’, None}, default None',\n",
       "         'param_desc': 'The axis to filter on, expressed either as an index (int)\\nor axis name (str). By default this is the info axis, ‘columns’ for\\nDataFrame. For Series this parameter is unused and defaults to None.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.filter',\n",
       "       'descriptions': 'Subset the dataframe rows or columns according to the specified index labels. Note that this routine does not filter a dataframe on its\\ncontents. The filter is applied to the labels of the index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'items': {'type': 'array',\n",
       "          'description': 'list-like. Keep labels from axis which are in items.\\n'},\n",
       "         'like': {'type': 'string',\n",
       "          'description': 'str. Keep labels from axis for which “like in label == True”.\\n'},\n",
       "         'regex': {'type': 'string',\n",
       "          'description': 'str (regular expression). Keep labels from axis for which re.search(regex, label) == True.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns', ' None'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’, None}, default None. The axis to filter on, expressed either as an index (int)\\nor axis name (str). By default this is the info axis, ‘columns’ for\\nDataFrame. For Series this parameter is unused and defaults to None.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.head([n])',\n",
       "      'func_desc': 'Return the first n rows.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html#pandas.DataFrame.head',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.head',\n",
       "       'full_function': 'DataFrame.head(n=5)',\n",
       "       'function_text': 'Return the first n rows. This function returns the first n rows for the object based\\non position. It is useful for quickly testing if your object\\nhas the right type of data in it. For negative values of n, this function returns all rows except\\nthe last |n| rows, equivalent to df[:n]. If n is larger than the number of rows, this function returns all rows.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 5',\n",
       "         'param_desc': 'Number of rows to select.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.head',\n",
       "       'descriptions': 'Return the first n rows. This function returns the first n rows for the object based\\non position. It is useful for quickly testing if your object\\nhas the right type of data in it. For negative values of n, this function returns all rows except\\nthe last |n| rows, equivalent to df[:n]. If n is larger than the number of rows, this function returns all rows.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 5. Number of rows to select.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.idxmin([axis,\\xa0skipna,\\xa0numeric_only])',\n",
       "      'func_desc': 'Return index of first occurrence of minimum over requested axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.idxmin.html#pandas.DataFrame.idxmin',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.idxmin',\n",
       "       'full_function': 'DataFrame.idxmin(axis=0, skipna=True, numeric_only=False)',\n",
       "       'function_text': 'Return index of first occurrence of minimum over requested axis. NA/null values are excluded.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.reindex([labels,\\xa0index,\\xa0columns,\\xa0...])',\n",
       "      'func_desc': 'Conform DataFrame to new index with optional filling logic.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reindex.html#pandas.DataFrame.reindex',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.reindex',\n",
       "       'full_function': 'DataFrame.reindex(labels=None, *, index=None, columns=None, axis=None, method=None, copy=None, level=None, fill_value=nan, limit=None, tolerance=None)',\n",
       "       'function_text': 'Conform DataFrame to new index with optional filling logic. Places NA/NaN in locations having no value in the previous index. A new object\\nis produced unless the new index is equivalent to the current one and\\ncopy=False.',\n",
       "       'parameter_names_desc': [{'param_name': 'labels',\n",
       "         'param_type': 'array-like, optional',\n",
       "         'param_desc': 'New labels / index to conform the axis specified by ‘axis’ to.\\n'},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'array-like, optional',\n",
       "         'param_desc': 'New labels for the index. Preferably an Index object to avoid\\nduplicating data.\\n'},\n",
       "        {'param_name': 'columns',\n",
       "         'param_type': 'array-like, optional',\n",
       "         'param_desc': 'New labels for the columns. Preferably an Index object to avoid\\nduplicating data.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': 'int or str, optional',\n",
       "         'param_desc': 'Axis to target. Can be either the axis name (‘index’, ‘columns’)\\nor number (0, 1).\\n'},\n",
       "        {'param_name': 'method',\n",
       "         'param_type': '{None, ‘backfill’/’bfill’, ‘pad’/’ffill’, ‘nearest’}',\n",
       "         'param_desc': 'Method to use for filling holes in reindexed DataFrame.\\nPlease note: this is only applicable to DataFrames/Series with a\\nmonotonically increasing/decreasing index.\\n\\nNone (default): don’t fill gaps\\npad / ffill: Propagate last valid observation forward to next\\nvalid.\\nbackfill / bfill: Use next valid observation to fill gap.\\nnearest: Use nearest valid observations to fill gap.\\n\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Return a new object, even if the passed indexes are the same.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or name',\n",
       "         'param_desc': 'Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'scalar, default np.nan',\n",
       "         'param_desc': 'Value to use for missing values. Defaults to NaN, but can be any\\n“compatible” value.\\n'},\n",
       "        {'param_name': 'limit',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'Maximum number of consecutive elements to forward or backward fill.\\n'},\n",
       "        {'param_name': 'tolerance',\n",
       "         'param_type': 'optional',\n",
       "         'param_desc': 'Maximum distance between original and new labels for inexact\\nmatches. The values of the index at the matching locations most\\nsatisfy the equation abs(index[indexer] - target) <= tolerance.\\nTolerance may be a scalar value, which applies the same tolerance\\nto all values, or list-like, which applies variable tolerance per\\nelement. List-like includes list, tuple, array, Series, and must be\\nthe same size as the index and its dtype must exactly match the\\nindex’s type.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.reindex',\n",
       "       'descriptions': 'Conform DataFrame to new index with optional filling logic. Places NA/NaN in locations having no value in the previous index. A new object\\nis produced unless the new index is equivalent to the current one and\\ncopy=False.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'labels': {'type': 'array',\n",
       "          'description': 'array-like, optional. New labels / index to conform the axis specified by ‘axis’ to.\\n'},\n",
       "         'index': {'type': 'array',\n",
       "          'description': 'array-like, optional. New labels for the index. Preferably an Index object to avoid\\nduplicating data.\\n'},\n",
       "         'columns': {'type': 'array',\n",
       "          'description': 'array-like, optional. New labels for the columns. Preferably an Index object to avoid\\nduplicating data.\\n'},\n",
       "         'axis': {'type': 'integer',\n",
       "          'description': 'int or str, optional. Axis to target. Can be either the axis name (‘index’, ‘columns’)\\nor number (0, 1).\\n'},\n",
       "         'method': {'type': 'string',\n",
       "          'enum': ['None', ' backfill/bfill', ' pad/ffill', ' nearest'],\n",
       "          'description': '{None, ‘backfill’/’bfill’, ‘pad’/’ffill’, ‘nearest’}. Method to use for filling holes in reindexed DataFrame.\\nPlease note: this is only applicable to DataFrames/Series with a\\nmonotonically increasing/decreasing index.\\n\\nNone (default): don’t fill gaps\\npad / ffill: Propagate last valid observation forward to next\\nvalid.\\nbackfill / bfill: Use next valid observation to fill gap.\\nnearest: Use nearest valid observations to fill gap.\\n\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Return a new object, even if the passed indexes are the same.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or name. Broadcast across a level, matching Index values on the\\npassed MultiIndex level.\\n'},\n",
       "         'fill_value': {'type': 'scalar, default np.nan',\n",
       "          'description': 'scalar, default np.nan. Value to use for missing values. Defaults to NaN, but can be any\\n“compatible” value.\\n'},\n",
       "         'limit': {'type': 'integer',\n",
       "          'description': 'int, default None. Maximum number of consecutive elements to forward or backward fill.\\n'},\n",
       "         'tolerance': {'type': 'optional',\n",
       "          'description': 'optional. Maximum distance between original and new labels for inexact\\nmatches. The values of the index at the matching locations most\\nsatisfy the equation abs(index[indexer] - target) <= tolerance.\\nTolerance may be a scalar value, which applies the same tolerance\\nto all values, or list-like, which applies variable tolerance per\\nelement. List-like includes list, tuple, array, Series, and must be\\nthe same size as the index and its dtype must exactly match the\\nindex’s type.\\n'}},\n",
       "        'required': ['labels=None']}}},\n",
       "     {'func_name': 'DataFrame.rename([mapper,\\xa0index,\\xa0columns,\\xa0...])',\n",
       "      'func_desc': 'Rename columns or index labels.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html#pandas.DataFrame.rename',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.rename',\n",
       "       'full_function': \"DataFrame.rename(mapper=None, *, index=None, columns=None, axis=None, copy=None, inplace=False, level=None, errors='ignore')\",\n",
       "       'function_text': 'Rename columns or index labels. Function / dict values must be unique (1-to-1). Labels not contained in\\na dict / Series will be left as-is. Extra labels listed don’t throw an\\nerror. See the user guide for more.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.reset_index([level,\\xa0drop,\\xa0...])',\n",
       "      'func_desc': 'Reset the index, or a level of it.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html#pandas.DataFrame.reset_index',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.reset_index',\n",
       "       'full_function': \"DataFrame.reset_index(level=None, *, drop=False, inplace=False, col_level=0, col_fill='', allow_duplicates=_NoDefault.no_default, names=None)\",\n",
       "       'function_text': 'Reset the index, or a level of it. Reset the index of the DataFrame, and use the default one instead.\\nIf the DataFrame has a MultiIndex, this method can remove one or more\\nlevels.',\n",
       "       'parameter_names_desc': [{'param_name': 'level',\n",
       "         'param_type': 'int, str, tuple, or list, default None',\n",
       "         'param_desc': 'Only remove the given levels from the index. Removes all levels by\\ndefault.\\n'},\n",
       "        {'param_name': 'drop',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Do not try to insert index into dataframe columns. This resets\\nthe index to the default integer index.\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to modify the DataFrame rather than creating a new one.\\n'},\n",
       "        {'param_name': 'col_level',\n",
       "         'param_type': 'int or str, default 0',\n",
       "         'param_desc': 'If the columns have multiple levels, determines which level the\\nlabels are inserted into. By default it is inserted into the first\\nlevel.\\n'},\n",
       "        {'param_name': 'col_fill',\n",
       "         'param_type': 'object, default ‘’',\n",
       "         'param_desc': 'If the columns have multiple levels, determines how the other\\nlevels are named. If None then the index name is repeated.\\n'},\n",
       "        {'param_name': 'allow_duplicates',\n",
       "         'param_type': 'bool, optional, default lib.no_default',\n",
       "         'param_desc': 'Allow duplicate column labels to be created.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "        {'param_name': 'names',\n",
       "         'param_type': 'int, str or 1-dimensional list, default None',\n",
       "         'param_desc': 'Using the given string, rename the DataFrame column which contains the\\nindex data. If the DataFrame has a MultiIndex, this has to be a list or\\ntuple with length equal to the number of levels.\\n\\nNew in version 1.5.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.reset_index',\n",
       "       'descriptions': 'Reset the index, or a level of it. Reset the index of the DataFrame, and use the default one instead.\\nIf the DataFrame has a MultiIndex, this method can remove one or more\\nlevels.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'level': {'type': 'integer',\n",
       "          'description': 'int, str, tuple, or list, default None. Only remove the given levels from the index. Removes all levels by\\ndefault.\\n'},\n",
       "         'drop': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Do not try to insert index into dataframe columns. This resets\\nthe index to the default integer index.\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to modify the DataFrame rather than creating a new one.\\n'},\n",
       "         'col_level': {'type': 'integer',\n",
       "          'description': 'int or str, default 0. If the columns have multiple levels, determines which level the\\nlabels are inserted into. By default it is inserted into the first\\nlevel.\\n'},\n",
       "         'col_fill': {'type': 'object',\n",
       "          'description': 'object, default ‘’. If the columns have multiple levels, determines how the other\\nlevels are named. If None then the index name is repeated.\\n'},\n",
       "         'allow_duplicates': {'type': 'boolean',\n",
       "          'description': 'bool, optional, default lib.no_default. Allow duplicate column labels to be created.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "         'names': {'type': 'integer',\n",
       "          'description': 'int, str or 1-dimensional list, default None. Using the given string, rename the DataFrame column which contains the\\nindex data. If the DataFrame has a MultiIndex, this has to be a list or\\ntuple with length equal to the number of levels.\\n\\nNew in version 1.5.0.\\n\\n'}},\n",
       "        'required': ['level=None']}}},\n",
       "     {'func_name': 'DataFrame.set_axis(labels,\\xa0*[,\\xa0axis,\\xa0copy])',\n",
       "      'func_desc': 'Assign desired index to given axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_axis.html#pandas.DataFrame.set_axis',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.set_axis',\n",
       "       'full_function': 'DataFrame.set_axis(labels, *, axis=0, copy=None)',\n",
       "       'function_text': 'Assign desired index to given axis. Indexes for column or row labels can be changed by assigning\\na list-like or Index.',\n",
       "       'parameter_names_desc': [{'param_name': 'labels',\n",
       "         'param_type': 'list-like, Index',\n",
       "         'param_desc': 'The values for the new index.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'The axis to update. The value 0 identifies the rows. For Series\\nthis parameter is unused and defaults to 0.\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to make a copy of the underlying data.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.set_axis',\n",
       "       'descriptions': 'Assign desired index to given axis. Indexes for column or row labels can be changed by assigning\\na list-like or Index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'labels': {'type': 'array',\n",
       "          'description': 'list-like, Index. The values for the new index.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. The axis to update. The value 0 identifies the rows. For Series\\nthis parameter is unused and defaults to 0.\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to make a copy of the underlying data.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'}},\n",
       "        'required': ['labels']}}},\n",
       "     {'func_name': 'DataFrame.tail([n])',\n",
       "      'func_desc': 'Return the last n rows.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tail.html#pandas.DataFrame.tail',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.tail',\n",
       "       'full_function': 'DataFrame.tail(n=5)',\n",
       "       'function_text': 'Return the last n rows. This function returns last n rows from the object based on\\nposition. It is useful for quickly verifying data, for example,\\nafter sorting or appending rows. For negative values of n, this function returns all rows except\\nthe first |n| rows, equivalent to df[|n|:]. If n is larger than the number of rows, this function returns all rows.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 5',\n",
       "         'param_desc': 'Number of rows to select.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.tail',\n",
       "       'descriptions': 'Return the last n rows. This function returns last n rows from the object based on\\nposition. It is useful for quickly verifying data, for example,\\nafter sorting or appending rows. For negative values of n, this function returns all rows except\\nthe first |n| rows, equivalent to df[|n|:]. If n is larger than the number of rows, this function returns all rows.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 5. Number of rows to select.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.truncate([before,\\xa0after,\\xa0axis,\\xa0copy])',\n",
       "      'func_desc': 'Truncate a Series or DataFrame before and after some index value.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.truncate.html#pandas.DataFrame.truncate',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.truncate',\n",
       "       'full_function': 'DataFrame.truncate(before=None, after=None, axis=None, copy=None)',\n",
       "       'function_text': 'Truncate a Series or DataFrame before and after some index value. This is a useful shorthand for boolean indexing based on index\\nvalues above or below certain thresholds.',\n",
       "       'parameter_names_desc': [{'param_name': 'before',\n",
       "         'param_type': 'date, str, int',\n",
       "         'param_desc': 'Truncate all rows before this index value.\\n'},\n",
       "        {'param_name': 'after',\n",
       "         'param_type': 'date, str, int',\n",
       "         'param_desc': 'Truncate all rows after this index value.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, optional',\n",
       "         'param_desc': 'Axis to truncate. Truncates the index (rows) by default.\\nFor Series this parameter is unused and defaults to 0.\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default is True,',\n",
       "         'param_desc': 'Return a copy of the truncated section.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.truncate',\n",
       "       'descriptions': 'Truncate a Series or DataFrame before and after some index value. This is a useful shorthand for boolean indexing based on index\\nvalues above or below certain thresholds.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'before': {'type': 'integer',\n",
       "          'description': 'date, str, int. Truncate all rows before this index value.\\n'},\n",
       "         'after': {'type': 'integer',\n",
       "          'description': 'date, str, int. Truncate all rows after this index value.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, optional. Axis to truncate. Truncates the index (rows) by default.\\nFor Series this parameter is unused and defaults to 0.\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default is True,. Return a copy of the truncated section.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Missing data handling': [{'func_name': 'DataFrame.backfill(*[,\\xa0axis,\\xa0inplace,\\xa0...])',\n",
       "      'func_desc': '(DEPRECATED) Fill NA/NaN values by using the next valid observation to fill the gap.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.backfill.html#pandas.DataFrame.backfill',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.backfill',\n",
       "       'full_function': 'DataFrame.backfill(*, axis=None, inplace=False, limit=None, downcast=_NoDefault.no_default)',\n",
       "       'function_text': 'Fill NA/NaN values by using the next valid observation to fill the gap. Deprecated since version 2.0: Series/DataFrame.backfill is deprecated. Use Series/DataFrame.bfill instead.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.dropna(*[,\\xa0axis,\\xa0how,\\xa0thresh,\\xa0...])',\n",
       "      'func_desc': 'Remove missing values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html#pandas.DataFrame.dropna',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.dropna',\n",
       "       'full_function': 'DataFrame.dropna(*, axis=0, how=_NoDefault.no_default, thresh=_NoDefault.no_default, subset=None, inplace=False, ignore_index=False)',\n",
       "       'function_text': 'Remove missing values. See the User Guide for more on which values are\\nconsidered missing, and how to work with missing data.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'Determine if rows or columns which contain missing values are\\nremoved.\\n\\n0, or ‘index’ : Drop rows which contain missing values.\\n1, or ‘columns’ : Drop columns which contain missing value.\\n\\nOnly a single axis is allowed.\\n'},\n",
       "        {'param_name': 'how',\n",
       "         'param_type': '{‘any’, ‘all’}, default ‘any’',\n",
       "         'param_desc': 'Determine if row or column is removed from DataFrame, when we have\\nat least one NA or all NA.\\n\\n‘any’ : If any NA values are present, drop that row or column.\\n‘all’ : If all values are NA, drop that row or column.\\n\\n'},\n",
       "        {'param_name': 'thresh',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Require that many non-NA values. Cannot be combined with how.\\n'},\n",
       "        {'param_name': 'subset',\n",
       "         'param_type': 'column label or sequence of labels, optional',\n",
       "         'param_desc': 'Labels along other axis to consider, e.g. if you are dropping rows\\nthese would be a list of columns to include.\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to modify the DataFrame rather than creating a new one.\\n'},\n",
       "        {'param_name': 'ignore_index',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True, the resulting axis will be labeled 0, 1, …, n - 1.\\n\\nNew in version 2.0.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.dropna',\n",
       "       'descriptions': 'Remove missing values. See the User Guide for more on which values are\\nconsidered missing, and how to work with missing data.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. Determine if rows or columns which contain missing values are\\nremoved.\\n\\n0, or ‘index’ : Drop rows which contain missing values.\\n1, or ‘columns’ : Drop columns which contain missing value.\\n\\nOnly a single axis is allowed.\\n'},\n",
       "         'how': {'type': 'string',\n",
       "          'enum': ['any', ' all'],\n",
       "          'description': '{‘any’, ‘all’}, default ‘any’. Determine if row or column is removed from DataFrame, when we have\\nat least one NA or all NA.\\n\\n‘any’ : If any NA values are present, drop that row or column.\\n‘all’ : If all values are NA, drop that row or column.\\n\\n'},\n",
       "         'thresh': {'type': 'integer',\n",
       "          'description': 'int, optional. Require that many non-NA values. Cannot be combined with how.\\n'},\n",
       "         'subset': {'type': 'column label or sequence of labels, optional',\n",
       "          'description': 'column label or sequence of labels, optional. Labels along other axis to consider, e.g. if you are dropping rows\\nthese would be a list of columns to include.\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to modify the DataFrame rather than creating a new one.\\n'},\n",
       "         'ignore_index': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True, the resulting axis will be labeled 0, 1, …, n - 1.\\n\\nNew in version 2.0.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.fillna([value,\\xa0method,\\xa0axis,\\xa0...])',\n",
       "      'func_desc': 'Fill NA/NaN values using the specified method.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.fillna',\n",
       "       'full_function': 'DataFrame.fillna(value=None, *, method=None, axis=None, inplace=False, limit=None, downcast=_NoDefault.no_default)',\n",
       "       'function_text': 'Fill NA/NaN values using the specified method.',\n",
       "       'parameter_names_desc': [{'param_name': 'value',\n",
       "         'param_type': 'scalar, dict, Series, or DataFrame',\n",
       "         'param_desc': 'Value to use to fill holes (e.g. 0), alternately a\\ndict/Series/DataFrame of values specifying which value to use for\\neach index (for a Series) or column (for a DataFrame). Values not\\nin the dict/Series/DataFrame will not be filled. This value cannot\\nbe a list.\\n'},\n",
       "        {'param_name': 'method',\n",
       "         'param_type': '{‘backfill’, ‘bfill’, ‘ffill’, None}, default None',\n",
       "         'param_desc': 'Method to use for filling holes in reindexed Series:\\n\\nffill: propagate last valid observation forward to next valid.\\nbackfill / bfill: use next valid observation to fill gap.\\n\\n\\nDeprecated since version 2.1.0: Use ffill or bfill instead.\\n\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame',\n",
       "         'param_desc': 'Axis along which to fill missing values. For Series\\nthis parameter is unused and defaults to 0.\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True, fill in-place. Note: this will modify any\\nother views on this object (e.g., a no-copy slice for a column in a\\nDataFrame).\\n'},\n",
       "        {'param_name': 'limit',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'If method is specified, this is the maximum number of consecutive\\nNaN values to forward/backward fill. In other words, if there is\\na gap with more than this number of consecutive NaNs, it will only\\nbe partially filled. If method is not specified, this is the\\nmaximum number of entries along the entire axis where NaNs will be\\nfilled. Must be greater than 0 if not None.\\n'},\n",
       "        {'param_name': 'downcast',\n",
       "         'param_type': 'dict, default is None',\n",
       "         'param_desc': 'A dict of item->dtype of what to downcast if possible,\\nor the string ‘infer’ which will try to downcast to an appropriate\\nequal type (e.g. float64 to int64 if possible).\\n\\nDeprecated since version 2.2.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.fillna',\n",
       "       'descriptions': 'Fill NA/NaN values using the specified method.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'value': {'type': 'scalar, dict, Series, or DataFrame',\n",
       "          'description': 'scalar, dict, Series, or DataFrame. Value to use to fill holes (e.g. 0), alternately a\\ndict/Series/DataFrame of values specifying which value to use for\\neach index (for a Series) or column (for a DataFrame). Values not\\nin the dict/Series/DataFrame will not be filled. This value cannot\\nbe a list.\\n'},\n",
       "         'method': {'type': 'string',\n",
       "          'enum': ['backfill', ' bfill', ' ffill', ' None'],\n",
       "          'description': '{‘backfill’, ‘bfill’, ‘ffill’, None}, default None. Method to use for filling holes in reindexed Series:\\n\\nffill: propagate last valid observation forward to next valid.\\nbackfill / bfill: use next valid observation to fill gap.\\n\\n\\nDeprecated since version 2.1.0: Use ffill or bfill instead.\\n\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame. Axis along which to fill missing values. For Series\\nthis parameter is unused and defaults to 0.\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True, fill in-place. Note: this will modify any\\nother views on this object (e.g., a no-copy slice for a column in a\\nDataFrame).\\n'},\n",
       "         'limit': {'type': 'integer',\n",
       "          'description': 'int, default None. If method is specified, this is the maximum number of consecutive\\nNaN values to forward/backward fill. In other words, if there is\\na gap with more than this number of consecutive NaNs, it will only\\nbe partially filled. If method is not specified, this is the\\nmaximum number of entries along the entire axis where NaNs will be\\nfilled. Must be greater than 0 if not None.\\n'},\n",
       "         'downcast': {'type': 'dict, default is None',\n",
       "          'description': 'dict, default is None. A dict of item->dtype of what to downcast if possible,\\nor the string ‘infer’ which will try to downcast to an appropriate\\nequal type (e.g. float64 to int64 if possible).\\n\\nDeprecated since version 2.2.0.\\n\\n'}},\n",
       "        'required': ['value=None']}}},\n",
       "     {'func_name': 'DataFrame.isna()',\n",
       "      'func_desc': 'Detect missing values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html#pandas.DataFrame.isna',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.isna',\n",
       "       'full_function': 'DataFrame.isna()',\n",
       "       'function_text': \"Detect missing values. Return a boolean same-sized object indicating if the values are NA.\\nNA values, such as None or numpy.NaN, gets mapped to True\\nvalues.\\nEverything else gets mapped to False values. Characters such as empty\\nstrings '' or numpy.inf are not considered NA values\\n(unless you set pandas.options.mode.use_inf_as_na = True).\",\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.notna()',\n",
       "      'func_desc': 'Detect existing (non-missing) values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.notna.html#pandas.DataFrame.notna',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.notna',\n",
       "       'full_function': 'DataFrame.notna()',\n",
       "       'function_text': \"Detect existing (non-missing) values. Return a boolean same-sized object indicating if the values are not NA.\\nNon-missing values get mapped to True. Characters such as empty\\nstrings '' or numpy.inf are not considered NA values\\n(unless you set pandas.options.mode.use_inf_as_na = True).\\nNA values, such as None or numpy.NaN, get mapped to False\\nvalues.\",\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.pad(*[,\\xa0axis,\\xa0inplace,\\xa0limit,\\xa0...])',\n",
       "      'func_desc': '(DEPRECATED) Fill NA/NaN values by propagating the last valid observation to next valid.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pad.html#pandas.DataFrame.pad',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.pad',\n",
       "       'full_function': 'DataFrame.pad(*, axis=None, inplace=False, limit=None, downcast=_NoDefault.no_default)',\n",
       "       'function_text': 'Fill NA/NaN values by propagating the last valid observation to next valid. Deprecated since version 2.0: Series/DataFrame.pad is deprecated. Use Series/DataFrame.ffill instead.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.bfill(*[,\\xa0axis,\\xa0inplace,\\xa0limit,\\xa0...])',\n",
       "      'func_desc': 'Fill NA/NaN values by using the next valid observation to fill the gap.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.bfill.html#pandas.DataFrame.bfill',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.bfill',\n",
       "       'full_function': 'DataFrame.bfill(*, axis=None, inplace=False, limit=None, limit_area=None, downcast=_NoDefault.no_default)',\n",
       "       'function_text': 'Fill NA/NaN values by using the next valid observation to fill the gap.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame',\n",
       "         'param_desc': 'Axis along which to fill missing values. For Series\\nthis parameter is unused and defaults to 0.\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True, fill in-place. Note: this will modify any\\nother views on this object (e.g., a no-copy slice for a column in a\\nDataFrame).\\n'},\n",
       "        {'param_name': 'limit',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'If method is specified, this is the maximum number of consecutive\\nNaN values to forward/backward fill. In other words, if there is\\na gap with more than this number of consecutive NaNs, it will only\\nbe partially filled. If method is not specified, this is the\\nmaximum number of entries along the entire axis where NaNs will be\\nfilled. Must be greater than 0 if not None.\\n'},\n",
       "        {'param_name': 'limit_area',\n",
       "         'param_type': '{None, ‘inside’, ‘outside’}, default None',\n",
       "         'param_desc': 'If limit is specified, consecutive NaNs will be filled with this\\nrestriction.\\n\\nNone: No fill restriction.\\n‘inside’: Only fill NaNs surrounded by valid values\\n(interpolate).\\n‘outside’: Only fill NaNs outside valid values (extrapolate).\\n\\n\\nNew in version 2.2.0.\\n\\n'},\n",
       "        {'param_name': 'downcast',\n",
       "         'param_type': 'dict, default is None',\n",
       "         'param_desc': 'A dict of item->dtype of what to downcast if possible,\\nor the string ‘infer’ which will try to downcast to an appropriate\\nequal type (e.g. float64 to int64 if possible).\\n\\nDeprecated since version 2.2.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.bfill',\n",
       "       'descriptions': 'Fill NA/NaN values by using the next valid observation to fill the gap.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame. Axis along which to fill missing values. For Series\\nthis parameter is unused and defaults to 0.\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True, fill in-place. Note: this will modify any\\nother views on this object (e.g., a no-copy slice for a column in a\\nDataFrame).\\n'},\n",
       "         'limit': {'type': 'integer',\n",
       "          'description': 'int, default None. If method is specified, this is the maximum number of consecutive\\nNaN values to forward/backward fill. In other words, if there is\\na gap with more than this number of consecutive NaNs, it will only\\nbe partially filled. If method is not specified, this is the\\nmaximum number of entries along the entire axis where NaNs will be\\nfilled. Must be greater than 0 if not None.\\n'},\n",
       "         'limit_area': {'type': 'string',\n",
       "          'enum': ['None', ' inside', ' outside'],\n",
       "          'description': '{None, ‘inside’, ‘outside’}, default None. If limit is specified, consecutive NaNs will be filled with this\\nrestriction.\\n\\nNone: No fill restriction.\\n‘inside’: Only fill NaNs surrounded by valid values\\n(interpolate).\\n‘outside’: Only fill NaNs outside valid values (extrapolate).\\n\\n\\nNew in version 2.2.0.\\n\\n'},\n",
       "         'downcast': {'type': 'dict, default is None',\n",
       "          'description': 'dict, default is None. A dict of item->dtype of what to downcast if possible,\\nor the string ‘infer’ which will try to downcast to an appropriate\\nequal type (e.g. float64 to int64 if possible).\\n\\nDeprecated since version 2.2.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.ffill(*[,\\xa0axis,\\xa0inplace,\\xa0limit,\\xa0...])',\n",
       "      'func_desc': 'Fill NA/NaN values by propagating the last valid observation to next valid.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ffill.html#pandas.DataFrame.ffill',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.ffill',\n",
       "       'full_function': 'DataFrame.ffill(*, axis=None, inplace=False, limit=None, limit_area=None, downcast=_NoDefault.no_default)',\n",
       "       'function_text': 'Fill NA/NaN values by propagating the last valid observation to next valid.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame',\n",
       "         'param_desc': 'Axis along which to fill missing values. For Series\\nthis parameter is unused and defaults to 0.\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True, fill in-place. Note: this will modify any\\nother views on this object (e.g., a no-copy slice for a column in a\\nDataFrame).\\n'},\n",
       "        {'param_name': 'limit',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'If method is specified, this is the maximum number of consecutive\\nNaN values to forward/backward fill. In other words, if there is\\na gap with more than this number of consecutive NaNs, it will only\\nbe partially filled. If method is not specified, this is the\\nmaximum number of entries along the entire axis where NaNs will be\\nfilled. Must be greater than 0 if not None.\\n'},\n",
       "        {'param_name': 'limit_area',\n",
       "         'param_type': '{None, ‘inside’, ‘outside’}, default None',\n",
       "         'param_desc': 'If limit is specified, consecutive NaNs will be filled with this\\nrestriction.\\n\\nNone: No fill restriction.\\n‘inside’: Only fill NaNs surrounded by valid values\\n(interpolate).\\n‘outside’: Only fill NaNs outside valid values (extrapolate).\\n\\n\\nNew in version 2.2.0.\\n\\n'},\n",
       "        {'param_name': 'downcast',\n",
       "         'param_type': 'dict, default is None',\n",
       "         'param_desc': 'A dict of item->dtype of what to downcast if possible,\\nor the string ‘infer’ which will try to downcast to an appropriate\\nequal type (e.g. float64 to int64 if possible).\\n\\nDeprecated since version 2.2.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.ffill',\n",
       "       'descriptions': 'Fill NA/NaN values by propagating the last valid observation to next valid.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': 'string',\n",
       "          'enum': ['0 or index'],\n",
       "          'description': '{0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame. Axis along which to fill missing values. For Series\\nthis parameter is unused and defaults to 0.\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True, fill in-place. Note: this will modify any\\nother views on this object (e.g., a no-copy slice for a column in a\\nDataFrame).\\n'},\n",
       "         'limit': {'type': 'integer',\n",
       "          'description': 'int, default None. If method is specified, this is the maximum number of consecutive\\nNaN values to forward/backward fill. In other words, if there is\\na gap with more than this number of consecutive NaNs, it will only\\nbe partially filled. If method is not specified, this is the\\nmaximum number of entries along the entire axis where NaNs will be\\nfilled. Must be greater than 0 if not None.\\n'},\n",
       "         'limit_area': {'type': 'string',\n",
       "          'enum': ['None', ' inside', ' outside'],\n",
       "          'description': '{None, ‘inside’, ‘outside’}, default None. If limit is specified, consecutive NaNs will be filled with this\\nrestriction.\\n\\nNone: No fill restriction.\\n‘inside’: Only fill NaNs surrounded by valid values\\n(interpolate).\\n‘outside’: Only fill NaNs outside valid values (extrapolate).\\n\\n\\nNew in version 2.2.0.\\n\\n'},\n",
       "         'downcast': {'type': 'dict, default is None',\n",
       "          'description': 'dict, default is None. A dict of item->dtype of what to downcast if possible,\\nor the string ‘infer’ which will try to downcast to an appropriate\\nequal type (e.g. float64 to int64 if possible).\\n\\nDeprecated since version 2.2.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.interpolate([method,\\xa0axis,\\xa0limit,\\xa0...])',\n",
       "      'func_desc': 'Fill NaN values using an interpolation method.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.interpolate.html#pandas.DataFrame.interpolate',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.interpolate',\n",
       "       'full_function': \"DataFrame.interpolate(method='linear', *, axis=0, limit=None, inplace=False, limit_direction=None, limit_area=None, downcast=_NoDefault.no_default, **kwargs)\",\n",
       "       'function_text': \"Fill NaN values using an interpolation method. Please note that only method='linear' is supported for\\nDataFrame/Series with a MultiIndex.\",\n",
       "       'parameter_names_desc': [{'param_name': 'method',\n",
       "         'param_type': 'str, default ‘linear’',\n",
       "         'param_desc': \"Interpolation technique to use. One of:\\n\\n‘linear’: Ignore the index and treat the values as equally\\nspaced. This is the only method supported on MultiIndexes.\\n‘time’: Works on daily and higher resolution data to interpolate\\ngiven length of interval.\\n‘index’, ‘values’: use the actual numerical values of the index.\\n‘pad’: Fill in NaNs using existing values.\\n‘nearest’, ‘zero’, ‘slinear’, ‘quadratic’, ‘cubic’,\\n‘barycentric’, ‘polynomial’: Passed to\\nscipy.interpolate.interp1d, whereas ‘spline’ is passed to\\nscipy.interpolate.UnivariateSpline. These methods use the numerical\\nvalues of the index. Both ‘polynomial’ and ‘spline’ require that\\nyou also specify an order (int), e.g.\\ndf.interpolate(method='polynomial', order=5). Note that,\\nslinear method in Pandas refers to the Scipy first order spline\\ninstead of Pandas first order spline.\\n‘krogh’, ‘piecewise_polynomial’, ‘spline’, ‘pchip’, ‘akima’,\\n‘cubicspline’: Wrappers around the SciPy interpolation methods of\\nsimilar names. See Notes.\\n‘from_derivatives’: Refers to\\nscipy.interpolate.BPoly.from_derivatives.\\n\\n\"},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{{0 or ‘index’, 1 or ‘columns’, None}}, default None',\n",
       "         'param_desc': 'Axis to interpolate along. For Series this parameter is unused\\nand defaults to 0.\\n'},\n",
       "        {'param_name': 'limit',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Maximum number of consecutive NaNs to fill. Must be greater than\\n0.\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Update the data in place if possible.\\n'},\n",
       "        {'param_name': 'limit_direction',\n",
       "         'param_type': '{{‘forward’, ‘backward’, ‘both’}}, Optional',\n",
       "         'param_desc': 'Consecutive NaNs will be filled in this direction.\\n\\nIf limit is specified:\\nIf ‘method’ is ‘pad’ or ‘ffill’, ‘limit_direction’ must be ‘forward’.\\nIf ‘method’ is ‘backfill’ or ‘bfill’, ‘limit_direction’ must be\\n‘backwards’.\\n\\n\\nIf ‘limit’ is not specified:\\nIf ‘method’ is ‘backfill’ or ‘bfill’, the default is ‘backward’\\nelse the default is ‘forward’\\n\\n\\nraises ValueError if limit_direction is ‘forward’ or ‘both’ andmethod is ‘backfill’ or ‘bfill’.\\n\\nraises ValueError if limit_direction is ‘backward’ or ‘both’ andmethod is ‘pad’ or ‘ffill’.\\n\\n\\n'},\n",
       "        {'param_name': 'limit_area',\n",
       "         'param_type': '{{None, ‘inside’, ‘outside’}}, default None',\n",
       "         'param_desc': 'If limit is specified, consecutive NaNs will be filled with this\\nrestriction.\\n\\nNone: No fill restriction.\\n‘inside’: Only fill NaNs surrounded by valid values\\n(interpolate).\\n‘outside’: Only fill NaNs outside valid values (extrapolate).\\n\\n'},\n",
       "        {'param_name': 'downcast',\n",
       "         'param_type': 'optional, ‘infer’ or None, defaults to None',\n",
       "         'param_desc': 'Downcast dtypes if possible.\\n\\nDeprecated since version 2.1.0.\\n\\n'},\n",
       "        {'param_name': '``**kwargs``',\n",
       "         'param_type': 'optional',\n",
       "         'param_desc': 'Keyword arguments to pass on to the interpolating function.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.interpolate',\n",
       "       'descriptions': \"Fill NaN values using an interpolation method. Please note that only method='linear' is supported for\\nDataFrame/Series with a MultiIndex.\",\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'method': {'type': 'string',\n",
       "          'description': \"str, default ‘linear’. Interpolation technique to use. One of:\\n\\n‘linear’: Ignore the index and treat the values as equally\\nspaced. This is the only method supported on MultiIndexes.\\n‘time’: Works on daily and higher resolution data to interpolate\\ngiven length of interval.\\n‘index’, ‘values’: use the actual numerical values of the index.\\n‘pad’: Fill in NaNs using existing values.\\n‘nearest’, ‘zero’, ‘slinear’, ‘quadratic’, ‘cubic’,\\n‘barycentric’, ‘polynomial’: Passed to\\nscipy.interpolate.interp1d, whereas ‘spline’ is passed to\\nscipy.interpolate.UnivariateSpline. These methods use the numerical\\nvalues of the index. Both ‘polynomial’ and ‘spline’ require that\\nyou also specify an order (int), e.g.\\ndf.interpolate(method='polynomial', order=5). Note that,\\nslinear method in Pandas refers to the Scipy first order spline\\ninstead of Pandas first order spline.\\n‘krogh’, ‘piecewise_polynomial’, ‘spline’, ‘pchip’, ‘akima’,\\n‘cubicspline’: Wrappers around the SciPy interpolation methods of\\nsimilar names. See Notes.\\n‘from_derivatives’: Refers to\\nscipy.interpolate.BPoly.from_derivatives.\\n\\n\"},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['{0 or index', ' 1 or columns', ' None'],\n",
       "          'description': '{{0 or ‘index’, 1 or ‘columns’, None}}, default None. Axis to interpolate along. For Series this parameter is unused\\nand defaults to 0.\\n'},\n",
       "         'limit': {'type': 'integer',\n",
       "          'description': 'int, optional. Maximum number of consecutive NaNs to fill. Must be greater than\\n0.\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Update the data in place if possible.\\n'},\n",
       "         'limit_direction': {'type': 'string',\n",
       "          'enum': ['{forward', ' backward', ' both'],\n",
       "          'description': '{{‘forward’, ‘backward’, ‘both’}}, Optional. Consecutive NaNs will be filled in this direction.\\n\\nIf limit is specified:\\nIf ‘method’ is ‘pad’ or ‘ffill’, ‘limit_direction’ must be ‘forward’.\\nIf ‘method’ is ‘backfill’ or ‘bfill’, ‘limit_direction’ must be\\n‘backwards’.\\n\\n\\nIf ‘limit’ is not specified:\\nIf ‘method’ is ‘backfill’ or ‘bfill’, the default is ‘backward’\\nelse the default is ‘forward’\\n\\n\\nraises ValueError if limit_direction is ‘forward’ or ‘both’ andmethod is ‘backfill’ or ‘bfill’.\\n\\nraises ValueError if limit_direction is ‘backward’ or ‘both’ andmethod is ‘pad’ or ‘ffill’.\\n\\n\\n'},\n",
       "         'limit_area': {'type': 'string',\n",
       "          'enum': ['{None', ' inside', ' outside'],\n",
       "          'description': '{{None, ‘inside’, ‘outside’}}, default None. If limit is specified, consecutive NaNs will be filled with this\\nrestriction.\\n\\nNone: No fill restriction.\\n‘inside’: Only fill NaNs surrounded by valid values\\n(interpolate).\\n‘outside’: Only fill NaNs outside valid values (extrapolate).\\n\\n'},\n",
       "         'downcast': {'type': 'optional, ‘infer’ or None, defaults to None',\n",
       "          'description': 'optional, ‘infer’ or None, defaults to None. Downcast dtypes if possible.\\n\\nDeprecated since version 2.1.0.\\n\\n'},\n",
       "         '``**kwargs``': {'type': 'optional',\n",
       "          'description': 'optional. Keyword arguments to pass on to the interpolating function.\\n'}},\n",
       "        'required': [\"method='linear'\"]}}},\n",
       "     {'func_name': 'DataFrame.isnull()',\n",
       "      'func_desc': 'DataFrame.isnull is an alias for DataFrame.isna.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isnull.html#pandas.DataFrame.isnull',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.isnull',\n",
       "       'full_function': 'DataFrame.isnull()',\n",
       "       'function_text': \"DataFrame.isnull is an alias for DataFrame.isna. Detect missing values. Return a boolean same-sized object indicating if the values are NA.\\nNA values, such as None or numpy.NaN, gets mapped to True\\nvalues.\\nEverything else gets mapped to False values. Characters such as empty\\nstrings '' or numpy.inf are not considered NA values\\n(unless you set pandas.options.mode.use_inf_as_na = True).\",\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.notnull()',\n",
       "      'func_desc': 'DataFrame.notnull is an alias for DataFrame.notna.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.notnull.html#pandas.DataFrame.notnull',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.notnull',\n",
       "       'full_function': 'DataFrame.notnull()',\n",
       "       'function_text': \"DataFrame.notnull is an alias for DataFrame.notna. Detect existing (non-missing) values. Return a boolean same-sized object indicating if the values are not NA.\\nNon-missing values get mapped to True. Characters such as empty\\nstrings '' or numpy.inf are not considered NA values\\n(unless you set pandas.options.mode.use_inf_as_na = True).\\nNA values, such as None or numpy.NaN, get mapped to False\\nvalues.\",\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.replace([to_replace,\\xa0value,\\xa0...])',\n",
       "      'func_desc': 'Replace values given in to_replace with value.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html#pandas.DataFrame.replace',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.replace',\n",
       "       'full_function': 'DataFrame.replace(to_replace=None, value=_NoDefault.no_default, *, inplace=False, limit=None, regex=False, method=_NoDefault.no_default)',\n",
       "       'function_text': 'Replace values given in to_replace with value. Values of the Series/DataFrame are replaced with other values dynamically.\\nThis differs from updating with .loc or .iloc, which require\\nyou to specify a location to update with some value.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'Reshaping, sorting, transposing': [{'func_name': 'DataFrame.droplevel(level[,\\xa0axis])',\n",
       "      'func_desc': 'Return Series/DataFrame with requested index / column level(s) removed.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.droplevel.html#pandas.DataFrame.droplevel',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.droplevel',\n",
       "       'full_function': 'DataFrame.droplevel(level, axis=0)',\n",
       "       'function_text': 'Return Series/DataFrame with requested index / column level(s) removed.',\n",
       "       'parameter_names_desc': [{'param_name': 'level',\n",
       "         'param_type': 'int, str, or list-like',\n",
       "         'param_desc': 'If a string is given, must be the name of a level\\nIf list-like, elements must be names or positional indexes\\nof levels.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'Axis along which the level(s) is removed:\\n\\n0 or ‘index’: remove level(s) in column.\\n1 or ‘columns’: remove level(s) in row.\\n\\nFor Series this parameter is unused and defaults to 0.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.droplevel',\n",
       "       'descriptions': 'Return Series/DataFrame with requested index / column level(s) removed.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'level': {'type': 'integer',\n",
       "          'description': 'int, str, or list-like. If a string is given, must be the name of a level\\nIf list-like, elements must be names or positional indexes\\nof levels.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. Axis along which the level(s) is removed:\\n\\n0 or ‘index’: remove level(s) in column.\\n1 or ‘columns’: remove level(s) in row.\\n\\nFor Series this parameter is unused and defaults to 0.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.pivot_table([values,\\xa0index,\\xa0...])',\n",
       "      'func_desc': 'Create a spreadsheet-style pivot table as a DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot_table.html#pandas.DataFrame.pivot_table',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.pivot_table',\n",
       "       'full_function': \"DataFrame.pivot_table(values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All', observed=_NoDefault.no_default, sort=True)\",\n",
       "       'function_text': 'Create a spreadsheet-style pivot table as a DataFrame. The levels in the pivot table will be stored in MultiIndex objects\\n(hierarchical indexes) on the index and columns of the result DataFrame.',\n",
       "       'parameter_names_desc': [{'param_name': 'values',\n",
       "         'param_type': 'list-like or scalar, optional',\n",
       "         'param_desc': 'Column or columns to aggregate.\\n'},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'column, Grouper, array, or list of the previous',\n",
       "         'param_desc': 'Keys to group by on the pivot table index. If a list is passed,\\nit can contain any of the other types (except list). If an array is\\npassed, it must be the same length as the data and will be used in\\nthe same manner as column values.\\n'},\n",
       "        {'param_name': 'columns',\n",
       "         'param_type': 'column, Grouper, array, or list of the previous',\n",
       "         'param_desc': 'Keys to group by on the pivot table column. If a list is passed,\\nit can contain any of the other types (except list). If an array is\\npassed, it must be the same length as the data and will be used in\\nthe same manner as column values.\\n'},\n",
       "        {'param_name': 'aggfunc',\n",
       "         'param_type': 'function, list of functions, dict, default “mean”',\n",
       "         'param_desc': 'If a list of functions is passed, the resulting pivot table will have\\nhierarchical columns whose top level are the function names\\n(inferred from the function objects themselves).\\nIf a dict is passed, the key is column to aggregate and the value is\\nfunction or list of functions. If margin=True, aggfunc will be\\nused to calculate the partial aggregates.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'scalar, default None',\n",
       "         'param_desc': 'Value to replace missing values with (in the resulting pivot table,\\nafter aggregation).\\n'},\n",
       "        {'param_name': 'margins',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If margins=True, special All columns and rows\\nwill be added with partial group aggregates across the categories\\non the rows and columns.\\n'},\n",
       "        {'param_name': 'dropna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Do not include columns whose entries are all NaN. If True,\\nrows with a NaN value in any column will be omitted before\\ncomputing margins.\\n'},\n",
       "        {'param_name': 'margins_name',\n",
       "         'param_type': 'str, default ‘All’',\n",
       "         'param_desc': 'Name of the row / column that will contain the totals\\nwhen margins is True.\\n'},\n",
       "        {'param_name': 'observed',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'This only applies if any of the groupers are Categoricals.\\nIf True: only show observed values for categorical groupers.\\nIf False: show all values for categorical groupers.\\n\\nDeprecated since version 2.2.0: The default value of False is deprecated and will change to\\nTrue in a future version of pandas.\\n\\n'},\n",
       "        {'param_name': 'sort',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Specifies if the result should be sorted.\\n\\nNew in version 1.3.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.pivot_table',\n",
       "       'descriptions': 'Create a spreadsheet-style pivot table as a DataFrame. The levels in the pivot table will be stored in MultiIndex objects\\n(hierarchical indexes) on the index and columns of the result DataFrame.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'values': {'type': 'array',\n",
       "          'description': 'list-like or scalar, optional. Column or columns to aggregate.\\n'},\n",
       "         'index': {'type': 'array',\n",
       "          'description': 'column, Grouper, array, or list of the previous. Keys to group by on the pivot table index. If a list is passed,\\nit can contain any of the other types (except list). If an array is\\npassed, it must be the same length as the data and will be used in\\nthe same manner as column values.\\n'},\n",
       "         'columns': {'type': 'array',\n",
       "          'description': 'column, Grouper, array, or list of the previous. Keys to group by on the pivot table column. If a list is passed,\\nit can contain any of the other types (except list). If an array is\\npassed, it must be the same length as the data and will be used in\\nthe same manner as column values.\\n'},\n",
       "         'aggfunc': {'type': 'array',\n",
       "          'description': 'function, list of functions, dict, default “mean”. If a list of functions is passed, the resulting pivot table will have\\nhierarchical columns whose top level are the function names\\n(inferred from the function objects themselves).\\nIf a dict is passed, the key is column to aggregate and the value is\\nfunction or list of functions. If margin=True, aggfunc will be\\nused to calculate the partial aggregates.\\n'},\n",
       "         'fill_value': {'type': 'scalar, default None',\n",
       "          'description': 'scalar, default None. Value to replace missing values with (in the resulting pivot table,\\nafter aggregation).\\n'},\n",
       "         'margins': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If margins=True, special All columns and rows\\nwill be added with partial group aggregates across the categories\\non the rows and columns.\\n'},\n",
       "         'dropna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Do not include columns whose entries are all NaN. If True,\\nrows with a NaN value in any column will be omitted before\\ncomputing margins.\\n'},\n",
       "         'margins_name': {'type': 'string',\n",
       "          'description': 'str, default ‘All’. Name of the row / column that will contain the totals\\nwhen margins is True.\\n'},\n",
       "         'observed': {'type': 'boolean',\n",
       "          'description': 'bool, default False. This only applies if any of the groupers are Categoricals.\\nIf True: only show observed values for categorical groupers.\\nIf False: show all values for categorical groupers.\\n\\nDeprecated since version 2.2.0: The default value of False is deprecated and will change to\\nTrue in a future version of pandas.\\n\\n'},\n",
       "         'sort': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Specifies if the result should be sorted.\\n\\nNew in version 1.3.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.sort_values(by,\\xa0*[,\\xa0axis,\\xa0...])',\n",
       "      'func_desc': 'Sort by the values along either axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html#pandas.DataFrame.sort_values',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.sort_values',\n",
       "       'full_function': \"DataFrame.sort_values(by, *, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last', ignore_index=False, key=None)\",\n",
       "       'function_text': 'Sort by the values along either axis.',\n",
       "       'parameter_names_desc': [{'param_name': 'by',\n",
       "         'param_type': 'str or list of str',\n",
       "         'param_desc': 'Name or list of names to sort by.\\n\\nif axis is 0 or ‘index’ then by may contain index\\nlevels and/or column labels.\\nif axis is 1 or ‘columns’ then by may contain column\\nlevels and/or index labels.\\n\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '“{0 or ‘index’, 1 or ‘columns’}”, default 0',\n",
       "         'param_desc': 'Axis to be sorted.\\n'},\n",
       "        {'param_name': 'ascending',\n",
       "         'param_type': 'bool or list of bool, default True',\n",
       "         'param_desc': 'Sort ascending vs. descending. Specify list for multiple sort\\norders. If this is a list of bools, must match the length of\\nthe by.\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True, perform operation in-place.\\n'},\n",
       "        {'param_name': 'kind',\n",
       "         'param_type': '{‘quicksort’, ‘mergesort’, ‘heapsort’, ‘stable’}, default ‘quicksort’',\n",
       "         'param_desc': 'Choice of sorting algorithm. See also numpy.sort() for more\\ninformation. mergesort and stable are the only stable algorithms. For\\nDataFrames, this option is only applied when sorting on a single\\ncolumn or label.\\n'},\n",
       "        {'param_name': 'na_position',\n",
       "         'param_type': '{‘first’, ‘last’}, default ‘last’',\n",
       "         'param_desc': 'Puts NaNs at the beginning if first; last puts NaNs at the\\nend.\\n'},\n",
       "        {'param_name': 'ignore_index',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True, the resulting axis will be labeled 0, 1, …, n - 1.\\n'},\n",
       "        {'param_name': 'key',\n",
       "         'param_type': 'callable, optional',\n",
       "         'param_desc': 'Apply the key function to the values\\nbefore sorting. This is similar to the key argument in the\\nbuiltin sorted() function, with the notable difference that\\nthis key function should be vectorized. It should expect a\\nSeries and return a Series with the same shape as the input.\\nIt will be applied to each column in by independently.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.sort_values',\n",
       "       'descriptions': 'Sort by the values along either axis.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'by': {'type': 'string',\n",
       "          'description': 'str or list of str. Name or list of names to sort by.\\n\\nif axis is 0 or ‘index’ then by may contain index\\nlevels and/or column labels.\\nif axis is 1 or ‘columns’ then by may contain column\\nlevels and/or index labels.\\n\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '“{0 or ‘index’, 1 or ‘columns’}”, default 0. Axis to be sorted.\\n'},\n",
       "         'ascending': {'type': 'boolean',\n",
       "          'description': 'bool or list of bool, default True. Sort ascending vs. descending. Specify list for multiple sort\\norders. If this is a list of bools, must match the length of\\nthe by.\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True, perform operation in-place.\\n'},\n",
       "         'kind': {'type': 'string',\n",
       "          'enum': ['quicksort', ' mergesort', ' heapsort', ' stable'],\n",
       "          'description': '{‘quicksort’, ‘mergesort’, ‘heapsort’, ‘stable’}, default ‘quicksort’. Choice of sorting algorithm. See also numpy.sort() for more\\ninformation. mergesort and stable are the only stable algorithms. For\\nDataFrames, this option is only applied when sorting on a single\\ncolumn or label.\\n'},\n",
       "         'na_position': {'type': 'string',\n",
       "          'enum': ['first', ' last'],\n",
       "          'description': '{‘first’, ‘last’}, default ‘last’. Puts NaNs at the beginning if first; last puts NaNs at the\\nend.\\n'},\n",
       "         'ignore_index': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True, the resulting axis will be labeled 0, 1, …, n - 1.\\n'},\n",
       "         'key': {'type': 'object',\n",
       "          'description': 'callable, optional. Apply the key function to the values\\nbefore sorting. This is similar to the key argument in the\\nbuiltin sorted() function, with the notable difference that\\nthis key function should be vectorized. It should expect a\\nSeries and return a Series with the same shape as the input.\\nIt will be applied to each column in by independently.\\n'}},\n",
       "        'required': ['by']}}},\n",
       "     {'func_name': 'DataFrame.nlargest(n,\\xa0columns[,\\xa0keep])',\n",
       "      'func_desc': 'Return the first n rows ordered by columns in descending order.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nlargest.html#pandas.DataFrame.nlargest',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.nlargest',\n",
       "       'full_function': \"DataFrame.nlargest(n, columns, keep='first')\",\n",
       "       'function_text': 'Return the first n rows ordered by columns in descending order. Return the first n rows with the largest values in columns, in\\ndescending order. The columns that are not specified are returned as\\nwell, but not used for ordering. This method is equivalent to\\ndf.sort_values(columns, ascending=False).head(n), but more\\nperformant.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int',\n",
       "         'param_desc': 'Number of rows to return.\\n'},\n",
       "        {'param_name': 'columns',\n",
       "         'param_type': 'label or list of labels',\n",
       "         'param_desc': 'Column label(s) to order by.\\n'},\n",
       "        {'param_name': 'keep',\n",
       "         'param_type': '{‘first’, ‘last’, ‘all’}, default ‘first’',\n",
       "         'param_desc': 'Where there are duplicate values:\\n\\nfirst : prioritize the first occurrence(s)\\nlast : prioritize the last occurrence(s)\\nall : keep all the ties of the smallest item even if it means\\nselecting more than n items.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.nlargest',\n",
       "       'descriptions': 'Return the first n rows ordered by columns in descending order. Return the first n rows with the largest values in columns, in\\ndescending order. The columns that are not specified are returned as\\nwell, but not used for ordering. This method is equivalent to\\ndf.sort_values(columns, ascending=False).head(n), but more\\nperformant.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int. Number of rows to return.\\n'},\n",
       "         'columns': {'type': 'array',\n",
       "          'description': 'label or list of labels. Column label(s) to order by.\\n'},\n",
       "         'keep': {'type': 'string',\n",
       "          'enum': ['first', ' last', ' all'],\n",
       "          'description': '{‘first’, ‘last’, ‘all’}, default ‘first’. Where there are duplicate values:\\n\\nfirst : prioritize the first occurrence(s)\\nlast : prioritize the last occurrence(s)\\nall : keep all the ties of the smallest item even if it means\\nselecting more than n items.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.swaplevel([i,\\xa0j,\\xa0axis])',\n",
       "      'func_desc': 'Swap levels i and j in a MultiIndex.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.swaplevel.html#pandas.DataFrame.swaplevel',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.swaplevel',\n",
       "       'full_function': 'DataFrame.swaplevel(i=-2, j=-1, axis=0)',\n",
       "       'function_text': 'Swap levels i and j in a MultiIndex. Default is to swap the two innermost levels of the index.',\n",
       "       'parameter_names_desc': [{'param_name': 'i, j',\n",
       "         'param_type': 'int or str',\n",
       "         'param_desc': 'Levels of the indices to be swapped. Can pass level name as string.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'The axis to swap levels on. 0 or ‘index’ for row-wise, 1 or\\n‘columns’ for column-wise.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.swaplevel',\n",
       "       'descriptions': 'Swap levels i and j in a MultiIndex. Default is to swap the two innermost levels of the index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'i, j': {'type': 'integer',\n",
       "          'description': 'int or str. Levels of the indices to be swapped. Can pass level name as string.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. The axis to swap levels on. 0 or ‘index’ for row-wise, 1 or\\n‘columns’ for column-wise.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.unstack([level,\\xa0fill_value,\\xa0sort])',\n",
       "      'func_desc': 'Pivot a level of the (necessarily hierarchical) index labels.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.unstack.html#pandas.DataFrame.unstack',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.unstack',\n",
       "       'full_function': 'DataFrame.unstack(level=-1, fill_value=None, sort=True)',\n",
       "       'function_text': 'Pivot a level of the (necessarily hierarchical) index labels. Returns a DataFrame having a new level of column labels whose inner-most level\\nconsists of the pivoted index labels. If the index is not a MultiIndex, the output will be a Series\\n(the analogue of stack when the columns are not a MultiIndex).',\n",
       "       'parameter_names_desc': [{'param_name': 'level',\n",
       "         'param_type': 'int, str, or list of these, default -1 (last level)',\n",
       "         'param_desc': 'Level(s) of index to unstack, can pass level name.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'int, str or dict',\n",
       "         'param_desc': 'Replace NaN with this value if the unstack produces missing values.\\n'},\n",
       "        {'param_name': 'sort',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Sort the level(s) in the resulting MultiIndex columns.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.unstack',\n",
       "       'descriptions': 'Pivot a level of the (necessarily hierarchical) index labels. Returns a DataFrame having a new level of column labels whose inner-most level\\nconsists of the pivoted index labels. If the index is not a MultiIndex, the output will be a Series\\n(the analogue of stack when the columns are not a MultiIndex).',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'level': {'type': 'integer',\n",
       "          'description': 'int, str, or list of these, default -1 (last level). Level(s) of index to unstack, can pass level name.\\n'},\n",
       "         'fill_value': {'type': 'integer',\n",
       "          'description': 'int, str or dict. Replace NaN with this value if the unstack produces missing values.\\n'},\n",
       "         'sort': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Sort the level(s) in the resulting MultiIndex columns.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.melt([id_vars,\\xa0value_vars,\\xa0...])',\n",
       "      'func_desc': 'Unpivot a DataFrame from wide to long format, optionally leaving identifiers set.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.melt.html#pandas.DataFrame.melt',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.melt',\n",
       "       'full_function': \"DataFrame.melt(id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None, ignore_index=True)\",\n",
       "       'function_text': 'Unpivot a DataFrame from wide to long format, optionally leaving identifiers set. This function is useful to massage a DataFrame into a format where one\\nor more columns are identifier variables (id_vars), while all other\\ncolumns, considered measured variables (value_vars), are “unpivoted” to\\nthe row axis, leaving just two non-identifier columns, ‘variable’ and\\n‘value’.',\n",
       "       'parameter_names_desc': [{'param_name': 'id_vars',\n",
       "         'param_type': 'scalar, tuple, list, or ndarray, optional',\n",
       "         'param_desc': 'Column(s) to use as identifier variables.\\n'},\n",
       "        {'param_name': 'value_vars',\n",
       "         'param_type': 'scalar, tuple, list, or ndarray, optional',\n",
       "         'param_desc': 'Column(s) to unpivot. If not specified, uses all columns that\\nare not set as id_vars.\\n'},\n",
       "        {'param_name': 'var_name',\n",
       "         'param_type': 'scalar, default None',\n",
       "         'param_desc': 'Name to use for the ‘variable’ column. If None it uses\\nframe.columns.name or ‘variable’.\\n'},\n",
       "        {'param_name': 'value_name',\n",
       "         'param_type': 'scalar, default ‘value’',\n",
       "         'param_desc': 'Name to use for the ‘value’ column, can’t be an existing column label.\\n'},\n",
       "        {'param_name': 'col_level',\n",
       "         'param_type': 'scalar, optional',\n",
       "         'param_desc': 'If columns are a MultiIndex then use this level to melt.\\n'},\n",
       "        {'param_name': 'ignore_index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If True, original index is ignored. If False, the original index is retained.\\nIndex labels will be repeated as necessary.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.melt',\n",
       "       'descriptions': 'Unpivot a DataFrame from wide to long format, optionally leaving identifiers set. This function is useful to massage a DataFrame into a format where one\\nor more columns are identifier variables (id_vars), while all other\\ncolumns, considered measured variables (value_vars), are “unpivoted” to\\nthe row axis, leaving just two non-identifier columns, ‘variable’ and\\n‘value’.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'id_vars': {'type': 'array',\n",
       "          'description': 'scalar, tuple, list, or ndarray, optional. Column(s) to use as identifier variables.\\n'},\n",
       "         'value_vars': {'type': 'array',\n",
       "          'description': 'scalar, tuple, list, or ndarray, optional. Column(s) to unpivot. If not specified, uses all columns that\\nare not set as id_vars.\\n'},\n",
       "         'var_name': {'type': 'scalar, default None',\n",
       "          'description': 'scalar, default None. Name to use for the ‘variable’ column. If None it uses\\nframe.columns.name or ‘variable’.\\n'},\n",
       "         'value_name': {'type': 'scalar, default ‘value’',\n",
       "          'description': 'scalar, default ‘value’. Name to use for the ‘value’ column, can’t be an existing column label.\\n'},\n",
       "         'col_level': {'type': 'scalar, optional',\n",
       "          'description': 'scalar, optional. If columns are a MultiIndex then use this level to melt.\\n'},\n",
       "         'ignore_index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If True, original index is ignored. If False, the original index is retained.\\nIndex labels will be repeated as necessary.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.squeeze([axis])',\n",
       "      'func_desc': 'Squeeze 1 dimensional axis objects into scalars.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.squeeze.html#pandas.DataFrame.squeeze',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.squeeze',\n",
       "       'full_function': 'DataFrame.squeeze(axis=None)',\n",
       "       'function_text': 'Squeeze 1 dimensional axis objects into scalars. Series or DataFrames with a single element are squeezed to a scalar.\\nDataFrames with a single column or a single row are squeezed to a\\nSeries. Otherwise the object is unchanged. This method is most useful when you don’t know if your\\nobject is a Series or DataFrame, but you do know it has just a single\\ncolumn. In that case you can safely call squeeze to ensure you have a\\nSeries.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’, None}, default None',\n",
       "         'param_desc': 'A specific axis to squeeze. By default, all length-1 axes are\\nsqueezed. For Series this parameter is unused and defaults to None.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.squeeze',\n",
       "       'descriptions': 'Squeeze 1 dimensional axis objects into scalars. Series or DataFrames with a single element are squeezed to a scalar.\\nDataFrames with a single column or a single row are squeezed to a\\nSeries. Otherwise the object is unchanged. This method is most useful when you don’t know if your\\nobject is a Series or DataFrame, but you do know it has just a single\\ncolumn. In that case you can safely call squeeze to ensure you have a\\nSeries.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns', ' None'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’, None}, default None. A specific axis to squeeze. By default, all length-1 axes are\\nsqueezed. For Series this parameter is unused and defaults to None.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.T',\n",
       "      'func_desc': 'The transpose of the DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.T.html#pandas.DataFrame.T',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.T',\n",
       "       'full_function': 'property DataFrame.T',\n",
       "       'function_text': 'The transpose of the DataFrame.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.pivot(*,\\xa0columns[,\\xa0index,\\xa0values])',\n",
       "      'func_desc': 'Return reshaped DataFrame organized by given index / column values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot.html#pandas.DataFrame.pivot',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.pivot',\n",
       "       'full_function': 'DataFrame.pivot(*, columns, index=_NoDefault.no_default, values=_NoDefault.no_default)',\n",
       "       'function_text': 'Return reshaped DataFrame organized by given index / column values. Reshape data (produce a “pivot” table) based on column values. Uses\\nunique values from specified index / columns to form axes of the\\nresulting DataFrame. This function does not support data\\naggregation, multiple values will result in a MultiIndex in the\\ncolumns. See the User Guide for more on reshaping.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.reorder_levels(order[,\\xa0axis])',\n",
       "      'func_desc': 'Rearrange index levels using input order.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reorder_levels.html#pandas.DataFrame.reorder_levels',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.reorder_levels',\n",
       "       'full_function': 'DataFrame.reorder_levels(order, axis=0)',\n",
       "       'function_text': 'Rearrange index levels using input order. May not drop or duplicate levels.',\n",
       "       'parameter_names_desc': [{'param_name': 'order',\n",
       "         'param_type': 'list of int or list of str',\n",
       "         'param_desc': 'List representing new level order. Reference level by number\\n(position) or by key (label).\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'Where to reorder levels.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.reorder_levels',\n",
       "       'descriptions': 'Rearrange index levels using input order. May not drop or duplicate levels.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'order': {'type': 'integer',\n",
       "          'description': 'list of int or list of str. List representing new level order. Reference level by number\\n(position) or by key (label).\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. Where to reorder levels.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.sort_index(*[,\\xa0axis,\\xa0level,\\xa0...])',\n",
       "      'func_desc': 'Sort object by labels (along an axis).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_index.html#pandas.DataFrame.sort_index',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.sort_index',\n",
       "       'full_function': \"DataFrame.sort_index(*, axis=0, level=None, ascending=True, inplace=False, kind='quicksort', na_position='last', sort_remaining=True, ignore_index=False, key=None)\",\n",
       "       'function_text': 'Sort object by labels (along an axis). Returns a new DataFrame sorted by label if inplace argument is\\nFalse, otherwise updates the original DataFrame and returns None.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'The axis along which to sort. The value 0 identifies the rows,\\nand 1 identifies the columns.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or level name or list of ints or list of level names',\n",
       "         'param_desc': 'If not None, sort on values in specified index level(s).\\n'},\n",
       "        {'param_name': 'ascending',\n",
       "         'param_type': 'bool or list-like of bools, default True',\n",
       "         'param_desc': 'Sort ascending vs. descending. When the index is a MultiIndex the\\nsort direction can be controlled for each level individually.\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to modify the DataFrame rather than creating a new one.\\n'},\n",
       "        {'param_name': 'kind',\n",
       "         'param_type': '{‘quicksort’, ‘mergesort’, ‘heapsort’, ‘stable’}, default ‘quicksort’',\n",
       "         'param_desc': 'Choice of sorting algorithm. See also numpy.sort() for more\\ninformation. mergesort and stable are the only stable algorithms. For\\nDataFrames, this option is only applied when sorting on a single\\ncolumn or label.\\n'},\n",
       "        {'param_name': 'na_position',\n",
       "         'param_type': '{‘first’, ‘last’}, default ‘last’',\n",
       "         'param_desc': 'Puts NaNs at the beginning if first; last puts NaNs at the end.\\nNot implemented for MultiIndex.\\n'},\n",
       "        {'param_name': 'sort_remaining',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If True and sorting by level and index is multilevel, sort by other\\nlevels too (in order) after sorting by specified level.\\n'},\n",
       "        {'param_name': 'ignore_index',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True, the resulting axis will be labeled 0, 1, …, n - 1.\\n'},\n",
       "        {'param_name': 'key',\n",
       "         'param_type': 'callable, optional',\n",
       "         'param_desc': 'If not None, apply the key function to the index values\\nbefore sorting. This is similar to the key argument in the\\nbuiltin sorted() function, with the notable difference that\\nthis key function should be vectorized. It should expect an\\nIndex and return an Index of the same shape. For MultiIndex\\ninputs, the key is applied per level.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.sort_index',\n",
       "       'descriptions': 'Sort object by labels (along an axis). Returns a new DataFrame sorted by label if inplace argument is\\nFalse, otherwise updates the original DataFrame and returns None.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. The axis along which to sort. The value 0 identifies the rows,\\nand 1 identifies the columns.\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or level name or list of ints or list of level names. If not None, sort on values in specified index level(s).\\n'},\n",
       "         'ascending': {'type': 'boolean',\n",
       "          'description': 'bool or list-like of bools, default True. Sort ascending vs. descending. When the index is a MultiIndex the\\nsort direction can be controlled for each level individually.\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to modify the DataFrame rather than creating a new one.\\n'},\n",
       "         'kind': {'type': 'string',\n",
       "          'enum': ['quicksort', ' mergesort', ' heapsort', ' stable'],\n",
       "          'description': '{‘quicksort’, ‘mergesort’, ‘heapsort’, ‘stable’}, default ‘quicksort’. Choice of sorting algorithm. See also numpy.sort() for more\\ninformation. mergesort and stable are the only stable algorithms. For\\nDataFrames, this option is only applied when sorting on a single\\ncolumn or label.\\n'},\n",
       "         'na_position': {'type': 'string',\n",
       "          'enum': ['first', ' last'],\n",
       "          'description': '{‘first’, ‘last’}, default ‘last’. Puts NaNs at the beginning if first; last puts NaNs at the end.\\nNot implemented for MultiIndex.\\n'},\n",
       "         'sort_remaining': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If True and sorting by level and index is multilevel, sort by other\\nlevels too (in order) after sorting by specified level.\\n'},\n",
       "         'ignore_index': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True, the resulting axis will be labeled 0, 1, …, n - 1.\\n'},\n",
       "         'key': {'type': 'object',\n",
       "          'description': 'callable, optional. If not None, apply the key function to the index values\\nbefore sorting. This is similar to the key argument in the\\nbuiltin sorted() function, with the notable difference that\\nthis key function should be vectorized. It should expect an\\nIndex and return an Index of the same shape. For MultiIndex\\ninputs, the key is applied per level.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.nsmallest(n,\\xa0columns[,\\xa0keep])',\n",
       "      'func_desc': 'Return the first n rows ordered by columns in ascending order.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nsmallest.html#pandas.DataFrame.nsmallest',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.nsmallest',\n",
       "       'full_function': \"DataFrame.nsmallest(n, columns, keep='first')\",\n",
       "       'function_text': 'Return the first n rows ordered by columns in ascending order. Return the first n rows with the smallest values in columns, in\\nascending order. The columns that are not specified are returned as\\nwell, but not used for ordering. This method is equivalent to\\ndf.sort_values(columns, ascending=True).head(n), but more\\nperformant.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int',\n",
       "         'param_desc': 'Number of items to retrieve.\\n'},\n",
       "        {'param_name': 'columns',\n",
       "         'param_type': 'list or str',\n",
       "         'param_desc': 'Column name or names to order by.\\n'},\n",
       "        {'param_name': 'keep',\n",
       "         'param_type': '{‘first’, ‘last’, ‘all’}, default ‘first’',\n",
       "         'param_desc': 'Where there are duplicate values:\\n\\nfirst : take the first occurrence.\\nlast : take the last occurrence.\\nall : keep all the ties of the largest item even if it means\\nselecting more than n items.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.nsmallest',\n",
       "       'descriptions': 'Return the first n rows ordered by columns in ascending order. Return the first n rows with the smallest values in columns, in\\nascending order. The columns that are not specified are returned as\\nwell, but not used for ordering. This method is equivalent to\\ndf.sort_values(columns, ascending=True).head(n), but more\\nperformant.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int. Number of items to retrieve.\\n'},\n",
       "         'columns': {'type': 'string',\n",
       "          'description': 'list or str. Column name or names to order by.\\n'},\n",
       "         'keep': {'type': 'string',\n",
       "          'enum': ['first', ' last', ' all'],\n",
       "          'description': '{‘first’, ‘last’, ‘all’}, default ‘first’. Where there are duplicate values:\\n\\nfirst : take the first occurrence.\\nlast : take the last occurrence.\\nall : keep all the ties of the largest item even if it means\\nselecting more than n items.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.stack([level,\\xa0dropna,\\xa0sort,\\xa0...])',\n",
       "      'func_desc': 'Stack the prescribed level(s) from columns to index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.stack.html#pandas.DataFrame.stack',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.stack',\n",
       "       'full_function': 'DataFrame.stack(level=-1, dropna=_NoDefault.no_default, sort=_NoDefault.no_default, future_stack=False)',\n",
       "       'function_text': 'Stack the prescribed level(s) from columns to index. Return a reshaped DataFrame or Series having a multi-level\\nindex with one or more new inner-most levels compared to the current\\nDataFrame. The new inner-most levels are created by pivoting the\\ncolumns of the current dataframe: if the columns have a single level, the output is a Series; if the columns have multiple levels, the new index\\nlevel(s) is (are) taken from the prescribed level(s) and\\nthe output is a DataFrame.',\n",
       "       'parameter_names_desc': [{'param_name': 'level',\n",
       "         'param_type': 'int, str, list, default -1',\n",
       "         'param_desc': 'Level(s) to stack from the column axis onto the index\\naxis, defined as one index or label, or a list of indices\\nor labels.\\n'},\n",
       "        {'param_name': 'dropna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to drop rows in the resulting Frame/Series with\\nmissing values. Stacking a column level onto the index\\naxis can create combinations of index and column values\\nthat are missing from the original dataframe. See Examples\\nsection.\\n'},\n",
       "        {'param_name': 'sort',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to sort the levels of the resulting MultiIndex.\\n'},\n",
       "        {'param_name': 'future_stack',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to use the new implementation that will replace the current\\nimplementation in pandas 3.0. When True, dropna and sort have no impact\\non the result and must remain unspecified. See pandas 2.1.0 Release\\nnotes for more details.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.stack',\n",
       "       'descriptions': 'Stack the prescribed level(s) from columns to index. Return a reshaped DataFrame or Series having a multi-level\\nindex with one or more new inner-most levels compared to the current\\nDataFrame. The new inner-most levels are created by pivoting the\\ncolumns of the current dataframe: if the columns have a single level, the output is a Series; if the columns have multiple levels, the new index\\nlevel(s) is (are) taken from the prescribed level(s) and\\nthe output is a DataFrame.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'level': {'type': 'integer',\n",
       "          'description': 'int, str, list, default -1. Level(s) to stack from the column axis onto the index\\naxis, defined as one index or label, or a list of indices\\nor labels.\\n'},\n",
       "         'dropna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to drop rows in the resulting Frame/Series with\\nmissing values. Stacking a column level onto the index\\naxis can create combinations of index and column values\\nthat are missing from the original dataframe. See Examples\\nsection.\\n'},\n",
       "         'sort': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to sort the levels of the resulting MultiIndex.\\n'},\n",
       "         'future_stack': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to use the new implementation that will replace the current\\nimplementation in pandas 3.0. When True, dropna and sort have no impact\\non the result and must remain unspecified. See pandas 2.1.0 Release\\nnotes for more details.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.swapaxes(axis1,\\xa0axis2[,\\xa0copy])',\n",
       "      'func_desc': '(DEPRECATED) Interchange axes and swap values axes appropriately.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.swapaxes.html#pandas.DataFrame.swapaxes',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.swapaxes',\n",
       "       'full_function': 'DataFrame.swapaxes(axis1, axis2, copy=None)',\n",
       "       'function_text': 'Interchange axes and swap values axes appropriately. Deprecated since version 2.1.0: swapaxes is deprecated and will be removed.\\nPlease use transpose instead.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.explode(column[,\\xa0ignore_index])',\n",
       "      'func_desc': 'Transform each element of a list-like to a row, replicating index values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.explode.html#pandas.DataFrame.explode',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.explode',\n",
       "       'full_function': 'DataFrame.explode(column, ignore_index=False)',\n",
       "       'function_text': 'Transform each element of a list-like to a row, replicating index values.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.to_xarray()',\n",
       "      'func_desc': 'Return an xarray object from the pandas object.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_xarray.html#pandas.DataFrame.to_xarray',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_xarray',\n",
       "       'full_function': 'DataFrame.to_xarray()',\n",
       "       'function_text': 'Return an xarray object from the pandas object.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.transpose(*args[,\\xa0copy])',\n",
       "      'func_desc': 'Transpose index and columns.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.transpose.html#pandas.DataFrame.transpose',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.transpose',\n",
       "       'full_function': 'DataFrame.transpose(*args, copy=False)',\n",
       "       'function_text': 'Transpose index and columns. Reflect the DataFrame over its main diagonal by writing rows as columns\\nand vice-versa. The property T is an accessor to the method\\ntranspose().',\n",
       "       'parameter_names_desc': [{'param_name': '*args',\n",
       "         'param_type': 'tuple, optional',\n",
       "         'param_desc': 'Accepted for compatibility with NumPy.\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to copy the data after transposing, even for DataFrames\\nwith a single dtype.\\nNote that a copy is always required for mixed dtype DataFrames,\\nor for DataFrames with any extension types.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.transpose',\n",
       "       'descriptions': 'Transpose index and columns. Reflect the DataFrame over its main diagonal by writing rows as columns\\nand vice-versa. The property T is an accessor to the method\\ntranspose().',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'*args': {'type': 'tuple, optional',\n",
       "          'description': 'tuple, optional. Accepted for compatibility with NumPy.\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to copy the data after transposing, even for DataFrames\\nwith a single dtype.\\nNote that a copy is always required for mixed dtype DataFrames,\\nor for DataFrames with any extension types.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Combining / comparing / joining / merging': [{'func_name': 'DataFrame.assign(**kwargs)',\n",
       "      'func_desc': 'Assign new columns to a DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.assign.html#pandas.DataFrame.assign',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.assign',\n",
       "       'full_function': 'DataFrame.assign(**kwargs)',\n",
       "       'function_text': 'Assign new columns to a DataFrame. Returns a new object with all original columns in addition to new ones.\\nExisting columns that are re-assigned will be overwritten.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.join(other[,\\xa0on,\\xa0how,\\xa0lsuffix,\\xa0...])',\n",
       "      'func_desc': 'Join columns of another DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.join.html#pandas.DataFrame.join',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.join',\n",
       "       'full_function': \"DataFrame.join(other, on=None, how='left', lsuffix='', rsuffix='', sort=False, validate=None)\",\n",
       "       'function_text': 'Join columns of another DataFrame. Join columns with other DataFrame either on index or on a key\\ncolumn. Efficiently join multiple DataFrame objects by index at once by\\npassing a list.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'DataFrame, Series, or a list containing any combination of them',\n",
       "         'param_desc': 'Index should be similar to one of the columns in this one. If a\\nSeries is passed, its name attribute must be set, and that will be\\nused as the column name in the resulting joined DataFrame.\\n'},\n",
       "        {'param_name': 'on',\n",
       "         'param_type': 'str, list of str, or array-like, optional',\n",
       "         'param_desc': 'Column or index level name(s) in the caller to join on the index\\nin other, otherwise joins index-on-index. If multiple\\nvalues given, the other DataFrame must have a MultiIndex. Can\\npass an array as the join key if it is not already contained in\\nthe calling DataFrame. Like an Excel VLOOKUP operation.\\n'},\n",
       "        {'param_name': 'how',\n",
       "         'param_type': '{‘left’, ‘right’, ‘outer’, ‘inner’, ‘cross’}, default ‘left’',\n",
       "         'param_desc': 'How to handle the operation of the two objects.\\n\\nleft: use calling frame’s index (or column if on is specified)\\nright: use other’s index.\\nouter: form union of calling frame’s index (or column if on is\\nspecified) with other’s index, and sort it lexicographically.\\ninner: form intersection of calling frame’s index (or column if\\non is specified) with other’s index, preserving the order\\nof the calling’s one.\\ncross: creates the cartesian product from both frames, preserves the order\\nof the left keys.\\n\\n'},\n",
       "        {'param_name': 'lsuffix',\n",
       "         'param_type': 'str, default ‘’',\n",
       "         'param_desc': 'Suffix to use from left frame’s overlapping columns.\\n'},\n",
       "        {'param_name': 'rsuffix',\n",
       "         'param_type': 'str, default ‘’',\n",
       "         'param_desc': 'Suffix to use from right frame’s overlapping columns.\\n'},\n",
       "        {'param_name': 'sort',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Order result DataFrame lexicographically by the join key. If False,\\nthe order of the join key depends on the join type (how keyword).\\n'},\n",
       "        {'param_name': 'validate',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'If specified, checks if join is of specified type.\\n\\n“one_to_one” or “1:1”: check if join keys are unique in both left\\nand right datasets.\\n“one_to_many” or “1:m”: check if join keys are unique in left dataset.\\n“many_to_one” or “m:1”: check if join keys are unique in right dataset.\\n“many_to_many” or “m:m”: allowed, but does not result in checks.\\n\\n\\nNew in version 1.5.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.join',\n",
       "       'descriptions': 'Join columns of another DataFrame. Join columns with other DataFrame either on index or on a key\\ncolumn. Efficiently join multiple DataFrame objects by index at once by\\npassing a list.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'array',\n",
       "          'description': 'DataFrame, Series, or a list containing any combination of them. Index should be similar to one of the columns in this one. If a\\nSeries is passed, its name attribute must be set, and that will be\\nused as the column name in the resulting joined DataFrame.\\n'},\n",
       "         'on': {'type': 'string',\n",
       "          'description': 'str, list of str, or array-like, optional. Column or index level name(s) in the caller to join on the index\\nin other, otherwise joins index-on-index. If multiple\\nvalues given, the other DataFrame must have a MultiIndex. Can\\npass an array as the join key if it is not already contained in\\nthe calling DataFrame. Like an Excel VLOOKUP operation.\\n'},\n",
       "         'how': {'type': 'string',\n",
       "          'enum': ['left', ' right', ' outer', ' inner', ' cross'],\n",
       "          'description': '{‘left’, ‘right’, ‘outer’, ‘inner’, ‘cross’}, default ‘left’. How to handle the operation of the two objects.\\n\\nleft: use calling frame’s index (or column if on is specified)\\nright: use other’s index.\\nouter: form union of calling frame’s index (or column if on is\\nspecified) with other’s index, and sort it lexicographically.\\ninner: form intersection of calling frame’s index (or column if\\non is specified) with other’s index, preserving the order\\nof the calling’s one.\\ncross: creates the cartesian product from both frames, preserves the order\\nof the left keys.\\n\\n'},\n",
       "         'lsuffix': {'type': 'string',\n",
       "          'description': 'str, default ‘’. Suffix to use from left frame’s overlapping columns.\\n'},\n",
       "         'rsuffix': {'type': 'string',\n",
       "          'description': 'str, default ‘’. Suffix to use from right frame’s overlapping columns.\\n'},\n",
       "         'sort': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Order result DataFrame lexicographically by the join key. If False,\\nthe order of the join key depends on the join type (how keyword).\\n'},\n",
       "         'validate': {'type': 'string',\n",
       "          'description': 'str, optional. If specified, checks if join is of specified type.\\n\\n“one_to_one” or “1:1”: check if join keys are unique in both left\\nand right datasets.\\n“one_to_many” or “1:m”: check if join keys are unique in left dataset.\\n“many_to_one” or “m:1”: check if join keys are unique in right dataset.\\n“many_to_many” or “m:m”: allowed, but does not result in checks.\\n\\n\\nNew in version 1.5.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.update(other[,\\xa0join,\\xa0overwrite,\\xa0...])',\n",
       "      'func_desc': 'Modify in place using non-NA values from another DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.update.html#pandas.DataFrame.update',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.update',\n",
       "       'full_function': \"DataFrame.update(other, join='left', overwrite=True, filter_func=None, errors='ignore')\",\n",
       "       'function_text': 'Modify in place using non-NA values from another DataFrame. Aligns on indices. There is no return value.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.compare(other[,\\xa0align_axis,\\xa0...])',\n",
       "      'func_desc': 'Compare to another DataFrame and show the differences.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.compare.html#pandas.DataFrame.compare',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.compare',\n",
       "       'full_function': \"DataFrame.compare(other, align_axis=1, keep_shape=False, keep_equal=False, result_names=('self', 'other'))\",\n",
       "       'function_text': 'Compare to another DataFrame and show the differences.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.merge(right[,\\xa0how,\\xa0on,\\xa0left_on,\\xa0...])',\n",
       "      'func_desc': 'Merge DataFrame or named Series objects with a database-style join.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html#pandas.DataFrame.merge',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.merge',\n",
       "       'full_function': \"DataFrame.merge(right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=None, indicator=False, validate=None)\",\n",
       "       'function_text': 'Merge DataFrame or named Series objects with a database-style join. A named Series object is treated as a DataFrame with a single named column. The join is done on columns or indexes. If joining columns on\\ncolumns, the DataFrame indexes will be ignored. Otherwise if joining indexes\\non indexes or indexes on a column or columns, the index will be passed on.\\nWhen performing a cross merge, no column specifications to merge on are\\nallowed. Warning If both key columns contain rows where the key is a null value, those\\nrows will be matched against each other. This is different from usual SQL\\njoin behaviour and can lead to unexpected results.',\n",
       "       'parameter_names_desc': [{'param_name': 'right',\n",
       "         'param_type': 'DataFrame or named Series',\n",
       "         'param_desc': 'Object to merge with.\\n'},\n",
       "        {'param_name': 'how',\n",
       "         'param_type': '{‘left’, ‘right’, ‘outer’, ‘inner’, ‘cross’}, default ‘inner’',\n",
       "         'param_desc': 'Type of merge to be performed.\\n\\nleft: use only keys from left frame, similar to a SQL left outer join;\\npreserve key order.\\nright: use only keys from right frame, similar to a SQL right outer join;\\npreserve key order.\\nouter: use union of keys from both frames, similar to a SQL full outer\\njoin; sort keys lexicographically.\\ninner: use intersection of keys from both frames, similar to a SQL inner\\njoin; preserve the order of the left keys.\\ncross: creates the cartesian product from both frames, preserves the order\\nof the left keys.\\n\\n'},\n",
       "        {'param_name': 'on',\n",
       "         'param_type': 'label or list',\n",
       "         'param_desc': 'Column or index level names to join on. These must be found in both\\nDataFrames. If on is None and not merging on indexes then this defaults\\nto the intersection of the columns in both DataFrames.\\n'},\n",
       "        {'param_name': 'left_on',\n",
       "         'param_type': 'label or list, or array-like',\n",
       "         'param_desc': 'Column or index level names to join on in the left DataFrame. Can also\\nbe an array or list of arrays of the length of the left DataFrame.\\nThese arrays are treated as if they are columns.\\n'},\n",
       "        {'param_name': 'right_on',\n",
       "         'param_type': 'label or list, or array-like',\n",
       "         'param_desc': 'Column or index level names to join on in the right DataFrame. Can also\\nbe an array or list of arrays of the length of the right DataFrame.\\nThese arrays are treated as if they are columns.\\n'},\n",
       "        {'param_name': 'left_index',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Use the index from the left DataFrame as the join key(s). If it is a\\nMultiIndex, the number of keys in the other DataFrame (either the index\\nor a number of columns) must match the number of levels.\\n'},\n",
       "        {'param_name': 'right_index',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Use the index from the right DataFrame as the join key. Same caveats as\\nleft_index.\\n'},\n",
       "        {'param_name': 'sort',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Sort the join keys lexicographically in the result DataFrame. If False,\\nthe order of the join keys depends on the join type (how keyword).\\n'},\n",
       "        {'param_name': 'suffixes',\n",
       "         'param_type': 'list-like, default is (“_x”, “_y”)',\n",
       "         'param_desc': 'A length-2 sequence where each element is optionally a string\\nindicating the suffix to add to overlapping column names in\\nleft and right respectively. Pass a value of None instead\\nof a string to indicate that the column name from left or\\nright should be left as-is, with no suffix. At least one of the\\nvalues must not be None.\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If False, avoid copy if possible.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'},\n",
       "        {'param_name': 'indicator',\n",
       "         'param_type': 'bool or str, default False',\n",
       "         'param_desc': 'If True, adds a column to the output DataFrame called “_merge” with\\ninformation on the source of each row. The column can be given a different\\nname by providing a string argument. The column will have a Categorical\\ntype with the value of “left_only” for observations whose merge key only\\nappears in the left DataFrame, “right_only” for observations\\nwhose merge key only appears in the right DataFrame, and “both”\\nif the observation’s merge key is found in both DataFrames.\\n'},\n",
       "        {'param_name': 'validate',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'If specified, checks if merge is of specified type.\\n\\n“one_to_one” or “1:1”: check if merge keys are unique in both\\nleft and right datasets.\\n“one_to_many” or “1:m”: check if merge keys are unique in left\\ndataset.\\n“many_to_one” or “m:1”: check if merge keys are unique in right\\ndataset.\\n“many_to_many” or “m:m”: allowed, but does not result in checks.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.merge',\n",
       "       'descriptions': 'Merge DataFrame or named Series objects with a database-style join. A named Series object is treated as a DataFrame with a single named column. The join is done on columns or indexes. If joining columns on\\ncolumns, the DataFrame indexes will be ignored. Otherwise if joining indexes\\non indexes or indexes on a column or columns, the index will be passed on.\\nWhen performing a cross merge, no column specifications to merge on are\\nallowed. Warning If both key columns contain rows where the key is a null value, those\\nrows will be matched against each other. This is different from usual SQL\\njoin behaviour and can lead to unexpected results.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'right': {'type': 'DataFrame or named Series',\n",
       "          'description': 'DataFrame or named Series. Object to merge with.\\n'},\n",
       "         'how': {'type': 'string',\n",
       "          'enum': ['left', ' right', ' outer', ' inner', ' cross'],\n",
       "          'description': '{‘left’, ‘right’, ‘outer’, ‘inner’, ‘cross’}, default ‘inner’. Type of merge to be performed.\\n\\nleft: use only keys from left frame, similar to a SQL left outer join;\\npreserve key order.\\nright: use only keys from right frame, similar to a SQL right outer join;\\npreserve key order.\\nouter: use union of keys from both frames, similar to a SQL full outer\\njoin; sort keys lexicographically.\\ninner: use intersection of keys from both frames, similar to a SQL inner\\njoin; preserve the order of the left keys.\\ncross: creates the cartesian product from both frames, preserves the order\\nof the left keys.\\n\\n'},\n",
       "         'on': {'type': 'array',\n",
       "          'description': 'label or list. Column or index level names to join on. These must be found in both\\nDataFrames. If on is None and not merging on indexes then this defaults\\nto the intersection of the columns in both DataFrames.\\n'},\n",
       "         'left_on': {'type': 'array',\n",
       "          'description': 'label or list, or array-like. Column or index level names to join on in the left DataFrame. Can also\\nbe an array or list of arrays of the length of the left DataFrame.\\nThese arrays are treated as if they are columns.\\n'},\n",
       "         'right_on': {'type': 'array',\n",
       "          'description': 'label or list, or array-like. Column or index level names to join on in the right DataFrame. Can also\\nbe an array or list of arrays of the length of the right DataFrame.\\nThese arrays are treated as if they are columns.\\n'},\n",
       "         'left_index': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Use the index from the left DataFrame as the join key(s). If it is a\\nMultiIndex, the number of keys in the other DataFrame (either the index\\nor a number of columns) must match the number of levels.\\n'},\n",
       "         'right_index': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Use the index from the right DataFrame as the join key. Same caveats as\\nleft_index.\\n'},\n",
       "         'sort': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Sort the join keys lexicographically in the result DataFrame. If False,\\nthe order of the join keys depends on the join type (how keyword).\\n'},\n",
       "         'suffixes': {'type': 'array',\n",
       "          'description': 'list-like, default is (“_x”, “_y”). A length-2 sequence where each element is optionally a string\\nindicating the suffix to add to overlapping column names in\\nleft and right respectively. Pass a value of None instead\\nof a string to indicate that the column name from left or\\nright should be left as-is, with no suffix. At least one of the\\nvalues must not be None.\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If False, avoid copy if possible.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'},\n",
       "         'indicator': {'type': 'string',\n",
       "          'description': 'bool or str, default False. If True, adds a column to the output DataFrame called “_merge” with\\ninformation on the source of each row. The column can be given a different\\nname by providing a string argument. The column will have a Categorical\\ntype with the value of “left_only” for observations whose merge key only\\nappears in the left DataFrame, “right_only” for observations\\nwhose merge key only appears in the right DataFrame, and “both”\\nif the observation’s merge key is found in both DataFrames.\\n'},\n",
       "         'validate': {'type': 'string',\n",
       "          'description': 'str, optional. If specified, checks if merge is of specified type.\\n\\n“one_to_one” or “1:1”: check if merge keys are unique in both\\nleft and right datasets.\\n“one_to_many” or “1:m”: check if merge keys are unique in left\\ndataset.\\n“many_to_one” or “m:1”: check if merge keys are unique in right\\ndataset.\\n“many_to_many” or “m:m”: allowed, but does not result in checks.\\n\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Time Series-related': [{'func_name': 'DataFrame.asfreq(freq[,\\xa0method,\\xa0how,\\xa0...])',\n",
       "      'func_desc': 'Convert time series to specified frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.asfreq.html#pandas.DataFrame.asfreq',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.asfreq',\n",
       "       'full_function': 'DataFrame.asfreq(freq, method=None, how=None, normalize=False, fill_value=None)',\n",
       "       'function_text': 'Convert time series to specified frequency. Returns the original data conformed to a new index with the specified\\nfrequency. If the index of this Series/DataFrame is a PeriodIndex, the new index\\nis the result of transforming the original index with\\nPeriodIndex.asfreq (so the original index\\nwill map one-to-one to the new index). Otherwise, the new index will be equivalent to pd.date_range(start, end,\\nfreq=freq) where start and end are, respectively, the first and\\nlast entries in the original index (see pandas.date_range()). The\\nvalues corresponding to any timesteps in the new index which were not present\\nin the original index will be null (NaN), unless a method for filling\\nsuch unknowns is provided (see the method parameter below). The resample() method is more appropriate if an operation on each group of\\ntimesteps (such as an aggregate) is necessary to represent the data at the new\\nfrequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'freq',\n",
       "         'param_type': 'DateOffset or str',\n",
       "         'param_desc': 'Frequency DateOffset or string.\\n'},\n",
       "        {'param_name': 'method',\n",
       "         'param_type': '{‘backfill’/’bfill’, ‘pad’/’ffill’}, default None',\n",
       "         'param_desc': 'Method to use for filling holes in reindexed Series (note this\\ndoes not fill NaNs that already were present):\\n\\n‘pad’ / ‘ffill’: propagate last valid observation forward to next\\nvalid\\n‘backfill’ / ‘bfill’: use NEXT valid observation to fill.\\n\\n'},\n",
       "        {'param_name': 'how',\n",
       "         'param_type': '{‘start’, ‘end’}, default end',\n",
       "         'param_desc': 'For PeriodIndex only (see PeriodIndex.asfreq).\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to reset output index to midnight.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'scalar, optional',\n",
       "         'param_desc': 'Value to use for missing values, applied during upsampling (note\\nthis does not fill NaNs that already were present).\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.asfreq',\n",
       "       'descriptions': 'Convert time series to specified frequency. Returns the original data conformed to a new index with the specified\\nfrequency. If the index of this Series/DataFrame is a PeriodIndex, the new index\\nis the result of transforming the original index with\\nPeriodIndex.asfreq (so the original index\\nwill map one-to-one to the new index). Otherwise, the new index will be equivalent to pd.date_range(start, end,\\nfreq=freq) where start and end are, respectively, the first and\\nlast entries in the original index (see pandas.date_range()). The\\nvalues corresponding to any timesteps in the new index which were not present\\nin the original index will be null (NaN), unless a method for filling\\nsuch unknowns is provided (see the method parameter below). The resample() method is more appropriate if an operation on each group of\\ntimesteps (such as an aggregate) is necessary to represent the data at the new\\nfrequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'freq': {'type': 'string',\n",
       "          'description': 'DateOffset or str. Frequency DateOffset or string.\\n'},\n",
       "         'method': {'type': 'string',\n",
       "          'enum': ['backfill/bfill', ' pad/ffill'],\n",
       "          'description': '{‘backfill’/’bfill’, ‘pad’/’ffill’}, default None. Method to use for filling holes in reindexed Series (note this\\ndoes not fill NaNs that already were present):\\n\\n‘pad’ / ‘ffill’: propagate last valid observation forward to next\\nvalid\\n‘backfill’ / ‘bfill’: use NEXT valid observation to fill.\\n\\n'},\n",
       "         'how': {'type': 'string',\n",
       "          'enum': ['start', ' end'],\n",
       "          'description': '{‘start’, ‘end’}, default end. For PeriodIndex only (see PeriodIndex.asfreq).\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to reset output index to midnight.\\n'},\n",
       "         'fill_value': {'type': 'scalar, optional',\n",
       "          'description': 'scalar, optional. Value to use for missing values, applied during upsampling (note\\nthis does not fill NaNs that already were present).\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.shift([periods,\\xa0freq,\\xa0axis,\\xa0...])',\n",
       "      'func_desc': 'Shift index by desired number of periods with an optional time freq.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shift.html#pandas.DataFrame.shift',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.shift',\n",
       "       'full_function': 'DataFrame.shift(periods=1, freq=None, axis=0, fill_value=_NoDefault.no_default, suffix=None)',\n",
       "       'function_text': 'Shift index by desired number of periods with an optional time freq. When freq is not passed, shift the index without realigning the data.\\nIf freq is passed (in this case, the index must be date or datetime,\\nor it will raise a NotImplementedError), the index will be\\nincreased using the periods and the freq. freq can be inferred\\nwhen specified as “infer” as long as either freq or inferred_freq\\nattribute is set in the index.',\n",
       "       'parameter_names_desc': [{'param_name': 'periods',\n",
       "         'param_type': 'int or Sequence',\n",
       "         'param_desc': 'Number of periods to shift. Can be positive or negative.\\nIf an iterable of ints, the data will be shifted once by each int.\\nThis is equivalent to shifting by one value at a time and\\nconcatenating all resulting frames. The resulting columns will have\\nthe shift suffixed to their column names. For multiple periods,\\naxis must not be 1.\\n'},\n",
       "        {'param_name': 'freq',\n",
       "         'param_type': 'DateOffset, tseries.offsets, timedelta, or str, optional',\n",
       "         'param_desc': 'Offset to use from the tseries module or time rule (e.g. ‘EOM’).\\nIf freq is specified then the index values are shifted but the\\ndata is not realigned. That is, use freq if you would like to\\nextend the index when shifting and preserve the original data.\\nIf freq is specified as “infer” then it will be inferred from\\nthe freq or inferred_freq attributes of the index. If neither of\\nthose attributes exist, a ValueError is thrown.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’, None}, default None',\n",
       "         'param_desc': 'Shift direction. For Series this parameter is unused and defaults to 0.\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'object, optional',\n",
       "         'param_desc': 'The scalar value to use for newly introduced missing values.\\nthe default depends on the dtype of self.\\nFor numeric data, np.nan is used.\\nFor datetime, timedelta, or period data, etc. NaT is used.\\nFor extension dtypes, self.dtype.na_value is used.\\n'},\n",
       "        {'param_name': 'suffix',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'If str and periods is an iterable, this is added after the column\\nname and before the shift value for each shifted column name.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.shift',\n",
       "       'descriptions': 'Shift index by desired number of periods with an optional time freq. When freq is not passed, shift the index without realigning the data.\\nIf freq is passed (in this case, the index must be date or datetime,\\nor it will raise a NotImplementedError), the index will be\\nincreased using the periods and the freq. freq can be inferred\\nwhen specified as “infer” as long as either freq or inferred_freq\\nattribute is set in the index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'periods': {'type': 'integer',\n",
       "          'description': 'int or Sequence. Number of periods to shift. Can be positive or negative.\\nIf an iterable of ints, the data will be shifted once by each int.\\nThis is equivalent to shifting by one value at a time and\\nconcatenating all resulting frames. The resulting columns will have\\nthe shift suffixed to their column names. For multiple periods,\\naxis must not be 1.\\n'},\n",
       "         'freq': {'type': 'string',\n",
       "          'description': 'DateOffset, tseries.offsets, timedelta, or str, optional. Offset to use from the tseries module or time rule (e.g. ‘EOM’).\\nIf freq is specified then the index values are shifted but the\\ndata is not realigned. That is, use freq if you would like to\\nextend the index when shifting and preserve the original data.\\nIf freq is specified as “infer” then it will be inferred from\\nthe freq or inferred_freq attributes of the index. If neither of\\nthose attributes exist, a ValueError is thrown.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns', ' None'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’, None}, default None. Shift direction. For Series this parameter is unused and defaults to 0.\\n'},\n",
       "         'fill_value': {'type': 'object',\n",
       "          'description': 'object, optional. The scalar value to use for newly introduced missing values.\\nthe default depends on the dtype of self.\\nFor numeric data, np.nan is used.\\nFor datetime, timedelta, or period data, etc. NaT is used.\\nFor extension dtypes, self.dtype.na_value is used.\\n'},\n",
       "         'suffix': {'type': 'string',\n",
       "          'description': 'str, optional. If str and periods is an iterable, this is added after the column\\nname and before the shift value for each shifted column name.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.last_valid_index()',\n",
       "      'func_desc': 'Return index for last non-NA value or None, if no non-NA value is found.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.last_valid_index.html#pandas.DataFrame.last_valid_index',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.last_valid_index',\n",
       "       'full_function': 'DataFrame.last_valid_index()',\n",
       "       'function_text': 'Return index for last non-NA value or None, if no non-NA value is found.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.to_period([freq,\\xa0axis,\\xa0copy])',\n",
       "      'func_desc': 'Convert DataFrame from DatetimeIndex to PeriodIndex.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_period.html#pandas.DataFrame.to_period',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_period',\n",
       "       'full_function': 'DataFrame.to_period(freq=None, axis=0, copy=None)',\n",
       "       'function_text': 'Convert DataFrame from DatetimeIndex to PeriodIndex. Convert DataFrame from DatetimeIndex to PeriodIndex with desired\\nfrequency (inferred from index if not passed).',\n",
       "       'parameter_names_desc': [{'param_name': 'freq',\n",
       "         'param_type': 'str, default',\n",
       "         'param_desc': 'Frequency of the PeriodIndex.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'The axis to convert (the index by default).\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If False then underlying input data is not copied.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.to_period',\n",
       "       'descriptions': 'Convert DataFrame from DatetimeIndex to PeriodIndex. Convert DataFrame from DatetimeIndex to PeriodIndex with desired\\nfrequency (inferred from index if not passed).',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'freq': {'type': 'string',\n",
       "          'description': 'str, default. Frequency of the PeriodIndex.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. The axis to convert (the index by default).\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If False then underlying input data is not copied.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.tz_convert(tz[,\\xa0axis,\\xa0level,\\xa0copy])',\n",
       "      'func_desc': 'Convert tz-aware axis to target time zone.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tz_convert.html#pandas.DataFrame.tz_convert',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.tz_convert',\n",
       "       'full_function': 'DataFrame.tz_convert(tz, axis=0, level=None, copy=None)',\n",
       "       'function_text': 'Convert tz-aware axis to target time zone.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.asof(where[,\\xa0subset])',\n",
       "      'func_desc': 'Return the last row(s) without any NaNs before where.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.asof.html#pandas.DataFrame.asof',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.asof',\n",
       "       'full_function': 'DataFrame.asof(where, subset=None)',\n",
       "       'function_text': 'Return the last row(s) without any NaNs before where. The last row (for each element in where, if list) without any\\nNaN is taken.\\nIn case of a DataFrame, the last row without NaN\\nconsidering only the subset of columns (if not None) If there is no good value, NaN is returned for a Series or\\na Series of NaN values for a DataFrame',\n",
       "       'parameter_names_desc': [{'param_name': 'where',\n",
       "         'param_type': 'date or array-like of dates',\n",
       "         'param_desc': 'Date(s) before which the last row(s) are returned.\\n'},\n",
       "        {'param_name': 'subset',\n",
       "         'param_type': 'str or array-like of str, default None',\n",
       "         'param_desc': 'For DataFrame, if not None, only use these columns to\\ncheck for NaNs.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.asof',\n",
       "       'descriptions': 'Return the last row(s) without any NaNs before where. The last row (for each element in where, if list) without any\\nNaN is taken.\\nIn case of a DataFrame, the last row without NaN\\nconsidering only the subset of columns (if not None) If there is no good value, NaN is returned for a Series or\\na Series of NaN values for a DataFrame',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'where': {'type': 'array',\n",
       "          'description': 'date or array-like of dates. Date(s) before which the last row(s) are returned.\\n'},\n",
       "         'subset': {'type': 'string',\n",
       "          'description': 'str or array-like of str, default None. For DataFrame, if not None, only use these columns to\\ncheck for NaNs.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.first_valid_index()',\n",
       "      'func_desc': 'Return index for first non-NA value or None, if no non-NA value is found.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.first_valid_index.html#pandas.DataFrame.first_valid_index',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.first_valid_index',\n",
       "       'full_function': 'DataFrame.first_valid_index()',\n",
       "       'function_text': 'Return index for first non-NA value or None, if no non-NA value is found.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.resample(rule[,\\xa0axis,\\xa0closed,\\xa0...])',\n",
       "      'func_desc': 'Resample time-series data.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html#pandas.DataFrame.resample',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.resample',\n",
       "       'full_function': \"DataFrame.resample(rule, axis=_NoDefault.no_default, closed=None, label=None, convention=_NoDefault.no_default, kind=_NoDefault.no_default, on=None, level=None, origin='start_day', offset=None, group_keys=False)\",\n",
       "       'function_text': 'Resample time-series data. Convenience method for frequency conversion and resampling of time series.\\nThe object must have a datetime-like index (DatetimeIndex, PeriodIndex,\\nor TimedeltaIndex), or the caller must pass the label of a datetime-like\\nseries/index to the on/level keyword parameter.',\n",
       "       'parameter_names_desc': [{'param_name': 'rule',\n",
       "         'param_type': 'DateOffset, Timedelta or str',\n",
       "         'param_desc': 'The offset string or object representing target conversion.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'Which axis to use for up- or down-sampling. For Series this parameter\\nis unused and defaults to 0. Must be\\nDatetimeIndex, TimedeltaIndex or PeriodIndex.\\n\\nDeprecated since version 2.0.0: Use frame.T.resample(…) instead.\\n\\n'},\n",
       "        {'param_name': 'closed',\n",
       "         'param_type': '{‘right’, ‘left’}, default None',\n",
       "         'param_desc': 'Which side of bin interval is closed. The default is ‘left’\\nfor all frequency offsets except for ‘ME’, ‘YE’, ‘QE’, ‘BME’,\\n‘BA’, ‘BQE’, and ‘W’ which all have a default of ‘right’.\\n'},\n",
       "        {'param_name': 'label',\n",
       "         'param_type': '{‘right’, ‘left’}, default None',\n",
       "         'param_desc': 'Which bin edge label to label bucket with. The default is ‘left’\\nfor all frequency offsets except for ‘ME’, ‘YE’, ‘QE’, ‘BME’,\\n‘BA’, ‘BQE’, and ‘W’ which all have a default of ‘right’.\\n'},\n",
       "        {'param_name': 'convention',\n",
       "         'param_type': '{‘start’, ‘end’, ‘s’, ‘e’}, default ‘start’',\n",
       "         'param_desc': 'For PeriodIndex only, controls whether to use the start or\\nend of rule.\\n\\nDeprecated since version 2.2.0: Convert PeriodIndex to DatetimeIndex before resampling instead.\\n\\n'},\n",
       "        {'param_name': 'kind',\n",
       "         'param_type': '{‘timestamp’, ‘period’}, optional, default None',\n",
       "         'param_desc': 'Pass ‘timestamp’ to convert the resulting index to a\\nDateTimeIndex or ‘period’ to convert it to a PeriodIndex.\\nBy default the input representation is retained.\\n\\nDeprecated since version 2.2.0: Convert index to desired type explicitly instead.\\n\\n'},\n",
       "        {'param_name': 'on',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'For a DataFrame, column to use instead of index for resampling.\\nColumn must be datetime-like.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'str or int, optional',\n",
       "         'param_desc': 'For a MultiIndex, level (name or number) to use for\\nresampling. level must be datetime-like.\\n'},\n",
       "        {'param_name': 'origin',\n",
       "         'param_type': 'Timestamp or str, default ‘start_day’',\n",
       "         'param_desc': 'The timestamp on which to adjust the grouping. The timezone of origin\\nmust match the timezone of the index.\\nIf string, must be one of the following:\\n\\n‘epoch’: origin is 1970-01-01\\n‘start’: origin is the first value of the timeseries\\n‘start_day’: origin is the first day at midnight of the timeseries\\n‘end’: origin is the last value of the timeseries\\n‘end_day’: origin is the ceiling midnight of the last day\\n\\n\\nNew in version 1.3.0.\\n\\n\\nNote\\nOnly takes effect for Tick-frequencies (i.e. fixed frequencies like\\ndays, hours, and minutes, rather than months or quarters).\\n\\n'},\n",
       "        {'param_name': 'offset',\n",
       "         'param_type': 'Timedelta or str, default is None',\n",
       "         'param_desc': 'An offset timedelta added to the origin.\\n'},\n",
       "        {'param_name': 'group_keys',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to include the group keys in the result index when using\\n.apply() on the resampled object.\\n\\nNew in version 1.5.0: Not specifying group_keys will retain values-dependent behavior\\nfrom pandas 1.4 and earlier (see pandas 1.5.0 Release notes for examples).\\n\\n\\nChanged in version 2.0.0: group_keys now defaults to False.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.resample',\n",
       "       'descriptions': 'Resample time-series data. Convenience method for frequency conversion and resampling of time series.\\nThe object must have a datetime-like index (DatetimeIndex, PeriodIndex,\\nor TimedeltaIndex), or the caller must pass the label of a datetime-like\\nseries/index to the on/level keyword parameter.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'rule': {'type': 'string',\n",
       "          'description': 'DateOffset, Timedelta or str. The offset string or object representing target conversion.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. Which axis to use for up- or down-sampling. For Series this parameter\\nis unused and defaults to 0. Must be\\nDatetimeIndex, TimedeltaIndex or PeriodIndex.\\n\\nDeprecated since version 2.0.0: Use frame.T.resample(…) instead.\\n\\n'},\n",
       "         'closed': {'type': 'string',\n",
       "          'enum': ['right', ' left'],\n",
       "          'description': '{‘right’, ‘left’}, default None. Which side of bin interval is closed. The default is ‘left’\\nfor all frequency offsets except for ‘ME’, ‘YE’, ‘QE’, ‘BME’,\\n‘BA’, ‘BQE’, and ‘W’ which all have a default of ‘right’.\\n'},\n",
       "         'label': {'type': 'string',\n",
       "          'enum': ['right', ' left'],\n",
       "          'description': '{‘right’, ‘left’}, default None. Which bin edge label to label bucket with. The default is ‘left’\\nfor all frequency offsets except for ‘ME’, ‘YE’, ‘QE’, ‘BME’,\\n‘BA’, ‘BQE’, and ‘W’ which all have a default of ‘right’.\\n'},\n",
       "         'convention': {'type': 'string',\n",
       "          'enum': ['start', ' end', ' s', ' e'],\n",
       "          'description': '{‘start’, ‘end’, ‘s’, ‘e’}, default ‘start’. For PeriodIndex only, controls whether to use the start or\\nend of rule.\\n\\nDeprecated since version 2.2.0: Convert PeriodIndex to DatetimeIndex before resampling instead.\\n\\n'},\n",
       "         'kind': {'type': 'string',\n",
       "          'enum': ['timestamp', ' period'],\n",
       "          'description': '{‘timestamp’, ‘period’}, optional, default None. Pass ‘timestamp’ to convert the resulting index to a\\nDateTimeIndex or ‘period’ to convert it to a PeriodIndex.\\nBy default the input representation is retained.\\n\\nDeprecated since version 2.2.0: Convert index to desired type explicitly instead.\\n\\n'},\n",
       "         'on': {'type': 'string',\n",
       "          'description': 'str, optional. For a DataFrame, column to use instead of index for resampling.\\nColumn must be datetime-like.\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'str or int, optional. For a MultiIndex, level (name or number) to use for\\nresampling. level must be datetime-like.\\n'},\n",
       "         'origin': {'type': 'string',\n",
       "          'description': 'Timestamp or str, default ‘start_day’. The timestamp on which to adjust the grouping. The timezone of origin\\nmust match the timezone of the index.\\nIf string, must be one of the following:\\n\\n‘epoch’: origin is 1970-01-01\\n‘start’: origin is the first value of the timeseries\\n‘start_day’: origin is the first day at midnight of the timeseries\\n‘end’: origin is the last value of the timeseries\\n‘end_day’: origin is the ceiling midnight of the last day\\n\\n\\nNew in version 1.3.0.\\n\\n\\nNote\\nOnly takes effect for Tick-frequencies (i.e. fixed frequencies like\\ndays, hours, and minutes, rather than months or quarters).\\n\\n'},\n",
       "         'offset': {'type': 'string',\n",
       "          'description': 'Timedelta or str, default is None. An offset timedelta added to the origin.\\n'},\n",
       "         'group_keys': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to include the group keys in the result index when using\\n.apply() on the resampled object.\\n\\nNew in version 1.5.0: Not specifying group_keys will retain values-dependent behavior\\nfrom pandas 1.4 and earlier (see pandas 1.5.0 Release notes for examples).\\n\\n\\nChanged in version 2.0.0: group_keys now defaults to False.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.to_timestamp([freq,\\xa0how,\\xa0axis,\\xa0copy])',\n",
       "      'func_desc': 'Cast to DatetimeIndex of timestamps, at beginning of period.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_timestamp.html#pandas.DataFrame.to_timestamp',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_timestamp',\n",
       "       'full_function': \"DataFrame.to_timestamp(freq=None, how='start', axis=0, copy=None)\",\n",
       "       'function_text': 'Cast to DatetimeIndex of timestamps, at beginning of period.',\n",
       "       'parameter_names_desc': [{'param_name': 'freq',\n",
       "         'param_type': 'str, default frequency of PeriodIndex',\n",
       "         'param_desc': 'Desired frequency.\\n'},\n",
       "        {'param_name': 'how',\n",
       "         'param_type': '{‘s’, ‘e’, ‘start’, ‘end’}',\n",
       "         'param_desc': 'Convention for converting period to timestamp; start of period\\nvs. end.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'The axis to convert (the index by default).\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If False then underlying input data is not copied.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.to_timestamp',\n",
       "       'descriptions': 'Cast to DatetimeIndex of timestamps, at beginning of period.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'freq': {'type': 'string',\n",
       "          'description': 'str, default frequency of PeriodIndex. Desired frequency.\\n'},\n",
       "         'how': {'type': 'string',\n",
       "          'enum': ['s', ' e', ' start', ' end'],\n",
       "          'description': '{‘s’, ‘e’, ‘start’, ‘end’}. Convention for converting period to timestamp; start of period\\nvs. end.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. The axis to convert (the index by default).\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If False then underlying input data is not copied.\\n\\nNote\\nThe copy keyword will change behavior in pandas 3.0.\\nCopy-on-Write\\nwill be enabled by default, which means that all methods with a\\ncopy keyword will use a lazy copy mechanism to defer the copy and\\nignore the copy keyword. The copy keyword will be removed in a\\nfuture version of pandas.\\nYou can already get the future behavior and improvements through\\nenabling copy on write pd.options.mode.copy_on_write = True\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.tz_localize(tz[,\\xa0axis,\\xa0level,\\xa0...])',\n",
       "      'func_desc': 'Localize tz-naive index of a Series or DataFrame to target time zone.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tz_localize.html#pandas.DataFrame.tz_localize',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.tz_localize',\n",
       "       'full_function': \"DataFrame.tz_localize(tz, axis=0, level=None, copy=None, ambiguous='raise', nonexistent='raise')\",\n",
       "       'function_text': 'Localize tz-naive index of a Series or DataFrame to target time zone. This operation localizes the Index. To localize the values in a\\ntimezone-naive Series, use Series.dt.tz_localize().',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'Flags': [{'func_name': 'Flags(obj,\\xa0*,\\xa0allows_duplicate_labels)',\n",
       "      'func_desc': 'Flags that apply to pandas objects.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Flags.html#pandas.Flags',\n",
       "      'function_definitions': {'function_name': 'pandas.Flags',\n",
       "       'full_function': 'class pandas.Flags(obj, *, allows_duplicate_labels)',\n",
       "       'function_text': 'Flags that apply to pandas objects.',\n",
       "       'parameter_names_desc': [{'param_name': 'obj',\n",
       "         'param_type': 'Series or DataFrame',\n",
       "         'param_desc': 'The object these flags are associated with.\\n'},\n",
       "        {'param_name': 'allows_duplicate_labels',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to allow duplicate labels in this object. By default,\\nduplicate labels are permitted. Setting this to False will\\ncause an errors.DuplicateLabelError to be raised when\\nindex (or columns for DataFrame) is not unique, or any\\nsubsequent operation on introduces duplicates.\\nSee Disallowing Duplicate Labels for more.\\n\\nWarning\\nThis is an experimental feature. Currently, many methods fail to\\npropagate the allows_duplicate_labels value. In future versions\\nit is expected that every method taking or returning one or more\\nDataFrame or Series objects will propagate allows_duplicate_labels.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Flags',\n",
       "       'descriptions': 'Flags that apply to pandas objects.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'obj': {'type': 'Series or DataFrame',\n",
       "          'description': 'Series or DataFrame. The object these flags are associated with.\\n'},\n",
       "         'allows_duplicate_labels': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to allow duplicate labels in this object. By default,\\nduplicate labels are permitted. Setting this to False will\\ncause an errors.DuplicateLabelError to be raised when\\nindex (or columns for DataFrame) is not unique, or any\\nsubsequent operation on introduces duplicates.\\nSee Disallowing Duplicate Labels for more.\\n\\nWarning\\nThis is an experimental feature. Currently, many methods fail to\\npropagate the allows_duplicate_labels value. In future versions\\nit is expected that every method taking or returning one or more\\nDataFrame or Series objects will propagate allows_duplicate_labels.\\n\\n'}},\n",
       "        'required': ['obj']}}}]},\n",
       "   {'Metadata': [{'func_name': 'DataFrame.attrs',\n",
       "      'func_desc': 'Dictionary of global attributes of this dataset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.attrs.html#pandas.DataFrame.attrs',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.attrs',\n",
       "       'full_function': 'property DataFrame.attrs',\n",
       "       'function_text': 'Dictionary of global attributes of this dataset. Warning attrs is experimental and may change without warning. See also Global flags applying to this object. Notes Many operations that create new datasets will copy attrs. Copies\\nare always deep so that changing attrs will only affect the\\npresent dataset. pandas.concat copies attrs only if all input\\ndatasets have the same attrs. Examples For Series: For DataFrame:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'Plotting': [{'func_name': 'DataFrame.plot([x,\\xa0y,\\xa0kind,\\xa0ax,\\xa0....])',\n",
       "      'func_desc': 'DataFrame plotting accessor and method',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html#pandas.DataFrame.plot',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.plot',\n",
       "       'full_function': 'DataFrame.plot(*args, **kwargs)',\n",
       "       'function_text': 'Make plots of Series or DataFrame. Uses the backend specified by the\\noption plotting.backend. By default, matplotlib is used.',\n",
       "       'parameter_names_desc': [{'param_name': 'data',\n",
       "         'param_type': 'Series or DataFrame',\n",
       "         'param_desc': 'The object for which the method is called.\\n'},\n",
       "        {'param_name': 'x',\n",
       "         'param_type': 'label or position, default None',\n",
       "         'param_desc': 'Only used if data is a DataFrame.\\n'},\n",
       "        {'param_name': 'y',\n",
       "         'param_type': 'label, position or list of label, positions, default None',\n",
       "         'param_desc': 'Allows plotting of one column versus another. Only used if data is a\\nDataFrame.\\n'},\n",
       "        {'param_name': 'kind',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'The kind of plot to produce:\\n\\n‘line’ : line plot (default)\\n‘bar’ : vertical bar plot\\n‘barh’ : horizontal bar plot\\n‘hist’ : histogram\\n‘box’ : boxplot\\n‘kde’ : Kernel Density Estimation plot\\n‘density’ : same as ‘kde’\\n‘area’ : area plot\\n‘pie’ : pie plot\\n‘scatter’ : scatter plot (DataFrame only)\\n‘hexbin’ : hexbin plot (DataFrame only)\\n\\n'},\n",
       "        {'param_name': 'ax',\n",
       "         'param_type': 'matplotlib axes object, default None',\n",
       "         'param_desc': 'An axes of the current figure.\\n'},\n",
       "        {'param_name': 'subplots',\n",
       "         'param_type': 'bool or sequence of iterables, default False',\n",
       "         'param_desc': 'Whether to group columns into subplots:\\n\\nFalse : No subplots will be used\\nTrue : Make separate subplots for each column.\\nsequence of iterables of column labels: Create a subplot for each\\ngroup of columns. For example [(‘a’, ‘c’), (‘b’, ‘d’)] will\\ncreate 2 subplots: one with columns ‘a’ and ‘c’, and one\\nwith columns ‘b’ and ‘d’. Remaining columns that aren’t specified\\nwill be plotted in additional subplots (one per column).\\n\\nNew in version 1.5.0.\\n\\n\\n\\n'},\n",
       "        {'param_name': 'sharex',\n",
       "         'param_type': 'bool, default True if ax is None else False',\n",
       "         'param_desc': 'In case subplots=True, share x axis and set some x axis labels\\nto invisible; defaults to True if ax is None otherwise False if\\nan ax is passed in; Be aware, that passing in both an ax and\\nsharex=True will alter all x axis labels for all axis in a figure.\\n'},\n",
       "        {'param_name': 'sharey',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'In case subplots=True, share y axis and set some y axis labels to invisible.\\n'},\n",
       "        {'param_name': 'layout',\n",
       "         'param_type': 'tuple, optional',\n",
       "         'param_desc': '(rows, columns) for the layout of subplots.\\n'},\n",
       "        {'param_name': 'figsize',\n",
       "         'param_type': 'a tuple (width, height) in inches',\n",
       "         'param_desc': 'Size of a figure object.\\n'},\n",
       "        {'param_name': 'use_index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Use index as ticks for x axis.\\n'},\n",
       "        {'param_name': 'title',\n",
       "         'param_type': 'str or list',\n",
       "         'param_desc': 'Title to use for the plot. If a string is passed, print the string\\nat the top of the figure. If a list is passed and subplots is\\nTrue, print each item in the list above the corresponding subplot.\\n'},\n",
       "        {'param_name': 'grid',\n",
       "         'param_type': 'bool, default None (matlab style default)',\n",
       "         'param_desc': 'Axis grid lines.\\n'},\n",
       "        {'param_name': 'legend',\n",
       "         'param_type': 'bool or {‘reverse’}',\n",
       "         'param_desc': 'Place legend on axis subplots.\\n'},\n",
       "        {'param_name': 'style',\n",
       "         'param_type': 'list or dict',\n",
       "         'param_desc': 'The matplotlib line style per column.\\n'},\n",
       "        {'param_name': 'logx',\n",
       "         'param_type': 'bool or ‘sym’, default False',\n",
       "         'param_desc': 'Use log scaling or symlog scaling on x axis.\\n'},\n",
       "        {'param_name': 'logy',\n",
       "         'param_type': 'bool or ‘sym’ default False',\n",
       "         'param_desc': 'Use log scaling or symlog scaling on y axis.\\n'},\n",
       "        {'param_name': 'loglog',\n",
       "         'param_type': 'bool or ‘sym’, default False',\n",
       "         'param_desc': 'Use log scaling or symlog scaling on both x and y axes.\\n'},\n",
       "        {'param_name': 'xticks',\n",
       "         'param_type': 'sequence',\n",
       "         'param_desc': 'Values to use for the xticks.\\n'},\n",
       "        {'param_name': 'yticks',\n",
       "         'param_type': 'sequence',\n",
       "         'param_desc': 'Values to use for the yticks.\\n'},\n",
       "        {'param_name': 'xlim',\n",
       "         'param_type': '2-tuple/list',\n",
       "         'param_desc': 'Set the x limits of the current axes.\\n'},\n",
       "        {'param_name': 'ylim',\n",
       "         'param_type': '2-tuple/list',\n",
       "         'param_desc': 'Set the y limits of the current axes.\\n'},\n",
       "        {'param_name': 'xlabel',\n",
       "         'param_type': 'label, optional',\n",
       "         'param_desc': 'Name to use for the xlabel on x-axis. Default uses index name as xlabel, or the\\nx-column name for planar plots.\\n\\nChanged in version 2.0.0: Now applicable to histograms.\\n\\n'},\n",
       "        {'param_name': 'ylabel',\n",
       "         'param_type': 'label, optional',\n",
       "         'param_desc': 'Name to use for the ylabel on y-axis. Default will show no ylabel, or the\\ny-column name for planar plots.\\n\\nChanged in version 2.0.0: Now applicable to histograms.\\n\\n'},\n",
       "        {'param_name': 'rot',\n",
       "         'param_type': 'float, default None',\n",
       "         'param_desc': 'Rotation for ticks (xticks for vertical, yticks for horizontal\\nplots).\\n'},\n",
       "        {'param_name': 'fontsize',\n",
       "         'param_type': 'float, default None',\n",
       "         'param_desc': 'Font size for xticks and yticks.\\n'},\n",
       "        {'param_name': 'colormap',\n",
       "         'param_type': 'str or matplotlib colormap object, default None',\n",
       "         'param_desc': 'Colormap to select colors from. If string, load colormap with that\\nname from matplotlib.\\n'},\n",
       "        {'param_name': 'colorbar',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'If True, plot colorbar (only relevant for ‘scatter’ and ‘hexbin’\\nplots).\\n'},\n",
       "        {'param_name': 'position',\n",
       "         'param_type': 'float',\n",
       "         'param_desc': 'Specify relative alignments for bar plot layout.\\nFrom 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\\n(center).\\n'},\n",
       "        {'param_name': 'table',\n",
       "         'param_type': 'bool, Series or DataFrame, default False',\n",
       "         'param_desc': 'If True, draw a table using the data in the DataFrame and the data\\nwill be transposed to meet matplotlib’s default layout.\\nIf a Series or DataFrame is passed, use passed data to draw a\\ntable.\\n'},\n",
       "        {'param_name': 'yerr',\n",
       "         'param_type': 'DataFrame, Series, array-like, dict and str',\n",
       "         'param_desc': 'See Plotting with Error Bars for\\ndetail.\\n'},\n",
       "        {'param_name': 'xerr',\n",
       "         'param_type': 'DataFrame, Series, array-like, dict and str',\n",
       "         'param_desc': 'Equivalent to yerr.\\n'},\n",
       "        {'param_name': 'stacked',\n",
       "         'param_type': 'bool, default False in line and bar plots, and True in area plot',\n",
       "         'param_desc': 'If True, create stacked plot.\\n'},\n",
       "        {'param_name': 'secondary_y',\n",
       "         'param_type': 'bool or sequence, default False',\n",
       "         'param_desc': 'Whether to plot on the secondary y-axis if a list/tuple, which\\ncolumns to plot on secondary y-axis.\\n'},\n",
       "        {'param_name': 'mark_right',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'When using a secondary_y axis, automatically mark the column\\nlabels with “(right)” in the legend.\\n'},\n",
       "        {'param_name': 'include_bool',\n",
       "         'param_type': 'bool, default is False',\n",
       "         'param_desc': 'If True, boolean values can be plotted.\\n'},\n",
       "        {'param_name': 'backend',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'Backend to use instead of the backend specified in the option\\nplotting.backend. For instance, ‘matplotlib’. Alternatively, to\\nspecify the plotting.backend for the whole session, set\\npd.options.plotting.backend.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.plot',\n",
       "       'descriptions': 'Make plots of Series or DataFrame. Uses the backend specified by the\\noption plotting.backend. By default, matplotlib is used.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'data': {'type': 'Series or DataFrame',\n",
       "          'description': 'Series or DataFrame. The object for which the method is called.\\n'},\n",
       "         'x': {'type': 'label or position, default None',\n",
       "          'description': 'label or position, default None. Only used if data is a DataFrame.\\n'},\n",
       "         'y': {'type': 'array',\n",
       "          'description': 'label, position or list of label, positions, default None. Allows plotting of one column versus another. Only used if data is a\\nDataFrame.\\n'},\n",
       "         'kind': {'type': 'string',\n",
       "          'description': 'str. The kind of plot to produce:\\n\\n‘line’ : line plot (default)\\n‘bar’ : vertical bar plot\\n‘barh’ : horizontal bar plot\\n‘hist’ : histogram\\n‘box’ : boxplot\\n‘kde’ : Kernel Density Estimation plot\\n‘density’ : same as ‘kde’\\n‘area’ : area plot\\n‘pie’ : pie plot\\n‘scatter’ : scatter plot (DataFrame only)\\n‘hexbin’ : hexbin plot (DataFrame only)\\n\\n'},\n",
       "         'ax': {'type': 'object',\n",
       "          'description': 'matplotlib axes object, default None. An axes of the current figure.\\n'},\n",
       "         'subplots': {'type': 'boolean',\n",
       "          'description': 'bool or sequence of iterables, default False. Whether to group columns into subplots:\\n\\nFalse : No subplots will be used\\nTrue : Make separate subplots for each column.\\nsequence of iterables of column labels: Create a subplot for each\\ngroup of columns. For example [(‘a’, ‘c’), (‘b’, ‘d’)] will\\ncreate 2 subplots: one with columns ‘a’ and ‘c’, and one\\nwith columns ‘b’ and ‘d’. Remaining columns that aren’t specified\\nwill be plotted in additional subplots (one per column).\\n\\nNew in version 1.5.0.\\n\\n\\n\\n'},\n",
       "         'sharex': {'type': 'boolean',\n",
       "          'description': 'bool, default True if ax is None else False. In case subplots=True, share x axis and set some x axis labels\\nto invisible; defaults to True if ax is None otherwise False if\\nan ax is passed in; Be aware, that passing in both an ax and\\nsharex=True will alter all x axis labels for all axis in a figure.\\n'},\n",
       "         'sharey': {'type': 'boolean',\n",
       "          'description': 'bool, default False. In case subplots=True, share y axis and set some y axis labels to invisible.\\n'},\n",
       "         'layout': {'type': 'tuple, optional',\n",
       "          'description': 'tuple, optional. (rows, columns) for the layout of subplots.\\n'},\n",
       "         'figsize': {'type': 'a tuple (width, height) in inches',\n",
       "          'description': 'a tuple (width, height) in inches. Size of a figure object.\\n'},\n",
       "         'use_index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Use index as ticks for x axis.\\n'},\n",
       "         'title': {'type': 'string',\n",
       "          'description': 'str or list. Title to use for the plot. If a string is passed, print the string\\nat the top of the figure. If a list is passed and subplots is\\nTrue, print each item in the list above the corresponding subplot.\\n'},\n",
       "         'grid': {'type': 'boolean',\n",
       "          'description': 'bool, default None (matlab style default). Axis grid lines.\\n'},\n",
       "         'legend': {'type': 'boolean',\n",
       "          'description': 'bool or {‘reverse’}. Place legend on axis subplots.\\n'},\n",
       "         'style': {'type': 'array',\n",
       "          'description': 'list or dict. The matplotlib line style per column.\\n'},\n",
       "         'logx': {'type': 'boolean',\n",
       "          'description': 'bool or ‘sym’, default False. Use log scaling or symlog scaling on x axis.\\n'},\n",
       "         'logy': {'type': 'boolean',\n",
       "          'description': 'bool or ‘sym’ default False. Use log scaling or symlog scaling on y axis.\\n'},\n",
       "         'loglog': {'type': 'boolean',\n",
       "          'description': 'bool or ‘sym’, default False. Use log scaling or symlog scaling on both x and y axes.\\n'},\n",
       "         'xticks': {'type': 'sequence',\n",
       "          'description': 'sequence. Values to use for the xticks.\\n'},\n",
       "         'yticks': {'type': 'sequence',\n",
       "          'description': 'sequence. Values to use for the yticks.\\n'},\n",
       "         'xlim': {'type': 'array',\n",
       "          'description': '2-tuple/list. Set the x limits of the current axes.\\n'},\n",
       "         'ylim': {'type': 'array',\n",
       "          'description': '2-tuple/list. Set the y limits of the current axes.\\n'},\n",
       "         'xlabel': {'type': 'label, optional',\n",
       "          'description': 'label, optional. Name to use for the xlabel on x-axis. Default uses index name as xlabel, or the\\nx-column name for planar plots.\\n\\nChanged in version 2.0.0: Now applicable to histograms.\\n\\n'},\n",
       "         'ylabel': {'type': 'label, optional',\n",
       "          'description': 'label, optional. Name to use for the ylabel on y-axis. Default will show no ylabel, or the\\ny-column name for planar plots.\\n\\nChanged in version 2.0.0: Now applicable to histograms.\\n\\n'},\n",
       "         'rot': {'type': 'float',\n",
       "          'description': 'float, default None. Rotation for ticks (xticks for vertical, yticks for horizontal\\nplots).\\n'},\n",
       "         'fontsize': {'type': 'float',\n",
       "          'description': 'float, default None. Font size for xticks and yticks.\\n'},\n",
       "         'colormap': {'type': 'string',\n",
       "          'description': 'str or matplotlib colormap object, default None. Colormap to select colors from. If string, load colormap with that\\nname from matplotlib.\\n'},\n",
       "         'colorbar': {'type': 'boolean',\n",
       "          'description': 'bool, optional. If True, plot colorbar (only relevant for ‘scatter’ and ‘hexbin’\\nplots).\\n'},\n",
       "         'position': {'type': 'float',\n",
       "          'description': 'float. Specify relative alignments for bar plot layout.\\nFrom 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\\n(center).\\n'},\n",
       "         'table': {'type': 'boolean',\n",
       "          'description': 'bool, Series or DataFrame, default False. If True, draw a table using the data in the DataFrame and the data\\nwill be transposed to meet matplotlib’s default layout.\\nIf a Series or DataFrame is passed, use passed data to draw a\\ntable.\\n'},\n",
       "         'yerr': {'type': 'string',\n",
       "          'description': 'DataFrame, Series, array-like, dict and str. See Plotting with Error Bars for\\ndetail.\\n'},\n",
       "         'xerr': {'type': 'string',\n",
       "          'description': 'DataFrame, Series, array-like, dict and str. Equivalent to yerr.\\n'},\n",
       "         'stacked': {'type': 'boolean',\n",
       "          'description': 'bool, default False in line and bar plots, and True in area plot. If True, create stacked plot.\\n'},\n",
       "         'secondary_y': {'type': 'boolean',\n",
       "          'description': 'bool or sequence, default False. Whether to plot on the secondary y-axis if a list/tuple, which\\ncolumns to plot on secondary y-axis.\\n'},\n",
       "         'mark_right': {'type': 'boolean',\n",
       "          'description': 'bool, default True. When using a secondary_y axis, automatically mark the column\\nlabels with “(right)” in the legend.\\n'},\n",
       "         'include_bool': {'type': 'boolean',\n",
       "          'description': 'bool, default is False. If True, boolean values can be plotted.\\n'},\n",
       "         'backend': {'type': 'string',\n",
       "          'description': 'str, default None. Backend to use instead of the backend specified in the option\\nplotting.backend. For instance, ‘matplotlib’. Alternatively, to\\nspecify the plotting.backend for the whole session, set\\npd.options.plotting.backend.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.plot.area([x,\\xa0y,\\xa0stacked])',\n",
       "      'func_desc': 'Draw a stacked area plot.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.area.html#pandas.DataFrame.plot.area',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.plot.area',\n",
       "       'full_function': 'DataFrame.plot.area(x=None, y=None, stacked=True, **kwargs)',\n",
       "       'function_text': 'Draw a stacked area plot. An area plot displays quantitative data visually.\\nThis function wraps the matplotlib area function.',\n",
       "       'parameter_names_desc': [{'param_name': 'x',\n",
       "         'param_type': 'label or position, optional',\n",
       "         'param_desc': 'Coordinates for the X axis. By default uses the index.\\n'},\n",
       "        {'param_name': 'y',\n",
       "         'param_type': 'label or position, optional',\n",
       "         'param_desc': 'Column to plot. By default uses all columns.\\n'},\n",
       "        {'param_name': 'stacked',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Area plots are stacked by default. Set to False to create a\\nunstacked plot.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.plot.area',\n",
       "       'descriptions': 'Draw a stacked area plot. An area plot displays quantitative data visually.\\nThis function wraps the matplotlib area function.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'x': {'type': 'label or position, optional',\n",
       "          'description': 'label or position, optional. Coordinates for the X axis. By default uses the index.\\n'},\n",
       "         'y': {'type': 'label or position, optional',\n",
       "          'description': 'label or position, optional. Column to plot. By default uses all columns.\\n'},\n",
       "         'stacked': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Area plots are stacked by default. Set to False to create a\\nunstacked plot.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.plot.barh([x,\\xa0y])',\n",
       "      'func_desc': 'Make a horizontal bar plot.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.barh.html#pandas.DataFrame.plot.barh',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.plot.barh',\n",
       "       'full_function': 'DataFrame.plot.barh(x=None, y=None, **kwargs)',\n",
       "       'function_text': 'Make a horizontal bar plot. A horizontal bar plot is a plot that presents quantitative data with\\nrectangular bars with lengths proportional to the values that they\\nrepresent. A bar plot shows comparisons among discrete categories. One\\naxis of the plot shows the specific categories being compared, and the\\nother axis represents a measured value.',\n",
       "       'parameter_names_desc': [{'param_name': 'x',\n",
       "         'param_type': 'label or position, optional',\n",
       "         'param_desc': 'Allows plotting of one column versus another. If not specified,\\nthe index of the DataFrame is used.\\n'},\n",
       "        {'param_name': 'y',\n",
       "         'param_type': 'label or position, optional',\n",
       "         'param_desc': 'Allows plotting of one column versus another. If not specified,\\nall numerical columns are used.\\n'},\n",
       "        {'param_name': 'color',\n",
       "         'param_type': 'str, array-like, or dict, optional',\n",
       "         'param_desc': 'The color for each of the DataFrame’s columns. Possible values are:\\n\\n\\nA single color string referred to by name, RGB or RGBA code,for instance ‘red’ or ‘#a98d19’.\\n\\n\\n\\n\\nA sequence of color strings referred to by name, RGB or RGBAcode, which will be used for each column recursively. For\\ninstance [‘green’,’yellow’] each column’s bar will be filled in\\ngreen or yellow, alternatively. If there is only a single column to\\nbe plotted, then only the first color from the color list will be\\nused.\\n\\n\\n\\n\\nA dict of the form {column namecolor}, so that each column will becolored accordingly. For example, if your columns are called a and\\nb, then passing {‘a’: ‘green’, ‘b’: ‘red’} will color bars for\\ncolumn a in green and bars for column b in red.\\n\\n\\n\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.plot.barh',\n",
       "       'descriptions': 'Make a horizontal bar plot. A horizontal bar plot is a plot that presents quantitative data with\\nrectangular bars with lengths proportional to the values that they\\nrepresent. A bar plot shows comparisons among discrete categories. One\\naxis of the plot shows the specific categories being compared, and the\\nother axis represents a measured value.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'x': {'type': 'label or position, optional',\n",
       "          'description': 'label or position, optional. Allows plotting of one column versus another. If not specified,\\nthe index of the DataFrame is used.\\n'},\n",
       "         'y': {'type': 'label or position, optional',\n",
       "          'description': 'label or position, optional. Allows plotting of one column versus another. If not specified,\\nall numerical columns are used.\\n'},\n",
       "         'color': {'type': 'string',\n",
       "          'description': 'str, array-like, or dict, optional. The color for each of the DataFrame’s columns. Possible values are:\\n\\n\\nA single color string referred to by name, RGB or RGBA code,for instance ‘red’ or ‘#a98d19’.\\n\\n\\n\\n\\nA sequence of color strings referred to by name, RGB or RGBAcode, which will be used for each column recursively. For\\ninstance [‘green’,’yellow’] each column’s bar will be filled in\\ngreen or yellow, alternatively. If there is only a single column to\\nbe plotted, then only the first color from the color list will be\\nused.\\n\\n\\n\\n\\nA dict of the form {column namecolor}, so that each column will becolored accordingly. For example, if your columns are called a and\\nb, then passing {‘a’: ‘green’, ‘b’: ‘red’} will color bars for\\ncolumn a in green and bars for column b in red.\\n\\n\\n\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.plot.density([bw_method,\\xa0ind])',\n",
       "      'func_desc': 'Generate Kernel Density Estimate plot using Gaussian kernels.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.density.html#pandas.DataFrame.plot.density',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.plot.density',\n",
       "       'full_function': 'DataFrame.plot.density(bw_method=None, ind=None, **kwargs)',\n",
       "       'function_text': 'Generate Kernel Density Estimate plot using Gaussian kernels. In statistics, kernel density estimation (KDE) is a non-parametric\\nway to estimate the probability density function (PDF) of a random\\nvariable. This function uses Gaussian kernels and includes automatic\\nbandwidth determination.',\n",
       "       'parameter_names_desc': [{'param_name': 'bw_method',\n",
       "         'param_type': 'str, scalar or callable, optional',\n",
       "         'param_desc': 'The method used to calculate the estimator bandwidth. This can be\\n‘scott’, ‘silverman’, a scalar constant or a callable.\\nIf None (default), ‘scott’ is used.\\nSee scipy.stats.gaussian_kde for more information.\\n'},\n",
       "        {'param_name': 'ind',\n",
       "         'param_type': 'NumPy array or int, optional',\n",
       "         'param_desc': 'Evaluation points for the estimated PDF. If None (default),\\n1000 equally spaced points are used. If ind is a NumPy array, the\\nKDE is evaluated at the points passed. If ind is an integer,\\nind number of equally spaced points are used.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.plot.density',\n",
       "       'descriptions': 'Generate Kernel Density Estimate plot using Gaussian kernels. In statistics, kernel density estimation (KDE) is a non-parametric\\nway to estimate the probability density function (PDF) of a random\\nvariable. This function uses Gaussian kernels and includes automatic\\nbandwidth determination.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'bw_method': {'type': 'string',\n",
       "          'description': 'str, scalar or callable, optional. The method used to calculate the estimator bandwidth. This can be\\n‘scott’, ‘silverman’, a scalar constant or a callable.\\nIf None (default), ‘scott’ is used.\\nSee scipy.stats.gaussian_kde for more information.\\n'},\n",
       "         'ind': {'type': 'integer',\n",
       "          'description': 'NumPy array or int, optional. Evaluation points for the estimated PDF. If None (default),\\n1000 equally spaced points are used. If ind is a NumPy array, the\\nKDE is evaluated at the points passed. If ind is an integer,\\nind number of equally spaced points are used.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.plot.hist([by,\\xa0bins])',\n",
       "      'func_desc': \"Draw one histogram of the DataFrame's columns.\",\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.hist.html#pandas.DataFrame.plot.hist',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.plot.hist',\n",
       "       'full_function': 'DataFrame.plot.hist(by=None, bins=10, **kwargs)',\n",
       "       'function_text': 'Draw one histogram of the DataFrame’s columns. A histogram is a representation of the distribution of data.\\nThis function groups the values of all given Series in the DataFrame\\ninto bins and draws all bins in one matplotlib.axes.Axes.\\nThis is useful when the DataFrame’s Series are in a similar scale.',\n",
       "       'parameter_names_desc': [{'param_name': 'by',\n",
       "         'param_type': 'str or sequence, optional',\n",
       "         'param_desc': 'Column in the DataFrame to group by.\\n\\nChanged in version 1.4.0: Previously, by is silently ignore and makes no groupings\\n\\n'},\n",
       "        {'param_name': 'bins',\n",
       "         'param_type': 'int, default 10',\n",
       "         'param_desc': 'Number of histogram bins to be used.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.plot.hist',\n",
       "       'descriptions': 'Draw one histogram of the DataFrame’s columns. A histogram is a representation of the distribution of data.\\nThis function groups the values of all given Series in the DataFrame\\ninto bins and draws all bins in one matplotlib.axes.Axes.\\nThis is useful when the DataFrame’s Series are in a similar scale.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'by': {'type': 'string',\n",
       "          'description': 'str or sequence, optional. Column in the DataFrame to group by.\\n\\nChanged in version 1.4.0: Previously, by is silently ignore and makes no groupings\\n\\n'},\n",
       "         'bins': {'type': 'integer',\n",
       "          'description': 'int, default 10. Number of histogram bins to be used.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.plot.line([x,\\xa0y])',\n",
       "      'func_desc': 'Plot Series or DataFrame as lines.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.line.html#pandas.DataFrame.plot.line',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.plot.line',\n",
       "       'full_function': 'DataFrame.plot.line(x=None, y=None, **kwargs)',\n",
       "       'function_text': 'Plot Series or DataFrame as lines. This function is useful to plot lines using DataFrame’s values\\nas coordinates.',\n",
       "       'parameter_names_desc': [{'param_name': 'x',\n",
       "         'param_type': 'label or position, optional',\n",
       "         'param_desc': 'Allows plotting of one column versus another. If not specified,\\nthe index of the DataFrame is used.\\n'},\n",
       "        {'param_name': 'y',\n",
       "         'param_type': 'label or position, optional',\n",
       "         'param_desc': 'Allows plotting of one column versus another. If not specified,\\nall numerical columns are used.\\n'},\n",
       "        {'param_name': 'color',\n",
       "         'param_type': 'str, array-like, or dict, optional',\n",
       "         'param_desc': 'The color for each of the DataFrame’s columns. Possible values are:\\n\\n\\nA single color string referred to by name, RGB or RGBA code,for instance ‘red’ or ‘#a98d19’.\\n\\n\\n\\n\\nA sequence of color strings referred to by name, RGB or RGBAcode, which will be used for each column recursively. For\\ninstance [‘green’,’yellow’] each column’s line will be filled in\\ngreen or yellow, alternatively. If there is only a single column to\\nbe plotted, then only the first color from the color list will be\\nused.\\n\\n\\n\\n\\nA dict of the form {column namecolor}, so that each column will becolored accordingly. For example, if your columns are called a and\\nb, then passing {‘a’: ‘green’, ‘b’: ‘red’} will color lines for\\ncolumn a in green and lines for column b in red.\\n\\n\\n\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.plot.line',\n",
       "       'descriptions': 'Plot Series or DataFrame as lines. This function is useful to plot lines using DataFrame’s values\\nas coordinates.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'x': {'type': 'label or position, optional',\n",
       "          'description': 'label or position, optional. Allows plotting of one column versus another. If not specified,\\nthe index of the DataFrame is used.\\n'},\n",
       "         'y': {'type': 'label or position, optional',\n",
       "          'description': 'label or position, optional. Allows plotting of one column versus another. If not specified,\\nall numerical columns are used.\\n'},\n",
       "         'color': {'type': 'string',\n",
       "          'description': 'str, array-like, or dict, optional. The color for each of the DataFrame’s columns. Possible values are:\\n\\n\\nA single color string referred to by name, RGB or RGBA code,for instance ‘red’ or ‘#a98d19’.\\n\\n\\n\\n\\nA sequence of color strings referred to by name, RGB or RGBAcode, which will be used for each column recursively. For\\ninstance [‘green’,’yellow’] each column’s line will be filled in\\ngreen or yellow, alternatively. If there is only a single column to\\nbe plotted, then only the first color from the color list will be\\nused.\\n\\n\\n\\n\\nA dict of the form {column namecolor}, so that each column will becolored accordingly. For example, if your columns are called a and\\nb, then passing {‘a’: ‘green’, ‘b’: ‘red’} will color lines for\\ncolumn a in green and lines for column b in red.\\n\\n\\n\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.plot.scatter(x,\\xa0y[,\\xa0s,\\xa0c])',\n",
       "      'func_desc': 'Create a scatter plot with varying marker point size and color.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.scatter.html#pandas.DataFrame.plot.scatter',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.plot.scatter',\n",
       "       'full_function': 'DataFrame.plot.scatter(x, y, s=None, c=None, **kwargs)',\n",
       "       'function_text': 'Create a scatter plot with varying marker point size and color. The coordinates of each point are defined by two dataframe columns and\\nfilled circles are used to represent each point. This kind of plot is\\nuseful to see complex correlations between two variables. Points could\\nbe for instance natural 2D coordinates like longitude and latitude in\\na map or, in general, any pair of metrics that can be plotted against\\neach other.',\n",
       "       'parameter_names_desc': [{'param_name': 'x',\n",
       "         'param_type': 'int or str',\n",
       "         'param_desc': 'The column name or column position to be used as horizontal\\ncoordinates for each point.\\n'},\n",
       "        {'param_name': 'y',\n",
       "         'param_type': 'int or str',\n",
       "         'param_desc': 'The column name or column position to be used as vertical\\ncoordinates for each point.\\n'},\n",
       "        {'param_name': 's',\n",
       "         'param_type': 'str, scalar or array-like, optional',\n",
       "         'param_desc': 'The size of each point. Possible values are:\\n\\nA string with the name of the column to be used for marker’s size.\\nA single scalar so all points have the same size.\\nA sequence of scalars, which will be used for each point’s size\\nrecursively. For instance, when passing [2,14] all points size\\nwill be either 2 or 14, alternatively.\\n\\n'},\n",
       "        {'param_name': 'c',\n",
       "         'param_type': 'str, int or array-like, optional',\n",
       "         'param_desc': 'The color of each point. Possible values are:\\n\\nA single color string referred to by name, RGB or RGBA code,\\nfor instance ‘red’ or ‘#a98d19’.\\nA sequence of color strings referred to by name, RGB or RGBA\\ncode, which will be used for each point’s color recursively. For\\ninstance [‘green’,’yellow’] all points will be filled in green or\\nyellow, alternatively.\\nA column name or position whose values will be used to color the\\nmarker points according to a colormap.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.plot.scatter',\n",
       "       'descriptions': 'Create a scatter plot with varying marker point size and color. The coordinates of each point are defined by two dataframe columns and\\nfilled circles are used to represent each point. This kind of plot is\\nuseful to see complex correlations between two variables. Points could\\nbe for instance natural 2D coordinates like longitude and latitude in\\na map or, in general, any pair of metrics that can be plotted against\\neach other.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'x': {'type': 'integer',\n",
       "          'description': 'int or str. The column name or column position to be used as horizontal\\ncoordinates for each point.\\n'},\n",
       "         'y': {'type': 'integer',\n",
       "          'description': 'int or str. The column name or column position to be used as vertical\\ncoordinates for each point.\\n'},\n",
       "         's': {'type': 'string',\n",
       "          'description': 'str, scalar or array-like, optional. The size of each point. Possible values are:\\n\\nA string with the name of the column to be used for marker’s size.\\nA single scalar so all points have the same size.\\nA sequence of scalars, which will be used for each point’s size\\nrecursively. For instance, when passing [2,14] all points size\\nwill be either 2 or 14, alternatively.\\n\\n'},\n",
       "         'c': {'type': 'integer',\n",
       "          'description': 'str, int or array-like, optional. The color of each point. Possible values are:\\n\\nA single color string referred to by name, RGB or RGBA code,\\nfor instance ‘red’ or ‘#a98d19’.\\nA sequence of color strings referred to by name, RGB or RGBA\\ncode, which will be used for each point’s color recursively. For\\ninstance [‘green’,’yellow’] all points will be filled in green or\\nyellow, alternatively.\\nA column name or position whose values will be used to color the\\nmarker points according to a colormap.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.boxplot([column,\\xa0by,\\xa0ax,\\xa0...])',\n",
       "      'func_desc': 'Make a box plot from DataFrame columns.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.boxplot.html#pandas.DataFrame.boxplot',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.boxplot',\n",
       "       'full_function': 'DataFrame.boxplot(column=None, by=None, ax=None, fontsize=None, rot=0, grid=True, figsize=None, layout=None, return_type=None, backend=None, **kwargs)',\n",
       "       'function_text': 'Make a box plot from DataFrame columns. Make a box-and-whisker plot from DataFrame columns, optionally grouped\\nby some other columns. A box plot is a method for graphically depicting\\ngroups of numerical data through their quartiles.\\nThe box extends from the Q1 to Q3 quartile values of the data,\\nwith a line at the median (Q2). The whiskers extend from the edges\\nof box to show the range of the data. By default, they extend no more than\\n1.5 * IQR (IQR = Q3 - Q1) from the edges of the box, ending at the farthest\\ndata point within that interval. Outliers are plotted as separate dots. For further details see\\nWikipedia’s entry for boxplot.',\n",
       "       'parameter_names_desc': [{'param_name': 'column',\n",
       "         'param_type': 'str or list of str, optional',\n",
       "         'param_desc': 'Column name or list of names, or vector.\\nCan be any valid input to pandas.DataFrame.groupby().\\n'},\n",
       "        {'param_name': 'by',\n",
       "         'param_type': 'str or array-like, optional',\n",
       "         'param_desc': 'Column in the DataFrame to pandas.DataFrame.groupby().\\nOne box-plot will be done per value of columns in by.\\n'},\n",
       "        {'param_name': 'ax',\n",
       "         'param_type': 'object of class matplotlib.axes.Axes, optional',\n",
       "         'param_desc': 'The matplotlib axes to be used by boxplot.\\n'},\n",
       "        {'param_name': 'fontsize',\n",
       "         'param_type': 'float or str',\n",
       "         'param_desc': 'Tick label font size in points or as a string (e.g., large).\\n'},\n",
       "        {'param_name': 'rot',\n",
       "         'param_type': 'float, default 0',\n",
       "         'param_desc': 'The rotation angle of labels (in degrees)\\nwith respect to the screen coordinate system.\\n'},\n",
       "        {'param_name': 'grid',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Setting this to True will show the grid.\\n'},\n",
       "        {'param_name': 'figsize',\n",
       "         'param_type': 'A tuple (width, height) in inches',\n",
       "         'param_desc': 'The size of the figure to create in matplotlib.\\n'},\n",
       "        {'param_name': 'layout',\n",
       "         'param_type': 'tuple (rows, columns), optional',\n",
       "         'param_desc': 'For example, (3, 5) will display the subplots\\nusing 3 rows and 5 columns, starting from the top-left.\\n'},\n",
       "        {'param_name': 'return_type',\n",
       "         'param_type': '{‘axes’, ‘dict’, ‘both’} or None, default ‘axes’',\n",
       "         'param_desc': 'The kind of object to return. The default is axes.\\n\\n‘axes’ returns the matplotlib axes the boxplot is drawn on.\\n‘dict’ returns a dictionary whose values are the matplotlib\\nLines of the boxplot.\\n‘both’ returns a namedtuple with the axes and dict.\\nwhen grouping with by, a Series mapping columns to\\nreturn_type is returned.\\nIf return_type is None, a NumPy array\\nof axes with the same shape as layout is returned.\\n\\n\\n'},\n",
       "        {'param_name': 'backend',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'Backend to use instead of the backend specified in the option\\nplotting.backend. For instance, ‘matplotlib’. Alternatively, to\\nspecify the plotting.backend for the whole session, set\\npd.options.plotting.backend.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.boxplot',\n",
       "       'descriptions': 'Make a box plot from DataFrame columns. Make a box-and-whisker plot from DataFrame columns, optionally grouped\\nby some other columns. A box plot is a method for graphically depicting\\ngroups of numerical data through their quartiles.\\nThe box extends from the Q1 to Q3 quartile values of the data,\\nwith a line at the median (Q2). The whiskers extend from the edges\\nof box to show the range of the data. By default, they extend no more than\\n1.5 * IQR (IQR = Q3 - Q1) from the edges of the box, ending at the farthest\\ndata point within that interval. Outliers are plotted as separate dots. For further details see\\nWikipedia’s entry for boxplot.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'column': {'type': 'string',\n",
       "          'description': 'str or list of str, optional. Column name or list of names, or vector.\\nCan be any valid input to pandas.DataFrame.groupby().\\n'},\n",
       "         'by': {'type': 'string',\n",
       "          'description': 'str or array-like, optional. Column in the DataFrame to pandas.DataFrame.groupby().\\nOne box-plot will be done per value of columns in by.\\n'},\n",
       "         'ax': {'type': 'object',\n",
       "          'description': 'object of class matplotlib.axes.Axes, optional. The matplotlib axes to be used by boxplot.\\n'},\n",
       "         'fontsize': {'type': 'string',\n",
       "          'description': 'float or str. Tick label font size in points or as a string (e.g., large).\\n'},\n",
       "         'rot': {'type': 'float',\n",
       "          'description': 'float, default 0. The rotation angle of labels (in degrees)\\nwith respect to the screen coordinate system.\\n'},\n",
       "         'grid': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Setting this to True will show the grid.\\n'},\n",
       "         'figsize': {'type': 'A tuple (width, height) in inches',\n",
       "          'description': 'A tuple (width, height) in inches. The size of the figure to create in matplotlib.\\n'},\n",
       "         'layout': {'type': 'tuple (rows, columns), optional',\n",
       "          'description': 'tuple (rows, columns), optional. For example, (3, 5) will display the subplots\\nusing 3 rows and 5 columns, starting from the top-left.\\n'},\n",
       "         'return_type': {'type': 'string',\n",
       "          'enum': ['axes', ' dict', ' both'],\n",
       "          'description': '{‘axes’, ‘dict’, ‘both’} or None, default ‘axes’. The kind of object to return. The default is axes.\\n\\n‘axes’ returns the matplotlib axes the boxplot is drawn on.\\n‘dict’ returns a dictionary whose values are the matplotlib\\nLines of the boxplot.\\n‘both’ returns a namedtuple with the axes and dict.\\nwhen grouping with by, a Series mapping columns to\\nreturn_type is returned.\\nIf return_type is None, a NumPy array\\nof axes with the same shape as layout is returned.\\n\\n\\n'},\n",
       "         'backend': {'type': 'string',\n",
       "          'description': 'str, default None. Backend to use instead of the backend specified in the option\\nplotting.backend. For instance, ‘matplotlib’. Alternatively, to\\nspecify the plotting.backend for the whole session, set\\npd.options.plotting.backend.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.plot.bar([x,\\xa0y])',\n",
       "      'func_desc': 'Vertical bar plot.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.bar.html#pandas.DataFrame.plot.bar',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.plot.bar',\n",
       "       'full_function': 'DataFrame.plot.bar(x=None, y=None, **kwargs)',\n",
       "       'function_text': 'Vertical bar plot. A bar plot is a plot that presents categorical data with\\nrectangular bars with lengths proportional to the values that they\\nrepresent. A bar plot shows comparisons among discrete categories. One\\naxis of the plot shows the specific categories being compared, and the\\nother axis represents a measured value.',\n",
       "       'parameter_names_desc': [{'param_name': 'x',\n",
       "         'param_type': 'label or position, optional',\n",
       "         'param_desc': 'Allows plotting of one column versus another. If not specified,\\nthe index of the DataFrame is used.\\n'},\n",
       "        {'param_name': 'y',\n",
       "         'param_type': 'label or position, optional',\n",
       "         'param_desc': 'Allows plotting of one column versus another. If not specified,\\nall numerical columns are used.\\n'},\n",
       "        {'param_name': 'color',\n",
       "         'param_type': 'str, array-like, or dict, optional',\n",
       "         'param_desc': 'The color for each of the DataFrame’s columns. Possible values are:\\n\\n\\nA single color string referred to by name, RGB or RGBA code,for instance ‘red’ or ‘#a98d19’.\\n\\n\\n\\n\\nA sequence of color strings referred to by name, RGB or RGBAcode, which will be used for each column recursively. For\\ninstance [‘green’,’yellow’] each column’s bar will be filled in\\ngreen or yellow, alternatively. If there is only a single column to\\nbe plotted, then only the first color from the color list will be\\nused.\\n\\n\\n\\n\\nA dict of the form {column namecolor}, so that each column will becolored accordingly. For example, if your columns are called a and\\nb, then passing {‘a’: ‘green’, ‘b’: ‘red’} will color bars for\\ncolumn a in green and bars for column b in red.\\n\\n\\n\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.plot.bar',\n",
       "       'descriptions': 'Vertical bar plot. A bar plot is a plot that presents categorical data with\\nrectangular bars with lengths proportional to the values that they\\nrepresent. A bar plot shows comparisons among discrete categories. One\\naxis of the plot shows the specific categories being compared, and the\\nother axis represents a measured value.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'x': {'type': 'label or position, optional',\n",
       "          'description': 'label or position, optional. Allows plotting of one column versus another. If not specified,\\nthe index of the DataFrame is used.\\n'},\n",
       "         'y': {'type': 'label or position, optional',\n",
       "          'description': 'label or position, optional. Allows plotting of one column versus another. If not specified,\\nall numerical columns are used.\\n'},\n",
       "         'color': {'type': 'string',\n",
       "          'description': 'str, array-like, or dict, optional. The color for each of the DataFrame’s columns. Possible values are:\\n\\n\\nA single color string referred to by name, RGB or RGBA code,for instance ‘red’ or ‘#a98d19’.\\n\\n\\n\\n\\nA sequence of color strings referred to by name, RGB or RGBAcode, which will be used for each column recursively. For\\ninstance [‘green’,’yellow’] each column’s bar will be filled in\\ngreen or yellow, alternatively. If there is only a single column to\\nbe plotted, then only the first color from the color list will be\\nused.\\n\\n\\n\\n\\nA dict of the form {column namecolor}, so that each column will becolored accordingly. For example, if your columns are called a and\\nb, then passing {‘a’: ‘green’, ‘b’: ‘red’} will color bars for\\ncolumn a in green and bars for column b in red.\\n\\n\\n\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.plot.box([by])',\n",
       "      'func_desc': 'Make a box plot of the DataFrame columns.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.box.html#pandas.DataFrame.plot.box',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.plot.box',\n",
       "       'full_function': 'DataFrame.plot.box(by=None, **kwargs)',\n",
       "       'function_text': 'Make a box plot of the DataFrame columns. A box plot is a method for graphically depicting groups of numerical\\ndata through their quartiles.\\nThe box extends from the Q1 to Q3 quartile values of the data,\\nwith a line at the median (Q2). The whiskers extend from the edges\\nof box to show the range of the data. The position of the whiskers\\nis set by default to 1.5*IQR (IQR = Q3 - Q1) from the edges of the\\nbox. Outlier points are those past the end of the whiskers. For further details see Wikipedia’s\\nentry for boxplot. A consideration when using this chart is that the box and the whiskers\\ncan overlap, which is very common when plotting small sets of data.',\n",
       "       'parameter_names_desc': [{'param_name': 'by',\n",
       "         'param_type': 'str or sequence',\n",
       "         'param_desc': 'Column in the DataFrame to group by.\\n\\nChanged in version 1.4.0: Previously, by is silently ignore and makes no groupings\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.plot.box',\n",
       "       'descriptions': 'Make a box plot of the DataFrame columns. A box plot is a method for graphically depicting groups of numerical\\ndata through their quartiles.\\nThe box extends from the Q1 to Q3 quartile values of the data,\\nwith a line at the median (Q2). The whiskers extend from the edges\\nof box to show the range of the data. The position of the whiskers\\nis set by default to 1.5*IQR (IQR = Q3 - Q1) from the edges of the\\nbox. Outlier points are those past the end of the whiskers. For further details see Wikipedia’s\\nentry for boxplot. A consideration when using this chart is that the box and the whiskers\\ncan overlap, which is very common when plotting small sets of data.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'by': {'type': 'string',\n",
       "          'description': 'str or sequence. Column in the DataFrame to group by.\\n\\nChanged in version 1.4.0: Previously, by is silently ignore and makes no groupings\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.plot.hexbin(x,\\xa0y[,\\xa0C,\\xa0...])',\n",
       "      'func_desc': 'Generate a hexagonal binning plot.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.hexbin.html#pandas.DataFrame.plot.hexbin',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.plot.hexbin',\n",
       "       'full_function': 'DataFrame.plot.hexbin(x, y, C=None, reduce_C_function=None, gridsize=None, **kwargs)',\n",
       "       'function_text': 'Generate a hexagonal binning plot. Generate a hexagonal binning plot of x versus y. If C is None\\n(the default), this is a histogram of the number of occurrences\\nof the observations at (x[i], y[i]). If C is specified, specifies values at given coordinates\\n(x[i], y[i]). These values are accumulated for each hexagonal\\nbin and then reduced according to reduce_C_function,\\nhaving as default the NumPy’s mean function (numpy.mean()).\\n(If C is specified, it must also be a 1-D sequence\\nof the same length as x and y, or a column label.)',\n",
       "       'parameter_names_desc': [{'param_name': 'x',\n",
       "         'param_type': 'int or str',\n",
       "         'param_desc': 'The column label or position for x points.\\n'},\n",
       "        {'param_name': 'y',\n",
       "         'param_type': 'int or str',\n",
       "         'param_desc': 'The column label or position for y points.\\n'},\n",
       "        {'param_name': 'C',\n",
       "         'param_type': 'int or str, optional',\n",
       "         'param_desc': 'The column label or position for the value of (x, y) point.\\n'},\n",
       "        {'param_name': 'reduce_C_function',\n",
       "         'param_type': 'callable, default np.mean',\n",
       "         'param_desc': 'Function of one argument that reduces all the values in a bin to\\na single number (e.g. np.mean, np.max, np.sum, np.std).\\n'},\n",
       "        {'param_name': 'gridsize',\n",
       "         'param_type': 'int or tuple of (int, int), default 100',\n",
       "         'param_desc': 'The number of hexagons in the x-direction.\\nThe corresponding number of hexagons in the y-direction is\\nchosen in a way that the hexagons are approximately regular.\\nAlternatively, gridsize can be a tuple with two elements\\nspecifying the number of hexagons in the x-direction and the\\ny-direction.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.plot.hexbin',\n",
       "       'descriptions': 'Generate a hexagonal binning plot. Generate a hexagonal binning plot of x versus y. If C is None\\n(the default), this is a histogram of the number of occurrences\\nof the observations at (x[i], y[i]). If C is specified, specifies values at given coordinates\\n(x[i], y[i]). These values are accumulated for each hexagonal\\nbin and then reduced according to reduce_C_function,\\nhaving as default the NumPy’s mean function (numpy.mean()).\\n(If C is specified, it must also be a 1-D sequence\\nof the same length as x and y, or a column label.)',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'x': {'type': 'integer',\n",
       "          'description': 'int or str. The column label or position for x points.\\n'},\n",
       "         'y': {'type': 'integer',\n",
       "          'description': 'int or str. The column label or position for y points.\\n'},\n",
       "         'C': {'type': 'integer',\n",
       "          'description': 'int or str, optional. The column label or position for the value of (x, y) point.\\n'},\n",
       "         'reduce_C_function': {'type': 'object',\n",
       "          'description': 'callable, default np.mean. Function of one argument that reduces all the values in a bin to\\na single number (e.g. np.mean, np.max, np.sum, np.std).\\n'},\n",
       "         'gridsize': {'type': 'integer',\n",
       "          'description': 'int or tuple of (int, int), default 100. The number of hexagons in the x-direction.\\nThe corresponding number of hexagons in the y-direction is\\nchosen in a way that the hexagons are approximately regular.\\nAlternatively, gridsize can be a tuple with two elements\\nspecifying the number of hexagons in the x-direction and the\\ny-direction.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.plot.kde([bw_method,\\xa0ind])',\n",
       "      'func_desc': 'Generate Kernel Density Estimate plot using Gaussian kernels.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.kde.html#pandas.DataFrame.plot.kde',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.plot.kde',\n",
       "       'full_function': 'DataFrame.plot.kde(bw_method=None, ind=None, **kwargs)',\n",
       "       'function_text': 'Generate Kernel Density Estimate plot using Gaussian kernels. In statistics, kernel density estimation (KDE) is a non-parametric\\nway to estimate the probability density function (PDF) of a random\\nvariable. This function uses Gaussian kernels and includes automatic\\nbandwidth determination.',\n",
       "       'parameter_names_desc': [{'param_name': 'bw_method',\n",
       "         'param_type': 'str, scalar or callable, optional',\n",
       "         'param_desc': 'The method used to calculate the estimator bandwidth. This can be\\n‘scott’, ‘silverman’, a scalar constant or a callable.\\nIf None (default), ‘scott’ is used.\\nSee scipy.stats.gaussian_kde for more information.\\n'},\n",
       "        {'param_name': 'ind',\n",
       "         'param_type': 'NumPy array or int, optional',\n",
       "         'param_desc': 'Evaluation points for the estimated PDF. If None (default),\\n1000 equally spaced points are used. If ind is a NumPy array, the\\nKDE is evaluated at the points passed. If ind is an integer,\\nind number of equally spaced points are used.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.plot.kde',\n",
       "       'descriptions': 'Generate Kernel Density Estimate plot using Gaussian kernels. In statistics, kernel density estimation (KDE) is a non-parametric\\nway to estimate the probability density function (PDF) of a random\\nvariable. This function uses Gaussian kernels and includes automatic\\nbandwidth determination.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'bw_method': {'type': 'string',\n",
       "          'description': 'str, scalar or callable, optional. The method used to calculate the estimator bandwidth. This can be\\n‘scott’, ‘silverman’, a scalar constant or a callable.\\nIf None (default), ‘scott’ is used.\\nSee scipy.stats.gaussian_kde for more information.\\n'},\n",
       "         'ind': {'type': 'integer',\n",
       "          'description': 'NumPy array or int, optional. Evaluation points for the estimated PDF. If None (default),\\n1000 equally spaced points are used. If ind is a NumPy array, the\\nKDE is evaluated at the points passed. If ind is an integer,\\nind number of equally spaced points are used.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.plot.pie(**kwargs)',\n",
       "      'func_desc': 'Generate a pie plot.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.pie.html#pandas.DataFrame.plot.pie',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.plot.pie',\n",
       "       'full_function': 'DataFrame.plot.pie(**kwargs)',\n",
       "       'function_text': 'Generate a pie plot. A pie plot is a proportional representation of the numerical data in a\\ncolumn. This function wraps matplotlib.pyplot.pie() for the\\nspecified column. If no column reference is passed and\\nsubplots=True a pie plot is drawn for each numerical column\\nindependently.',\n",
       "       'parameter_names_desc': [{'param_name': 'y',\n",
       "         'param_type': 'int or label, optional',\n",
       "         'param_desc': 'Label or position of the column to plot.\\nIf not provided, subplots=True argument must be passed.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.plot.pie',\n",
       "       'descriptions': 'Generate a pie plot. A pie plot is a proportional representation of the numerical data in a\\ncolumn. This function wraps matplotlib.pyplot.pie() for the\\nspecified column. If no column reference is passed and\\nsubplots=True a pie plot is drawn for each numerical column\\nindependently.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'y': {'type': 'integer',\n",
       "          'description': 'int or label, optional. Label or position of the column to plot.\\nIf not provided, subplots=True argument must be passed.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.hist([column,\\xa0by,\\xa0grid,\\xa0...])',\n",
       "      'func_desc': \"Make a histogram of the DataFrame's columns.\",\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.hist.html#pandas.DataFrame.hist',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.hist',\n",
       "       'full_function': 'DataFrame.hist(column=None, by=None, grid=True, xlabelsize=None, xrot=None, ylabelsize=None, yrot=None, ax=None, sharex=False, sharey=False, figsize=None, layout=None, bins=10, backend=None, legend=False, **kwargs)',\n",
       "       'function_text': 'Make a histogram of the DataFrame’s columns. A histogram is a representation of the distribution of data.\\nThis function calls matplotlib.pyplot.hist(), on each series in\\nthe DataFrame, resulting in one histogram per column.',\n",
       "       'parameter_names_desc': [{'param_name': 'data',\n",
       "         'param_type': 'DataFrame',\n",
       "         'param_desc': 'The pandas object holding the data.\\n'},\n",
       "        {'param_name': 'column',\n",
       "         'param_type': 'str or sequence, optional',\n",
       "         'param_desc': 'If passed, will be used to limit data to a subset of columns.\\n'},\n",
       "        {'param_name': 'by',\n",
       "         'param_type': 'object, optional',\n",
       "         'param_desc': 'If passed, then used to form histograms for separate groups.\\n'},\n",
       "        {'param_name': 'grid',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to show axis grid lines.\\n'},\n",
       "        {'param_name': 'xlabelsize',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'If specified changes the x-axis label size.\\n'},\n",
       "        {'param_name': 'xrot',\n",
       "         'param_type': 'float, default None',\n",
       "         'param_desc': 'Rotation of x axis labels. For example, a value of 90 displays the\\nx labels rotated 90 degrees clockwise.\\n'},\n",
       "        {'param_name': 'ylabelsize',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'If specified changes the y-axis label size.\\n'},\n",
       "        {'param_name': 'yrot',\n",
       "         'param_type': 'float, default None',\n",
       "         'param_desc': 'Rotation of y axis labels. For example, a value of 90 displays the\\ny labels rotated 90 degrees clockwise.\\n'},\n",
       "        {'param_name': 'ax',\n",
       "         'param_type': 'Matplotlib axes object, default None',\n",
       "         'param_desc': 'The axes to plot the histogram on.\\n'},\n",
       "        {'param_name': 'sharex',\n",
       "         'param_type': 'bool, default True if ax is None else False',\n",
       "         'param_desc': 'In case subplots=True, share x axis and set some x axis labels to\\ninvisible; defaults to True if ax is None otherwise False if an ax\\nis passed in.\\nNote that passing in both an ax and sharex=True will alter all x axis\\nlabels for all subplots in a figure.\\n'},\n",
       "        {'param_name': 'sharey',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'In case subplots=True, share y axis and set some y axis labels to\\ninvisible.\\n'},\n",
       "        {'param_name': 'figsize',\n",
       "         'param_type': 'tuple, optional',\n",
       "         'param_desc': 'The size in inches of the figure to create. Uses the value in\\nmatplotlib.rcParams by default.\\n'},\n",
       "        {'param_name': 'layout',\n",
       "         'param_type': 'tuple, optional',\n",
       "         'param_desc': 'Tuple of (rows, columns) for the layout of the histograms.\\n'},\n",
       "        {'param_name': 'bins',\n",
       "         'param_type': 'int or sequence, default 10',\n",
       "         'param_desc': 'Number of histogram bins to be used. If an integer is given, bins + 1\\nbin edges are calculated and returned. If bins is a sequence, gives\\nbin edges, including left edge of first bin and right edge of last\\nbin. In this case, bins is returned unmodified.\\n'},\n",
       "        {'param_name': 'backend',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'Backend to use instead of the backend specified in the option\\nplotting.backend. For instance, ‘matplotlib’. Alternatively, to\\nspecify the plotting.backend for the whole session, set\\npd.options.plotting.backend.\\n'},\n",
       "        {'param_name': 'legend',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to show the legend.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.hist',\n",
       "       'descriptions': 'Make a histogram of the DataFrame’s columns. A histogram is a representation of the distribution of data.\\nThis function calls matplotlib.pyplot.hist(), on each series in\\nthe DataFrame, resulting in one histogram per column.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'data': {'type': 'DataFrame',\n",
       "          'description': 'DataFrame. The pandas object holding the data.\\n'},\n",
       "         'column': {'type': 'string',\n",
       "          'description': 'str or sequence, optional. If passed, will be used to limit data to a subset of columns.\\n'},\n",
       "         'by': {'type': 'object',\n",
       "          'description': 'object, optional. If passed, then used to form histograms for separate groups.\\n'},\n",
       "         'grid': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to show axis grid lines.\\n'},\n",
       "         'xlabelsize': {'type': 'integer',\n",
       "          'description': 'int, default None. If specified changes the x-axis label size.\\n'},\n",
       "         'xrot': {'type': 'float',\n",
       "          'description': 'float, default None. Rotation of x axis labels. For example, a value of 90 displays the\\nx labels rotated 90 degrees clockwise.\\n'},\n",
       "         'ylabelsize': {'type': 'integer',\n",
       "          'description': 'int, default None. If specified changes the y-axis label size.\\n'},\n",
       "         'yrot': {'type': 'float',\n",
       "          'description': 'float, default None. Rotation of y axis labels. For example, a value of 90 displays the\\ny labels rotated 90 degrees clockwise.\\n'},\n",
       "         'ax': {'type': 'object',\n",
       "          'description': 'Matplotlib axes object, default None. The axes to plot the histogram on.\\n'},\n",
       "         'sharex': {'type': 'boolean',\n",
       "          'description': 'bool, default True if ax is None else False. In case subplots=True, share x axis and set some x axis labels to\\ninvisible; defaults to True if ax is None otherwise False if an ax\\nis passed in.\\nNote that passing in both an ax and sharex=True will alter all x axis\\nlabels for all subplots in a figure.\\n'},\n",
       "         'sharey': {'type': 'boolean',\n",
       "          'description': 'bool, default False. In case subplots=True, share y axis and set some y axis labels to\\ninvisible.\\n'},\n",
       "         'figsize': {'type': 'tuple, optional',\n",
       "          'description': 'tuple, optional. The size in inches of the figure to create. Uses the value in\\nmatplotlib.rcParams by default.\\n'},\n",
       "         'layout': {'type': 'tuple, optional',\n",
       "          'description': 'tuple, optional. Tuple of (rows, columns) for the layout of the histograms.\\n'},\n",
       "         'bins': {'type': 'integer',\n",
       "          'description': 'int or sequence, default 10. Number of histogram bins to be used. If an integer is given, bins + 1\\nbin edges are calculated and returned. If bins is a sequence, gives\\nbin edges, including left edge of first bin and right edge of last\\nbin. In this case, bins is returned unmodified.\\n'},\n",
       "         'backend': {'type': 'string',\n",
       "          'description': 'str, default None. Backend to use instead of the backend specified in the option\\nplotting.backend. For instance, ‘matplotlib’. Alternatively, to\\nspecify the plotting.backend for the whole session, set\\npd.options.plotting.backend.\\n'},\n",
       "         'legend': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to show the legend.\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Sparse accessor': [{'func_name': 'DataFrame.sparse.density',\n",
       "      'func_desc': 'Ratio of non-sparse points to total (dense) data points.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sparse.density.html#pandas.DataFrame.sparse.density',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.sparse.density',\n",
       "       'full_function': 'DataFrame.sparse.density',\n",
       "       'function_text': 'Ratio of non-sparse points to total (dense) data points. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.sparse.from_spmatrix(data[,\\xa0...])',\n",
       "      'func_desc': 'Create a new DataFrame from a scipy sparse matrix.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sparse.from_spmatrix.html#pandas.DataFrame.sparse.from_spmatrix',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.sparse.from_spmatrix',\n",
       "       'full_function': 'classmethod DataFrame.sparse.from_spmatrix(data, index=None, columns=None)',\n",
       "       'function_text': 'Create a new DataFrame from a scipy sparse matrix.',\n",
       "       'parameter_names_desc': [{'param_name': 'data',\n",
       "         'param_type': 'scipy.sparse.spmatrix',\n",
       "         'param_desc': 'Must be convertible to csc format.\\n'},\n",
       "        {'param_name': 'index, columns',\n",
       "         'param_type': 'Index, optional',\n",
       "         'param_desc': 'Row and column labels to use for the resulting DataFrame.\\nDefaults to a RangeIndex.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.sparse.from_spmatrix',\n",
       "       'descriptions': 'Create a new DataFrame from a scipy sparse matrix.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'data': {'type': 'scipy.sparse.spmatrix',\n",
       "          'description': 'scipy.sparse.spmatrix. Must be convertible to csc format.\\n'},\n",
       "         'index, columns': {'type': 'Index, optional',\n",
       "          'description': 'Index, optional. Row and column labels to use for the resulting DataFrame.\\nDefaults to a RangeIndex.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.sparse.to_dense()',\n",
       "      'func_desc': 'Convert a DataFrame with sparse values to dense.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sparse.to_dense.html#pandas.DataFrame.sparse.to_dense',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.sparse.to_dense',\n",
       "       'full_function': 'DataFrame.sparse.to_dense()',\n",
       "       'function_text': 'Convert a DataFrame with sparse values to dense.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.sparse.to_coo()',\n",
       "      'func_desc': 'Return the contents of the frame as a sparse SciPy COO matrix.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sparse.to_coo.html#pandas.DataFrame.sparse.to_coo',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.sparse.to_coo',\n",
       "       'full_function': 'DataFrame.sparse.to_coo()',\n",
       "       'function_text': 'Return the contents of the frame as a sparse SciPy COO matrix.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'Serialization / IO / conversion': [{'func_name': 'DataFrame.from_dict(data[,\\xa0orient,\\xa0dtype,\\xa0...])',\n",
       "      'func_desc': 'Construct DataFrame from dict of array-like or dicts.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.from_dict.html#pandas.DataFrame.from_dict',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.from_dict',\n",
       "       'full_function': \"classmethod DataFrame.from_dict(data, orient='columns', dtype=None, columns=None)\",\n",
       "       'function_text': 'Construct DataFrame from dict of array-like or dicts. Creates DataFrame object from dictionary by columns or by index\\nallowing dtype specification.',\n",
       "       'parameter_names_desc': [{'param_name': 'data',\n",
       "         'param_type': 'dict',\n",
       "         'param_desc': 'Of the form {field : array-like} or {field : dict}.\\n'},\n",
       "        {'param_name': 'orient',\n",
       "         'param_type': '{‘columns’, ‘index’, ‘tight’}, default ‘columns’',\n",
       "         'param_desc': 'The “orientation” of the data. If the keys of the passed dict\\nshould be the columns of the resulting DataFrame, pass ‘columns’\\n(default). Otherwise if the keys should be rows, pass ‘index’.\\nIf ‘tight’, assume a dict with keys [‘index’, ‘columns’, ‘data’,\\n‘index_names’, ‘column_names’].\\n\\nNew in version 1.4.0: ‘tight’ as an allowed value for the orient argument\\n\\n'},\n",
       "        {'param_name': 'dtype',\n",
       "         'param_type': 'dtype, default None',\n",
       "         'param_desc': 'Data type to force after DataFrame construction, otherwise infer.\\n'},\n",
       "        {'param_name': 'columns',\n",
       "         'param_type': 'list, default None',\n",
       "         'param_desc': \"Column labels to use when orient='index'. Raises a ValueError\\nif used with orient='columns' or orient='tight'.\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.from_dict',\n",
       "       'descriptions': 'Construct DataFrame from dict of array-like or dicts. Creates DataFrame object from dictionary by columns or by index\\nallowing dtype specification.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'data': {'type': 'dict',\n",
       "          'description': 'dict. Of the form {field : array-like} or {field : dict}.\\n'},\n",
       "         'orient': {'type': 'string',\n",
       "          'enum': ['columns', ' index', ' tight'],\n",
       "          'description': '{‘columns’, ‘index’, ‘tight’}, default ‘columns’. The “orientation” of the data. If the keys of the passed dict\\nshould be the columns of the resulting DataFrame, pass ‘columns’\\n(default). Otherwise if the keys should be rows, pass ‘index’.\\nIf ‘tight’, assume a dict with keys [‘index’, ‘columns’, ‘data’,\\n‘index_names’, ‘column_names’].\\n\\nNew in version 1.4.0: ‘tight’ as an allowed value for the orient argument\\n\\n'},\n",
       "         'dtype': {'type': 'dtype, default None',\n",
       "          'description': 'dtype, default None. Data type to force after DataFrame construction, otherwise infer.\\n'},\n",
       "         'columns': {'type': 'array',\n",
       "          'description': \"list, default None. Column labels to use when orient='index'. Raises a ValueError\\nif used with orient='columns' or orient='tight'.\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.to_orc([path,\\xa0engine,\\xa0index,\\xa0...])',\n",
       "      'func_desc': 'Write a DataFrame to the ORC format.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_orc.html#pandas.DataFrame.to_orc',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_orc',\n",
       "       'full_function': \"DataFrame.to_orc(path=None, *, engine='pyarrow', index=None, engine_kwargs=None)\",\n",
       "       'function_text': 'Write a DataFrame to the ORC format. New in version 1.5.0.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.to_pickle(path,\\xa0*[,\\xa0compression,\\xa0...])',\n",
       "      'func_desc': 'Pickle (serialize) object to file.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_pickle.html#pandas.DataFrame.to_pickle',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_pickle',\n",
       "       'full_function': \"DataFrame.to_pickle(path, *, compression='infer', protocol=5, storage_options=None)\",\n",
       "       'function_text': 'Pickle (serialize) object to file.',\n",
       "       'parameter_names_desc': [{'param_name': 'path',\n",
       "         'param_type': 'str, path object, or file-like object',\n",
       "         'param_desc': 'String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a binary write() function. File path where\\nthe pickled object will be stored.\\n'},\n",
       "        {'param_name': 'compression',\n",
       "         'param_type': 'str or dict, default ‘infer’',\n",
       "         'param_desc': \"For on-the-fly compression of the output data. If ‘infer’ and ‘path’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nSet to None for no compression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for faster compression and to create\\na reproducible gzip archive:\\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\n\\n\"},\n",
       "        {'param_name': 'protocol',\n",
       "         'param_type': 'int',\n",
       "         'param_desc': 'Int which indicates which protocol should be used by the pickler,\\ndefault HIGHEST_PROTOCOL (see [1] paragraph 12.1.2). The possible\\nvalues are 0, 1, 2, 3, 4, 5. A negative value for the protocol\\nparameter is equivalent to setting its value to HIGHEST_PROTOCOL.\\n\\n\\n[1]\\nhttps://docs.python.org/3/library/pickle.html.\\n\\n\\n'},\n",
       "        {'param_name': 'storage_options',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.to_pickle',\n",
       "       'descriptions': 'Pickle (serialize) object to file.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'path': {'type': 'string',\n",
       "          'description': 'str, path object, or file-like object. String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a binary write() function. File path where\\nthe pickled object will be stored.\\n'},\n",
       "         'compression': {'type': 'string',\n",
       "          'description': \"str or dict, default ‘infer’. For on-the-fly compression of the output data. If ‘infer’ and ‘path’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nSet to None for no compression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for faster compression and to create\\na reproducible gzip archive:\\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\n\\n\"},\n",
       "         'protocol': {'type': 'integer',\n",
       "          'description': 'int. Int which indicates which protocol should be used by the pickler,\\ndefault HIGHEST_PROTOCOL (see [1] paragraph 12.1.2). The possible\\nvalues are 0, 1, 2, 3, 4, 5. A negative value for the protocol\\nparameter is equivalent to setting its value to HIGHEST_PROTOCOL.\\n\\n\\n[1]\\nhttps://docs.python.org/3/library/pickle.html.\\n\\n\\n'},\n",
       "         'storage_options': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'}},\n",
       "        'required': ['path']}}},\n",
       "     {'func_name': 'DataFrame.to_hdf(path_or_buf,\\xa0*,\\xa0key[,\\xa0...])',\n",
       "      'func_desc': 'Write the contained data to an HDF5 file using HDFStore.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_hdf.html#pandas.DataFrame.to_hdf',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_hdf',\n",
       "       'full_function': \"DataFrame.to_hdf(path_or_buf, *, key, mode='a', complevel=None, complib=None, append=False, format=None, index=True, min_itemsize=None, nan_rep=None, dropna=None, data_columns=None, errors='strict', encoding='UTF-8')\",\n",
       "       'function_text': 'Write the contained data to an HDF5 file using HDFStore. Hierarchical Data Format (HDF) is self-describing, allowing an\\napplication to interpret the structure and contents of a file with\\nno outside information. One HDF file can hold a mix of related objects\\nwhich can be accessed as a group or as individual objects. In order to add another DataFrame or Series to an existing HDF file\\nplease use append mode and a different a key. Warning One can store a subclass of DataFrame or Series to HDF5,\\nbut the type of the subclass is lost upon storing. For more information see the user guide.',\n",
       "       'parameter_names_desc': [{'param_name': 'path_or_buf',\n",
       "         'param_type': 'str or pandas.HDFStore',\n",
       "         'param_desc': 'File path or HDFStore object.\\n'},\n",
       "        {'param_name': 'key',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'Identifier for the group in the store.\\n'},\n",
       "        {'param_name': 'mode',\n",
       "         'param_type': '{‘a’, ‘w’, ‘r+’}, default ‘a’',\n",
       "         'param_desc': 'Mode to open file:\\n\\n‘w’: write, a new file is created (an existing file with\\nthe same name would be deleted).\\n‘a’: append, an existing file is opened for reading and\\nwriting, and if the file does not exist it is created.\\n‘r+’: similar to ‘a’, but the file must already exist.\\n\\n'},\n",
       "        {'param_name': 'complevel',\n",
       "         'param_type': '{0-9}, default None',\n",
       "         'param_desc': 'Specifies a compression level for data.\\nA value of 0 or None disables compression.\\n'},\n",
       "        {'param_name': 'complib',\n",
       "         'param_type': '{‘zlib’, ‘lzo’, ‘bzip2’, ‘blosc’}, default ‘zlib’',\n",
       "         'param_desc': 'Specifies the compression library to be used.\\nThese additional compressors for Blosc are supported\\n(default if no compressor specified: ‘blosc:blosclz’):\\n{‘blosc:blosclz’, ‘blosc:lz4’, ‘blosc:lz4hc’, ‘blosc:snappy’,\\n‘blosc:zlib’, ‘blosc:zstd’}.\\nSpecifying a compression library which is not available issues\\na ValueError.\\n'},\n",
       "        {'param_name': 'append',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'For Table formats, append the input data to the existing.\\n'},\n",
       "        {'param_name': 'format',\n",
       "         'param_type': '{‘fixed’, ‘table’, None}, default ‘fixed’',\n",
       "         'param_desc': 'Possible values:\\n\\n‘fixed’: Fixed format. Fast writing/reading. Not-appendable,\\nnor searchable.\\n‘table’: Table format. Write as a PyTables Table structure\\nwhich may perform worse but allow more flexible operations\\nlike searching / selecting subsets of the data.\\nIf None, pd.get_option(‘io.hdf.default_format’) is checked,\\nfollowed by fallback to “fixed”.\\n\\n'},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Write DataFrame index as a column.\\n'},\n",
       "        {'param_name': 'min_itemsize',\n",
       "         'param_type': 'dict or int, optional',\n",
       "         'param_desc': 'Map column names to minimum string sizes for columns.\\n'},\n",
       "        {'param_name': 'nan_rep',\n",
       "         'param_type': 'Any, optional',\n",
       "         'param_desc': 'How to represent null values as str.\\nNot allowed with append=True.\\n'},\n",
       "        {'param_name': 'dropna',\n",
       "         'param_type': 'bool, default False, optional',\n",
       "         'param_desc': 'Remove missing values.\\n'},\n",
       "        {'param_name': 'data_columns',\n",
       "         'param_type': 'list of columns or True, optional',\n",
       "         'param_desc': 'List of columns to create as indexed data columns for on-disk\\nqueries, or True to use all columns. By default only the axes\\nof the object are indexed. See\\nQuery via data columns. for\\nmore information.\\nApplicable only to format=’table’.\\n'},\n",
       "        {'param_name': 'errors',\n",
       "         'param_type': 'str, default ‘strict’',\n",
       "         'param_desc': 'Specifies how encoding and decoding errors are to be handled.\\nSee the errors argument for open() for a full list\\nof options.\\n'},\n",
       "        {'param_name': 'encoding',\n",
       "         'param_type': 'str, default “UTF-8”',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.to_hdf',\n",
       "       'descriptions': 'Write the contained data to an HDF5 file using HDFStore. Hierarchical Data Format (HDF) is self-describing, allowing an\\napplication to interpret the structure and contents of a file with\\nno outside information. One HDF file can hold a mix of related objects\\nwhich can be accessed as a group or as individual objects. In order to add another DataFrame or Series to an existing HDF file\\nplease use append mode and a different a key. Warning One can store a subclass of DataFrame or Series to HDF5,\\nbut the type of the subclass is lost upon storing. For more information see the user guide.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'path_or_buf': {'type': 'string',\n",
       "          'description': 'str or pandas.HDFStore. File path or HDFStore object.\\n'},\n",
       "         'key': {'type': 'string',\n",
       "          'description': 'str. Identifier for the group in the store.\\n'},\n",
       "         'mode': {'type': 'string',\n",
       "          'enum': ['a', ' w', ' r+'],\n",
       "          'description': '{‘a’, ‘w’, ‘r+’}, default ‘a’. Mode to open file:\\n\\n‘w’: write, a new file is created (an existing file with\\nthe same name would be deleted).\\n‘a’: append, an existing file is opened for reading and\\nwriting, and if the file does not exist it is created.\\n‘r+’: similar to ‘a’, but the file must already exist.\\n\\n'},\n",
       "         'complevel': {'type': '{0-9}, default None',\n",
       "          'description': '{0-9}, default None. Specifies a compression level for data.\\nA value of 0 or None disables compression.\\n'},\n",
       "         'complib': {'type': 'string',\n",
       "          'enum': ['zlib', ' lzo', ' bzip2', ' blosc'],\n",
       "          'description': '{‘zlib’, ‘lzo’, ‘bzip2’, ‘blosc’}, default ‘zlib’. Specifies the compression library to be used.\\nThese additional compressors for Blosc are supported\\n(default if no compressor specified: ‘blosc:blosclz’):\\n{‘blosc:blosclz’, ‘blosc:lz4’, ‘blosc:lz4hc’, ‘blosc:snappy’,\\n‘blosc:zlib’, ‘blosc:zstd’}.\\nSpecifying a compression library which is not available issues\\na ValueError.\\n'},\n",
       "         'append': {'type': 'boolean',\n",
       "          'description': 'bool, default False. For Table formats, append the input data to the existing.\\n'},\n",
       "         'format': {'type': 'string',\n",
       "          'enum': ['fixed', ' table', ' None'],\n",
       "          'description': '{‘fixed’, ‘table’, None}, default ‘fixed’. Possible values:\\n\\n‘fixed’: Fixed format. Fast writing/reading. Not-appendable,\\nnor searchable.\\n‘table’: Table format. Write as a PyTables Table structure\\nwhich may perform worse but allow more flexible operations\\nlike searching / selecting subsets of the data.\\nIf None, pd.get_option(‘io.hdf.default_format’) is checked,\\nfollowed by fallback to “fixed”.\\n\\n'},\n",
       "         'index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Write DataFrame index as a column.\\n'},\n",
       "         'min_itemsize': {'type': 'integer',\n",
       "          'description': 'dict or int, optional. Map column names to minimum string sizes for columns.\\n'},\n",
       "         'nan_rep': {'type': 'Any, optional',\n",
       "          'description': 'Any, optional. How to represent null values as str.\\nNot allowed with append=True.\\n'},\n",
       "         'dropna': {'type': 'boolean',\n",
       "          'description': 'bool, default False, optional. Remove missing values.\\n'},\n",
       "         'data_columns': {'type': 'array',\n",
       "          'description': 'list of columns or True, optional. List of columns to create as indexed data columns for on-disk\\nqueries, or True to use all columns. By default only the axes\\nof the object are indexed. See\\nQuery via data columns. for\\nmore information.\\nApplicable only to format=’table’.\\n'},\n",
       "         'errors': {'type': 'string',\n",
       "          'description': 'str, default ‘strict’. Specifies how encoding and decoding errors are to be handled.\\nSee the errors argument for open() for a full list\\nof options.\\n'},\n",
       "         'encoding': {'type': 'string',\n",
       "          'description': 'str, default “UTF-8”. '}},\n",
       "        'required': ['path_or_buf']}}},\n",
       "     {'func_name': 'DataFrame.to_dict([orient,\\xa0into,\\xa0index])',\n",
       "      'func_desc': 'Convert the DataFrame to a dictionary.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_dict.html#pandas.DataFrame.to_dict',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_dict',\n",
       "       'full_function': \"DataFrame.to_dict(orient='dict', *, into=<class 'dict'>, index=True)\",\n",
       "       'function_text': 'Convert the DataFrame to a dictionary. The type of the key-value pairs can be customized with the parameters\\n(see below).',\n",
       "       'parameter_names_desc': [{'param_name': 'orient',\n",
       "         'param_type': 'str {‘dict’, ‘list’, ‘series’, ‘split’, ‘tight’, ‘records’, ‘index’}',\n",
       "         'param_desc': 'Determines the type of the values of the dictionary.\\n\\n‘dict’ (default) : dict like {column -> {index -> value}}\\n‘list’ : dict like {column -> [values]}\\n‘series’ : dict like {column -> Series(values)}\\n‘split’ : dict like\\n{‘index’ -> [index], ‘columns’ -> [columns], ‘data’ -> [values]}\\n‘tight’ : dict like\\n{‘index’ -> [index], ‘columns’ -> [columns], ‘data’ -> [values],\\n‘index_names’ -> [index.names], ‘column_names’ -> [column.names]}\\n‘records’ : list like\\n[{column -> value}, … , {column -> value}]\\n‘index’ : dict like {index -> {column -> value}}\\n\\n\\nNew in version 1.4.0: ‘tight’ as an allowed value for the orient argument\\n\\n'},\n",
       "        {'param_name': 'into',\n",
       "         'param_type': 'class, default dict',\n",
       "         'param_desc': 'The collections.abc.MutableMapping subclass used for all Mappings\\nin the return value. Can be the actual class or an empty\\ninstance of the mapping type you want. If you want a\\ncollections.defaultdict, you must pass it initialized.\\n'},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to include the index item (and index_names item if orient\\nis ‘tight’) in the returned dictionary. Can only be False\\nwhen orient is ‘split’ or ‘tight’.\\n\\nNew in version 2.0.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.to_dict',\n",
       "       'descriptions': 'Convert the DataFrame to a dictionary. The type of the key-value pairs can be customized with the parameters\\n(see below).',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'orient': {'type': 'string',\n",
       "          'description': 'str {‘dict’, ‘list’, ‘series’, ‘split’, ‘tight’, ‘records’, ‘index’}. Determines the type of the values of the dictionary.\\n\\n‘dict’ (default) : dict like {column -> {index -> value}}\\n‘list’ : dict like {column -> [values]}\\n‘series’ : dict like {column -> Series(values)}\\n‘split’ : dict like\\n{‘index’ -> [index], ‘columns’ -> [columns], ‘data’ -> [values]}\\n‘tight’ : dict like\\n{‘index’ -> [index], ‘columns’ -> [columns], ‘data’ -> [values],\\n‘index_names’ -> [index.names], ‘column_names’ -> [column.names]}\\n‘records’ : list like\\n[{column -> value}, … , {column -> value}]\\n‘index’ : dict like {index -> {column -> value}}\\n\\n\\nNew in version 1.4.0: ‘tight’ as an allowed value for the orient argument\\n\\n'},\n",
       "         'into': {'type': 'class, default dict',\n",
       "          'description': 'class, default dict. The collections.abc.MutableMapping subclass used for all Mappings\\nin the return value. Can be the actual class or an empty\\ninstance of the mapping type you want. If you want a\\ncollections.defaultdict, you must pass it initialized.\\n'},\n",
       "         'index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to include the index item (and index_names item if orient\\nis ‘tight’) in the returned dictionary. Can only be False\\nwhen orient is ‘split’ or ‘tight’.\\n\\nNew in version 2.0.0.\\n\\n'}},\n",
       "        'required': [\"orient='dict'\"]}}},\n",
       "     {'func_name': 'DataFrame.to_json([path_or_buf,\\xa0orient,\\xa0...])',\n",
       "      'func_desc': 'Convert the object to a JSON string.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_json.html#pandas.DataFrame.to_json',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_json',\n",
       "       'full_function': \"DataFrame.to_json(path_or_buf=None, *, orient=None, date_format=None, double_precision=10, force_ascii=True, date_unit='ms', default_handler=None, lines=False, compression='infer', index=None, indent=None, storage_options=None, mode='w')\",\n",
       "       'function_text': 'Convert the object to a JSON string. Note NaN’s and None will be converted to null and datetime objects\\nwill be converted to UNIX timestamps.',\n",
       "       'parameter_names_desc': [{'param_name': 'path_or_buf',\n",
       "         'param_type': 'str, path object, file-like object, or None, default None',\n",
       "         'param_desc': 'String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a write() function. If None, the result is\\nreturned as a string.\\n'},\n",
       "        {'param_name': 'orient',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': \"Indication of expected JSON string format.\\n\\nSeries:\\n\\n\\ndefault is ‘index’\\nallowed values are: {‘split’, ‘records’, ‘index’, ‘table’}.\\n\\n\\n\\nDataFrame:\\n\\n\\ndefault is ‘columns’\\nallowed values are: {‘split’, ‘records’, ‘index’, ‘columns’,\\n‘values’, ‘table’}.\\n\\n\\n\\nThe format of the JSON string:\\n\\n\\n‘split’ : dict like {‘index’ -> [index], ‘columns’ -> [columns],\\n‘data’ -> [values]}\\n‘records’ : list like [{column -> value}, … , {column -> value}]\\n‘index’ : dict like {index -> {column -> value}}\\n‘columns’ : dict like {column -> {index -> value}}\\n‘values’ : just the values array\\n‘table’ : dict like {‘schema’: {schema}, ‘data’: {data}}\\n\\nDescribing the data, where data component is like orient='records'.\\n\\n\\n\\n\"},\n",
       "        {'param_name': 'date_format',\n",
       "         'param_type': '{None, ‘epoch’, ‘iso’}',\n",
       "         'param_desc': \"Type of date conversion. ‘epoch’ = epoch milliseconds,\\n‘iso’ = ISO8601. The default depends on the orient. For\\norient='table', the default is ‘iso’. For all other orients,\\nthe default is ‘epoch’.\\n\"},\n",
       "        {'param_name': 'double_precision',\n",
       "         'param_type': 'int, default 10',\n",
       "         'param_desc': 'The number of decimal places to use when encoding\\nfloating point values. The possible maximal value is 15.\\nPassing double_precision greater than 15 will raise a ValueError.\\n'},\n",
       "        {'param_name': 'force_ascii',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Force encoded string to be ASCII.\\n'},\n",
       "        {'param_name': 'date_unit',\n",
       "         'param_type': 'str, default ‘ms’ (milliseconds)',\n",
       "         'param_desc': 'The time unit to encode to, governs timestamp and ISO8601\\nprecision. One of ‘s’, ‘ms’, ‘us’, ‘ns’ for second, millisecond,\\nmicrosecond, and nanosecond respectively.\\n'},\n",
       "        {'param_name': 'default_handler',\n",
       "         'param_type': 'callable, default None',\n",
       "         'param_desc': 'Handler to call if object cannot otherwise be converted to a\\nsuitable format for JSON. Should receive a single argument which is\\nthe object to convert and return a serialisable object.\\n'},\n",
       "        {'param_name': 'lines',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If ‘orient’ is ‘records’ write out line-delimited json format. Will\\nthrow ValueError if incorrect ‘orient’ since others are not\\nlist-like.\\n'},\n",
       "        {'param_name': 'compression',\n",
       "         'param_type': 'str or dict, default ‘infer’',\n",
       "         'param_desc': \"For on-the-fly compression of the output data. If ‘infer’ and ‘path_or_buf’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nSet to None for no compression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for faster compression and to create\\na reproducible gzip archive:\\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\n\\n\\nChanged in version 1.4.0: Zstandard support.\\n\\n\"},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'bool or None, default None',\n",
       "         'param_desc': 'The index is only used when ‘orient’ is ‘split’, ‘index’, ‘column’,\\nor ‘table’. Of these, ‘index’ and ‘column’ do not support\\nindex=False.\\n'},\n",
       "        {'param_name': 'indent',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Length of whitespace used to indent each record.\\n'},\n",
       "        {'param_name': 'storage_options',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'},\n",
       "        {'param_name': 'mode',\n",
       "         'param_type': 'str, default ‘w’ (writing)',\n",
       "         'param_desc': 'Specify the IO mode for output when supplying a path_or_buf.\\nAccepted args are ‘w’ (writing) and ‘a’ (append) only.\\nmode=’a’ is only supported when lines is True and orient is ‘records’.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.to_json',\n",
       "       'descriptions': 'Convert the object to a JSON string. Note NaN’s and None will be converted to null and datetime objects\\nwill be converted to UNIX timestamps.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'path_or_buf': {'type': 'string',\n",
       "          'description': 'str, path object, file-like object, or None, default None. String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a write() function. If None, the result is\\nreturned as a string.\\n'},\n",
       "         'orient': {'type': 'string',\n",
       "          'description': \"str. Indication of expected JSON string format.\\n\\nSeries:\\n\\n\\ndefault is ‘index’\\nallowed values are: {‘split’, ‘records’, ‘index’, ‘table’}.\\n\\n\\n\\nDataFrame:\\n\\n\\ndefault is ‘columns’\\nallowed values are: {‘split’, ‘records’, ‘index’, ‘columns’,\\n‘values’, ‘table’}.\\n\\n\\n\\nThe format of the JSON string:\\n\\n\\n‘split’ : dict like {‘index’ -> [index], ‘columns’ -> [columns],\\n‘data’ -> [values]}\\n‘records’ : list like [{column -> value}, … , {column -> value}]\\n‘index’ : dict like {index -> {column -> value}}\\n‘columns’ : dict like {column -> {index -> value}}\\n‘values’ : just the values array\\n‘table’ : dict like {‘schema’: {schema}, ‘data’: {data}}\\n\\nDescribing the data, where data component is like orient='records'.\\n\\n\\n\\n\"},\n",
       "         'date_format': {'type': 'string',\n",
       "          'enum': ['None', ' epoch', ' iso'],\n",
       "          'description': \"{None, ‘epoch’, ‘iso’}. Type of date conversion. ‘epoch’ = epoch milliseconds,\\n‘iso’ = ISO8601. The default depends on the orient. For\\norient='table', the default is ‘iso’. For all other orients,\\nthe default is ‘epoch’.\\n\"},\n",
       "         'double_precision': {'type': 'integer',\n",
       "          'description': 'int, default 10. The number of decimal places to use when encoding\\nfloating point values. The possible maximal value is 15.\\nPassing double_precision greater than 15 will raise a ValueError.\\n'},\n",
       "         'force_ascii': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Force encoded string to be ASCII.\\n'},\n",
       "         'date_unit': {'type': 'string',\n",
       "          'description': 'str, default ‘ms’ (milliseconds). The time unit to encode to, governs timestamp and ISO8601\\nprecision. One of ‘s’, ‘ms’, ‘us’, ‘ns’ for second, millisecond,\\nmicrosecond, and nanosecond respectively.\\n'},\n",
       "         'default_handler': {'type': 'object',\n",
       "          'description': 'callable, default None. Handler to call if object cannot otherwise be converted to a\\nsuitable format for JSON. Should receive a single argument which is\\nthe object to convert and return a serialisable object.\\n'},\n",
       "         'lines': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If ‘orient’ is ‘records’ write out line-delimited json format. Will\\nthrow ValueError if incorrect ‘orient’ since others are not\\nlist-like.\\n'},\n",
       "         'compression': {'type': 'string',\n",
       "          'description': \"str or dict, default ‘infer’. For on-the-fly compression of the output data. If ‘infer’ and ‘path_or_buf’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nSet to None for no compression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for faster compression and to create\\na reproducible gzip archive:\\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\n\\n\\nChanged in version 1.4.0: Zstandard support.\\n\\n\"},\n",
       "         'index': {'type': 'boolean',\n",
       "          'description': 'bool or None, default None. The index is only used when ‘orient’ is ‘split’, ‘index’, ‘column’,\\nor ‘table’. Of these, ‘index’ and ‘column’ do not support\\nindex=False.\\n'},\n",
       "         'indent': {'type': 'integer',\n",
       "          'description': 'int, optional. Length of whitespace used to indent each record.\\n'},\n",
       "         'storage_options': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'},\n",
       "         'mode': {'type': 'string',\n",
       "          'description': 'str, default ‘w’ (writing). Specify the IO mode for output when supplying a path_or_buf.\\nAccepted args are ‘w’ (writing) and ‘a’ (append) only.\\nmode=’a’ is only supported when lines is True and orient is ‘records’.\\n'}},\n",
       "        'required': ['path_or_buf=None']}}},\n",
       "     {'func_name': 'DataFrame.to_feather(path,\\xa0**kwargs)',\n",
       "      'func_desc': 'Write a DataFrame to the binary Feather format.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_feather.html#pandas.DataFrame.to_feather',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_feather',\n",
       "       'full_function': 'DataFrame.to_feather(path, **kwargs)',\n",
       "       'function_text': 'Write a DataFrame to the binary Feather format.',\n",
       "       'parameter_names_desc': [{'param_name': 'path',\n",
       "         'param_type': 'str, path object, file-like object',\n",
       "         'param_desc': 'String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a binary write() function. If a string or a path,\\nit will be used as Root Directory path when writing a partitioned dataset.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.to_feather',\n",
       "       'descriptions': 'Write a DataFrame to the binary Feather format.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'path': {'type': 'string',\n",
       "          'description': 'str, path object, file-like object. String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a binary write() function. If a string or a path,\\nit will be used as Root Directory path when writing a partitioned dataset.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.to_stata(path,\\xa0*[,\\xa0convert_dates,\\xa0...])',\n",
       "      'func_desc': 'Export DataFrame object to Stata dta format.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_stata.html#pandas.DataFrame.to_stata',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_stata',\n",
       "       'full_function': \"DataFrame.to_stata(path, *, convert_dates=None, write_index=True, byteorder=None, time_stamp=None, data_label=None, variable_labels=None, version=114, convert_strl=None, compression='infer', storage_options=None, value_labels=None)\",\n",
       "       'function_text': 'Export DataFrame object to Stata dta format. Writes the DataFrame to a Stata dataset file.\\n“dta” files contain a Stata dataset.',\n",
       "       'parameter_names_desc': [{'param_name': 'path',\n",
       "         'param_type': 'str, path object, or buffer',\n",
       "         'param_desc': 'String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a binary write() function.\\n'},\n",
       "        {'param_name': 'convert_dates',\n",
       "         'param_type': 'dict',\n",
       "         'param_desc': 'Dictionary mapping columns containing datetime types to stata\\ninternal format to use when writing the dates. Options are ‘tc’,\\n‘td’, ‘tm’, ‘tw’, ‘th’, ‘tq’, ‘ty’. Column can be either an integer\\nor a name. Datetime columns that do not have a conversion type\\nspecified will be converted to ‘tc’. Raises NotImplementedError if\\na datetime column has timezone information.\\n'},\n",
       "        {'param_name': 'write_index',\n",
       "         'param_type': 'bool',\n",
       "         'param_desc': 'Write the index to Stata dataset.\\n'},\n",
       "        {'param_name': 'byteorder',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'Can be “>”, “<”, “little”, or “big”. default is sys.byteorder.\\n'},\n",
       "        {'param_name': 'time_stamp',\n",
       "         'param_type': 'datetime',\n",
       "         'param_desc': 'A datetime to use as file creation date. Default is the current\\ntime.\\n'},\n",
       "        {'param_name': 'data_label',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'A label for the data set. Must be 80 characters or smaller.\\n'},\n",
       "        {'param_name': 'variable_labels',\n",
       "         'param_type': 'dict',\n",
       "         'param_desc': 'Dictionary containing columns as keys and variable labels as\\nvalues. Each label must be 80 characters or smaller.\\n'},\n",
       "        {'param_name': 'version',\n",
       "         'param_type': '{114, 117, 118, 119, None}, default 114',\n",
       "         'param_desc': 'Version to use in the output dta file. Set to None to let pandas\\ndecide between 118 or 119 formats depending on the number of\\ncolumns in the frame. Version 114 can be read by Stata 10 and\\nlater. Version 117 can be read by Stata 13 or later. Version 118\\nis supported in Stata 14 and later. Version 119 is supported in\\nStata 15 and later. Version 114 limits string variables to 244\\ncharacters or fewer while versions 117 and later allow strings\\nwith lengths up to 2,000,000 characters. Versions 118 and 119\\nsupport Unicode characters, and version 119 supports more than\\n32,767 variables.\\nVersion 119 should usually only be used when the number of\\nvariables exceeds the capacity of dta format 118. Exporting\\nsmaller datasets in format 119 may have unintended consequences,\\nand, as of November 2020, Stata SE cannot read version 119 files.\\n'},\n",
       "        {'param_name': 'convert_strl',\n",
       "         'param_type': 'list, optional',\n",
       "         'param_desc': 'List of column names to convert to string columns to Stata StrL\\nformat. Only available if version is 117. Storing strings in the\\nStrL format can produce smaller dta files if strings have more than\\n8 characters and values are repeated.\\n'},\n",
       "        {'param_name': 'compression',\n",
       "         'param_type': 'str or dict, default ‘infer’',\n",
       "         'param_desc': \"For on-the-fly compression of the output data. If ‘infer’ and ‘path’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nSet to None for no compression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for faster compression and to create\\na reproducible gzip archive:\\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\n\\n\\nChanged in version 1.4.0: Zstandard support.\\n\\n\"},\n",
       "        {'param_name': 'storage_options',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'},\n",
       "        {'param_name': 'value_labels',\n",
       "         'param_type': 'dict of dicts',\n",
       "         'param_desc': 'Dictionary containing columns as keys and dictionaries of column value\\nto labels as values. Labels for a single variable must be 32,000\\ncharacters or smaller.\\n\\nNew in version 1.4.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.to_stata',\n",
       "       'descriptions': 'Export DataFrame object to Stata dta format. Writes the DataFrame to a Stata dataset file.\\n“dta” files contain a Stata dataset.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'path': {'type': 'string',\n",
       "          'description': 'str, path object, or buffer. String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a binary write() function.\\n'},\n",
       "         'convert_dates': {'type': 'dict',\n",
       "          'description': 'dict. Dictionary mapping columns containing datetime types to stata\\ninternal format to use when writing the dates. Options are ‘tc’,\\n‘td’, ‘tm’, ‘tw’, ‘th’, ‘tq’, ‘ty’. Column can be either an integer\\nor a name. Datetime columns that do not have a conversion type\\nspecified will be converted to ‘tc’. Raises NotImplementedError if\\na datetime column has timezone information.\\n'},\n",
       "         'write_index': {'type': 'boolean',\n",
       "          'description': 'bool. Write the index to Stata dataset.\\n'},\n",
       "         'byteorder': {'type': 'string',\n",
       "          'description': 'str. Can be “>”, “<”, “little”, or “big”. default is sys.byteorder.\\n'},\n",
       "         'time_stamp': {'type': 'datetime',\n",
       "          'description': 'datetime. A datetime to use as file creation date. Default is the current\\ntime.\\n'},\n",
       "         'data_label': {'type': 'string',\n",
       "          'description': 'str, optional. A label for the data set. Must be 80 characters or smaller.\\n'},\n",
       "         'variable_labels': {'type': 'dict',\n",
       "          'description': 'dict. Dictionary containing columns as keys and variable labels as\\nvalues. Each label must be 80 characters or smaller.\\n'},\n",
       "         'version': {'type': '{114, 117, 118, 119, None}, default 114',\n",
       "          'description': '{114, 117, 118, 119, None}, default 114. Version to use in the output dta file. Set to None to let pandas\\ndecide between 118 or 119 formats depending on the number of\\ncolumns in the frame. Version 114 can be read by Stata 10 and\\nlater. Version 117 can be read by Stata 13 or later. Version 118\\nis supported in Stata 14 and later. Version 119 is supported in\\nStata 15 and later. Version 114 limits string variables to 244\\ncharacters or fewer while versions 117 and later allow strings\\nwith lengths up to 2,000,000 characters. Versions 118 and 119\\nsupport Unicode characters, and version 119 supports more than\\n32,767 variables.\\nVersion 119 should usually only be used when the number of\\nvariables exceeds the capacity of dta format 118. Exporting\\nsmaller datasets in format 119 may have unintended consequences,\\nand, as of November 2020, Stata SE cannot read version 119 files.\\n'},\n",
       "         'convert_strl': {'type': 'array',\n",
       "          'description': 'list, optional. List of column names to convert to string columns to Stata StrL\\nformat. Only available if version is 117. Storing strings in the\\nStrL format can produce smaller dta files if strings have more than\\n8 characters and values are repeated.\\n'},\n",
       "         'compression': {'type': 'string',\n",
       "          'description': \"str or dict, default ‘infer’. For on-the-fly compression of the output data. If ‘infer’ and ‘path’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nSet to None for no compression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for faster compression and to create\\na reproducible gzip archive:\\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\n\\n\\nChanged in version 1.4.0: Zstandard support.\\n\\n\"},\n",
       "         'storage_options': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'},\n",
       "         'value_labels': {'type': 'dict of dicts',\n",
       "          'description': 'dict of dicts. Dictionary containing columns as keys and dictionaries of column value\\nto labels as values. Labels for a single variable must be 32,000\\ncharacters or smaller.\\n\\nNew in version 1.4.0.\\n\\n'}},\n",
       "        'required': ['path']}}},\n",
       "     {'func_name': 'DataFrame.to_records([index,\\xa0column_dtypes,\\xa0...])',\n",
       "      'func_desc': 'Convert DataFrame to a NumPy record array.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_records.html#pandas.DataFrame.to_records',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_records',\n",
       "       'full_function': 'DataFrame.to_records(index=True, column_dtypes=None, index_dtypes=None)',\n",
       "       'function_text': 'Convert DataFrame to a NumPy record array. Index will be included as the first field of the record array if\\nrequested.',\n",
       "       'parameter_names_desc': [{'param_name': 'index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Include index in resulting record array, stored in ‘index’\\nfield or using the index label, if set.\\n'},\n",
       "        {'param_name': 'column_dtypes',\n",
       "         'param_type': 'str, type, dict, default None',\n",
       "         'param_desc': 'If a string or type, the data type to store all columns. If\\na dictionary, a mapping of column names and indices (zero-indexed)\\nto specific data types.\\n'},\n",
       "        {'param_name': 'index_dtypes',\n",
       "         'param_type': 'str, type, dict, default None',\n",
       "         'param_desc': 'If a string or type, the data type to store all index levels. If\\na dictionary, a mapping of index level names and indices\\n(zero-indexed) to specific data types.\\nThis mapping is applied only if index=True.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.to_records',\n",
       "       'descriptions': 'Convert DataFrame to a NumPy record array. Index will be included as the first field of the record array if\\nrequested.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Include index in resulting record array, stored in ‘index’\\nfield or using the index label, if set.\\n'},\n",
       "         'column_dtypes': {'type': 'string',\n",
       "          'description': 'str, type, dict, default None. If a string or type, the data type to store all columns. If\\na dictionary, a mapping of column names and indices (zero-indexed)\\nto specific data types.\\n'},\n",
       "         'index_dtypes': {'type': 'string',\n",
       "          'description': 'str, type, dict, default None. If a string or type, the data type to store all index levels. If\\na dictionary, a mapping of index level names and indices\\n(zero-indexed) to specific data types.\\nThis mapping is applied only if index=True.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.to_clipboard(*[,\\xa0excel,\\xa0sep])',\n",
       "      'func_desc': 'Copy object to the system clipboard.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_clipboard.html#pandas.DataFrame.to_clipboard',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_clipboard',\n",
       "       'full_function': 'DataFrame.to_clipboard(*, excel=True, sep=None, **kwargs)',\n",
       "       'function_text': 'Copy object to the system clipboard. Write a text representation of object to the system clipboard.\\nThis can be pasted into Excel, for example.',\n",
       "       'parameter_names_desc': [{'param_name': 'excel',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Produce output in a csv format for easy pasting into excel.\\n\\nTrue, use the provided separator for csv pasting.\\nFalse, write a string representation of the object to the clipboard.\\n\\n'},\n",
       "        {'param_name': 'sep',\n",
       "         'param_type': \"str, default '\\\\t'\",\n",
       "         'param_desc': 'Field delimiter.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.to_clipboard',\n",
       "       'descriptions': 'Copy object to the system clipboard. Write a text representation of object to the system clipboard.\\nThis can be pasted into Excel, for example.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'excel': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Produce output in a csv format for easy pasting into excel.\\n\\nTrue, use the provided separator for csv pasting.\\nFalse, write a string representation of the object to the clipboard.\\n\\n'},\n",
       "         'sep': {'type': 'string',\n",
       "          'description': \"str, default '\\\\t'. Field delimiter.\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.style',\n",
       "      'func_desc': 'Returns a Styler object.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.style.html#pandas.DataFrame.style',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.style',\n",
       "       'full_function': 'property DataFrame.style',\n",
       "       'function_text': 'Returns a Styler object. Contains methods for building a styled HTML representation of the DataFrame. See also Helps style a DataFrame or Series according to the data with HTML and CSS. Examples Please see\\nTable Visualization for more examples.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.from_records(data[,\\xa0index,\\xa0...])',\n",
       "      'func_desc': 'Convert structured or record ndarray to DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.from_records.html#pandas.DataFrame.from_records',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.from_records',\n",
       "       'full_function': 'classmethod DataFrame.from_records(data, index=None, exclude=None, columns=None, coerce_float=False, nrows=None)',\n",
       "       'function_text': 'Convert structured or record ndarray to DataFrame. Creates a DataFrame object from a structured ndarray, sequence of\\ntuples or dicts, or DataFrame.',\n",
       "       'parameter_names_desc': [{'param_name': 'data',\n",
       "         'param_type': 'structured ndarray, sequence of tuples or dicts, or DataFrame',\n",
       "         'param_desc': 'Structured input data.\\n\\nDeprecated since version 2.1.0: Passing a DataFrame is deprecated.\\n\\n'},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'str, list of fields, array-like',\n",
       "         'param_desc': 'Field of array to use as the index, alternately a specific set of\\ninput labels to use.\\n'},\n",
       "        {'param_name': 'exclude',\n",
       "         'param_type': 'sequence, default None',\n",
       "         'param_desc': 'Columns or fields to exclude.\\n'},\n",
       "        {'param_name': 'columns',\n",
       "         'param_type': 'sequence, default None',\n",
       "         'param_desc': 'Column names to use. If the passed data do not have names\\nassociated with them, this argument provides names for the\\ncolumns. Otherwise this argument indicates the order of the columns\\nin the result (any names not found in the data will become all-NA\\ncolumns).\\n'},\n",
       "        {'param_name': 'coerce_float',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Attempt to convert values of non-string, non-numeric objects (like\\ndecimal.Decimal) to floating point, useful for SQL result sets.\\n'},\n",
       "        {'param_name': 'nrows',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'Number of rows to read if data is an iterator.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.from_records',\n",
       "       'descriptions': 'Convert structured or record ndarray to DataFrame. Creates a DataFrame object from a structured ndarray, sequence of\\ntuples or dicts, or DataFrame.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'data': {'type': 'string',\n",
       "          'description': 'structured ndarray, sequence of tuples or dicts, or DataFrame. Structured input data.\\n\\nDeprecated since version 2.1.0: Passing a DataFrame is deprecated.\\n\\n'},\n",
       "         'index': {'type': 'string',\n",
       "          'description': 'str, list of fields, array-like. Field of array to use as the index, alternately a specific set of\\ninput labels to use.\\n'},\n",
       "         'exclude': {'type': 'sequence, default None',\n",
       "          'description': 'sequence, default None. Columns or fields to exclude.\\n'},\n",
       "         'columns': {'type': 'sequence, default None',\n",
       "          'description': 'sequence, default None. Column names to use. If the passed data do not have names\\nassociated with them, this argument provides names for the\\ncolumns. Otherwise this argument indicates the order of the columns\\nin the result (any names not found in the data will become all-NA\\ncolumns).\\n'},\n",
       "         'coerce_float': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Attempt to convert values of non-string, non-numeric objects (like\\ndecimal.Decimal) to floating point, useful for SQL result sets.\\n'},\n",
       "         'nrows': {'type': 'integer',\n",
       "          'description': 'int, default None. Number of rows to read if data is an iterator.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrame.to_parquet([path,\\xa0engine,\\xa0...])',\n",
       "      'func_desc': 'Write a DataFrame to the binary parquet format.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_parquet.html#pandas.DataFrame.to_parquet',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_parquet',\n",
       "       'full_function': \"DataFrame.to_parquet(path=None, *, engine='auto', compression='snappy', index=None, partition_cols=None, storage_options=None, **kwargs)\",\n",
       "       'function_text': 'Write a DataFrame to the binary parquet format. This function writes the dataframe as a parquet file. You can choose different parquet\\nbackends, and have the option of compression. See\\nthe user guide for more details.',\n",
       "       'parameter_names_desc': [{'param_name': 'path',\n",
       "         'param_type': 'str, path object, file-like object, or None, default None',\n",
       "         'param_desc': 'String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a binary write() function. If None, the result is\\nreturned as bytes. If a string or path, it will be used as Root Directory\\npath when writing a partitioned dataset.\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': '{‘auto’, ‘pyarrow’, ‘fastparquet’}, default ‘auto’',\n",
       "         'param_desc': 'Parquet library to use. If ‘auto’, then the option\\nio.parquet.engine is used. The default io.parquet.engine\\nbehavior is to try ‘pyarrow’, falling back to ‘fastparquet’ if\\n‘pyarrow’ is unavailable.\\n'},\n",
       "        {'param_name': 'compression',\n",
       "         'param_type': 'str or None, default ‘snappy’',\n",
       "         'param_desc': 'Name of the compression to use. Use None for no compression.\\nSupported options: ‘snappy’, ‘gzip’, ‘brotli’, ‘lz4’, ‘zstd’.\\n'},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'bool, default None',\n",
       "         'param_desc': 'If True, include the dataframe’s index(es) in the file output.\\nIf False, they will not be written to the file.\\nIf None, similar to True the dataframe’s index(es)\\nwill be saved. However, instead of being saved as values,\\nthe RangeIndex will be stored as a range in the metadata so it\\ndoesn’t require much space and is faster. Other indexes will\\nbe included as columns in the file output.\\n'},\n",
       "        {'param_name': 'partition_cols',\n",
       "         'param_type': 'list, optional, default None',\n",
       "         'param_desc': 'Column names by which to partition the dataset.\\nColumns are partitioned in the order they are given.\\nMust be None if path is not a string.\\n'},\n",
       "        {'param_name': 'storage_options',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.to_parquet',\n",
       "       'descriptions': 'Write a DataFrame to the binary parquet format. This function writes the dataframe as a parquet file. You can choose different parquet\\nbackends, and have the option of compression. See\\nthe user guide for more details.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'path': {'type': 'string',\n",
       "          'description': 'str, path object, file-like object, or None, default None. String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a binary write() function. If None, the result is\\nreturned as bytes. If a string or path, it will be used as Root Directory\\npath when writing a partitioned dataset.\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'enum': ['auto', ' pyarrow', ' fastparquet'],\n",
       "          'description': '{‘auto’, ‘pyarrow’, ‘fastparquet’}, default ‘auto’. Parquet library to use. If ‘auto’, then the option\\nio.parquet.engine is used. The default io.parquet.engine\\nbehavior is to try ‘pyarrow’, falling back to ‘fastparquet’ if\\n‘pyarrow’ is unavailable.\\n'},\n",
       "         'compression': {'type': 'string',\n",
       "          'description': 'str or None, default ‘snappy’. Name of the compression to use. Use None for no compression.\\nSupported options: ‘snappy’, ‘gzip’, ‘brotli’, ‘lz4’, ‘zstd’.\\n'},\n",
       "         'index': {'type': 'boolean',\n",
       "          'description': 'bool, default None. If True, include the dataframe’s index(es) in the file output.\\nIf False, they will not be written to the file.\\nIf None, similar to True the dataframe’s index(es)\\nwill be saved. However, instead of being saved as values,\\nthe RangeIndex will be stored as a range in the metadata so it\\ndoesn’t require much space and is faster. Other indexes will\\nbe included as columns in the file output.\\n'},\n",
       "         'partition_cols': {'type': 'array',\n",
       "          'description': 'list, optional, default None. Column names by which to partition the dataset.\\nColumns are partitioned in the order they are given.\\nMust be None if path is not a string.\\n'},\n",
       "         'storage_options': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'}},\n",
       "        'required': ['path=None']}}},\n",
       "     {'func_name': 'DataFrame.to_csv([path_or_buf,\\xa0sep,\\xa0na_rep,\\xa0...])',\n",
       "      'func_desc': 'Write object to a comma-separated values (csv) file.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html#pandas.DataFrame.to_csv',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_csv',\n",
       "       'full_function': 'DataFrame.to_csv(path_or_buf=None, *, sep=\\',\\', na_rep=\\'\\', float_format=None, columns=None, header=True, index=True, index_label=None, mode=\\'w\\', encoding=None, compression=\\'infer\\', quoting=None, quotechar=\\'\"\\', lineterminator=None, chunksize=None, date_format=None, doublequote=True, escapechar=None, decimal=\\'.\\', errors=\\'strict\\', storage_options=None)',\n",
       "       'function_text': 'Write object to a comma-separated values (csv) file.',\n",
       "       'parameter_names_desc': [{'param_name': 'path_or_buf',\n",
       "         'param_type': 'str, path object, file-like object, or None, default None',\n",
       "         'param_desc': 'String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a write() function. If None, the result is\\nreturned as a string. If a non-binary file object is passed, it should\\nbe opened with newline=’’, disabling universal newlines. If a binary\\nfile object is passed, mode might need to contain a ‘b’.\\n'},\n",
       "        {'param_name': 'sep',\n",
       "         'param_type': 'str, default ‘,’',\n",
       "         'param_desc': 'String of length 1. Field delimiter for the output file.\\n'},\n",
       "        {'param_name': 'na_rep',\n",
       "         'param_type': 'str, default ‘’',\n",
       "         'param_desc': 'Missing data representation.\\n'},\n",
       "        {'param_name': 'float_format',\n",
       "         'param_type': 'str, Callable, default None',\n",
       "         'param_desc': 'Format string for floating point numbers. If a Callable is given, it takes\\nprecedence over other numeric formatting parameters, like decimal.\\n'},\n",
       "        {'param_name': 'columns',\n",
       "         'param_type': 'sequence, optional',\n",
       "         'param_desc': 'Columns to write.\\n'},\n",
       "        {'param_name': 'header',\n",
       "         'param_type': 'bool or list of str, default True',\n",
       "         'param_desc': 'Write out the column names. If a list of strings is given it is\\nassumed to be aliases for the column names.\\n'},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Write row names (index).\\n'},\n",
       "        {'param_name': 'index_label',\n",
       "         'param_type': 'str or sequence, or False, default None',\n",
       "         'param_desc': 'Column label for index column(s) if desired. If None is given, and\\nheader and index are True, then the index names are used. A\\nsequence should be given if the object uses MultiIndex. If\\nFalse do not print fields for index names. Use index_label=False\\nfor easier importing in R.\\n'},\n",
       "        {'param_name': 'mode',\n",
       "         'param_type': '{‘w’, ‘x’, ‘a’}, default ‘w’',\n",
       "         'param_desc': 'Forwarded to either open(mode=) or fsspec.open(mode=) to control\\nthe file opening. Typical values include:\\n\\n‘w’, truncate the file first.\\n‘x’, exclusive creation, failing if the file already exists.\\n‘a’, append to the end of file if it exists.\\n\\n'},\n",
       "        {'param_name': 'encoding',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'A string representing the encoding to use in the output file,\\ndefaults to ‘utf-8’. encoding is not supported if path_or_buf\\nis a non-binary file object.\\n'},\n",
       "        {'param_name': 'compression',\n",
       "         'param_type': 'str or dict, default ‘infer’',\n",
       "         'param_desc': \"For on-the-fly compression of the output data. If ‘infer’ and ‘path_or_buf’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nSet to None for no compression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for faster compression and to create\\na reproducible gzip archive:\\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\nMay be a dict with key ‘method’ as compression mode\\nand other entries as additional compression options if\\ncompression mode is ‘zip’.\\nPassing compression options as keys in dict is\\nsupported for compression modes ‘gzip’, ‘bz2’, ‘zstd’, and ‘zip’.\\n\\n\"},\n",
       "        {'param_name': 'quoting',\n",
       "         'param_type': 'optional constant from csv module',\n",
       "         'param_desc': 'Defaults to csv.QUOTE_MINIMAL. If you have set a float_format\\nthen floats are converted to strings and thus csv.QUOTE_NONNUMERIC\\nwill treat them as non-numeric.\\n'},\n",
       "        {'param_name': 'quotechar',\n",
       "         'param_type': 'str, default ‘\"’',\n",
       "         'param_desc': 'String of length 1. Character used to quote fields.\\n'},\n",
       "        {'param_name': 'lineterminator',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'The newline character or character sequence to use in the output\\nfile. Defaults to os.linesep, which depends on the OS in which\\nthis method is called (’\\\\n’ for linux, ‘\\\\r\\\\n’ for Windows, i.e.).\\n\\nChanged in version 1.5.0: Previously was line_terminator, changed for consistency with\\nread_csv and the standard library ‘csv’ module.\\n\\n'},\n",
       "        {'param_name': 'chunksize',\n",
       "         'param_type': 'int or None',\n",
       "         'param_desc': 'Rows to write at a time.\\n'},\n",
       "        {'param_name': 'date_format',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'Format string for datetime objects.\\n'},\n",
       "        {'param_name': 'doublequote',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Control quoting of quotechar inside a field.\\n'},\n",
       "        {'param_name': 'escapechar',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'String of length 1. Character used to escape sep and quotechar\\nwhen appropriate.\\n'},\n",
       "        {'param_name': 'decimal',\n",
       "         'param_type': 'str, default ‘.’',\n",
       "         'param_desc': 'Character recognized as decimal separator. E.g. use ‘,’ for\\nEuropean data.\\n'},\n",
       "        {'param_name': 'errors',\n",
       "         'param_type': 'str, default ‘strict’',\n",
       "         'param_desc': 'Specifies how encoding and decoding errors are to be handled.\\nSee the errors argument for open() for a full list\\nof options.\\n'},\n",
       "        {'param_name': 'storage_options',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.to_csv',\n",
       "       'descriptions': 'Write object to a comma-separated values (csv) file.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'path_or_buf': {'type': 'string',\n",
       "          'description': 'str, path object, file-like object, or None, default None. String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a write() function. If None, the result is\\nreturned as a string. If a non-binary file object is passed, it should\\nbe opened with newline=’’, disabling universal newlines. If a binary\\nfile object is passed, mode might need to contain a ‘b’.\\n'},\n",
       "         'sep': {'type': 'string',\n",
       "          'description': 'str, default ‘,’. String of length 1. Field delimiter for the output file.\\n'},\n",
       "         'na_rep': {'type': 'string',\n",
       "          'description': 'str, default ‘’. Missing data representation.\\n'},\n",
       "         'float_format': {'type': 'string',\n",
       "          'description': 'str, Callable, default None. Format string for floating point numbers. If a Callable is given, it takes\\nprecedence over other numeric formatting parameters, like decimal.\\n'},\n",
       "         'columns': {'type': 'sequence, optional',\n",
       "          'description': 'sequence, optional. Columns to write.\\n'},\n",
       "         'header': {'type': 'string',\n",
       "          'description': 'bool or list of str, default True. Write out the column names. If a list of strings is given it is\\nassumed to be aliases for the column names.\\n'},\n",
       "         'index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Write row names (index).\\n'},\n",
       "         'index_label': {'type': 'string',\n",
       "          'description': 'str or sequence, or False, default None. Column label for index column(s) if desired. If None is given, and\\nheader and index are True, then the index names are used. A\\nsequence should be given if the object uses MultiIndex. If\\nFalse do not print fields for index names. Use index_label=False\\nfor easier importing in R.\\n'},\n",
       "         'mode': {'type': 'string',\n",
       "          'enum': ['w', ' x', ' a'],\n",
       "          'description': '{‘w’, ‘x’, ‘a’}, default ‘w’. Forwarded to either open(mode=) or fsspec.open(mode=) to control\\nthe file opening. Typical values include:\\n\\n‘w’, truncate the file first.\\n‘x’, exclusive creation, failing if the file already exists.\\n‘a’, append to the end of file if it exists.\\n\\n'},\n",
       "         'encoding': {'type': 'string',\n",
       "          'description': 'str, optional. A string representing the encoding to use in the output file,\\ndefaults to ‘utf-8’. encoding is not supported if path_or_buf\\nis a non-binary file object.\\n'},\n",
       "         'compression': {'type': 'string',\n",
       "          'description': \"str or dict, default ‘infer’. For on-the-fly compression of the output data. If ‘infer’ and ‘path_or_buf’ is\\npath-like, then detect compression from the following extensions: ‘.gz’,\\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\\n(otherwise no compression).\\nSet to None for no compression.\\nCan also be a dict with key 'method' set\\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\\nother key-value pairs are forwarded to\\nzipfile.ZipFile, gzip.GzipFile,\\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\\ntarfile.TarFile, respectively.\\nAs an example, the following could be passed for faster compression and to create\\na reproducible gzip archive:\\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\\n\\nNew in version 1.5.0: Added support for .tar files.\\nMay be a dict with key ‘method’ as compression mode\\nand other entries as additional compression options if\\ncompression mode is ‘zip’.\\nPassing compression options as keys in dict is\\nsupported for compression modes ‘gzip’, ‘bz2’, ‘zstd’, and ‘zip’.\\n\\n\"},\n",
       "         'quoting': {'type': 'optional constant from csv module',\n",
       "          'description': 'optional constant from csv module. Defaults to csv.QUOTE_MINIMAL. If you have set a float_format\\nthen floats are converted to strings and thus csv.QUOTE_NONNUMERIC\\nwill treat them as non-numeric.\\n'},\n",
       "         'quotechar': {'type': 'string',\n",
       "          'description': 'str, default ‘\"’. String of length 1. Character used to quote fields.\\n'},\n",
       "         'lineterminator': {'type': 'string',\n",
       "          'description': 'str, optional. The newline character or character sequence to use in the output\\nfile. Defaults to os.linesep, which depends on the OS in which\\nthis method is called (’\\\\n’ for linux, ‘\\\\r\\\\n’ for Windows, i.e.).\\n\\nChanged in version 1.5.0: Previously was line_terminator, changed for consistency with\\nread_csv and the standard library ‘csv’ module.\\n\\n'},\n",
       "         'chunksize': {'type': 'integer',\n",
       "          'description': 'int or None. Rows to write at a time.\\n'},\n",
       "         'date_format': {'type': 'string',\n",
       "          'description': 'str, default None. Format string for datetime objects.\\n'},\n",
       "         'doublequote': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Control quoting of quotechar inside a field.\\n'},\n",
       "         'escapechar': {'type': 'string',\n",
       "          'description': 'str, default None. String of length 1. Character used to escape sep and quotechar\\nwhen appropriate.\\n'},\n",
       "         'decimal': {'type': 'string',\n",
       "          'description': 'str, default ‘.’. Character recognized as decimal separator. E.g. use ‘,’ for\\nEuropean data.\\n'},\n",
       "         'errors': {'type': 'string',\n",
       "          'description': 'str, default ‘strict’. Specifies how encoding and decoding errors are to be handled.\\nSee the errors argument for open() for a full list\\nof options.\\n'},\n",
       "         'storage_options': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'}},\n",
       "        'required': ['path_or_buf=None']}}},\n",
       "     {'func_name': 'DataFrame.to_sql(name,\\xa0con,\\xa0*[,\\xa0schema,\\xa0...])',\n",
       "      'func_desc': 'Write records stored in a DataFrame to a SQL database.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_sql.html#pandas.DataFrame.to_sql',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_sql',\n",
       "       'full_function': \"DataFrame.to_sql(name, con, *, schema=None, if_exists='fail', index=True, index_label=None, chunksize=None, dtype=None, method=None)\",\n",
       "       'function_text': 'Write records stored in a DataFrame to a SQL database. Databases supported by SQLAlchemy [1] are supported. Tables can be\\nnewly created, appended to, or overwritten.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrame.to_excel(excel_writer,\\xa0*[,\\xa0...])',\n",
       "      'func_desc': 'Write object to an Excel sheet.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_excel.html#pandas.DataFrame.to_excel',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_excel',\n",
       "       'full_function': \"DataFrame.to_excel(excel_writer, *, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, inf_rep='inf', freeze_panes=None, storage_options=None, engine_kwargs=None)\",\n",
       "       'function_text': 'Write object to an Excel sheet. To write a single object to an Excel .xlsx file it is only necessary to\\nspecify a target file name. To write to multiple sheets it is necessary to\\ncreate an ExcelWriter object with a target file name, and specify a sheet\\nin the file to write to. Multiple sheets may be written to by specifying unique sheet_name.\\nWith all data written to the file it is necessary to save the changes.\\nNote that creating an ExcelWriter object with a file name that already\\nexists will result in the contents of the existing file being erased.',\n",
       "       'parameter_names_desc': [{'param_name': 'excel_writer',\n",
       "         'param_type': 'path-like, file-like, or ExcelWriter object',\n",
       "         'param_desc': 'File path or existing ExcelWriter.\\n'},\n",
       "        {'param_name': 'sheet_name',\n",
       "         'param_type': 'str, default ‘Sheet1’',\n",
       "         'param_desc': 'Name of sheet which will contain DataFrame.\\n'},\n",
       "        {'param_name': 'na_rep',\n",
       "         'param_type': 'str, default ‘’',\n",
       "         'param_desc': 'Missing data representation.\\n'},\n",
       "        {'param_name': 'float_format',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Format string for floating point numbers. For example\\nfloat_format=\"%.2f\" will format 0.1234 to 0.12.\\n'},\n",
       "        {'param_name': 'columns',\n",
       "         'param_type': 'sequence or list of str, optional',\n",
       "         'param_desc': 'Columns to write.\\n'},\n",
       "        {'param_name': 'header',\n",
       "         'param_type': 'bool or list of str, default True',\n",
       "         'param_desc': 'Write out the column names. If a list of string is given it is\\nassumed to be aliases for the column names.\\n'},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Write row names (index).\\n'},\n",
       "        {'param_name': 'index_label',\n",
       "         'param_type': 'str or sequence, optional',\n",
       "         'param_desc': 'Column label for index column(s) if desired. If not specified, and\\nheader and index are True, then the index names are used. A\\nsequence should be given if the DataFrame uses MultiIndex.\\n'},\n",
       "        {'param_name': 'startrow',\n",
       "         'param_type': 'int, default 0',\n",
       "         'param_desc': 'Upper left cell row to dump data frame.\\n'},\n",
       "        {'param_name': 'startcol',\n",
       "         'param_type': 'int, default 0',\n",
       "         'param_desc': 'Upper left cell column to dump data frame.\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Write engine to use, ‘openpyxl’ or ‘xlsxwriter’. You can also set this\\nvia the options io.excel.xlsx.writer or\\nio.excel.xlsm.writer.\\n'},\n",
       "        {'param_name': 'merge_cells',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Write MultiIndex and Hierarchical Rows as merged cells.\\n'},\n",
       "        {'param_name': 'inf_rep',\n",
       "         'param_type': 'str, default ‘inf’',\n",
       "         'param_desc': 'Representation for infinity (there is no native representation for\\ninfinity in Excel).\\n'},\n",
       "        {'param_name': 'freeze_panes',\n",
       "         'param_type': 'tuple of int (length 2), optional',\n",
       "         'param_desc': 'Specifies the one-based bottommost row and rightmost column that\\nis to be frozen.\\n'},\n",
       "        {'param_name': 'storage_options',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n\\nNew in version 1.2.0.\\n\\n'},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Arbitrary keyword arguments passed to excel engine.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.to_excel',\n",
       "       'descriptions': 'Write object to an Excel sheet. To write a single object to an Excel .xlsx file it is only necessary to\\nspecify a target file name. To write to multiple sheets it is necessary to\\ncreate an ExcelWriter object with a target file name, and specify a sheet\\nin the file to write to. Multiple sheets may be written to by specifying unique sheet_name.\\nWith all data written to the file it is necessary to save the changes.\\nNote that creating an ExcelWriter object with a file name that already\\nexists will result in the contents of the existing file being erased.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'excel_writer': {'type': 'object',\n",
       "          'description': 'path-like, file-like, or ExcelWriter object. File path or existing ExcelWriter.\\n'},\n",
       "         'sheet_name': {'type': 'string',\n",
       "          'description': 'str, default ‘Sheet1’. Name of sheet which will contain DataFrame.\\n'},\n",
       "         'na_rep': {'type': 'string',\n",
       "          'description': 'str, default ‘’. Missing data representation.\\n'},\n",
       "         'float_format': {'type': 'string',\n",
       "          'description': 'str, optional. Format string for floating point numbers. For example\\nfloat_format=\"%.2f\" will format 0.1234 to 0.12.\\n'},\n",
       "         'columns': {'type': 'string',\n",
       "          'description': 'sequence or list of str, optional. Columns to write.\\n'},\n",
       "         'header': {'type': 'string',\n",
       "          'description': 'bool or list of str, default True. Write out the column names. If a list of string is given it is\\nassumed to be aliases for the column names.\\n'},\n",
       "         'index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Write row names (index).\\n'},\n",
       "         'index_label': {'type': 'string',\n",
       "          'description': 'str or sequence, optional. Column label for index column(s) if desired. If not specified, and\\nheader and index are True, then the index names are used. A\\nsequence should be given if the DataFrame uses MultiIndex.\\n'},\n",
       "         'startrow': {'type': 'integer',\n",
       "          'description': 'int, default 0. Upper left cell row to dump data frame.\\n'},\n",
       "         'startcol': {'type': 'integer',\n",
       "          'description': 'int, default 0. Upper left cell column to dump data frame.\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': 'str, optional. Write engine to use, ‘openpyxl’ or ‘xlsxwriter’. You can also set this\\nvia the options io.excel.xlsx.writer or\\nio.excel.xlsm.writer.\\n'},\n",
       "         'merge_cells': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Write MultiIndex and Hierarchical Rows as merged cells.\\n'},\n",
       "         'inf_rep': {'type': 'string',\n",
       "          'description': 'str, default ‘inf’. Representation for infinity (there is no native representation for\\ninfinity in Excel).\\n'},\n",
       "         'freeze_panes': {'type': 'integer',\n",
       "          'description': 'tuple of int (length 2), optional. Specifies the one-based bottommost row and rightmost column that\\nis to be frozen.\\n'},\n",
       "         'storage_options': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n\\nNew in version 1.2.0.\\n\\n'},\n",
       "         'engine_kwargs': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Arbitrary keyword arguments passed to excel engine.\\n'}},\n",
       "        'required': ['excel_writer']}}},\n",
       "     {'func_name': 'DataFrame.to_html([buf,\\xa0columns,\\xa0col_space,\\xa0...])',\n",
       "      'func_desc': 'Render a DataFrame as an HTML table.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_html.html#pandas.DataFrame.to_html',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_html',\n",
       "       'full_function': \"DataFrame.to_html(buf=None, *, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, justify=None, max_rows=None, max_cols=None, show_dimensions=False, decimal='.', bold_rows=True, classes=None, escape=True, notebook=False, border=None, table_id=None, render_links=False, encoding=None)\",\n",
       "       'function_text': 'Render a DataFrame as an HTML table.',\n",
       "       'parameter_names_desc': [{'param_name': 'buf',\n",
       "         'param_type': 'str, Path or StringIO-like, optional, default None',\n",
       "         'param_desc': 'Buffer to write to. If None, the output is returned as a string.\\n'},\n",
       "        {'param_name': 'columns',\n",
       "         'param_type': 'array-like, optional, default None',\n",
       "         'param_desc': 'The subset of columns to write. Writes all columns by default.\\n'},\n",
       "        {'param_name': 'col_space',\n",
       "         'param_type': 'str or int, list or dict of int or str, optional',\n",
       "         'param_desc': 'The minimum width of each column in CSS length units. An int is assumed to be px units..\\n'},\n",
       "        {'param_name': 'header',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'Whether to print column labels, default True.\\n'},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'bool, optional, default True',\n",
       "         'param_desc': 'Whether to print index (row) labels.\\n'},\n",
       "        {'param_name': 'na_rep',\n",
       "         'param_type': 'str, optional, default ‘NaN’',\n",
       "         'param_desc': 'String representation of NaN to use.\\n'},\n",
       "        {'param_name': 'formatters',\n",
       "         'param_type': 'list, tuple or dict of one-param. functions, optional',\n",
       "         'param_desc': 'Formatter functions to apply to columns’ elements by position or\\nname.\\nThe result of each function must be a unicode string.\\nList/tuple must be of length equal to the number of columns.\\n'},\n",
       "        {'param_name': 'float_format',\n",
       "         'param_type': 'one-parameter function, optional, default None',\n",
       "         'param_desc': 'Formatter function to apply to columns’ elements if they are\\nfloats. This function must return a unicode string and will be\\napplied only to the non-NaN elements, with NaN being\\nhandled by na_rep.\\n'},\n",
       "        {'param_name': 'sparsify',\n",
       "         'param_type': 'bool, optional, default True',\n",
       "         'param_desc': 'Set to False for a DataFrame with a hierarchical index to print\\nevery multiindex key at each row.\\n'},\n",
       "        {'param_name': 'index_names',\n",
       "         'param_type': 'bool, optional, default True',\n",
       "         'param_desc': 'Prints the names of the indexes.\\n'},\n",
       "        {'param_name': 'justify',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'How to justify the column labels. If None uses the option from\\nthe print configuration (controlled by set_option), ‘right’ out\\nof the box. Valid values are\\n\\nleft\\nright\\ncenter\\njustify\\njustify-all\\nstart\\nend\\ninherit\\nmatch-parent\\ninitial\\nunset.\\n\\n'},\n",
       "        {'param_name': 'max_rows',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Maximum number of rows to display in the console.\\n'},\n",
       "        {'param_name': 'max_cols',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Maximum number of columns to display in the console.\\n'},\n",
       "        {'param_name': 'show_dimensions',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Display DataFrame dimensions (number of rows by number of columns).\\n'},\n",
       "        {'param_name': 'decimal',\n",
       "         'param_type': 'str, default ‘.’',\n",
       "         'param_desc': 'Character recognized as decimal separator, e.g. ‘,’ in Europe.\\n'},\n",
       "        {'param_name': 'bold_rows',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Make the row labels bold in the output.\\n'},\n",
       "        {'param_name': 'classes',\n",
       "         'param_type': 'str or list or tuple, default None',\n",
       "         'param_desc': 'CSS class(es) to apply to the resulting html table.\\n'},\n",
       "        {'param_name': 'escape',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Convert the characters <, >, and & to HTML-safe sequences.\\n'},\n",
       "        {'param_name': 'notebook',\n",
       "         'param_type': '{True, False}, default False',\n",
       "         'param_desc': 'Whether the generated HTML is for IPython Notebook.\\n'},\n",
       "        {'param_name': 'border',\n",
       "         'param_type': 'int',\n",
       "         'param_desc': 'A border=border attribute is included in the opening\\n<table> tag. Default pd.options.display.html.border.\\n'},\n",
       "        {'param_name': 'table_id',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'A css id is included in the opening <table> tag if specified.\\n'},\n",
       "        {'param_name': 'render_links',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Convert URLs to HTML links.\\n'},\n",
       "        {'param_name': 'encoding',\n",
       "         'param_type': 'str, default “utf-8”',\n",
       "         'param_desc': 'Set character encoding.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.to_html',\n",
       "       'descriptions': 'Render a DataFrame as an HTML table.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'buf': {'type': 'string',\n",
       "          'description': 'str, Path or StringIO-like, optional, default None. Buffer to write to. If None, the output is returned as a string.\\n'},\n",
       "         'columns': {'type': 'array',\n",
       "          'description': 'array-like, optional, default None. The subset of columns to write. Writes all columns by default.\\n'},\n",
       "         'col_space': {'type': 'integer',\n",
       "          'description': 'str or int, list or dict of int or str, optional. The minimum width of each column in CSS length units. An int is assumed to be px units..\\n'},\n",
       "         'header': {'type': 'boolean',\n",
       "          'description': 'bool, optional. Whether to print column labels, default True.\\n'},\n",
       "         'index': {'type': 'boolean',\n",
       "          'description': 'bool, optional, default True. Whether to print index (row) labels.\\n'},\n",
       "         'na_rep': {'type': 'string',\n",
       "          'description': 'str, optional, default ‘NaN’. String representation of NaN to use.\\n'},\n",
       "         'formatters': {'type': 'array',\n",
       "          'description': 'list, tuple or dict of one-param. functions, optional. Formatter functions to apply to columns’ elements by position or\\nname.\\nThe result of each function must be a unicode string.\\nList/tuple must be of length equal to the number of columns.\\n'},\n",
       "         'float_format': {'type': 'one-parameter function, optional, default None',\n",
       "          'description': 'one-parameter function, optional, default None. Formatter function to apply to columns’ elements if they are\\nfloats. This function must return a unicode string and will be\\napplied only to the non-NaN elements, with NaN being\\nhandled by na_rep.\\n'},\n",
       "         'sparsify': {'type': 'boolean',\n",
       "          'description': 'bool, optional, default True. Set to False for a DataFrame with a hierarchical index to print\\nevery multiindex key at each row.\\n'},\n",
       "         'index_names': {'type': 'boolean',\n",
       "          'description': 'bool, optional, default True. Prints the names of the indexes.\\n'},\n",
       "         'justify': {'type': 'string',\n",
       "          'description': 'str, default None. How to justify the column labels. If None uses the option from\\nthe print configuration (controlled by set_option), ‘right’ out\\nof the box. Valid values are\\n\\nleft\\nright\\ncenter\\njustify\\njustify-all\\nstart\\nend\\ninherit\\nmatch-parent\\ninitial\\nunset.\\n\\n'},\n",
       "         'max_rows': {'type': 'integer',\n",
       "          'description': 'int, optional. Maximum number of rows to display in the console.\\n'},\n",
       "         'max_cols': {'type': 'integer',\n",
       "          'description': 'int, optional. Maximum number of columns to display in the console.\\n'},\n",
       "         'show_dimensions': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Display DataFrame dimensions (number of rows by number of columns).\\n'},\n",
       "         'decimal': {'type': 'string',\n",
       "          'description': 'str, default ‘.’. Character recognized as decimal separator, e.g. ‘,’ in Europe.\\n'},\n",
       "         'bold_rows': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Make the row labels bold in the output.\\n'},\n",
       "         'classes': {'type': 'string',\n",
       "          'description': 'str or list or tuple, default None. CSS class(es) to apply to the resulting html table.\\n'},\n",
       "         'escape': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Convert the characters <, >, and & to HTML-safe sequences.\\n'},\n",
       "         'notebook': {'type': '{True, False}, default False',\n",
       "          'description': '{True, False}, default False. Whether the generated HTML is for IPython Notebook.\\n'},\n",
       "         'border': {'type': 'integer',\n",
       "          'description': 'int. A border=border attribute is included in the opening\\n<table> tag. Default pd.options.display.html.border.\\n'},\n",
       "         'table_id': {'type': 'string',\n",
       "          'description': 'str, optional. A css id is included in the opening <table> tag if specified.\\n'},\n",
       "         'render_links': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Convert URLs to HTML links.\\n'},\n",
       "         'encoding': {'type': 'string',\n",
       "          'description': 'str, default “utf-8”. Set character encoding.\\n'}},\n",
       "        'required': ['buf=None']}}},\n",
       "     {'func_name': 'DataFrame.to_latex([buf,\\xa0columns,\\xa0header,\\xa0...])',\n",
       "      'func_desc': 'Render object to a LaTeX tabular, longtable, or nested table.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_latex.html#pandas.DataFrame.to_latex',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_latex',\n",
       "       'full_function': \"DataFrame.to_latex(buf=None, *, columns=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, bold_rows=False, column_format=None, longtable=None, escape=None, encoding=None, decimal='.', multicolumn=None, multicolumn_format=None, multirow=None, caption=None, label=None, position=None)\",\n",
       "       'function_text': 'Render object to a LaTeX tabular, longtable, or nested table. Requires \\\\usepackage{{booktabs}}. The output can be copy/pasted\\ninto a main LaTeX document or read from an external file\\nwith \\\\input{{table.tex}}. Changed in version 2.0.0: Refactored to use the Styler implementation via jinja2 templating.',\n",
       "       'parameter_names_desc': [{'param_name': 'buf',\n",
       "         'param_type': 'str, Path or StringIO-like, optional, default None',\n",
       "         'param_desc': 'Buffer to write to. If None, the output is returned as a string.\\n'},\n",
       "        {'param_name': 'columns',\n",
       "         'param_type': 'list of label, optional',\n",
       "         'param_desc': 'The subset of columns to write. Writes all columns by default.\\n'},\n",
       "        {'param_name': 'header',\n",
       "         'param_type': 'bool or list of str, default True',\n",
       "         'param_desc': 'Write out the column names. If a list of strings is given,\\nit is assumed to be aliases for the column names.\\n'},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Write row names (index).\\n'},\n",
       "        {'param_name': 'na_rep',\n",
       "         'param_type': 'str, default ‘NaN’',\n",
       "         'param_desc': 'Missing data representation.\\n'},\n",
       "        {'param_name': 'formatters',\n",
       "         'param_type': 'list of functions or dict of {{str: function}}, optional',\n",
       "         'param_desc': 'Formatter functions to apply to columns’ elements by position or\\nname. The result of each function must be a unicode string.\\nList must be of length equal to the number of columns.\\n'},\n",
       "        {'param_name': 'float_format',\n",
       "         'param_type': 'one-parameter function or str, optional, default None',\n",
       "         'param_desc': 'Formatter for floating point numbers. For example\\nfloat_format=\"%.2f\" and float_format=\"{{:0.2f}}\".format will\\nboth result in 0.1234 being formatted as 0.12.\\n'},\n",
       "        {'param_name': 'sparsify',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'Set to False for a DataFrame with a hierarchical index to print\\nevery multiindex key at each row. By default, the value will be\\nread from the config module.\\n'},\n",
       "        {'param_name': 'index_names',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Prints the names of the indexes.\\n'},\n",
       "        {'param_name': 'bold_rows',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Make the row labels bold in the output.\\n'},\n",
       "        {'param_name': 'column_format',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'The columns format as specified in LaTeX table format e.g. ‘rcl’ for 3\\ncolumns. By default, ‘l’ will be used for all columns except\\ncolumns of numbers, which default to ‘r’.\\n'},\n",
       "        {'param_name': 'longtable',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'Use a longtable environment instead of tabular. Requires\\nadding a usepackage{{longtable}} to your LaTeX preamble.\\nBy default, the value will be read from the pandas config\\nmodule, and set to True if the option styler.latex.environment is\\n“longtable”.\\n\\nChanged in version 2.0.0: The pandas option affecting this argument has changed.\\n\\n'},\n",
       "        {'param_name': 'escape',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'By default, the value will be read from the pandas config\\nmodule and set to True if the option styler.format.escape is\\n“latex”. When set to False prevents from escaping latex special\\ncharacters in column names.\\n\\nChanged in version 2.0.0: The pandas option affecting this argument has changed, as has the\\ndefault value to False.\\n\\n'},\n",
       "        {'param_name': 'encoding',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'A string representing the encoding to use in the output file,\\ndefaults to ‘utf-8’.\\n'},\n",
       "        {'param_name': 'decimal',\n",
       "         'param_type': 'str, default ‘.’',\n",
       "         'param_desc': 'Character recognized as decimal separator, e.g. ‘,’ in Europe.\\n'},\n",
       "        {'param_name': 'multicolumn',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Use multicolumn to enhance MultiIndex columns.\\nThe default will be read from the config module, and is set\\nas the option styler.sparse.columns.\\n\\nChanged in version 2.0.0: The pandas option affecting this argument has changed.\\n\\n'},\n",
       "        {'param_name': 'multicolumn_format',\n",
       "         'param_type': 'str, default ‘r’',\n",
       "         'param_desc': 'The alignment for multicolumns, similar to column_format\\nThe default will be read from the config module, and is set as the option\\nstyler.latex.multicol_align.\\n\\nChanged in version 2.0.0: The pandas option affecting this argument has changed, as has the\\ndefault value to “r”.\\n\\n'},\n",
       "        {'param_name': 'multirow',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Use multirow to enhance MultiIndex rows. Requires adding a\\nusepackage{{multirow}} to your LaTeX preamble. Will print\\ncentered labels (instead of top-aligned) across the contained\\nrows, separating groups via clines. The default will be read\\nfrom the pandas config module, and is set as the option\\nstyler.sparse.index.\\n\\nChanged in version 2.0.0: The pandas option affecting this argument has changed, as has the\\ndefault value to True.\\n\\n'},\n",
       "        {'param_name': 'caption',\n",
       "         'param_type': 'str or tuple, optional',\n",
       "         'param_desc': 'Tuple (full_caption, short_caption),\\nwhich results in \\\\caption[short_caption]{{full_caption}};\\nif a single string is passed, no short caption will be set.\\n'},\n",
       "        {'param_name': 'label',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'The LaTeX label to be placed inside \\\\label{{}} in the output.\\nThis is used with \\\\ref{{}} in the main .tex file.\\n'},\n",
       "        {'param_name': 'position',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'The LaTeX positional argument for tables, to be placed after\\n\\\\begin{{}} in the output.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.to_latex',\n",
       "       'descriptions': 'Render object to a LaTeX tabular, longtable, or nested table. Requires \\\\usepackage{{booktabs}}. The output can be copy/pasted\\ninto a main LaTeX document or read from an external file\\nwith \\\\input{{table.tex}}. Changed in version 2.0.0: Refactored to use the Styler implementation via jinja2 templating.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'buf': {'type': 'string',\n",
       "          'description': 'str, Path or StringIO-like, optional, default None. Buffer to write to. If None, the output is returned as a string.\\n'},\n",
       "         'columns': {'type': 'array',\n",
       "          'description': 'list of label, optional. The subset of columns to write. Writes all columns by default.\\n'},\n",
       "         'header': {'type': 'string',\n",
       "          'description': 'bool or list of str, default True. Write out the column names. If a list of strings is given,\\nit is assumed to be aliases for the column names.\\n'},\n",
       "         'index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Write row names (index).\\n'},\n",
       "         'na_rep': {'type': 'string',\n",
       "          'description': 'str, default ‘NaN’. Missing data representation.\\n'},\n",
       "         'formatters': {'type': 'string',\n",
       "          'description': 'list of functions or dict of {{str: function}}, optional. Formatter functions to apply to columns’ elements by position or\\nname. The result of each function must be a unicode string.\\nList must be of length equal to the number of columns.\\n'},\n",
       "         'float_format': {'type': 'string',\n",
       "          'description': 'one-parameter function or str, optional, default None. Formatter for floating point numbers. For example\\nfloat_format=\"%.2f\" and float_format=\"{{:0.2f}}\".format will\\nboth result in 0.1234 being formatted as 0.12.\\n'},\n",
       "         'sparsify': {'type': 'boolean',\n",
       "          'description': 'bool, optional. Set to False for a DataFrame with a hierarchical index to print\\nevery multiindex key at each row. By default, the value will be\\nread from the config module.\\n'},\n",
       "         'index_names': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Prints the names of the indexes.\\n'},\n",
       "         'bold_rows': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Make the row labels bold in the output.\\n'},\n",
       "         'column_format': {'type': 'string',\n",
       "          'description': 'str, optional. The columns format as specified in LaTeX table format e.g. ‘rcl’ for 3\\ncolumns. By default, ‘l’ will be used for all columns except\\ncolumns of numbers, which default to ‘r’.\\n'},\n",
       "         'longtable': {'type': 'boolean',\n",
       "          'description': 'bool, optional. Use a longtable environment instead of tabular. Requires\\nadding a usepackage{{longtable}} to your LaTeX preamble.\\nBy default, the value will be read from the pandas config\\nmodule, and set to True if the option styler.latex.environment is\\n“longtable”.\\n\\nChanged in version 2.0.0: The pandas option affecting this argument has changed.\\n\\n'},\n",
       "         'escape': {'type': 'boolean',\n",
       "          'description': 'bool, optional. By default, the value will be read from the pandas config\\nmodule and set to True if the option styler.format.escape is\\n“latex”. When set to False prevents from escaping latex special\\ncharacters in column names.\\n\\nChanged in version 2.0.0: The pandas option affecting this argument has changed, as has the\\ndefault value to False.\\n\\n'},\n",
       "         'encoding': {'type': 'string',\n",
       "          'description': 'str, optional. A string representing the encoding to use in the output file,\\ndefaults to ‘utf-8’.\\n'},\n",
       "         'decimal': {'type': 'string',\n",
       "          'description': 'str, default ‘.’. Character recognized as decimal separator, e.g. ‘,’ in Europe.\\n'},\n",
       "         'multicolumn': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Use multicolumn to enhance MultiIndex columns.\\nThe default will be read from the config module, and is set\\nas the option styler.sparse.columns.\\n\\nChanged in version 2.0.0: The pandas option affecting this argument has changed.\\n\\n'},\n",
       "         'multicolumn_format': {'type': 'string',\n",
       "          'description': 'str, default ‘r’. The alignment for multicolumns, similar to column_format\\nThe default will be read from the config module, and is set as the option\\nstyler.latex.multicol_align.\\n\\nChanged in version 2.0.0: The pandas option affecting this argument has changed, as has the\\ndefault value to “r”.\\n\\n'},\n",
       "         'multirow': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Use multirow to enhance MultiIndex rows. Requires adding a\\nusepackage{{multirow}} to your LaTeX preamble. Will print\\ncentered labels (instead of top-aligned) across the contained\\nrows, separating groups via clines. The default will be read\\nfrom the pandas config module, and is set as the option\\nstyler.sparse.index.\\n\\nChanged in version 2.0.0: The pandas option affecting this argument has changed, as has the\\ndefault value to True.\\n\\n'},\n",
       "         'caption': {'type': 'string',\n",
       "          'description': 'str or tuple, optional. Tuple (full_caption, short_caption),\\nwhich results in \\\\caption[short_caption]{{full_caption}};\\nif a single string is passed, no short caption will be set.\\n'},\n",
       "         'label': {'type': 'string',\n",
       "          'description': 'str, optional. The LaTeX label to be placed inside \\\\label{{}} in the output.\\nThis is used with \\\\ref{{}} in the main .tex file.\\n'},\n",
       "         'position': {'type': 'string',\n",
       "          'description': 'str, optional. The LaTeX positional argument for tables, to be placed after\\n\\\\begin{{}} in the output.\\n'}},\n",
       "        'required': ['buf=None']}}},\n",
       "     {'func_name': 'DataFrame.to_gbq(destination_table,\\xa0*[,\\xa0...])',\n",
       "      'func_desc': '(DEPRECATED) Write a DataFrame to a Google BigQuery table.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_gbq.html#pandas.DataFrame.to_gbq',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_gbq',\n",
       "       'full_function': \"DataFrame.to_gbq(destination_table, *, project_id=None, chunksize=None, reauth=False, if_exists='fail', auth_local_webserver=True, table_schema=None, location=None, progress_bar=True, credentials=None)\",\n",
       "       'function_text': 'Write a DataFrame to a Google BigQuery table. Deprecated since version 2.2.0: Please use pandas_gbq.to_gbq instead. This function requires the pandas-gbq package. See the How to authenticate with Google BigQuery\\nguide for authentication instructions.',\n",
       "       'parameter_names_desc': [{'param_name': 'destination_table',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'Name of table to be written, in the form dataset.tablename.\\n'},\n",
       "        {'param_name': 'project_id',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Google BigQuery Account project ID. Optional when available from\\nthe environment.\\n'},\n",
       "        {'param_name': 'chunksize',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Number of rows to be inserted in each chunk from the dataframe.\\nSet to None to load the whole dataframe at once.\\n'},\n",
       "        {'param_name': 'reauth',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Force Google BigQuery to re-authenticate the user. This is useful\\nif multiple accounts are used.\\n'},\n",
       "        {'param_name': 'if_exists',\n",
       "         'param_type': 'str, default ‘fail’',\n",
       "         'param_desc': \"Behavior when the destination table exists. Value can be one of:\\n\\n'fail'If table exists raise pandas_gbq.gbq.TableCreationError.\\n\\n'replace'If table exists, drop it, recreate it, and insert data.\\n\\n'append'If table exists, insert data. Create if does not exist.\\n\\n\\n\"},\n",
       "        {'param_name': 'auth_local_webserver',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Use the local webserver flow instead of the console flow\\nwhen getting user credentials.\\nNew in version 0.2.0 of pandas-gbq.\\n\\nChanged in version 1.5.0: Default value is changed to True. Google has deprecated the\\nauth_local_webserver = False “out of band” (copy-paste)\\nflow.\\n\\n'},\n",
       "        {'param_name': 'table_schema',\n",
       "         'param_type': 'list of dicts, optional',\n",
       "         'param_desc': \"List of BigQuery table fields to which according DataFrame\\ncolumns conform to, e.g. [{'name': 'col1', 'type':\\n'STRING'},...]. If schema is not provided, it will be\\ngenerated according to dtypes of DataFrame columns. See\\nBigQuery API documentation on available names of a field.\\nNew in version 0.3.1 of pandas-gbq.\\n\"},\n",
       "        {'param_name': 'location',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Location where the load job should run. See the BigQuery locations\\ndocumentation for a\\nlist of available locations. The location must match that of the\\ntarget dataset.\\nNew in version 0.5.0 of pandas-gbq.\\n'},\n",
       "        {'param_name': 'progress_bar',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Use the library tqdm to show the progress bar for the upload,\\nchunk by chunk.\\nNew in version 0.5.0 of pandas-gbq.\\n'},\n",
       "        {'param_name': 'credentials',\n",
       "         'param_type': 'google.auth.credentials.Credentials, optional',\n",
       "         'param_desc': 'Credentials for accessing Google APIs. Use this parameter to\\noverride default credentials, such as to use Compute Engine\\ngoogle.auth.compute_engine.Credentials or Service\\nAccount google.oauth2.service_account.Credentials\\ndirectly.\\nNew in version 0.8.0 of pandas-gbq.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.to_gbq',\n",
       "       'descriptions': 'Write a DataFrame to a Google BigQuery table. Deprecated since version 2.2.0: Please use pandas_gbq.to_gbq instead. This function requires the pandas-gbq package. See the How to authenticate with Google BigQuery\\nguide for authentication instructions.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'destination_table': {'type': 'string',\n",
       "          'description': 'str. Name of table to be written, in the form dataset.tablename.\\n'},\n",
       "         'project_id': {'type': 'string',\n",
       "          'description': 'str, optional. Google BigQuery Account project ID. Optional when available from\\nthe environment.\\n'},\n",
       "         'chunksize': {'type': 'integer',\n",
       "          'description': 'int, optional. Number of rows to be inserted in each chunk from the dataframe.\\nSet to None to load the whole dataframe at once.\\n'},\n",
       "         'reauth': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Force Google BigQuery to re-authenticate the user. This is useful\\nif multiple accounts are used.\\n'},\n",
       "         'if_exists': {'type': 'string',\n",
       "          'description': \"str, default ‘fail’. Behavior when the destination table exists. Value can be one of:\\n\\n'fail'If table exists raise pandas_gbq.gbq.TableCreationError.\\n\\n'replace'If table exists, drop it, recreate it, and insert data.\\n\\n'append'If table exists, insert data. Create if does not exist.\\n\\n\\n\"},\n",
       "         'auth_local_webserver': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Use the local webserver flow instead of the console flow\\nwhen getting user credentials.\\nNew in version 0.2.0 of pandas-gbq.\\n\\nChanged in version 1.5.0: Default value is changed to True. Google has deprecated the\\nauth_local_webserver = False “out of band” (copy-paste)\\nflow.\\n\\n'},\n",
       "         'table_schema': {'type': 'array',\n",
       "          'description': \"list of dicts, optional. List of BigQuery table fields to which according DataFrame\\ncolumns conform to, e.g. [{'name': 'col1', 'type':\\n'STRING'},...]. If schema is not provided, it will be\\ngenerated according to dtypes of DataFrame columns. See\\nBigQuery API documentation on available names of a field.\\nNew in version 0.3.1 of pandas-gbq.\\n\"},\n",
       "         'location': {'type': 'string',\n",
       "          'description': 'str, optional. Location where the load job should run. See the BigQuery locations\\ndocumentation for a\\nlist of available locations. The location must match that of the\\ntarget dataset.\\nNew in version 0.5.0 of pandas-gbq.\\n'},\n",
       "         'progress_bar': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Use the library tqdm to show the progress bar for the upload,\\nchunk by chunk.\\nNew in version 0.5.0 of pandas-gbq.\\n'},\n",
       "         'credentials': {'type': 'google.auth.credentials.Credentials, optional',\n",
       "          'description': 'google.auth.credentials.Credentials, optional. Credentials for accessing Google APIs. Use this parameter to\\noverride default credentials, such as to use Compute Engine\\ngoogle.auth.compute_engine.Credentials or Service\\nAccount google.oauth2.service_account.Credentials\\ndirectly.\\nNew in version 0.8.0 of pandas-gbq.\\n'}},\n",
       "        'required': ['destination_table']}}},\n",
       "     {'func_name': 'DataFrame.to_string([buf,\\xa0columns,\\xa0...])',\n",
       "      'func_desc': 'Render a DataFrame to a console-friendly tabular output.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_string.html#pandas.DataFrame.to_string',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_string',\n",
       "       'full_function': \"DataFrame.to_string(buf=None, *, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, justify=None, max_rows=None, max_cols=None, show_dimensions=False, decimal='.', line_width=None, min_rows=None, max_colwidth=None, encoding=None)\",\n",
       "       'function_text': 'Render a DataFrame to a console-friendly tabular output.',\n",
       "       'parameter_names_desc': [{'param_name': 'buf',\n",
       "         'param_type': 'str, Path or StringIO-like, optional, default None',\n",
       "         'param_desc': 'Buffer to write to. If None, the output is returned as a string.\\n'},\n",
       "        {'param_name': 'columns',\n",
       "         'param_type': 'array-like, optional, default None',\n",
       "         'param_desc': 'The subset of columns to write. Writes all columns by default.\\n'},\n",
       "        {'param_name': 'col_space',\n",
       "         'param_type': 'int, list or dict of int, optional',\n",
       "         'param_desc': 'The minimum width of each column. If a list of ints is given every integers corresponds with one column. If a dict is given, the key references the column, while the value defines the space to use..\\n'},\n",
       "        {'param_name': 'header',\n",
       "         'param_type': 'bool or list of str, optional',\n",
       "         'param_desc': 'Write out the column names. If a list of columns is given, it is assumed to be aliases for the column names.\\n'},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'bool, optional, default True',\n",
       "         'param_desc': 'Whether to print index (row) labels.\\n'},\n",
       "        {'param_name': 'na_rep',\n",
       "         'param_type': 'str, optional, default ‘NaN’',\n",
       "         'param_desc': 'String representation of NaN to use.\\n'},\n",
       "        {'param_name': 'formatters',\n",
       "         'param_type': 'list, tuple or dict of one-param. functions, optional',\n",
       "         'param_desc': 'Formatter functions to apply to columns’ elements by position or\\nname.\\nThe result of each function must be a unicode string.\\nList/tuple must be of length equal to the number of columns.\\n'},\n",
       "        {'param_name': 'float_format',\n",
       "         'param_type': 'one-parameter function, optional, default None',\n",
       "         'param_desc': 'Formatter function to apply to columns’ elements if they are\\nfloats. This function must return a unicode string and will be\\napplied only to the non-NaN elements, with NaN being\\nhandled by na_rep.\\n'},\n",
       "        {'param_name': 'sparsify',\n",
       "         'param_type': 'bool, optional, default True',\n",
       "         'param_desc': 'Set to False for a DataFrame with a hierarchical index to print\\nevery multiindex key at each row.\\n'},\n",
       "        {'param_name': 'index_names',\n",
       "         'param_type': 'bool, optional, default True',\n",
       "         'param_desc': 'Prints the names of the indexes.\\n'},\n",
       "        {'param_name': 'justify',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'How to justify the column labels. If None uses the option from\\nthe print configuration (controlled by set_option), ‘right’ out\\nof the box. Valid values are\\n\\nleft\\nright\\ncenter\\njustify\\njustify-all\\nstart\\nend\\ninherit\\nmatch-parent\\ninitial\\nunset.\\n\\n'},\n",
       "        {'param_name': 'max_rows',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Maximum number of rows to display in the console.\\n'},\n",
       "        {'param_name': 'max_cols',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Maximum number of columns to display in the console.\\n'},\n",
       "        {'param_name': 'show_dimensions',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Display DataFrame dimensions (number of rows by number of columns).\\n'},\n",
       "        {'param_name': 'decimal',\n",
       "         'param_type': 'str, default ‘.’',\n",
       "         'param_desc': 'Character recognized as decimal separator, e.g. ‘,’ in Europe.\\n'},\n",
       "        {'param_name': 'line_width',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Width to wrap a line in characters.\\n'},\n",
       "        {'param_name': 'min_rows',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'The number of rows to display in the console in a truncated repr\\n(when number of rows is above max_rows).\\n'},\n",
       "        {'param_name': 'max_colwidth',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Max width to truncate each column in characters. By default, no limit.\\n'},\n",
       "        {'param_name': 'encoding',\n",
       "         'param_type': 'str, default “utf-8”',\n",
       "         'param_desc': 'Set character encoding.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.to_string',\n",
       "       'descriptions': 'Render a DataFrame to a console-friendly tabular output.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'buf': {'type': 'string',\n",
       "          'description': 'str, Path or StringIO-like, optional, default None. Buffer to write to. If None, the output is returned as a string.\\n'},\n",
       "         'columns': {'type': 'array',\n",
       "          'description': 'array-like, optional, default None. The subset of columns to write. Writes all columns by default.\\n'},\n",
       "         'col_space': {'type': 'integer',\n",
       "          'description': 'int, list or dict of int, optional. The minimum width of each column. If a list of ints is given every integers corresponds with one column. If a dict is given, the key references the column, while the value defines the space to use..\\n'},\n",
       "         'header': {'type': 'string',\n",
       "          'description': 'bool or list of str, optional. Write out the column names. If a list of columns is given, it is assumed to be aliases for the column names.\\n'},\n",
       "         'index': {'type': 'boolean',\n",
       "          'description': 'bool, optional, default True. Whether to print index (row) labels.\\n'},\n",
       "         'na_rep': {'type': 'string',\n",
       "          'description': 'str, optional, default ‘NaN’. String representation of NaN to use.\\n'},\n",
       "         'formatters': {'type': 'array',\n",
       "          'description': 'list, tuple or dict of one-param. functions, optional. Formatter functions to apply to columns’ elements by position or\\nname.\\nThe result of each function must be a unicode string.\\nList/tuple must be of length equal to the number of columns.\\n'},\n",
       "         'float_format': {'type': 'one-parameter function, optional, default None',\n",
       "          'description': 'one-parameter function, optional, default None. Formatter function to apply to columns’ elements if they are\\nfloats. This function must return a unicode string and will be\\napplied only to the non-NaN elements, with NaN being\\nhandled by na_rep.\\n'},\n",
       "         'sparsify': {'type': 'boolean',\n",
       "          'description': 'bool, optional, default True. Set to False for a DataFrame with a hierarchical index to print\\nevery multiindex key at each row.\\n'},\n",
       "         'index_names': {'type': 'boolean',\n",
       "          'description': 'bool, optional, default True. Prints the names of the indexes.\\n'},\n",
       "         'justify': {'type': 'string',\n",
       "          'description': 'str, default None. How to justify the column labels. If None uses the option from\\nthe print configuration (controlled by set_option), ‘right’ out\\nof the box. Valid values are\\n\\nleft\\nright\\ncenter\\njustify\\njustify-all\\nstart\\nend\\ninherit\\nmatch-parent\\ninitial\\nunset.\\n\\n'},\n",
       "         'max_rows': {'type': 'integer',\n",
       "          'description': 'int, optional. Maximum number of rows to display in the console.\\n'},\n",
       "         'max_cols': {'type': 'integer',\n",
       "          'description': 'int, optional. Maximum number of columns to display in the console.\\n'},\n",
       "         'show_dimensions': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Display DataFrame dimensions (number of rows by number of columns).\\n'},\n",
       "         'decimal': {'type': 'string',\n",
       "          'description': 'str, default ‘.’. Character recognized as decimal separator, e.g. ‘,’ in Europe.\\n'},\n",
       "         'line_width': {'type': 'integer',\n",
       "          'description': 'int, optional. Width to wrap a line in characters.\\n'},\n",
       "         'min_rows': {'type': 'integer',\n",
       "          'description': 'int, optional. The number of rows to display in the console in a truncated repr\\n(when number of rows is above max_rows).\\n'},\n",
       "         'max_colwidth': {'type': 'integer',\n",
       "          'description': 'int, optional. Max width to truncate each column in characters. By default, no limit.\\n'},\n",
       "         'encoding': {'type': 'string',\n",
       "          'description': 'str, default “utf-8”. Set character encoding.\\n'}},\n",
       "        'required': ['buf=None']}}},\n",
       "     {'func_name': 'DataFrame.to_markdown([buf,\\xa0mode,\\xa0index,\\xa0...])',\n",
       "      'func_desc': 'Print DataFrame in Markdown-friendly format.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_markdown.html#pandas.DataFrame.to_markdown',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.to_markdown',\n",
       "       'full_function': \"DataFrame.to_markdown(buf=None, *, mode='wt', index=True, storage_options=None, **kwargs)\",\n",
       "       'function_text': 'Print DataFrame in Markdown-friendly format.',\n",
       "       'parameter_names_desc': [{'param_name': 'buf',\n",
       "         'param_type': 'str, Path or StringIO-like, optional, default None',\n",
       "         'param_desc': 'Buffer to write to. If None, the output is returned as a string.\\n'},\n",
       "        {'param_name': 'mode',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Mode in which file is opened, “wt” by default.\\n'},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'bool, optional, default True',\n",
       "         'param_desc': 'Add index (row) labels.\\n'},\n",
       "        {'param_name': 'storage_options',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.to_markdown',\n",
       "       'descriptions': 'Print DataFrame in Markdown-friendly format.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'buf': {'type': 'string',\n",
       "          'description': 'str, Path or StringIO-like, optional, default None. Buffer to write to. If None, the output is returned as a string.\\n'},\n",
       "         'mode': {'type': 'string',\n",
       "          'description': 'str, optional. Mode in which file is opened, “wt” by default.\\n'},\n",
       "         'index': {'type': 'boolean',\n",
       "          'description': 'bool, optional, default True. Add index (row) labels.\\n'},\n",
       "         'storage_options': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n'}},\n",
       "        'required': ['buf=None']}}},\n",
       "     {'func_name': 'DataFrame.__dataframe__([nan_as_null,\\xa0...])',\n",
       "      'func_desc': 'Return the dataframe interchange object implementing the interchange protocol.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.__dataframe__.html#pandas.DataFrame.__dataframe__',\n",
       "      'function_definitions': {'function_name': 'pandas.DataFrame.__dataframe__',\n",
       "       'full_function': 'DataFrame.__dataframe__(nan_as_null=False, allow_copy=True)',\n",
       "       'function_text': 'Return the dataframe interchange object implementing the interchange protocol.',\n",
       "       'parameter_names_desc': [{'param_name': 'nan_as_null',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'nan_as_null is DEPRECATED and has no effect. Please avoid using\\nit; it will be removed in a future release.\\n'},\n",
       "        {'param_name': 'allow_copy',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to allow memory copying when exporting. If set to False\\nit would cause non-zero-copy exports to fail.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DataFrame.__dataframe__',\n",
       "       'descriptions': 'Return the dataframe interchange object implementing the interchange protocol.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'nan_as_null': {'type': 'boolean',\n",
       "          'description': 'bool, default False. nan_as_null is DEPRECATED and has no effect. Please avoid using\\nit; it will be removed in a future release.\\n'},\n",
       "         'allow_copy': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to allow memory copying when exporting. If set to False\\nit would cause non-zero-copy exports to fail.\\n'}},\n",
       "        'required': []}}}]}],\n",
       "  'name': 'DataFrame',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/frame.html'},\n",
       " 'arrays.html': {'functions': [{'Objects': [{'func_name': 'TZ-aware datetime',\n",
       "      'func_desc': 'DatetimeTZDtype',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeTZDtype.html#pandas.DatetimeTZDtype',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeTZDtype',\n",
       "       'full_function': \"class pandas.DatetimeTZDtype(unit='ns', tz=None)\",\n",
       "       'function_text': 'An ExtensionDtype for timezone-aware datetime data. This is not an actual numpy dtype, but a duck type.',\n",
       "       'parameter_names_desc': [{'param_name': 'unit',\n",
       "         'param_type': 'str, default “ns”',\n",
       "         'param_desc': 'The precision of the datetime data. Currently limited\\nto \"ns\".\\n'},\n",
       "        {'param_name': 'tz',\n",
       "         'param_type': 'str, int, or datetime.tzinfo',\n",
       "         'param_desc': 'The timezone.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DatetimeTZDtype',\n",
       "       'descriptions': 'An ExtensionDtype for timezone-aware datetime data. This is not an actual numpy dtype, but a duck type.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'unit': {'type': 'string',\n",
       "          'description': 'str, default “ns”. The precision of the datetime data. Currently limited\\nto \"ns\".\\n'},\n",
       "         'tz': {'type': 'integer',\n",
       "          'description': 'str, int, or datetime.tzinfo. The timezone.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Period (time spans)',\n",
       "      'func_desc': 'PeriodDtype',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.PeriodDtype.html#pandas.PeriodDtype',\n",
       "      'function_definitions': {'function_name': 'pandas.PeriodDtype',\n",
       "       'full_function': 'class pandas.PeriodDtype(freq)',\n",
       "       'function_text': 'An ExtensionDtype for Period data. This is not an actual numpy dtype, but a duck type.',\n",
       "       'parameter_names_desc': [{'param_name': 'freq',\n",
       "         'param_type': 'str or DateOffset',\n",
       "         'param_desc': 'The frequency of this PeriodDtype.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.PeriodDtype',\n",
       "       'descriptions': 'An ExtensionDtype for Period data. This is not an actual numpy dtype, but a duck type.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'freq': {'type': 'string',\n",
       "          'description': 'str or DateOffset. The frequency of this PeriodDtype.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Nullable Integer',\n",
       "      'func_desc': 'Int64Dtype, …',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Int64Dtype.html#pandas.Int64Dtype',\n",
       "      'function_definitions': {'function_name': 'pandas.Int64Dtype',\n",
       "       'full_function': 'class pandas.Int64Dtype',\n",
       "       'function_text': 'An ExtensionDtype for int64 integer data. Uses pandas.NA as its missing value, rather than numpy.nan. Examples For Int8Dtype: For Int16Dtype: For Int32Dtype: For Int64Dtype: For UInt8Dtype: For UInt16Dtype: For UInt32Dtype: For UInt64Dtype: Attributes None Methods None',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Categorical',\n",
       "      'func_desc': 'CategoricalDtype',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.CategoricalDtype.html#pandas.CategoricalDtype',\n",
       "      'function_definitions': {'function_name': 'pandas.CategoricalDtype',\n",
       "       'full_function': 'class pandas.CategoricalDtype(categories=None, ordered=False)',\n",
       "       'function_text': 'Type for categorical data with the categories and orderedness.',\n",
       "       'parameter_names_desc': [{'param_name': 'categories',\n",
       "         'param_type': 'sequence, optional',\n",
       "         'param_desc': 'Must be unique, and must not contain any nulls.\\nThe categories are stored in an Index,\\nand if an index is provided the dtype of that index will be used.\\n'},\n",
       "        {'param_name': 'ordered',\n",
       "         'param_type': 'bool or None, default False',\n",
       "         'param_desc': 'Whether or not this categorical is treated as a ordered categorical.\\nNone can be used to maintain the ordered value of existing categoricals when\\nused in operations that combine categoricals, e.g. astype, and will resolve to\\nFalse if there is no existing ordered to maintain.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.CategoricalDtype',\n",
       "       'descriptions': 'Type for categorical data with the categories and orderedness.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'categories': {'type': 'sequence, optional',\n",
       "          'description': 'sequence, optional. Must be unique, and must not contain any nulls.\\nThe categories are stored in an Index,\\nand if an index is provided the dtype of that index will be used.\\n'},\n",
       "         'ordered': {'type': 'boolean',\n",
       "          'description': 'bool or None, default False. Whether or not this categorical is treated as a ordered categorical.\\nNone can be used to maintain the ordered value of existing categoricals when\\nused in operations that combine categoricals, e.g. astype, and will resolve to\\nFalse if there is no existing ordered to maintain.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Strings',\n",
       "      'func_desc': 'StringDtype',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.StringDtype.html#pandas.StringDtype',\n",
       "      'function_definitions': {'function_name': 'pandas.StringDtype',\n",
       "       'full_function': 'class pandas.StringDtype(storage=None)',\n",
       "       'function_text': 'Extension dtype for string data. Warning StringDtype is considered experimental. The implementation and\\nparts of the API may change without warning.',\n",
       "       'parameter_names_desc': [{'param_name': 'storage',\n",
       "         'param_type': '{“python”, “pyarrow”, “pyarrow_numpy”}, optional',\n",
       "         'param_desc': 'If not given, the value of pd.options.mode.string_storage.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.StringDtype',\n",
       "       'descriptions': 'Extension dtype for string data. Warning StringDtype is considered experimental. The implementation and\\nparts of the API may change without warning.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'storage': {'type': '{“python”, “pyarrow”, “pyarrow_numpy”}, optional',\n",
       "          'description': '{“python”, “pyarrow”, “pyarrow_numpy”}, optional. If not given, the value of pd.options.mode.string_storage.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'PyArrow',\n",
       "      'func_desc': 'ArrowDtype',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.ArrowDtype.html#pandas.ArrowDtype',\n",
       "      'function_definitions': {'function_name': 'pandas.ArrowDtype',\n",
       "       'full_function': 'class pandas.ArrowDtype(pyarrow_dtype)',\n",
       "       'function_text': 'An ExtensionDtype for PyArrow data types. Warning ArrowDtype is considered experimental. The implementation and\\nparts of the API may change without warning. While most dtype arguments can accept the “string”\\nconstructor, e.g. \"int64[pyarrow]\", ArrowDtype is useful\\nif the data type contains parameters like pyarrow.timestamp.',\n",
       "       'parameter_names_desc': [{'param_name': 'pyarrow_dtype',\n",
       "         'param_type': 'pa.DataType',\n",
       "         'param_desc': 'An instance of a pyarrow.DataType.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.ArrowDtype',\n",
       "       'descriptions': 'An ExtensionDtype for PyArrow data types. Warning ArrowDtype is considered experimental. The implementation and\\nparts of the API may change without warning. While most dtype arguments can accept the “string”\\nconstructor, e.g. \"int64[pyarrow]\", ArrowDtype is useful\\nif the data type contains parameters like pyarrow.timestamp.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'pyarrow_dtype': {'type': 'pa.DataType',\n",
       "          'description': 'pa.DataType. An instance of a pyarrow.DataType.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'pyarrow.bool_()',\n",
       "      'func_desc': 'BooleanDtype',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.bool_.html#pyarrow.bool_',\n",
       "      'function_definitions': {'function_name': '',\n",
       "       'full_function': '',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'pyarrow.int16()',\n",
       "      'func_desc': 'Int16Dtype',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.int16.html#pyarrow.int16',\n",
       "      'function_definitions': {'function_name': '',\n",
       "       'full_function': '',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'pyarrow.int64()',\n",
       "      'func_desc': 'Int64Dtype',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.int64.html#pyarrow.int64',\n",
       "      'function_definitions': {'function_name': '',\n",
       "       'full_function': '',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'pyarrow.uint16()',\n",
       "      'func_desc': 'UInt16Dtype',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.uint16.html#pyarrow.uint16',\n",
       "      'function_definitions': {'function_name': '',\n",
       "       'full_function': '',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'pyarrow.uint64()',\n",
       "      'func_desc': 'UInt64Dtype',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.uint64.html#pyarrow.uint64',\n",
       "      'function_definitions': {'function_name': '',\n",
       "       'full_function': '',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'pyarrow.float64()',\n",
       "      'func_desc': 'Float64Dtype',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.float64.html#pyarrow.float64',\n",
       "      'function_definitions': {'function_name': '',\n",
       "       'full_function': '',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'pyarrow.time64()',\n",
       "      'func_desc': '(none)',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.time64.html#pyarrow.time64',\n",
       "      'function_definitions': {'function_name': '',\n",
       "       'full_function': '',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'pyarrow.date32()',\n",
       "      'func_desc': '(none)',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.date32.html#pyarrow.date32',\n",
       "      'function_definitions': {'function_name': '',\n",
       "       'full_function': '',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'pyarrow.duration()',\n",
       "      'func_desc': '(none)',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.duration.html#pyarrow.duration',\n",
       "      'function_definitions': {'function_name': '',\n",
       "       'full_function': '',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'pyarrow.string()',\n",
       "      'func_desc': 'StringDtype',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.string.html#pyarrow.string',\n",
       "      'function_definitions': {'function_name': '',\n",
       "       'full_function': '',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'pyarrow.list_()',\n",
       "      'func_desc': '(none)',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.list_.html#pyarrow.list_',\n",
       "      'function_definitions': {'function_name': '',\n",
       "       'full_function': '',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'pyarrow.dictionary()',\n",
       "      'func_desc': 'CategoricalDtype',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.dictionary.html#pyarrow.dictionary',\n",
       "      'function_definitions': {'function_name': '',\n",
       "       'full_function': '',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timestamp.day',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.day.html#pandas.Timestamp.day',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.day',\n",
       "       'full_function': 'Timestamp.day#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timestamp.day_of_week',\n",
       "      'func_desc': 'Return day of the week.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.day_of_week.html#pandas.Timestamp.day_of_week',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.day_of_week',\n",
       "       'full_function': 'Timestamp.day_of_week#',\n",
       "       'function_text': 'Return day of the week.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timestamp.day_of_year',\n",
       "      'func_desc': 'Return the day of the year.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.day_of_year.html#pandas.Timestamp.day_of_year',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.day_of_year',\n",
       "       'full_function': 'Timestamp.day_of_year#',\n",
       "       'function_text': 'Return the day of the year.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timestamp.daysinmonth',\n",
       "      'func_desc': 'Return the number of days in the month.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.daysinmonth.html#pandas.Timestamp.daysinmonth',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.daysinmonth',\n",
       "       'full_function': 'Timestamp.daysinmonth#',\n",
       "       'function_text': 'Return the number of days in the month.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timestamp.hour',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.hour.html#pandas.Timestamp.hour',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.hour',\n",
       "       'full_function': 'Timestamp.hour#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timestamp.is_month_end',\n",
       "      'func_desc': 'Check if the date is the last day of the month.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.is_month_end.html#pandas.Timestamp.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.is_month_end',\n",
       "       'full_function': 'Timestamp.is_month_end#',\n",
       "       'function_text': 'Check if the date is the last day of the month.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timestamp.is_quarter_end',\n",
       "      'func_desc': 'Check if date is last day of the quarter.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.is_quarter_end.html#pandas.Timestamp.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.is_quarter_end',\n",
       "       'full_function': 'Timestamp.is_quarter_end#',\n",
       "       'function_text': 'Check if date is last day of the quarter.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timestamp.is_year_end',\n",
       "      'func_desc': 'Return True if date is last day of the year.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.is_year_end.html#pandas.Timestamp.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.is_year_end',\n",
       "       'full_function': 'Timestamp.is_year_end#',\n",
       "       'function_text': 'Return True if date is last day of the year.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timestamp.max',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.max.html#pandas.Timestamp.max',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.max',\n",
       "       'full_function': \"Timestamp.max = Timestamp('2262-04-11 23:47:16.854775807')#\",\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timestamp.min',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.min.html#pandas.Timestamp.min',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.min',\n",
       "       'full_function': \"Timestamp.min = Timestamp('1677-09-21 00:12:43.145224193')#\",\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timestamp.month',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.month.html#pandas.Timestamp.month',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.month',\n",
       "       'full_function': 'Timestamp.month#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timestamp.quarter',\n",
       "      'func_desc': 'Return the quarter of the year.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.quarter.html#pandas.Timestamp.quarter',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.quarter',\n",
       "       'full_function': 'Timestamp.quarter#',\n",
       "       'function_text': 'Return the quarter of the year.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timestamp.second',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.second.html#pandas.Timestamp.second',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.second',\n",
       "       'full_function': 'Timestamp.second#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timestamp.tzinfo',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.tzinfo.html#pandas.Timestamp.tzinfo',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.tzinfo',\n",
       "       'full_function': 'Timestamp.tzinfo#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timestamp.value',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.value.html#pandas.Timestamp.value',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.value',\n",
       "       'full_function': 'Timestamp.value#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timestamp.weekofyear',\n",
       "      'func_desc': 'Return the week number of the year.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.weekofyear.html#pandas.Timestamp.weekofyear',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.weekofyear',\n",
       "       'full_function': 'Timestamp.weekofyear#',\n",
       "       'function_text': 'Return the week number of the year.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timestamp.astimezone(tz)',\n",
       "      'func_desc': 'Convert timezone-aware Timestamp to another time zone.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.astimezone.html#pandas.Timestamp.astimezone',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.astimezone',\n",
       "       'full_function': 'Timestamp.astimezone(tz)#',\n",
       "       'function_text': 'Convert timezone-aware Timestamp to another time zone.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timestamp.combine(date,\\xa0time)',\n",
       "      'func_desc': 'Combine date, time into datetime with same date and time fields.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.combine.html#pandas.Timestamp.combine',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.combine',\n",
       "       'full_function': 'classmethod Timestamp.combine(date, time)#',\n",
       "       'function_text': 'Combine date, time into datetime with same date and time fields. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timestamp.date()',\n",
       "      'func_desc': 'Return date object with same year, month and day.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.date.html#pandas.Timestamp.date',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.date',\n",
       "       'full_function': 'Timestamp.date()#',\n",
       "       'function_text': 'Return date object with same year, month and day. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timestamp.dst()',\n",
       "      'func_desc': 'Return the daylight saving time (DST) adjustment.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.dst.html#pandas.Timestamp.dst',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.dst',\n",
       "       'full_function': 'Timestamp.dst()#',\n",
       "       'function_text': 'Return the daylight saving time (DST) adjustment. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timestamp.fromordinal(ordinal[,\\xa0tz])',\n",
       "      'func_desc': 'Construct a timestamp from a a proleptic Gregorian ordinal.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.fromordinal.html#pandas.Timestamp.fromordinal',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.fromordinal',\n",
       "       'full_function': 'classmethod Timestamp.fromordinal(ordinal, tz=None)#',\n",
       "       'function_text': 'Construct a timestamp from a a proleptic Gregorian ordinal.',\n",
       "       'parameter_names_desc': [{'param_name': 'ordinal',\n",
       "         'param_type': 'int',\n",
       "         'param_desc': 'Date corresponding to a proleptic Gregorian ordinal.\\n'},\n",
       "        {'param_name': 'tz',\n",
       "         'param_type': 'str, pytz.timezone, dateutil.tz.tzfile or None',\n",
       "         'param_desc': 'Time zone for the Timestamp.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Timestamp.fromordinal',\n",
       "       'descriptions': 'Construct a timestamp from a a proleptic Gregorian ordinal.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'ordinal': {'type': 'integer',\n",
       "          'description': 'int. Date corresponding to a proleptic Gregorian ordinal.\\n'},\n",
       "         'tz': {'type': 'string',\n",
       "          'description': 'str, pytz.timezone, dateutil.tz.tzfile or None. Time zone for the Timestamp.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Timestamp.isocalendar()',\n",
       "      'func_desc': 'Return a named tuple containing ISO year, week number, and weekday.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.isocalendar.html#pandas.Timestamp.isocalendar',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.isocalendar',\n",
       "       'full_function': 'Timestamp.isocalendar()#',\n",
       "       'function_text': 'Return a named tuple containing ISO year, week number, and weekday. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timestamp.isoweekday()',\n",
       "      'func_desc': 'Return the day of the week represented by the date.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.isoweekday.html#pandas.Timestamp.isoweekday',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.isoweekday',\n",
       "       'full_function': 'Timestamp.isoweekday()#',\n",
       "       'function_text': 'Return the day of the week represented by the date. Monday == 1 … Sunday == 7. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timestamp.normalize()',\n",
       "      'func_desc': 'Normalize Timestamp to midnight, preserving tz information.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.normalize.html#pandas.Timestamp.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.normalize',\n",
       "       'full_function': 'Timestamp.normalize()#',\n",
       "       'function_text': 'Normalize Timestamp to midnight, preserving tz information. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timestamp.replace([year,\\xa0month,\\xa0day,\\xa0hour,\\xa0...])',\n",
       "      'func_desc': 'Implements datetime.replace, handles nanoseconds.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.replace.html#pandas.Timestamp.replace',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.replace',\n",
       "       'full_function': \"Timestamp.replace(year=None, month=None, day=None, hour=None, minute=None, second=None, microsecond=None, nanosecond=None, tzinfo=<class 'object'>, fold=None)#\",\n",
       "       'function_text': 'Implements datetime.replace, handles nanoseconds.',\n",
       "       'parameter_names_desc': [{'param_name': 'year',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'month',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'day', 'param_type': 'int, optional', 'param_desc': ''},\n",
       "        {'param_name': 'hour',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'minute',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'second',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'microsecond',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'nanosecond',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'tzinfo',\n",
       "         'param_type': 'tz-convertible, optional',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'fold',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.Timestamp.replace',\n",
       "       'descriptions': 'Implements datetime.replace, handles nanoseconds.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'year': {'type': 'integer',\n",
       "          'description': 'int, optional. '},\n",
       "         'month': {'type': 'integer', 'description': 'int, optional. '},\n",
       "         'day': {'type': 'integer', 'description': 'int, optional. '},\n",
       "         'hour': {'type': 'integer', 'description': 'int, optional. '},\n",
       "         'minute': {'type': 'integer', 'description': 'int, optional. '},\n",
       "         'second': {'type': 'integer', 'description': 'int, optional. '},\n",
       "         'microsecond': {'type': 'integer', 'description': 'int, optional. '},\n",
       "         'nanosecond': {'type': 'integer', 'description': 'int, optional. '},\n",
       "         'tzinfo': {'type': 'tz-convertible, optional',\n",
       "          'description': 'tz-convertible, optional. '},\n",
       "         'fold': {'type': 'integer', 'description': 'int, optional. '}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Timestamp.strftime(format)',\n",
       "      'func_desc': 'Return a formatted string of the Timestamp.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.strftime.html#pandas.Timestamp.strftime',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.strftime',\n",
       "       'full_function': 'Timestamp.strftime(format)#',\n",
       "       'function_text': 'Return a formatted string of the Timestamp.',\n",
       "       'parameter_names_desc': [{'param_name': 'format',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'Format string to convert Timestamp to string.\\nSee strftime documentation for more information on the format string:\\nhttps://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Timestamp.strftime',\n",
       "       'descriptions': 'Return a formatted string of the Timestamp.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'format': {'type': 'string',\n",
       "          'description': 'str. Format string to convert Timestamp to string.\\nSee strftime documentation for more information on the format string:\\nhttps://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Timestamp.time()',\n",
       "      'func_desc': 'Return time object with same time but with tzinfo=None.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.time.html#pandas.Timestamp.time',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.time',\n",
       "       'full_function': 'Timestamp.time()#',\n",
       "       'function_text': 'Return time object with same time but with tzinfo=None. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timestamp.timetuple()',\n",
       "      'func_desc': 'Return time tuple, compatible with time.localtime().',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.timetuple.html#pandas.Timestamp.timetuple',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.timetuple',\n",
       "       'full_function': 'Timestamp.timetuple()#',\n",
       "       'function_text': 'Return time tuple, compatible with time.localtime(). Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timestamp.to_datetime64()',\n",
       "      'func_desc': 'Return a numpy.datetime64 object with same precision.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.to_datetime64.html#pandas.Timestamp.to_datetime64',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.to_datetime64',\n",
       "       'full_function': 'Timestamp.to_datetime64()#',\n",
       "       'function_text': 'Return a numpy.datetime64 object with same precision. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timestamp.to_julian_date()',\n",
       "      'func_desc': 'Convert TimeStamp to a Julian Date.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.to_julian_date.html#pandas.Timestamp.to_julian_date',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.to_julian_date',\n",
       "       'full_function': 'Timestamp.to_julian_date()#',\n",
       "       'function_text': 'Convert TimeStamp to a Julian Date. 0 Julian date is noon January 1, 4713 BC. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timestamp.to_pydatetime([warn])',\n",
       "      'func_desc': 'Convert a Timestamp object to a native Python datetime object.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.to_pydatetime.html#pandas.Timestamp.to_pydatetime',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.to_pydatetime',\n",
       "       'full_function': 'Timestamp.to_pydatetime(warn=True)#',\n",
       "       'function_text': 'Convert a Timestamp object to a native Python datetime object. If warn=True, issue a warning if nanoseconds is nonzero. Examples Analogous for pd.NaT:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timestamp.toordinal()',\n",
       "      'func_desc': 'Return proleptic Gregorian ordinal.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.toordinal.html#pandas.Timestamp.toordinal',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.toordinal',\n",
       "       'full_function': 'Timestamp.toordinal()#',\n",
       "       'function_text': 'Return proleptic Gregorian ordinal. January 1 of year 1 is day 1. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timestamp.tz_localize(tz[,\\xa0ambiguous,\\xa0...])',\n",
       "      'func_desc': 'Localize the Timestamp to a timezone.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.tz_localize.html#pandas.Timestamp.tz_localize',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.tz_localize',\n",
       "       'full_function': \"Timestamp.tz_localize(tz, ambiguous='raise', nonexistent='raise')#\",\n",
       "       'function_text': 'Localize the Timestamp to a timezone. Convert naive Timestamp to local time zone or remove\\ntimezone from timezone-aware Timestamp.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timestamp.utcfromtimestamp(ts)',\n",
       "      'func_desc': 'Construct a timezone-aware UTC datetime from a POSIX timestamp.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.utcfromtimestamp.html#pandas.Timestamp.utcfromtimestamp',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.utcfromtimestamp',\n",
       "       'full_function': 'classmethod Timestamp.utcfromtimestamp(ts)#',\n",
       "       'function_text': 'Construct a timezone-aware UTC datetime from a POSIX timestamp. Notes Timestamp.utcfromtimestamp behavior differs from datetime.utcfromtimestamp\\nin returning a timezone-aware object. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timestamp.utcoffset()',\n",
       "      'func_desc': 'Return utc offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.utcoffset.html#pandas.Timestamp.utcoffset',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.utcoffset',\n",
       "       'full_function': 'Timestamp.utcoffset()#',\n",
       "       'function_text': 'Return utc offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timestamp.weekday()',\n",
       "      'func_desc': 'Return the day of the week represented by the date.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.weekday.html#pandas.Timestamp.weekday',\n",
       "      'function_definitions': {'function_name': 'pandas.Timestamp.weekday',\n",
       "       'full_function': 'Timestamp.weekday()#',\n",
       "       'function_text': 'Return the day of the week represented by the date. Monday == 0 … Sunday == 6. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timedelta.components',\n",
       "      'func_desc': 'Return a components namedtuple-like.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.components.html#pandas.Timedelta.components',\n",
       "      'function_definitions': {'function_name': 'pandas.Timedelta.components',\n",
       "       'full_function': 'Timedelta.components#',\n",
       "       'function_text': 'Return a components namedtuple-like. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timedelta.max',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.max.html#pandas.Timedelta.max',\n",
       "      'function_definitions': {'function_name': 'pandas.Timedelta.max',\n",
       "       'full_function': \"Timedelta.max = Timedelta('106751 days 23:47:16.854775807')#\",\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timedelta.min',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.min.html#pandas.Timedelta.min',\n",
       "      'function_definitions': {'function_name': 'pandas.Timedelta.min',\n",
       "       'full_function': \"Timedelta.min = Timedelta('-106752 days +00:12:43.145224193')#\",\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timedelta.resolution',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.resolution.html#pandas.Timedelta.resolution',\n",
       "      'function_definitions': {'function_name': 'pandas.Timedelta.resolution',\n",
       "       'full_function': \"Timedelta.resolution = Timedelta('0 days 00:00:00.000000001')#\",\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timedelta.unit',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.unit.html#pandas.Timedelta.unit',\n",
       "      'function_definitions': {'function_name': 'pandas.Timedelta.unit',\n",
       "       'full_function': 'Timedelta.unit#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timedelta.view(dtype)',\n",
       "      'func_desc': 'Array view compatibility.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.view.html#pandas.Timedelta.view',\n",
       "      'function_definitions': {'function_name': 'pandas.Timedelta.view',\n",
       "       'full_function': 'Timedelta.view(dtype)#',\n",
       "       'function_text': 'Array view compatibility.',\n",
       "       'parameter_names_desc': [{'param_name': 'dtype',\n",
       "         'param_type': 'str or dtype',\n",
       "         'param_desc': 'The dtype to view the underlying data as.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Timedelta.view',\n",
       "       'descriptions': 'Array view compatibility.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dtype': {'type': 'string',\n",
       "          'description': 'str or dtype. The dtype to view the underlying data as.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Timedelta.ceil(freq)',\n",
       "      'func_desc': 'Return a new Timedelta ceiled to this resolution.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.ceil.html#pandas.Timedelta.ceil',\n",
       "      'function_definitions': {'function_name': 'pandas.Timedelta.ceil',\n",
       "       'full_function': 'Timedelta.ceil(freq)#',\n",
       "       'function_text': 'Return a new Timedelta ceiled to this resolution.',\n",
       "       'parameter_names_desc': [{'param_name': 'freq',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'Frequency string indicating the ceiling resolution.\\nIt uses the same units as class constructor Timedelta.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Timedelta.ceil',\n",
       "       'descriptions': 'Return a new Timedelta ceiled to this resolution.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'freq': {'type': 'string',\n",
       "          'description': 'str. Frequency string indicating the ceiling resolution.\\nIt uses the same units as class constructor Timedelta.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Timedelta.isoformat()',\n",
       "      'func_desc': 'Format the Timedelta as ISO 8601 Duration.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.isoformat.html#pandas.Timedelta.isoformat',\n",
       "      'function_definitions': {'function_name': 'pandas.Timedelta.isoformat',\n",
       "       'full_function': 'Timedelta.isoformat()#',\n",
       "       'function_text': 'Format the Timedelta as ISO 8601 Duration. P[n]Y[n]M[n]DT[n]H[n]M[n]S, where the [n] s are replaced by the\\nvalues. See https://en.wikipedia.org/wiki/ISO_8601#Durations.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timedelta.to_pytimedelta()',\n",
       "      'func_desc': 'Convert a pandas Timedelta object into a python datetime.timedelta object.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.to_pytimedelta.html#pandas.Timedelta.to_pytimedelta',\n",
       "      'function_definitions': {'function_name': 'pandas.Timedelta.to_pytimedelta',\n",
       "       'full_function': 'Timedelta.to_pytimedelta()#',\n",
       "       'function_text': 'Convert a pandas Timedelta object into a python datetime.timedelta object. Timedelta objects are internally saved as numpy datetime64[ns] dtype.\\nUse to_pytimedelta() to convert to object dtype.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Timedelta.to_numpy([dtype,\\xa0copy])',\n",
       "      'func_desc': 'Convert the Timedelta to a NumPy timedelta64.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.to_numpy.html#pandas.Timedelta.to_numpy',\n",
       "      'function_definitions': {'function_name': 'pandas.Timedelta.to_numpy',\n",
       "       'full_function': 'Timedelta.to_numpy(dtype=None, copy=False)#',\n",
       "       'function_text': 'Convert the Timedelta to a NumPy timedelta64. This is an alias method for Timedelta.to_timedelta64(). The dtype and\\ncopy parameters are available here only for compatibility. Their values\\nwill not affect the return value.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Period.dayofweek',\n",
       "      'func_desc': 'Day of the week the period lies in, with Monday=0 and Sunday=6.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Period.dayofweek.html#pandas.Period.dayofweek',\n",
       "      'function_definitions': {'function_name': 'pandas.Period.dayofweek',\n",
       "       'full_function': 'Period.dayofweek#',\n",
       "       'function_text': 'Day of the week the period lies in, with Monday=0 and Sunday=6. If the period frequency is lower than daily (e.g. hourly), and the\\nperiod spans over multiple days, the day at the start of the period is\\nused. If the frequency is higher than daily (e.g. monthly), the last day\\nof the period is used.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Period.dayofyear',\n",
       "      'func_desc': 'Return the day of the year.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Period.dayofyear.html#pandas.Period.dayofyear',\n",
       "      'function_definitions': {'function_name': 'pandas.Period.dayofyear',\n",
       "       'full_function': 'Period.dayofyear#',\n",
       "       'function_text': 'Return the day of the year. This attribute returns the day of the year on which the particular\\ndate occurs. The return value ranges between 1 to 365 for regular\\nyears and 1 to 366 for leap years.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Period.days_in_month',\n",
       "      'func_desc': 'Get the total number of days in the month that this period falls on.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Period.days_in_month.html#pandas.Period.days_in_month',\n",
       "      'function_definitions': {'function_name': 'pandas.Period.days_in_month',\n",
       "       'full_function': 'Period.days_in_month#',\n",
       "       'function_text': 'Get the total number of days in the month that this period falls on.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Period.end_time',\n",
       "      'func_desc': 'Get the Timestamp for the end of the period.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Period.end_time.html#pandas.Period.end_time',\n",
       "      'function_definitions': {'function_name': 'pandas.Period.end_time',\n",
       "       'full_function': 'Period.end_time#',\n",
       "       'function_text': 'Get the Timestamp for the end of the period.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Period.freqstr',\n",
       "      'func_desc': 'Return a string representation of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Period.freqstr.html#pandas.Period.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.Period.freqstr',\n",
       "       'full_function': 'Period.freqstr#',\n",
       "       'function_text': 'Return a string representation of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Period.is_leap_year',\n",
       "      'func_desc': \"Return True if the period's year is in a leap year.\",\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Period.is_leap_year.html#pandas.Period.is_leap_year',\n",
       "      'function_definitions': {'function_name': 'pandas.Period.is_leap_year',\n",
       "       'full_function': 'Period.is_leap_year#',\n",
       "       'function_text': 'Return True if the period’s year is in a leap year. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Period.month',\n",
       "      'func_desc': 'Return the month this Period falls on.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Period.month.html#pandas.Period.month',\n",
       "      'function_definitions': {'function_name': 'pandas.Period.month',\n",
       "       'full_function': 'Period.month#',\n",
       "       'function_text': 'Return the month this Period falls on. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Period.quarter',\n",
       "      'func_desc': 'Return the quarter this Period falls on.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Period.quarter.html#pandas.Period.quarter',\n",
       "      'function_definitions': {'function_name': 'pandas.Period.quarter',\n",
       "       'full_function': 'Period.quarter#',\n",
       "       'function_text': 'Return the quarter this Period falls on. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Period.second',\n",
       "      'func_desc': 'Get the second component of the Period.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Period.second.html#pandas.Period.second',\n",
       "      'function_definitions': {'function_name': 'pandas.Period.second',\n",
       "       'full_function': 'Period.second#',\n",
       "       'function_text': 'Get the second component of the Period.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Period.week',\n",
       "      'func_desc': 'Get the week of the year on the given Period.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Period.week.html#pandas.Period.week',\n",
       "      'function_definitions': {'function_name': 'pandas.Period.week',\n",
       "       'full_function': 'Period.week#',\n",
       "       'function_text': 'Get the week of the year on the given Period.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Period.weekofyear',\n",
       "      'func_desc': 'Get the week of the year on the given Period.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Period.weekofyear.html#pandas.Period.weekofyear',\n",
       "      'function_definitions': {'function_name': 'pandas.Period.weekofyear',\n",
       "       'full_function': 'Period.weekofyear#',\n",
       "       'function_text': 'Get the week of the year on the given Period.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Period.now(freq)',\n",
       "      'func_desc': \"Return the period of now's date.\",\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Period.now.html#pandas.Period.now',\n",
       "      'function_definitions': {'function_name': 'pandas.Period.now',\n",
       "       'full_function': 'classmethod Period.now(freq)#',\n",
       "       'function_text': 'Return the period of now’s date.',\n",
       "       'parameter_names_desc': [{'param_name': 'freq',\n",
       "         'param_type': 'str, BaseOffset',\n",
       "         'param_desc': 'Frequency to use for the returned period.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Period.now',\n",
       "       'descriptions': 'Return the period of now’s date.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'freq': {'type': 'string',\n",
       "          'description': 'str, BaseOffset. Frequency to use for the returned period.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Period.to_timestamp([freq,\\xa0how])',\n",
       "      'func_desc': 'Return the Timestamp representation of the Period.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Period.to_timestamp.html#pandas.Period.to_timestamp',\n",
       "      'function_definitions': {'function_name': 'pandas.Period.to_timestamp',\n",
       "       'full_function': \"Period.to_timestamp(freq=None, how='start')#\",\n",
       "       'function_text': 'Return the Timestamp representation of the Period. Uses the target frequency specified at the part of the period specified\\nby how, which is either Start or Finish.',\n",
       "       'parameter_names_desc': [{'param_name': 'freq',\n",
       "         'param_type': 'str or DateOffset',\n",
       "         'param_desc': 'Target frequency. Default is ‘D’ if self.freq is week or\\nlonger and ‘S’ otherwise.\\n'},\n",
       "        {'param_name': 'how',\n",
       "         'param_type': 'str, default ‘S’ (start)',\n",
       "         'param_desc': 'One of ‘S’, ‘E’. Can be aliased as case insensitive\\n‘Start’, ‘Finish’, ‘Begin’, ‘End’.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Period.to_timestamp',\n",
       "       'descriptions': 'Return the Timestamp representation of the Period. Uses the target frequency specified at the part of the period specified\\nby how, which is either Start or Finish.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'freq': {'type': 'string',\n",
       "          'description': 'str or DateOffset. Target frequency. Default is ‘D’ if self.freq is week or\\nlonger and ‘S’ otherwise.\\n'},\n",
       "         'how': {'type': 'string',\n",
       "          'description': 'str, default ‘S’ (start). One of ‘S’, ‘E’. Can be aliased as case insensitive\\n‘Start’, ‘Finish’, ‘Begin’, ‘End’.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Interval.closed_left',\n",
       "      'func_desc': 'Check if the interval is closed on the left side.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Interval.closed_left.html#pandas.Interval.closed_left',\n",
       "      'function_definitions': {'function_name': 'pandas.Interval.closed_left',\n",
       "       'full_function': 'Interval.closed_left#',\n",
       "       'function_text': 'Check if the interval is closed on the left side. For the meaning of closed and open see Interval.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Interval.is_empty',\n",
       "      'func_desc': 'Indicates if an interval is empty, meaning it contains no points.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Interval.is_empty.html#pandas.Interval.is_empty',\n",
       "      'function_definitions': {'function_name': 'pandas.Interval.is_empty',\n",
       "       'full_function': 'Interval.is_empty#',\n",
       "       'function_text': 'Indicates if an interval is empty, meaning it contains no points.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Interval.length',\n",
       "      'func_desc': 'Return the length of the Interval.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Interval.length.html#pandas.Interval.length',\n",
       "      'function_definitions': {'function_name': 'pandas.Interval.length',\n",
       "       'full_function': 'Interval.length#',\n",
       "       'function_text': 'Return the length of the Interval. See also Indicates if an interval contains no points. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Interval.open_left',\n",
       "      'func_desc': 'Check if the interval is open on the left side.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Interval.open_left.html#pandas.Interval.open_left',\n",
       "      'function_definitions': {'function_name': 'pandas.Interval.open_left',\n",
       "       'full_function': 'Interval.open_left#',\n",
       "       'function_text': 'Check if the interval is open on the left side. For the meaning of closed and open see Interval.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Interval.overlaps(other)',\n",
       "      'func_desc': 'Check whether two Interval objects overlap.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Interval.overlaps.html#pandas.Interval.overlaps',\n",
       "      'function_definitions': {'function_name': 'pandas.Interval.overlaps',\n",
       "       'full_function': 'Interval.overlaps(other)#',\n",
       "       'function_text': 'Check whether two Interval objects overlap. Two intervals overlap if they share a common point, including closed\\nendpoints. Intervals that only have an open endpoint in common do not\\noverlap.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Interval',\n",
       "         'param_desc': 'Interval to check against for an overlap.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Interval.overlaps',\n",
       "       'descriptions': 'Check whether two Interval objects overlap. Two intervals overlap if they share a common point, including closed\\nendpoints. Intervals that only have an open endpoint in common do not\\noverlap.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Interval',\n",
       "          'description': 'Interval. Interval to check against for an overlap.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Int16Dtype()',\n",
       "      'func_desc': 'An ExtensionDtype for int16 integer data.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Int16Dtype.html#pandas.Int16Dtype',\n",
       "      'function_definitions': {'function_name': 'pandas.Int16Dtype',\n",
       "       'full_function': 'class pandas.Int16Dtype',\n",
       "       'function_text': 'An ExtensionDtype for int16 integer data. Uses pandas.NA as its missing value, rather than numpy.nan. Examples For Int8Dtype: For Int16Dtype: For Int32Dtype: For Int64Dtype: For UInt8Dtype: For UInt16Dtype: For UInt32Dtype: For UInt64Dtype: Attributes None Methods None',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Int64Dtype()',\n",
       "      'func_desc': 'An ExtensionDtype for int64 integer data.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Int64Dtype.html#pandas.Int64Dtype',\n",
       "      'function_definitions': {'function_name': 'pandas.Int64Dtype',\n",
       "       'full_function': 'class pandas.Int64Dtype',\n",
       "       'function_text': 'An ExtensionDtype for int64 integer data. Uses pandas.NA as its missing value, rather than numpy.nan. Examples For Int8Dtype: For Int16Dtype: For Int32Dtype: For Int64Dtype: For UInt8Dtype: For UInt16Dtype: For UInt32Dtype: For UInt64Dtype: Attributes None Methods None',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'UInt16Dtype()',\n",
       "      'func_desc': 'An ExtensionDtype for uint16 integer data.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.UInt16Dtype.html#pandas.UInt16Dtype',\n",
       "      'function_definitions': {'function_name': 'pandas.UInt16Dtype',\n",
       "       'full_function': 'class pandas.UInt16Dtype',\n",
       "       'function_text': 'An ExtensionDtype for uint16 integer data. Uses pandas.NA as its missing value, rather than numpy.nan. Examples For Int8Dtype: For Int16Dtype: For Int32Dtype: For Int64Dtype: For UInt8Dtype: For UInt16Dtype: For UInt32Dtype: For UInt64Dtype: Attributes None Methods None',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'UInt64Dtype()',\n",
       "      'func_desc': 'An ExtensionDtype for uint64 integer data.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.UInt64Dtype.html#pandas.UInt64Dtype',\n",
       "      'function_definitions': {'function_name': 'pandas.UInt64Dtype',\n",
       "       'full_function': 'class pandas.UInt64Dtype',\n",
       "       'function_text': 'An ExtensionDtype for uint64 integer data. Uses pandas.NA as its missing value, rather than numpy.nan. Examples For Int8Dtype: For Int16Dtype: For Int32Dtype: For Int64Dtype: For UInt8Dtype: For UInt16Dtype: For UInt32Dtype: For UInt64Dtype: Attributes None Methods None',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Float64Dtype()',\n",
       "      'func_desc': 'An ExtensionDtype for float64 data.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Float64Dtype.html#pandas.Float64Dtype',\n",
       "      'function_definitions': {'function_name': 'pandas.Float64Dtype',\n",
       "       'full_function': 'class pandas.Float64Dtype',\n",
       "       'function_text': 'An ExtensionDtype for float64 data. This dtype uses pd.NA as missing value indicator. Examples For Float32Dtype: For Float64Dtype: Attributes None Methods None',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CategoricalDtype.ordered',\n",
       "      'func_desc': 'Whether the categories have an ordered relationship.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.CategoricalDtype.ordered.html#pandas.CategoricalDtype.ordered',\n",
       "      'function_definitions': {'function_name': 'pandas.CategoricalDtype.ordered',\n",
       "       'full_function': 'property CategoricalDtype.ordered',\n",
       "       'function_text': 'Whether the categories have an ordered relationship. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Categorical.categories',\n",
       "      'func_desc': 'The categories of this categorical.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Categorical.categories.html#pandas.Categorical.categories',\n",
       "      'function_definitions': {'function_name': 'pandas.Categorical.categories',\n",
       "       'full_function': 'property Categorical.categories',\n",
       "       'function_text': 'The categories of this categorical. Setting assigns new values to each category (effectively a rename of\\neach individual category). The assigned value has to be a list-like object. All items must be\\nunique and the number of items in the new categories must be the same\\nas the number of items in the old categories.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Categorical.codes',\n",
       "      'func_desc': 'The category codes of this categorical index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Categorical.codes.html#pandas.Categorical.codes',\n",
       "      'function_definitions': {'function_name': 'pandas.Categorical.codes',\n",
       "       'full_function': 'property Categorical.codes',\n",
       "       'function_text': 'The category codes of this categorical index. Codes are an array of integers which are the positions of the actual\\nvalues in the categories array. There is no setter, use the other categorical methods and the normal item\\nsetter to change values in the categorical.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'arrays.ArrowStringArray(values)',\n",
       "      'func_desc': 'Extension array for string data in a pyarrow.ChunkedArray.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.arrays.ArrowStringArray.html#pandas.arrays.ArrowStringArray',\n",
       "      'function_definitions': {'function_name': 'pandas.arrays.ArrowStringArray',\n",
       "       'full_function': 'class pandas.arrays.ArrowStringArray(values)',\n",
       "       'function_text': 'Extension array for string data in a pyarrow.ChunkedArray. Warning ArrowStringArray is considered experimental. The implementation and\\nparts of the API may change without warning.',\n",
       "       'parameter_names_desc': [{'param_name': 'values',\n",
       "         'param_type': 'pyarrow.Array or pyarrow.ChunkedArray',\n",
       "         'param_desc': 'The array of data.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.arrays.ArrowStringArray',\n",
       "       'descriptions': 'Extension array for string data in a pyarrow.ChunkedArray. Warning ArrowStringArray is considered experimental. The implementation and\\nparts of the API may change without warning.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'values': {'type': 'pyarrow.Array or pyarrow.ChunkedArray',\n",
       "          'description': 'pyarrow.Array or pyarrow.ChunkedArray. The array of data.\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Utilities': [{'func_name': 'api.types.union_categoricals(to_union[,\\xa0...])',\n",
       "      'func_desc': 'Combine list-like of Categorical-like, unioning categories.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.union_categoricals.html#pandas.api.types.union_categoricals',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.union_categoricals',\n",
       "       'full_function': 'pandas.api.types.union_categoricals(to_union, sort_categories=False, ignore_order=False)',\n",
       "       'function_text': 'Combine list-like of Categorical-like, unioning categories. All categories must have the same dtype.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'api.types.pandas_dtype(dtype)',\n",
       "      'func_desc': 'Convert input into a pandas only dtype object or a numpy dtype object.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.pandas_dtype.html#pandas.api.types.pandas_dtype',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.pandas_dtype',\n",
       "       'full_function': 'pandas.api.types.pandas_dtype(dtype)',\n",
       "       'function_text': 'Convert input into a pandas only dtype object or a numpy dtype object.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'api.types.is_any_real_numeric_dtype(arr_or_dtype)',\n",
       "      'func_desc': 'Check whether the provided array or dtype is of a real number dtype.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_any_real_numeric_dtype.html#pandas.api.types.is_any_real_numeric_dtype',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_any_real_numeric_dtype',\n",
       "       'full_function': 'pandas.api.types.is_any_real_numeric_dtype(arr_or_dtype)',\n",
       "       'function_text': 'Check whether the provided array or dtype is of a real number dtype.',\n",
       "       'parameter_names_desc': [{'param_name': 'arr_or_dtype',\n",
       "         'param_type': 'array-like or dtype',\n",
       "         'param_desc': 'The array or dtype to check.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.api.types.is_any_real_numeric_dtype',\n",
       "       'descriptions': 'Check whether the provided array or dtype is of a real number dtype.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'arr_or_dtype': {'type': 'array',\n",
       "          'description': 'array-like or dtype. The array or dtype to check.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'api.types.is_categorical_dtype(arr_or_dtype)',\n",
       "      'func_desc': '(DEPRECATED) Check whether an array-like or dtype is of the Categorical dtype.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_categorical_dtype.html#pandas.api.types.is_categorical_dtype',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_categorical_dtype',\n",
       "       'full_function': 'pandas.api.types.is_categorical_dtype(arr_or_dtype)',\n",
       "       'function_text': 'Check whether an array-like or dtype is of the Categorical dtype. Deprecated since version 2.2.0: Use isinstance(dtype, pd.CategoricalDtype) instead.',\n",
       "       'parameter_names_desc': [{'param_name': 'arr_or_dtype',\n",
       "         'param_type': 'array-like or dtype',\n",
       "         'param_desc': 'The array-like or dtype to check.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.api.types.is_categorical_dtype',\n",
       "       'descriptions': 'Check whether an array-like or dtype is of the Categorical dtype. Deprecated since version 2.2.0: Use isinstance(dtype, pd.CategoricalDtype) instead.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'arr_or_dtype': {'type': 'array',\n",
       "          'description': 'array-like or dtype. The array-like or dtype to check.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'api.types.is_datetime64_any_dtype(arr_or_dtype)',\n",
       "      'func_desc': 'Check whether the provided array or dtype is of the datetime64 dtype.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_datetime64_any_dtype.html#pandas.api.types.is_datetime64_any_dtype',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_datetime64_any_dtype',\n",
       "       'full_function': 'pandas.api.types.is_datetime64_any_dtype(arr_or_dtype)',\n",
       "       'function_text': 'Check whether the provided array or dtype is of the datetime64 dtype.',\n",
       "       'parameter_names_desc': [{'param_name': 'arr_or_dtype',\n",
       "         'param_type': 'array-like or dtype',\n",
       "         'param_desc': 'The array or dtype to check.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.api.types.is_datetime64_any_dtype',\n",
       "       'descriptions': 'Check whether the provided array or dtype is of the datetime64 dtype.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'arr_or_dtype': {'type': 'array',\n",
       "          'description': 'array-like or dtype. The array or dtype to check.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'api.types.is_datetime64_ns_dtype(arr_or_dtype)',\n",
       "      'func_desc': 'Check whether the provided array or dtype is of the datetime64[ns] dtype.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_datetime64_ns_dtype.html#pandas.api.types.is_datetime64_ns_dtype',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_datetime64_ns_dtype',\n",
       "       'full_function': 'pandas.api.types.is_datetime64_ns_dtype(arr_or_dtype)',\n",
       "       'function_text': 'Check whether the provided array or dtype is of the datetime64[ns] dtype.',\n",
       "       'parameter_names_desc': [{'param_name': 'arr_or_dtype',\n",
       "         'param_type': 'array-like or dtype',\n",
       "         'param_desc': 'The array or dtype to check.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.api.types.is_datetime64_ns_dtype',\n",
       "       'descriptions': 'Check whether the provided array or dtype is of the datetime64[ns] dtype.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'arr_or_dtype': {'type': 'array',\n",
       "          'description': 'array-like or dtype. The array or dtype to check.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'api.types.is_extension_array_dtype(arr_or_dtype)',\n",
       "      'func_desc': 'Check if an object is a pandas extension array type.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_extension_array_dtype.html#pandas.api.types.is_extension_array_dtype',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_extension_array_dtype',\n",
       "       'full_function': 'pandas.api.types.is_extension_array_dtype(arr_or_dtype)',\n",
       "       'function_text': 'Check if an object is a pandas extension array type. See the Use Guide for more.',\n",
       "       'parameter_names_desc': [{'param_name': 'arr_or_dtype',\n",
       "         'param_type': 'object',\n",
       "         'param_desc': 'For array-like input, the .dtype attribute will\\nbe extracted.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.api.types.is_extension_array_dtype',\n",
       "       'descriptions': 'Check if an object is a pandas extension array type. See the Use Guide for more.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'arr_or_dtype': {'type': 'object',\n",
       "          'description': 'object. For array-like input, the .dtype attribute will\\nbe extracted.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'api.types.is_int64_dtype(arr_or_dtype)',\n",
       "      'func_desc': '(DEPRECATED) Check whether the provided array or dtype is of the int64 dtype.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_int64_dtype.html#pandas.api.types.is_int64_dtype',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_int64_dtype',\n",
       "       'full_function': 'pandas.api.types.is_int64_dtype(arr_or_dtype)',\n",
       "       'function_text': 'Check whether the provided array or dtype is of the int64 dtype. Deprecated since version 2.1.0: is_int64_dtype is deprecated and will be removed in a future\\nversion. Use dtype == np.int64 instead.',\n",
       "       'parameter_names_desc': [{'param_name': 'arr_or_dtype',\n",
       "         'param_type': 'array-like or dtype',\n",
       "         'param_desc': 'The array or dtype to check.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.api.types.is_int64_dtype',\n",
       "       'descriptions': 'Check whether the provided array or dtype is of the int64 dtype. Deprecated since version 2.1.0: is_int64_dtype is deprecated and will be removed in a future\\nversion. Use dtype == np.int64 instead.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'arr_or_dtype': {'type': 'array',\n",
       "          'description': 'array-like or dtype. The array or dtype to check.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'api.types.is_interval_dtype(arr_or_dtype)',\n",
       "      'func_desc': '(DEPRECATED) Check whether an array-like or dtype is of the Interval dtype.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_interval_dtype.html#pandas.api.types.is_interval_dtype',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_interval_dtype',\n",
       "       'full_function': 'pandas.api.types.is_interval_dtype(arr_or_dtype)',\n",
       "       'function_text': 'Check whether an array-like or dtype is of the Interval dtype. Deprecated since version 2.2.0: Use isinstance(dtype, pd.IntervalDtype) instead.',\n",
       "       'parameter_names_desc': [{'param_name': 'arr_or_dtype',\n",
       "         'param_type': 'array-like or dtype',\n",
       "         'param_desc': 'The array-like or dtype to check.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.api.types.is_interval_dtype',\n",
       "       'descriptions': 'Check whether an array-like or dtype is of the Interval dtype. Deprecated since version 2.2.0: Use isinstance(dtype, pd.IntervalDtype) instead.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'arr_or_dtype': {'type': 'array',\n",
       "          'description': 'array-like or dtype. The array-like or dtype to check.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'api.types.is_object_dtype(arr_or_dtype)',\n",
       "      'func_desc': 'Check whether an array-like or dtype is of the object dtype.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_object_dtype.html#pandas.api.types.is_object_dtype',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_object_dtype',\n",
       "       'full_function': 'pandas.api.types.is_object_dtype(arr_or_dtype)',\n",
       "       'function_text': 'Check whether an array-like or dtype is of the object dtype.',\n",
       "       'parameter_names_desc': [{'param_name': 'arr_or_dtype',\n",
       "         'param_type': 'array-like or dtype',\n",
       "         'param_desc': 'The array-like or dtype to check.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.api.types.is_object_dtype',\n",
       "       'descriptions': 'Check whether an array-like or dtype is of the object dtype.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'arr_or_dtype': {'type': 'array',\n",
       "          'description': 'array-like or dtype. The array-like or dtype to check.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'api.types.is_signed_integer_dtype(arr_or_dtype)',\n",
       "      'func_desc': 'Check whether the provided array or dtype is of a signed integer dtype.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_signed_integer_dtype.html#pandas.api.types.is_signed_integer_dtype',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_signed_integer_dtype',\n",
       "       'full_function': 'pandas.api.types.is_signed_integer_dtype(arr_or_dtype)',\n",
       "       'function_text': 'Check whether the provided array or dtype is of a signed integer dtype. Unlike in is_any_int_dtype, timedelta64 instances will return False. The nullable Integer dtypes (e.g. pandas.Int64Dtype) are also considered\\nas integer by this function.',\n",
       "       'parameter_names_desc': [{'param_name': 'arr_or_dtype',\n",
       "         'param_type': 'array-like or dtype',\n",
       "         'param_desc': 'The array or dtype to check.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.api.types.is_signed_integer_dtype',\n",
       "       'descriptions': 'Check whether the provided array or dtype is of a signed integer dtype. Unlike in is_any_int_dtype, timedelta64 instances will return False. The nullable Integer dtypes (e.g. pandas.Int64Dtype) are also considered\\nas integer by this function.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'arr_or_dtype': {'type': 'array',\n",
       "          'description': 'array-like or dtype. The array or dtype to check.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'api.types.is_timedelta64_dtype(arr_or_dtype)',\n",
       "      'func_desc': 'Check whether an array-like or dtype is of the timedelta64 dtype.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_timedelta64_dtype.html#pandas.api.types.is_timedelta64_dtype',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_timedelta64_dtype',\n",
       "       'full_function': 'pandas.api.types.is_timedelta64_dtype(arr_or_dtype)',\n",
       "       'function_text': 'Check whether an array-like or dtype is of the timedelta64 dtype.',\n",
       "       'parameter_names_desc': [{'param_name': 'arr_or_dtype',\n",
       "         'param_type': 'array-like or dtype',\n",
       "         'param_desc': 'The array-like or dtype to check.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.api.types.is_timedelta64_dtype',\n",
       "       'descriptions': 'Check whether an array-like or dtype is of the timedelta64 dtype.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'arr_or_dtype': {'type': 'array',\n",
       "          'description': 'array-like or dtype. The array-like or dtype to check.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'api.types.is_unsigned_integer_dtype(arr_or_dtype)',\n",
       "      'func_desc': 'Check whether the provided array or dtype is of an unsigned integer dtype.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_unsigned_integer_dtype.html#pandas.api.types.is_unsigned_integer_dtype',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_unsigned_integer_dtype',\n",
       "       'full_function': 'pandas.api.types.is_unsigned_integer_dtype(arr_or_dtype)',\n",
       "       'function_text': 'Check whether the provided array or dtype is of an unsigned integer dtype. The nullable Integer dtypes (e.g. pandas.UInt64Dtype) are also\\nconsidered as integer by this function.',\n",
       "       'parameter_names_desc': [{'param_name': 'arr_or_dtype',\n",
       "         'param_type': 'array-like or dtype',\n",
       "         'param_desc': 'The array or dtype to check.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.api.types.is_unsigned_integer_dtype',\n",
       "       'descriptions': 'Check whether the provided array or dtype is of an unsigned integer dtype. The nullable Integer dtypes (e.g. pandas.UInt64Dtype) are also\\nconsidered as integer by this function.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'arr_or_dtype': {'type': 'array',\n",
       "          'description': 'array-like or dtype. The array or dtype to check.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'api.types.is_dict_like(obj)',\n",
       "      'func_desc': 'Check if the object is dict-like.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_dict_like.html#pandas.api.types.is_dict_like',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_dict_like',\n",
       "       'full_function': 'pandas.api.types.is_dict_like(obj)',\n",
       "       'function_text': 'Check if the object is dict-like.',\n",
       "       'parameter_names_desc': [{'param_name': 'obj',\n",
       "         'param_type': 'The object to check',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.api.types.is_dict_like',\n",
       "       'descriptions': 'Check if the object is dict-like.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'obj': {'type': 'object',\n",
       "          'description': 'The object to check. '}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'api.types.is_list_like(obj[,\\xa0allow_sets])',\n",
       "      'func_desc': 'Check if the object is list-like.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_list_like.html#pandas.api.types.is_list_like',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_list_like',\n",
       "       'full_function': 'pandas.api.types.is_list_like(obj, allow_sets=True)#',\n",
       "       'function_text': 'Check if the object is list-like. Objects that are considered list-like are for example Python\\nlists, tuples, sets, NumPy arrays, and Pandas Series. Strings and datetime objects, however, are not considered list-like.',\n",
       "       'parameter_names_desc': [{'param_name': 'obj',\n",
       "         'param_type': 'object',\n",
       "         'param_desc': 'Object to check.\\n'},\n",
       "        {'param_name': 'allow_sets',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If this parameter is False, sets will not be considered list-like.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.api.types.is_list_like',\n",
       "       'descriptions': 'Check if the object is list-like. Objects that are considered list-like are for example Python\\nlists, tuples, sets, NumPy arrays, and Pandas Series. Strings and datetime objects, however, are not considered list-like.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'obj': {'type': 'object',\n",
       "          'description': 'object. Object to check.\\n'},\n",
       "         'allow_sets': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If this parameter is False, sets will not be considered list-like.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'api.types.is_iterator(obj)',\n",
       "      'func_desc': 'Check if the object is an iterator.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_iterator.html#pandas.api.types.is_iterator',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_iterator',\n",
       "       'full_function': 'pandas.api.types.is_iterator(obj)#',\n",
       "       'function_text': 'Check if the object is an iterator. This is intended for generators, not list-like objects.',\n",
       "       'parameter_names_desc': [{'param_name': 'obj',\n",
       "         'param_type': 'The object to check',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.api.types.is_iterator',\n",
       "       'descriptions': 'Check if the object is an iterator. This is intended for generators, not list-like objects.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'obj': {'type': 'object',\n",
       "          'description': 'The object to check. '}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'api.types.is_bool(obj)',\n",
       "      'func_desc': 'Return True if given object is boolean.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_bool.html#pandas.api.types.is_bool',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_bool',\n",
       "       'full_function': 'pandas.api.types.is_bool(obj)#',\n",
       "       'function_text': 'Return True if given object is boolean.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'api.types.is_float(obj)',\n",
       "      'func_desc': 'Return True if given object is float.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_float.html#pandas.api.types.is_float',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_float',\n",
       "       'full_function': 'pandas.api.types.is_float(obj)#',\n",
       "       'function_text': 'Return True if given object is float.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'api.types.is_integer(obj)',\n",
       "      'func_desc': 'Return True if given object is integer.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_integer.html#pandas.api.types.is_integer',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_integer',\n",
       "       'full_function': 'pandas.api.types.is_integer(obj)#',\n",
       "       'function_text': 'Return True if given object is integer.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'api.types.is_number(obj)',\n",
       "      'func_desc': 'Check if the object is a number.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_number.html#pandas.api.types.is_number',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_number',\n",
       "       'full_function': 'pandas.api.types.is_number(obj)',\n",
       "       'function_text': 'Check if the object is a number. Returns True when the object is a number, and False if is not.',\n",
       "       'parameter_names_desc': [{'param_name': 'obj',\n",
       "         'param_type': 'any type',\n",
       "         'param_desc': 'The object to check if is a number.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.api.types.is_number',\n",
       "       'descriptions': 'Check if the object is a number. Returns True when the object is a number, and False if is not.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'obj': {'type': 'any type',\n",
       "          'description': 'any type. The object to check if is a number.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'api.types.is_re_compilable(obj)',\n",
       "      'func_desc': 'Check if the object can be compiled into a regex pattern instance.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_re_compilable.html#pandas.api.types.is_re_compilable',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_re_compilable',\n",
       "       'full_function': 'pandas.api.types.is_re_compilable(obj)',\n",
       "       'function_text': 'Check if the object can be compiled into a regex pattern instance.',\n",
       "       'parameter_names_desc': [{'param_name': 'obj',\n",
       "         'param_type': 'The object to check',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.api.types.is_re_compilable',\n",
       "       'descriptions': 'Check if the object can be compiled into a regex pattern instance.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'obj': {'type': 'object',\n",
       "          'description': 'The object to check. '}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'api.types.infer_dtype(value[,\\xa0skipna])',\n",
       "      'func_desc': 'Return a string label of the type of a scalar or list-like of values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.infer_dtype.html#pandas.api.types.infer_dtype',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.infer_dtype',\n",
       "       'full_function': 'pandas.api.types.infer_dtype(value, skipna=True)#',\n",
       "       'function_text': 'Return a string label of the type of a scalar or list-like of values.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'api.types.is_bool_dtype(arr_or_dtype)',\n",
       "      'func_desc': 'Check whether the provided array or dtype is of a boolean dtype.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_bool_dtype.html#pandas.api.types.is_bool_dtype',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_bool_dtype',\n",
       "       'full_function': 'pandas.api.types.is_bool_dtype(arr_or_dtype)',\n",
       "       'function_text': 'Check whether the provided array or dtype is of a boolean dtype.',\n",
       "       'parameter_names_desc': [{'param_name': 'arr_or_dtype',\n",
       "         'param_type': 'array-like or dtype',\n",
       "         'param_desc': 'The array or dtype to check.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.api.types.is_bool_dtype',\n",
       "       'descriptions': 'Check whether the provided array or dtype is of a boolean dtype.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'arr_or_dtype': {'type': 'array',\n",
       "          'description': 'array-like or dtype. The array or dtype to check.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'api.types.is_complex_dtype(arr_or_dtype)',\n",
       "      'func_desc': 'Check whether the provided array or dtype is of a complex dtype.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_complex_dtype.html#pandas.api.types.is_complex_dtype',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_complex_dtype',\n",
       "       'full_function': 'pandas.api.types.is_complex_dtype(arr_or_dtype)',\n",
       "       'function_text': 'Check whether the provided array or dtype is of a complex dtype.',\n",
       "       'parameter_names_desc': [{'param_name': 'arr_or_dtype',\n",
       "         'param_type': 'array-like or dtype',\n",
       "         'param_desc': 'The array or dtype to check.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.api.types.is_complex_dtype',\n",
       "       'descriptions': 'Check whether the provided array or dtype is of a complex dtype.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'arr_or_dtype': {'type': 'array',\n",
       "          'description': 'array-like or dtype. The array or dtype to check.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'api.types.is_datetime64_dtype(arr_or_dtype)',\n",
       "      'func_desc': 'Check whether an array-like or dtype is of the datetime64 dtype.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_datetime64_dtype.html#pandas.api.types.is_datetime64_dtype',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_datetime64_dtype',\n",
       "       'full_function': 'pandas.api.types.is_datetime64_dtype(arr_or_dtype)',\n",
       "       'function_text': 'Check whether an array-like or dtype is of the datetime64 dtype.',\n",
       "       'parameter_names_desc': [{'param_name': 'arr_or_dtype',\n",
       "         'param_type': 'array-like or dtype',\n",
       "         'param_desc': 'The array-like or dtype to check.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.api.types.is_datetime64_dtype',\n",
       "       'descriptions': 'Check whether an array-like or dtype is of the datetime64 dtype.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'arr_or_dtype': {'type': 'array',\n",
       "          'description': 'array-like or dtype. The array-like or dtype to check.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'api.types.is_datetime64tz_dtype(arr_or_dtype)',\n",
       "      'func_desc': '(DEPRECATED) Check whether an array-like or dtype is of a DatetimeTZDtype dtype.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_datetime64tz_dtype.html#pandas.api.types.is_datetime64tz_dtype',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_datetime64tz_dtype',\n",
       "       'full_function': 'pandas.api.types.is_datetime64tz_dtype(arr_or_dtype)',\n",
       "       'function_text': 'Check whether an array-like or dtype is of a DatetimeTZDtype dtype. Deprecated since version 2.1.0: Use isinstance(dtype, pd.DatetimeTZDtype) instead.',\n",
       "       'parameter_names_desc': [{'param_name': 'arr_or_dtype',\n",
       "         'param_type': 'array-like or dtype',\n",
       "         'param_desc': 'The array-like or dtype to check.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.api.types.is_datetime64tz_dtype',\n",
       "       'descriptions': 'Check whether an array-like or dtype is of a DatetimeTZDtype dtype. Deprecated since version 2.1.0: Use isinstance(dtype, pd.DatetimeTZDtype) instead.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'arr_or_dtype': {'type': 'array',\n",
       "          'description': 'array-like or dtype. The array-like or dtype to check.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'api.types.is_float_dtype(arr_or_dtype)',\n",
       "      'func_desc': 'Check whether the provided array or dtype is of a float dtype.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_float_dtype.html#pandas.api.types.is_float_dtype',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_float_dtype',\n",
       "       'full_function': 'pandas.api.types.is_float_dtype(arr_or_dtype)',\n",
       "       'function_text': 'Check whether the provided array or dtype is of a float dtype.',\n",
       "       'parameter_names_desc': [{'param_name': 'arr_or_dtype',\n",
       "         'param_type': 'array-like or dtype',\n",
       "         'param_desc': 'The array or dtype to check.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.api.types.is_float_dtype',\n",
       "       'descriptions': 'Check whether the provided array or dtype is of a float dtype.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'arr_or_dtype': {'type': 'array',\n",
       "          'description': 'array-like or dtype. The array or dtype to check.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'api.types.is_integer_dtype(arr_or_dtype)',\n",
       "      'func_desc': 'Check whether the provided array or dtype is of an integer dtype.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_integer_dtype.html#pandas.api.types.is_integer_dtype',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_integer_dtype',\n",
       "       'full_function': 'pandas.api.types.is_integer_dtype(arr_or_dtype)',\n",
       "       'function_text': 'Check whether the provided array or dtype is of an integer dtype. Unlike in is_any_int_dtype, timedelta64 instances will return False. The nullable Integer dtypes (e.g. pandas.Int64Dtype) are also considered\\nas integer by this function.',\n",
       "       'parameter_names_desc': [{'param_name': 'arr_or_dtype',\n",
       "         'param_type': 'array-like or dtype',\n",
       "         'param_desc': 'The array or dtype to check.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.api.types.is_integer_dtype',\n",
       "       'descriptions': 'Check whether the provided array or dtype is of an integer dtype. Unlike in is_any_int_dtype, timedelta64 instances will return False. The nullable Integer dtypes (e.g. pandas.Int64Dtype) are also considered\\nas integer by this function.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'arr_or_dtype': {'type': 'array',\n",
       "          'description': 'array-like or dtype. The array or dtype to check.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'api.types.is_numeric_dtype(arr_or_dtype)',\n",
       "      'func_desc': 'Check whether the provided array or dtype is of a numeric dtype.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_numeric_dtype.html#pandas.api.types.is_numeric_dtype',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_numeric_dtype',\n",
       "       'full_function': 'pandas.api.types.is_numeric_dtype(arr_or_dtype)',\n",
       "       'function_text': 'Check whether the provided array or dtype is of a numeric dtype.',\n",
       "       'parameter_names_desc': [{'param_name': 'arr_or_dtype',\n",
       "         'param_type': 'array-like or dtype',\n",
       "         'param_desc': 'The array or dtype to check.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.api.types.is_numeric_dtype',\n",
       "       'descriptions': 'Check whether the provided array or dtype is of a numeric dtype.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'arr_or_dtype': {'type': 'array',\n",
       "          'description': 'array-like or dtype. The array or dtype to check.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'api.types.is_period_dtype(arr_or_dtype)',\n",
       "      'func_desc': '(DEPRECATED) Check whether an array-like or dtype is of the Period dtype.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_period_dtype.html#pandas.api.types.is_period_dtype',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_period_dtype',\n",
       "       'full_function': 'pandas.api.types.is_period_dtype(arr_or_dtype)',\n",
       "       'function_text': 'Check whether an array-like or dtype is of the Period dtype. Deprecated since version 2.2.0: Use isinstance(dtype, pd.Period) instead.',\n",
       "       'parameter_names_desc': [{'param_name': 'arr_or_dtype',\n",
       "         'param_type': 'array-like or dtype',\n",
       "         'param_desc': 'The array-like or dtype to check.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.api.types.is_period_dtype',\n",
       "       'descriptions': 'Check whether an array-like or dtype is of the Period dtype. Deprecated since version 2.2.0: Use isinstance(dtype, pd.Period) instead.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'arr_or_dtype': {'type': 'array',\n",
       "          'description': 'array-like or dtype. The array-like or dtype to check.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'api.types.is_string_dtype(arr_or_dtype)',\n",
       "      'func_desc': 'Check whether the provided array or dtype is of the string dtype.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_string_dtype.html#pandas.api.types.is_string_dtype',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_string_dtype',\n",
       "       'full_function': 'pandas.api.types.is_string_dtype(arr_or_dtype)',\n",
       "       'function_text': 'Check whether the provided array or dtype is of the string dtype. If an array is passed with an object dtype, the elements must be\\ninferred as strings.',\n",
       "       'parameter_names_desc': [{'param_name': 'arr_or_dtype',\n",
       "         'param_type': 'array-like or dtype',\n",
       "         'param_desc': 'The array or dtype to check.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.api.types.is_string_dtype',\n",
       "       'descriptions': 'Check whether the provided array or dtype is of the string dtype. If an array is passed with an object dtype, the elements must be\\ninferred as strings.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'arr_or_dtype': {'type': 'array',\n",
       "          'description': 'array-like or dtype. The array or dtype to check.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'api.types.is_timedelta64_ns_dtype(arr_or_dtype)',\n",
       "      'func_desc': 'Check whether the provided array or dtype is of the timedelta64[ns] dtype.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_timedelta64_ns_dtype.html#pandas.api.types.is_timedelta64_ns_dtype',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_timedelta64_ns_dtype',\n",
       "       'full_function': 'pandas.api.types.is_timedelta64_ns_dtype(arr_or_dtype)',\n",
       "       'function_text': 'Check whether the provided array or dtype is of the timedelta64[ns] dtype. This is a very specific dtype, so generic ones like np.timedelta64\\nwill return False if passed into this function.',\n",
       "       'parameter_names_desc': [{'param_name': 'arr_or_dtype',\n",
       "         'param_type': 'array-like or dtype',\n",
       "         'param_desc': 'The array or dtype to check.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.api.types.is_timedelta64_ns_dtype',\n",
       "       'descriptions': 'Check whether the provided array or dtype is of the timedelta64[ns] dtype. This is a very specific dtype, so generic ones like np.timedelta64\\nwill return False if passed into this function.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'arr_or_dtype': {'type': 'array',\n",
       "          'description': 'array-like or dtype. The array or dtype to check.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'api.types.is_sparse(arr)',\n",
       "      'func_desc': '(DEPRECATED) Check whether an array-like is a 1-D pandas sparse array.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_sparse.html#pandas.api.types.is_sparse',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_sparse',\n",
       "       'full_function': 'pandas.api.types.is_sparse(arr)',\n",
       "       'function_text': 'Check whether an array-like is a 1-D pandas sparse array. Deprecated since version 2.1.0: Use isinstance(dtype, pd.SparseDtype) instead. Check that the one-dimensional array-like is a pandas sparse array.\\nReturns True if it is a pandas sparse array, not another type of\\nsparse array.',\n",
       "       'parameter_names_desc': [{'param_name': 'arr',\n",
       "         'param_type': 'array-like',\n",
       "         'param_desc': 'Array-like to check.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.api.types.is_sparse',\n",
       "       'descriptions': 'Check whether an array-like is a 1-D pandas sparse array. Deprecated since version 2.1.0: Use isinstance(dtype, pd.SparseDtype) instead. Check that the one-dimensional array-like is a pandas sparse array.\\nReturns True if it is a pandas sparse array, not another type of\\nsparse array.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'arr': {'type': 'array',\n",
       "          'description': 'array-like. Array-like to check.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'api.types.is_file_like(obj)',\n",
       "      'func_desc': 'Check if the object is a file-like object.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_file_like.html#pandas.api.types.is_file_like',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_file_like',\n",
       "       'full_function': 'pandas.api.types.is_file_like(obj)',\n",
       "       'function_text': 'Check if the object is a file-like object. For objects to be considered file-like, they must\\nbe an iterator AND have either a read and/or write\\nmethod as an attribute. Note: file-like objects must be iterable, but\\niterable objects need not be file-like.',\n",
       "       'parameter_names_desc': [{'param_name': 'obj',\n",
       "         'param_type': 'The object to check',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.api.types.is_file_like',\n",
       "       'descriptions': 'Check if the object is a file-like object. For objects to be considered file-like, they must\\nbe an iterator AND have either a read and/or write\\nmethod as an attribute. Note: file-like objects must be iterable, but\\niterable objects need not be file-like.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'obj': {'type': 'object',\n",
       "          'description': 'The object to check. '}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'api.types.is_named_tuple(obj)',\n",
       "      'func_desc': 'Check if the object is a named tuple.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_named_tuple.html#pandas.api.types.is_named_tuple',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_named_tuple',\n",
       "       'full_function': 'pandas.api.types.is_named_tuple(obj)',\n",
       "       'function_text': 'Check if the object is a named tuple.',\n",
       "       'parameter_names_desc': [{'param_name': 'obj',\n",
       "         'param_type': 'The object to check',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.api.types.is_named_tuple',\n",
       "       'descriptions': 'Check if the object is a named tuple.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'obj': {'type': 'object',\n",
       "          'description': 'The object to check. '}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'api.types.is_complex(obj)',\n",
       "      'func_desc': 'Return True if given object is complex.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_complex.html#pandas.api.types.is_complex',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_complex',\n",
       "       'full_function': 'pandas.api.types.is_complex(obj)#',\n",
       "       'function_text': 'Return True if given object is complex.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'api.types.is_hashable(obj)',\n",
       "      'func_desc': 'Return True if hash(obj) will succeed, False otherwise.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_hashable.html#pandas.api.types.is_hashable',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_hashable',\n",
       "       'full_function': 'pandas.api.types.is_hashable(obj)',\n",
       "       'function_text': 'Return True if hash(obj) will succeed, False otherwise. Some types will pass a test against collections.abc.Hashable but fail when\\nthey are actually hashed with hash(). Distinguish between these and other types by trying the call to hash() and\\nseeing if they raise TypeError.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'api.types.is_interval(obj)',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_interval.html#pandas.api.types.is_interval',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_interval',\n",
       "       'full_function': 'pandas.api.types.is_interval(obj)#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'api.types.is_re(obj)',\n",
       "      'func_desc': 'Check if the object is a regex pattern instance.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_re.html#pandas.api.types.is_re',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_re',\n",
       "       'full_function': 'pandas.api.types.is_re(obj)',\n",
       "       'function_text': 'Check if the object is a regex pattern instance.',\n",
       "       'parameter_names_desc': [{'param_name': 'obj',\n",
       "         'param_type': 'The object to check',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.api.types.is_re',\n",
       "       'descriptions': 'Check if the object is a regex pattern instance.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'obj': {'type': 'object',\n",
       "          'description': 'The object to check. '}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'api.types.is_scalar(val)',\n",
       "      'func_desc': 'Return True if given object is scalar.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_scalar.html#pandas.api.types.is_scalar',\n",
       "      'function_definitions': {'function_name': 'pandas.api.types.is_scalar',\n",
       "       'full_function': 'pandas.api.types.is_scalar(val)#',\n",
       "       'function_text': 'Return True if given object is scalar.',\n",
       "       'parameter_names_desc': [{'param_name': 'val',\n",
       "         'param_type': 'object',\n",
       "         'param_desc': 'This includes:\\n\\nnumpy array scalar (e.g. np.int64)\\nPython builtin numerics\\nPython builtin byte arrays and strings\\nNone\\ndatetime.datetime\\ndatetime.timedelta\\nPeriod\\ndecimal.Decimal\\nInterval\\nDateOffset\\nFraction\\nNumber.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.api.types.is_scalar',\n",
       "       'descriptions': 'Return True if given object is scalar.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'val': {'type': 'object',\n",
       "          'description': 'object. This includes:\\n\\nnumpy array scalar (e.g. np.int64)\\nPython builtin numerics\\nPython builtin byte arrays and strings\\nNone\\ndatetime.datetime\\ndatetime.timedelta\\nPeriod\\ndecimal.Decimal\\nInterval\\nDateOffset\\nFraction\\nNumber.\\n\\n'}},\n",
       "        'required': []}}}]}],\n",
       "  'name': 'pandas arrays, scalars, and data types',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/arrays.html'},\n",
       " 'indexing.html': {'functions': [{'Index': [{'func_name': 'Index([data,\\xa0dtype,\\xa0copy,\\xa0name,\\xa0tupleize_cols])',\n",
       "      'func_desc': 'Immutable sequence used for indexing and alignment.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.html#pandas.Index',\n",
       "      'function_definitions': {'function_name': 'pandas.Index',\n",
       "       'full_function': 'class pandas.Index(data=None, dtype=None, copy=False, name=None, tupleize_cols=True)',\n",
       "       'function_text': 'Immutable sequence used for indexing and alignment. The basic object storing axis labels for all pandas objects. Changed in version 2.0.0: Index can hold all numpy numeric dtypes (except float16). Previously only\\nint64/uint64/float64 dtypes were accepted.',\n",
       "       'parameter_names_desc': [{'param_name': 'data',\n",
       "         'param_type': 'array-like (1-dimensional)',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'dtype',\n",
       "         'param_type': 'str, numpy.dtype, or ExtensionDtype, optional',\n",
       "         'param_desc': 'Data type for the output Index. If not specified, this will be\\ninferred from data.\\nSee the user guide for more usages.\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Copy input data.\\n'},\n",
       "        {'param_name': 'name',\n",
       "         'param_type': 'object',\n",
       "         'param_desc': 'Name to be stored in the index.\\n'},\n",
       "        {'param_name': 'tupleize_cols',\n",
       "         'param_type': 'bool (default: True)',\n",
       "         'param_desc': 'When True, attempt to create a MultiIndex if possible.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index',\n",
       "       'descriptions': 'Immutable sequence used for indexing and alignment. The basic object storing axis labels for all pandas objects. Changed in version 2.0.0: Index can hold all numpy numeric dtypes (except float16). Previously only\\nint64/uint64/float64 dtypes were accepted.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'data': {'type': 'array',\n",
       "          'description': 'array-like (1-dimensional). '},\n",
       "         'dtype': {'type': 'string',\n",
       "          'description': 'str, numpy.dtype, or ExtensionDtype, optional. Data type for the output Index. If not specified, this will be\\ninferred from data.\\nSee the user guide for more usages.\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Copy input data.\\n'},\n",
       "         'name': {'type': 'object',\n",
       "          'description': 'object. Name to be stored in the index.\\n'},\n",
       "         'tupleize_cols': {'type': 'boolean',\n",
       "          'description': 'bool (default: True). When True, attempt to create a MultiIndex if possible.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.values',\n",
       "      'func_desc': 'Return an array representing the data in the Index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.values.html#pandas.Index.values',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.values',\n",
       "       'full_function': 'property Index.values',\n",
       "       'function_text': 'Return an array representing the data in the Index. Warning We recommend using Index.array or\\nIndex.to_numpy(), depending on whether you need\\na reference to the underlying data or a NumPy array.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.is_monotonic_decreasing',\n",
       "      'func_desc': 'Return a boolean if the values are equal or decreasing.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.is_monotonic_decreasing.html#pandas.Index.is_monotonic_decreasing',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.is_monotonic_decreasing',\n",
       "       'full_function': 'property Index.is_monotonic_decreasing',\n",
       "       'function_text': 'Return a boolean if the values are equal or decreasing.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.has_duplicates',\n",
       "      'func_desc': 'Check if the Index has duplicate values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.has_duplicates.html#pandas.Index.has_duplicates',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.has_duplicates',\n",
       "       'full_function': 'property Index.has_duplicates',\n",
       "       'function_text': 'Check if the Index has duplicate values.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.dtype',\n",
       "      'func_desc': 'Return the dtype object of the underlying data.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.dtype.html#pandas.Index.dtype',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.dtype',\n",
       "       'full_function': 'Index.dtype',\n",
       "       'function_text': 'Return the dtype object of the underlying data. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.shape',\n",
       "      'func_desc': 'Return a tuple of the shape of the underlying data.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.shape.html#pandas.Index.shape',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.shape',\n",
       "       'full_function': 'property Index.shape',\n",
       "       'function_text': 'Return a tuple of the shape of the underlying data. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.names',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.names.html#pandas.Index.names',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.names',\n",
       "       'full_function': 'property Index.names',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.ndim',\n",
       "      'func_desc': 'Number of dimensions of the underlying data, by definition 1.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.ndim.html#pandas.Index.ndim',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.ndim',\n",
       "       'full_function': 'property Index.ndim',\n",
       "       'function_text': 'Number of dimensions of the underlying data, by definition 1. Examples For Index:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.empty',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.empty.html#pandas.Index.empty',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.empty',\n",
       "       'full_function': 'property Index.empty',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.memory_usage([deep])',\n",
       "      'func_desc': 'Memory usage of the values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.memory_usage.html#pandas.Index.memory_usage',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.memory_usage',\n",
       "       'full_function': 'Index.memory_usage(deep=False)',\n",
       "       'function_text': 'Memory usage of the values.',\n",
       "       'parameter_names_desc': [{'param_name': 'deep',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Introspect the data deeply, interrogate\\nobject dtypes for system-level memory consumption.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.memory_usage',\n",
       "       'descriptions': 'Memory usage of the values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'deep': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Introspect the data deeply, interrogate\\nobject dtypes for system-level memory consumption.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.all(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Return whether all elements are Truthy.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.all.html#pandas.Index.all',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.all',\n",
       "       'full_function': 'Index.all(*args, **kwargs)',\n",
       "       'function_text': 'Return whether all elements are Truthy.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.argmin([axis,\\xa0skipna])',\n",
       "      'func_desc': 'Return int position of the smallest value in the Series.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.argmin.html#pandas.Index.argmin',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.argmin',\n",
       "       'full_function': 'Index.argmin(axis=None, skipna=True, *args, **kwargs)',\n",
       "       'function_text': 'Return int position of the smallest value in the Series. If the minimum is achieved in multiple locations,\\nthe first row position is returned.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{None}',\n",
       "         'param_desc': 'Unused. Parameter needed for compatibility with DataFrame.\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values when showing the result.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.argmin',\n",
       "       'descriptions': 'Return int position of the smallest value in the Series. If the minimum is achieved in multiple locations,\\nthe first row position is returned.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': '{None}',\n",
       "          'description': '{None}. Unused. Parameter needed for compatibility with DataFrame.\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values when showing the result.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.copy([name,\\xa0deep])',\n",
       "      'func_desc': 'Make a copy of this object.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.copy.html#pandas.Index.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.copy',\n",
       "       'full_function': 'Index.copy(name=None, deep=False)',\n",
       "       'function_text': 'Make a copy of this object. Name is set on the new object.',\n",
       "       'parameter_names_desc': [{'param_name': 'name',\n",
       "         'param_type': 'Label, optional',\n",
       "         'param_desc': 'Set name for new object.\\n'},\n",
       "        {'param_name': 'deep',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.Index.copy',\n",
       "       'descriptions': 'Make a copy of this object. Name is set on the new object.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'name': {'type': 'Label, optional',\n",
       "          'description': 'Label, optional. Set name for new object.\\n'},\n",
       "         'deep': {'type': 'boolean', 'description': 'bool, default False. '}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.drop(labels[,\\xa0errors])',\n",
       "      'func_desc': 'Make new Index with passed list of labels deleted.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.drop.html#pandas.Index.drop',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.drop',\n",
       "       'full_function': \"Index.drop(labels, errors='raise')\",\n",
       "       'function_text': 'Make new Index with passed list of labels deleted.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.duplicated([keep])',\n",
       "      'func_desc': 'Indicate duplicate index values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.duplicated.html#pandas.Index.duplicated',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.duplicated',\n",
       "       'full_function': \"Index.duplicated(keep='first')\",\n",
       "       'function_text': 'Indicate duplicate index values. Duplicated values are indicated as True values in the resulting\\narray. Either all duplicates, all except the first, or all except the\\nlast occurrence of duplicates can be indicated.',\n",
       "       'parameter_names_desc': [{'param_name': 'keep',\n",
       "         'param_type': '{‘first’, ‘last’, False}, default ‘first’',\n",
       "         'param_desc': 'The value or values in a set of duplicates to mark as missing.\\n\\n‘first’ : Mark duplicates as True except for the first\\noccurrence.\\n‘last’ : Mark duplicates as True except for the last\\noccurrence.\\nFalse : Mark all duplicates as True.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.duplicated',\n",
       "       'descriptions': 'Indicate duplicate index values. Duplicated values are indicated as True values in the resulting\\narray. Either all duplicates, all except the first, or all except the\\nlast occurrence of duplicates can be indicated.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'keep': {'type': 'string',\n",
       "          'enum': ['first', ' last', ' False'],\n",
       "          'description': '{‘first’, ‘last’, False}, default ‘first’. The value or values in a set of duplicates to mark as missing.\\n\\n‘first’ : Mark duplicates as True except for the first\\noccurrence.\\n‘last’ : Mark duplicates as True except for the last\\noccurrence.\\nFalse : Mark all duplicates as True.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.factorize([sort,\\xa0use_na_sentinel])',\n",
       "      'func_desc': 'Encode the object as an enumerated type or categorical variable.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.factorize.html#pandas.Index.factorize',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.factorize',\n",
       "       'full_function': 'Index.factorize(sort=False, use_na_sentinel=True)',\n",
       "       'function_text': 'Encode the object as an enumerated type or categorical variable. This method is useful for obtaining a numeric representation of an\\narray when all that matters is identifying distinct values. factorize\\nis available as both a top-level function pandas.factorize(),\\nand as a method Series.factorize() and Index.factorize().',\n",
       "       'parameter_names_desc': [{'param_name': 'sort',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Sort uniques and shuffle codes to maintain the\\nrelationship.\\n'},\n",
       "        {'param_name': 'use_na_sentinel',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If True, the sentinel -1 will be used for NaN values. If False,\\nNaN values will be encoded as non-negative integers and will not drop the\\nNaN from the uniques of the values.\\n\\nNew in version 1.5.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.factorize',\n",
       "       'descriptions': 'Encode the object as an enumerated type or categorical variable. This method is useful for obtaining a numeric representation of an\\narray when all that matters is identifying distinct values. factorize\\nis available as both a top-level function pandas.factorize(),\\nand as a method Series.factorize() and Index.factorize().',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'sort': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Sort uniques and shuffle codes to maintain the\\nrelationship.\\n'},\n",
       "         'use_na_sentinel': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If True, the sentinel -1 will be used for NaN values. If False,\\nNaN values will be encoded as non-negative integers and will not drop the\\nNaN from the uniques of the values.\\n\\nNew in version 1.5.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.insert(loc,\\xa0item)',\n",
       "      'func_desc': 'Make new Index inserting new item at location.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.insert.html#pandas.Index.insert',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.insert',\n",
       "       'full_function': 'Index.insert(loc, item)',\n",
       "       'function_text': 'Make new Index inserting new item at location. Follows Python numpy.insert semantics for negative values.',\n",
       "       'parameter_names_desc': [{'param_name': 'loc',\n",
       "         'param_type': 'int',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'item', 'param_type': 'object', 'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.Index.insert',\n",
       "       'descriptions': 'Make new Index inserting new item at location. Follows Python numpy.insert semantics for negative values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'loc': {'type': 'integer', 'description': 'int. '},\n",
       "         'item': {'type': 'object', 'description': 'object. '}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.is_boolean()',\n",
       "      'func_desc': '(DEPRECATED) Check if the Index only consists of booleans.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.is_boolean.html#pandas.Index.is_boolean',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.is_boolean',\n",
       "       'full_function': 'final Index.is_boolean()',\n",
       "       'function_text': 'Check if the Index only consists of booleans. Deprecated since version 2.0.0: Use pandas.api.types.is_bool_dtype instead.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.is_floating()',\n",
       "      'func_desc': '(DEPRECATED) Check if the Index is a floating type.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.is_floating.html#pandas.Index.is_floating',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.is_floating',\n",
       "       'full_function': 'final Index.is_floating()',\n",
       "       'function_text': 'Check if the Index is a floating type. Deprecated since version 2.0.0: Use pandas.api.types.is_float_dtype instead The Index may consist of only floats, NaNs, or a mix of floats,\\nintegers, or NaNs.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.is_interval()',\n",
       "      'func_desc': '(DEPRECATED) Check if the Index holds Interval objects.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.is_interval.html#pandas.Index.is_interval',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.is_interval',\n",
       "       'full_function': 'final Index.is_interval()',\n",
       "       'function_text': 'Check if the Index holds Interval objects. Deprecated since version 2.0.0: Use isinstance(index.dtype, pd.IntervalDtype) instead.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.is_object()',\n",
       "      'func_desc': '(DEPRECATED) Check if the Index is of the object dtype.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.is_object.html#pandas.Index.is_object',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.is_object',\n",
       "       'full_function': 'final Index.is_object()',\n",
       "       'function_text': 'Check if the Index is of the object dtype. Deprecated since version 2.0.0: Use pandas.api.types.is_object_dtype instead.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.max([axis,\\xa0skipna])',\n",
       "      'func_desc': 'Return the maximum value of the Index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.max.html#pandas.Index.max',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.max',\n",
       "       'full_function': 'Index.max(axis=None, skipna=True, *args, **kwargs)',\n",
       "       'function_text': 'Return the maximum value of the Index.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'For compatibility with NumPy. Only 0 or None are allowed.\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values when showing the result.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.max',\n",
       "       'descriptions': 'Return the maximum value of the Index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': 'integer',\n",
       "          'description': 'int, optional. For compatibility with NumPy. Only 0 or None are allowed.\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values when showing the result.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.rename(name,\\xa0*[,\\xa0inplace])',\n",
       "      'func_desc': 'Alter Index or MultiIndex name.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.rename.html#pandas.Index.rename',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.rename',\n",
       "       'full_function': 'Index.rename(name, *, inplace=False)',\n",
       "       'function_text': 'Alter Index or MultiIndex name. Able to set new names without level. Defaults to returning new index.\\nLength of names must match number of levels in MultiIndex.',\n",
       "       'parameter_names_desc': [{'param_name': 'name',\n",
       "         'param_type': 'label or list of labels',\n",
       "         'param_desc': 'Name(s) to set.\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Modifies the object directly, instead of creating a new Index or\\nMultiIndex.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.rename',\n",
       "       'descriptions': 'Alter Index or MultiIndex name. Able to set new names without level. Defaults to returning new index.\\nLength of names must match number of levels in MultiIndex.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'name': {'type': 'array',\n",
       "          'description': 'label or list of labels. Name(s) to set.\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Modifies the object directly, instead of creating a new Index or\\nMultiIndex.\\n'}},\n",
       "        'required': ['name']}}},\n",
       "     {'func_name': 'Index.where(cond[,\\xa0other])',\n",
       "      'func_desc': 'Replace values where the condition is False.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.where.html#pandas.Index.where',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.where',\n",
       "       'full_function': 'final Index.where(cond, other=None)',\n",
       "       'function_text': 'Replace values where the condition is False. The replacement is taken from other.',\n",
       "       'parameter_names_desc': [{'param_name': 'cond',\n",
       "         'param_type': 'bool array-like with the same length as self',\n",
       "         'param_desc': 'Condition to select the values on.\\n'},\n",
       "        {'param_name': 'other',\n",
       "         'param_type': 'scalar, or array-like, default None',\n",
       "         'param_desc': 'Replacement if the condition is False.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.where',\n",
       "       'descriptions': 'Replace values where the condition is False. The replacement is taken from other.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'cond': {'type': 'boolean',\n",
       "          'description': 'bool array-like with the same length as self. Condition to select the values on.\\n'},\n",
       "         'other': {'type': 'array',\n",
       "          'description': 'scalar, or array-like, default None. Replacement if the condition is False.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.putmask(mask,\\xa0value)',\n",
       "      'func_desc': 'Return a new Index of the values set with the mask.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.putmask.html#pandas.Index.putmask',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.putmask',\n",
       "       'full_function': 'Index.putmask(mask, value)',\n",
       "       'function_text': 'Return a new Index of the values set with the mask.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.nunique([dropna])',\n",
       "      'func_desc': 'Return number of unique elements in the object.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.nunique.html#pandas.Index.nunique',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.nunique',\n",
       "       'full_function': 'Index.nunique(dropna=True)',\n",
       "       'function_text': 'Return number of unique elements in the object. Excludes NA values by default.',\n",
       "       'parameter_names_desc': [{'param_name': 'dropna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Don’t include NaN in the count.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.nunique',\n",
       "       'descriptions': 'Return number of unique elements in the object. Excludes NA values by default.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dropna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Don’t include NaN in the count.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.set_names(names,\\xa0*[,\\xa0level,\\xa0inplace])',\n",
       "      'func_desc': 'Set Index or MultiIndex name.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.set_names.html#pandas.Index.set_names',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.set_names',\n",
       "       'full_function': 'Index.set_names(names, *, level=None, inplace=False)',\n",
       "       'function_text': 'Set Index or MultiIndex name. Able to set new names partially and by level.',\n",
       "       'parameter_names_desc': [{'param_name': 'names',\n",
       "         'param_type': 'label or list of label or dict-like for MultiIndex',\n",
       "         'param_desc': 'Name(s) to set.\\n\\nChanged in version 1.3.0.\\n\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int, label or list of int or label, optional',\n",
       "         'param_desc': 'If the index is a MultiIndex and names is not dict-like, level(s) to set\\n(None for all levels). Otherwise level must be None.\\n\\nChanged in version 1.3.0.\\n\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Modifies the object directly, instead of creating a new Index or\\nMultiIndex.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.set_names',\n",
       "       'descriptions': 'Set Index or MultiIndex name. Able to set new names partially and by level.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'names': {'type': 'array',\n",
       "          'description': 'label or list of label or dict-like for MultiIndex. Name(s) to set.\\n\\nChanged in version 1.3.0.\\n\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int, label or list of int or label, optional. If the index is a MultiIndex and names is not dict-like, level(s) to set\\n(None for all levels). Otherwise level must be None.\\n\\nChanged in version 1.3.0.\\n\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Modifies the object directly, instead of creating a new Index or\\nMultiIndex.\\n'}},\n",
       "        'required': ['names']}}},\n",
       "     {'func_name': 'Index.fillna([value,\\xa0downcast])',\n",
       "      'func_desc': 'Fill NA/NaN values with the specified value.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.fillna.html#pandas.Index.fillna',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.fillna',\n",
       "       'full_function': 'Index.fillna(value=None, downcast=_NoDefault.no_default)',\n",
       "       'function_text': 'Fill NA/NaN values with the specified value.',\n",
       "       'parameter_names_desc': [{'param_name': 'value',\n",
       "         'param_type': 'scalar',\n",
       "         'param_desc': 'Scalar value to use to fill holes (e.g. 0).\\nThis value cannot be a list-likes.\\n'},\n",
       "        {'param_name': 'downcast',\n",
       "         'param_type': 'dict, default is None',\n",
       "         'param_desc': 'A dict of item->dtype of what to downcast if possible,\\nor the string ‘infer’ which will try to downcast to an appropriate\\nequal type (e.g. float64 to int64 if possible).\\n\\nDeprecated since version 2.1.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.fillna',\n",
       "       'descriptions': 'Fill NA/NaN values with the specified value.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'value': {'type': 'scalar',\n",
       "          'description': 'scalar. Scalar value to use to fill holes (e.g. 0).\\nThis value cannot be a list-likes.\\n'},\n",
       "         'downcast': {'type': 'dict, default is None',\n",
       "          'description': 'dict, default is None. A dict of item->dtype of what to downcast if possible,\\nor the string ‘infer’ which will try to downcast to an appropriate\\nequal type (e.g. float64 to int64 if possible).\\n\\nDeprecated since version 2.1.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.isna()',\n",
       "      'func_desc': 'Detect missing values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.isna.html#pandas.Index.isna',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.isna',\n",
       "       'full_function': 'final Index.isna()',\n",
       "       'function_text': 'Detect missing values. Return a boolean same-sized object indicating if the values are NA.\\nNA values, such as None, numpy.NaN or pd.NaT, get\\nmapped to True values.\\nEverything else get mapped to False values. Characters such as\\nempty strings ‘’ or numpy.inf are not considered NA values.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.astype(dtype[,\\xa0copy])',\n",
       "      'func_desc': 'Create an Index with values cast to dtypes.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.astype.html#pandas.Index.astype',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.astype',\n",
       "       'full_function': 'Index.astype(dtype, copy=True)',\n",
       "       'function_text': 'Create an Index with values cast to dtypes. The class of a new Index is determined by dtype. When conversion is\\nimpossible, a TypeError exception is raised.',\n",
       "       'parameter_names_desc': [{'param_name': 'dtype',\n",
       "         'param_type': 'numpy dtype or pandas type',\n",
       "         'param_desc': \"Note that any signed integer dtype is treated as 'int64',\\nand any unsigned integer dtype is treated as 'uint64',\\nregardless of the size.\\n\"},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'By default, astype always returns a newly allocated object.\\nIf copy is set to False and internal requirements on dtype are\\nsatisfied, the original data is used to create a new Index\\nor the original Index is returned.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.astype',\n",
       "       'descriptions': 'Create an Index with values cast to dtypes. The class of a new Index is determined by dtype. When conversion is\\nimpossible, a TypeError exception is raised.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dtype': {'type': 'numpy dtype or pandas type',\n",
       "          'description': \"numpy dtype or pandas type. Note that any signed integer dtype is treated as 'int64',\\nand any unsigned integer dtype is treated as 'uint64',\\nregardless of the size.\\n\"},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default True. By default, astype always returns a newly allocated object.\\nIf copy is set to False and internal requirements on dtype are\\nsatisfied, the original data is used to create a new Index\\nor the original Index is returned.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.map(mapper[,\\xa0na_action])',\n",
       "      'func_desc': 'Map values using an input mapping or function.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.map.html#pandas.Index.map',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.map',\n",
       "       'full_function': 'Index.map(mapper, na_action=None)',\n",
       "       'function_text': 'Map values using an input mapping or function.',\n",
       "       'parameter_names_desc': [{'param_name': 'mapper',\n",
       "         'param_type': 'function, dict, or Series',\n",
       "         'param_desc': 'Mapping correspondence.\\n'},\n",
       "        {'param_name': 'na_action',\n",
       "         'param_type': '{None, ‘ignore’}',\n",
       "         'param_desc': 'If ‘ignore’, propagate NA values, without passing them to the\\nmapping correspondence.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.map',\n",
       "       'descriptions': 'Map values using an input mapping or function.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'mapper': {'type': 'function, dict, or Series',\n",
       "          'description': 'function, dict, or Series. Mapping correspondence.\\n'},\n",
       "         'na_action': {'type': 'string',\n",
       "          'enum': ['None', ' ignore'],\n",
       "          'description': '{None, ‘ignore’}. If ‘ignore’, propagate NA values, without passing them to the\\nmapping correspondence.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.to_list()',\n",
       "      'func_desc': 'Return a list of the values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.to_list.html#pandas.Index.to_list',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.to_list',\n",
       "       'full_function': 'Index.to_list()',\n",
       "       'function_text': 'Return a list of the values. These are each a scalar type, which is a Python scalar\\n(for str, int, float) or a pandas scalar\\n(for Timestamp/Timedelta/Interval/Period)',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.to_frame([index,\\xa0name])',\n",
       "      'func_desc': 'Create a DataFrame with a column containing the Index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.to_frame.html#pandas.Index.to_frame',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.to_frame',\n",
       "       'full_function': 'Index.to_frame(index=True, name=_NoDefault.no_default)',\n",
       "       'function_text': 'Create a DataFrame with a column containing the Index.',\n",
       "       'parameter_names_desc': [{'param_name': 'index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Set the index of the returned DataFrame as the original Index.\\n'},\n",
       "        {'param_name': 'name',\n",
       "         'param_type': 'object, defaults to index.name',\n",
       "         'param_desc': 'The passed name should substitute for the index name (if it has\\none).\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.to_frame',\n",
       "       'descriptions': 'Create a DataFrame with a column containing the Index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Set the index of the returned DataFrame as the original Index.\\n'},\n",
       "         'name': {'type': 'object',\n",
       "          'description': 'object, defaults to index.name. The passed name should substitute for the index name (if it has\\none).\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.argsort(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Return the integer indices that would sort the index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.argsort.html#pandas.Index.argsort',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.argsort',\n",
       "       'full_function': 'Index.argsort(*args, **kwargs)',\n",
       "       'function_text': 'Return the integer indices that would sort the index.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.sort_values(*[,\\xa0return_indexer,\\xa0...])',\n",
       "      'func_desc': 'Return a sorted copy of the index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.sort_values.html#pandas.Index.sort_values',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.sort_values',\n",
       "       'full_function': \"Index.sort_values(*, return_indexer=False, ascending=True, na_position='last', key=None)\",\n",
       "       'function_text': 'Return a sorted copy of the index. Return a sorted copy of the index, and optionally return the indices\\nthat sorted the index itself.',\n",
       "       'parameter_names_desc': [{'param_name': 'return_indexer',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Should the indices that would sort the index be returned.\\n'},\n",
       "        {'param_name': 'ascending',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Should the index values be sorted in an ascending order.\\n'},\n",
       "        {'param_name': 'na_position',\n",
       "         'param_type': '{‘first’ or ‘last’}, default ‘last’',\n",
       "         'param_desc': 'Argument ‘first’ puts NaNs at the beginning, ‘last’ puts NaNs at\\nthe end.\\n'},\n",
       "        {'param_name': 'key',\n",
       "         'param_type': 'callable, optional',\n",
       "         'param_desc': 'If not None, apply the key function to the index values\\nbefore sorting. This is similar to the key argument in the\\nbuiltin sorted() function, with the notable difference that\\nthis key function should be vectorized. It should expect an\\nIndex and return an Index of the same shape.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.sort_values',\n",
       "       'descriptions': 'Return a sorted copy of the index. Return a sorted copy of the index, and optionally return the indices\\nthat sorted the index itself.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'return_indexer': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Should the indices that would sort the index be returned.\\n'},\n",
       "         'ascending': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Should the index values be sorted in an ascending order.\\n'},\n",
       "         'na_position': {'type': 'string',\n",
       "          'enum': ['first or last'],\n",
       "          'description': '{‘first’ or ‘last’}, default ‘last’. Argument ‘first’ puts NaNs at the beginning, ‘last’ puts NaNs at\\nthe end.\\n'},\n",
       "         'key': {'type': 'object',\n",
       "          'description': 'callable, optional. If not None, apply the key function to the index values\\nbefore sorting. This is similar to the key argument in the\\nbuiltin sorted() function, with the notable difference that\\nthis key function should be vectorized. It should expect an\\nIndex and return an Index of the same shape.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.shift([periods,\\xa0freq])',\n",
       "      'func_desc': 'Shift index by desired number of time frequency increments.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.shift.html#pandas.Index.shift',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.shift',\n",
       "       'full_function': 'Index.shift(periods=1, freq=None)',\n",
       "       'function_text': 'Shift index by desired number of time frequency increments. This method is for shifting the values of datetime-like indexes\\nby a specified time increment a given number of times.',\n",
       "       'parameter_names_desc': [{'param_name': 'periods',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Number of periods (or increments) to shift by,\\ncan be positive or negative.\\n'},\n",
       "        {'param_name': 'freq',\n",
       "         'param_type': 'pandas.DateOffset, pandas.Timedelta or str, optional',\n",
       "         'param_desc': 'Frequency increment to shift by.\\nIf None, the index is shifted by its own freq attribute.\\nOffset aliases are valid strings, e.g., ‘D’, ‘W’, ‘M’ etc.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.shift',\n",
       "       'descriptions': 'Shift index by desired number of time frequency increments. This method is for shifting the values of datetime-like indexes\\nby a specified time increment a given number of times.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'periods': {'type': 'integer',\n",
       "          'description': 'int, default 1. Number of periods (or increments) to shift by,\\ncan be positive or negative.\\n'},\n",
       "         'freq': {'type': 'string',\n",
       "          'description': 'pandas.DateOffset, pandas.Timedelta or str, optional. Frequency increment to shift by.\\nIf None, the index is shifted by its own freq attribute.\\nOffset aliases are valid strings, e.g., ‘D’, ‘W’, ‘M’ etc.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.append(other)',\n",
       "      'func_desc': 'Append a collection of Index options together.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.append.html#pandas.Index.append',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.append',\n",
       "       'full_function': 'Index.append(other)',\n",
       "       'function_text': 'Append a collection of Index options together.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Index or list/tuple of indices',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.Index.append',\n",
       "       'descriptions': 'Append a collection of Index options together.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'array',\n",
       "          'description': 'Index or list/tuple of indices. '}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.intersection(other[,\\xa0sort])',\n",
       "      'func_desc': 'Form the intersection of two Index objects.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.intersection.html#pandas.Index.intersection',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.intersection',\n",
       "       'full_function': 'final Index.intersection(other, sort=False)',\n",
       "       'function_text': 'Form the intersection of two Index objects. This returns a new Index with elements common to the index and other.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Index or array-like',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'sort',\n",
       "         'param_type': 'True, False or None, default False',\n",
       "         'param_desc': 'Whether to sort the resulting index.\\n\\nNone : sort the result, except when self and other are equal\\nor when the values cannot be compared.\\nFalse : do not sort the result.\\nTrue : Sort the result (which may raise TypeError).\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.intersection',\n",
       "       'descriptions': 'Form the intersection of two Index objects. This returns a new Index with elements common to the index and other.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'array',\n",
       "          'description': 'Index or array-like. '},\n",
       "         'sort': {'type': 'True, False or None, default False',\n",
       "          'description': 'True, False or None, default False. Whether to sort the resulting index.\\n\\nNone : sort the result, except when self and other are equal\\nor when the values cannot be compared.\\nFalse : do not sort the result.\\nTrue : Sort the result (which may raise TypeError).\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.difference(other[,\\xa0sort])',\n",
       "      'func_desc': 'Return a new Index with elements of index not in other.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.difference.html#pandas.Index.difference',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.difference',\n",
       "       'full_function': 'final Index.difference(other, sort=None)',\n",
       "       'function_text': 'Return a new Index with elements of index not in other. This is the set difference of two Index objects.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Index or array-like',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'sort',\n",
       "         'param_type': 'bool or None, default None',\n",
       "         'param_desc': 'Whether to sort the resulting index. By default, the\\nvalues are attempted to be sorted, but any TypeError from\\nincomparable elements is caught by pandas.\\n\\nNone : Attempt to sort the result, but catch any TypeErrors\\nfrom comparing incomparable elements.\\nFalse : Do not sort the result.\\nTrue : Sort the result (which may raise TypeError).\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.difference',\n",
       "       'descriptions': 'Return a new Index with elements of index not in other. This is the set difference of two Index objects.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'array',\n",
       "          'description': 'Index or array-like. '},\n",
       "         'sort': {'type': 'boolean',\n",
       "          'description': 'bool or None, default None. Whether to sort the resulting index. By default, the\\nvalues are attempted to be sorted, but any TypeError from\\nincomparable elements is caught by pandas.\\n\\nNone : Attempt to sort the result, but catch any TypeErrors\\nfrom comparing incomparable elements.\\nFalse : Do not sort the result.\\nTrue : Sort the result (which may raise TypeError).\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.asof(label)',\n",
       "      'func_desc': 'Return the label from the index, or, if not present, the previous one.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.asof.html#pandas.Index.asof',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.asof',\n",
       "       'full_function': 'final Index.asof(label)',\n",
       "       'function_text': 'Return the label from the index, or, if not present, the previous one. Assuming that the index is sorted, return the passed index label if it\\nis in the index, or return the previous index label if the passed one\\nis not in the index.',\n",
       "       'parameter_names_desc': [{'param_name': 'label',\n",
       "         'param_type': 'object',\n",
       "         'param_desc': 'The label up to which the method returns the latest index label.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.asof',\n",
       "       'descriptions': 'Return the label from the index, or, if not present, the previous one. Assuming that the index is sorted, return the passed index label if it\\nis in the index, or return the previous index label if the passed one\\nis not in the index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'label': {'type': 'object',\n",
       "          'description': 'object. The label up to which the method returns the latest index label.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.get_indexer(target[,\\xa0method,\\xa0limit,\\xa0...])',\n",
       "      'func_desc': 'Compute indexer and mask for new index given the current index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.get_indexer.html#pandas.Index.get_indexer',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.get_indexer',\n",
       "       'full_function': 'final Index.get_indexer(target, method=None, limit=None, tolerance=None)',\n",
       "       'function_text': 'Compute indexer and mask for new index given the current index. The indexer should be then used as an input to ndarray.take to align the\\ncurrent data to the new index.',\n",
       "       'parameter_names_desc': [{'param_name': 'target',\n",
       "         'param_type': 'Index',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'method',\n",
       "         'param_type': '{None, ‘pad’/’ffill’, ‘backfill’/’bfill’, ‘nearest’}, optional',\n",
       "         'param_desc': '\\ndefault: exact matches only.\\npad / ffill: find the PREVIOUS index value if no exact match.\\nbackfill / bfill: use NEXT index value if no exact match\\nnearest: use the NEAREST index value if no exact match. Tied\\ndistances are broken by preferring the larger index value.\\n\\n'},\n",
       "        {'param_name': 'limit',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Maximum number of consecutive labels in target to match for\\ninexact matches.\\n'},\n",
       "        {'param_name': 'tolerance',\n",
       "         'param_type': 'optional',\n",
       "         'param_desc': 'Maximum distance between original and new labels for inexact\\nmatches. The values of the index at the matching locations must\\nsatisfy the equation abs(index[indexer] - target) <= tolerance.\\nTolerance may be a scalar value, which applies the same tolerance\\nto all values, or list-like, which applies variable tolerance per\\nelement. List-like includes list, tuple, array, Series, and must be\\nthe same size as the index and its dtype must exactly match the\\nindex’s type.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.get_indexer',\n",
       "       'descriptions': 'Compute indexer and mask for new index given the current index. The indexer should be then used as an input to ndarray.take to align the\\ncurrent data to the new index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'target': {'type': 'Index', 'description': 'Index. '},\n",
       "         'method': {'type': 'string',\n",
       "          'enum': ['None', ' pad/ffill', ' backfill/bfill', ' nearest'],\n",
       "          'description': '{None, ‘pad’/’ffill’, ‘backfill’/’bfill’, ‘nearest’}, optional. \\ndefault: exact matches only.\\npad / ffill: find the PREVIOUS index value if no exact match.\\nbackfill / bfill: use NEXT index value if no exact match\\nnearest: use the NEAREST index value if no exact match. Tied\\ndistances are broken by preferring the larger index value.\\n\\n'},\n",
       "         'limit': {'type': 'integer',\n",
       "          'description': 'int, optional. Maximum number of consecutive labels in target to match for\\ninexact matches.\\n'},\n",
       "         'tolerance': {'type': 'optional',\n",
       "          'description': 'optional. Maximum distance between original and new labels for inexact\\nmatches. The values of the index at the matching locations must\\nsatisfy the equation abs(index[indexer] - target) <= tolerance.\\nTolerance may be a scalar value, which applies the same tolerance\\nto all values, or list-like, which applies variable tolerance per\\nelement. List-like includes list, tuple, array, Series, and must be\\nthe same size as the index and its dtype must exactly match the\\nindex’s type.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.get_indexer_non_unique(target)',\n",
       "      'func_desc': 'Compute indexer and mask for new index given the current index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.get_indexer_non_unique.html#pandas.Index.get_indexer_non_unique',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.get_indexer_non_unique',\n",
       "       'full_function': 'Index.get_indexer_non_unique(target)',\n",
       "       'function_text': 'Compute indexer and mask for new index given the current index. The indexer should be then used as an input to ndarray.take to align the\\ncurrent data to the new index.',\n",
       "       'parameter_names_desc': [{'param_name': 'target',\n",
       "         'param_type': 'Index',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.Index.get_indexer_non_unique',\n",
       "       'descriptions': 'Compute indexer and mask for new index given the current index. The indexer should be then used as an input to ndarray.take to align the\\ncurrent data to the new index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'target': {'type': 'Index', 'description': 'Index. '}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.get_loc(key)',\n",
       "      'func_desc': 'Get integer location, slice or boolean mask for requested label.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.get_loc.html#pandas.Index.get_loc',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.get_loc',\n",
       "       'full_function': 'Index.get_loc(key)',\n",
       "       'function_text': 'Get integer location, slice or boolean mask for requested label.',\n",
       "       'parameter_names_desc': [{'param_name': 'key',\n",
       "         'param_type': 'label',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.Index.get_loc',\n",
       "       'descriptions': 'Get integer location, slice or boolean mask for requested label.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'key': {'type': 'label', 'description': 'label. '}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.isin(values[,\\xa0level])',\n",
       "      'func_desc': 'Return a boolean array where the index values are in values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.isin.html#pandas.Index.isin',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.isin',\n",
       "       'full_function': 'Index.isin(values, level=None)',\n",
       "       'function_text': 'Return a boolean array where the index values are in values. Compute boolean array of whether each index value is found in the\\npassed set of values. The length of the returned boolean array matches\\nthe length of the index.',\n",
       "       'parameter_names_desc': [{'param_name': 'values',\n",
       "         'param_type': 'set or list-like',\n",
       "         'param_desc': 'Sought values.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'str or int, optional',\n",
       "         'param_desc': 'Name or position of the index level to use (if the index is a\\nMultiIndex).\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.isin',\n",
       "       'descriptions': 'Return a boolean array where the index values are in values. Compute boolean array of whether each index value is found in the\\npassed set of values. The length of the returned boolean array matches\\nthe length of the index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'values': {'type': 'array',\n",
       "          'description': 'set or list-like. Sought values.\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'str or int, optional. Name or position of the index level to use (if the index is a\\nMultiIndex).\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.slice_locs([start,\\xa0end,\\xa0step])',\n",
       "      'func_desc': 'Compute slice locations for input labels.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.slice_locs.html#pandas.Index.slice_locs',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.slice_locs',\n",
       "       'full_function': 'Index.slice_locs(start=None, end=None, step=None)',\n",
       "       'function_text': 'Compute slice locations for input labels.',\n",
       "       'parameter_names_desc': [{'param_name': 'start',\n",
       "         'param_type': 'label, default None',\n",
       "         'param_desc': 'If None, defaults to the beginning.\\n'},\n",
       "        {'param_name': 'end',\n",
       "         'param_type': 'label, default None',\n",
       "         'param_desc': 'If None, defaults to the end.\\n'},\n",
       "        {'param_name': 'step',\n",
       "         'param_type': 'int, defaults None',\n",
       "         'param_desc': 'If None, defaults to 1.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.slice_locs',\n",
       "       'descriptions': 'Compute slice locations for input labels.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'start': {'type': 'label, default None',\n",
       "          'description': 'label, default None. If None, defaults to the beginning.\\n'},\n",
       "         'end': {'type': 'label, default None',\n",
       "          'description': 'label, default None. If None, defaults to the end.\\n'},\n",
       "         'step': {'type': 'integer',\n",
       "          'description': 'int, defaults None. If None, defaults to 1.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.is_monotonic_increasing',\n",
       "      'func_desc': 'Return a boolean if the values are equal or increasing.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.is_monotonic_increasing.html#pandas.Index.is_monotonic_increasing',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.is_monotonic_increasing',\n",
       "       'full_function': 'property Index.is_monotonic_increasing',\n",
       "       'function_text': 'Return a boolean if the values are equal or increasing.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.is_unique',\n",
       "      'func_desc': 'Return if the index has unique values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.is_unique.html#pandas.Index.is_unique',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.is_unique',\n",
       "       'full_function': 'Index.is_unique',\n",
       "       'function_text': 'Return if the index has unique values.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.hasnans',\n",
       "      'func_desc': 'Return True if there are any NaNs.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.hasnans.html#pandas.Index.hasnans',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.hasnans',\n",
       "       'full_function': 'Index.hasnans',\n",
       "       'function_text': 'Return True if there are any NaNs. Enables various performance speedups.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.inferred_type',\n",
       "      'func_desc': 'Return a string of the type inferred from the values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.inferred_type.html#pandas.Index.inferred_type',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.inferred_type',\n",
       "       'full_function': 'Index.inferred_type',\n",
       "       'function_text': 'Return a string of the type inferred from the values. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.name',\n",
       "      'func_desc': 'Return Index or MultiIndex name.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.name.html#pandas.Index.name',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.name',\n",
       "       'full_function': 'property Index.name',\n",
       "       'function_text': 'Return Index or MultiIndex name. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.nbytes',\n",
       "      'func_desc': 'Return the number of bytes in the underlying data.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.nbytes.html#pandas.Index.nbytes',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.nbytes',\n",
       "       'full_function': 'property Index.nbytes',\n",
       "       'function_text': 'Return the number of bytes in the underlying data. Examples For Series: For Index:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.size',\n",
       "      'func_desc': 'Return the number of elements in the underlying data.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.size.html#pandas.Index.size',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.size',\n",
       "       'full_function': 'property Index.size',\n",
       "       'function_text': 'Return the number of elements in the underlying data. Examples For Series: For Index:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.T',\n",
       "      'func_desc': 'Return the transpose, which is by definition self.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.T.html#pandas.Index.T',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.T',\n",
       "       'full_function': 'property Index.T',\n",
       "       'function_text': 'Return the transpose, which is by definition self. Examples For Series: For Index:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.any(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Return whether any element is Truthy.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.any.html#pandas.Index.any',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.any',\n",
       "       'full_function': 'Index.any(*args, **kwargs)',\n",
       "       'function_text': 'Return whether any element is Truthy.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.argmax([axis,\\xa0skipna])',\n",
       "      'func_desc': 'Return int position of the largest value in the Series.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.argmax.html#pandas.Index.argmax',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.argmax',\n",
       "       'full_function': 'Index.argmax(axis=None, skipna=True, *args, **kwargs)',\n",
       "       'function_text': 'Return int position of the largest value in the Series. If the maximum is achieved in multiple locations,\\nthe first row position is returned.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{None}',\n",
       "         'param_desc': 'Unused. Parameter needed for compatibility with DataFrame.\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values when showing the result.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.argmax',\n",
       "       'descriptions': 'Return int position of the largest value in the Series. If the maximum is achieved in multiple locations,\\nthe first row position is returned.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': '{None}',\n",
       "          'description': '{None}. Unused. Parameter needed for compatibility with DataFrame.\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values when showing the result.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.delete(loc)',\n",
       "      'func_desc': 'Make new Index with passed location(-s) deleted.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.delete.html#pandas.Index.delete',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.delete',\n",
       "       'full_function': 'Index.delete(loc)',\n",
       "       'function_text': 'Make new Index with passed location(-s) deleted.',\n",
       "       'parameter_names_desc': [{'param_name': 'loc',\n",
       "         'param_type': 'int or list of int',\n",
       "         'param_desc': 'Location of item(-s) which will be deleted.\\nUse a list of locations to delete more than one value at the same time.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.delete',\n",
       "       'descriptions': 'Make new Index with passed location(-s) deleted.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'loc': {'type': 'integer',\n",
       "          'description': 'int or list of int. Location of item(-s) which will be deleted.\\nUse a list of locations to delete more than one value at the same time.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.drop_duplicates(*[,\\xa0keep])',\n",
       "      'func_desc': 'Return Index with duplicate values removed.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.drop_duplicates.html#pandas.Index.drop_duplicates',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.drop_duplicates',\n",
       "       'full_function': \"Index.drop_duplicates(*, keep='first')\",\n",
       "       'function_text': 'Return Index with duplicate values removed.',\n",
       "       'parameter_names_desc': [{'param_name': 'keep',\n",
       "         'param_type': '{‘first’, ‘last’, False}, default ‘first’',\n",
       "         'param_desc': '\\n‘first’ : Drop duplicates except for the first occurrence.\\n‘last’ : Drop duplicates except for the last occurrence.\\nFalse : Drop all duplicates.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.drop_duplicates',\n",
       "       'descriptions': 'Return Index with duplicate values removed.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'keep': {'type': 'string',\n",
       "          'enum': ['first', ' last', ' False'],\n",
       "          'description': '{‘first’, ‘last’, False}, default ‘first’. \\n‘first’ : Drop duplicates except for the first occurrence.\\n‘last’ : Drop duplicates except for the last occurrence.\\nFalse : Drop all duplicates.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.equals(other)',\n",
       "      'func_desc': 'Determine if two Index object are equal.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.equals.html#pandas.Index.equals',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.equals',\n",
       "       'full_function': 'Index.equals(other)',\n",
       "       'function_text': 'Determine if two Index object are equal. The things that are being compared are: The elements inside the Index object. The order of the elements inside the Index object.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Any',\n",
       "         'param_desc': 'The other object to compare against.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.equals',\n",
       "       'descriptions': 'Determine if two Index object are equal. The things that are being compared are: The elements inside the Index object. The order of the elements inside the Index object.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Any',\n",
       "          'description': 'Any. The other object to compare against.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.identical(other)',\n",
       "      'func_desc': 'Similar to equals, but checks that object attributes and types are also equal.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.identical.html#pandas.Index.identical',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.identical',\n",
       "       'full_function': 'final Index.identical(other)',\n",
       "       'function_text': 'Similar to equals, but checks that object attributes and types are also equal.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.is_(other)',\n",
       "      'func_desc': 'More flexible, faster check like is but that works through views.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.is_.html#pandas.Index.is_',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.is_',\n",
       "       'full_function': 'final Index.is_(other)',\n",
       "       'function_text': 'More flexible, faster check like is but that works through views. Note: this is not the same as Index.identical(), which checks\\nthat metadata is also the same.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'object',\n",
       "         'param_desc': 'Other object to compare against.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.is_',\n",
       "       'descriptions': 'More flexible, faster check like is but that works through views. Note: this is not the same as Index.identical(), which checks\\nthat metadata is also the same.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'object',\n",
       "          'description': 'object. Other object to compare against.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.is_categorical()',\n",
       "      'func_desc': '(DEPRECATED) Check if the Index holds categorical data.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.is_categorical.html#pandas.Index.is_categorical',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.is_categorical',\n",
       "       'full_function': 'final Index.is_categorical()',\n",
       "       'function_text': 'Check if the Index holds categorical data. Deprecated since version 2.0.0: Use isinstance(index.dtype, pd.CategoricalDtype) instead.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.is_integer()',\n",
       "      'func_desc': '(DEPRECATED) Check if the Index only consists of integers.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.is_integer.html#pandas.Index.is_integer',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.is_integer',\n",
       "       'full_function': 'final Index.is_integer()',\n",
       "       'function_text': 'Check if the Index only consists of integers. Deprecated since version 2.0.0: Use pandas.api.types.is_integer_dtype instead.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.is_numeric()',\n",
       "      'func_desc': '(DEPRECATED) Check if the Index only consists of numeric data.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.is_numeric.html#pandas.Index.is_numeric',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.is_numeric',\n",
       "       'full_function': 'final Index.is_numeric()',\n",
       "       'function_text': 'Check if the Index only consists of numeric data. Deprecated since version 2.0.0: Use pandas.api.types.is_numeric_dtype instead.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.min([axis,\\xa0skipna])',\n",
       "      'func_desc': 'Return the minimum value of the Index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.min.html#pandas.Index.min',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.min',\n",
       "       'full_function': 'Index.min(axis=None, skipna=True, *args, **kwargs)',\n",
       "       'function_text': 'Return the minimum value of the Index.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{None}',\n",
       "         'param_desc': 'Dummy argument for consistency with Series.\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values when showing the result.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.min',\n",
       "       'descriptions': 'Return the minimum value of the Index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': '{None}',\n",
       "          'description': '{None}. Dummy argument for consistency with Series.\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values when showing the result.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.reindex(target[,\\xa0method,\\xa0level,\\xa0...])',\n",
       "      'func_desc': \"Create index with target's values.\",\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.reindex.html#pandas.Index.reindex',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.reindex',\n",
       "       'full_function': 'Index.reindex(target, method=None, level=None, limit=None, tolerance=None)',\n",
       "       'function_text': 'Create index with target’s values.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.repeat(repeats[,\\xa0axis])',\n",
       "      'func_desc': 'Repeat elements of a Index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.repeat.html#pandas.Index.repeat',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.repeat',\n",
       "       'full_function': 'Index.repeat(repeats, axis=None)',\n",
       "       'function_text': 'Repeat elements of a Index. Returns a new Index where each element of the current Index\\nis repeated consecutively a given number of times.',\n",
       "       'parameter_names_desc': [{'param_name': 'repeats',\n",
       "         'param_type': 'int or array of ints',\n",
       "         'param_desc': 'The number of repetitions for each element. This should be a\\nnon-negative integer. Repeating 0 times will return an empty\\nIndex.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': 'None',\n",
       "         'param_desc': 'Must be None. Has no effect but is accepted for compatibility\\nwith numpy.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.repeat',\n",
       "       'descriptions': 'Repeat elements of a Index. Returns a new Index where each element of the current Index\\nis repeated consecutively a given number of times.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'repeats': {'type': 'integer',\n",
       "          'description': 'int or array of ints. The number of repetitions for each element. This should be a\\nnon-negative integer. Repeating 0 times will return an empty\\nIndex.\\n'},\n",
       "         'axis': {'type': 'None',\n",
       "          'description': 'None. Must be None. Has no effect but is accepted for compatibility\\nwith numpy.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.take(indices[,\\xa0axis,\\xa0allow_fill,\\xa0...])',\n",
       "      'func_desc': 'Return a new Index of the values selected by the indices.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.take.html#pandas.Index.take',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.take',\n",
       "       'full_function': 'Index.take(indices, axis=0, allow_fill=True, fill_value=None, **kwargs)',\n",
       "       'function_text': 'Return a new Index of the values selected by the indices. For internal compatibility with numpy arrays.',\n",
       "       'parameter_names_desc': [{'param_name': 'indices',\n",
       "         'param_type': 'array-like',\n",
       "         'param_desc': 'Indices to be taken.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'The axis over which to select values, always 0.\\n'},\n",
       "        {'param_name': 'allow_fill',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'scalar, default None',\n",
       "         'param_desc': 'If allow_fill=True and fill_value is not None, indices specified by\\n-1 are regarded as NA. If Index doesn’t hold NA, raise ValueError.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.take',\n",
       "       'descriptions': 'Return a new Index of the values selected by the indices. For internal compatibility with numpy arrays.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'indices': {'type': 'array',\n",
       "          'description': 'array-like. Indices to be taken.\\n'},\n",
       "         'axis': {'type': 'integer',\n",
       "          'description': 'int, optional. The axis over which to select values, always 0.\\n'},\n",
       "         'allow_fill': {'type': 'boolean',\n",
       "          'description': 'bool, default True. '},\n",
       "         'fill_value': {'type': 'scalar, default None',\n",
       "          'description': 'scalar, default None. If allow_fill=True and fill_value is not None, indices specified by\\n-1 are regarded as NA. If Index doesn’t hold NA, raise ValueError.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.unique([level])',\n",
       "      'func_desc': 'Return unique values in the index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.unique.html#pandas.Index.unique',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.unique',\n",
       "       'full_function': 'Index.unique(level=None)',\n",
       "       'function_text': 'Return unique values in the index. Unique values are returned in order of appearance, this does NOT sort.',\n",
       "       'parameter_names_desc': [{'param_name': 'level',\n",
       "         'param_type': 'int or hashable, optional',\n",
       "         'param_desc': 'Only return values from specified level (for MultiIndex).\\nIf int, gets the level by integer position, else by level name.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.unique',\n",
       "       'descriptions': 'Return unique values in the index. Unique values are returned in order of appearance, this does NOT sort.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'level': {'type': 'integer',\n",
       "          'description': 'int or hashable, optional. Only return values from specified level (for MultiIndex).\\nIf int, gets the level by integer position, else by level name.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.value_counts([normalize,\\xa0sort,\\xa0...])',\n",
       "      'func_desc': 'Return a Series containing counts of unique values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.value_counts.html#pandas.Index.value_counts',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.value_counts',\n",
       "       'full_function': 'Index.value_counts(normalize=False, sort=True, ascending=False, bins=None, dropna=True)',\n",
       "       'function_text': 'Return a Series containing counts of unique values. The resulting object will be in descending order so that the\\nfirst element is the most frequently-occurring element.\\nExcludes NA values by default.',\n",
       "       'parameter_names_desc': [{'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True then the object returned will contain the relative\\nfrequencies of the unique values.\\n'},\n",
       "        {'param_name': 'sort',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Sort by frequencies when True. Preserve the order of the data when False.\\n'},\n",
       "        {'param_name': 'ascending',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Sort in ascending order.\\n'},\n",
       "        {'param_name': 'bins',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Rather than count values, group them into half-open bins,\\na convenience for pd.cut, only works with numeric data.\\n'},\n",
       "        {'param_name': 'dropna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Don’t include counts of NaN.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.value_counts',\n",
       "       'descriptions': 'Return a Series containing counts of unique values. The resulting object will be in descending order so that the\\nfirst element is the most frequently-occurring element.\\nExcludes NA values by default.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True then the object returned will contain the relative\\nfrequencies of the unique values.\\n'},\n",
       "         'sort': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Sort by frequencies when True. Preserve the order of the data when False.\\n'},\n",
       "         'ascending': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Sort in ascending order.\\n'},\n",
       "         'bins': {'type': 'integer',\n",
       "          'description': 'int, optional. Rather than count values, group them into half-open bins,\\na convenience for pd.cut, only works with numeric data.\\n'},\n",
       "         'dropna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Don’t include counts of NaN.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.droplevel([level])',\n",
       "      'func_desc': 'Return index with requested level(s) removed.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.droplevel.html#pandas.Index.droplevel',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.droplevel',\n",
       "       'full_function': 'final Index.droplevel(level=0)',\n",
       "       'function_text': 'Return index with requested level(s) removed. If resulting index has only 1 level left, the result will be\\nof Index type, not MultiIndex. The original index is not modified inplace.',\n",
       "       'parameter_names_desc': [{'param_name': 'level',\n",
       "         'param_type': 'int, str, or list-like, default 0',\n",
       "         'param_desc': 'If a string is given, must be the name of a level\\nIf list-like, elements must be names or indexes of levels.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.droplevel',\n",
       "       'descriptions': 'Return index with requested level(s) removed. If resulting index has only 1 level left, the result will be\\nof Index type, not MultiIndex. The original index is not modified inplace.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'level': {'type': 'integer',\n",
       "          'description': 'int, str, or list-like, default 0. If a string is given, must be the name of a level\\nIf list-like, elements must be names or indexes of levels.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.dropna([how])',\n",
       "      'func_desc': 'Return Index without NA/NaN values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.dropna.html#pandas.Index.dropna',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.dropna',\n",
       "       'full_function': \"Index.dropna(how='any')\",\n",
       "       'function_text': 'Return Index without NA/NaN values.',\n",
       "       'parameter_names_desc': [{'param_name': 'how',\n",
       "         'param_type': '{‘any’, ‘all’}, default ‘any’',\n",
       "         'param_desc': 'If the Index is a MultiIndex, drop the value when any or all levels\\nare NaN.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.dropna',\n",
       "       'descriptions': 'Return Index without NA/NaN values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'how': {'type': 'string',\n",
       "          'enum': ['any', ' all'],\n",
       "          'description': '{‘any’, ‘all’}, default ‘any’. If the Index is a MultiIndex, drop the value when any or all levels\\nare NaN.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.notna()',\n",
       "      'func_desc': 'Detect existing (non-missing) values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.notna.html#pandas.Index.notna',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.notna',\n",
       "       'full_function': 'final Index.notna()',\n",
       "       'function_text': \"Detect existing (non-missing) values. Return a boolean same-sized object indicating if the values are not NA.\\nNon-missing values get mapped to True. Characters such as empty\\nstrings '' or numpy.inf are not considered NA values.\\nNA values, such as None or numpy.NaN, get mapped to False\\nvalues.\",\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.item()',\n",
       "      'func_desc': 'Return the first element of the underlying data as a Python scalar.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.item.html#pandas.Index.item',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.item',\n",
       "       'full_function': 'Index.item()',\n",
       "       'function_text': 'Return the first element of the underlying data as a Python scalar.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.ravel([order])',\n",
       "      'func_desc': 'Return a view on self.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.ravel.html#pandas.Index.ravel',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.ravel',\n",
       "       'full_function': \"final Index.ravel(order='C')\",\n",
       "       'function_text': 'Return a view on self.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.to_series([index,\\xa0name])',\n",
       "      'func_desc': 'Create a Series with both index and values equal to the index keys.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.to_series.html#pandas.Index.to_series',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.to_series',\n",
       "       'full_function': 'final Index.to_series(index=None, name=None)',\n",
       "       'function_text': 'Create a Series with both index and values equal to the index keys. Useful with map for returning an indexer based on an index.',\n",
       "       'parameter_names_desc': [{'param_name': 'index',\n",
       "         'param_type': 'Index, optional',\n",
       "         'param_desc': 'Index of resulting Series. If None, defaults to original index.\\n'},\n",
       "        {'param_name': 'name',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Name of resulting Series. If None, defaults to name of original\\nindex.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.to_series',\n",
       "       'descriptions': 'Create a Series with both index and values equal to the index keys. Useful with map for returning an indexer based on an index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'index': {'type': 'Index, optional',\n",
       "          'description': 'Index, optional. Index of resulting Series. If None, defaults to original index.\\n'},\n",
       "         'name': {'type': 'string',\n",
       "          'description': 'str, optional. Name of resulting Series. If None, defaults to name of original\\nindex.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.view([cls])',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.view.html#pandas.Index.view',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.view',\n",
       "       'full_function': 'Index.view(cls=None)',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.searchsorted(value[,\\xa0side,\\xa0sorter])',\n",
       "      'func_desc': 'Find indices where elements should be inserted to maintain order.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.searchsorted.html#pandas.Index.searchsorted',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.searchsorted',\n",
       "       'full_function': \"Index.searchsorted(value, side='left', sorter=None)\",\n",
       "       'function_text': 'Find indices where elements should be inserted to maintain order. Find the indices into a sorted Index self such that, if the\\ncorresponding elements in value were inserted before the indices,\\nthe order of self would be preserved. Note The Index must be monotonically sorted, otherwise\\nwrong locations will likely be returned. Pandas does not\\ncheck this for you.',\n",
       "       'parameter_names_desc': [{'param_name': 'value',\n",
       "         'param_type': 'array-like or scalar',\n",
       "         'param_desc': 'Values to insert into self.\\n'},\n",
       "        {'param_name': 'side',\n",
       "         'param_type': '{‘left’, ‘right’}, optional',\n",
       "         'param_desc': 'If ‘left’, the index of the first suitable location found is given.\\nIf ‘right’, return the last such index. If there is no suitable\\nindex, return either 0 or N (where N is the length of self).\\n'},\n",
       "        {'param_name': 'sorter',\n",
       "         'param_type': '1-D array-like, optional',\n",
       "         'param_desc': 'Optional array of integer indices that sort self into ascending\\norder. They are typically the result of np.argsort.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.searchsorted',\n",
       "       'descriptions': 'Find indices where elements should be inserted to maintain order. Find the indices into a sorted Index self such that, if the\\ncorresponding elements in value were inserted before the indices,\\nthe order of self would be preserved. Note The Index must be monotonically sorted, otherwise\\nwrong locations will likely be returned. Pandas does not\\ncheck this for you.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'value': {'type': 'array',\n",
       "          'description': 'array-like or scalar. Values to insert into self.\\n'},\n",
       "         'side': {'type': 'string',\n",
       "          'enum': ['left', ' right'],\n",
       "          'description': '{‘left’, ‘right’}, optional. If ‘left’, the index of the first suitable location found is given.\\nIf ‘right’, return the last such index. If there is no suitable\\nindex, return either 0 or N (where N is the length of self).\\n'},\n",
       "         'sorter': {'type': 'array',\n",
       "          'description': '1-D array-like, optional. Optional array of integer indices that sort self into ascending\\norder. They are typically the result of np.argsort.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.join(other,\\xa0*[,\\xa0how,\\xa0level,\\xa0...])',\n",
       "      'func_desc': 'Compute join_index and indexers to conform data structures to the new index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.join.html#pandas.Index.join',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.join',\n",
       "       'full_function': \"final Index.join(other, *, how='left', level=None, return_indexers=False, sort=False)\",\n",
       "       'function_text': 'Compute join_index and indexers to conform data structures to the new index.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Index',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'how',\n",
       "         'param_type': '{‘left’, ‘right’, ‘inner’, ‘outer’}',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or level name, default None',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'return_indexers',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'sort',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Sort the join keys lexicographically in the result Index. If False,\\nthe order of the join keys depends on the join type (how keyword).\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.join',\n",
       "       'descriptions': 'Compute join_index and indexers to conform data structures to the new index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Index', 'description': 'Index. '},\n",
       "         'how': {'type': 'string',\n",
       "          'enum': ['left', ' right', ' inner', ' outer'],\n",
       "          'description': '{‘left’, ‘right’, ‘inner’, ‘outer’}. '},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or level name, default None. '},\n",
       "         'return_indexers': {'type': 'boolean',\n",
       "          'description': 'bool, default False. '},\n",
       "         'sort': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Sort the join keys lexicographically in the result Index. If False,\\nthe order of the join keys depends on the join type (how keyword).\\n'}},\n",
       "        'required': ['other']}}},\n",
       "     {'func_name': 'Index.union(other[,\\xa0sort])',\n",
       "      'func_desc': 'Form the union of two Index objects.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.union.html#pandas.Index.union',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.union',\n",
       "       'full_function': 'final Index.union(other, sort=None)',\n",
       "       'function_text': 'Form the union of two Index objects. If the Index objects are incompatible, both Index objects will be\\ncast to dtype(‘object’) first.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Index or array-like',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'sort',\n",
       "         'param_type': 'bool or None, default None',\n",
       "         'param_desc': 'Whether to sort the resulting Index.\\n\\nNone : Sort the result, except when\\n\\nself and other are equal.\\nself or other has length 0.\\nSome values in self or other cannot be compared.\\nA RuntimeWarning is issued in this case.\\n\\n\\nFalse : do not sort the result.\\nTrue : Sort the result (which may raise TypeError).\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.union',\n",
       "       'descriptions': 'Form the union of two Index objects. If the Index objects are incompatible, both Index objects will be\\ncast to dtype(‘object’) first.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'array',\n",
       "          'description': 'Index or array-like. '},\n",
       "         'sort': {'type': 'boolean',\n",
       "          'description': 'bool or None, default None. Whether to sort the resulting Index.\\n\\nNone : Sort the result, except when\\n\\nself and other are equal.\\nself or other has length 0.\\nSome values in self or other cannot be compared.\\nA RuntimeWarning is issued in this case.\\n\\n\\nFalse : do not sort the result.\\nTrue : Sort the result (which may raise TypeError).\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.symmetric_difference(other[,\\xa0...])',\n",
       "      'func_desc': 'Compute the symmetric difference of two Index objects.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.symmetric_difference.html#pandas.Index.symmetric_difference',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.symmetric_difference',\n",
       "       'full_function': 'Index.symmetric_difference(other, result_name=None, sort=None)',\n",
       "       'function_text': 'Compute the symmetric difference of two Index objects.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Index or array-like',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'result_name', 'param_type': 'str', 'param_desc': ''},\n",
       "        {'param_name': 'sort',\n",
       "         'param_type': 'bool or None, default None',\n",
       "         'param_desc': 'Whether to sort the resulting index. By default, the\\nvalues are attempted to be sorted, but any TypeError from\\nincomparable elements is caught by pandas.\\n\\nNone : Attempt to sort the result, but catch any TypeErrors\\nfrom comparing incomparable elements.\\nFalse : Do not sort the result.\\nTrue : Sort the result (which may raise TypeError).\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.symmetric_difference',\n",
       "       'descriptions': 'Compute the symmetric difference of two Index objects.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'array',\n",
       "          'description': 'Index or array-like. '},\n",
       "         'result_name': {'type': 'string', 'description': 'str. '},\n",
       "         'sort': {'type': 'boolean',\n",
       "          'description': 'bool or None, default None. Whether to sort the resulting index. By default, the\\nvalues are attempted to be sorted, but any TypeError from\\nincomparable elements is caught by pandas.\\n\\nNone : Attempt to sort the result, but catch any TypeErrors\\nfrom comparing incomparable elements.\\nFalse : Do not sort the result.\\nTrue : Sort the result (which may raise TypeError).\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.asof_locs(where,\\xa0mask)',\n",
       "      'func_desc': 'Return the locations (indices) of labels in the index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.asof_locs.html#pandas.Index.asof_locs',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.asof_locs',\n",
       "       'full_function': 'Index.asof_locs(where, mask)',\n",
       "       'function_text': 'Return the locations (indices) of labels in the index. As in the pandas.Index.asof(), if the label (a particular entry in\\nwhere) is not in the index, the latest index label up to the\\npassed label is chosen and its index returned. If all of the labels in the index are later than a label in where,\\n-1 is returned. mask is used to ignore NA values in the index during calculation.',\n",
       "       'parameter_names_desc': [{'param_name': 'where',\n",
       "         'param_type': 'Index',\n",
       "         'param_desc': 'An Index consisting of an array of timestamps.\\n'},\n",
       "        {'param_name': 'mask',\n",
       "         'param_type': 'np.ndarray[bool]',\n",
       "         'param_desc': 'Array of booleans denoting where values in the original\\ndata are not NA.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.asof_locs',\n",
       "       'descriptions': 'Return the locations (indices) of labels in the index. As in the pandas.Index.asof(), if the label (a particular entry in\\nwhere) is not in the index, the latest index label up to the\\npassed label is chosen and its index returned. If all of the labels in the index are later than a label in where,\\n-1 is returned. mask is used to ignore NA values in the index during calculation.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'where': {'type': 'Index',\n",
       "          'description': 'Index. An Index consisting of an array of timestamps.\\n'},\n",
       "         'mask': {'type': 'boolean',\n",
       "          'description': 'np.ndarray[bool]. Array of booleans denoting where values in the original\\ndata are not NA.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.get_indexer_for(target)',\n",
       "      'func_desc': 'Guaranteed return of an indexer even when non-unique.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.get_indexer_for.html#pandas.Index.get_indexer_for',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.get_indexer_for',\n",
       "       'full_function': 'final Index.get_indexer_for(target)',\n",
       "       'function_text': 'Guaranteed return of an indexer even when non-unique. This dispatches to get_indexer or get_indexer_non_unique\\nas appropriate.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Index.get_level_values(level)',\n",
       "      'func_desc': 'Return an Index of values for requested level.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.get_level_values.html#pandas.Index.get_level_values',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.get_level_values',\n",
       "       'full_function': 'Index.get_level_values(level)',\n",
       "       'function_text': 'Return an Index of values for requested level. This is primarily useful to get an individual level of values from a\\nMultiIndex, but is provided on Index as well for compatibility.',\n",
       "       'parameter_names_desc': [{'param_name': 'level',\n",
       "         'param_type': 'int or str',\n",
       "         'param_desc': 'It is either the integer position or the name of the level.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.get_level_values',\n",
       "       'descriptions': 'Return an Index of values for requested level. This is primarily useful to get an individual level of values from a\\nMultiIndex, but is provided on Index as well for compatibility.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'level': {'type': 'integer',\n",
       "          'description': 'int or str. It is either the integer position or the name of the level.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.get_slice_bound(label,\\xa0side)',\n",
       "      'func_desc': 'Calculate slice bound that corresponds to given label.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.get_slice_bound.html#pandas.Index.get_slice_bound',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.get_slice_bound',\n",
       "       'full_function': 'Index.get_slice_bound(label, side)',\n",
       "       'function_text': \"Calculate slice bound that corresponds to given label. Returns leftmost (one-past-the-rightmost if side=='right') position\\nof given label.\",\n",
       "       'parameter_names_desc': [{'param_name': 'label',\n",
       "         'param_type': 'object',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'side',\n",
       "         'param_type': '{‘left’, ‘right’}',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.Index.get_slice_bound',\n",
       "       'descriptions': \"Calculate slice bound that corresponds to given label. Returns leftmost (one-past-the-rightmost if side=='right') position\\nof given label.\",\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'label': {'type': 'object', 'description': 'object. '},\n",
       "         'side': {'type': 'string',\n",
       "          'enum': ['left', ' right'],\n",
       "          'description': '{‘left’, ‘right’}. '}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Index.slice_indexer([start,\\xa0end,\\xa0step])',\n",
       "      'func_desc': 'Compute the slice indexer for input labels and step.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Index.slice_indexer.html#pandas.Index.slice_indexer',\n",
       "      'function_definitions': {'function_name': 'pandas.Index.slice_indexer',\n",
       "       'full_function': 'Index.slice_indexer(start=None, end=None, step=None)',\n",
       "       'function_text': 'Compute the slice indexer for input labels and step. Index needs to be ordered and unique.',\n",
       "       'parameter_names_desc': [{'param_name': 'KeyError',\n",
       "         'param_type': 'If key does not exist, or key is not unique and index is',\n",
       "         'param_desc': 'not ordered.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Index.slice_indexer',\n",
       "       'descriptions': 'Compute the slice indexer for input labels and step. Index needs to be ordered and unique.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'KeyError': {'type': 'If key does not exist, or key is not unique and index is',\n",
       "          'description': 'If key does not exist, or key is not unique and index is. not ordered.\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Numeric Index': [{'func_name': 'RangeIndex([start,\\xa0stop,\\xa0step,\\xa0dtype,\\xa0copy,\\xa0...])',\n",
       "      'func_desc': 'Immutable Index implementing a monotonic integer range.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.RangeIndex.html#pandas.RangeIndex',\n",
       "      'function_definitions': {'function_name': 'pandas.RangeIndex',\n",
       "       'full_function': 'class pandas.RangeIndex(start=None, stop=None, step=None, dtype=None, copy=False, name=None)',\n",
       "       'function_text': 'Immutable Index implementing a monotonic integer range. RangeIndex is a memory-saving special case of an Index limited to representing\\nmonotonic ranges with a 64-bit dtype. Using RangeIndex may in some instances\\nimprove computing speed. This is the default index type used\\nby DataFrame and Series when no explicit index is provided by the user.',\n",
       "       'parameter_names_desc': [{'param_name': 'start',\n",
       "         'param_type': 'int (default: 0), range, or other RangeIndex instance',\n",
       "         'param_desc': 'If int and “stop” is not given, interpreted as “stop” instead.\\n'},\n",
       "        {'param_name': 'stop',\n",
       "         'param_type': 'int (default: 0)',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'step',\n",
       "         'param_type': 'int (default: 1)',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'dtype',\n",
       "         'param_type': 'np.int64',\n",
       "         'param_desc': 'Unused, accepted for homogeneity with other index types.\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Unused, accepted for homogeneity with other index types.\\n'},\n",
       "        {'param_name': 'name',\n",
       "         'param_type': 'object, optional',\n",
       "         'param_desc': 'Name to be stored in the index.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.RangeIndex',\n",
       "       'descriptions': 'Immutable Index implementing a monotonic integer range. RangeIndex is a memory-saving special case of an Index limited to representing\\nmonotonic ranges with a 64-bit dtype. Using RangeIndex may in some instances\\nimprove computing speed. This is the default index type used\\nby DataFrame and Series when no explicit index is provided by the user.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'start': {'type': 'integer',\n",
       "          'description': 'int (default: 0), range, or other RangeIndex instance. If int and “stop” is not given, interpreted as “stop” instead.\\n'},\n",
       "         'stop': {'type': 'integer', 'description': 'int (default: 0). '},\n",
       "         'step': {'type': 'integer', 'description': 'int (default: 1). '},\n",
       "         'dtype': {'type': 'integer',\n",
       "          'description': 'np.int64. Unused, accepted for homogeneity with other index types.\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Unused, accepted for homogeneity with other index types.\\n'},\n",
       "         'name': {'type': 'object',\n",
       "          'description': 'object, optional. Name to be stored in the index.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'RangeIndex.start',\n",
       "      'func_desc': 'The value of the start parameter (0 if this was not supplied).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.RangeIndex.start.html#pandas.RangeIndex.start',\n",
       "      'function_definitions': {'function_name': 'pandas.RangeIndex.start',\n",
       "       'full_function': 'property RangeIndex.start',\n",
       "       'function_text': 'The value of the start parameter (0 if this was not supplied). Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'RangeIndex.step',\n",
       "      'func_desc': 'The value of the step parameter (1 if this was not supplied).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.RangeIndex.step.html#pandas.RangeIndex.step',\n",
       "      'function_definitions': {'function_name': 'pandas.RangeIndex.step',\n",
       "       'full_function': 'property RangeIndex.step',\n",
       "       'function_text': 'The value of the step parameter (1 if this was not supplied). Examples Even if pandas.RangeIndex is empty, step is still 1 if\\nnot supplied.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'RangeIndex.stop',\n",
       "      'func_desc': 'The value of the stop parameter.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.RangeIndex.stop.html#pandas.RangeIndex.stop',\n",
       "      'function_definitions': {'function_name': 'pandas.RangeIndex.stop',\n",
       "       'full_function': 'property RangeIndex.stop',\n",
       "       'function_text': 'The value of the stop parameter. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'RangeIndex.from_range(data[,\\xa0name,\\xa0dtype])',\n",
       "      'func_desc': 'Create pandas.RangeIndex from a range object.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.RangeIndex.from_range.html#pandas.RangeIndex.from_range',\n",
       "      'function_definitions': {'function_name': 'pandas.RangeIndex.from_range',\n",
       "       'full_function': 'classmethod RangeIndex.from_range(data, name=None, dtype=None)',\n",
       "       'function_text': 'Create pandas.RangeIndex from a range object.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'CategoricalIndex': [{'func_name': 'CategoricalIndex([data,\\xa0categories,\\xa0...])',\n",
       "      'func_desc': 'Index based on an underlying Categorical.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.html#pandas.CategoricalIndex',\n",
       "      'function_definitions': {'function_name': 'pandas.CategoricalIndex',\n",
       "       'full_function': 'class pandas.CategoricalIndex(data=None, categories=None, ordered=None, dtype=None, copy=False, name=None)',\n",
       "       'function_text': 'Index based on an underlying Categorical. CategoricalIndex, like Categorical, can only take on a limited,\\nand usually fixed, number of possible values (categories). Also,\\nlike Categorical, it might have an order, but numerical operations\\n(additions, divisions, …) are not possible.',\n",
       "       'parameter_names_desc': [{'param_name': 'data',\n",
       "         'param_type': 'array-like (1-dimensional)',\n",
       "         'param_desc': 'The values of the categorical. If categories are given, values not in\\ncategories will be replaced with NaN.\\n'},\n",
       "        {'param_name': 'categories',\n",
       "         'param_type': 'index-like, optional',\n",
       "         'param_desc': 'The categories for the categorical. Items need to be unique.\\nIf the categories are not given here (and also not in dtype), they\\nwill be inferred from the data.\\n'},\n",
       "        {'param_name': 'ordered',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'Whether or not this categorical is treated as an ordered\\ncategorical. If not given here or in dtype, the resulting\\ncategorical will be unordered.\\n'},\n",
       "        {'param_name': 'dtype',\n",
       "         'param_type': 'CategoricalDtype or “category”, optional',\n",
       "         'param_desc': 'If CategoricalDtype, cannot be used together with\\ncategories or ordered.\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Make a copy of input ndarray.\\n'},\n",
       "        {'param_name': 'name',\n",
       "         'param_type': 'object, optional',\n",
       "         'param_desc': 'Name to be stored in the index.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.CategoricalIndex',\n",
       "       'descriptions': 'Index based on an underlying Categorical. CategoricalIndex, like Categorical, can only take on a limited,\\nand usually fixed, number of possible values (categories). Also,\\nlike Categorical, it might have an order, but numerical operations\\n(additions, divisions, …) are not possible.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'data': {'type': 'array',\n",
       "          'description': 'array-like (1-dimensional). The values of the categorical. If categories are given, values not in\\ncategories will be replaced with NaN.\\n'},\n",
       "         'categories': {'type': 'index-like, optional',\n",
       "          'description': 'index-like, optional. The categories for the categorical. Items need to be unique.\\nIf the categories are not given here (and also not in dtype), they\\nwill be inferred from the data.\\n'},\n",
       "         'ordered': {'type': 'boolean',\n",
       "          'description': 'bool, optional. Whether or not this categorical is treated as an ordered\\ncategorical. If not given here or in dtype, the resulting\\ncategorical will be unordered.\\n'},\n",
       "         'dtype': {'type': 'CategoricalDtype or “category”, optional',\n",
       "          'description': 'CategoricalDtype or “category”, optional. If CategoricalDtype, cannot be used together with\\ncategories or ordered.\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Make a copy of input ndarray.\\n'},\n",
       "         'name': {'type': 'object',\n",
       "          'description': 'object, optional. Name to be stored in the index.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'CategoricalIndex.codes',\n",
       "      'func_desc': 'The category codes of this categorical index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.codes.html#pandas.CategoricalIndex.codes',\n",
       "      'function_definitions': {'function_name': 'pandas.CategoricalIndex.codes',\n",
       "       'full_function': 'property CategoricalIndex.codes',\n",
       "       'function_text': 'The category codes of this categorical index. Codes are an array of integers which are the positions of the actual\\nvalues in the categories array. There is no setter, use the other categorical methods and the normal item\\nsetter to change values in the categorical.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CategoricalIndex.ordered',\n",
       "      'func_desc': 'Whether the categories have an ordered relationship.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.ordered.html#pandas.CategoricalIndex.ordered',\n",
       "      'function_definitions': {'function_name': 'pandas.CategoricalIndex.ordered',\n",
       "       'full_function': 'property CategoricalIndex.ordered',\n",
       "       'function_text': 'Whether the categories have an ordered relationship. Examples For pandas.Series: For pandas.Categorical: For pandas.CategoricalIndex:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CategoricalIndex.reorder_categories(*args,\\xa0...)',\n",
       "      'func_desc': 'Reorder categories as specified in new_categories.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.reorder_categories.html#pandas.CategoricalIndex.reorder_categories',\n",
       "      'function_definitions': {'function_name': 'pandas.CategoricalIndex.reorder_categories',\n",
       "       'full_function': 'CategoricalIndex.reorder_categories(*args, **kwargs)',\n",
       "       'function_text': 'Reorder categories as specified in new_categories. new_categories need to include all old categories and no new category\\nitems.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CategoricalIndex.remove_categories(*args,\\xa0...)',\n",
       "      'func_desc': 'Remove the specified categories.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.remove_categories.html#pandas.CategoricalIndex.remove_categories',\n",
       "      'function_definitions': {'function_name': 'pandas.CategoricalIndex.remove_categories',\n",
       "       'full_function': 'CategoricalIndex.remove_categories(*args, **kwargs)',\n",
       "       'function_text': 'Remove the specified categories. removals must be included in the old categories. Values which were in\\nthe removed categories will be set to NaN',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CategoricalIndex.set_categories(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Set the categories to the specified new categories.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.set_categories.html#pandas.CategoricalIndex.set_categories',\n",
       "      'function_definitions': {'function_name': 'pandas.CategoricalIndex.set_categories',\n",
       "       'full_function': 'CategoricalIndex.set_categories(*args, **kwargs)',\n",
       "       'function_text': 'Set the categories to the specified new categories. new_categories can include new categories (which will result in\\nunused categories) or remove old categories (which results in values\\nset to NaN). If rename=True, the categories will simply be renamed\\n(less or more items than in old categories will result in values set to\\nNaN or in unused categories respectively). This method can be used to perform more than one action of adding,\\nremoving, and reordering simultaneously and is therefore faster than\\nperforming the individual steps via the more specialised methods. On the other hand this methods does not do checks (e.g., whether the\\nold categories are included in the new categories on a reorder), which\\ncan result in surprising changes, for example when using special string\\ndtypes, which does not considers a S1 string equal to a single char\\npython string.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CategoricalIndex.as_unordered(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Set the Categorical to be unordered.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.as_unordered.html#pandas.CategoricalIndex.as_unordered',\n",
       "      'function_definitions': {'function_name': 'pandas.CategoricalIndex.as_unordered',\n",
       "       'full_function': 'CategoricalIndex.as_unordered(*args, **kwargs)',\n",
       "       'function_text': 'Set the Categorical to be unordered.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CategoricalIndex.map(mapper[,\\xa0na_action])',\n",
       "      'func_desc': 'Map values using input an input mapping or function.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.map.html#pandas.CategoricalIndex.map',\n",
       "      'function_definitions': {'function_name': 'pandas.CategoricalIndex.map',\n",
       "       'full_function': 'CategoricalIndex.map(mapper, na_action=None)',\n",
       "       'function_text': 'Map values using input an input mapping or function. Maps the values (their categories, not the codes) of the index to new\\ncategories. If the mapping correspondence is one-to-one the result is a\\nCategoricalIndex which has the same order property as\\nthe original, otherwise an Index is returned. If a dict or Series is used any unmapped category is\\nmapped to NaN. Note that if this happens an Index\\nwill be returned.',\n",
       "       'parameter_names_desc': [{'param_name': 'mapper',\n",
       "         'param_type': 'function, dict, or Series',\n",
       "         'param_desc': 'Mapping correspondence.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.CategoricalIndex.map',\n",
       "       'descriptions': 'Map values using input an input mapping or function. Maps the values (their categories, not the codes) of the index to new\\ncategories. If the mapping correspondence is one-to-one the result is a\\nCategoricalIndex which has the same order property as\\nthe original, otherwise an Index is returned. If a dict or Series is used any unmapped category is\\nmapped to NaN. Note that if this happens an Index\\nwill be returned.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'mapper': {'type': 'function, dict, or Series',\n",
       "          'description': 'function, dict, or Series. Mapping correspondence.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'CategoricalIndex.categories',\n",
       "      'func_desc': 'The categories of this categorical.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.categories.html#pandas.CategoricalIndex.categories',\n",
       "      'function_definitions': {'function_name': 'pandas.CategoricalIndex.categories',\n",
       "       'full_function': 'property CategoricalIndex.categories',\n",
       "       'function_text': 'The categories of this categorical. Setting assigns new values to each category (effectively a rename of\\neach individual category). The assigned value has to be a list-like object. All items must be\\nunique and the number of items in the new categories must be the same\\nas the number of items in the old categories.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CategoricalIndex.rename_categories(*args,\\xa0...)',\n",
       "      'func_desc': 'Rename categories.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.rename_categories.html#pandas.CategoricalIndex.rename_categories',\n",
       "      'function_definitions': {'function_name': 'pandas.CategoricalIndex.rename_categories',\n",
       "       'full_function': 'CategoricalIndex.rename_categories(*args, **kwargs)',\n",
       "       'function_text': 'Rename categories.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CategoricalIndex.add_categories(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Add new categories.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.add_categories.html#pandas.CategoricalIndex.add_categories',\n",
       "      'function_definitions': {'function_name': 'pandas.CategoricalIndex.add_categories',\n",
       "       'full_function': 'CategoricalIndex.add_categories(*args, **kwargs)',\n",
       "       'function_text': 'Add new categories. new_categories will be included at the last/highest place in the\\ncategories and will be unused directly after this call.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CategoricalIndex.remove_unused_categories(...)',\n",
       "      'func_desc': 'Remove categories which are not used.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.remove_unused_categories.html#pandas.CategoricalIndex.remove_unused_categories',\n",
       "      'function_definitions': {'function_name': 'pandas.CategoricalIndex.remove_unused_categories',\n",
       "       'full_function': 'CategoricalIndex.remove_unused_categories(*args, **kwargs)',\n",
       "       'function_text': 'Remove categories which are not used.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CategoricalIndex.as_ordered(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Set the Categorical to be ordered.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.as_ordered.html#pandas.CategoricalIndex.as_ordered',\n",
       "      'function_definitions': {'function_name': 'pandas.CategoricalIndex.as_ordered',\n",
       "       'full_function': 'CategoricalIndex.as_ordered(*args, **kwargs)',\n",
       "       'function_text': 'Set the Categorical to be ordered.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CategoricalIndex.equals(other)',\n",
       "      'func_desc': 'Determine if two CategoricalIndex objects contain the same elements.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.equals.html#pandas.CategoricalIndex.equals',\n",
       "      'function_definitions': {'function_name': 'pandas.CategoricalIndex.equals',\n",
       "       'full_function': 'CategoricalIndex.equals(other)',\n",
       "       'function_text': 'Determine if two CategoricalIndex objects contain the same elements.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'IntervalIndex': [{'func_name': 'IntervalIndex(data[,\\xa0closed,\\xa0dtype,\\xa0copy,\\xa0...])',\n",
       "      'func_desc': 'Immutable index of intervals that are closed on the same side.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.html#pandas.IntervalIndex',\n",
       "      'function_definitions': {'function_name': 'pandas.IntervalIndex',\n",
       "       'full_function': 'class pandas.IntervalIndex(data, closed=None, dtype=None, copy=False, name=None, verify_integrity=True)',\n",
       "       'function_text': 'Immutable index of intervals that are closed on the same side.',\n",
       "       'parameter_names_desc': [{'param_name': 'data',\n",
       "         'param_type': 'array-like (1-dimensional)',\n",
       "         'param_desc': 'Array-like (ndarray, DateTimeArray, TimeDeltaArray) containing\\nInterval objects from which to build the IntervalIndex.\\n'},\n",
       "        {'param_name': 'closed',\n",
       "         'param_type': '{‘left’, ‘right’, ‘both’, ‘neither’}, default ‘right’',\n",
       "         'param_desc': 'Whether the intervals are closed on the left-side, right-side, both or\\nneither.\\n'},\n",
       "        {'param_name': 'dtype',\n",
       "         'param_type': 'dtype or None, default None',\n",
       "         'param_desc': 'If None, dtype will be inferred.\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Copy the input data.\\n'},\n",
       "        {'param_name': 'name',\n",
       "         'param_type': 'object, optional',\n",
       "         'param_desc': 'Name to be stored in the index.\\n'},\n",
       "        {'param_name': 'verify_integrity',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Verify that the IntervalIndex is valid.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.IntervalIndex',\n",
       "       'descriptions': 'Immutable index of intervals that are closed on the same side.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'data': {'type': 'array',\n",
       "          'description': 'array-like (1-dimensional). Array-like (ndarray, DateTimeArray, TimeDeltaArray) containing\\nInterval objects from which to build the IntervalIndex.\\n'},\n",
       "         'closed': {'type': 'string',\n",
       "          'enum': ['left', ' right', ' both', ' neither'],\n",
       "          'description': '{‘left’, ‘right’, ‘both’, ‘neither’}, default ‘right’. Whether the intervals are closed on the left-side, right-side, both or\\nneither.\\n'},\n",
       "         'dtype': {'type': 'dtype or None, default None',\n",
       "          'description': 'dtype or None, default None. If None, dtype will be inferred.\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Copy the input data.\\n'},\n",
       "         'name': {'type': 'object',\n",
       "          'description': 'object, optional. Name to be stored in the index.\\n'},\n",
       "         'verify_integrity': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Verify that the IntervalIndex is valid.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'IntervalIndex.from_arrays(left,\\xa0right[,\\xa0...])',\n",
       "      'func_desc': 'Construct from two arrays defining the left and right bounds.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.from_arrays.html#pandas.IntervalIndex.from_arrays',\n",
       "      'function_definitions': {'function_name': 'pandas.IntervalIndex.from_arrays',\n",
       "       'full_function': \"classmethod IntervalIndex.from_arrays(left, right, closed='right', name=None, copy=False, dtype=None)\",\n",
       "       'function_text': 'Construct from two arrays defining the left and right bounds.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'IntervalIndex.from_breaks(breaks[,\\xa0closed,\\xa0...])',\n",
       "      'func_desc': 'Construct an IntervalIndex from an array of splits.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.from_breaks.html#pandas.IntervalIndex.from_breaks',\n",
       "      'function_definitions': {'function_name': 'pandas.IntervalIndex.from_breaks',\n",
       "       'full_function': \"classmethod IntervalIndex.from_breaks(breaks, closed='right', name=None, copy=False, dtype=None)\",\n",
       "       'function_text': 'Construct an IntervalIndex from an array of splits.',\n",
       "       'parameter_names_desc': [{'param_name': 'breaks',\n",
       "         'param_type': 'array-like (1-dimensional)',\n",
       "         'param_desc': 'Left and right bounds for each interval.\\n'},\n",
       "        {'param_name': 'closed',\n",
       "         'param_type': '{‘left’, ‘right’, ‘both’, ‘neither’}, default ‘right’',\n",
       "         'param_desc': 'Whether the intervals are closed on the left-side, right-side, both\\nor neither.\\n'},\n",
       "        {'param_name': 'name',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Name of the resulting IntervalIndex.\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Copy the data.\\n'},\n",
       "        {'param_name': 'dtype',\n",
       "         'param_type': 'dtype or None, default None',\n",
       "         'param_desc': 'If None, dtype will be inferred.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.IntervalIndex.from_breaks',\n",
       "       'descriptions': 'Construct an IntervalIndex from an array of splits.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'breaks': {'type': 'array',\n",
       "          'description': 'array-like (1-dimensional). Left and right bounds for each interval.\\n'},\n",
       "         'closed': {'type': 'string',\n",
       "          'enum': ['left', ' right', ' both', ' neither'],\n",
       "          'description': '{‘left’, ‘right’, ‘both’, ‘neither’}, default ‘right’. Whether the intervals are closed on the left-side, right-side, both\\nor neither.\\n'},\n",
       "         'name': {'type': 'string',\n",
       "          'description': 'str, optional. Name of the resulting IntervalIndex.\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Copy the data.\\n'},\n",
       "         'dtype': {'type': 'dtype or None, default None',\n",
       "          'description': 'dtype or None, default None. If None, dtype will be inferred.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'IntervalIndex.right',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.right.html#pandas.IntervalIndex.right',\n",
       "      'function_definitions': {'function_name': 'pandas.IntervalIndex.right',\n",
       "       'full_function': 'IntervalIndex.right',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'IntervalIndex.closed',\n",
       "      'func_desc': 'String describing the inclusive side the intervals.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.closed.html#pandas.IntervalIndex.closed',\n",
       "      'function_definitions': {'function_name': 'pandas.IntervalIndex.closed',\n",
       "       'full_function': 'IntervalIndex.closed',\n",
       "       'function_text': 'String describing the inclusive side the intervals. Either left, right, both or neither. Examples For arrays: For Interval Index:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'IntervalIndex.values',\n",
       "      'func_desc': 'Return an array representing the data in the Index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.values.html#pandas.IntervalIndex.values',\n",
       "      'function_definitions': {'function_name': 'pandas.IntervalIndex.values',\n",
       "       'full_function': 'property IntervalIndex.values',\n",
       "       'function_text': 'Return an array representing the data in the Index. Warning We recommend using Index.array or\\nIndex.to_numpy(), depending on whether you need\\na reference to the underlying data or a NumPy array.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'IntervalIndex.is_non_overlapping_monotonic',\n",
       "      'func_desc': 'Return a boolean whether the IntervalArray is non-overlapping and monotonic.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.is_non_overlapping_monotonic.html#pandas.IntervalIndex.is_non_overlapping_monotonic',\n",
       "      'function_definitions': {'function_name': 'pandas.IntervalIndex.is_non_overlapping_monotonic',\n",
       "       'full_function': 'IntervalIndex.is_non_overlapping_monotonic',\n",
       "       'function_text': 'Return a boolean whether the IntervalArray is non-overlapping and monotonic. Non-overlapping means (no Intervals share points), and monotonic means\\neither monotonic increasing or monotonic decreasing. Examples For arrays: For Interval Index:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'IntervalIndex.get_loc(key)',\n",
       "      'func_desc': 'Get integer location, slice or boolean mask for requested label.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.get_loc.html#pandas.IntervalIndex.get_loc',\n",
       "      'function_definitions': {'function_name': 'pandas.IntervalIndex.get_loc',\n",
       "       'full_function': 'IntervalIndex.get_loc(key)',\n",
       "       'function_text': 'Get integer location, slice or boolean mask for requested label.',\n",
       "       'parameter_names_desc': [{'param_name': 'key',\n",
       "         'param_type': 'label',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.IntervalIndex.get_loc',\n",
       "       'descriptions': 'Get integer location, slice or boolean mask for requested label.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'key': {'type': 'label', 'description': 'label. '}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'IntervalIndex.set_closed(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Return an identical IntervalArray closed on the specified side.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.set_closed.html#pandas.IntervalIndex.set_closed',\n",
       "      'function_definitions': {'function_name': 'pandas.IntervalIndex.set_closed',\n",
       "       'full_function': 'IntervalIndex.set_closed(*args, **kwargs)',\n",
       "       'function_text': 'Return an identical IntervalArray closed on the specified side.',\n",
       "       'parameter_names_desc': [{'param_name': 'closed',\n",
       "         'param_type': '{‘left’, ‘right’, ‘both’, ‘neither’}',\n",
       "         'param_desc': 'Whether the intervals are closed on the left-side, right-side, both\\nor neither.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.IntervalIndex.set_closed',\n",
       "       'descriptions': 'Return an identical IntervalArray closed on the specified side.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'closed': {'type': 'string',\n",
       "          'enum': ['left', ' right', ' both', ' neither'],\n",
       "          'description': '{‘left’, ‘right’, ‘both’, ‘neither’}. Whether the intervals are closed on the left-side, right-side, both\\nor neither.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'IntervalIndex.overlaps(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Check elementwise if an Interval overlaps the values in the IntervalArray.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.overlaps.html#pandas.IntervalIndex.overlaps',\n",
       "      'function_definitions': {'function_name': 'pandas.IntervalIndex.overlaps',\n",
       "       'full_function': 'IntervalIndex.overlaps(*args, **kwargs)',\n",
       "       'function_text': 'Check elementwise if an Interval overlaps the values in the IntervalArray. Two intervals overlap if they share a common point, including closed\\nendpoints. Intervals that only have an open endpoint in common do not\\noverlap.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'IntervalArray',\n",
       "         'param_desc': 'Interval to check against for an overlap.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.IntervalIndex.overlaps',\n",
       "       'descriptions': 'Check elementwise if an Interval overlaps the values in the IntervalArray. Two intervals overlap if they share a common point, including closed\\nendpoints. Intervals that only have an open endpoint in common do not\\noverlap.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'IntervalArray',\n",
       "          'description': 'IntervalArray. Interval to check against for an overlap.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'IntervalIndex.from_tuples(data[,\\xa0closed,\\xa0...])',\n",
       "      'func_desc': 'Construct an IntervalIndex from an array-like of tuples.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.from_tuples.html#pandas.IntervalIndex.from_tuples',\n",
       "      'function_definitions': {'function_name': 'pandas.IntervalIndex.from_tuples',\n",
       "       'full_function': \"classmethod IntervalIndex.from_tuples(data, closed='right', name=None, copy=False, dtype=None)\",\n",
       "       'function_text': 'Construct an IntervalIndex from an array-like of tuples.',\n",
       "       'parameter_names_desc': [{'param_name': 'data',\n",
       "         'param_type': 'array-like (1-dimensional)',\n",
       "         'param_desc': 'Array of tuples.\\n'},\n",
       "        {'param_name': 'closed',\n",
       "         'param_type': '{‘left’, ‘right’, ‘both’, ‘neither’}, default ‘right’',\n",
       "         'param_desc': 'Whether the intervals are closed on the left-side, right-side, both\\nor neither.\\n'},\n",
       "        {'param_name': 'name',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Name of the resulting IntervalIndex.\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'By-default copy the data, this is compat only and ignored.\\n'},\n",
       "        {'param_name': 'dtype',\n",
       "         'param_type': 'dtype or None, default None',\n",
       "         'param_desc': 'If None, dtype will be inferred.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.IntervalIndex.from_tuples',\n",
       "       'descriptions': 'Construct an IntervalIndex from an array-like of tuples.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'data': {'type': 'array',\n",
       "          'description': 'array-like (1-dimensional). Array of tuples.\\n'},\n",
       "         'closed': {'type': 'string',\n",
       "          'enum': ['left', ' right', ' both', ' neither'],\n",
       "          'description': '{‘left’, ‘right’, ‘both’, ‘neither’}, default ‘right’. Whether the intervals are closed on the left-side, right-side, both\\nor neither.\\n'},\n",
       "         'name': {'type': 'string',\n",
       "          'description': 'str, optional. Name of the resulting IntervalIndex.\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default False. By-default copy the data, this is compat only and ignored.\\n'},\n",
       "         'dtype': {'type': 'dtype or None, default None',\n",
       "          'description': 'dtype or None, default None. If None, dtype will be inferred.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'IntervalIndex.left',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.left.html#pandas.IntervalIndex.left',\n",
       "      'function_definitions': {'function_name': 'pandas.IntervalIndex.left',\n",
       "       'full_function': 'IntervalIndex.left',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'IntervalIndex.mid',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.mid.html#pandas.IntervalIndex.mid',\n",
       "      'function_definitions': {'function_name': 'pandas.IntervalIndex.mid',\n",
       "       'full_function': 'IntervalIndex.mid',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'IntervalIndex.length',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.length.html#pandas.IntervalIndex.length',\n",
       "      'function_definitions': {'function_name': 'pandas.IntervalIndex.length',\n",
       "       'full_function': 'property IntervalIndex.length',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'IntervalIndex.is_empty',\n",
       "      'func_desc': 'Indicates if an interval is empty, meaning it contains no points.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.is_empty.html#pandas.IntervalIndex.is_empty',\n",
       "      'function_definitions': {'function_name': 'pandas.IntervalIndex.is_empty',\n",
       "       'full_function': 'property IntervalIndex.is_empty',\n",
       "       'function_text': 'Indicates if an interval is empty, meaning it contains no points.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'IntervalIndex.is_overlapping',\n",
       "      'func_desc': 'Return True if the IntervalIndex has overlapping intervals, else False.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.is_overlapping.html#pandas.IntervalIndex.is_overlapping',\n",
       "      'function_definitions': {'function_name': 'pandas.IntervalIndex.is_overlapping',\n",
       "       'full_function': 'property IntervalIndex.is_overlapping',\n",
       "       'function_text': 'Return True if the IntervalIndex has overlapping intervals, else False. Two intervals overlap if they share a common point, including closed\\nendpoints. Intervals that only have an open endpoint in common do not\\noverlap.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'IntervalIndex.get_indexer(target[,\\xa0method,\\xa0...])',\n",
       "      'func_desc': 'Compute indexer and mask for new index given the current index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.get_indexer.html#pandas.IntervalIndex.get_indexer',\n",
       "      'function_definitions': {'function_name': 'pandas.IntervalIndex.get_indexer',\n",
       "       'full_function': 'IntervalIndex.get_indexer(target, method=None, limit=None, tolerance=None)',\n",
       "       'function_text': 'Compute indexer and mask for new index given the current index. The indexer should be then used as an input to ndarray.take to align the\\ncurrent data to the new index.',\n",
       "       'parameter_names_desc': [{'param_name': 'target',\n",
       "         'param_type': 'Index',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'method',\n",
       "         'param_type': '{None, ‘pad’/’ffill’, ‘backfill’/’bfill’, ‘nearest’}, optional',\n",
       "         'param_desc': '\\ndefault: exact matches only.\\npad / ffill: find the PREVIOUS index value if no exact match.\\nbackfill / bfill: use NEXT index value if no exact match\\nnearest: use the NEAREST index value if no exact match. Tied\\ndistances are broken by preferring the larger index value.\\n\\n'},\n",
       "        {'param_name': 'limit',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Maximum number of consecutive labels in target to match for\\ninexact matches.\\n'},\n",
       "        {'param_name': 'tolerance',\n",
       "         'param_type': 'optional',\n",
       "         'param_desc': 'Maximum distance between original and new labels for inexact\\nmatches. The values of the index at the matching locations must\\nsatisfy the equation abs(index[indexer] - target) <= tolerance.\\nTolerance may be a scalar value, which applies the same tolerance\\nto all values, or list-like, which applies variable tolerance per\\nelement. List-like includes list, tuple, array, Series, and must be\\nthe same size as the index and its dtype must exactly match the\\nindex’s type.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.IntervalIndex.get_indexer',\n",
       "       'descriptions': 'Compute indexer and mask for new index given the current index. The indexer should be then used as an input to ndarray.take to align the\\ncurrent data to the new index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'target': {'type': 'Index', 'description': 'Index. '},\n",
       "         'method': {'type': 'string',\n",
       "          'enum': ['None', ' pad/ffill', ' backfill/bfill', ' nearest'],\n",
       "          'description': '{None, ‘pad’/’ffill’, ‘backfill’/’bfill’, ‘nearest’}, optional. \\ndefault: exact matches only.\\npad / ffill: find the PREVIOUS index value if no exact match.\\nbackfill / bfill: use NEXT index value if no exact match\\nnearest: use the NEAREST index value if no exact match. Tied\\ndistances are broken by preferring the larger index value.\\n\\n'},\n",
       "         'limit': {'type': 'integer',\n",
       "          'description': 'int, optional. Maximum number of consecutive labels in target to match for\\ninexact matches.\\n'},\n",
       "         'tolerance': {'type': 'optional',\n",
       "          'description': 'optional. Maximum distance between original and new labels for inexact\\nmatches. The values of the index at the matching locations must\\nsatisfy the equation abs(index[indexer] - target) <= tolerance.\\nTolerance may be a scalar value, which applies the same tolerance\\nto all values, or list-like, which applies variable tolerance per\\nelement. List-like includes list, tuple, array, Series, and must be\\nthe same size as the index and its dtype must exactly match the\\nindex’s type.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'IntervalIndex.contains(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Check elementwise if the Intervals contain the value.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.contains.html#pandas.IntervalIndex.contains',\n",
       "      'function_definitions': {'function_name': 'pandas.IntervalIndex.contains',\n",
       "       'full_function': 'IntervalIndex.contains(*args, **kwargs)',\n",
       "       'function_text': 'Check elementwise if the Intervals contain the value. Return a boolean mask whether the value is contained in the Intervals\\nof the IntervalArray.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'scalar',\n",
       "         'param_desc': 'The value to check whether it is contained in the Intervals.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.IntervalIndex.contains',\n",
       "       'descriptions': 'Check elementwise if the Intervals contain the value. Return a boolean mask whether the value is contained in the Intervals\\nof the IntervalArray.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'scalar',\n",
       "          'description': 'scalar. The value to check whether it is contained in the Intervals.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'IntervalIndex.to_tuples(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Return an ndarray (if self is IntervalArray) or Index (if self is IntervalIndex) of tuples of the form (left, right).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.to_tuples.html#pandas.IntervalIndex.to_tuples',\n",
       "      'function_definitions': {'function_name': 'pandas.IntervalIndex.to_tuples',\n",
       "       'full_function': 'IntervalIndex.to_tuples(*args, **kwargs)',\n",
       "       'function_text': 'Return an ndarray (if self is IntervalArray) or Index (if self is IntervalIndex) of tuples of the form (left, right).',\n",
       "       'parameter_names_desc': [{'param_name': 'na_tuple',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If True, return NA as a tuple (nan, nan). If False,\\njust return NA as nan.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.IntervalIndex.to_tuples',\n",
       "       'descriptions': 'Return an ndarray (if self is IntervalArray) or Index (if self is IntervalIndex) of tuples of the form (left, right).',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'na_tuple': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If True, return NA as a tuple (nan, nan). If False,\\njust return NA as nan.\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'MultiIndex': [{'func_name': 'MultiIndex([levels,\\xa0codes,\\xa0sortorder,\\xa0...])',\n",
       "      'func_desc': 'A multi-level, or hierarchical, index object for pandas objects.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.html#pandas.MultiIndex',\n",
       "      'function_definitions': {'function_name': 'pandas.MultiIndex',\n",
       "       'full_function': 'class pandas.MultiIndex(levels=None, codes=None, sortorder=None, names=None, dtype=None, copy=False, name=None, verify_integrity=True)',\n",
       "       'function_text': 'A multi-level, or hierarchical, index object for pandas objects.',\n",
       "       'parameter_names_desc': [{'param_name': 'levels',\n",
       "         'param_type': 'sequence of arrays',\n",
       "         'param_desc': 'The unique labels for each level.\\n'},\n",
       "        {'param_name': 'codes',\n",
       "         'param_type': 'sequence of arrays',\n",
       "         'param_desc': 'Integers for each level designating which label at each location.\\n'},\n",
       "        {'param_name': 'sortorder',\n",
       "         'param_type': 'optional int',\n",
       "         'param_desc': 'Level of sortedness (must be lexicographically sorted by that\\nlevel).\\n'},\n",
       "        {'param_name': 'names',\n",
       "         'param_type': 'optional sequence of objects',\n",
       "         'param_desc': 'Names for each of the index levels. (name is accepted for compat).\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Copy the meta-data.\\n'},\n",
       "        {'param_name': 'verify_integrity',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Check that the levels/codes are consistent and valid.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.MultiIndex',\n",
       "       'descriptions': 'A multi-level, or hierarchical, index object for pandas objects.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'levels': {'type': 'array',\n",
       "          'description': 'sequence of arrays. The unique labels for each level.\\n'},\n",
       "         'codes': {'type': 'array',\n",
       "          'description': 'sequence of arrays. Integers for each level designating which label at each location.\\n'},\n",
       "         'sortorder': {'type': 'integer',\n",
       "          'description': 'optional int. Level of sortedness (must be lexicographically sorted by that\\nlevel).\\n'},\n",
       "         'names': {'type': 'object',\n",
       "          'description': 'optional sequence of objects. Names for each of the index levels. (name is accepted for compat).\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Copy the meta-data.\\n'},\n",
       "         'verify_integrity': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Check that the levels/codes are consistent and valid.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'MultiIndex.from_arrays(arrays[,\\xa0sortorder,\\xa0...])',\n",
       "      'func_desc': 'Convert arrays to MultiIndex.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.from_arrays.html#pandas.MultiIndex.from_arrays',\n",
       "      'function_definitions': {'function_name': 'pandas.MultiIndex.from_arrays',\n",
       "       'full_function': 'classmethod MultiIndex.from_arrays(arrays, sortorder=None, names=_NoDefault.no_default)',\n",
       "       'function_text': 'Convert arrays to MultiIndex.',\n",
       "       'parameter_names_desc': [{'param_name': 'arrays',\n",
       "         'param_type': 'list / sequence of array-likes',\n",
       "         'param_desc': 'Each array-like gives one level’s value for each data point.\\nlen(arrays) is the number of levels.\\n'},\n",
       "        {'param_name': 'sortorder',\n",
       "         'param_type': 'int or None',\n",
       "         'param_desc': 'Level of sortedness (must be lexicographically sorted by that\\nlevel).\\n'},\n",
       "        {'param_name': 'names',\n",
       "         'param_type': 'list / sequence of str, optional',\n",
       "         'param_desc': 'Names for the levels in the index.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.MultiIndex.from_arrays',\n",
       "       'descriptions': 'Convert arrays to MultiIndex.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'arrays': {'type': 'array',\n",
       "          'description': 'list / sequence of array-likes. Each array-like gives one level’s value for each data point.\\nlen(arrays) is the number of levels.\\n'},\n",
       "         'sortorder': {'type': 'integer',\n",
       "          'description': 'int or None. Level of sortedness (must be lexicographically sorted by that\\nlevel).\\n'},\n",
       "         'names': {'type': 'string',\n",
       "          'description': 'list / sequence of str, optional. Names for the levels in the index.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'MultiIndex.from_product(iterables[,\\xa0...])',\n",
       "      'func_desc': 'Make a MultiIndex from the cartesian product of multiple iterables.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.from_product.html#pandas.MultiIndex.from_product',\n",
       "      'function_definitions': {'function_name': 'pandas.MultiIndex.from_product',\n",
       "       'full_function': 'classmethod MultiIndex.from_product(iterables, sortorder=None, names=_NoDefault.no_default)',\n",
       "       'function_text': 'Make a MultiIndex from the cartesian product of multiple iterables.',\n",
       "       'parameter_names_desc': [{'param_name': 'iterables',\n",
       "         'param_type': 'list / sequence of iterables',\n",
       "         'param_desc': 'Each iterable has unique labels for each level of the index.\\n'},\n",
       "        {'param_name': 'sortorder',\n",
       "         'param_type': 'int or None',\n",
       "         'param_desc': 'Level of sortedness (must be lexicographically sorted by that\\nlevel).\\n'},\n",
       "        {'param_name': 'names',\n",
       "         'param_type': 'list / sequence of str, optional',\n",
       "         'param_desc': 'Names for the levels in the index.\\nIf not explicitly provided, names will be inferred from the\\nelements of iterables if an element has a name attribute.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.MultiIndex.from_product',\n",
       "       'descriptions': 'Make a MultiIndex from the cartesian product of multiple iterables.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'iterables': {'type': 'array',\n",
       "          'description': 'list / sequence of iterables. Each iterable has unique labels for each level of the index.\\n'},\n",
       "         'sortorder': {'type': 'integer',\n",
       "          'description': 'int or None. Level of sortedness (must be lexicographically sorted by that\\nlevel).\\n'},\n",
       "         'names': {'type': 'string',\n",
       "          'description': 'list / sequence of str, optional. Names for the levels in the index.\\nIf not explicitly provided, names will be inferred from the\\nelements of iterables if an element has a name attribute.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'MultiIndex.names',\n",
       "      'func_desc': 'Names of levels in MultiIndex.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.names.html#pandas.MultiIndex.names',\n",
       "      'function_definitions': {'function_name': 'pandas.MultiIndex.names',\n",
       "       'full_function': 'property MultiIndex.names',\n",
       "       'function_text': 'Names of levels in MultiIndex. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MultiIndex.codes',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.codes.html#pandas.MultiIndex.codes',\n",
       "      'function_definitions': {'function_name': 'pandas.MultiIndex.codes',\n",
       "       'full_function': 'property MultiIndex.codes',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MultiIndex.levshape',\n",
       "      'func_desc': 'A tuple with the length of each level.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.levshape.html#pandas.MultiIndex.levshape',\n",
       "      'function_definitions': {'function_name': 'pandas.MultiIndex.levshape',\n",
       "       'full_function': 'property MultiIndex.levshape',\n",
       "       'function_text': 'A tuple with the length of each level. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MultiIndex.set_levels(levels,\\xa0*[,\\xa0level,\\xa0...])',\n",
       "      'func_desc': 'Set new levels on MultiIndex.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.set_levels.html#pandas.MultiIndex.set_levels',\n",
       "      'function_definitions': {'function_name': 'pandas.MultiIndex.set_levels',\n",
       "       'full_function': 'MultiIndex.set_levels(levels, *, level=None, verify_integrity=True)',\n",
       "       'function_text': 'Set new levels on MultiIndex. Defaults to returning new index.',\n",
       "       'parameter_names_desc': [{'param_name': 'levels',\n",
       "         'param_type': 'sequence or list of sequence',\n",
       "         'param_desc': 'New level(s) to apply.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int, level name, or sequence of int/level names (default None)',\n",
       "         'param_desc': 'Level(s) to set (None for all levels).\\n'},\n",
       "        {'param_name': 'verify_integrity',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If True, checks that levels and codes are compatible.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.MultiIndex.set_levels',\n",
       "       'descriptions': 'Set new levels on MultiIndex. Defaults to returning new index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'levels': {'type': 'array',\n",
       "          'description': 'sequence or list of sequence. New level(s) to apply.\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int, level name, or sequence of int/level names (default None). Level(s) to set (None for all levels).\\n'},\n",
       "         'verify_integrity': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If True, checks that levels and codes are compatible.\\n'}},\n",
       "        'required': ['levels']}}},\n",
       "     {'func_name': 'MultiIndex.to_flat_index()',\n",
       "      'func_desc': 'Convert a MultiIndex to an Index of Tuples containing the level values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.to_flat_index.html#pandas.MultiIndex.to_flat_index',\n",
       "      'function_definitions': {'function_name': 'pandas.MultiIndex.to_flat_index',\n",
       "       'full_function': 'MultiIndex.to_flat_index()',\n",
       "       'function_text': 'Convert a MultiIndex to an Index of Tuples containing the level values.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MultiIndex.sortlevel([level,\\xa0ascending,\\xa0...])',\n",
       "      'func_desc': 'Sort MultiIndex at the requested level.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.sortlevel.html#pandas.MultiIndex.sortlevel',\n",
       "      'function_definitions': {'function_name': 'pandas.MultiIndex.sortlevel',\n",
       "       'full_function': \"MultiIndex.sortlevel(level=0, ascending=True, sort_remaining=True, na_position='first')\",\n",
       "       'function_text': 'Sort MultiIndex at the requested level. The result will respect the original ordering of the associated\\nfactor at that level.',\n",
       "       'parameter_names_desc': [{'param_name': 'level',\n",
       "         'param_type': 'list-like, int or str, default 0',\n",
       "         'param_desc': 'If a string is given, must be a name of the level.\\nIf list-like must be names or ints of levels.\\n'},\n",
       "        {'param_name': 'ascending',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'False to sort in descending order.\\nCan also be a list to specify a directed ordering.\\n'},\n",
       "        {'param_name': 'sort_remaining',\n",
       "         'param_type': 'sort by the remaining levels after level',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'na_position',\n",
       "         'param_type': '{‘first’ or ‘last’}, default ‘first’',\n",
       "         'param_desc': 'Argument ‘first’ puts NaNs at the beginning, ‘last’ puts NaNs at\\nthe end.\\n\\nNew in version 2.1.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.MultiIndex.sortlevel',\n",
       "       'descriptions': 'Sort MultiIndex at the requested level. The result will respect the original ordering of the associated\\nfactor at that level.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'level': {'type': 'integer',\n",
       "          'description': 'list-like, int or str, default 0. If a string is given, must be a name of the level.\\nIf list-like must be names or ints of levels.\\n'},\n",
       "         'ascending': {'type': 'boolean',\n",
       "          'description': 'bool, default True. False to sort in descending order.\\nCan also be a list to specify a directed ordering.\\n'},\n",
       "         'sort_remaining': {'type': 'sort by the remaining levels after level',\n",
       "          'description': 'sort by the remaining levels after level. '},\n",
       "         'na_position': {'type': 'string',\n",
       "          'enum': ['first or last'],\n",
       "          'description': '{‘first’ or ‘last’}, default ‘first’. Argument ‘first’ puts NaNs at the beginning, ‘last’ puts NaNs at\\nthe end.\\n\\nNew in version 2.1.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'MultiIndex.swaplevel([i,\\xa0j])',\n",
       "      'func_desc': 'Swap level i with level j.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.swaplevel.html#pandas.MultiIndex.swaplevel',\n",
       "      'function_definitions': {'function_name': 'pandas.MultiIndex.swaplevel',\n",
       "       'full_function': 'MultiIndex.swaplevel(i=-2, j=-1)',\n",
       "       'function_text': 'Swap level i with level j. Calling this method does not change the ordering of the values.',\n",
       "       'parameter_names_desc': [{'param_name': 'i',\n",
       "         'param_type': 'int, str, default -2',\n",
       "         'param_desc': 'First level of index to be swapped. Can pass level name as string.\\nType of parameters can be mixed.\\n'},\n",
       "        {'param_name': 'j',\n",
       "         'param_type': 'int, str, default -1',\n",
       "         'param_desc': 'Second level of index to be swapped. Can pass level name as string.\\nType of parameters can be mixed.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.MultiIndex.swaplevel',\n",
       "       'descriptions': 'Swap level i with level j. Calling this method does not change the ordering of the values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'i': {'type': 'integer',\n",
       "          'description': 'int, str, default -2. First level of index to be swapped. Can pass level name as string.\\nType of parameters can be mixed.\\n'},\n",
       "         'j': {'type': 'integer',\n",
       "          'description': 'int, str, default -1. Second level of index to be swapped. Can pass level name as string.\\nType of parameters can be mixed.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'MultiIndex.remove_unused_levels()',\n",
       "      'func_desc': 'Create new MultiIndex from current that removes unused levels.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.remove_unused_levels.html#pandas.MultiIndex.remove_unused_levels',\n",
       "      'function_definitions': {'function_name': 'pandas.MultiIndex.remove_unused_levels',\n",
       "       'full_function': 'MultiIndex.remove_unused_levels()',\n",
       "       'function_text': 'Create new MultiIndex from current that removes unused levels. Unused level(s) means levels that are not expressed in the\\nlabels. The resulting MultiIndex will have the same outward\\nappearance, meaning the same .values and ordering. It will\\nalso be .equals() to the original.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MultiIndex.copy([names,\\xa0deep,\\xa0name])',\n",
       "      'func_desc': 'Make a copy of this object.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.copy.html#pandas.MultiIndex.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.MultiIndex.copy',\n",
       "       'full_function': 'MultiIndex.copy(names=None, deep=False, name=None)',\n",
       "       'function_text': 'Make a copy of this object. Names, dtype, levels and codes can be passed and will be set on new copy.',\n",
       "       'parameter_names_desc': [{'param_name': 'names',\n",
       "         'param_type': 'sequence, optional',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'deep',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'name',\n",
       "         'param_type': 'Label',\n",
       "         'param_desc': 'Kept for compatibility with 1-dimensional Index. Should not be used.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.MultiIndex.copy',\n",
       "       'descriptions': 'Make a copy of this object. Names, dtype, levels and codes can be passed and will be set on new copy.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'names': {'type': 'sequence, optional',\n",
       "          'description': 'sequence, optional. '},\n",
       "         'deep': {'type': 'boolean', 'description': 'bool, default False. '},\n",
       "         'name': {'type': 'Label',\n",
       "          'description': 'Label. Kept for compatibility with 1-dimensional Index. Should not be used.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'MultiIndex.truncate([before,\\xa0after])',\n",
       "      'func_desc': 'Slice index between two labels / tuples, return new MultiIndex.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.truncate.html#pandas.MultiIndex.truncate',\n",
       "      'function_definitions': {'function_name': 'pandas.MultiIndex.truncate',\n",
       "       'full_function': 'MultiIndex.truncate(before=None, after=None)',\n",
       "       'function_text': 'Slice index between two labels / tuples, return new MultiIndex.',\n",
       "       'parameter_names_desc': [{'param_name': 'before',\n",
       "         'param_type': 'label or tuple, can be partial. Default None',\n",
       "         'param_desc': 'None defaults to start.\\n'},\n",
       "        {'param_name': 'after',\n",
       "         'param_type': 'label or tuple, can be partial. Default None',\n",
       "         'param_desc': 'None defaults to end.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.MultiIndex.truncate',\n",
       "       'descriptions': 'Slice index between two labels / tuples, return new MultiIndex.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'before': {'type': 'label or tuple, can be partial. Default None',\n",
       "          'description': 'label or tuple, can be partial. Default None. None defaults to start.\\n'},\n",
       "         'after': {'type': 'label or tuple, can be partial. Default None',\n",
       "          'description': 'label or tuple, can be partial. Default None. None defaults to end.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'MultiIndex.get_loc(key)',\n",
       "      'func_desc': 'Get location for a label or a tuple of labels.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.get_loc.html#pandas.MultiIndex.get_loc',\n",
       "      'function_definitions': {'function_name': 'pandas.MultiIndex.get_loc',\n",
       "       'full_function': 'MultiIndex.get_loc(key)',\n",
       "       'function_text': 'Get location for a label or a tuple of labels. The location is returned as an integer/slice or boolean\\nmask.',\n",
       "       'parameter_names_desc': [{'param_name': 'key',\n",
       "         'param_type': 'label or tuple of labels (one for each level)',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.MultiIndex.get_loc',\n",
       "       'descriptions': 'Get location for a label or a tuple of labels. The location is returned as an integer/slice or boolean\\nmask.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'key': {'type': 'label or tuple of labels (one for each level)',\n",
       "          'description': 'label or tuple of labels (one for each level). '}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'MultiIndex.get_loc_level(key[,\\xa0level,\\xa0...])',\n",
       "      'func_desc': 'Get location and sliced index for requested label(s)/level(s).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.get_loc_level.html#pandas.MultiIndex.get_loc_level',\n",
       "      'function_definitions': {'function_name': 'pandas.MultiIndex.get_loc_level',\n",
       "       'full_function': 'MultiIndex.get_loc_level(key, level=0, drop_level=True)',\n",
       "       'function_text': 'Get location and sliced index for requested label(s)/level(s).',\n",
       "       'parameter_names_desc': [{'param_name': 'key',\n",
       "         'param_type': 'label or sequence of labels',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int/level name or list thereof, optional',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'drop_level',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If False, the resulting index will not drop any level.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.MultiIndex.get_loc_level',\n",
       "       'descriptions': 'Get location and sliced index for requested label(s)/level(s).',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'key': {'type': 'label or sequence of labels',\n",
       "          'description': 'label or sequence of labels. '},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int/level name or list thereof, optional. '},\n",
       "         'drop_level': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If False, the resulting index will not drop any level.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'MultiIndex.get_level_values(level)',\n",
       "      'func_desc': 'Return vector of label values for requested level.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.get_level_values.html#pandas.MultiIndex.get_level_values',\n",
       "      'function_definitions': {'function_name': 'pandas.MultiIndex.get_level_values',\n",
       "       'full_function': 'MultiIndex.get_level_values(level)',\n",
       "       'function_text': 'Return vector of label values for requested level. Length of returned vector is equal to the length of the index.',\n",
       "       'parameter_names_desc': [{'param_name': 'level',\n",
       "         'param_type': 'int or str',\n",
       "         'param_desc': 'level is either the integer position of the level in the\\nMultiIndex, or the name of the level.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.MultiIndex.get_level_values',\n",
       "       'descriptions': 'Return vector of label values for requested level. Length of returned vector is equal to the length of the index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'level': {'type': 'integer',\n",
       "          'description': 'int or str. level is either the integer position of the level in the\\nMultiIndex, or the name of the level.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'IndexSlice',\n",
       "      'func_desc': 'Create an object to more easily perform multi-index slicing.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.IndexSlice.html#pandas.IndexSlice',\n",
       "      'function_definitions': {'function_name': 'pandas.IndexSlice',\n",
       "       'full_function': 'pandas.IndexSlice = <pandas.core.indexing._IndexSlice object>#',\n",
       "       'function_text': 'Create an object to more easily perform multi-index slicing. See also New MultiIndex with no unused levels. Notes See Defined Levels\\nfor further info on slicing a MultiIndex. Examples Using the default slice command: Using the IndexSlice class for a more intuitive command:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MultiIndex.from_tuples(tuples[,\\xa0sortorder,\\xa0...])',\n",
       "      'func_desc': 'Convert list of tuples to MultiIndex.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.from_tuples.html#pandas.MultiIndex.from_tuples',\n",
       "      'function_definitions': {'function_name': 'pandas.MultiIndex.from_tuples',\n",
       "       'full_function': 'classmethod MultiIndex.from_tuples(tuples, sortorder=None, names=None)',\n",
       "       'function_text': 'Convert list of tuples to MultiIndex.',\n",
       "       'parameter_names_desc': [{'param_name': 'tuples',\n",
       "         'param_type': 'list / sequence of tuple-likes',\n",
       "         'param_desc': 'Each tuple is the index of one row/column.\\n'},\n",
       "        {'param_name': 'sortorder',\n",
       "         'param_type': 'int or None',\n",
       "         'param_desc': 'Level of sortedness (must be lexicographically sorted by that\\nlevel).\\n'},\n",
       "        {'param_name': 'names',\n",
       "         'param_type': 'list / sequence of str, optional',\n",
       "         'param_desc': 'Names for the levels in the index.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.MultiIndex.from_tuples',\n",
       "       'descriptions': 'Convert list of tuples to MultiIndex.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'tuples': {'type': 'array',\n",
       "          'description': 'list / sequence of tuple-likes. Each tuple is the index of one row/column.\\n'},\n",
       "         'sortorder': {'type': 'integer',\n",
       "          'description': 'int or None. Level of sortedness (must be lexicographically sorted by that\\nlevel).\\n'},\n",
       "         'names': {'type': 'string',\n",
       "          'description': 'list / sequence of str, optional. Names for the levels in the index.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'MultiIndex.from_frame(df[,\\xa0sortorder,\\xa0names])',\n",
       "      'func_desc': 'Make a MultiIndex from a DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.from_frame.html#pandas.MultiIndex.from_frame',\n",
       "      'function_definitions': {'function_name': 'pandas.MultiIndex.from_frame',\n",
       "       'full_function': 'classmethod MultiIndex.from_frame(df, sortorder=None, names=None)',\n",
       "       'function_text': 'Make a MultiIndex from a DataFrame.',\n",
       "       'parameter_names_desc': [{'param_name': 'df',\n",
       "         'param_type': 'DataFrame',\n",
       "         'param_desc': 'DataFrame to be converted to MultiIndex.\\n'},\n",
       "        {'param_name': 'sortorder',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Level of sortedness (must be lexicographically sorted by that\\nlevel).\\n'},\n",
       "        {'param_name': 'names',\n",
       "         'param_type': 'list-like, optional',\n",
       "         'param_desc': 'If no names are provided, use the column names, or tuple of column\\nnames if the columns is a MultiIndex. If a sequence, overwrite\\nnames with the given sequence.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.MultiIndex.from_frame',\n",
       "       'descriptions': 'Make a MultiIndex from a DataFrame.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'df': {'type': 'DataFrame',\n",
       "          'description': 'DataFrame. DataFrame to be converted to MultiIndex.\\n'},\n",
       "         'sortorder': {'type': 'integer',\n",
       "          'description': 'int, optional. Level of sortedness (must be lexicographically sorted by that\\nlevel).\\n'},\n",
       "         'names': {'type': 'array',\n",
       "          'description': 'list-like, optional. If no names are provided, use the column names, or tuple of column\\nnames if the columns is a MultiIndex. If a sequence, overwrite\\nnames with the given sequence.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'MultiIndex.levels',\n",
       "      'func_desc': 'Levels of the MultiIndex.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.levels.html#pandas.MultiIndex.levels',\n",
       "      'function_definitions': {'function_name': 'pandas.MultiIndex.levels',\n",
       "       'full_function': 'MultiIndex.levels',\n",
       "       'function_text': 'Levels of the MultiIndex. Levels refer to the different hierarchical levels or layers in a MultiIndex.\\nIn a MultiIndex, each level represents a distinct dimension or category of\\nthe index. To access the levels, you can use the levels attribute of the MultiIndex,\\nwhich returns a tuple of Index objects. Each Index object represents a\\nlevel in the MultiIndex and contains the unique values found in that\\nspecific level. If a MultiIndex is created with levels A, B, C, and the DataFrame using\\nit filters out all rows of the level C, MultiIndex.levels will still\\nreturn A, B, C. Examples MultiIndex levels will not change even if the DataFrame using the MultiIndex\\ndoes not contain all them anymore.\\nSee how “human” is not in the DataFrame, but it is still in levels:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MultiIndex.nlevels',\n",
       "      'func_desc': 'Integer number of levels in this MultiIndex.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.nlevels.html#pandas.MultiIndex.nlevels',\n",
       "      'function_definitions': {'function_name': 'pandas.MultiIndex.nlevels',\n",
       "       'full_function': 'property MultiIndex.nlevels',\n",
       "       'function_text': 'Integer number of levels in this MultiIndex. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MultiIndex.dtypes',\n",
       "      'func_desc': 'Return the dtypes as a Series for the underlying MultiIndex.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.dtypes.html#pandas.MultiIndex.dtypes',\n",
       "      'function_definitions': {'function_name': 'pandas.MultiIndex.dtypes',\n",
       "       'full_function': 'MultiIndex.dtypes',\n",
       "       'function_text': 'Return the dtypes as a Series for the underlying MultiIndex. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MultiIndex.set_codes(codes,\\xa0*[,\\xa0level,\\xa0...])',\n",
       "      'func_desc': 'Set new codes on MultiIndex.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.set_codes.html#pandas.MultiIndex.set_codes',\n",
       "      'function_definitions': {'function_name': 'pandas.MultiIndex.set_codes',\n",
       "       'full_function': 'MultiIndex.set_codes(codes, *, level=None, verify_integrity=True)',\n",
       "       'function_text': 'Set new codes on MultiIndex. Defaults to returning new index.',\n",
       "       'parameter_names_desc': [{'param_name': 'codes',\n",
       "         'param_type': 'sequence or list of sequence',\n",
       "         'param_desc': 'New codes to apply.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int, level name, or sequence of int/level names (default None)',\n",
       "         'param_desc': 'Level(s) to set (None for all levels).\\n'},\n",
       "        {'param_name': 'verify_integrity',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If True, checks that levels and codes are compatible.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.MultiIndex.set_codes',\n",
       "       'descriptions': 'Set new codes on MultiIndex. Defaults to returning new index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'codes': {'type': 'array',\n",
       "          'description': 'sequence or list of sequence. New codes to apply.\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int, level name, or sequence of int/level names (default None). Level(s) to set (None for all levels).\\n'},\n",
       "         'verify_integrity': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If True, checks that levels and codes are compatible.\\n'}},\n",
       "        'required': ['codes']}}},\n",
       "     {'func_name': 'MultiIndex.to_frame([index,\\xa0name,\\xa0...])',\n",
       "      'func_desc': 'Create a DataFrame with the levels of the MultiIndex as columns.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.to_frame.html#pandas.MultiIndex.to_frame',\n",
       "      'function_definitions': {'function_name': 'pandas.MultiIndex.to_frame',\n",
       "       'full_function': 'MultiIndex.to_frame(index=True, name=_NoDefault.no_default, allow_duplicates=False)',\n",
       "       'function_text': 'Create a DataFrame with the levels of the MultiIndex as columns. Column ordering is determined by the DataFrame constructor with data as\\na dict.',\n",
       "       'parameter_names_desc': [{'param_name': 'index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Set the index of the returned DataFrame as the original MultiIndex.\\n'},\n",
       "        {'param_name': 'name',\n",
       "         'param_type': 'list / sequence of str, optional',\n",
       "         'param_desc': 'The passed names should substitute index level names.\\n'},\n",
       "        {'param_name': 'allow_duplicates',\n",
       "         'param_type': 'bool, optional default False',\n",
       "         'param_desc': 'Allow duplicate column labels to be created.\\n\\nNew in version 1.5.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.MultiIndex.to_frame',\n",
       "       'descriptions': 'Create a DataFrame with the levels of the MultiIndex as columns. Column ordering is determined by the DataFrame constructor with data as\\na dict.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Set the index of the returned DataFrame as the original MultiIndex.\\n'},\n",
       "         'name': {'type': 'string',\n",
       "          'description': 'list / sequence of str, optional. The passed names should substitute index level names.\\n'},\n",
       "         'allow_duplicates': {'type': 'boolean',\n",
       "          'description': 'bool, optional default False. Allow duplicate column labels to be created.\\n\\nNew in version 1.5.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'MultiIndex.droplevel([level])',\n",
       "      'func_desc': 'Return index with requested level(s) removed.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.droplevel.html#pandas.MultiIndex.droplevel',\n",
       "      'function_definitions': {'function_name': 'pandas.MultiIndex.droplevel',\n",
       "       'full_function': 'MultiIndex.droplevel(level=0)',\n",
       "       'function_text': 'Return index with requested level(s) removed. If resulting index has only 1 level left, the result will be\\nof Index type, not MultiIndex. The original index is not modified inplace.',\n",
       "       'parameter_names_desc': [{'param_name': 'level',\n",
       "         'param_type': 'int, str, or list-like, default 0',\n",
       "         'param_desc': 'If a string is given, must be the name of a level\\nIf list-like, elements must be names or indexes of levels.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.MultiIndex.droplevel',\n",
       "       'descriptions': 'Return index with requested level(s) removed. If resulting index has only 1 level left, the result will be\\nof Index type, not MultiIndex. The original index is not modified inplace.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'level': {'type': 'integer',\n",
       "          'description': 'int, str, or list-like, default 0. If a string is given, must be the name of a level\\nIf list-like, elements must be names or indexes of levels.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'MultiIndex.reorder_levels(order)',\n",
       "      'func_desc': 'Rearrange levels using input order.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.reorder_levels.html#pandas.MultiIndex.reorder_levels',\n",
       "      'function_definitions': {'function_name': 'pandas.MultiIndex.reorder_levels',\n",
       "       'full_function': 'MultiIndex.reorder_levels(order)',\n",
       "       'function_text': 'Rearrange levels using input order. May not drop or duplicate levels.',\n",
       "       'parameter_names_desc': [{'param_name': 'order',\n",
       "         'param_type': 'list of int or list of str',\n",
       "         'param_desc': 'List representing new level order. Reference level by number\\n(position) or by key (label).\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.MultiIndex.reorder_levels',\n",
       "       'descriptions': 'Rearrange levels using input order. May not drop or duplicate levels.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'order': {'type': 'integer',\n",
       "          'description': 'list of int or list of str. List representing new level order. Reference level by number\\n(position) or by key (label).\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'MultiIndex.drop(codes[,\\xa0level,\\xa0errors])',\n",
       "      'func_desc': 'Make a new pandas.MultiIndex with the passed list of codes deleted.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.drop.html#pandas.MultiIndex.drop',\n",
       "      'function_definitions': {'function_name': 'pandas.MultiIndex.drop',\n",
       "       'full_function': \"MultiIndex.drop(codes, level=None, errors='raise')\",\n",
       "       'function_text': 'Make a new pandas.MultiIndex with the passed list of codes deleted.',\n",
       "       'parameter_names_desc': [{'param_name': 'codes',\n",
       "         'param_type': 'array-like',\n",
       "         'param_desc': 'Must be a list of tuples when level is not specified.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int or level name, default None',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'errors',\n",
       "         'param_type': 'str, default ‘raise’',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.MultiIndex.drop',\n",
       "       'descriptions': 'Make a new pandas.MultiIndex with the passed list of codes deleted.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'codes': {'type': 'array',\n",
       "          'description': 'array-like. Must be a list of tuples when level is not specified.\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int or level name, default None. '},\n",
       "         'errors': {'type': 'string',\n",
       "          'description': 'str, default ‘raise’. '}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'MultiIndex.append(other)',\n",
       "      'func_desc': 'Append a collection of Index options together.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.append.html#pandas.MultiIndex.append',\n",
       "      'function_definitions': {'function_name': 'pandas.MultiIndex.append',\n",
       "       'full_function': 'MultiIndex.append(other)',\n",
       "       'function_text': 'Append a collection of Index options together.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Index or list/tuple of indices',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.MultiIndex.append',\n",
       "       'descriptions': 'Append a collection of Index options together.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'array',\n",
       "          'description': 'Index or list/tuple of indices. '}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'MultiIndex.get_locs(seq)',\n",
       "      'func_desc': 'Get location for a sequence of labels.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.get_locs.html#pandas.MultiIndex.get_locs',\n",
       "      'function_definitions': {'function_name': 'pandas.MultiIndex.get_locs',\n",
       "       'full_function': 'MultiIndex.get_locs(seq)',\n",
       "       'function_text': 'Get location for a sequence of labels.',\n",
       "       'parameter_names_desc': [{'param_name': 'seq',\n",
       "         'param_type': 'label, slice, list, mask or a sequence of such',\n",
       "         'param_desc': 'You should use one of the above for each level.\\nIf a level should not be used, set it to slice(None).\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.MultiIndex.get_locs',\n",
       "       'descriptions': 'Get location for a sequence of labels.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'seq': {'type': 'array',\n",
       "          'description': 'label, slice, list, mask or a sequence of such. You should use one of the above for each level.\\nIf a level should not be used, set it to slice(None).\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'MultiIndex.get_indexer(target[,\\xa0method,\\xa0...])',\n",
       "      'func_desc': 'Compute indexer and mask for new index given the current index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.get_indexer.html#pandas.MultiIndex.get_indexer',\n",
       "      'function_definitions': {'function_name': 'pandas.MultiIndex.get_indexer',\n",
       "       'full_function': 'MultiIndex.get_indexer(target, method=None, limit=None, tolerance=None)',\n",
       "       'function_text': 'Compute indexer and mask for new index given the current index. The indexer should be then used as an input to ndarray.take to align the\\ncurrent data to the new index.',\n",
       "       'parameter_names_desc': [{'param_name': 'target',\n",
       "         'param_type': 'Index',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'method',\n",
       "         'param_type': '{None, ‘pad’/’ffill’, ‘backfill’/’bfill’, ‘nearest’}, optional',\n",
       "         'param_desc': '\\ndefault: exact matches only.\\npad / ffill: find the PREVIOUS index value if no exact match.\\nbackfill / bfill: use NEXT index value if no exact match\\nnearest: use the NEAREST index value if no exact match. Tied\\ndistances are broken by preferring the larger index value.\\n\\n'},\n",
       "        {'param_name': 'limit',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Maximum number of consecutive labels in target to match for\\ninexact matches.\\n'},\n",
       "        {'param_name': 'tolerance',\n",
       "         'param_type': 'optional',\n",
       "         'param_desc': 'Maximum distance between original and new labels for inexact\\nmatches. The values of the index at the matching locations must\\nsatisfy the equation abs(index[indexer] - target) <= tolerance.\\nTolerance may be a scalar value, which applies the same tolerance\\nto all values, or list-like, which applies variable tolerance per\\nelement. List-like includes list, tuple, array, Series, and must be\\nthe same size as the index and its dtype must exactly match the\\nindex’s type.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.MultiIndex.get_indexer',\n",
       "       'descriptions': 'Compute indexer and mask for new index given the current index. The indexer should be then used as an input to ndarray.take to align the\\ncurrent data to the new index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'target': {'type': 'Index', 'description': 'Index. '},\n",
       "         'method': {'type': 'string',\n",
       "          'enum': ['None', ' pad/ffill', ' backfill/bfill', ' nearest'],\n",
       "          'description': '{None, ‘pad’/’ffill’, ‘backfill’/’bfill’, ‘nearest’}, optional. \\ndefault: exact matches only.\\npad / ffill: find the PREVIOUS index value if no exact match.\\nbackfill / bfill: use NEXT index value if no exact match\\nnearest: use the NEAREST index value if no exact match. Tied\\ndistances are broken by preferring the larger index value.\\n\\n'},\n",
       "         'limit': {'type': 'integer',\n",
       "          'description': 'int, optional. Maximum number of consecutive labels in target to match for\\ninexact matches.\\n'},\n",
       "         'tolerance': {'type': 'optional',\n",
       "          'description': 'optional. Maximum distance between original and new labels for inexact\\nmatches. The values of the index at the matching locations must\\nsatisfy the equation abs(index[indexer] - target) <= tolerance.\\nTolerance may be a scalar value, which applies the same tolerance\\nto all values, or list-like, which applies variable tolerance per\\nelement. List-like includes list, tuple, array, Series, and must be\\nthe same size as the index and its dtype must exactly match the\\nindex’s type.\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'DatetimeIndex': [{'func_name': 'DatetimeIndex([data,\\xa0freq,\\xa0tz,\\xa0normalize,\\xa0...])',\n",
       "      'func_desc': 'Immutable ndarray-like of datetime64 data.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.html#pandas.DatetimeIndex',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex',\n",
       "       'full_function': \"class pandas.DatetimeIndex(data=None, freq=_NoDefault.no_default, tz=_NoDefault.no_default, normalize=_NoDefault.no_default, closed=_NoDefault.no_default, ambiguous='raise', dayfirst=False, yearfirst=False, dtype=None, copy=False, name=None)\",\n",
       "       'function_text': 'Immutable ndarray-like of datetime64 data. Represented internally as int64, and which can be boxed to Timestamp objects\\nthat are subclasses of datetime and carry metadata. Changed in version 2.0.0: The various numeric date/time attributes (day,\\nmonth, year etc.) now have dtype\\nint32. Previously they had dtype int64.',\n",
       "       'parameter_names_desc': [{'param_name': 'data',\n",
       "         'param_type': 'array-like (1-dimensional)',\n",
       "         'param_desc': 'Datetime-like data to construct index with.\\n'},\n",
       "        {'param_name': 'freq',\n",
       "         'param_type': 'str or pandas offset object, optional',\n",
       "         'param_desc': 'One of pandas date offset strings or corresponding objects. The string\\n‘infer’ can be passed in order to set the frequency of the index as the\\ninferred frequency upon creation.\\n'},\n",
       "        {'param_name': 'tz',\n",
       "         'param_type': 'pytz.timezone or dateutil.tz.tzfile or datetime.tzinfo or str',\n",
       "         'param_desc': 'Set the Timezone of the data.\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Normalize start/end dates to midnight before generating date range.\\n\\nDeprecated since version 2.1.0.\\n\\n'},\n",
       "        {'param_name': 'closed',\n",
       "         'param_type': '{‘left’, ‘right’}, optional',\n",
       "         'param_desc': 'Set whether to include start and end that are on the\\nboundary. The default includes boundary points on either end.\\n\\nDeprecated since version 2.1.0.\\n\\n'},\n",
       "        {'param_name': 'ambiguous',\n",
       "         'param_type': '‘infer’, bool-ndarray, ‘NaT’, default ‘raise’',\n",
       "         'param_desc': 'When clocks moved backward due to DST, ambiguous times may arise.\\nFor example in Central European Time (UTC+01), when going from 03:00\\nDST to 02:00 non-DST, 02:30:00 local time occurs both at 00:30:00 UTC\\nand at 01:30:00 UTC. In such a situation, the ambiguous parameter\\ndictates how ambiguous times should be handled.\\n\\n‘infer’ will attempt to infer fall dst-transition hours based on\\norder\\nbool-ndarray where True signifies a DST time, False signifies a\\nnon-DST time (note that this flag is only applicable for ambiguous\\ntimes)\\n‘NaT’ will return NaT where there are ambiguous times\\n‘raise’ will raise an AmbiguousTimeError if there are ambiguous times.\\n\\n'},\n",
       "        {'param_name': 'dayfirst',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True, parse dates in data with the day first order.\\n'},\n",
       "        {'param_name': 'yearfirst',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True parse dates in data with the year first order.\\n'},\n",
       "        {'param_name': 'dtype',\n",
       "         'param_type': 'numpy.dtype or DatetimeTZDtype or str, default None',\n",
       "         'param_desc': 'Note that the only NumPy dtype allowed is datetime64[ns].\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Make a copy of input ndarray.\\n'},\n",
       "        {'param_name': 'name',\n",
       "         'param_type': 'label, default None',\n",
       "         'param_desc': 'Name to be stored in the index.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DatetimeIndex',\n",
       "       'descriptions': 'Immutable ndarray-like of datetime64 data. Represented internally as int64, and which can be boxed to Timestamp objects\\nthat are subclasses of datetime and carry metadata. Changed in version 2.0.0: The various numeric date/time attributes (day,\\nmonth, year etc.) now have dtype\\nint32. Previously they had dtype int64.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'data': {'type': 'array',\n",
       "          'description': 'array-like (1-dimensional). Datetime-like data to construct index with.\\n'},\n",
       "         'freq': {'type': 'string',\n",
       "          'description': 'str or pandas offset object, optional. One of pandas date offset strings or corresponding objects. The string\\n‘infer’ can be passed in order to set the frequency of the index as the\\ninferred frequency upon creation.\\n'},\n",
       "         'tz': {'type': 'string',\n",
       "          'description': 'pytz.timezone or dateutil.tz.tzfile or datetime.tzinfo or str. Set the Timezone of the data.\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Normalize start/end dates to midnight before generating date range.\\n\\nDeprecated since version 2.1.0.\\n\\n'},\n",
       "         'closed': {'type': 'string',\n",
       "          'enum': ['left', ' right'],\n",
       "          'description': '{‘left’, ‘right’}, optional. Set whether to include start and end that are on the\\nboundary. The default includes boundary points on either end.\\n\\nDeprecated since version 2.1.0.\\n\\n'},\n",
       "         'ambiguous': {'type': 'boolean',\n",
       "          'description': '‘infer’, bool-ndarray, ‘NaT’, default ‘raise’. When clocks moved backward due to DST, ambiguous times may arise.\\nFor example in Central European Time (UTC+01), when going from 03:00\\nDST to 02:00 non-DST, 02:30:00 local time occurs both at 00:30:00 UTC\\nand at 01:30:00 UTC. In such a situation, the ambiguous parameter\\ndictates how ambiguous times should be handled.\\n\\n‘infer’ will attempt to infer fall dst-transition hours based on\\norder\\nbool-ndarray where True signifies a DST time, False signifies a\\nnon-DST time (note that this flag is only applicable for ambiguous\\ntimes)\\n‘NaT’ will return NaT where there are ambiguous times\\n‘raise’ will raise an AmbiguousTimeError if there are ambiguous times.\\n\\n'},\n",
       "         'dayfirst': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True, parse dates in data with the day first order.\\n'},\n",
       "         'yearfirst': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True parse dates in data with the year first order.\\n'},\n",
       "         'dtype': {'type': 'string',\n",
       "          'description': 'numpy.dtype or DatetimeTZDtype or str, default None. Note that the only NumPy dtype allowed is datetime64[ns].\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Make a copy of input ndarray.\\n'},\n",
       "         'name': {'type': 'label, default None',\n",
       "          'description': 'label, default None. Name to be stored in the index.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DatetimeIndex.year',\n",
       "      'func_desc': 'The year of the datetime.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.year.html#pandas.DatetimeIndex.year',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.year',\n",
       "       'full_function': 'property DatetimeIndex.year',\n",
       "       'function_text': 'The year of the datetime. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.day',\n",
       "      'func_desc': 'The day of the datetime.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.day.html#pandas.DatetimeIndex.day',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.day',\n",
       "       'full_function': 'property DatetimeIndex.day',\n",
       "       'function_text': 'The day of the datetime. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.minute',\n",
       "      'func_desc': 'The minutes of the datetime.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.minute.html#pandas.DatetimeIndex.minute',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.minute',\n",
       "       'full_function': 'property DatetimeIndex.minute',\n",
       "       'function_text': 'The minutes of the datetime. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.microsecond',\n",
       "      'func_desc': 'The microseconds of the datetime.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.microsecond.html#pandas.DatetimeIndex.microsecond',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.microsecond',\n",
       "       'full_function': 'property DatetimeIndex.microsecond',\n",
       "       'function_text': 'The microseconds of the datetime. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.date',\n",
       "      'func_desc': 'Returns numpy array of python datetime.date objects.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.date.html#pandas.DatetimeIndex.date',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.date',\n",
       "       'full_function': 'property DatetimeIndex.date',\n",
       "       'function_text': 'Returns numpy array of python datetime.date objects. Namely, the date part of Timestamps without time and\\ntimezone information. Examples For Series: For DatetimeIndex:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.timetz',\n",
       "      'func_desc': 'Returns numpy array of datetime.time objects with timezones.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.timetz.html#pandas.DatetimeIndex.timetz',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.timetz',\n",
       "       'full_function': 'property DatetimeIndex.timetz',\n",
       "       'function_text': 'Returns numpy array of datetime.time objects with timezones. The time part of the Timestamps. Examples For Series: For DatetimeIndex:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.day_of_year',\n",
       "      'func_desc': 'The ordinal day of the year.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.day_of_year.html#pandas.DatetimeIndex.day_of_year',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.day_of_year',\n",
       "       'full_function': 'property DatetimeIndex.day_of_year',\n",
       "       'function_text': 'The ordinal day of the year. Examples For Series: For DatetimeIndex:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.day_of_week',\n",
       "      'func_desc': 'The day of the week with Monday=0, Sunday=6.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.day_of_week.html#pandas.DatetimeIndex.day_of_week',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.day_of_week',\n",
       "       'full_function': 'property DatetimeIndex.day_of_week',\n",
       "       'function_text': 'The day of the week with Monday=0, Sunday=6. Return the day of the week. It is assumed the week starts on\\nMonday, which is denoted by 0 and ends on Sunday which is denoted\\nby 6. This method is available on both Series with datetime\\nvalues (using the dt accessor) or DatetimeIndex.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.quarter',\n",
       "      'func_desc': 'The quarter of the date.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.quarter.html#pandas.DatetimeIndex.quarter',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.quarter',\n",
       "       'full_function': 'property DatetimeIndex.quarter',\n",
       "       'function_text': 'The quarter of the date. Examples For Series: For DatetimeIndex:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.freq',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.freq.html#pandas.DatetimeIndex.freq',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.freq',\n",
       "       'full_function': 'property DatetimeIndex.freq',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.is_month_start',\n",
       "      'func_desc': 'Indicates whether the date is the first day of the month.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_month_start.html#pandas.DatetimeIndex.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.is_month_start',\n",
       "       'full_function': 'property DatetimeIndex.is_month_start',\n",
       "       'function_text': 'Indicates whether the date is the first day of the month.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.is_quarter_start',\n",
       "      'func_desc': 'Indicator for whether the date is the first day of a quarter.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_quarter_start.html#pandas.DatetimeIndex.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.is_quarter_start',\n",
       "       'full_function': 'property DatetimeIndex.is_quarter_start',\n",
       "       'function_text': 'Indicator for whether the date is the first day of a quarter.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.is_year_start',\n",
       "      'func_desc': 'Indicate whether the date is the first day of a year.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_year_start.html#pandas.DatetimeIndex.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.is_year_start',\n",
       "       'full_function': 'property DatetimeIndex.is_year_start',\n",
       "       'function_text': 'Indicate whether the date is the first day of a year.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.is_leap_year',\n",
       "      'func_desc': 'Boolean indicator if the date belongs to a leap year.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_leap_year.html#pandas.DatetimeIndex.is_leap_year',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.is_leap_year',\n",
       "       'full_function': 'property DatetimeIndex.is_leap_year',\n",
       "       'function_text': 'Boolean indicator if the date belongs to a leap year. A leap year is a year, which has 366 days (instead of 365) including\\n29th of February as an intercalary day.\\nLeap years are years which are multiples of four with the exception\\nof years divisible by 100 but not by 400.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.indexer_at_time(time[,\\xa0asof])',\n",
       "      'func_desc': 'Return index locations of values at particular time of day.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.indexer_at_time.html#pandas.DatetimeIndex.indexer_at_time',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.indexer_at_time',\n",
       "       'full_function': 'DatetimeIndex.indexer_at_time(time, asof=False)',\n",
       "       'function_text': 'Return index locations of values at particular time of day.',\n",
       "       'parameter_names_desc': [{'param_name': 'time',\n",
       "         'param_type': 'datetime.time or str',\n",
       "         'param_desc': 'Time passed in either as object (datetime.time) or as string in\\nappropriate format (“%H:%M”, “%H%M”, “%I:%M%p”, “%I%M%p”,\\n“%H:%M:%S”, “%H%M%S”, “%I:%M:%S%p”, “%I%M%S%p”).\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DatetimeIndex.indexer_at_time',\n",
       "       'descriptions': 'Return index locations of values at particular time of day.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'time': {'type': 'string',\n",
       "          'description': 'datetime.time or str. Time passed in either as object (datetime.time) or as string in\\nappropriate format (“%H:%M”, “%H%M”, “%I:%M%p”, “%I%M%p”,\\n“%H:%M:%S”, “%H%M%S”, “%I:%M:%S%p”, “%I%M%S%p”).\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DatetimeIndex.normalize(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Convert times to midnight.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.normalize.html#pandas.DatetimeIndex.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.normalize',\n",
       "       'full_function': 'DatetimeIndex.normalize(*args, **kwargs)',\n",
       "       'function_text': 'Convert times to midnight. The time component of the date-time is converted to midnight i.e.\\n00:00:00. This is useful in cases, when the time does not matter.\\nLength is unaltered. The timezones are unaffected. This method is available on Series with datetime values under\\nthe .dt accessor, and directly on Datetime Array/Index.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.snap([freq])',\n",
       "      'func_desc': 'Snap time stamps to nearest occurring frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.snap.html#pandas.DatetimeIndex.snap',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.snap',\n",
       "       'full_function': \"DatetimeIndex.snap(freq='S')\",\n",
       "       'function_text': 'Snap time stamps to nearest occurring frequency.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.tz_localize(tz[,\\xa0ambiguous,\\xa0...])',\n",
       "      'func_desc': 'Localize tz-naive Datetime Array/Index to tz-aware Datetime Array/Index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.tz_localize.html#pandas.DatetimeIndex.tz_localize',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.tz_localize',\n",
       "       'full_function': \"DatetimeIndex.tz_localize(tz, ambiguous='raise', nonexistent='raise')\",\n",
       "       'function_text': 'Localize tz-naive Datetime Array/Index to tz-aware Datetime Array/Index. This method takes a time zone (tz) naive Datetime Array/Index object\\nand makes this time zone aware. It does not move the time to another\\ntime zone. This method can also be used to do the inverse – to create a time\\nzone unaware object from an aware object. To that end, pass tz=None.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.floor(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Perform floor operation on the data to the specified freq.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.floor.html#pandas.DatetimeIndex.floor',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.floor',\n",
       "       'full_function': 'DatetimeIndex.floor(*args, **kwargs)',\n",
       "       'function_text': 'Perform floor operation on the data to the specified freq.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.month_name(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Return the month names with specified locale.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.month_name.html#pandas.DatetimeIndex.month_name',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.month_name',\n",
       "       'full_function': 'DatetimeIndex.month_name(*args, **kwargs)',\n",
       "       'function_text': 'Return the month names with specified locale.',\n",
       "       'parameter_names_desc': [{'param_name': 'locale',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': \"Locale determining the language in which to return the month name.\\nDefault is English locale ('en_US.utf8'). Use the command\\nlocale -a on your terminal on Unix systems to find your locale\\nlanguage code.\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.DatetimeIndex.month_name',\n",
       "       'descriptions': 'Return the month names with specified locale.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'locale': {'type': 'string',\n",
       "          'description': \"str, optional. Locale determining the language in which to return the month name.\\nDefault is English locale ('en_US.utf8'). Use the command\\nlocale -a on your terminal on Unix systems to find your locale\\nlanguage code.\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DatetimeIndex.as_unit(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Convert to a dtype with the given unit resolution.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.as_unit.html#pandas.DatetimeIndex.as_unit',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.as_unit',\n",
       "       'full_function': 'DatetimeIndex.as_unit(*args, **kwargs)',\n",
       "       'function_text': 'Convert to a dtype with the given unit resolution.',\n",
       "       'parameter_names_desc': [{'param_name': 'unit',\n",
       "         'param_type': '{‘s’, ‘ms’, ‘us’, ‘ns’}',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.DatetimeIndex.as_unit',\n",
       "       'descriptions': 'Convert to a dtype with the given unit resolution.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'unit': {'type': 'string',\n",
       "          'enum': ['s', ' ms', ' us', ' ns'],\n",
       "          'description': '{‘s’, ‘ms’, ‘us’, ‘ns’}. '}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DatetimeIndex.to_pydatetime(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Return an ndarray of datetime.datetime objects.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.to_pydatetime.html#pandas.DatetimeIndex.to_pydatetime',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.to_pydatetime',\n",
       "       'full_function': 'DatetimeIndex.to_pydatetime(*args, **kwargs)',\n",
       "       'function_text': 'Return an ndarray of datetime.datetime objects.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.to_frame([index,\\xa0name])',\n",
       "      'func_desc': 'Create a DataFrame with a column containing the Index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.to_frame.html#pandas.DatetimeIndex.to_frame',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.to_frame',\n",
       "       'full_function': 'DatetimeIndex.to_frame(index=True, name=_NoDefault.no_default)',\n",
       "       'function_text': 'Create a DataFrame with a column containing the Index.',\n",
       "       'parameter_names_desc': [{'param_name': 'index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Set the index of the returned DataFrame as the original Index.\\n'},\n",
       "        {'param_name': 'name',\n",
       "         'param_type': 'object, defaults to index.name',\n",
       "         'param_desc': 'The passed name should substitute for the index name (if it has\\none).\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DatetimeIndex.to_frame',\n",
       "       'descriptions': 'Create a DataFrame with a column containing the Index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Set the index of the returned DataFrame as the original Index.\\n'},\n",
       "         'name': {'type': 'object',\n",
       "          'description': 'object, defaults to index.name. The passed name should substitute for the index name (if it has\\none).\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DatetimeIndex.mean(*[,\\xa0skipna,\\xa0axis])',\n",
       "      'func_desc': 'Return the mean value of the Array.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.mean.html#pandas.DatetimeIndex.mean',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.mean',\n",
       "       'full_function': 'DatetimeIndex.mean(*, skipna=True, axis=0)',\n",
       "       'function_text': 'Return the mean value of the Array.',\n",
       "       'parameter_names_desc': [{'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to ignore any NaT elements.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': 'int, optional, default 0',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.DatetimeIndex.mean',\n",
       "       'descriptions': 'Return the mean value of the Array.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to ignore any NaT elements.\\n'},\n",
       "         'axis': {'type': 'integer',\n",
       "          'description': 'int, optional, default 0. '}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DatetimeIndex.month',\n",
       "      'func_desc': 'The month as January=1, December=12.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.month.html#pandas.DatetimeIndex.month',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.month',\n",
       "       'full_function': 'property DatetimeIndex.month',\n",
       "       'function_text': 'The month as January=1, December=12. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.hour',\n",
       "      'func_desc': 'The hours of the datetime.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.hour.html#pandas.DatetimeIndex.hour',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.hour',\n",
       "       'full_function': 'property DatetimeIndex.hour',\n",
       "       'function_text': 'The hours of the datetime. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.second',\n",
       "      'func_desc': 'The seconds of the datetime.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.second.html#pandas.DatetimeIndex.second',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.second',\n",
       "       'full_function': 'property DatetimeIndex.second',\n",
       "       'function_text': 'The seconds of the datetime. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.nanosecond',\n",
       "      'func_desc': 'The nanoseconds of the datetime.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.nanosecond.html#pandas.DatetimeIndex.nanosecond',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.nanosecond',\n",
       "       'full_function': 'property DatetimeIndex.nanosecond',\n",
       "       'function_text': 'The nanoseconds of the datetime. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.time',\n",
       "      'func_desc': 'Returns numpy array of datetime.time objects.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.time.html#pandas.DatetimeIndex.time',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.time',\n",
       "       'full_function': 'property DatetimeIndex.time',\n",
       "       'function_text': 'Returns numpy array of datetime.time objects. The time part of the Timestamps. Examples For Series: For DatetimeIndex:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.dayofyear',\n",
       "      'func_desc': 'The ordinal day of the year.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.dayofyear.html#pandas.DatetimeIndex.dayofyear',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.dayofyear',\n",
       "       'full_function': 'property DatetimeIndex.dayofyear',\n",
       "       'function_text': 'The ordinal day of the year. Examples For Series: For DatetimeIndex:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.dayofweek',\n",
       "      'func_desc': 'The day of the week with Monday=0, Sunday=6.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.dayofweek.html#pandas.DatetimeIndex.dayofweek',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.dayofweek',\n",
       "       'full_function': 'property DatetimeIndex.dayofweek',\n",
       "       'function_text': 'The day of the week with Monday=0, Sunday=6. Return the day of the week. It is assumed the week starts on\\nMonday, which is denoted by 0 and ends on Sunday which is denoted\\nby 6. This method is available on both Series with datetime\\nvalues (using the dt accessor) or DatetimeIndex.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.weekday',\n",
       "      'func_desc': 'The day of the week with Monday=0, Sunday=6.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.weekday.html#pandas.DatetimeIndex.weekday',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.weekday',\n",
       "       'full_function': 'property DatetimeIndex.weekday',\n",
       "       'function_text': 'The day of the week with Monday=0, Sunday=6. Return the day of the week. It is assumed the week starts on\\nMonday, which is denoted by 0 and ends on Sunday which is denoted\\nby 6. This method is available on both Series with datetime\\nvalues (using the dt accessor) or DatetimeIndex.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.tz',\n",
       "      'func_desc': 'Return the timezone.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.tz.html#pandas.DatetimeIndex.tz',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.tz',\n",
       "       'full_function': 'property DatetimeIndex.tz',\n",
       "       'function_text': 'Return the timezone.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.freqstr',\n",
       "      'func_desc': \"Return the frequency object as a string if it's set, otherwise None.\",\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.freqstr.html#pandas.DatetimeIndex.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.freqstr',\n",
       "       'full_function': 'property DatetimeIndex.freqstr',\n",
       "       'function_text': 'Return the frequency object as a string if it’s set, otherwise None. Examples For DatetimeIndex: The frequency can be inferred if there are more than 2 points: For PeriodIndex:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.is_month_end',\n",
       "      'func_desc': 'Indicates whether the date is the last day of the month.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_month_end.html#pandas.DatetimeIndex.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.is_month_end',\n",
       "       'full_function': 'property DatetimeIndex.is_month_end',\n",
       "       'function_text': 'Indicates whether the date is the last day of the month.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.is_quarter_end',\n",
       "      'func_desc': 'Indicator for whether the date is the last day of a quarter.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_quarter_end.html#pandas.DatetimeIndex.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.is_quarter_end',\n",
       "       'full_function': 'property DatetimeIndex.is_quarter_end',\n",
       "       'function_text': 'Indicator for whether the date is the last day of a quarter.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.is_year_end',\n",
       "      'func_desc': 'Indicate whether the date is the last day of the year.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_year_end.html#pandas.DatetimeIndex.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.is_year_end',\n",
       "       'full_function': 'property DatetimeIndex.is_year_end',\n",
       "       'function_text': 'Indicate whether the date is the last day of the year.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.inferred_freq',\n",
       "      'func_desc': 'Tries to return a string representing a frequency generated by infer_freq.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.inferred_freq.html#pandas.DatetimeIndex.inferred_freq',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.inferred_freq',\n",
       "       'full_function': 'DatetimeIndex.inferred_freq',\n",
       "       'function_text': 'Tries to return a string representing a frequency generated by infer_freq. Returns None if it can’t autodetect the frequency. Examples For DatetimeIndex: For TimedeltaIndex:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.indexer_between_time(...[,\\xa0...])',\n",
       "      'func_desc': 'Return index locations of values between particular times of day.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.indexer_between_time.html#pandas.DatetimeIndex.indexer_between_time',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.indexer_between_time',\n",
       "       'full_function': 'DatetimeIndex.indexer_between_time(start_time, end_time, include_start=True, include_end=True)',\n",
       "       'function_text': 'Return index locations of values between particular times of day.',\n",
       "       'parameter_names_desc': [{'param_name': 'start_time, end_time',\n",
       "         'param_type': 'datetime.time, str',\n",
       "         'param_desc': 'Time passed either as object (datetime.time) or as string in\\nappropriate format (“%H:%M”, “%H%M”, “%I:%M%p”, “%I%M%p”,\\n“%H:%M:%S”, “%H%M%S”, “%I:%M:%S%p”,”%I%M%S%p”).\\n'},\n",
       "        {'param_name': 'include_start',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'include_end',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.DatetimeIndex.indexer_between_time',\n",
       "       'descriptions': 'Return index locations of values between particular times of day.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'start_time, end_time': {'type': 'string',\n",
       "          'description': 'datetime.time, str. Time passed either as object (datetime.time) or as string in\\nappropriate format (“%H:%M”, “%H%M”, “%I:%M%p”, “%I%M%p”,\\n“%H:%M:%S”, “%H%M%S”, “%I:%M:%S%p”,”%I%M%S%p”).\\n'},\n",
       "         'include_start': {'type': 'boolean',\n",
       "          'description': 'bool, default True. '},\n",
       "         'include_end': {'type': 'boolean',\n",
       "          'description': 'bool, default True. '}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DatetimeIndex.strftime(date_format)',\n",
       "      'func_desc': 'Convert to Index using specified date_format.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.strftime.html#pandas.DatetimeIndex.strftime',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.strftime',\n",
       "       'full_function': 'DatetimeIndex.strftime(date_format)',\n",
       "       'function_text': 'Convert to Index using specified date_format. Return an Index of formatted strings specified by date_format, which\\nsupports the same string format as the python standard library. Details\\nof the string format can be found in python string format\\ndoc. Formats supported by the C strftime API but not by the python string format\\ndoc (such as “%R”, “%r”) are not officially supported and should be\\npreferably replaced with their supported equivalents (such as “%H:%M”,\\n“%I:%M:%S %p”). Note that PeriodIndex support additional directives, detailed in\\nPeriod.strftime.',\n",
       "       'parameter_names_desc': [{'param_name': 'date_format',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'Date format string (e.g. “%Y-%m-%d”).\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DatetimeIndex.strftime',\n",
       "       'descriptions': 'Convert to Index using specified date_format. Return an Index of formatted strings specified by date_format, which\\nsupports the same string format as the python standard library. Details\\nof the string format can be found in python string format\\ndoc. Formats supported by the C strftime API but not by the python string format\\ndoc (such as “%R”, “%r”) are not officially supported and should be\\npreferably replaced with their supported equivalents (such as “%H:%M”,\\n“%I:%M:%S %p”). Note that PeriodIndex support additional directives, detailed in\\nPeriod.strftime.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'date_format': {'type': 'string',\n",
       "          'description': 'str. Date format string (e.g. “%Y-%m-%d”).\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DatetimeIndex.tz_convert(tz)',\n",
       "      'func_desc': 'Convert tz-aware Datetime Array/Index from one time zone to another.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.tz_convert.html#pandas.DatetimeIndex.tz_convert',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.tz_convert',\n",
       "       'full_function': 'DatetimeIndex.tz_convert(tz)',\n",
       "       'function_text': 'Convert tz-aware Datetime Array/Index from one time zone to another.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.round(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Perform round operation on the data to the specified freq.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.round.html#pandas.DatetimeIndex.round',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.round',\n",
       "       'full_function': 'DatetimeIndex.round(*args, **kwargs)',\n",
       "       'function_text': 'Perform round operation on the data to the specified freq.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.ceil(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Perform ceil operation on the data to the specified freq.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.ceil.html#pandas.DatetimeIndex.ceil',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.ceil',\n",
       "       'full_function': 'DatetimeIndex.ceil(*args, **kwargs)',\n",
       "       'function_text': 'Perform ceil operation on the data to the specified freq.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.day_name(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Return the day names with specified locale.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.day_name.html#pandas.DatetimeIndex.day_name',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.day_name',\n",
       "       'full_function': 'DatetimeIndex.day_name(*args, **kwargs)',\n",
       "       'function_text': 'Return the day names with specified locale.',\n",
       "       'parameter_names_desc': [{'param_name': 'locale',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': \"Locale determining the language in which to return the day name.\\nDefault is English locale ('en_US.utf8'). Use the command\\nlocale -a on your terminal on Unix systems to find your locale\\nlanguage code.\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.DatetimeIndex.day_name',\n",
       "       'descriptions': 'Return the day names with specified locale.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'locale': {'type': 'string',\n",
       "          'description': \"str, optional. Locale determining the language in which to return the day name.\\nDefault is English locale ('en_US.utf8'). Use the command\\nlocale -a on your terminal on Unix systems to find your locale\\nlanguage code.\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DatetimeIndex.to_period(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Cast to PeriodArray/PeriodIndex at a particular frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.to_period.html#pandas.DatetimeIndex.to_period',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.to_period',\n",
       "       'full_function': 'DatetimeIndex.to_period(*args, **kwargs)',\n",
       "       'function_text': 'Cast to PeriodArray/PeriodIndex at a particular frequency. Converts DatetimeArray/Index to PeriodArray/PeriodIndex.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DatetimeIndex.to_series([index,\\xa0name])',\n",
       "      'func_desc': 'Create a Series with both index and values equal to the index keys.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.to_series.html#pandas.DatetimeIndex.to_series',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.to_series',\n",
       "       'full_function': 'DatetimeIndex.to_series(index=None, name=None)',\n",
       "       'function_text': 'Create a Series with both index and values equal to the index keys. Useful with map for returning an indexer based on an index.',\n",
       "       'parameter_names_desc': [{'param_name': 'index',\n",
       "         'param_type': 'Index, optional',\n",
       "         'param_desc': 'Index of resulting Series. If None, defaults to original index.\\n'},\n",
       "        {'param_name': 'name',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Name of resulting Series. If None, defaults to name of original\\nindex.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DatetimeIndex.to_series',\n",
       "       'descriptions': 'Create a Series with both index and values equal to the index keys. Useful with map for returning an indexer based on an index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'index': {'type': 'Index, optional',\n",
       "          'description': 'Index, optional. Index of resulting Series. If None, defaults to original index.\\n'},\n",
       "         'name': {'type': 'string',\n",
       "          'description': 'str, optional. Name of resulting Series. If None, defaults to name of original\\nindex.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DatetimeIndex.std(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Return sample standard deviation over requested axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.std.html#pandas.DatetimeIndex.std',\n",
       "      'function_definitions': {'function_name': 'pandas.DatetimeIndex.std',\n",
       "       'full_function': 'DatetimeIndex.std(*args, **kwargs)',\n",
       "       'function_text': 'Return sample standard deviation over requested axis. Normalized by N-1 by default. This can be changed using ddof.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Axis for the function to be applied on. For pandas.Series\\nthis parameter is unused and defaults to None.\\n'},\n",
       "        {'param_name': 'ddof',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Degrees of Freedom. The divisor used in calculations is N - ddof,\\nwhere N represents the number of elements.\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.DatetimeIndex.std',\n",
       "       'descriptions': 'Return sample standard deviation over requested axis. Normalized by N-1 by default. This can be changed using ddof.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': 'integer',\n",
       "          'description': 'int, optional. Axis for the function to be applied on. For pandas.Series\\nthis parameter is unused and defaults to None.\\n'},\n",
       "         'ddof': {'type': 'integer',\n",
       "          'description': 'int, default 1. Degrees of Freedom. The divisor used in calculations is N - ddof,\\nwhere N represents the number of elements.\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'TimedeltaIndex': [{'func_name': 'TimedeltaIndex([data,\\xa0unit,\\xa0freq,\\xa0closed,\\xa0...])',\n",
       "      'func_desc': 'Immutable Index of timedelta64 data.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.html#pandas.TimedeltaIndex',\n",
       "      'function_definitions': {'function_name': 'pandas.TimedeltaIndex',\n",
       "       'full_function': 'class pandas.TimedeltaIndex(data=None, unit=_NoDefault.no_default, freq=_NoDefault.no_default, closed=_NoDefault.no_default, dtype=None, copy=False, name=None)',\n",
       "       'function_text': 'Immutable Index of timedelta64 data. Represented internally as int64, and scalars returned Timedelta objects.',\n",
       "       'parameter_names_desc': [{'param_name': 'data',\n",
       "         'param_type': 'array-like (1-dimensional), optional',\n",
       "         'param_desc': 'Optional timedelta-like data to construct index with.\\n'},\n",
       "        {'param_name': 'unit',\n",
       "         'param_type': '{‘D’, ‘h’, ‘m’, ‘s’, ‘ms’, ‘us’, ‘ns’}, optional',\n",
       "         'param_desc': 'The unit of data.\\n\\nDeprecated since version 2.2.0: Use pd.to_timedelta instead.\\n\\n'},\n",
       "        {'param_name': 'freq',\n",
       "         'param_type': 'str or pandas offset object, optional',\n",
       "         'param_desc': \"One of pandas date offset strings or corresponding objects. The string\\n'infer' can be passed in order to set the frequency of the index as\\nthe inferred frequency upon creation.\\n\"},\n",
       "        {'param_name': 'dtype',\n",
       "         'param_type': 'numpy.dtype or str, default None',\n",
       "         'param_desc': 'Valid numpy dtypes are timedelta64[ns], timedelta64[us],\\ntimedelta64[ms], and timedelta64[s].\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool',\n",
       "         'param_desc': 'Make a copy of input array.\\n'},\n",
       "        {'param_name': 'name',\n",
       "         'param_type': 'object',\n",
       "         'param_desc': 'Name to be stored in the index.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.TimedeltaIndex',\n",
       "       'descriptions': 'Immutable Index of timedelta64 data. Represented internally as int64, and scalars returned Timedelta objects.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'data': {'type': 'array',\n",
       "          'description': 'array-like (1-dimensional), optional. Optional timedelta-like data to construct index with.\\n'},\n",
       "         'unit': {'type': 'string',\n",
       "          'enum': ['D', ' h', ' m', ' s', ' ms', ' us', ' ns'],\n",
       "          'description': '{‘D’, ‘h’, ‘m’, ‘s’, ‘ms’, ‘us’, ‘ns’}, optional. The unit of data.\\n\\nDeprecated since version 2.2.0: Use pd.to_timedelta instead.\\n\\n'},\n",
       "         'freq': {'type': 'string',\n",
       "          'description': \"str or pandas offset object, optional. One of pandas date offset strings or corresponding objects. The string\\n'infer' can be passed in order to set the frequency of the index as\\nthe inferred frequency upon creation.\\n\"},\n",
       "         'dtype': {'type': 'string',\n",
       "          'description': 'numpy.dtype or str, default None. Valid numpy dtypes are timedelta64[ns], timedelta64[us],\\ntimedelta64[ms], and timedelta64[s].\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool. Make a copy of input array.\\n'},\n",
       "         'name': {'type': 'object',\n",
       "          'description': 'object. Name to be stored in the index.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'TimedeltaIndex.days',\n",
       "      'func_desc': 'Number of days for each element.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.days.html#pandas.TimedeltaIndex.days',\n",
       "      'function_definitions': {'function_name': 'pandas.TimedeltaIndex.days',\n",
       "       'full_function': 'property TimedeltaIndex.days',\n",
       "       'function_text': 'Number of days for each element. Examples For Series: For TimedeltaIndex:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'TimedeltaIndex.microseconds',\n",
       "      'func_desc': 'Number of microseconds (>= 0 and less than 1 second) for each element.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.microseconds.html#pandas.TimedeltaIndex.microseconds',\n",
       "      'function_definitions': {'function_name': 'pandas.TimedeltaIndex.microseconds',\n",
       "       'full_function': 'property TimedeltaIndex.microseconds',\n",
       "       'function_text': 'Number of microseconds (>= 0 and less than 1 second) for each element. Examples For Series: For TimedeltaIndex:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'TimedeltaIndex.components',\n",
       "      'func_desc': 'Return a DataFrame of the individual resolution components of the Timedeltas.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.components.html#pandas.TimedeltaIndex.components',\n",
       "      'function_definitions': {'function_name': 'pandas.TimedeltaIndex.components',\n",
       "       'full_function': 'property TimedeltaIndex.components',\n",
       "       'function_text': 'Return a DataFrame of the individual resolution components of the Timedeltas. The components (days, hours, minutes seconds, milliseconds, microseconds,\\nnanoseconds) are returned as columns in a DataFrame.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'TimedeltaIndex.as_unit(unit)',\n",
       "      'func_desc': 'Convert to a dtype with the given unit resolution.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.as_unit.html#pandas.TimedeltaIndex.as_unit',\n",
       "      'function_definitions': {'function_name': 'pandas.TimedeltaIndex.as_unit',\n",
       "       'full_function': 'TimedeltaIndex.as_unit(unit)',\n",
       "       'function_text': 'Convert to a dtype with the given unit resolution.',\n",
       "       'parameter_names_desc': [{'param_name': 'unit',\n",
       "         'param_type': '{‘s’, ‘ms’, ‘us’, ‘ns’}',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.TimedeltaIndex.as_unit',\n",
       "       'descriptions': 'Convert to a dtype with the given unit resolution.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'unit': {'type': 'string',\n",
       "          'enum': ['s', ' ms', ' us', ' ns'],\n",
       "          'description': '{‘s’, ‘ms’, ‘us’, ‘ns’}. '}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'TimedeltaIndex.to_series([index,\\xa0name])',\n",
       "      'func_desc': 'Create a Series with both index and values equal to the index keys.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.to_series.html#pandas.TimedeltaIndex.to_series',\n",
       "      'function_definitions': {'function_name': 'pandas.TimedeltaIndex.to_series',\n",
       "       'full_function': 'TimedeltaIndex.to_series(index=None, name=None)',\n",
       "       'function_text': 'Create a Series with both index and values equal to the index keys. Useful with map for returning an indexer based on an index.',\n",
       "       'parameter_names_desc': [{'param_name': 'index',\n",
       "         'param_type': 'Index, optional',\n",
       "         'param_desc': 'Index of resulting Series. If None, defaults to original index.\\n'},\n",
       "        {'param_name': 'name',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Name of resulting Series. If None, defaults to name of original\\nindex.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.TimedeltaIndex.to_series',\n",
       "       'descriptions': 'Create a Series with both index and values equal to the index keys. Useful with map for returning an indexer based on an index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'index': {'type': 'Index, optional',\n",
       "          'description': 'Index, optional. Index of resulting Series. If None, defaults to original index.\\n'},\n",
       "         'name': {'type': 'string',\n",
       "          'description': 'str, optional. Name of resulting Series. If None, defaults to name of original\\nindex.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'TimedeltaIndex.floor(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Perform floor operation on the data to the specified freq.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.floor.html#pandas.TimedeltaIndex.floor',\n",
       "      'function_definitions': {'function_name': 'pandas.TimedeltaIndex.floor',\n",
       "       'full_function': 'TimedeltaIndex.floor(*args, **kwargs)',\n",
       "       'function_text': 'Perform floor operation on the data to the specified freq.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'TimedeltaIndex.to_frame([index,\\xa0name])',\n",
       "      'func_desc': 'Create a DataFrame with a column containing the Index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.to_frame.html#pandas.TimedeltaIndex.to_frame',\n",
       "      'function_definitions': {'function_name': 'pandas.TimedeltaIndex.to_frame',\n",
       "       'full_function': 'TimedeltaIndex.to_frame(index=True, name=_NoDefault.no_default)',\n",
       "       'function_text': 'Create a DataFrame with a column containing the Index.',\n",
       "       'parameter_names_desc': [{'param_name': 'index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Set the index of the returned DataFrame as the original Index.\\n'},\n",
       "        {'param_name': 'name',\n",
       "         'param_type': 'object, defaults to index.name',\n",
       "         'param_desc': 'The passed name should substitute for the index name (if it has\\none).\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.TimedeltaIndex.to_frame',\n",
       "       'descriptions': 'Create a DataFrame with a column containing the Index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Set the index of the returned DataFrame as the original Index.\\n'},\n",
       "         'name': {'type': 'object',\n",
       "          'description': 'object, defaults to index.name. The passed name should substitute for the index name (if it has\\none).\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'TimedeltaIndex.mean(*[,\\xa0skipna,\\xa0axis])',\n",
       "      'func_desc': 'Return the mean value of the Array.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.mean.html#pandas.TimedeltaIndex.mean',\n",
       "      'function_definitions': {'function_name': 'pandas.TimedeltaIndex.mean',\n",
       "       'full_function': 'TimedeltaIndex.mean(*, skipna=True, axis=0)',\n",
       "       'function_text': 'Return the mean value of the Array.',\n",
       "       'parameter_names_desc': [{'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to ignore any NaT elements.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': 'int, optional, default 0',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.TimedeltaIndex.mean',\n",
       "       'descriptions': 'Return the mean value of the Array.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to ignore any NaT elements.\\n'},\n",
       "         'axis': {'type': 'integer',\n",
       "          'description': 'int, optional, default 0. '}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'TimedeltaIndex.seconds',\n",
       "      'func_desc': 'Number of seconds (>= 0 and less than 1 day) for each element.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.seconds.html#pandas.TimedeltaIndex.seconds',\n",
       "      'function_definitions': {'function_name': 'pandas.TimedeltaIndex.seconds',\n",
       "       'full_function': 'property TimedeltaIndex.seconds',\n",
       "       'function_text': 'Number of seconds (>= 0 and less than 1 day) for each element. Examples For Series: For TimedeltaIndex:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'TimedeltaIndex.nanoseconds',\n",
       "      'func_desc': 'Number of nanoseconds (>= 0 and less than 1 microsecond) for each element.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.nanoseconds.html#pandas.TimedeltaIndex.nanoseconds',\n",
       "      'function_definitions': {'function_name': 'pandas.TimedeltaIndex.nanoseconds',\n",
       "       'full_function': 'property TimedeltaIndex.nanoseconds',\n",
       "       'function_text': 'Number of nanoseconds (>= 0 and less than 1 microsecond) for each element. Examples For Series: For TimedeltaIndex:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'TimedeltaIndex.inferred_freq',\n",
       "      'func_desc': 'Tries to return a string representing a frequency generated by infer_freq.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.inferred_freq.html#pandas.TimedeltaIndex.inferred_freq',\n",
       "      'function_definitions': {'function_name': 'pandas.TimedeltaIndex.inferred_freq',\n",
       "       'full_function': 'TimedeltaIndex.inferred_freq',\n",
       "       'function_text': 'Tries to return a string representing a frequency generated by infer_freq. Returns None if it can’t autodetect the frequency. Examples For DatetimeIndex: For TimedeltaIndex:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'TimedeltaIndex.to_pytimedelta(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Return an ndarray of datetime.timedelta objects.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.to_pytimedelta.html#pandas.TimedeltaIndex.to_pytimedelta',\n",
       "      'function_definitions': {'function_name': 'pandas.TimedeltaIndex.to_pytimedelta',\n",
       "       'full_function': 'TimedeltaIndex.to_pytimedelta(*args, **kwargs)',\n",
       "       'function_text': 'Return an ndarray of datetime.timedelta objects.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'TimedeltaIndex.round(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Perform round operation on the data to the specified freq.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.round.html#pandas.TimedeltaIndex.round',\n",
       "      'function_definitions': {'function_name': 'pandas.TimedeltaIndex.round',\n",
       "       'full_function': 'TimedeltaIndex.round(*args, **kwargs)',\n",
       "       'function_text': 'Perform round operation on the data to the specified freq.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'TimedeltaIndex.ceil(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Perform ceil operation on the data to the specified freq.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.ceil.html#pandas.TimedeltaIndex.ceil',\n",
       "      'function_definitions': {'function_name': 'pandas.TimedeltaIndex.ceil',\n",
       "       'full_function': 'TimedeltaIndex.ceil(*args, **kwargs)',\n",
       "       'function_text': 'Perform ceil operation on the data to the specified freq.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'PeriodIndex': [{'func_name': 'PeriodIndex([data,\\xa0ordinal,\\xa0freq,\\xa0dtype,\\xa0...])',\n",
       "      'func_desc': 'Immutable ndarray holding ordinal values indicating regular periods in time.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.html#pandas.PeriodIndex',\n",
       "      'function_definitions': {'function_name': 'pandas.PeriodIndex',\n",
       "       'full_function': 'class pandas.PeriodIndex(data=None, ordinal=None, freq=None, dtype=None, copy=False, name=None, **fields)',\n",
       "       'function_text': 'Immutable ndarray holding ordinal values indicating regular periods in time. Index keys are boxed to Period objects which carries the metadata (eg,\\nfrequency information).',\n",
       "       'parameter_names_desc': [{'param_name': 'data',\n",
       "         'param_type': 'array-like (1d int np.ndarray or PeriodArray), optional',\n",
       "         'param_desc': 'Optional period-like data to construct index with.\\n'},\n",
       "        {'param_name': 'copy',\n",
       "         'param_type': 'bool',\n",
       "         'param_desc': 'Make a copy of input ndarray.\\n'},\n",
       "        {'param_name': 'freq',\n",
       "         'param_type': 'str or period object, optional',\n",
       "         'param_desc': 'One of pandas period strings or corresponding objects.\\n'},\n",
       "        {'param_name': 'year',\n",
       "         'param_type': 'int, array, or Series, default None',\n",
       "         'param_desc': '\\nDeprecated since version 2.2.0: Use PeriodIndex.from_fields instead.\\n\\n'},\n",
       "        {'param_name': 'month',\n",
       "         'param_type': 'int, array, or Series, default None',\n",
       "         'param_desc': '\\nDeprecated since version 2.2.0: Use PeriodIndex.from_fields instead.\\n\\n'},\n",
       "        {'param_name': 'quarter',\n",
       "         'param_type': 'int, array, or Series, default None',\n",
       "         'param_desc': '\\nDeprecated since version 2.2.0: Use PeriodIndex.from_fields instead.\\n\\n'},\n",
       "        {'param_name': 'day',\n",
       "         'param_type': 'int, array, or Series, default None',\n",
       "         'param_desc': '\\nDeprecated since version 2.2.0: Use PeriodIndex.from_fields instead.\\n\\n'},\n",
       "        {'param_name': 'hour',\n",
       "         'param_type': 'int, array, or Series, default None',\n",
       "         'param_desc': '\\nDeprecated since version 2.2.0: Use PeriodIndex.from_fields instead.\\n\\n'},\n",
       "        {'param_name': 'minute',\n",
       "         'param_type': 'int, array, or Series, default None',\n",
       "         'param_desc': '\\nDeprecated since version 2.2.0: Use PeriodIndex.from_fields instead.\\n\\n'},\n",
       "        {'param_name': 'second',\n",
       "         'param_type': 'int, array, or Series, default None',\n",
       "         'param_desc': '\\nDeprecated since version 2.2.0: Use PeriodIndex.from_fields instead.\\n\\n'},\n",
       "        {'param_name': 'dtype',\n",
       "         'param_type': 'str or PeriodDtype, default None',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.PeriodIndex',\n",
       "       'descriptions': 'Immutable ndarray holding ordinal values indicating regular periods in time. Index keys are boxed to Period objects which carries the metadata (eg,\\nfrequency information).',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'data': {'type': 'integer',\n",
       "          'description': 'array-like (1d int np.ndarray or PeriodArray), optional. Optional period-like data to construct index with.\\n'},\n",
       "         'copy': {'type': 'boolean',\n",
       "          'description': 'bool. Make a copy of input ndarray.\\n'},\n",
       "         'freq': {'type': 'string',\n",
       "          'description': 'str or period object, optional. One of pandas period strings or corresponding objects.\\n'},\n",
       "         'year': {'type': 'integer',\n",
       "          'description': 'int, array, or Series, default None. \\nDeprecated since version 2.2.0: Use PeriodIndex.from_fields instead.\\n\\n'},\n",
       "         'month': {'type': 'integer',\n",
       "          'description': 'int, array, or Series, default None. \\nDeprecated since version 2.2.0: Use PeriodIndex.from_fields instead.\\n\\n'},\n",
       "         'quarter': {'type': 'integer',\n",
       "          'description': 'int, array, or Series, default None. \\nDeprecated since version 2.2.0: Use PeriodIndex.from_fields instead.\\n\\n'},\n",
       "         'day': {'type': 'integer',\n",
       "          'description': 'int, array, or Series, default None. \\nDeprecated since version 2.2.0: Use PeriodIndex.from_fields instead.\\n\\n'},\n",
       "         'hour': {'type': 'integer',\n",
       "          'description': 'int, array, or Series, default None. \\nDeprecated since version 2.2.0: Use PeriodIndex.from_fields instead.\\n\\n'},\n",
       "         'minute': {'type': 'integer',\n",
       "          'description': 'int, array, or Series, default None. \\nDeprecated since version 2.2.0: Use PeriodIndex.from_fields instead.\\n\\n'},\n",
       "         'second': {'type': 'integer',\n",
       "          'description': 'int, array, or Series, default None. \\nDeprecated since version 2.2.0: Use PeriodIndex.from_fields instead.\\n\\n'},\n",
       "         'dtype': {'type': 'string',\n",
       "          'description': 'str or PeriodDtype, default None. '}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'PeriodIndex.day',\n",
       "      'func_desc': 'The days of the period.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.day.html#pandas.PeriodIndex.day',\n",
       "      'function_definitions': {'function_name': 'pandas.PeriodIndex.day',\n",
       "       'full_function': 'property PeriodIndex.day',\n",
       "       'function_text': 'The days of the period. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'PeriodIndex.day_of_week',\n",
       "      'func_desc': 'The day of the week with Monday=0, Sunday=6.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.day_of_week.html#pandas.PeriodIndex.day_of_week',\n",
       "      'function_definitions': {'function_name': 'pandas.PeriodIndex.day_of_week',\n",
       "       'full_function': 'property PeriodIndex.day_of_week',\n",
       "       'function_text': 'The day of the week with Monday=0, Sunday=6. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'PeriodIndex.day_of_year',\n",
       "      'func_desc': 'The ordinal day of the year.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.day_of_year.html#pandas.PeriodIndex.day_of_year',\n",
       "      'function_definitions': {'function_name': 'pandas.PeriodIndex.day_of_year',\n",
       "       'full_function': 'property PeriodIndex.day_of_year',\n",
       "       'function_text': 'The ordinal day of the year. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'PeriodIndex.daysinmonth',\n",
       "      'func_desc': 'The number of days in the month.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.daysinmonth.html#pandas.PeriodIndex.daysinmonth',\n",
       "      'function_definitions': {'function_name': 'pandas.PeriodIndex.daysinmonth',\n",
       "       'full_function': 'property PeriodIndex.daysinmonth',\n",
       "       'function_text': 'The number of days in the month. Examples For Series: For PeriodIndex:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'PeriodIndex.freq',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.freq.html#pandas.PeriodIndex.freq',\n",
       "      'function_definitions': {'function_name': 'pandas.PeriodIndex.freq',\n",
       "       'full_function': 'property PeriodIndex.freq',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'PeriodIndex.hour',\n",
       "      'func_desc': 'The hour of the period.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.hour.html#pandas.PeriodIndex.hour',\n",
       "      'function_definitions': {'function_name': 'pandas.PeriodIndex.hour',\n",
       "       'full_function': 'property PeriodIndex.hour',\n",
       "       'function_text': 'The hour of the period. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'PeriodIndex.minute',\n",
       "      'func_desc': 'The minute of the period.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.minute.html#pandas.PeriodIndex.minute',\n",
       "      'function_definitions': {'function_name': 'pandas.PeriodIndex.minute',\n",
       "       'full_function': 'property PeriodIndex.minute',\n",
       "       'function_text': 'The minute of the period. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'PeriodIndex.quarter',\n",
       "      'func_desc': 'The quarter of the date.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.quarter.html#pandas.PeriodIndex.quarter',\n",
       "      'function_definitions': {'function_name': 'pandas.PeriodIndex.quarter',\n",
       "       'full_function': 'property PeriodIndex.quarter',\n",
       "       'function_text': 'The quarter of the date. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'PeriodIndex.second',\n",
       "      'func_desc': 'The second of the period.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.second.html#pandas.PeriodIndex.second',\n",
       "      'function_definitions': {'function_name': 'pandas.PeriodIndex.second',\n",
       "       'full_function': 'property PeriodIndex.second',\n",
       "       'function_text': 'The second of the period. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'PeriodIndex.week',\n",
       "      'func_desc': 'The week ordinal of the year.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.week.html#pandas.PeriodIndex.week',\n",
       "      'function_definitions': {'function_name': 'pandas.PeriodIndex.week',\n",
       "       'full_function': 'property PeriodIndex.week',\n",
       "       'function_text': 'The week ordinal of the year. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'PeriodIndex.weekofyear',\n",
       "      'func_desc': 'The week ordinal of the year.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.weekofyear.html#pandas.PeriodIndex.weekofyear',\n",
       "      'function_definitions': {'function_name': 'pandas.PeriodIndex.weekofyear',\n",
       "       'full_function': 'property PeriodIndex.weekofyear',\n",
       "       'function_text': 'The week ordinal of the year. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'PeriodIndex.asfreq([freq,\\xa0how])',\n",
       "      'func_desc': 'Convert the PeriodArray to the specified frequency freq.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.asfreq.html#pandas.PeriodIndex.asfreq',\n",
       "      'function_definitions': {'function_name': 'pandas.PeriodIndex.asfreq',\n",
       "       'full_function': \"PeriodIndex.asfreq(freq=None, how='E')\",\n",
       "       'function_text': 'Convert the PeriodArray to the specified frequency freq. Equivalent to applying pandas.Period.asfreq() with the given arguments\\nto each Period in this PeriodArray.',\n",
       "       'parameter_names_desc': [{'param_name': 'freq',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'A frequency.\\n'},\n",
       "        {'param_name': 'how',\n",
       "         'param_type': 'str {‘E’, ‘S’}, default ‘E’',\n",
       "         'param_desc': 'Whether the elements should be aligned to the end\\nor start within pa period.\\n\\n‘E’, ‘END’, or ‘FINISH’ for end,\\n‘S’, ‘START’, or ‘BEGIN’ for start.\\n\\nJanuary 31st (‘END’) vs. January 1st (‘START’) for example.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.PeriodIndex.asfreq',\n",
       "       'descriptions': 'Convert the PeriodArray to the specified frequency freq. Equivalent to applying pandas.Period.asfreq() with the given arguments\\nto each Period in this PeriodArray.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'freq': {'type': 'string',\n",
       "          'description': 'str. A frequency.\\n'},\n",
       "         'how': {'type': 'string',\n",
       "          'description': 'str {‘E’, ‘S’}, default ‘E’. Whether the elements should be aligned to the end\\nor start within pa period.\\n\\n‘E’, ‘END’, or ‘FINISH’ for end,\\n‘S’, ‘START’, or ‘BEGIN’ for start.\\n\\nJanuary 31st (‘END’) vs. January 1st (‘START’) for example.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'PeriodIndex.to_timestamp([freq,\\xa0how])',\n",
       "      'func_desc': 'Cast to DatetimeArray/Index.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.to_timestamp.html#pandas.PeriodIndex.to_timestamp',\n",
       "      'function_definitions': {'function_name': 'pandas.PeriodIndex.to_timestamp',\n",
       "       'full_function': \"PeriodIndex.to_timestamp(freq=None, how='start')\",\n",
       "       'function_text': 'Cast to DatetimeArray/Index.',\n",
       "       'parameter_names_desc': [{'param_name': 'freq',\n",
       "         'param_type': 'str or DateOffset, optional',\n",
       "         'param_desc': 'Target frequency. The default is ‘D’ for week or longer,\\n‘s’ otherwise.\\n'},\n",
       "        {'param_name': 'how',\n",
       "         'param_type': '{‘s’, ‘e’, ‘start’, ‘end’}',\n",
       "         'param_desc': 'Whether to use the start or end of the time period being converted.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.PeriodIndex.to_timestamp',\n",
       "       'descriptions': 'Cast to DatetimeArray/Index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'freq': {'type': 'string',\n",
       "          'description': 'str or DateOffset, optional. Target frequency. The default is ‘D’ for week or longer,\\n‘s’ otherwise.\\n'},\n",
       "         'how': {'type': 'string',\n",
       "          'enum': ['s', ' e', ' start', ' end'],\n",
       "          'description': '{‘s’, ‘e’, ‘start’, ‘end’}. Whether to use the start or end of the time period being converted.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'PeriodIndex.from_ordinals(ordinals,\\xa0*,\\xa0freq)',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.from_ordinals.html#pandas.PeriodIndex.from_ordinals',\n",
       "      'function_definitions': {'function_name': 'pandas.PeriodIndex.from_ordinals',\n",
       "       'full_function': 'classmethod PeriodIndex.from_ordinals(ordinals, *, freq, name=None)',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'PeriodIndex.dayofweek',\n",
       "      'func_desc': 'The day of the week with Monday=0, Sunday=6.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.dayofweek.html#pandas.PeriodIndex.dayofweek',\n",
       "      'function_definitions': {'function_name': 'pandas.PeriodIndex.dayofweek',\n",
       "       'full_function': 'property PeriodIndex.dayofweek',\n",
       "       'function_text': 'The day of the week with Monday=0, Sunday=6. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'PeriodIndex.dayofyear',\n",
       "      'func_desc': 'The ordinal day of the year.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.dayofyear.html#pandas.PeriodIndex.dayofyear',\n",
       "      'function_definitions': {'function_name': 'pandas.PeriodIndex.dayofyear',\n",
       "       'full_function': 'property PeriodIndex.dayofyear',\n",
       "       'function_text': 'The ordinal day of the year. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'PeriodIndex.days_in_month',\n",
       "      'func_desc': 'The number of days in the month.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.days_in_month.html#pandas.PeriodIndex.days_in_month',\n",
       "      'function_definitions': {'function_name': 'pandas.PeriodIndex.days_in_month',\n",
       "       'full_function': 'property PeriodIndex.days_in_month',\n",
       "       'function_text': 'The number of days in the month. Examples For Series: For PeriodIndex:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'PeriodIndex.end_time',\n",
       "      'func_desc': 'Get the Timestamp for the end of the period.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.end_time.html#pandas.PeriodIndex.end_time',\n",
       "      'function_definitions': {'function_name': 'pandas.PeriodIndex.end_time',\n",
       "       'full_function': 'property PeriodIndex.end_time',\n",
       "       'function_text': 'Get the Timestamp for the end of the period.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'PeriodIndex.freqstr',\n",
       "      'func_desc': \"Return the frequency object as a string if it's set, otherwise None.\",\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.freqstr.html#pandas.PeriodIndex.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.PeriodIndex.freqstr',\n",
       "       'full_function': 'property PeriodIndex.freqstr',\n",
       "       'function_text': 'Return the frequency object as a string if it’s set, otherwise None. Examples For DatetimeIndex: The frequency can be inferred if there are more than 2 points: For PeriodIndex:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'PeriodIndex.is_leap_year',\n",
       "      'func_desc': 'Logical indicating if the date belongs to a leap year.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.is_leap_year.html#pandas.PeriodIndex.is_leap_year',\n",
       "      'function_definitions': {'function_name': 'pandas.PeriodIndex.is_leap_year',\n",
       "       'full_function': 'property PeriodIndex.is_leap_year',\n",
       "       'function_text': 'Logical indicating if the date belongs to a leap year. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'PeriodIndex.month',\n",
       "      'func_desc': 'The month as January=1, December=12.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.month.html#pandas.PeriodIndex.month',\n",
       "      'function_definitions': {'function_name': 'pandas.PeriodIndex.month',\n",
       "       'full_function': 'property PeriodIndex.month',\n",
       "       'function_text': 'The month as January=1, December=12. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'PeriodIndex.qyear',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.qyear.html#pandas.PeriodIndex.qyear',\n",
       "      'function_definitions': {'function_name': 'pandas.PeriodIndex.qyear',\n",
       "       'full_function': 'property PeriodIndex.qyear',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'PeriodIndex.start_time',\n",
       "      'func_desc': 'Get the Timestamp for the start of the period.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.start_time.html#pandas.PeriodIndex.start_time',\n",
       "      'function_definitions': {'function_name': 'pandas.PeriodIndex.start_time',\n",
       "       'full_function': 'property PeriodIndex.start_time',\n",
       "       'function_text': 'Get the Timestamp for the start of the period.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'PeriodIndex.weekday',\n",
       "      'func_desc': 'The day of the week with Monday=0, Sunday=6.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.weekday.html#pandas.PeriodIndex.weekday',\n",
       "      'function_definitions': {'function_name': 'pandas.PeriodIndex.weekday',\n",
       "       'full_function': 'property PeriodIndex.weekday',\n",
       "       'function_text': 'The day of the week with Monday=0, Sunday=6. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'PeriodIndex.year',\n",
       "      'func_desc': 'The year of the period.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.year.html#pandas.PeriodIndex.year',\n",
       "      'function_definitions': {'function_name': 'pandas.PeriodIndex.year',\n",
       "       'full_function': 'property PeriodIndex.year',\n",
       "       'function_text': 'The year of the period. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'PeriodIndex.strftime(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Convert to Index using specified date_format.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.strftime.html#pandas.PeriodIndex.strftime',\n",
       "      'function_definitions': {'function_name': 'pandas.PeriodIndex.strftime',\n",
       "       'full_function': 'PeriodIndex.strftime(*args, **kwargs)',\n",
       "       'function_text': 'Convert to Index using specified date_format. Return an Index of formatted strings specified by date_format, which\\nsupports the same string format as the python standard library. Details\\nof the string format can be found in python string format\\ndoc. Formats supported by the C strftime API but not by the python string format\\ndoc (such as “%R”, “%r”) are not officially supported and should be\\npreferably replaced with their supported equivalents (such as “%H:%M”,\\n“%I:%M:%S %p”). Note that PeriodIndex support additional directives, detailed in\\nPeriod.strftime.',\n",
       "       'parameter_names_desc': [{'param_name': 'date_format',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'Date format string (e.g. “%Y-%m-%d”).\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.PeriodIndex.strftime',\n",
       "       'descriptions': 'Convert to Index using specified date_format. Return an Index of formatted strings specified by date_format, which\\nsupports the same string format as the python standard library. Details\\nof the string format can be found in python string format\\ndoc. Formats supported by the C strftime API but not by the python string format\\ndoc (such as “%R”, “%r”) are not officially supported and should be\\npreferably replaced with their supported equivalents (such as “%H:%M”,\\n“%I:%M:%S %p”). Note that PeriodIndex support additional directives, detailed in\\nPeriod.strftime.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'date_format': {'type': 'string',\n",
       "          'description': 'str. Date format string (e.g. “%Y-%m-%d”).\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'PeriodIndex.from_fields(*[,\\xa0year,\\xa0quarter,\\xa0...])',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.from_fields.html#pandas.PeriodIndex.from_fields',\n",
       "      'function_definitions': {'function_name': 'pandas.PeriodIndex.from_fields',\n",
       "       'full_function': 'classmethod PeriodIndex.from_fields(*, year=None, quarter=None, month=None, day=None, hour=None, minute=None, second=None, freq=None)',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]}],\n",
       "  'name': 'Index objects',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/indexing.html'},\n",
       " 'offset_frequency.html': {'functions': [{'DateOffset': [{'func_name': 'DateOffset',\n",
       "      'func_desc': 'Standard kind of date increment used for a date range.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.html#pandas.tseries.offsets.DateOffset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.DateOffset',\n",
       "       'full_function': 'class pandas.tseries.offsets.DateOffset#',\n",
       "       'function_text': 'Standard kind of date increment used for a date range. Works exactly like the keyword argument form of relativedelta.\\nNote that the positional argument form of relativedelata is not\\nsupported. Use of the keyword n is discouraged– you would be better\\noff specifying n in the keywords you use, but regardless it is\\nthere for you. n is needed for DateOffset subclasses. DateOffset works as follows. Each offset specify a set of dates\\nthat conform to the DateOffset. For example, Bday defines this\\nset to be the set of dates that are weekdays (M-F). To test if a\\ndate is in the set of a DateOffset dateOffset we can use the\\nis_on_offset method: dateOffset.is_on_offset(date). If a date is not on a valid date, the rollback and rollforward\\nmethods can be used to roll the date to the nearest valid date\\nbefore/after the date. DateOffsets can be created to move dates forward a given number of\\nvalid dates. For example, Bday(2) can be added to a date to move\\nit two business days forward. If the date does not start on a\\nvalid date, first it is moved to a valid date. Thus pseudo code\\nis: When a date offset is created for a negative number of periods,\\nthe date is first rolled forward. The pseudo code is: Zero presents a problem. Should it roll forward or back? We\\narbitrarily have it rollforward: date + BDay(0) == BDay.rollforward(date) Since 0 is a bit weird, we suggest avoiding its use. Besides, adding a DateOffsets specified by the singular form of the date\\ncomponent can be used to replace certain component of the timestamp.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'The number of time periods the offset represents.\\nIf specified without a temporal pattern, defaults to n days.\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to round the result of a DateOffset addition down to the\\nprevious midnight.\\n'},\n",
       "        {'param_name': 'weekday',\n",
       "         'param_type': 'int {0, 1, …, 6}, default 0',\n",
       "         'param_desc': 'A specific integer for the day of the week.\\n\\n0 is Monday\\n1 is Tuesday\\n2 is Wednesday\\n3 is Thursday\\n4 is Friday\\n5 is Saturday\\n6 is Sunday\\n\\nInstead Weekday type from dateutil.relativedelta can be used.\\n\\nMO is Monday\\nTU is Tuesday\\nWE is Wednesday\\nTH is Thursday\\nFR is Friday\\nSA is Saturday\\nSU is Sunday.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.DateOffset',\n",
       "       'descriptions': 'Standard kind of date increment used for a date range. Works exactly like the keyword argument form of relativedelta.\\nNote that the positional argument form of relativedelata is not\\nsupported. Use of the keyword n is discouraged– you would be better\\noff specifying n in the keywords you use, but regardless it is\\nthere for you. n is needed for DateOffset subclasses. DateOffset works as follows. Each offset specify a set of dates\\nthat conform to the DateOffset. For example, Bday defines this\\nset to be the set of dates that are weekdays (M-F). To test if a\\ndate is in the set of a DateOffset dateOffset we can use the\\nis_on_offset method: dateOffset.is_on_offset(date). If a date is not on a valid date, the rollback and rollforward\\nmethods can be used to roll the date to the nearest valid date\\nbefore/after the date. DateOffsets can be created to move dates forward a given number of\\nvalid dates. For example, Bday(2) can be added to a date to move\\nit two business days forward. If the date does not start on a\\nvalid date, first it is moved to a valid date. Thus pseudo code\\nis: When a date offset is created for a negative number of periods,\\nthe date is first rolled forward. The pseudo code is: Zero presents a problem. Should it roll forward or back? We\\narbitrarily have it rollforward: date + BDay(0) == BDay.rollforward(date) Since 0 is a bit weird, we suggest avoiding its use. Besides, adding a DateOffsets specified by the singular form of the date\\ncomponent can be used to replace certain component of the timestamp.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 1. The number of time periods the offset represents.\\nIf specified without a temporal pattern, defaults to n days.\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to round the result of a DateOffset addition down to the\\nprevious midnight.\\n'},\n",
       "         'weekday': {'type': 'integer',\n",
       "          'description': 'int {0, 1, …, 6}, default 0. A specific integer for the day of the week.\\n\\n0 is Monday\\n1 is Tuesday\\n2 is Wednesday\\n3 is Thursday\\n4 is Friday\\n5 is Saturday\\n6 is Sunday\\n\\nInstead Weekday type from dateutil.relativedelta can be used.\\n\\nMO is Monday\\nTU is Tuesday\\nWE is Wednesday\\nTH is Thursday\\nFR is Friday\\nSA is Saturday\\nSU is Sunday.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DateOffset.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.freqstr.html#pandas.tseries.offsets.DateOffset.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.DateOffset.freqstr',\n",
       "       'full_function': 'DateOffset.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DateOffset.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.name.html#pandas.tseries.offsets.DateOffset.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.DateOffset.name',\n",
       "       'full_function': 'DateOffset.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DateOffset.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.normalize.html#pandas.tseries.offsets.DateOffset.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.DateOffset.normalize',\n",
       "       'full_function': 'DateOffset.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DateOffset.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.n.html#pandas.tseries.offsets.DateOffset.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.DateOffset.n',\n",
       "       'full_function': 'DateOffset.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DateOffset.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.is_month_end.html#pandas.tseries.offsets.DateOffset.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.DateOffset.is_month_end',\n",
       "       'full_function': 'DateOffset.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DateOffset.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.copy.html#pandas.tseries.offsets.DateOffset.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.DateOffset.copy',\n",
       "       'full_function': 'DateOffset.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DateOffset.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.is_on_offset.html#pandas.tseries.offsets.DateOffset.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.DateOffset.is_on_offset',\n",
       "       'full_function': 'DateOffset.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.DateOffset.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DateOffset.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.is_month_end.html#pandas.tseries.offsets.DateOffset.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.DateOffset.is_month_end',\n",
       "       'full_function': 'DateOffset.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DateOffset.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.is_quarter_end.html#pandas.tseries.offsets.DateOffset.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.DateOffset.is_quarter_end',\n",
       "       'full_function': 'DateOffset.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DateOffset.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.is_year_end.html#pandas.tseries.offsets.DateOffset.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.DateOffset.is_year_end',\n",
       "       'full_function': 'DateOffset.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DateOffset.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.kwds.html#pandas.tseries.offsets.DateOffset.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.DateOffset.kwds',\n",
       "       'full_function': 'DateOffset.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DateOffset.nanos',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.nanos.html#pandas.tseries.offsets.DateOffset.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.DateOffset.nanos',\n",
       "       'full_function': 'DateOffset.nanos#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DateOffset.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.rule_code.html#pandas.tseries.offsets.DateOffset.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.DateOffset.rule_code',\n",
       "       'full_function': 'DateOffset.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DateOffset.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.is_month_start.html#pandas.tseries.offsets.DateOffset.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.DateOffset.is_month_start',\n",
       "       'full_function': 'DateOffset.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DateOffset.is_anchored()',\n",
       "      'func_desc': '(DEPRECATED) Return boolean whether the frequency is a unit frequency (n=1).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.is_anchored.html#pandas.tseries.offsets.DateOffset.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.DateOffset.is_anchored',\n",
       "       'full_function': 'DateOffset.is_anchored()#',\n",
       "       'function_text': 'Return boolean whether the frequency is a unit frequency (n=1). Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse obj.n == 1 instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DateOffset.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.is_month_start.html#pandas.tseries.offsets.DateOffset.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.DateOffset.is_month_start',\n",
       "       'full_function': 'DateOffset.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DateOffset.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.is_quarter_start.html#pandas.tseries.offsets.DateOffset.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.DateOffset.is_quarter_start',\n",
       "       'full_function': 'DateOffset.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DateOffset.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.is_year_start.html#pandas.tseries.offsets.DateOffset.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.DateOffset.is_year_start',\n",
       "       'full_function': 'DateOffset.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'BusinessDay': [{'func_name': 'BusinessDay',\n",
       "      'func_desc': 'DateOffset subclass representing possibly n business days.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.html#pandas.tseries.offsets.BusinessDay',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessDay',\n",
       "       'full_function': 'class pandas.tseries.offsets.BusinessDay#',\n",
       "       'function_text': 'DateOffset subclass representing possibly n business days.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'The number of days represented.\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Normalize start/end dates to midnight.\\n'},\n",
       "        {'param_name': 'offset',\n",
       "         'param_type': 'timedelta, default timedelta(0)',\n",
       "         'param_desc': 'Time offset to apply.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.BusinessDay',\n",
       "       'descriptions': 'DateOffset subclass representing possibly n business days.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 1. The number of days represented.\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Normalize start/end dates to midnight.\\n'},\n",
       "         'offset': {'type': 'timedelta, default timedelta(0)',\n",
       "          'description': 'timedelta, default timedelta(0). Time offset to apply.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'BDay',\n",
       "      'func_desc': 'alias of BusinessDay',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BDay.html#pandas.tseries.offsets.BDay',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BDay',\n",
       "       'full_function': 'pandas.tseries.offsets.BDay#',\n",
       "       'function_text': 'alias of BusinessDay',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessDay.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.freqstr.html#pandas.tseries.offsets.BusinessDay.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessDay.freqstr',\n",
       "       'full_function': 'BusinessDay.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessDay.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.name.html#pandas.tseries.offsets.BusinessDay.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessDay.name',\n",
       "       'full_function': 'BusinessDay.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessDay.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.normalize.html#pandas.tseries.offsets.BusinessDay.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessDay.normalize',\n",
       "       'full_function': 'BusinessDay.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessDay.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.n.html#pandas.tseries.offsets.BusinessDay.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessDay.n',\n",
       "       'full_function': 'BusinessDay.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessDay.holidays',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.holidays.html#pandas.tseries.offsets.BusinessDay.holidays',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessDay.holidays',\n",
       "       'full_function': 'BusinessDay.holidays#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessDay.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.copy.html#pandas.tseries.offsets.BusinessDay.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessDay.copy',\n",
       "       'full_function': 'BusinessDay.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessDay.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.is_on_offset.html#pandas.tseries.offsets.BusinessDay.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessDay.is_on_offset',\n",
       "       'full_function': 'BusinessDay.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.BusinessDay.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'BusinessDay.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.is_month_end.html#pandas.tseries.offsets.BusinessDay.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessDay.is_month_end',\n",
       "       'full_function': 'BusinessDay.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessDay.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.is_quarter_end.html#pandas.tseries.offsets.BusinessDay.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessDay.is_quarter_end',\n",
       "       'full_function': 'BusinessDay.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessDay.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.is_year_end.html#pandas.tseries.offsets.BusinessDay.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessDay.is_year_end',\n",
       "       'full_function': 'BusinessDay.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessDay.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.kwds.html#pandas.tseries.offsets.BusinessDay.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessDay.kwds',\n",
       "       'full_function': 'BusinessDay.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessDay.nanos',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.nanos.html#pandas.tseries.offsets.BusinessDay.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessDay.nanos',\n",
       "       'full_function': 'BusinessDay.nanos#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessDay.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.rule_code.html#pandas.tseries.offsets.BusinessDay.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessDay.rule_code',\n",
       "       'full_function': 'BusinessDay.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessDay.weekmask',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.weekmask.html#pandas.tseries.offsets.BusinessDay.weekmask',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessDay.weekmask',\n",
       "       'full_function': 'BusinessDay.weekmask#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessDay.calendar',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.calendar.html#pandas.tseries.offsets.BusinessDay.calendar',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessDay.calendar',\n",
       "       'full_function': 'BusinessDay.calendar#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessDay.is_anchored()',\n",
       "      'func_desc': '(DEPRECATED) Return boolean whether the frequency is a unit frequency (n=1).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.is_anchored.html#pandas.tseries.offsets.BusinessDay.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessDay.is_anchored',\n",
       "       'full_function': 'BusinessDay.is_anchored()#',\n",
       "       'function_text': 'Return boolean whether the frequency is a unit frequency (n=1). Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse obj.n == 1 instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessDay.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.is_month_start.html#pandas.tseries.offsets.BusinessDay.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessDay.is_month_start',\n",
       "       'full_function': 'BusinessDay.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessDay.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.is_quarter_start.html#pandas.tseries.offsets.BusinessDay.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessDay.is_quarter_start',\n",
       "       'full_function': 'BusinessDay.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessDay.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.is_year_start.html#pandas.tseries.offsets.BusinessDay.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessDay.is_year_start',\n",
       "       'full_function': 'BusinessDay.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'BusinessHour': [{'func_name': 'BusinessHour',\n",
       "      'func_desc': 'DateOffset subclass representing possibly n business hours.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.html#pandas.tseries.offsets.BusinessHour',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessHour',\n",
       "       'full_function': 'class pandas.tseries.offsets.BusinessHour#',\n",
       "       'function_text': 'DateOffset subclass representing possibly n business hours.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'The number of hours represented.\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "        {'param_name': 'start',\n",
       "         'param_type': 'str, time, or list of str/time, default “09:00”',\n",
       "         'param_desc': 'Start time of your custom business hour in 24h format.\\n'},\n",
       "        {'param_name': 'end',\n",
       "         'param_type': 'str, time, or list of str/time, default: “17:00”',\n",
       "         'param_desc': 'End time of your custom business hour in 24h format.\\n'},\n",
       "        {'param_name': 'offset',\n",
       "         'param_type': 'timedelta, default timedelta(0)',\n",
       "         'param_desc': 'Time offset to apply.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.BusinessHour',\n",
       "       'descriptions': 'DateOffset subclass representing possibly n business hours.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 1. The number of hours represented.\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "         'start': {'type': 'string',\n",
       "          'description': 'str, time, or list of str/time, default “09:00”. Start time of your custom business hour in 24h format.\\n'},\n",
       "         'end': {'type': 'string',\n",
       "          'description': 'str, time, or list of str/time, default: “17:00”. End time of your custom business hour in 24h format.\\n'},\n",
       "         'offset': {'type': 'timedelta, default timedelta(0)',\n",
       "          'description': 'timedelta, default timedelta(0). Time offset to apply.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'BusinessHour.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.freqstr.html#pandas.tseries.offsets.BusinessHour.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessHour.freqstr',\n",
       "       'full_function': 'BusinessHour.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessHour.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.name.html#pandas.tseries.offsets.BusinessHour.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessHour.name',\n",
       "       'full_function': 'BusinessHour.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessHour.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.normalize.html#pandas.tseries.offsets.BusinessHour.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessHour.normalize',\n",
       "       'full_function': 'BusinessHour.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessHour.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.n.html#pandas.tseries.offsets.BusinessHour.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessHour.n',\n",
       "       'full_function': 'BusinessHour.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessHour.end',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.end.html#pandas.tseries.offsets.BusinessHour.end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessHour.end',\n",
       "       'full_function': 'BusinessHour.end#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessHour.holidays',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.holidays.html#pandas.tseries.offsets.BusinessHour.holidays',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessHour.holidays',\n",
       "       'full_function': 'BusinessHour.holidays#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessHour.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.copy.html#pandas.tseries.offsets.BusinessHour.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessHour.copy',\n",
       "       'full_function': 'BusinessHour.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessHour.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.is_on_offset.html#pandas.tseries.offsets.BusinessHour.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessHour.is_on_offset',\n",
       "       'full_function': 'BusinessHour.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.BusinessHour.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'BusinessHour.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.is_month_end.html#pandas.tseries.offsets.BusinessHour.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessHour.is_month_end',\n",
       "       'full_function': 'BusinessHour.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessHour.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.is_quarter_end.html#pandas.tseries.offsets.BusinessHour.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessHour.is_quarter_end',\n",
       "       'full_function': 'BusinessHour.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessHour.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.is_year_end.html#pandas.tseries.offsets.BusinessHour.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessHour.is_year_end',\n",
       "       'full_function': 'BusinessHour.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessHour.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.kwds.html#pandas.tseries.offsets.BusinessHour.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessHour.kwds',\n",
       "       'full_function': 'BusinessHour.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessHour.nanos',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.nanos.html#pandas.tseries.offsets.BusinessHour.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessHour.nanos',\n",
       "       'full_function': 'BusinessHour.nanos#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessHour.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.rule_code.html#pandas.tseries.offsets.BusinessHour.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessHour.rule_code',\n",
       "       'full_function': 'BusinessHour.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessHour.start',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.start.html#pandas.tseries.offsets.BusinessHour.start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessHour.start',\n",
       "       'full_function': 'BusinessHour.start#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessHour.weekmask',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.weekmask.html#pandas.tseries.offsets.BusinessHour.weekmask',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessHour.weekmask',\n",
       "       'full_function': 'BusinessHour.weekmask#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessHour.calendar',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.calendar.html#pandas.tseries.offsets.BusinessHour.calendar',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessHour.calendar',\n",
       "       'full_function': 'BusinessHour.calendar#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessHour.is_anchored()',\n",
       "      'func_desc': '(DEPRECATED) Return boolean whether the frequency is a unit frequency (n=1).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.is_anchored.html#pandas.tseries.offsets.BusinessHour.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessHour.is_anchored',\n",
       "       'full_function': 'BusinessHour.is_anchored()#',\n",
       "       'function_text': 'Return boolean whether the frequency is a unit frequency (n=1). Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse obj.n == 1 instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessHour.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.is_month_start.html#pandas.tseries.offsets.BusinessHour.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessHour.is_month_start',\n",
       "       'full_function': 'BusinessHour.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessHour.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.is_quarter_start.html#pandas.tseries.offsets.BusinessHour.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessHour.is_quarter_start',\n",
       "       'full_function': 'BusinessHour.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessHour.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.is_year_start.html#pandas.tseries.offsets.BusinessHour.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessHour.is_year_start',\n",
       "       'full_function': 'BusinessHour.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'CustomBusinessDay': [{'func_name': 'CustomBusinessDay',\n",
       "      'func_desc': 'DateOffset subclass representing possibly n custom business days.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.html#pandas.tseries.offsets.CustomBusinessDay',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessDay',\n",
       "       'full_function': 'class pandas.tseries.offsets.CustomBusinessDay#',\n",
       "       'function_text': 'DateOffset subclass representing possibly n custom business days. In CustomBusinessDay we can use custom weekmask, holidays, and calendar.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'The number of days represented.\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "        {'param_name': 'weekmask',\n",
       "         'param_type': 'str, Default ‘Mon Tue Wed Thu Fri’',\n",
       "         'param_desc': 'Weekmask of valid business days, passed to numpy.busdaycalendar.\\n'},\n",
       "        {'param_name': 'holidays',\n",
       "         'param_type': 'list',\n",
       "         'param_desc': 'List/array of dates to exclude from the set of valid business days,\\npassed to numpy.busdaycalendar.\\n'},\n",
       "        {'param_name': 'calendar',\n",
       "         'param_type': 'np.busdaycalendar',\n",
       "         'param_desc': 'Calendar to integrate.\\n'},\n",
       "        {'param_name': 'offset',\n",
       "         'param_type': 'timedelta, default timedelta(0)',\n",
       "         'param_desc': 'Time offset to apply.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.CustomBusinessDay',\n",
       "       'descriptions': 'DateOffset subclass representing possibly n custom business days. In CustomBusinessDay we can use custom weekmask, holidays, and calendar.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 1. The number of days represented.\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "         'weekmask': {'type': 'string',\n",
       "          'description': 'str, Default ‘Mon Tue Wed Thu Fri’. Weekmask of valid business days, passed to numpy.busdaycalendar.\\n'},\n",
       "         'holidays': {'type': 'array',\n",
       "          'description': 'list. List/array of dates to exclude from the set of valid business days,\\npassed to numpy.busdaycalendar.\\n'},\n",
       "         'calendar': {'type': 'np.busdaycalendar',\n",
       "          'description': 'np.busdaycalendar. Calendar to integrate.\\n'},\n",
       "         'offset': {'type': 'timedelta, default timedelta(0)',\n",
       "          'description': 'timedelta, default timedelta(0). Time offset to apply.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'CDay',\n",
       "      'func_desc': 'alias of CustomBusinessDay',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CDay.html#pandas.tseries.offsets.CDay',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CDay',\n",
       "       'full_function': 'pandas.tseries.offsets.CDay#',\n",
       "       'function_text': 'alias of CustomBusinessDay',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessDay.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.freqstr.html#pandas.tseries.offsets.CustomBusinessDay.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessDay.freqstr',\n",
       "       'full_function': 'CustomBusinessDay.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessDay.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.name.html#pandas.tseries.offsets.CustomBusinessDay.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessDay.name',\n",
       "       'full_function': 'CustomBusinessDay.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessDay.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.normalize.html#pandas.tseries.offsets.CustomBusinessDay.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessDay.normalize',\n",
       "       'full_function': 'CustomBusinessDay.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessDay.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.n.html#pandas.tseries.offsets.CustomBusinessDay.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessDay.n',\n",
       "       'full_function': 'CustomBusinessDay.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessDay.calendar',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.calendar.html#pandas.tseries.offsets.CustomBusinessDay.calendar',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessDay.calendar',\n",
       "       'full_function': 'CustomBusinessDay.calendar#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessDay.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.copy.html#pandas.tseries.offsets.CustomBusinessDay.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessDay.copy',\n",
       "       'full_function': 'CustomBusinessDay.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessDay.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.is_on_offset.html#pandas.tseries.offsets.CustomBusinessDay.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessDay.is_on_offset',\n",
       "       'full_function': 'CustomBusinessDay.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.CustomBusinessDay.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'CustomBusinessDay.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.is_month_end.html#pandas.tseries.offsets.CustomBusinessDay.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessDay.is_month_end',\n",
       "       'full_function': 'CustomBusinessDay.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessDay.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.is_quarter_end.html#pandas.tseries.offsets.CustomBusinessDay.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessDay.is_quarter_end',\n",
       "       'full_function': 'CustomBusinessDay.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessDay.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.is_year_end.html#pandas.tseries.offsets.CustomBusinessDay.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessDay.is_year_end',\n",
       "       'full_function': 'CustomBusinessDay.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessDay.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.kwds.html#pandas.tseries.offsets.CustomBusinessDay.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessDay.kwds',\n",
       "       'full_function': 'CustomBusinessDay.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessDay.nanos',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.nanos.html#pandas.tseries.offsets.CustomBusinessDay.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessDay.nanos',\n",
       "       'full_function': 'CustomBusinessDay.nanos#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessDay.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.rule_code.html#pandas.tseries.offsets.CustomBusinessDay.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessDay.rule_code',\n",
       "       'full_function': 'CustomBusinessDay.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessDay.weekmask',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.weekmask.html#pandas.tseries.offsets.CustomBusinessDay.weekmask',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessDay.weekmask',\n",
       "       'full_function': 'CustomBusinessDay.weekmask#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessDay.holidays',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.holidays.html#pandas.tseries.offsets.CustomBusinessDay.holidays',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessDay.holidays',\n",
       "       'full_function': 'CustomBusinessDay.holidays#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessDay.is_anchored()',\n",
       "      'func_desc': '(DEPRECATED) Return boolean whether the frequency is a unit frequency (n=1).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.is_anchored.html#pandas.tseries.offsets.CustomBusinessDay.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessDay.is_anchored',\n",
       "       'full_function': 'CustomBusinessDay.is_anchored()#',\n",
       "       'function_text': 'Return boolean whether the frequency is a unit frequency (n=1). Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse obj.n == 1 instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessDay.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.is_month_start.html#pandas.tseries.offsets.CustomBusinessDay.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessDay.is_month_start',\n",
       "       'full_function': 'CustomBusinessDay.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessDay.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.is_quarter_start.html#pandas.tseries.offsets.CustomBusinessDay.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessDay.is_quarter_start',\n",
       "       'full_function': 'CustomBusinessDay.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessDay.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.is_year_start.html#pandas.tseries.offsets.CustomBusinessDay.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessDay.is_year_start',\n",
       "       'full_function': 'CustomBusinessDay.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'CustomBusinessHour': [{'func_name': 'CustomBusinessHour',\n",
       "      'func_desc': 'DateOffset subclass representing possibly n custom business days.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.html#pandas.tseries.offsets.CustomBusinessHour',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessHour',\n",
       "       'full_function': 'class pandas.tseries.offsets.CustomBusinessHour#',\n",
       "       'function_text': 'DateOffset subclass representing possibly n custom business days. In CustomBusinessHour we can use custom weekmask, holidays, and calendar.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'The number of hours represented.\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "        {'param_name': 'weekmask',\n",
       "         'param_type': 'str, Default ‘Mon Tue Wed Thu Fri’',\n",
       "         'param_desc': 'Weekmask of valid business days, passed to numpy.busdaycalendar.\\n'},\n",
       "        {'param_name': 'holidays',\n",
       "         'param_type': 'list',\n",
       "         'param_desc': 'List/array of dates to exclude from the set of valid business days,\\npassed to numpy.busdaycalendar.\\n'},\n",
       "        {'param_name': 'calendar',\n",
       "         'param_type': 'np.busdaycalendar',\n",
       "         'param_desc': 'Calendar to integrate.\\n'},\n",
       "        {'param_name': 'start',\n",
       "         'param_type': 'str, time, or list of str/time, default “09:00”',\n",
       "         'param_desc': 'Start time of your custom business hour in 24h format.\\n'},\n",
       "        {'param_name': 'end',\n",
       "         'param_type': 'str, time, or list of str/time, default: “17:00”',\n",
       "         'param_desc': 'End time of your custom business hour in 24h format.\\n'},\n",
       "        {'param_name': 'offset',\n",
       "         'param_type': 'timedelta, default timedelta(0)',\n",
       "         'param_desc': 'Time offset to apply.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.CustomBusinessHour',\n",
       "       'descriptions': 'DateOffset subclass representing possibly n custom business days. In CustomBusinessHour we can use custom weekmask, holidays, and calendar.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 1. The number of hours represented.\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "         'weekmask': {'type': 'string',\n",
       "          'description': 'str, Default ‘Mon Tue Wed Thu Fri’. Weekmask of valid business days, passed to numpy.busdaycalendar.\\n'},\n",
       "         'holidays': {'type': 'array',\n",
       "          'description': 'list. List/array of dates to exclude from the set of valid business days,\\npassed to numpy.busdaycalendar.\\n'},\n",
       "         'calendar': {'type': 'np.busdaycalendar',\n",
       "          'description': 'np.busdaycalendar. Calendar to integrate.\\n'},\n",
       "         'start': {'type': 'string',\n",
       "          'description': 'str, time, or list of str/time, default “09:00”. Start time of your custom business hour in 24h format.\\n'},\n",
       "         'end': {'type': 'string',\n",
       "          'description': 'str, time, or list of str/time, default: “17:00”. End time of your custom business hour in 24h format.\\n'},\n",
       "         'offset': {'type': 'timedelta, default timedelta(0)',\n",
       "          'description': 'timedelta, default timedelta(0). Time offset to apply.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'CustomBusinessHour.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.freqstr.html#pandas.tseries.offsets.CustomBusinessHour.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessHour.freqstr',\n",
       "       'full_function': 'CustomBusinessHour.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessHour.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.name.html#pandas.tseries.offsets.CustomBusinessHour.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessHour.name',\n",
       "       'full_function': 'CustomBusinessHour.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessHour.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.normalize.html#pandas.tseries.offsets.CustomBusinessHour.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessHour.normalize',\n",
       "       'full_function': 'CustomBusinessHour.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessHour.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.n.html#pandas.tseries.offsets.CustomBusinessHour.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessHour.n',\n",
       "       'full_function': 'CustomBusinessHour.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessHour.calendar',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.calendar.html#pandas.tseries.offsets.CustomBusinessHour.calendar',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessHour.calendar',\n",
       "       'full_function': 'CustomBusinessHour.calendar#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessHour.start',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.start.html#pandas.tseries.offsets.CustomBusinessHour.start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessHour.start',\n",
       "       'full_function': 'CustomBusinessHour.start#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessHour.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.copy.html#pandas.tseries.offsets.CustomBusinessHour.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessHour.copy',\n",
       "       'full_function': 'CustomBusinessHour.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessHour.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.is_on_offset.html#pandas.tseries.offsets.CustomBusinessHour.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessHour.is_on_offset',\n",
       "       'full_function': 'CustomBusinessHour.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.CustomBusinessHour.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'CustomBusinessHour.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.is_month_end.html#pandas.tseries.offsets.CustomBusinessHour.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessHour.is_month_end',\n",
       "       'full_function': 'CustomBusinessHour.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessHour.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.is_quarter_end.html#pandas.tseries.offsets.CustomBusinessHour.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessHour.is_quarter_end',\n",
       "       'full_function': 'CustomBusinessHour.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessHour.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.is_year_end.html#pandas.tseries.offsets.CustomBusinessHour.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessHour.is_year_end',\n",
       "       'full_function': 'CustomBusinessHour.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessHour.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.kwds.html#pandas.tseries.offsets.CustomBusinessHour.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessHour.kwds',\n",
       "       'full_function': 'CustomBusinessHour.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessHour.nanos',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.nanos.html#pandas.tseries.offsets.CustomBusinessHour.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessHour.nanos',\n",
       "       'full_function': 'CustomBusinessHour.nanos#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessHour.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.rule_code.html#pandas.tseries.offsets.CustomBusinessHour.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessHour.rule_code',\n",
       "       'full_function': 'CustomBusinessHour.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessHour.weekmask',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.weekmask.html#pandas.tseries.offsets.CustomBusinessHour.weekmask',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessHour.weekmask',\n",
       "       'full_function': 'CustomBusinessHour.weekmask#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessHour.holidays',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.holidays.html#pandas.tseries.offsets.CustomBusinessHour.holidays',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessHour.holidays',\n",
       "       'full_function': 'CustomBusinessHour.holidays#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessHour.end',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.end.html#pandas.tseries.offsets.CustomBusinessHour.end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessHour.end',\n",
       "       'full_function': 'CustomBusinessHour.end#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessHour.is_anchored()',\n",
       "      'func_desc': '(DEPRECATED) Return boolean whether the frequency is a unit frequency (n=1).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.is_anchored.html#pandas.tseries.offsets.CustomBusinessHour.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessHour.is_anchored',\n",
       "       'full_function': 'CustomBusinessHour.is_anchored()#',\n",
       "       'function_text': 'Return boolean whether the frequency is a unit frequency (n=1). Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse obj.n == 1 instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessHour.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.is_month_start.html#pandas.tseries.offsets.CustomBusinessHour.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessHour.is_month_start',\n",
       "       'full_function': 'CustomBusinessHour.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessHour.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.is_quarter_start.html#pandas.tseries.offsets.CustomBusinessHour.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessHour.is_quarter_start',\n",
       "       'full_function': 'CustomBusinessHour.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessHour.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.is_year_start.html#pandas.tseries.offsets.CustomBusinessHour.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessHour.is_year_start',\n",
       "       'full_function': 'CustomBusinessHour.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'MonthEnd': [{'func_name': 'MonthEnd',\n",
       "      'func_desc': 'DateOffset of one month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.html#pandas.tseries.offsets.MonthEnd',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.MonthEnd',\n",
       "       'full_function': 'class pandas.tseries.offsets.MonthEnd#',\n",
       "       'function_text': 'DateOffset of one month end. MonthEnd goes to the next date which is an end of the month.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'The number of months represented.\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Normalize start/end dates to midnight before generating date range.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.MonthEnd',\n",
       "       'descriptions': 'DateOffset of one month end. MonthEnd goes to the next date which is an end of the month.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 1. The number of months represented.\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Normalize start/end dates to midnight before generating date range.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'MonthEnd.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.freqstr.html#pandas.tseries.offsets.MonthEnd.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.MonthEnd.freqstr',\n",
       "       'full_function': 'MonthEnd.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MonthEnd.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.name.html#pandas.tseries.offsets.MonthEnd.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.MonthEnd.name',\n",
       "       'full_function': 'MonthEnd.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MonthEnd.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.normalize.html#pandas.tseries.offsets.MonthEnd.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.MonthEnd.normalize',\n",
       "       'full_function': 'MonthEnd.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MonthEnd.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.n.html#pandas.tseries.offsets.MonthEnd.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.MonthEnd.n',\n",
       "       'full_function': 'MonthEnd.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MonthEnd.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.copy.html#pandas.tseries.offsets.MonthEnd.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.MonthEnd.copy',\n",
       "       'full_function': 'MonthEnd.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MonthEnd.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.is_on_offset.html#pandas.tseries.offsets.MonthEnd.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.MonthEnd.is_on_offset',\n",
       "       'full_function': 'MonthEnd.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.MonthEnd.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'MonthEnd.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.is_month_end.html#pandas.tseries.offsets.MonthEnd.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.MonthEnd.is_month_end',\n",
       "       'full_function': 'MonthEnd.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MonthEnd.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.is_quarter_end.html#pandas.tseries.offsets.MonthEnd.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.MonthEnd.is_quarter_end',\n",
       "       'full_function': 'MonthEnd.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MonthEnd.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.is_year_end.html#pandas.tseries.offsets.MonthEnd.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.MonthEnd.is_year_end',\n",
       "       'full_function': 'MonthEnd.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MonthEnd.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.kwds.html#pandas.tseries.offsets.MonthEnd.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.MonthEnd.kwds',\n",
       "       'full_function': 'MonthEnd.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MonthEnd.nanos',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.nanos.html#pandas.tseries.offsets.MonthEnd.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.MonthEnd.nanos',\n",
       "       'full_function': 'MonthEnd.nanos#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MonthEnd.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.rule_code.html#pandas.tseries.offsets.MonthEnd.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.MonthEnd.rule_code',\n",
       "       'full_function': 'MonthEnd.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MonthEnd.is_anchored()',\n",
       "      'func_desc': '(DEPRECATED) Return boolean whether the frequency is a unit frequency (n=1).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.is_anchored.html#pandas.tseries.offsets.MonthEnd.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.MonthEnd.is_anchored',\n",
       "       'full_function': 'MonthEnd.is_anchored()#',\n",
       "       'function_text': 'Return boolean whether the frequency is a unit frequency (n=1). Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse obj.n == 1 instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MonthEnd.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.is_month_start.html#pandas.tseries.offsets.MonthEnd.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.MonthEnd.is_month_start',\n",
       "       'full_function': 'MonthEnd.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MonthEnd.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.is_quarter_start.html#pandas.tseries.offsets.MonthEnd.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.MonthEnd.is_quarter_start',\n",
       "       'full_function': 'MonthEnd.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MonthEnd.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.is_year_start.html#pandas.tseries.offsets.MonthEnd.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.MonthEnd.is_year_start',\n",
       "       'full_function': 'MonthEnd.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'MonthBegin': [{'func_name': 'MonthBegin',\n",
       "      'func_desc': 'DateOffset of one month at beginning.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.html#pandas.tseries.offsets.MonthBegin',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.MonthBegin',\n",
       "       'full_function': 'class pandas.tseries.offsets.MonthBegin#',\n",
       "       'function_text': 'DateOffset of one month at beginning. MonthBegin goes to the next date which is a start of the month.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'The number of months represented.\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Normalize start/end dates to midnight before generating date range.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.MonthBegin',\n",
       "       'descriptions': 'DateOffset of one month at beginning. MonthBegin goes to the next date which is a start of the month.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 1. The number of months represented.\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Normalize start/end dates to midnight before generating date range.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'MonthBegin.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.freqstr.html#pandas.tseries.offsets.MonthBegin.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.MonthBegin.freqstr',\n",
       "       'full_function': 'MonthBegin.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MonthBegin.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.name.html#pandas.tseries.offsets.MonthBegin.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.MonthBegin.name',\n",
       "       'full_function': 'MonthBegin.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MonthBegin.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.normalize.html#pandas.tseries.offsets.MonthBegin.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.MonthBegin.normalize',\n",
       "       'full_function': 'MonthBegin.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MonthBegin.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.n.html#pandas.tseries.offsets.MonthBegin.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.MonthBegin.n',\n",
       "       'full_function': 'MonthBegin.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MonthBegin.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.copy.html#pandas.tseries.offsets.MonthBegin.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.MonthBegin.copy',\n",
       "       'full_function': 'MonthBegin.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MonthBegin.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.is_on_offset.html#pandas.tseries.offsets.MonthBegin.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.MonthBegin.is_on_offset',\n",
       "       'full_function': 'MonthBegin.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.MonthBegin.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'MonthBegin.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.is_month_end.html#pandas.tseries.offsets.MonthBegin.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.MonthBegin.is_month_end',\n",
       "       'full_function': 'MonthBegin.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MonthBegin.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.is_quarter_end.html#pandas.tseries.offsets.MonthBegin.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.MonthBegin.is_quarter_end',\n",
       "       'full_function': 'MonthBegin.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MonthBegin.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.is_year_end.html#pandas.tseries.offsets.MonthBegin.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.MonthBegin.is_year_end',\n",
       "       'full_function': 'MonthBegin.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MonthBegin.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.kwds.html#pandas.tseries.offsets.MonthBegin.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.MonthBegin.kwds',\n",
       "       'full_function': 'MonthBegin.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MonthBegin.nanos',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.nanos.html#pandas.tseries.offsets.MonthBegin.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.MonthBegin.nanos',\n",
       "       'full_function': 'MonthBegin.nanos#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MonthBegin.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.rule_code.html#pandas.tseries.offsets.MonthBegin.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.MonthBegin.rule_code',\n",
       "       'full_function': 'MonthBegin.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MonthBegin.is_anchored()',\n",
       "      'func_desc': '(DEPRECATED) Return boolean whether the frequency is a unit frequency (n=1).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.is_anchored.html#pandas.tseries.offsets.MonthBegin.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.MonthBegin.is_anchored',\n",
       "       'full_function': 'MonthBegin.is_anchored()#',\n",
       "       'function_text': 'Return boolean whether the frequency is a unit frequency (n=1). Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse obj.n == 1 instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MonthBegin.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.is_month_start.html#pandas.tseries.offsets.MonthBegin.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.MonthBegin.is_month_start',\n",
       "       'full_function': 'MonthBegin.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MonthBegin.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.is_quarter_start.html#pandas.tseries.offsets.MonthBegin.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.MonthBegin.is_quarter_start',\n",
       "       'full_function': 'MonthBegin.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'MonthBegin.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.is_year_start.html#pandas.tseries.offsets.MonthBegin.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.MonthBegin.is_year_start',\n",
       "       'full_function': 'MonthBegin.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'BusinessMonthEnd': [{'func_name': 'BusinessMonthEnd',\n",
       "      'func_desc': 'DateOffset increments between the last business day of the month.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.html#pandas.tseries.offsets.BusinessMonthEnd',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessMonthEnd',\n",
       "       'full_function': 'class pandas.tseries.offsets.BusinessMonthEnd#',\n",
       "       'function_text': 'DateOffset increments between the last business day of the month. BusinessMonthEnd goes to the next date which is the last business day of the month.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'The number of months represented.\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Normalize start/end dates to midnight before generating date range.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.BusinessMonthEnd',\n",
       "       'descriptions': 'DateOffset increments between the last business day of the month. BusinessMonthEnd goes to the next date which is the last business day of the month.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 1. The number of months represented.\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Normalize start/end dates to midnight before generating date range.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'BMonthEnd',\n",
       "      'func_desc': 'alias of BusinessMonthEnd',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BMonthEnd.html#pandas.tseries.offsets.BMonthEnd',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BMonthEnd',\n",
       "       'full_function': 'pandas.tseries.offsets.BMonthEnd#',\n",
       "       'function_text': 'alias of BusinessMonthEnd',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessMonthEnd.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.freqstr.html#pandas.tseries.offsets.BusinessMonthEnd.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessMonthEnd.freqstr',\n",
       "       'full_function': 'BusinessMonthEnd.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessMonthEnd.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.name.html#pandas.tseries.offsets.BusinessMonthEnd.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessMonthEnd.name',\n",
       "       'full_function': 'BusinessMonthEnd.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessMonthEnd.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.normalize.html#pandas.tseries.offsets.BusinessMonthEnd.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessMonthEnd.normalize',\n",
       "       'full_function': 'BusinessMonthEnd.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessMonthEnd.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.n.html#pandas.tseries.offsets.BusinessMonthEnd.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessMonthEnd.n',\n",
       "       'full_function': 'BusinessMonthEnd.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessMonthEnd.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.copy.html#pandas.tseries.offsets.BusinessMonthEnd.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessMonthEnd.copy',\n",
       "       'full_function': 'BusinessMonthEnd.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessMonthEnd.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.is_on_offset.html#pandas.tseries.offsets.BusinessMonthEnd.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessMonthEnd.is_on_offset',\n",
       "       'full_function': 'BusinessMonthEnd.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.BusinessMonthEnd.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'BusinessMonthEnd.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.is_month_end.html#pandas.tseries.offsets.BusinessMonthEnd.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessMonthEnd.is_month_end',\n",
       "       'full_function': 'BusinessMonthEnd.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessMonthEnd.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.is_quarter_end.html#pandas.tseries.offsets.BusinessMonthEnd.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessMonthEnd.is_quarter_end',\n",
       "       'full_function': 'BusinessMonthEnd.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessMonthEnd.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.is_year_end.html#pandas.tseries.offsets.BusinessMonthEnd.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessMonthEnd.is_year_end',\n",
       "       'full_function': 'BusinessMonthEnd.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessMonthEnd.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.kwds.html#pandas.tseries.offsets.BusinessMonthEnd.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessMonthEnd.kwds',\n",
       "       'full_function': 'BusinessMonthEnd.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessMonthEnd.nanos',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.nanos.html#pandas.tseries.offsets.BusinessMonthEnd.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessMonthEnd.nanos',\n",
       "       'full_function': 'BusinessMonthEnd.nanos#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessMonthEnd.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.rule_code.html#pandas.tseries.offsets.BusinessMonthEnd.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessMonthEnd.rule_code',\n",
       "       'full_function': 'BusinessMonthEnd.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessMonthEnd.is_anchored()',\n",
       "      'func_desc': '(DEPRECATED) Return boolean whether the frequency is a unit frequency (n=1).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.is_anchored.html#pandas.tseries.offsets.BusinessMonthEnd.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessMonthEnd.is_anchored',\n",
       "       'full_function': 'BusinessMonthEnd.is_anchored()#',\n",
       "       'function_text': 'Return boolean whether the frequency is a unit frequency (n=1). Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse obj.n == 1 instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessMonthEnd.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.is_month_start.html#pandas.tseries.offsets.BusinessMonthEnd.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessMonthEnd.is_month_start',\n",
       "       'full_function': 'BusinessMonthEnd.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessMonthEnd.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.is_quarter_start.html#pandas.tseries.offsets.BusinessMonthEnd.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessMonthEnd.is_quarter_start',\n",
       "       'full_function': 'BusinessMonthEnd.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessMonthEnd.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.is_year_start.html#pandas.tseries.offsets.BusinessMonthEnd.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessMonthEnd.is_year_start',\n",
       "       'full_function': 'BusinessMonthEnd.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'BusinessMonthBegin': [{'func_name': 'BusinessMonthBegin',\n",
       "      'func_desc': 'DateOffset of one month at the first business day.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.html#pandas.tseries.offsets.BusinessMonthBegin',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessMonthBegin',\n",
       "       'full_function': 'class pandas.tseries.offsets.BusinessMonthBegin#',\n",
       "       'function_text': 'DateOffset of one month at the first business day. BusinessMonthBegin goes to the next date which is the first business day\\nof the month.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'The number of months represented.\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Normalize start/end dates to midnight before generating date range.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.BusinessMonthBegin',\n",
       "       'descriptions': 'DateOffset of one month at the first business day. BusinessMonthBegin goes to the next date which is the first business day\\nof the month.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 1. The number of months represented.\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Normalize start/end dates to midnight before generating date range.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'BMonthBegin',\n",
       "      'func_desc': 'alias of BusinessMonthBegin',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BMonthBegin.html#pandas.tseries.offsets.BMonthBegin',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BMonthBegin',\n",
       "       'full_function': 'pandas.tseries.offsets.BMonthBegin#',\n",
       "       'function_text': 'alias of BusinessMonthBegin',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessMonthBegin.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.freqstr.html#pandas.tseries.offsets.BusinessMonthBegin.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessMonthBegin.freqstr',\n",
       "       'full_function': 'BusinessMonthBegin.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessMonthBegin.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.name.html#pandas.tseries.offsets.BusinessMonthBegin.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessMonthBegin.name',\n",
       "       'full_function': 'BusinessMonthBegin.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessMonthBegin.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.normalize.html#pandas.tseries.offsets.BusinessMonthBegin.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessMonthBegin.normalize',\n",
       "       'full_function': 'BusinessMonthBegin.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessMonthBegin.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.n.html#pandas.tseries.offsets.BusinessMonthBegin.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessMonthBegin.n',\n",
       "       'full_function': 'BusinessMonthBegin.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessMonthBegin.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.copy.html#pandas.tseries.offsets.BusinessMonthBegin.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessMonthBegin.copy',\n",
       "       'full_function': 'BusinessMonthBegin.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessMonthBegin.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.is_on_offset.html#pandas.tseries.offsets.BusinessMonthBegin.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessMonthBegin.is_on_offset',\n",
       "       'full_function': 'BusinessMonthBegin.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.BusinessMonthBegin.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'BusinessMonthBegin.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.is_month_end.html#pandas.tseries.offsets.BusinessMonthBegin.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessMonthBegin.is_month_end',\n",
       "       'full_function': 'BusinessMonthBegin.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessMonthBegin.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.is_quarter_end.html#pandas.tseries.offsets.BusinessMonthBegin.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessMonthBegin.is_quarter_end',\n",
       "       'full_function': 'BusinessMonthBegin.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessMonthBegin.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.is_year_end.html#pandas.tseries.offsets.BusinessMonthBegin.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessMonthBegin.is_year_end',\n",
       "       'full_function': 'BusinessMonthBegin.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessMonthBegin.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.kwds.html#pandas.tseries.offsets.BusinessMonthBegin.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessMonthBegin.kwds',\n",
       "       'full_function': 'BusinessMonthBegin.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessMonthBegin.nanos',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.nanos.html#pandas.tseries.offsets.BusinessMonthBegin.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessMonthBegin.nanos',\n",
       "       'full_function': 'BusinessMonthBegin.nanos#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessMonthBegin.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.rule_code.html#pandas.tseries.offsets.BusinessMonthBegin.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessMonthBegin.rule_code',\n",
       "       'full_function': 'BusinessMonthBegin.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessMonthBegin.is_anchored()',\n",
       "      'func_desc': '(DEPRECATED) Return boolean whether the frequency is a unit frequency (n=1).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.is_anchored.html#pandas.tseries.offsets.BusinessMonthBegin.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessMonthBegin.is_anchored',\n",
       "       'full_function': 'BusinessMonthBegin.is_anchored()#',\n",
       "       'function_text': 'Return boolean whether the frequency is a unit frequency (n=1). Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse obj.n == 1 instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessMonthBegin.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.is_month_start.html#pandas.tseries.offsets.BusinessMonthBegin.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessMonthBegin.is_month_start',\n",
       "       'full_function': 'BusinessMonthBegin.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessMonthBegin.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.is_quarter_start.html#pandas.tseries.offsets.BusinessMonthBegin.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessMonthBegin.is_quarter_start',\n",
       "       'full_function': 'BusinessMonthBegin.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BusinessMonthBegin.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.is_year_start.html#pandas.tseries.offsets.BusinessMonthBegin.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BusinessMonthBegin.is_year_start',\n",
       "       'full_function': 'BusinessMonthBegin.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'CustomBusinessMonthEnd': [{'func_name': 'CustomBusinessMonthEnd',\n",
       "      'func_desc': 'DateOffset subclass representing custom business month(s).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.html#pandas.tseries.offsets.CustomBusinessMonthEnd',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthEnd',\n",
       "       'full_function': 'class pandas.tseries.offsets.CustomBusinessMonthEnd#',\n",
       "       'function_text': 'DateOffset subclass representing custom business month(s). Increments between end of month dates.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'The number of months represented.\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Normalize end dates to midnight before generating date range.\\n'},\n",
       "        {'param_name': 'weekmask',\n",
       "         'param_type': 'str, Default ‘Mon Tue Wed Thu Fri’',\n",
       "         'param_desc': 'Weekmask of valid business days, passed to numpy.busdaycalendar.\\n'},\n",
       "        {'param_name': 'holidays',\n",
       "         'param_type': 'list',\n",
       "         'param_desc': 'List/array of dates to exclude from the set of valid business days,\\npassed to numpy.busdaycalendar.\\n'},\n",
       "        {'param_name': 'calendar',\n",
       "         'param_type': 'np.busdaycalendar',\n",
       "         'param_desc': 'Calendar to integrate.\\n'},\n",
       "        {'param_name': 'offset',\n",
       "         'param_type': 'timedelta, default timedelta(0)',\n",
       "         'param_desc': 'Time offset to apply.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.CustomBusinessMonthEnd',\n",
       "       'descriptions': 'DateOffset subclass representing custom business month(s). Increments between end of month dates.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 1. The number of months represented.\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Normalize end dates to midnight before generating date range.\\n'},\n",
       "         'weekmask': {'type': 'string',\n",
       "          'description': 'str, Default ‘Mon Tue Wed Thu Fri’. Weekmask of valid business days, passed to numpy.busdaycalendar.\\n'},\n",
       "         'holidays': {'type': 'array',\n",
       "          'description': 'list. List/array of dates to exclude from the set of valid business days,\\npassed to numpy.busdaycalendar.\\n'},\n",
       "         'calendar': {'type': 'np.busdaycalendar',\n",
       "          'description': 'np.busdaycalendar. Calendar to integrate.\\n'},\n",
       "         'offset': {'type': 'timedelta, default timedelta(0)',\n",
       "          'description': 'timedelta, default timedelta(0). Time offset to apply.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'CBMonthEnd',\n",
       "      'func_desc': 'alias of CustomBusinessMonthEnd',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CBMonthEnd.html#pandas.tseries.offsets.CBMonthEnd',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CBMonthEnd',\n",
       "       'full_function': 'pandas.tseries.offsets.CBMonthEnd#',\n",
       "       'function_text': 'alias of CustomBusinessMonthEnd',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthEnd.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.freqstr.html#pandas.tseries.offsets.CustomBusinessMonthEnd.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthEnd.freqstr',\n",
       "       'full_function': 'CustomBusinessMonthEnd.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthEnd.m_offset',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.m_offset.html#pandas.tseries.offsets.CustomBusinessMonthEnd.m_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthEnd.m_offset',\n",
       "       'full_function': 'CustomBusinessMonthEnd.m_offset#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthEnd.nanos',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.nanos.html#pandas.tseries.offsets.CustomBusinessMonthEnd.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthEnd.nanos',\n",
       "       'full_function': 'CustomBusinessMonthEnd.nanos#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthEnd.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.rule_code.html#pandas.tseries.offsets.CustomBusinessMonthEnd.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthEnd.rule_code',\n",
       "       'full_function': 'CustomBusinessMonthEnd.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthEnd.weekmask',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.weekmask.html#pandas.tseries.offsets.CustomBusinessMonthEnd.weekmask',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthEnd.weekmask',\n",
       "       'full_function': 'CustomBusinessMonthEnd.weekmask#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthEnd.holidays',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.holidays.html#pandas.tseries.offsets.CustomBusinessMonthEnd.holidays',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthEnd.holidays',\n",
       "       'full_function': 'CustomBusinessMonthEnd.holidays#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthEnd.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.copy.html#pandas.tseries.offsets.CustomBusinessMonthEnd.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthEnd.copy',\n",
       "       'full_function': 'CustomBusinessMonthEnd.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthEnd.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.is_on_offset.html#pandas.tseries.offsets.CustomBusinessMonthEnd.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthEnd.is_on_offset',\n",
       "       'full_function': 'CustomBusinessMonthEnd.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.CustomBusinessMonthEnd.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'CustomBusinessMonthEnd.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.is_month_end.html#pandas.tseries.offsets.CustomBusinessMonthEnd.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthEnd.is_month_end',\n",
       "       'full_function': 'CustomBusinessMonthEnd.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthEnd.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.is_quarter_end.html#pandas.tseries.offsets.CustomBusinessMonthEnd.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthEnd.is_quarter_end',\n",
       "       'full_function': 'CustomBusinessMonthEnd.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthEnd.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.is_year_end.html#pandas.tseries.offsets.CustomBusinessMonthEnd.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthEnd.is_year_end',\n",
       "       'full_function': 'CustomBusinessMonthEnd.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthEnd.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.kwds.html#pandas.tseries.offsets.CustomBusinessMonthEnd.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthEnd.kwds',\n",
       "       'full_function': 'CustomBusinessMonthEnd.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthEnd.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.name.html#pandas.tseries.offsets.CustomBusinessMonthEnd.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthEnd.name',\n",
       "       'full_function': 'CustomBusinessMonthEnd.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthEnd.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.normalize.html#pandas.tseries.offsets.CustomBusinessMonthEnd.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthEnd.normalize',\n",
       "       'full_function': 'CustomBusinessMonthEnd.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthEnd.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.n.html#pandas.tseries.offsets.CustomBusinessMonthEnd.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthEnd.n',\n",
       "       'full_function': 'CustomBusinessMonthEnd.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthEnd.calendar',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.calendar.html#pandas.tseries.offsets.CustomBusinessMonthEnd.calendar',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthEnd.calendar',\n",
       "       'full_function': 'CustomBusinessMonthEnd.calendar#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthEnd.is_anchored()',\n",
       "      'func_desc': '(DEPRECATED) Return boolean whether the frequency is a unit frequency (n=1).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.is_anchored.html#pandas.tseries.offsets.CustomBusinessMonthEnd.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthEnd.is_anchored',\n",
       "       'full_function': 'CustomBusinessMonthEnd.is_anchored()#',\n",
       "       'function_text': 'Return boolean whether the frequency is a unit frequency (n=1). Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse obj.n == 1 instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthEnd.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.is_month_start.html#pandas.tseries.offsets.CustomBusinessMonthEnd.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthEnd.is_month_start',\n",
       "       'full_function': 'CustomBusinessMonthEnd.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthEnd.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.is_quarter_start.html#pandas.tseries.offsets.CustomBusinessMonthEnd.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthEnd.is_quarter_start',\n",
       "       'full_function': 'CustomBusinessMonthEnd.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthEnd.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.is_year_start.html#pandas.tseries.offsets.CustomBusinessMonthEnd.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthEnd.is_year_start',\n",
       "       'full_function': 'CustomBusinessMonthEnd.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'CustomBusinessMonthBegin': [{'func_name': 'CustomBusinessMonthBegin',\n",
       "      'func_desc': 'DateOffset subclass representing custom business month(s).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.html#pandas.tseries.offsets.CustomBusinessMonthBegin',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthBegin',\n",
       "       'full_function': 'class pandas.tseries.offsets.CustomBusinessMonthBegin#',\n",
       "       'function_text': 'DateOffset subclass representing custom business month(s). Increments between beginning of month dates.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'The number of months represented.\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Normalize start dates to midnight before generating date range.\\n'},\n",
       "        {'param_name': 'weekmask',\n",
       "         'param_type': 'str, Default ‘Mon Tue Wed Thu Fri’',\n",
       "         'param_desc': 'Weekmask of valid business days, passed to numpy.busdaycalendar.\\n'},\n",
       "        {'param_name': 'holidays',\n",
       "         'param_type': 'list',\n",
       "         'param_desc': 'List/array of dates to exclude from the set of valid business days,\\npassed to numpy.busdaycalendar.\\n'},\n",
       "        {'param_name': 'calendar',\n",
       "         'param_type': 'np.busdaycalendar',\n",
       "         'param_desc': 'Calendar to integrate.\\n'},\n",
       "        {'param_name': 'offset',\n",
       "         'param_type': 'timedelta, default timedelta(0)',\n",
       "         'param_desc': 'Time offset to apply.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.CustomBusinessMonthBegin',\n",
       "       'descriptions': 'DateOffset subclass representing custom business month(s). Increments between beginning of month dates.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 1. The number of months represented.\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Normalize start dates to midnight before generating date range.\\n'},\n",
       "         'weekmask': {'type': 'string',\n",
       "          'description': 'str, Default ‘Mon Tue Wed Thu Fri’. Weekmask of valid business days, passed to numpy.busdaycalendar.\\n'},\n",
       "         'holidays': {'type': 'array',\n",
       "          'description': 'list. List/array of dates to exclude from the set of valid business days,\\npassed to numpy.busdaycalendar.\\n'},\n",
       "         'calendar': {'type': 'np.busdaycalendar',\n",
       "          'description': 'np.busdaycalendar. Calendar to integrate.\\n'},\n",
       "         'offset': {'type': 'timedelta, default timedelta(0)',\n",
       "          'description': 'timedelta, default timedelta(0). Time offset to apply.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'CBMonthBegin',\n",
       "      'func_desc': 'alias of CustomBusinessMonthBegin',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CBMonthBegin.html#pandas.tseries.offsets.CBMonthBegin',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CBMonthBegin',\n",
       "       'full_function': 'pandas.tseries.offsets.CBMonthBegin#',\n",
       "       'function_text': 'alias of CustomBusinessMonthBegin',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthBegin.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.freqstr.html#pandas.tseries.offsets.CustomBusinessMonthBegin.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthBegin.freqstr',\n",
       "       'full_function': 'CustomBusinessMonthBegin.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthBegin.m_offset',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.m_offset.html#pandas.tseries.offsets.CustomBusinessMonthBegin.m_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthBegin.m_offset',\n",
       "       'full_function': 'CustomBusinessMonthBegin.m_offset#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthBegin.nanos',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.nanos.html#pandas.tseries.offsets.CustomBusinessMonthBegin.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthBegin.nanos',\n",
       "       'full_function': 'CustomBusinessMonthBegin.nanos#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthBegin.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.rule_code.html#pandas.tseries.offsets.CustomBusinessMonthBegin.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthBegin.rule_code',\n",
       "       'full_function': 'CustomBusinessMonthBegin.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthBegin.weekmask',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.weekmask.html#pandas.tseries.offsets.CustomBusinessMonthBegin.weekmask',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthBegin.weekmask',\n",
       "       'full_function': 'CustomBusinessMonthBegin.weekmask#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthBegin.holidays',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.holidays.html#pandas.tseries.offsets.CustomBusinessMonthBegin.holidays',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthBegin.holidays',\n",
       "       'full_function': 'CustomBusinessMonthBegin.holidays#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthBegin.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.copy.html#pandas.tseries.offsets.CustomBusinessMonthBegin.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthBegin.copy',\n",
       "       'full_function': 'CustomBusinessMonthBegin.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthBegin.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.is_on_offset.html#pandas.tseries.offsets.CustomBusinessMonthBegin.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthBegin.is_on_offset',\n",
       "       'full_function': 'CustomBusinessMonthBegin.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.CustomBusinessMonthBegin.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'CustomBusinessMonthBegin.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.is_month_end.html#pandas.tseries.offsets.CustomBusinessMonthBegin.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthBegin.is_month_end',\n",
       "       'full_function': 'CustomBusinessMonthBegin.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthBegin.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.is_quarter_end.html#pandas.tseries.offsets.CustomBusinessMonthBegin.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthBegin.is_quarter_end',\n",
       "       'full_function': 'CustomBusinessMonthBegin.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthBegin.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.is_year_end.html#pandas.tseries.offsets.CustomBusinessMonthBegin.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthBegin.is_year_end',\n",
       "       'full_function': 'CustomBusinessMonthBegin.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthBegin.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.kwds.html#pandas.tseries.offsets.CustomBusinessMonthBegin.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthBegin.kwds',\n",
       "       'full_function': 'CustomBusinessMonthBegin.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthBegin.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.name.html#pandas.tseries.offsets.CustomBusinessMonthBegin.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthBegin.name',\n",
       "       'full_function': 'CustomBusinessMonthBegin.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthBegin.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.normalize.html#pandas.tseries.offsets.CustomBusinessMonthBegin.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthBegin.normalize',\n",
       "       'full_function': 'CustomBusinessMonthBegin.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthBegin.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.n.html#pandas.tseries.offsets.CustomBusinessMonthBegin.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthBegin.n',\n",
       "       'full_function': 'CustomBusinessMonthBegin.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthBegin.calendar',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.calendar.html#pandas.tseries.offsets.CustomBusinessMonthBegin.calendar',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthBegin.calendar',\n",
       "       'full_function': 'CustomBusinessMonthBegin.calendar#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthBegin.is_anchored()',\n",
       "      'func_desc': '(DEPRECATED) Return boolean whether the frequency is a unit frequency (n=1).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.is_anchored.html#pandas.tseries.offsets.CustomBusinessMonthBegin.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthBegin.is_anchored',\n",
       "       'full_function': 'CustomBusinessMonthBegin.is_anchored()#',\n",
       "       'function_text': 'Return boolean whether the frequency is a unit frequency (n=1). Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse obj.n == 1 instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthBegin.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.is_month_start.html#pandas.tseries.offsets.CustomBusinessMonthBegin.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthBegin.is_month_start',\n",
       "       'full_function': 'CustomBusinessMonthBegin.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthBegin.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.is_quarter_start.html#pandas.tseries.offsets.CustomBusinessMonthBegin.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthBegin.is_quarter_start',\n",
       "       'full_function': 'CustomBusinessMonthBegin.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'CustomBusinessMonthBegin.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.is_year_start.html#pandas.tseries.offsets.CustomBusinessMonthBegin.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.CustomBusinessMonthBegin.is_year_start',\n",
       "       'full_function': 'CustomBusinessMonthBegin.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'SemiMonthEnd': [{'func_name': 'SemiMonthEnd',\n",
       "      'func_desc': \"Two DateOffset's per month repeating on the last day of the month & day_of_month.\",\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.html#pandas.tseries.offsets.SemiMonthEnd',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthEnd',\n",
       "       'full_function': 'class pandas.tseries.offsets.SemiMonthEnd#',\n",
       "       'function_text': 'Two DateOffset’s per month repeating on the last day of the month & day_of_month.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'The number of months represented.\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "        {'param_name': 'day_of_month',\n",
       "         'param_type': 'int, {1, 3,…,27}, default 15',\n",
       "         'param_desc': 'A specific integer for the day of the month.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.SemiMonthEnd',\n",
       "       'descriptions': 'Two DateOffset’s per month repeating on the last day of the month & day_of_month.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 1. The number of months represented.\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "         'day_of_month': {'type': 'integer',\n",
       "          'description': 'int, {1, 3,…,27}, default 15. A specific integer for the day of the month.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SemiMonthEnd.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.freqstr.html#pandas.tseries.offsets.SemiMonthEnd.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthEnd.freqstr',\n",
       "       'full_function': 'SemiMonthEnd.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SemiMonthEnd.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.name.html#pandas.tseries.offsets.SemiMonthEnd.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthEnd.name',\n",
       "       'full_function': 'SemiMonthEnd.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SemiMonthEnd.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.normalize.html#pandas.tseries.offsets.SemiMonthEnd.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthEnd.normalize',\n",
       "       'full_function': 'SemiMonthEnd.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SemiMonthEnd.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.n.html#pandas.tseries.offsets.SemiMonthEnd.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthEnd.n',\n",
       "       'full_function': 'SemiMonthEnd.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SemiMonthEnd.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.copy.html#pandas.tseries.offsets.SemiMonthEnd.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthEnd.copy',\n",
       "       'full_function': 'SemiMonthEnd.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SemiMonthEnd.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.is_on_offset.html#pandas.tseries.offsets.SemiMonthEnd.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthEnd.is_on_offset',\n",
       "       'full_function': 'SemiMonthEnd.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.SemiMonthEnd.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SemiMonthEnd.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.is_month_end.html#pandas.tseries.offsets.SemiMonthEnd.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthEnd.is_month_end',\n",
       "       'full_function': 'SemiMonthEnd.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SemiMonthEnd.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.is_quarter_end.html#pandas.tseries.offsets.SemiMonthEnd.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthEnd.is_quarter_end',\n",
       "       'full_function': 'SemiMonthEnd.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SemiMonthEnd.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.is_year_end.html#pandas.tseries.offsets.SemiMonthEnd.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthEnd.is_year_end',\n",
       "       'full_function': 'SemiMonthEnd.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SemiMonthEnd.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.kwds.html#pandas.tseries.offsets.SemiMonthEnd.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthEnd.kwds',\n",
       "       'full_function': 'SemiMonthEnd.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SemiMonthEnd.nanos',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.nanos.html#pandas.tseries.offsets.SemiMonthEnd.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthEnd.nanos',\n",
       "       'full_function': 'SemiMonthEnd.nanos#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SemiMonthEnd.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.rule_code.html#pandas.tseries.offsets.SemiMonthEnd.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthEnd.rule_code',\n",
       "       'full_function': 'SemiMonthEnd.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SemiMonthEnd.day_of_month',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.day_of_month.html#pandas.tseries.offsets.SemiMonthEnd.day_of_month',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthEnd.day_of_month',\n",
       "       'full_function': 'SemiMonthEnd.day_of_month#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SemiMonthEnd.is_anchored()',\n",
       "      'func_desc': '(DEPRECATED) Return boolean whether the frequency is a unit frequency (n=1).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.is_anchored.html#pandas.tseries.offsets.SemiMonthEnd.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthEnd.is_anchored',\n",
       "       'full_function': 'SemiMonthEnd.is_anchored()#',\n",
       "       'function_text': 'Return boolean whether the frequency is a unit frequency (n=1). Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse obj.n == 1 instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SemiMonthEnd.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.is_month_start.html#pandas.tseries.offsets.SemiMonthEnd.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthEnd.is_month_start',\n",
       "       'full_function': 'SemiMonthEnd.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SemiMonthEnd.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.is_quarter_start.html#pandas.tseries.offsets.SemiMonthEnd.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthEnd.is_quarter_start',\n",
       "       'full_function': 'SemiMonthEnd.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SemiMonthEnd.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.is_year_start.html#pandas.tseries.offsets.SemiMonthEnd.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthEnd.is_year_start',\n",
       "       'full_function': 'SemiMonthEnd.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'SemiMonthBegin': [{'func_name': 'SemiMonthBegin',\n",
       "      'func_desc': \"Two DateOffset's per month repeating on the first day of the month & day_of_month.\",\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.html#pandas.tseries.offsets.SemiMonthBegin',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthBegin',\n",
       "       'full_function': 'class pandas.tseries.offsets.SemiMonthBegin#',\n",
       "       'function_text': 'Two DateOffset’s per month repeating on the first day of the month & day_of_month.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'The number of months represented.\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "        {'param_name': 'day_of_month',\n",
       "         'param_type': 'int, {1, 3,…,27}, default 15',\n",
       "         'param_desc': 'A specific integer for the day of the month.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.SemiMonthBegin',\n",
       "       'descriptions': 'Two DateOffset’s per month repeating on the first day of the month & day_of_month.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 1. The number of months represented.\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "         'day_of_month': {'type': 'integer',\n",
       "          'description': 'int, {1, 3,…,27}, default 15. A specific integer for the day of the month.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SemiMonthBegin.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.freqstr.html#pandas.tseries.offsets.SemiMonthBegin.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthBegin.freqstr',\n",
       "       'full_function': 'SemiMonthBegin.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SemiMonthBegin.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.name.html#pandas.tseries.offsets.SemiMonthBegin.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthBegin.name',\n",
       "       'full_function': 'SemiMonthBegin.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SemiMonthBegin.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.normalize.html#pandas.tseries.offsets.SemiMonthBegin.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthBegin.normalize',\n",
       "       'full_function': 'SemiMonthBegin.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SemiMonthBegin.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.n.html#pandas.tseries.offsets.SemiMonthBegin.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthBegin.n',\n",
       "       'full_function': 'SemiMonthBegin.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SemiMonthBegin.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.copy.html#pandas.tseries.offsets.SemiMonthBegin.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthBegin.copy',\n",
       "       'full_function': 'SemiMonthBegin.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SemiMonthBegin.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.is_on_offset.html#pandas.tseries.offsets.SemiMonthBegin.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthBegin.is_on_offset',\n",
       "       'full_function': 'SemiMonthBegin.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.SemiMonthBegin.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SemiMonthBegin.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.is_month_end.html#pandas.tseries.offsets.SemiMonthBegin.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthBegin.is_month_end',\n",
       "       'full_function': 'SemiMonthBegin.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SemiMonthBegin.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.is_quarter_end.html#pandas.tseries.offsets.SemiMonthBegin.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthBegin.is_quarter_end',\n",
       "       'full_function': 'SemiMonthBegin.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SemiMonthBegin.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.is_year_end.html#pandas.tseries.offsets.SemiMonthBegin.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthBegin.is_year_end',\n",
       "       'full_function': 'SemiMonthBegin.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SemiMonthBegin.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.kwds.html#pandas.tseries.offsets.SemiMonthBegin.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthBegin.kwds',\n",
       "       'full_function': 'SemiMonthBegin.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SemiMonthBegin.nanos',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.nanos.html#pandas.tseries.offsets.SemiMonthBegin.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthBegin.nanos',\n",
       "       'full_function': 'SemiMonthBegin.nanos#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SemiMonthBegin.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.rule_code.html#pandas.tseries.offsets.SemiMonthBegin.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthBegin.rule_code',\n",
       "       'full_function': 'SemiMonthBegin.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SemiMonthBegin.day_of_month',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.day_of_month.html#pandas.tseries.offsets.SemiMonthBegin.day_of_month',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthBegin.day_of_month',\n",
       "       'full_function': 'SemiMonthBegin.day_of_month#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SemiMonthBegin.is_anchored()',\n",
       "      'func_desc': '(DEPRECATED) Return boolean whether the frequency is a unit frequency (n=1).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.is_anchored.html#pandas.tseries.offsets.SemiMonthBegin.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthBegin.is_anchored',\n",
       "       'full_function': 'SemiMonthBegin.is_anchored()#',\n",
       "       'function_text': 'Return boolean whether the frequency is a unit frequency (n=1). Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse obj.n == 1 instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SemiMonthBegin.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.is_month_start.html#pandas.tseries.offsets.SemiMonthBegin.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthBegin.is_month_start',\n",
       "       'full_function': 'SemiMonthBegin.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SemiMonthBegin.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.is_quarter_start.html#pandas.tseries.offsets.SemiMonthBegin.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthBegin.is_quarter_start',\n",
       "       'full_function': 'SemiMonthBegin.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SemiMonthBegin.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.is_year_start.html#pandas.tseries.offsets.SemiMonthBegin.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.SemiMonthBegin.is_year_start',\n",
       "       'full_function': 'SemiMonthBegin.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'Week': [{'func_name': 'Week',\n",
       "      'func_desc': 'Weekly offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.html#pandas.tseries.offsets.Week',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Week',\n",
       "       'full_function': 'class pandas.tseries.offsets.Week#',\n",
       "       'function_text': 'Weekly offset.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'The number of weeks represented.\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "        {'param_name': 'weekday',\n",
       "         'param_type': 'int or None, default None',\n",
       "         'param_desc': 'Always generate specific day of week.\\n0 for Monday and 6 for Sunday.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.Week',\n",
       "       'descriptions': 'Weekly offset.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 1. The number of weeks represented.\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "         'weekday': {'type': 'integer',\n",
       "          'description': 'int or None, default None. Always generate specific day of week.\\n0 for Monday and 6 for Sunday.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Week.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.freqstr.html#pandas.tseries.offsets.Week.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Week.freqstr',\n",
       "       'full_function': 'Week.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Week.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.name.html#pandas.tseries.offsets.Week.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Week.name',\n",
       "       'full_function': 'Week.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Week.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.normalize.html#pandas.tseries.offsets.Week.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Week.normalize',\n",
       "       'full_function': 'Week.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Week.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.n.html#pandas.tseries.offsets.Week.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Week.n',\n",
       "       'full_function': 'Week.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Week.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.copy.html#pandas.tseries.offsets.Week.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Week.copy',\n",
       "       'full_function': 'Week.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Week.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.is_on_offset.html#pandas.tseries.offsets.Week.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Week.is_on_offset',\n",
       "       'full_function': 'Week.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.Week.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Week.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.is_month_end.html#pandas.tseries.offsets.Week.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Week.is_month_end',\n",
       "       'full_function': 'Week.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Week.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.is_quarter_end.html#pandas.tseries.offsets.Week.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Week.is_quarter_end',\n",
       "       'full_function': 'Week.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Week.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.is_year_end.html#pandas.tseries.offsets.Week.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Week.is_year_end',\n",
       "       'full_function': 'Week.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Week.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.kwds.html#pandas.tseries.offsets.Week.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Week.kwds',\n",
       "       'full_function': 'Week.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Week.nanos',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.nanos.html#pandas.tseries.offsets.Week.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Week.nanos',\n",
       "       'full_function': 'Week.nanos#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Week.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.rule_code.html#pandas.tseries.offsets.Week.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Week.rule_code',\n",
       "       'full_function': 'Week.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Week.weekday',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.weekday.html#pandas.tseries.offsets.Week.weekday',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Week.weekday',\n",
       "       'full_function': 'Week.weekday#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Week.is_anchored()',\n",
       "      'func_desc': 'Return boolean whether the frequency is a unit frequency (n=1).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.is_anchored.html#pandas.tseries.offsets.Week.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Week.is_anchored',\n",
       "       'full_function': 'Week.is_anchored()#',\n",
       "       'function_text': 'Return boolean whether the frequency is a unit frequency (n=1). Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse obj.n == 1 instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Week.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.is_month_start.html#pandas.tseries.offsets.Week.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Week.is_month_start',\n",
       "       'full_function': 'Week.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Week.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.is_quarter_start.html#pandas.tseries.offsets.Week.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Week.is_quarter_start',\n",
       "       'full_function': 'Week.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Week.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.is_year_start.html#pandas.tseries.offsets.Week.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Week.is_year_start',\n",
       "       'full_function': 'Week.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'WeekOfMonth': [{'func_name': 'WeekOfMonth',\n",
       "      'func_desc': 'Describes monthly dates like \"the Tuesday of the 2nd week of each month\".',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.html#pandas.tseries.offsets.WeekOfMonth',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.WeekOfMonth',\n",
       "       'full_function': 'class pandas.tseries.offsets.WeekOfMonth#',\n",
       "       'function_text': 'Describes monthly dates like “the Tuesday of the 2nd week of each month”.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'The number of months represented.\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "        {'param_name': 'week',\n",
       "         'param_type': 'int {0, 1, 2, 3, …}, default 0',\n",
       "         'param_desc': 'A specific integer for the week of the month.\\ne.g. 0 is 1st week of month, 1 is the 2nd week, etc.\\n'},\n",
       "        {'param_name': 'weekday',\n",
       "         'param_type': 'int {0, 1, …, 6}, default 0',\n",
       "         'param_desc': 'A specific integer for the day of the week.\\n\\n0 is Monday\\n1 is Tuesday\\n2 is Wednesday\\n3 is Thursday\\n4 is Friday\\n5 is Saturday\\n6 is Sunday.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.WeekOfMonth',\n",
       "       'descriptions': 'Describes monthly dates like “the Tuesday of the 2nd week of each month”.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 1. The number of months represented.\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "         'week': {'type': 'integer',\n",
       "          'description': 'int {0, 1, 2, 3, …}, default 0. A specific integer for the week of the month.\\ne.g. 0 is 1st week of month, 1 is the 2nd week, etc.\\n'},\n",
       "         'weekday': {'type': 'integer',\n",
       "          'description': 'int {0, 1, …, 6}, default 0. A specific integer for the day of the week.\\n\\n0 is Monday\\n1 is Tuesday\\n2 is Wednesday\\n3 is Thursday\\n4 is Friday\\n5 is Saturday\\n6 is Sunday.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'WeekOfMonth.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.freqstr.html#pandas.tseries.offsets.WeekOfMonth.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.WeekOfMonth.freqstr',\n",
       "       'full_function': 'WeekOfMonth.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'WeekOfMonth.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.name.html#pandas.tseries.offsets.WeekOfMonth.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.WeekOfMonth.name',\n",
       "       'full_function': 'WeekOfMonth.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'WeekOfMonth.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.normalize.html#pandas.tseries.offsets.WeekOfMonth.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.WeekOfMonth.normalize',\n",
       "       'full_function': 'WeekOfMonth.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'WeekOfMonth.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.n.html#pandas.tseries.offsets.WeekOfMonth.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.WeekOfMonth.n',\n",
       "       'full_function': 'WeekOfMonth.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'WeekOfMonth.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.copy.html#pandas.tseries.offsets.WeekOfMonth.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.WeekOfMonth.copy',\n",
       "       'full_function': 'WeekOfMonth.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'WeekOfMonth.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.is_on_offset.html#pandas.tseries.offsets.WeekOfMonth.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.WeekOfMonth.is_on_offset',\n",
       "       'full_function': 'WeekOfMonth.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.WeekOfMonth.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'WeekOfMonth.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.is_month_start.html#pandas.tseries.offsets.WeekOfMonth.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.WeekOfMonth.is_month_start',\n",
       "       'full_function': 'WeekOfMonth.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'WeekOfMonth.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.is_quarter_start.html#pandas.tseries.offsets.WeekOfMonth.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.WeekOfMonth.is_quarter_start',\n",
       "       'full_function': 'WeekOfMonth.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'WeekOfMonth.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.is_year_start.html#pandas.tseries.offsets.WeekOfMonth.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.WeekOfMonth.is_year_start',\n",
       "       'full_function': 'WeekOfMonth.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'WeekOfMonth.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.kwds.html#pandas.tseries.offsets.WeekOfMonth.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.WeekOfMonth.kwds',\n",
       "       'full_function': 'WeekOfMonth.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'WeekOfMonth.nanos',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.nanos.html#pandas.tseries.offsets.WeekOfMonth.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.WeekOfMonth.nanos',\n",
       "       'full_function': 'WeekOfMonth.nanos#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'WeekOfMonth.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.rule_code.html#pandas.tseries.offsets.WeekOfMonth.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.WeekOfMonth.rule_code',\n",
       "       'full_function': 'WeekOfMonth.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'WeekOfMonth.week',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.week.html#pandas.tseries.offsets.WeekOfMonth.week',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.WeekOfMonth.week',\n",
       "       'full_function': 'WeekOfMonth.week#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'WeekOfMonth.is_anchored()',\n",
       "      'func_desc': '(DEPRECATED) Return boolean whether the frequency is a unit frequency (n=1).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.is_anchored.html#pandas.tseries.offsets.WeekOfMonth.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.WeekOfMonth.is_anchored',\n",
       "       'full_function': 'WeekOfMonth.is_anchored()#',\n",
       "       'function_text': 'Return boolean whether the frequency is a unit frequency (n=1). Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse obj.n == 1 instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'WeekOfMonth.weekday',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.weekday.html#pandas.tseries.offsets.WeekOfMonth.weekday',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.WeekOfMonth.weekday',\n",
       "       'full_function': 'WeekOfMonth.weekday#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'WeekOfMonth.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.is_month_end.html#pandas.tseries.offsets.WeekOfMonth.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.WeekOfMonth.is_month_end',\n",
       "       'full_function': 'WeekOfMonth.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'WeekOfMonth.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.is_quarter_end.html#pandas.tseries.offsets.WeekOfMonth.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.WeekOfMonth.is_quarter_end',\n",
       "       'full_function': 'WeekOfMonth.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'WeekOfMonth.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.is_year_end.html#pandas.tseries.offsets.WeekOfMonth.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.WeekOfMonth.is_year_end',\n",
       "       'full_function': 'WeekOfMonth.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'LastWeekOfMonth': [{'func_name': 'LastWeekOfMonth',\n",
       "      'func_desc': 'Describes monthly dates in last week of month.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.html#pandas.tseries.offsets.LastWeekOfMonth',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.LastWeekOfMonth',\n",
       "       'full_function': 'class pandas.tseries.offsets.LastWeekOfMonth#',\n",
       "       'function_text': 'Describes monthly dates in last week of month. For example “the last Tuesday of each month”.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'The number of months represented.\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "        {'param_name': 'weekday',\n",
       "         'param_type': 'int {0, 1, …, 6}, default 0',\n",
       "         'param_desc': 'A specific integer for the day of the week.\\n\\n0 is Monday\\n1 is Tuesday\\n2 is Wednesday\\n3 is Thursday\\n4 is Friday\\n5 is Saturday\\n6 is Sunday.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.LastWeekOfMonth',\n",
       "       'descriptions': 'Describes monthly dates in last week of month. For example “the last Tuesday of each month”.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 1. The number of months represented.\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "         'weekday': {'type': 'integer',\n",
       "          'description': 'int {0, 1, …, 6}, default 0. A specific integer for the day of the week.\\n\\n0 is Monday\\n1 is Tuesday\\n2 is Wednesday\\n3 is Thursday\\n4 is Friday\\n5 is Saturday\\n6 is Sunday.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'LastWeekOfMonth.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.freqstr.html#pandas.tseries.offsets.LastWeekOfMonth.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.LastWeekOfMonth.freqstr',\n",
       "       'full_function': 'LastWeekOfMonth.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'LastWeekOfMonth.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.name.html#pandas.tseries.offsets.LastWeekOfMonth.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.LastWeekOfMonth.name',\n",
       "       'full_function': 'LastWeekOfMonth.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'LastWeekOfMonth.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.normalize.html#pandas.tseries.offsets.LastWeekOfMonth.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.LastWeekOfMonth.normalize',\n",
       "       'full_function': 'LastWeekOfMonth.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'LastWeekOfMonth.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.n.html#pandas.tseries.offsets.LastWeekOfMonth.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.LastWeekOfMonth.n',\n",
       "       'full_function': 'LastWeekOfMonth.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'LastWeekOfMonth.week',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.week.html#pandas.tseries.offsets.LastWeekOfMonth.week',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.LastWeekOfMonth.week',\n",
       "       'full_function': 'LastWeekOfMonth.week#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'LastWeekOfMonth.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.copy.html#pandas.tseries.offsets.LastWeekOfMonth.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.LastWeekOfMonth.copy',\n",
       "       'full_function': 'LastWeekOfMonth.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'LastWeekOfMonth.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.is_on_offset.html#pandas.tseries.offsets.LastWeekOfMonth.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.LastWeekOfMonth.is_on_offset',\n",
       "       'full_function': 'LastWeekOfMonth.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.LastWeekOfMonth.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'LastWeekOfMonth.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.is_month_end.html#pandas.tseries.offsets.LastWeekOfMonth.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.LastWeekOfMonth.is_month_end',\n",
       "       'full_function': 'LastWeekOfMonth.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'LastWeekOfMonth.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.is_quarter_end.html#pandas.tseries.offsets.LastWeekOfMonth.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.LastWeekOfMonth.is_quarter_end',\n",
       "       'full_function': 'LastWeekOfMonth.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'LastWeekOfMonth.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.is_year_end.html#pandas.tseries.offsets.LastWeekOfMonth.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.LastWeekOfMonth.is_year_end',\n",
       "       'full_function': 'LastWeekOfMonth.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'LastWeekOfMonth.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.kwds.html#pandas.tseries.offsets.LastWeekOfMonth.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.LastWeekOfMonth.kwds',\n",
       "       'full_function': 'LastWeekOfMonth.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'LastWeekOfMonth.nanos',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.nanos.html#pandas.tseries.offsets.LastWeekOfMonth.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.LastWeekOfMonth.nanos',\n",
       "       'full_function': 'LastWeekOfMonth.nanos#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'LastWeekOfMonth.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.rule_code.html#pandas.tseries.offsets.LastWeekOfMonth.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.LastWeekOfMonth.rule_code',\n",
       "       'full_function': 'LastWeekOfMonth.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'LastWeekOfMonth.weekday',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.weekday.html#pandas.tseries.offsets.LastWeekOfMonth.weekday',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.LastWeekOfMonth.weekday',\n",
       "       'full_function': 'LastWeekOfMonth.weekday#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'LastWeekOfMonth.is_anchored()',\n",
       "      'func_desc': '(DEPRECATED) Return boolean whether the frequency is a unit frequency (n=1).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.is_anchored.html#pandas.tseries.offsets.LastWeekOfMonth.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.LastWeekOfMonth.is_anchored',\n",
       "       'full_function': 'LastWeekOfMonth.is_anchored()#',\n",
       "       'function_text': 'Return boolean whether the frequency is a unit frequency (n=1). Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse obj.n == 1 instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'LastWeekOfMonth.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.is_month_start.html#pandas.tseries.offsets.LastWeekOfMonth.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.LastWeekOfMonth.is_month_start',\n",
       "       'full_function': 'LastWeekOfMonth.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'LastWeekOfMonth.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.is_quarter_start.html#pandas.tseries.offsets.LastWeekOfMonth.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.LastWeekOfMonth.is_quarter_start',\n",
       "       'full_function': 'LastWeekOfMonth.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'LastWeekOfMonth.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.is_year_start.html#pandas.tseries.offsets.LastWeekOfMonth.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.LastWeekOfMonth.is_year_start',\n",
       "       'full_function': 'LastWeekOfMonth.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'BQuarterEnd': [{'func_name': 'BQuarterEnd',\n",
       "      'func_desc': 'DateOffset increments between the last business day of each Quarter.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.html#pandas.tseries.offsets.BQuarterEnd',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterEnd',\n",
       "       'full_function': 'class pandas.tseries.offsets.BQuarterEnd#',\n",
       "       'function_text': 'DateOffset increments between the last business day of each Quarter. startingMonth = 1 corresponds to dates like 1/31/2007, 4/30/2007, …\\nstartingMonth = 2 corresponds to dates like 2/28/2007, 5/31/2007, …\\nstartingMonth = 3 corresponds to dates like 3/30/2007, 6/29/2007, …',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'The number of quarters represented.\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "        {'param_name': 'startingMonth',\n",
       "         'param_type': 'int, default 3',\n",
       "         'param_desc': 'A specific integer for the month of the year from which we start quarters.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.BQuarterEnd',\n",
       "       'descriptions': 'DateOffset increments between the last business day of each Quarter. startingMonth = 1 corresponds to dates like 1/31/2007, 4/30/2007, …\\nstartingMonth = 2 corresponds to dates like 2/28/2007, 5/31/2007, …\\nstartingMonth = 3 corresponds to dates like 3/30/2007, 6/29/2007, …',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 1. The number of quarters represented.\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "         'startingMonth': {'type': 'integer',\n",
       "          'description': 'int, default 3. A specific integer for the month of the year from which we start quarters.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'BQuarterEnd.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.freqstr.html#pandas.tseries.offsets.BQuarterEnd.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterEnd.freqstr',\n",
       "       'full_function': 'BQuarterEnd.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BQuarterEnd.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.name.html#pandas.tseries.offsets.BQuarterEnd.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterEnd.name',\n",
       "       'full_function': 'BQuarterEnd.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BQuarterEnd.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.normalize.html#pandas.tseries.offsets.BQuarterEnd.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterEnd.normalize',\n",
       "       'full_function': 'BQuarterEnd.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BQuarterEnd.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.n.html#pandas.tseries.offsets.BQuarterEnd.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterEnd.n',\n",
       "       'full_function': 'BQuarterEnd.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BQuarterEnd.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.copy.html#pandas.tseries.offsets.BQuarterEnd.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterEnd.copy',\n",
       "       'full_function': 'BQuarterEnd.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BQuarterEnd.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.is_on_offset.html#pandas.tseries.offsets.BQuarterEnd.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterEnd.is_on_offset',\n",
       "       'full_function': 'BQuarterEnd.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.BQuarterEnd.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'BQuarterEnd.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.is_month_end.html#pandas.tseries.offsets.BQuarterEnd.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterEnd.is_month_end',\n",
       "       'full_function': 'BQuarterEnd.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BQuarterEnd.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.is_quarter_end.html#pandas.tseries.offsets.BQuarterEnd.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterEnd.is_quarter_end',\n",
       "       'full_function': 'BQuarterEnd.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BQuarterEnd.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.is_year_end.html#pandas.tseries.offsets.BQuarterEnd.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterEnd.is_year_end',\n",
       "       'full_function': 'BQuarterEnd.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BQuarterEnd.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.kwds.html#pandas.tseries.offsets.BQuarterEnd.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterEnd.kwds',\n",
       "       'full_function': 'BQuarterEnd.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BQuarterEnd.nanos',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.nanos.html#pandas.tseries.offsets.BQuarterEnd.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterEnd.nanos',\n",
       "       'full_function': 'BQuarterEnd.nanos#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BQuarterEnd.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.rule_code.html#pandas.tseries.offsets.BQuarterEnd.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterEnd.rule_code',\n",
       "       'full_function': 'BQuarterEnd.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BQuarterEnd.startingMonth',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.startingMonth.html#pandas.tseries.offsets.BQuarterEnd.startingMonth',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterEnd.startingMonth',\n",
       "       'full_function': 'BQuarterEnd.startingMonth#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BQuarterEnd.is_anchored()',\n",
       "      'func_desc': 'Return boolean whether the frequency is a unit frequency (n=1).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.is_anchored.html#pandas.tseries.offsets.BQuarterEnd.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterEnd.is_anchored',\n",
       "       'full_function': 'BQuarterEnd.is_anchored()#',\n",
       "       'function_text': 'Return boolean whether the frequency is a unit frequency (n=1). Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse obj.n == 1 instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BQuarterEnd.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.is_month_start.html#pandas.tseries.offsets.BQuarterEnd.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterEnd.is_month_start',\n",
       "       'full_function': 'BQuarterEnd.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BQuarterEnd.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.is_quarter_start.html#pandas.tseries.offsets.BQuarterEnd.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterEnd.is_quarter_start',\n",
       "       'full_function': 'BQuarterEnd.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BQuarterEnd.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.is_year_start.html#pandas.tseries.offsets.BQuarterEnd.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterEnd.is_year_start',\n",
       "       'full_function': 'BQuarterEnd.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'BQuarterBegin': [{'func_name': 'BQuarterBegin',\n",
       "      'func_desc': 'DateOffset increments between the first business day of each Quarter.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.html#pandas.tseries.offsets.BQuarterBegin',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterBegin',\n",
       "       'full_function': 'class pandas.tseries.offsets.BQuarterBegin#',\n",
       "       'function_text': 'DateOffset increments between the first business day of each Quarter. startingMonth = 1 corresponds to dates like 1/01/2007, 4/01/2007, …\\nstartingMonth = 2 corresponds to dates like 2/01/2007, 5/01/2007, …\\nstartingMonth = 3 corresponds to dates like 3/01/2007, 6/01/2007, …',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'The number of quarters represented.\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "        {'param_name': 'startingMonth',\n",
       "         'param_type': 'int, default 3',\n",
       "         'param_desc': 'A specific integer for the month of the year from which we start quarters.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.BQuarterBegin',\n",
       "       'descriptions': 'DateOffset increments between the first business day of each Quarter. startingMonth = 1 corresponds to dates like 1/01/2007, 4/01/2007, …\\nstartingMonth = 2 corresponds to dates like 2/01/2007, 5/01/2007, …\\nstartingMonth = 3 corresponds to dates like 3/01/2007, 6/01/2007, …',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 1. The number of quarters represented.\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "         'startingMonth': {'type': 'integer',\n",
       "          'description': 'int, default 3. A specific integer for the month of the year from which we start quarters.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'BQuarterBegin.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.freqstr.html#pandas.tseries.offsets.BQuarterBegin.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterBegin.freqstr',\n",
       "       'full_function': 'BQuarterBegin.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BQuarterBegin.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.name.html#pandas.tseries.offsets.BQuarterBegin.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterBegin.name',\n",
       "       'full_function': 'BQuarterBegin.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BQuarterBegin.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.normalize.html#pandas.tseries.offsets.BQuarterBegin.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterBegin.normalize',\n",
       "       'full_function': 'BQuarterBegin.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BQuarterBegin.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.n.html#pandas.tseries.offsets.BQuarterBegin.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterBegin.n',\n",
       "       'full_function': 'BQuarterBegin.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BQuarterBegin.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.copy.html#pandas.tseries.offsets.BQuarterBegin.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterBegin.copy',\n",
       "       'full_function': 'BQuarterBegin.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BQuarterBegin.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.is_on_offset.html#pandas.tseries.offsets.BQuarterBegin.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterBegin.is_on_offset',\n",
       "       'full_function': 'BQuarterBegin.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.BQuarterBegin.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'BQuarterBegin.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.is_month_end.html#pandas.tseries.offsets.BQuarterBegin.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterBegin.is_month_end',\n",
       "       'full_function': 'BQuarterBegin.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BQuarterBegin.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.is_quarter_end.html#pandas.tseries.offsets.BQuarterBegin.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterBegin.is_quarter_end',\n",
       "       'full_function': 'BQuarterBegin.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BQuarterBegin.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.is_year_end.html#pandas.tseries.offsets.BQuarterBegin.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterBegin.is_year_end',\n",
       "       'full_function': 'BQuarterBegin.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BQuarterBegin.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.kwds.html#pandas.tseries.offsets.BQuarterBegin.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterBegin.kwds',\n",
       "       'full_function': 'BQuarterBegin.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BQuarterBegin.nanos',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.nanos.html#pandas.tseries.offsets.BQuarterBegin.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterBegin.nanos',\n",
       "       'full_function': 'BQuarterBegin.nanos#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BQuarterBegin.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.rule_code.html#pandas.tseries.offsets.BQuarterBegin.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterBegin.rule_code',\n",
       "       'full_function': 'BQuarterBegin.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BQuarterBegin.startingMonth',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.startingMonth.html#pandas.tseries.offsets.BQuarterBegin.startingMonth',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterBegin.startingMonth',\n",
       "       'full_function': 'BQuarterBegin.startingMonth#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BQuarterBegin.is_anchored()',\n",
       "      'func_desc': 'Return boolean whether the frequency is a unit frequency (n=1).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.is_anchored.html#pandas.tseries.offsets.BQuarterBegin.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterBegin.is_anchored',\n",
       "       'full_function': 'BQuarterBegin.is_anchored()#',\n",
       "       'function_text': 'Return boolean whether the frequency is a unit frequency (n=1). Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse obj.n == 1 instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BQuarterBegin.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.is_month_start.html#pandas.tseries.offsets.BQuarterBegin.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterBegin.is_month_start',\n",
       "       'full_function': 'BQuarterBegin.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BQuarterBegin.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.is_quarter_start.html#pandas.tseries.offsets.BQuarterBegin.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterBegin.is_quarter_start',\n",
       "       'full_function': 'BQuarterBegin.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BQuarterBegin.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.is_year_start.html#pandas.tseries.offsets.BQuarterBegin.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BQuarterBegin.is_year_start',\n",
       "       'full_function': 'BQuarterBegin.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'QuarterEnd': [{'func_name': 'QuarterEnd',\n",
       "      'func_desc': 'DateOffset increments between Quarter end dates.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.html#pandas.tseries.offsets.QuarterEnd',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterEnd',\n",
       "       'full_function': 'class pandas.tseries.offsets.QuarterEnd#',\n",
       "       'function_text': 'DateOffset increments between Quarter end dates. startingMonth = 1 corresponds to dates like 1/31/2007, 4/30/2007, …\\nstartingMonth = 2 corresponds to dates like 2/28/2007, 5/31/2007, …\\nstartingMonth = 3 corresponds to dates like 3/31/2007, 6/30/2007, …',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'The number of quarters represented.\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "        {'param_name': 'startingMonth',\n",
       "         'param_type': 'int, default 3',\n",
       "         'param_desc': 'A specific integer for the month of the year from which we start quarters.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.QuarterEnd',\n",
       "       'descriptions': 'DateOffset increments between Quarter end dates. startingMonth = 1 corresponds to dates like 1/31/2007, 4/30/2007, …\\nstartingMonth = 2 corresponds to dates like 2/28/2007, 5/31/2007, …\\nstartingMonth = 3 corresponds to dates like 3/31/2007, 6/30/2007, …',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 1. The number of quarters represented.\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "         'startingMonth': {'type': 'integer',\n",
       "          'description': 'int, default 3. A specific integer for the month of the year from which we start quarters.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'QuarterEnd.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.freqstr.html#pandas.tseries.offsets.QuarterEnd.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterEnd.freqstr',\n",
       "       'full_function': 'QuarterEnd.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'QuarterEnd.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.name.html#pandas.tseries.offsets.QuarterEnd.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterEnd.name',\n",
       "       'full_function': 'QuarterEnd.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'QuarterEnd.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.normalize.html#pandas.tseries.offsets.QuarterEnd.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterEnd.normalize',\n",
       "       'full_function': 'QuarterEnd.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'QuarterEnd.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.n.html#pandas.tseries.offsets.QuarterEnd.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterEnd.n',\n",
       "       'full_function': 'QuarterEnd.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'QuarterEnd.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.copy.html#pandas.tseries.offsets.QuarterEnd.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterEnd.copy',\n",
       "       'full_function': 'QuarterEnd.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'QuarterEnd.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.is_on_offset.html#pandas.tseries.offsets.QuarterEnd.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterEnd.is_on_offset',\n",
       "       'full_function': 'QuarterEnd.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.QuarterEnd.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'QuarterEnd.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.is_month_end.html#pandas.tseries.offsets.QuarterEnd.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterEnd.is_month_end',\n",
       "       'full_function': 'QuarterEnd.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'QuarterEnd.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.is_quarter_end.html#pandas.tseries.offsets.QuarterEnd.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterEnd.is_quarter_end',\n",
       "       'full_function': 'QuarterEnd.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'QuarterEnd.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.is_year_end.html#pandas.tseries.offsets.QuarterEnd.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterEnd.is_year_end',\n",
       "       'full_function': 'QuarterEnd.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'QuarterEnd.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.kwds.html#pandas.tseries.offsets.QuarterEnd.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterEnd.kwds',\n",
       "       'full_function': 'QuarterEnd.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'QuarterEnd.nanos',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.nanos.html#pandas.tseries.offsets.QuarterEnd.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterEnd.nanos',\n",
       "       'full_function': 'QuarterEnd.nanos#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'QuarterEnd.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.rule_code.html#pandas.tseries.offsets.QuarterEnd.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterEnd.rule_code',\n",
       "       'full_function': 'QuarterEnd.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'QuarterEnd.startingMonth',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.startingMonth.html#pandas.tseries.offsets.QuarterEnd.startingMonth',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterEnd.startingMonth',\n",
       "       'full_function': 'QuarterEnd.startingMonth#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'QuarterEnd.is_anchored()',\n",
       "      'func_desc': 'Return boolean whether the frequency is a unit frequency (n=1).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.is_anchored.html#pandas.tseries.offsets.QuarterEnd.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterEnd.is_anchored',\n",
       "       'full_function': 'QuarterEnd.is_anchored()#',\n",
       "       'function_text': 'Return boolean whether the frequency is a unit frequency (n=1). Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse obj.n == 1 instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'QuarterEnd.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.is_month_start.html#pandas.tseries.offsets.QuarterEnd.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterEnd.is_month_start',\n",
       "       'full_function': 'QuarterEnd.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'QuarterEnd.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.is_quarter_start.html#pandas.tseries.offsets.QuarterEnd.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterEnd.is_quarter_start',\n",
       "       'full_function': 'QuarterEnd.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'QuarterEnd.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.is_year_start.html#pandas.tseries.offsets.QuarterEnd.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterEnd.is_year_start',\n",
       "       'full_function': 'QuarterEnd.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'QuarterBegin': [{'func_name': 'QuarterBegin',\n",
       "      'func_desc': 'DateOffset increments between Quarter start dates.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.html#pandas.tseries.offsets.QuarterBegin',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterBegin',\n",
       "       'full_function': 'class pandas.tseries.offsets.QuarterBegin#',\n",
       "       'function_text': 'DateOffset increments between Quarter start dates. startingMonth = 1 corresponds to dates like 1/01/2007, 4/01/2007, …\\nstartingMonth = 2 corresponds to dates like 2/01/2007, 5/01/2007, …\\nstartingMonth = 3 corresponds to dates like 3/01/2007, 6/01/2007, …',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'The number of quarters represented.\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "        {'param_name': 'startingMonth',\n",
       "         'param_type': 'int, default 3',\n",
       "         'param_desc': 'A specific integer for the month of the year from which we start quarters.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.QuarterBegin',\n",
       "       'descriptions': 'DateOffset increments between Quarter start dates. startingMonth = 1 corresponds to dates like 1/01/2007, 4/01/2007, …\\nstartingMonth = 2 corresponds to dates like 2/01/2007, 5/01/2007, …\\nstartingMonth = 3 corresponds to dates like 3/01/2007, 6/01/2007, …',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 1. The number of quarters represented.\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "         'startingMonth': {'type': 'integer',\n",
       "          'description': 'int, default 3. A specific integer for the month of the year from which we start quarters.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'QuarterBegin.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.freqstr.html#pandas.tseries.offsets.QuarterBegin.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterBegin.freqstr',\n",
       "       'full_function': 'QuarterBegin.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'QuarterBegin.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.name.html#pandas.tseries.offsets.QuarterBegin.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterBegin.name',\n",
       "       'full_function': 'QuarterBegin.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'QuarterBegin.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.normalize.html#pandas.tseries.offsets.QuarterBegin.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterBegin.normalize',\n",
       "       'full_function': 'QuarterBegin.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'QuarterBegin.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.n.html#pandas.tseries.offsets.QuarterBegin.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterBegin.n',\n",
       "       'full_function': 'QuarterBegin.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'QuarterBegin.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.copy.html#pandas.tseries.offsets.QuarterBegin.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterBegin.copy',\n",
       "       'full_function': 'QuarterBegin.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'QuarterBegin.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.is_on_offset.html#pandas.tseries.offsets.QuarterBegin.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterBegin.is_on_offset',\n",
       "       'full_function': 'QuarterBegin.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.QuarterBegin.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'QuarterBegin.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.is_month_end.html#pandas.tseries.offsets.QuarterBegin.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterBegin.is_month_end',\n",
       "       'full_function': 'QuarterBegin.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'QuarterBegin.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.is_quarter_end.html#pandas.tseries.offsets.QuarterBegin.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterBegin.is_quarter_end',\n",
       "       'full_function': 'QuarterBegin.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'QuarterBegin.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.is_year_end.html#pandas.tseries.offsets.QuarterBegin.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterBegin.is_year_end',\n",
       "       'full_function': 'QuarterBegin.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'QuarterBegin.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.kwds.html#pandas.tseries.offsets.QuarterBegin.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterBegin.kwds',\n",
       "       'full_function': 'QuarterBegin.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'QuarterBegin.nanos',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.nanos.html#pandas.tseries.offsets.QuarterBegin.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterBegin.nanos',\n",
       "       'full_function': 'QuarterBegin.nanos#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'QuarterBegin.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.rule_code.html#pandas.tseries.offsets.QuarterBegin.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterBegin.rule_code',\n",
       "       'full_function': 'QuarterBegin.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'QuarterBegin.startingMonth',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.startingMonth.html#pandas.tseries.offsets.QuarterBegin.startingMonth',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterBegin.startingMonth',\n",
       "       'full_function': 'QuarterBegin.startingMonth#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'QuarterBegin.is_anchored()',\n",
       "      'func_desc': 'Return boolean whether the frequency is a unit frequency (n=1).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.is_anchored.html#pandas.tseries.offsets.QuarterBegin.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterBegin.is_anchored',\n",
       "       'full_function': 'QuarterBegin.is_anchored()#',\n",
       "       'function_text': 'Return boolean whether the frequency is a unit frequency (n=1). Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse obj.n == 1 instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'QuarterBegin.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.is_month_start.html#pandas.tseries.offsets.QuarterBegin.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterBegin.is_month_start',\n",
       "       'full_function': 'QuarterBegin.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'QuarterBegin.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.is_quarter_start.html#pandas.tseries.offsets.QuarterBegin.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterBegin.is_quarter_start',\n",
       "       'full_function': 'QuarterBegin.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'QuarterBegin.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.is_year_start.html#pandas.tseries.offsets.QuarterBegin.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.QuarterBegin.is_year_start',\n",
       "       'full_function': 'QuarterBegin.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'BYearEnd': [{'func_name': 'BYearEnd',\n",
       "      'func_desc': 'DateOffset increments between the last business day of the year.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.html#pandas.tseries.offsets.BYearEnd',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearEnd',\n",
       "       'full_function': 'class pandas.tseries.offsets.BYearEnd#',\n",
       "       'function_text': 'DateOffset increments between the last business day of the year.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'The number of years represented.\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "        {'param_name': 'month',\n",
       "         'param_type': 'int, default 12',\n",
       "         'param_desc': 'A specific integer for the month of the year.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.BYearEnd',\n",
       "       'descriptions': 'DateOffset increments between the last business day of the year.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 1. The number of years represented.\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "         'month': {'type': 'integer',\n",
       "          'description': 'int, default 12. A specific integer for the month of the year.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'BYearEnd.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.freqstr.html#pandas.tseries.offsets.BYearEnd.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearEnd.freqstr',\n",
       "       'full_function': 'BYearEnd.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BYearEnd.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.name.html#pandas.tseries.offsets.BYearEnd.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearEnd.name',\n",
       "       'full_function': 'BYearEnd.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BYearEnd.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.normalize.html#pandas.tseries.offsets.BYearEnd.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearEnd.normalize',\n",
       "       'full_function': 'BYearEnd.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BYearEnd.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.n.html#pandas.tseries.offsets.BYearEnd.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearEnd.n',\n",
       "       'full_function': 'BYearEnd.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BYearEnd.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.copy.html#pandas.tseries.offsets.BYearEnd.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearEnd.copy',\n",
       "       'full_function': 'BYearEnd.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BYearEnd.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.is_on_offset.html#pandas.tseries.offsets.BYearEnd.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearEnd.is_on_offset',\n",
       "       'full_function': 'BYearEnd.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.BYearEnd.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'BYearEnd.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.is_month_end.html#pandas.tseries.offsets.BYearEnd.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearEnd.is_month_end',\n",
       "       'full_function': 'BYearEnd.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BYearEnd.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.is_quarter_end.html#pandas.tseries.offsets.BYearEnd.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearEnd.is_quarter_end',\n",
       "       'full_function': 'BYearEnd.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BYearEnd.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.is_year_end.html#pandas.tseries.offsets.BYearEnd.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearEnd.is_year_end',\n",
       "       'full_function': 'BYearEnd.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BYearEnd.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.kwds.html#pandas.tseries.offsets.BYearEnd.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearEnd.kwds',\n",
       "       'full_function': 'BYearEnd.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BYearEnd.nanos',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.nanos.html#pandas.tseries.offsets.BYearEnd.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearEnd.nanos',\n",
       "       'full_function': 'BYearEnd.nanos#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BYearEnd.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.rule_code.html#pandas.tseries.offsets.BYearEnd.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearEnd.rule_code',\n",
       "       'full_function': 'BYearEnd.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BYearEnd.month',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.month.html#pandas.tseries.offsets.BYearEnd.month',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearEnd.month',\n",
       "       'full_function': 'BYearEnd.month#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BYearEnd.is_anchored()',\n",
       "      'func_desc': '(DEPRECATED) Return boolean whether the frequency is a unit frequency (n=1).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.is_anchored.html#pandas.tseries.offsets.BYearEnd.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearEnd.is_anchored',\n",
       "       'full_function': 'BYearEnd.is_anchored()#',\n",
       "       'function_text': 'Return boolean whether the frequency is a unit frequency (n=1). Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse obj.n == 1 instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BYearEnd.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.is_month_start.html#pandas.tseries.offsets.BYearEnd.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearEnd.is_month_start',\n",
       "       'full_function': 'BYearEnd.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BYearEnd.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.is_quarter_start.html#pandas.tseries.offsets.BYearEnd.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearEnd.is_quarter_start',\n",
       "       'full_function': 'BYearEnd.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BYearEnd.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.is_year_start.html#pandas.tseries.offsets.BYearEnd.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearEnd.is_year_start',\n",
       "       'full_function': 'BYearEnd.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'BYearBegin': [{'func_name': 'BYearBegin',\n",
       "      'func_desc': 'DateOffset increments between the first business day of the year.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.html#pandas.tseries.offsets.BYearBegin',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearBegin',\n",
       "       'full_function': 'class pandas.tseries.offsets.BYearBegin#',\n",
       "       'function_text': 'DateOffset increments between the first business day of the year.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'The number of years represented.\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "        {'param_name': 'month',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'A specific integer for the month of the year.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.BYearBegin',\n",
       "       'descriptions': 'DateOffset increments between the first business day of the year.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 1. The number of years represented.\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "         'month': {'type': 'integer',\n",
       "          'description': 'int, default 1. A specific integer for the month of the year.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'BYearBegin.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.freqstr.html#pandas.tseries.offsets.BYearBegin.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearBegin.freqstr',\n",
       "       'full_function': 'BYearBegin.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BYearBegin.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.name.html#pandas.tseries.offsets.BYearBegin.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearBegin.name',\n",
       "       'full_function': 'BYearBegin.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BYearBegin.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.normalize.html#pandas.tseries.offsets.BYearBegin.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearBegin.normalize',\n",
       "       'full_function': 'BYearBegin.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BYearBegin.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.n.html#pandas.tseries.offsets.BYearBegin.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearBegin.n',\n",
       "       'full_function': 'BYearBegin.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BYearBegin.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.copy.html#pandas.tseries.offsets.BYearBegin.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearBegin.copy',\n",
       "       'full_function': 'BYearBegin.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BYearBegin.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.is_on_offset.html#pandas.tseries.offsets.BYearBegin.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearBegin.is_on_offset',\n",
       "       'full_function': 'BYearBegin.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.BYearBegin.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'BYearBegin.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.is_month_end.html#pandas.tseries.offsets.BYearBegin.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearBegin.is_month_end',\n",
       "       'full_function': 'BYearBegin.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BYearBegin.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.is_quarter_end.html#pandas.tseries.offsets.BYearBegin.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearBegin.is_quarter_end',\n",
       "       'full_function': 'BYearBegin.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BYearBegin.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.is_year_end.html#pandas.tseries.offsets.BYearBegin.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearBegin.is_year_end',\n",
       "       'full_function': 'BYearBegin.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BYearBegin.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.kwds.html#pandas.tseries.offsets.BYearBegin.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearBegin.kwds',\n",
       "       'full_function': 'BYearBegin.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BYearBegin.nanos',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.nanos.html#pandas.tseries.offsets.BYearBegin.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearBegin.nanos',\n",
       "       'full_function': 'BYearBegin.nanos#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BYearBegin.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.rule_code.html#pandas.tseries.offsets.BYearBegin.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearBegin.rule_code',\n",
       "       'full_function': 'BYearBegin.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BYearBegin.month',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.month.html#pandas.tseries.offsets.BYearBegin.month',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearBegin.month',\n",
       "       'full_function': 'BYearBegin.month#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BYearBegin.is_anchored()',\n",
       "      'func_desc': '(DEPRECATED) Return boolean whether the frequency is a unit frequency (n=1).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.is_anchored.html#pandas.tseries.offsets.BYearBegin.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearBegin.is_anchored',\n",
       "       'full_function': 'BYearBegin.is_anchored()#',\n",
       "       'function_text': 'Return boolean whether the frequency is a unit frequency (n=1). Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse obj.n == 1 instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BYearBegin.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.is_month_start.html#pandas.tseries.offsets.BYearBegin.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearBegin.is_month_start',\n",
       "       'full_function': 'BYearBegin.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BYearBegin.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.is_quarter_start.html#pandas.tseries.offsets.BYearBegin.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearBegin.is_quarter_start',\n",
       "       'full_function': 'BYearBegin.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'BYearBegin.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.is_year_start.html#pandas.tseries.offsets.BYearBegin.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.BYearBegin.is_year_start',\n",
       "       'full_function': 'BYearBegin.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'YearEnd': [{'func_name': 'YearEnd',\n",
       "      'func_desc': 'DateOffset increments between calendar year end dates.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.html#pandas.tseries.offsets.YearEnd',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearEnd',\n",
       "       'full_function': 'class pandas.tseries.offsets.YearEnd#',\n",
       "       'function_text': 'DateOffset increments between calendar year end dates. YearEnd goes to the next date which is the end of the year.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'The number of years represented.\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "        {'param_name': 'month',\n",
       "         'param_type': 'int, default 12',\n",
       "         'param_desc': 'A specific integer for the month of the year.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.YearEnd',\n",
       "       'descriptions': 'DateOffset increments between calendar year end dates. YearEnd goes to the next date which is the end of the year.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 1. The number of years represented.\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "         'month': {'type': 'integer',\n",
       "          'description': 'int, default 12. A specific integer for the month of the year.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'YearEnd.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.freqstr.html#pandas.tseries.offsets.YearEnd.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearEnd.freqstr',\n",
       "       'full_function': 'YearEnd.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'YearEnd.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.name.html#pandas.tseries.offsets.YearEnd.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearEnd.name',\n",
       "       'full_function': 'YearEnd.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'YearEnd.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.normalize.html#pandas.tseries.offsets.YearEnd.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearEnd.normalize',\n",
       "       'full_function': 'YearEnd.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'YearEnd.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.n.html#pandas.tseries.offsets.YearEnd.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearEnd.n',\n",
       "       'full_function': 'YearEnd.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'YearEnd.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.copy.html#pandas.tseries.offsets.YearEnd.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearEnd.copy',\n",
       "       'full_function': 'YearEnd.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'YearEnd.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.is_on_offset.html#pandas.tseries.offsets.YearEnd.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearEnd.is_on_offset',\n",
       "       'full_function': 'YearEnd.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.YearEnd.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'YearEnd.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.is_month_end.html#pandas.tseries.offsets.YearEnd.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearEnd.is_month_end',\n",
       "       'full_function': 'YearEnd.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'YearEnd.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.is_quarter_end.html#pandas.tseries.offsets.YearEnd.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearEnd.is_quarter_end',\n",
       "       'full_function': 'YearEnd.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'YearEnd.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.is_year_end.html#pandas.tseries.offsets.YearEnd.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearEnd.is_year_end',\n",
       "       'full_function': 'YearEnd.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'YearEnd.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.kwds.html#pandas.tseries.offsets.YearEnd.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearEnd.kwds',\n",
       "       'full_function': 'YearEnd.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'YearEnd.nanos',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.nanos.html#pandas.tseries.offsets.YearEnd.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearEnd.nanos',\n",
       "       'full_function': 'YearEnd.nanos#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'YearEnd.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.rule_code.html#pandas.tseries.offsets.YearEnd.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearEnd.rule_code',\n",
       "       'full_function': 'YearEnd.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'YearEnd.month',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.month.html#pandas.tseries.offsets.YearEnd.month',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearEnd.month',\n",
       "       'full_function': 'YearEnd.month#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'YearEnd.is_anchored()',\n",
       "      'func_desc': '(DEPRECATED) Return boolean whether the frequency is a unit frequency (n=1).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.is_anchored.html#pandas.tseries.offsets.YearEnd.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearEnd.is_anchored',\n",
       "       'full_function': 'YearEnd.is_anchored()#',\n",
       "       'function_text': 'Return boolean whether the frequency is a unit frequency (n=1). Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse obj.n == 1 instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'YearEnd.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.is_month_start.html#pandas.tseries.offsets.YearEnd.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearEnd.is_month_start',\n",
       "       'full_function': 'YearEnd.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'YearEnd.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.is_quarter_start.html#pandas.tseries.offsets.YearEnd.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearEnd.is_quarter_start',\n",
       "       'full_function': 'YearEnd.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'YearEnd.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.is_year_start.html#pandas.tseries.offsets.YearEnd.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearEnd.is_year_start',\n",
       "       'full_function': 'YearEnd.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'YearBegin': [{'func_name': 'YearBegin',\n",
       "      'func_desc': 'DateOffset increments between calendar year begin dates.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.html#pandas.tseries.offsets.YearBegin',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearBegin',\n",
       "       'full_function': 'class pandas.tseries.offsets.YearBegin#',\n",
       "       'function_text': 'DateOffset increments between calendar year begin dates. YearBegin goes to the next date which is the start of the year.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'The number of years represented.\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "        {'param_name': 'month',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'A specific integer for the month of the year.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.YearBegin',\n",
       "       'descriptions': 'DateOffset increments between calendar year begin dates. YearBegin goes to the next date which is the start of the year.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 1. The number of years represented.\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "         'month': {'type': 'integer',\n",
       "          'description': 'int, default 1. A specific integer for the month of the year.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'YearBegin.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.freqstr.html#pandas.tseries.offsets.YearBegin.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearBegin.freqstr',\n",
       "       'full_function': 'YearBegin.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'YearBegin.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.name.html#pandas.tseries.offsets.YearBegin.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearBegin.name',\n",
       "       'full_function': 'YearBegin.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'YearBegin.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.normalize.html#pandas.tseries.offsets.YearBegin.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearBegin.normalize',\n",
       "       'full_function': 'YearBegin.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'YearBegin.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.n.html#pandas.tseries.offsets.YearBegin.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearBegin.n',\n",
       "       'full_function': 'YearBegin.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'YearBegin.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.copy.html#pandas.tseries.offsets.YearBegin.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearBegin.copy',\n",
       "       'full_function': 'YearBegin.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'YearBegin.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.is_on_offset.html#pandas.tseries.offsets.YearBegin.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearBegin.is_on_offset',\n",
       "       'full_function': 'YearBegin.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.YearBegin.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'YearBegin.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.is_month_end.html#pandas.tseries.offsets.YearBegin.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearBegin.is_month_end',\n",
       "       'full_function': 'YearBegin.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'YearBegin.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.is_quarter_end.html#pandas.tseries.offsets.YearBegin.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearBegin.is_quarter_end',\n",
       "       'full_function': 'YearBegin.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'YearBegin.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.is_year_end.html#pandas.tseries.offsets.YearBegin.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearBegin.is_year_end',\n",
       "       'full_function': 'YearBegin.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'YearBegin.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.kwds.html#pandas.tseries.offsets.YearBegin.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearBegin.kwds',\n",
       "       'full_function': 'YearBegin.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'YearBegin.nanos',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.nanos.html#pandas.tseries.offsets.YearBegin.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearBegin.nanos',\n",
       "       'full_function': 'YearBegin.nanos#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'YearBegin.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.rule_code.html#pandas.tseries.offsets.YearBegin.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearBegin.rule_code',\n",
       "       'full_function': 'YearBegin.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'YearBegin.month',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.month.html#pandas.tseries.offsets.YearBegin.month',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearBegin.month',\n",
       "       'full_function': 'YearBegin.month#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'YearBegin.is_anchored()',\n",
       "      'func_desc': '(DEPRECATED) Return boolean whether the frequency is a unit frequency (n=1).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.is_anchored.html#pandas.tseries.offsets.YearBegin.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearBegin.is_anchored',\n",
       "       'full_function': 'YearBegin.is_anchored()#',\n",
       "       'function_text': 'Return boolean whether the frequency is a unit frequency (n=1). Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse obj.n == 1 instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'YearBegin.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.is_month_start.html#pandas.tseries.offsets.YearBegin.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearBegin.is_month_start',\n",
       "       'full_function': 'YearBegin.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'YearBegin.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.is_quarter_start.html#pandas.tseries.offsets.YearBegin.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearBegin.is_quarter_start',\n",
       "       'full_function': 'YearBegin.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'YearBegin.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.is_year_start.html#pandas.tseries.offsets.YearBegin.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.YearBegin.is_year_start',\n",
       "       'full_function': 'YearBegin.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'FY5253': [{'func_name': 'FY5253',\n",
       "      'func_desc': 'Describes 52-53 week fiscal year.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.html#pandas.tseries.offsets.FY5253',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253',\n",
       "       'full_function': 'class pandas.tseries.offsets.FY5253#',\n",
       "       'function_text': 'Describes 52-53 week fiscal year. This is also known as a 4-4-5 calendar. It is used by companies that desire that their\\nfiscal year always end on the same day of the week. It is a method of managing accounting periods.\\nIt is a common calendar structure for some industries,\\nsuch as retail, manufacturing and parking industry. For more information see:\\nhttps://en.wikipedia.org/wiki/4-4-5_calendar The year may either: end on the last X day of the Y month. end on the last X day closest to the last day of the Y month. X is a specific day of the week.\\nY is a certain month of the year',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int',\n",
       "         'param_desc': 'The number of fiscal years represented.\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "        {'param_name': 'weekday',\n",
       "         'param_type': 'int {0, 1, …, 6}, default 0',\n",
       "         'param_desc': 'A specific integer for the day of the week.\\n\\n0 is Monday\\n1 is Tuesday\\n2 is Wednesday\\n3 is Thursday\\n4 is Friday\\n5 is Saturday\\n6 is Sunday.\\n\\n'},\n",
       "        {'param_name': 'startingMonth',\n",
       "         'param_type': 'int {1, 2, … 12}, default 1',\n",
       "         'param_desc': 'The month in which the fiscal year ends.\\n'},\n",
       "        {'param_name': 'variation',\n",
       "         'param_type': 'str, default “nearest”',\n",
       "         'param_desc': 'Method of employing 4-4-5 calendar.\\nThere are two options:\\n\\n“nearest” means year end is weekday closest to last day of month in year.\\n“last” means year end is final weekday of the final month in fiscal year.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.FY5253',\n",
       "       'descriptions': 'Describes 52-53 week fiscal year. This is also known as a 4-4-5 calendar. It is used by companies that desire that their\\nfiscal year always end on the same day of the week. It is a method of managing accounting periods.\\nIt is a common calendar structure for some industries,\\nsuch as retail, manufacturing and parking industry. For more information see:\\nhttps://en.wikipedia.org/wiki/4-4-5_calendar The year may either: end on the last X day of the Y month. end on the last X day closest to the last day of the Y month. X is a specific day of the week.\\nY is a certain month of the year',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int. The number of fiscal years represented.\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "         'weekday': {'type': 'integer',\n",
       "          'description': 'int {0, 1, …, 6}, default 0. A specific integer for the day of the week.\\n\\n0 is Monday\\n1 is Tuesday\\n2 is Wednesday\\n3 is Thursday\\n4 is Friday\\n5 is Saturday\\n6 is Sunday.\\n\\n'},\n",
       "         'startingMonth': {'type': 'integer',\n",
       "          'description': 'int {1, 2, … 12}, default 1. The month in which the fiscal year ends.\\n'},\n",
       "         'variation': {'type': 'string',\n",
       "          'description': 'str, default “nearest”. Method of employing 4-4-5 calendar.\\nThere are two options:\\n\\n“nearest” means year end is weekday closest to last day of month in year.\\n“last” means year end is final weekday of the final month in fiscal year.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'FY5253.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.freqstr.html#pandas.tseries.offsets.FY5253.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253.freqstr',\n",
       "       'full_function': 'FY5253.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.name.html#pandas.tseries.offsets.FY5253.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253.name',\n",
       "       'full_function': 'FY5253.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.normalize.html#pandas.tseries.offsets.FY5253.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253.normalize',\n",
       "       'full_function': 'FY5253.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.n.html#pandas.tseries.offsets.FY5253.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253.n',\n",
       "       'full_function': 'FY5253.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253.variation',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.variation.html#pandas.tseries.offsets.FY5253.variation',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253.variation',\n",
       "       'full_function': 'FY5253.variation#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.copy.html#pandas.tseries.offsets.FY5253.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253.copy',\n",
       "       'full_function': 'FY5253.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253.get_year_end(dt)',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.get_year_end.html#pandas.tseries.offsets.FY5253.get_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253.get_year_end',\n",
       "       'full_function': 'FY5253.get_year_end(dt)#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.is_on_offset.html#pandas.tseries.offsets.FY5253.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253.is_on_offset',\n",
       "       'full_function': 'FY5253.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.FY5253.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'FY5253.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.is_month_end.html#pandas.tseries.offsets.FY5253.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253.is_month_end',\n",
       "       'full_function': 'FY5253.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.is_quarter_end.html#pandas.tseries.offsets.FY5253.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253.is_quarter_end',\n",
       "       'full_function': 'FY5253.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.is_year_end.html#pandas.tseries.offsets.FY5253.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253.is_year_end',\n",
       "       'full_function': 'FY5253.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.kwds.html#pandas.tseries.offsets.FY5253.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253.kwds',\n",
       "       'full_function': 'FY5253.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253.nanos',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.nanos.html#pandas.tseries.offsets.FY5253.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253.nanos',\n",
       "       'full_function': 'FY5253.nanos#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.rule_code.html#pandas.tseries.offsets.FY5253.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253.rule_code',\n",
       "       'full_function': 'FY5253.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253.startingMonth',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.startingMonth.html#pandas.tseries.offsets.FY5253.startingMonth',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253.startingMonth',\n",
       "       'full_function': 'FY5253.startingMonth#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253.weekday',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.weekday.html#pandas.tseries.offsets.FY5253.weekday',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253.weekday',\n",
       "       'full_function': 'FY5253.weekday#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253.get_rule_code_suffix()',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.get_rule_code_suffix.html#pandas.tseries.offsets.FY5253.get_rule_code_suffix',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253.get_rule_code_suffix',\n",
       "       'full_function': 'FY5253.get_rule_code_suffix()#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253.is_anchored()',\n",
       "      'func_desc': 'Return boolean whether the frequency is a unit frequency (n=1).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.is_anchored.html#pandas.tseries.offsets.FY5253.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253.is_anchored',\n",
       "       'full_function': 'FY5253.is_anchored()#',\n",
       "       'function_text': 'Return boolean whether the frequency is a unit frequency (n=1). Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse obj.n == 1 instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.is_month_start.html#pandas.tseries.offsets.FY5253.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253.is_month_start',\n",
       "       'full_function': 'FY5253.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.is_quarter_start.html#pandas.tseries.offsets.FY5253.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253.is_quarter_start',\n",
       "       'full_function': 'FY5253.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.is_year_start.html#pandas.tseries.offsets.FY5253.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253.is_year_start',\n",
       "       'full_function': 'FY5253.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'FY5253Quarter': [{'func_name': 'FY5253Quarter',\n",
       "      'func_desc': 'DateOffset increments between business quarter dates for 52-53 week fiscal year.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.html#pandas.tseries.offsets.FY5253Quarter',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253Quarter',\n",
       "       'full_function': 'class pandas.tseries.offsets.FY5253Quarter#',\n",
       "       'function_text': 'DateOffset increments between business quarter dates for 52-53 week fiscal year. Also known as a 4-4-5 calendar. It is used by companies that desire that their\\nfiscal year always end on the same day of the week. It is a method of managing accounting periods.\\nIt is a common calendar structure for some industries,\\nsuch as retail, manufacturing and parking industry. For more information see:\\nhttps://en.wikipedia.org/wiki/4-4-5_calendar The year may either: end on the last X day of the Y month. end on the last X day closest to the last day of the Y month. X is a specific day of the week.\\nY is a certain month of the year startingMonth = 1 corresponds to dates like 1/31/2007, 4/30/2007, …\\nstartingMonth = 2 corresponds to dates like 2/28/2007, 5/31/2007, …\\nstartingMonth = 3 corresponds to dates like 3/30/2007, 6/29/2007, …',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int',\n",
       "         'param_desc': 'The number of business quarters represented.\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "        {'param_name': 'weekday',\n",
       "         'param_type': 'int {0, 1, …, 6}, default 0',\n",
       "         'param_desc': 'A specific integer for the day of the week.\\n\\n0 is Monday\\n1 is Tuesday\\n2 is Wednesday\\n3 is Thursday\\n4 is Friday\\n5 is Saturday\\n6 is Sunday.\\n\\n'},\n",
       "        {'param_name': 'startingMonth',\n",
       "         'param_type': 'int {1, 2, …, 12}, default 1',\n",
       "         'param_desc': 'The month in which fiscal years end.\\n'},\n",
       "        {'param_name': 'qtr_with_extra_week',\n",
       "         'param_type': 'int {1, 2, 3, 4}, default 1',\n",
       "         'param_desc': 'The quarter number that has the leap or 14 week when needed.\\n'},\n",
       "        {'param_name': 'variation',\n",
       "         'param_type': 'str, default “nearest”',\n",
       "         'param_desc': 'Method of employing 4-4-5 calendar.\\nThere are two options:\\n\\n“nearest” means year end is weekday closest to last day of month in year.\\n“last” means year end is final weekday of the final month in fiscal year.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.FY5253Quarter',\n",
       "       'descriptions': 'DateOffset increments between business quarter dates for 52-53 week fiscal year. Also known as a 4-4-5 calendar. It is used by companies that desire that their\\nfiscal year always end on the same day of the week. It is a method of managing accounting periods.\\nIt is a common calendar structure for some industries,\\nsuch as retail, manufacturing and parking industry. For more information see:\\nhttps://en.wikipedia.org/wiki/4-4-5_calendar The year may either: end on the last X day of the Y month. end on the last X day closest to the last day of the Y month. X is a specific day of the week.\\nY is a certain month of the year startingMonth = 1 corresponds to dates like 1/31/2007, 4/30/2007, …\\nstartingMonth = 2 corresponds to dates like 2/28/2007, 5/31/2007, …\\nstartingMonth = 3 corresponds to dates like 3/30/2007, 6/29/2007, …',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int. The number of business quarters represented.\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Normalize start/end dates to midnight before generating date range.\\n'},\n",
       "         'weekday': {'type': 'integer',\n",
       "          'description': 'int {0, 1, …, 6}, default 0. A specific integer for the day of the week.\\n\\n0 is Monday\\n1 is Tuesday\\n2 is Wednesday\\n3 is Thursday\\n4 is Friday\\n5 is Saturday\\n6 is Sunday.\\n\\n'},\n",
       "         'startingMonth': {'type': 'integer',\n",
       "          'description': 'int {1, 2, …, 12}, default 1. The month in which fiscal years end.\\n'},\n",
       "         'qtr_with_extra_week': {'type': 'integer',\n",
       "          'description': 'int {1, 2, 3, 4}, default 1. The quarter number that has the leap or 14 week when needed.\\n'},\n",
       "         'variation': {'type': 'string',\n",
       "          'description': 'str, default “nearest”. Method of employing 4-4-5 calendar.\\nThere are two options:\\n\\n“nearest” means year end is weekday closest to last day of month in year.\\n“last” means year end is final weekday of the final month in fiscal year.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'FY5253Quarter.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.freqstr.html#pandas.tseries.offsets.FY5253Quarter.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253Quarter.freqstr',\n",
       "       'full_function': 'FY5253Quarter.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253Quarter.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.name.html#pandas.tseries.offsets.FY5253Quarter.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253Quarter.name',\n",
       "       'full_function': 'FY5253Quarter.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253Quarter.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.normalize.html#pandas.tseries.offsets.FY5253Quarter.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253Quarter.normalize',\n",
       "       'full_function': 'FY5253Quarter.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253Quarter.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.n.html#pandas.tseries.offsets.FY5253Quarter.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253Quarter.n',\n",
       "       'full_function': 'FY5253Quarter.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253Quarter.startingMonth',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.startingMonth.html#pandas.tseries.offsets.FY5253Quarter.startingMonth',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253Quarter.startingMonth',\n",
       "       'full_function': 'FY5253Quarter.startingMonth#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253Quarter.weekday',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.weekday.html#pandas.tseries.offsets.FY5253Quarter.weekday',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253Quarter.weekday',\n",
       "       'full_function': 'FY5253Quarter.weekday#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253Quarter.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.copy.html#pandas.tseries.offsets.FY5253Quarter.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253Quarter.copy',\n",
       "       'full_function': 'FY5253Quarter.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253Quarter.get_weeks(dt)',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.get_weeks.html#pandas.tseries.offsets.FY5253Quarter.get_weeks',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253Quarter.get_weeks',\n",
       "       'full_function': 'FY5253Quarter.get_weeks(dt)#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253Quarter.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.is_on_offset.html#pandas.tseries.offsets.FY5253Quarter.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253Quarter.is_on_offset',\n",
       "       'full_function': 'FY5253Quarter.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.FY5253Quarter.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'FY5253Quarter.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.is_month_start.html#pandas.tseries.offsets.FY5253Quarter.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253Quarter.is_month_start',\n",
       "       'full_function': 'FY5253Quarter.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253Quarter.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.is_quarter_start.html#pandas.tseries.offsets.FY5253Quarter.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253Quarter.is_quarter_start',\n",
       "       'full_function': 'FY5253Quarter.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253Quarter.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.is_year_start.html#pandas.tseries.offsets.FY5253Quarter.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253Quarter.is_year_start',\n",
       "       'full_function': 'FY5253Quarter.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253Quarter.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.kwds.html#pandas.tseries.offsets.FY5253Quarter.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253Quarter.kwds',\n",
       "       'full_function': 'FY5253Quarter.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253Quarter.nanos',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.nanos.html#pandas.tseries.offsets.FY5253Quarter.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253Quarter.nanos',\n",
       "       'full_function': 'FY5253Quarter.nanos#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253Quarter.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.rule_code.html#pandas.tseries.offsets.FY5253Quarter.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253Quarter.rule_code',\n",
       "       'full_function': 'FY5253Quarter.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253Quarter.qtr_with_extra_week',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.qtr_with_extra_week.html#pandas.tseries.offsets.FY5253Quarter.qtr_with_extra_week',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253Quarter.qtr_with_extra_week',\n",
       "       'full_function': 'FY5253Quarter.qtr_with_extra_week#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253Quarter.variation',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.variation.html#pandas.tseries.offsets.FY5253Quarter.variation',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253Quarter.variation',\n",
       "       'full_function': 'FY5253Quarter.variation#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253Quarter.get_rule_code_suffix()',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.get_rule_code_suffix.html#pandas.tseries.offsets.FY5253Quarter.get_rule_code_suffix',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253Quarter.get_rule_code_suffix',\n",
       "       'full_function': 'FY5253Quarter.get_rule_code_suffix()#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253Quarter.is_anchored()',\n",
       "      'func_desc': 'Return boolean whether the frequency is a unit frequency (n=1).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.is_anchored.html#pandas.tseries.offsets.FY5253Quarter.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253Quarter.is_anchored',\n",
       "       'full_function': 'FY5253Quarter.is_anchored()#',\n",
       "       'function_text': 'Return boolean whether the frequency is a unit frequency (n=1). Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse obj.n == 1 instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253Quarter.year_has_extra_week(dt)',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.year_has_extra_week.html#pandas.tseries.offsets.FY5253Quarter.year_has_extra_week',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253Quarter.year_has_extra_week',\n",
       "       'full_function': 'FY5253Quarter.year_has_extra_week(dt)#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253Quarter.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.is_month_end.html#pandas.tseries.offsets.FY5253Quarter.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253Quarter.is_month_end',\n",
       "       'full_function': 'FY5253Quarter.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253Quarter.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.is_quarter_end.html#pandas.tseries.offsets.FY5253Quarter.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253Quarter.is_quarter_end',\n",
       "       'full_function': 'FY5253Quarter.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'FY5253Quarter.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.is_year_end.html#pandas.tseries.offsets.FY5253Quarter.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.FY5253Quarter.is_year_end',\n",
       "       'full_function': 'FY5253Quarter.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'Easter': [{'func_name': 'Easter',\n",
       "      'func_desc': 'DateOffset for the Easter holiday using logic defined in dateutil.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.html#pandas.tseries.offsets.Easter',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Easter',\n",
       "       'full_function': 'class pandas.tseries.offsets.Easter#',\n",
       "       'function_text': 'DateOffset for the Easter holiday using logic defined in dateutil. Right now uses the revised method which is valid in years 1583-4099.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'The number of years represented.\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Normalize start/end dates to midnight before generating date range.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.Easter',\n",
       "       'descriptions': 'DateOffset for the Easter holiday using logic defined in dateutil. Right now uses the revised method which is valid in years 1583-4099.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 1. The number of years represented.\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Normalize start/end dates to midnight before generating date range.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Easter.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.freqstr.html#pandas.tseries.offsets.Easter.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Easter.freqstr',\n",
       "       'full_function': 'Easter.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Easter.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.name.html#pandas.tseries.offsets.Easter.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Easter.name',\n",
       "       'full_function': 'Easter.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Easter.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.normalize.html#pandas.tseries.offsets.Easter.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Easter.normalize',\n",
       "       'full_function': 'Easter.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Easter.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.n.html#pandas.tseries.offsets.Easter.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Easter.n',\n",
       "       'full_function': 'Easter.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Easter.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.copy.html#pandas.tseries.offsets.Easter.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Easter.copy',\n",
       "       'full_function': 'Easter.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Easter.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.is_on_offset.html#pandas.tseries.offsets.Easter.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Easter.is_on_offset',\n",
       "       'full_function': 'Easter.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.Easter.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Easter.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.is_month_end.html#pandas.tseries.offsets.Easter.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Easter.is_month_end',\n",
       "       'full_function': 'Easter.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Easter.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.is_quarter_end.html#pandas.tseries.offsets.Easter.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Easter.is_quarter_end',\n",
       "       'full_function': 'Easter.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Easter.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.is_year_end.html#pandas.tseries.offsets.Easter.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Easter.is_year_end',\n",
       "       'full_function': 'Easter.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Easter.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.kwds.html#pandas.tseries.offsets.Easter.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Easter.kwds',\n",
       "       'full_function': 'Easter.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Easter.nanos',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.nanos.html#pandas.tseries.offsets.Easter.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Easter.nanos',\n",
       "       'full_function': 'Easter.nanos#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Easter.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.rule_code.html#pandas.tseries.offsets.Easter.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Easter.rule_code',\n",
       "       'full_function': 'Easter.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Easter.is_anchored()',\n",
       "      'func_desc': '(DEPRECATED) Return boolean whether the frequency is a unit frequency (n=1).',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.is_anchored.html#pandas.tseries.offsets.Easter.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Easter.is_anchored',\n",
       "       'full_function': 'Easter.is_anchored()#',\n",
       "       'function_text': 'Return boolean whether the frequency is a unit frequency (n=1). Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse obj.n == 1 instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Easter.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.is_month_start.html#pandas.tseries.offsets.Easter.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Easter.is_month_start',\n",
       "       'full_function': 'Easter.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Easter.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.is_quarter_start.html#pandas.tseries.offsets.Easter.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Easter.is_quarter_start',\n",
       "       'full_function': 'Easter.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Easter.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.is_year_start.html#pandas.tseries.offsets.Easter.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Easter.is_year_start',\n",
       "       'full_function': 'Easter.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'Tick': [{'func_name': 'Tick',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.html#pandas.tseries.offsets.Tick',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Tick',\n",
       "       'full_function': 'class pandas.tseries.offsets.Tick#',\n",
       "       'function_text': 'Attributes base Returns a copy of the calling offset object with n=1 and all other attributes equal. delta  freqstr Return a string representing the frequency. kwds Return a dict of extra parameters for the offset. n  name Return a string representing the base frequency. nanos Return an integer of the total number of nanoseconds. normalize  rule_code  Methods copy() Return a copy of the frequency. is_anchored() (DEPRECATED) Return False. is_month_end(ts) Return boolean whether a timestamp occurs on the month end. is_month_start(ts) Return boolean whether a timestamp occurs on the month start. is_on_offset(dt) Return boolean whether a timestamp intersects with this frequency. is_quarter_end(ts) Return boolean whether a timestamp occurs on the quarter end. is_quarter_start(ts) Return boolean whether a timestamp occurs on the quarter start. is_year_end(ts) Return boolean whether a timestamp occurs on the year end. is_year_start(ts) Return boolean whether a timestamp occurs on the year start. rollback(dt) Roll provided date backward to next offset only if not on offset. rollforward(dt) Roll provided date forward to next offset only if not on offset.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Tick.delta',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.delta.html#pandas.tseries.offsets.Tick.delta',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Tick.delta',\n",
       "       'full_function': 'Tick.delta#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Tick.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.kwds.html#pandas.tseries.offsets.Tick.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Tick.kwds',\n",
       "       'full_function': 'Tick.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Tick.nanos',\n",
       "      'func_desc': 'Return an integer of the total number of nanoseconds.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.nanos.html#pandas.tseries.offsets.Tick.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Tick.nanos',\n",
       "       'full_function': 'Tick.nanos#',\n",
       "       'function_text': 'Return an integer of the total number of nanoseconds.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Tick.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.rule_code.html#pandas.tseries.offsets.Tick.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Tick.rule_code',\n",
       "       'full_function': 'Tick.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Tick.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.copy.html#pandas.tseries.offsets.Tick.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Tick.copy',\n",
       "       'full_function': 'Tick.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Tick.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.is_on_offset.html#pandas.tseries.offsets.Tick.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Tick.is_on_offset',\n",
       "       'full_function': 'Tick.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.Tick.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Tick.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.is_month_end.html#pandas.tseries.offsets.Tick.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Tick.is_month_end',\n",
       "       'full_function': 'Tick.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Tick.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.is_quarter_end.html#pandas.tseries.offsets.Tick.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Tick.is_quarter_end',\n",
       "       'full_function': 'Tick.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Tick.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.is_year_end.html#pandas.tseries.offsets.Tick.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Tick.is_year_end',\n",
       "       'full_function': 'Tick.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Tick.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.freqstr.html#pandas.tseries.offsets.Tick.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Tick.freqstr',\n",
       "       'full_function': 'Tick.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Tick.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.name.html#pandas.tseries.offsets.Tick.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Tick.name',\n",
       "       'full_function': 'Tick.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Tick.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.normalize.html#pandas.tseries.offsets.Tick.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Tick.normalize',\n",
       "       'full_function': 'Tick.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Tick.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.n.html#pandas.tseries.offsets.Tick.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Tick.n',\n",
       "       'full_function': 'Tick.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Tick.is_anchored()',\n",
       "      'func_desc': '(DEPRECATED) Return False.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.is_anchored.html#pandas.tseries.offsets.Tick.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Tick.is_anchored',\n",
       "       'full_function': 'Tick.is_anchored()#',\n",
       "       'function_text': 'Return False. Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse False instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Tick.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.is_month_start.html#pandas.tseries.offsets.Tick.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Tick.is_month_start',\n",
       "       'full_function': 'Tick.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Tick.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.is_quarter_start.html#pandas.tseries.offsets.Tick.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Tick.is_quarter_start',\n",
       "       'full_function': 'Tick.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Tick.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.is_year_start.html#pandas.tseries.offsets.Tick.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Tick.is_year_start',\n",
       "       'full_function': 'Tick.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'Day': [{'func_name': 'Day',\n",
       "      'func_desc': 'Offset n days.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.html#pandas.tseries.offsets.Day',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Day',\n",
       "       'full_function': 'class pandas.tseries.offsets.Day#',\n",
       "       'function_text': 'Offset n days.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'The number of days represented.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.Day',\n",
       "       'descriptions': 'Offset n days.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 1. The number of days represented.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Day.delta',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.delta.html#pandas.tseries.offsets.Day.delta',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Day.delta',\n",
       "       'full_function': 'Day.delta#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Day.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.kwds.html#pandas.tseries.offsets.Day.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Day.kwds',\n",
       "       'full_function': 'Day.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Day.nanos',\n",
       "      'func_desc': 'Return an integer of the total number of nanoseconds.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.nanos.html#pandas.tseries.offsets.Day.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Day.nanos',\n",
       "       'full_function': 'Day.nanos#',\n",
       "       'function_text': 'Return an integer of the total number of nanoseconds.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Day.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.rule_code.html#pandas.tseries.offsets.Day.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Day.rule_code',\n",
       "       'full_function': 'Day.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Day.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.copy.html#pandas.tseries.offsets.Day.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Day.copy',\n",
       "       'full_function': 'Day.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Day.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.is_on_offset.html#pandas.tseries.offsets.Day.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Day.is_on_offset',\n",
       "       'full_function': 'Day.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.Day.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Day.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.is_month_end.html#pandas.tseries.offsets.Day.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Day.is_month_end',\n",
       "       'full_function': 'Day.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Day.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.is_quarter_end.html#pandas.tseries.offsets.Day.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Day.is_quarter_end',\n",
       "       'full_function': 'Day.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Day.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.is_year_end.html#pandas.tseries.offsets.Day.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Day.is_year_end',\n",
       "       'full_function': 'Day.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Day.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.freqstr.html#pandas.tseries.offsets.Day.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Day.freqstr',\n",
       "       'full_function': 'Day.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Day.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.name.html#pandas.tseries.offsets.Day.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Day.name',\n",
       "       'full_function': 'Day.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Day.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.normalize.html#pandas.tseries.offsets.Day.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Day.normalize',\n",
       "       'full_function': 'Day.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Day.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.n.html#pandas.tseries.offsets.Day.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Day.n',\n",
       "       'full_function': 'Day.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Day.is_anchored()',\n",
       "      'func_desc': '(DEPRECATED) Return False.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.is_anchored.html#pandas.tseries.offsets.Day.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Day.is_anchored',\n",
       "       'full_function': 'Day.is_anchored()#',\n",
       "       'function_text': 'Return False. Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse False instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Day.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.is_month_start.html#pandas.tseries.offsets.Day.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Day.is_month_start',\n",
       "       'full_function': 'Day.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Day.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.is_quarter_start.html#pandas.tseries.offsets.Day.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Day.is_quarter_start',\n",
       "       'full_function': 'Day.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Day.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.is_year_start.html#pandas.tseries.offsets.Day.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Day.is_year_start',\n",
       "       'full_function': 'Day.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'Hour': [{'func_name': 'Hour',\n",
       "      'func_desc': 'Offset n hours.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.html#pandas.tseries.offsets.Hour',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Hour',\n",
       "       'full_function': 'class pandas.tseries.offsets.Hour#',\n",
       "       'function_text': 'Offset n hours.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'The number of hours represented.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.Hour',\n",
       "       'descriptions': 'Offset n hours.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 1. The number of hours represented.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Hour.delta',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.delta.html#pandas.tseries.offsets.Hour.delta',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Hour.delta',\n",
       "       'full_function': 'Hour.delta#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Hour.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.kwds.html#pandas.tseries.offsets.Hour.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Hour.kwds',\n",
       "       'full_function': 'Hour.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Hour.nanos',\n",
       "      'func_desc': 'Return an integer of the total number of nanoseconds.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.nanos.html#pandas.tseries.offsets.Hour.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Hour.nanos',\n",
       "       'full_function': 'Hour.nanos#',\n",
       "       'function_text': 'Return an integer of the total number of nanoseconds.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Hour.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.rule_code.html#pandas.tseries.offsets.Hour.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Hour.rule_code',\n",
       "       'full_function': 'Hour.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Hour.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.copy.html#pandas.tseries.offsets.Hour.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Hour.copy',\n",
       "       'full_function': 'Hour.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Hour.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.is_on_offset.html#pandas.tseries.offsets.Hour.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Hour.is_on_offset',\n",
       "       'full_function': 'Hour.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.Hour.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Hour.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.is_month_end.html#pandas.tseries.offsets.Hour.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Hour.is_month_end',\n",
       "       'full_function': 'Hour.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Hour.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.is_quarter_end.html#pandas.tseries.offsets.Hour.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Hour.is_quarter_end',\n",
       "       'full_function': 'Hour.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Hour.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.is_year_end.html#pandas.tseries.offsets.Hour.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Hour.is_year_end',\n",
       "       'full_function': 'Hour.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Hour.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.freqstr.html#pandas.tseries.offsets.Hour.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Hour.freqstr',\n",
       "       'full_function': 'Hour.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Hour.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.name.html#pandas.tseries.offsets.Hour.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Hour.name',\n",
       "       'full_function': 'Hour.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Hour.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.normalize.html#pandas.tseries.offsets.Hour.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Hour.normalize',\n",
       "       'full_function': 'Hour.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Hour.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.n.html#pandas.tseries.offsets.Hour.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Hour.n',\n",
       "       'full_function': 'Hour.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Hour.is_anchored()',\n",
       "      'func_desc': '(DEPRECATED) Return False.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.is_anchored.html#pandas.tseries.offsets.Hour.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Hour.is_anchored',\n",
       "       'full_function': 'Hour.is_anchored()#',\n",
       "       'function_text': 'Return False. Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse False instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Hour.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.is_month_start.html#pandas.tseries.offsets.Hour.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Hour.is_month_start',\n",
       "       'full_function': 'Hour.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Hour.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.is_quarter_start.html#pandas.tseries.offsets.Hour.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Hour.is_quarter_start',\n",
       "       'full_function': 'Hour.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Hour.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.is_year_start.html#pandas.tseries.offsets.Hour.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Hour.is_year_start',\n",
       "       'full_function': 'Hour.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'Minute': [{'func_name': 'Minute',\n",
       "      'func_desc': 'Offset n minutes.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.html#pandas.tseries.offsets.Minute',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Minute',\n",
       "       'full_function': 'class pandas.tseries.offsets.Minute#',\n",
       "       'function_text': 'Offset n minutes.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'The number of minutes represented.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.Minute',\n",
       "       'descriptions': 'Offset n minutes.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 1. The number of minutes represented.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Minute.delta',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.delta.html#pandas.tseries.offsets.Minute.delta',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Minute.delta',\n",
       "       'full_function': 'Minute.delta#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Minute.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.kwds.html#pandas.tseries.offsets.Minute.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Minute.kwds',\n",
       "       'full_function': 'Minute.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Minute.nanos',\n",
       "      'func_desc': 'Return an integer of the total number of nanoseconds.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.nanos.html#pandas.tseries.offsets.Minute.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Minute.nanos',\n",
       "       'full_function': 'Minute.nanos#',\n",
       "       'function_text': 'Return an integer of the total number of nanoseconds.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Minute.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.rule_code.html#pandas.tseries.offsets.Minute.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Minute.rule_code',\n",
       "       'full_function': 'Minute.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Minute.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.copy.html#pandas.tseries.offsets.Minute.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Minute.copy',\n",
       "       'full_function': 'Minute.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Minute.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.is_on_offset.html#pandas.tseries.offsets.Minute.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Minute.is_on_offset',\n",
       "       'full_function': 'Minute.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.Minute.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Minute.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.is_month_end.html#pandas.tseries.offsets.Minute.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Minute.is_month_end',\n",
       "       'full_function': 'Minute.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Minute.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.is_quarter_end.html#pandas.tseries.offsets.Minute.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Minute.is_quarter_end',\n",
       "       'full_function': 'Minute.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Minute.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.is_year_end.html#pandas.tseries.offsets.Minute.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Minute.is_year_end',\n",
       "       'full_function': 'Minute.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Minute.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.freqstr.html#pandas.tseries.offsets.Minute.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Minute.freqstr',\n",
       "       'full_function': 'Minute.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Minute.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.name.html#pandas.tseries.offsets.Minute.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Minute.name',\n",
       "       'full_function': 'Minute.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Minute.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.normalize.html#pandas.tseries.offsets.Minute.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Minute.normalize',\n",
       "       'full_function': 'Minute.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Minute.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.n.html#pandas.tseries.offsets.Minute.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Minute.n',\n",
       "       'full_function': 'Minute.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Minute.is_anchored()',\n",
       "      'func_desc': '(DEPRECATED) Return False.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.is_anchored.html#pandas.tseries.offsets.Minute.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Minute.is_anchored',\n",
       "       'full_function': 'Minute.is_anchored()#',\n",
       "       'function_text': 'Return False. Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse False instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Minute.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.is_month_start.html#pandas.tseries.offsets.Minute.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Minute.is_month_start',\n",
       "       'full_function': 'Minute.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Minute.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.is_quarter_start.html#pandas.tseries.offsets.Minute.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Minute.is_quarter_start',\n",
       "       'full_function': 'Minute.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Minute.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.is_year_start.html#pandas.tseries.offsets.Minute.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Minute.is_year_start',\n",
       "       'full_function': 'Minute.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'Second': [{'func_name': 'Second',\n",
       "      'func_desc': 'Offset n seconds.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.html#pandas.tseries.offsets.Second',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Second',\n",
       "       'full_function': 'class pandas.tseries.offsets.Second#',\n",
       "       'function_text': 'Offset n seconds.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'The number of seconds represented.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.Second',\n",
       "       'descriptions': 'Offset n seconds.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 1. The number of seconds represented.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Second.delta',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.delta.html#pandas.tseries.offsets.Second.delta',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Second.delta',\n",
       "       'full_function': 'Second.delta#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Second.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.kwds.html#pandas.tseries.offsets.Second.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Second.kwds',\n",
       "       'full_function': 'Second.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Second.nanos',\n",
       "      'func_desc': 'Return an integer of the total number of nanoseconds.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.nanos.html#pandas.tseries.offsets.Second.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Second.nanos',\n",
       "       'full_function': 'Second.nanos#',\n",
       "       'function_text': 'Return an integer of the total number of nanoseconds.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Second.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.rule_code.html#pandas.tseries.offsets.Second.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Second.rule_code',\n",
       "       'full_function': 'Second.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Second.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.copy.html#pandas.tseries.offsets.Second.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Second.copy',\n",
       "       'full_function': 'Second.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Second.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.is_on_offset.html#pandas.tseries.offsets.Second.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Second.is_on_offset',\n",
       "       'full_function': 'Second.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.Second.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Second.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.is_month_end.html#pandas.tseries.offsets.Second.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Second.is_month_end',\n",
       "       'full_function': 'Second.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Second.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.is_quarter_end.html#pandas.tseries.offsets.Second.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Second.is_quarter_end',\n",
       "       'full_function': 'Second.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Second.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.is_year_end.html#pandas.tseries.offsets.Second.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Second.is_year_end',\n",
       "       'full_function': 'Second.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Second.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.freqstr.html#pandas.tseries.offsets.Second.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Second.freqstr',\n",
       "       'full_function': 'Second.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Second.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.name.html#pandas.tseries.offsets.Second.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Second.name',\n",
       "       'full_function': 'Second.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Second.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.normalize.html#pandas.tseries.offsets.Second.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Second.normalize',\n",
       "       'full_function': 'Second.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Second.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.n.html#pandas.tseries.offsets.Second.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Second.n',\n",
       "       'full_function': 'Second.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Second.is_anchored()',\n",
       "      'func_desc': '(DEPRECATED) Return False.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.is_anchored.html#pandas.tseries.offsets.Second.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Second.is_anchored',\n",
       "       'full_function': 'Second.is_anchored()#',\n",
       "       'function_text': 'Return False. Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse False instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Second.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.is_month_start.html#pandas.tseries.offsets.Second.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Second.is_month_start',\n",
       "       'full_function': 'Second.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Second.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.is_quarter_start.html#pandas.tseries.offsets.Second.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Second.is_quarter_start',\n",
       "       'full_function': 'Second.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Second.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.is_year_start.html#pandas.tseries.offsets.Second.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Second.is_year_start',\n",
       "       'full_function': 'Second.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'Milli': [{'func_name': 'Milli',\n",
       "      'func_desc': 'Offset n milliseconds.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.html#pandas.tseries.offsets.Milli',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Milli',\n",
       "       'full_function': 'class pandas.tseries.offsets.Milli#',\n",
       "       'function_text': 'Offset n milliseconds.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'The number of milliseconds represented.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.Milli',\n",
       "       'descriptions': 'Offset n milliseconds.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 1. The number of milliseconds represented.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Milli.delta',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.delta.html#pandas.tseries.offsets.Milli.delta',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Milli.delta',\n",
       "       'full_function': 'Milli.delta#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Milli.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.kwds.html#pandas.tseries.offsets.Milli.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Milli.kwds',\n",
       "       'full_function': 'Milli.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Milli.nanos',\n",
       "      'func_desc': 'Return an integer of the total number of nanoseconds.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.nanos.html#pandas.tseries.offsets.Milli.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Milli.nanos',\n",
       "       'full_function': 'Milli.nanos#',\n",
       "       'function_text': 'Return an integer of the total number of nanoseconds.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Milli.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.rule_code.html#pandas.tseries.offsets.Milli.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Milli.rule_code',\n",
       "       'full_function': 'Milli.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Milli.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.copy.html#pandas.tseries.offsets.Milli.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Milli.copy',\n",
       "       'full_function': 'Milli.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Milli.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.is_on_offset.html#pandas.tseries.offsets.Milli.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Milli.is_on_offset',\n",
       "       'full_function': 'Milli.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.Milli.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Milli.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.is_month_end.html#pandas.tseries.offsets.Milli.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Milli.is_month_end',\n",
       "       'full_function': 'Milli.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Milli.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.is_quarter_end.html#pandas.tseries.offsets.Milli.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Milli.is_quarter_end',\n",
       "       'full_function': 'Milli.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Milli.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.is_year_end.html#pandas.tseries.offsets.Milli.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Milli.is_year_end',\n",
       "       'full_function': 'Milli.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Milli.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.freqstr.html#pandas.tseries.offsets.Milli.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Milli.freqstr',\n",
       "       'full_function': 'Milli.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Milli.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.name.html#pandas.tseries.offsets.Milli.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Milli.name',\n",
       "       'full_function': 'Milli.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Milli.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.normalize.html#pandas.tseries.offsets.Milli.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Milli.normalize',\n",
       "       'full_function': 'Milli.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Milli.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.n.html#pandas.tseries.offsets.Milli.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Milli.n',\n",
       "       'full_function': 'Milli.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Milli.is_anchored()',\n",
       "      'func_desc': '(DEPRECATED) Return False.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.is_anchored.html#pandas.tseries.offsets.Milli.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Milli.is_anchored',\n",
       "       'full_function': 'Milli.is_anchored()#',\n",
       "       'function_text': 'Return False. Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse False instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Milli.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.is_month_start.html#pandas.tseries.offsets.Milli.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Milli.is_month_start',\n",
       "       'full_function': 'Milli.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Milli.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.is_quarter_start.html#pandas.tseries.offsets.Milli.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Milli.is_quarter_start',\n",
       "       'full_function': 'Milli.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Milli.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.is_year_start.html#pandas.tseries.offsets.Milli.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Milli.is_year_start',\n",
       "       'full_function': 'Milli.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'Micro': [{'func_name': 'Micro',\n",
       "      'func_desc': 'Offset n microseconds.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.html#pandas.tseries.offsets.Micro',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Micro',\n",
       "       'full_function': 'class pandas.tseries.offsets.Micro#',\n",
       "       'function_text': 'Offset n microseconds.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'The number of microseconds represented.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.Micro',\n",
       "       'descriptions': 'Offset n microseconds.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 1. The number of microseconds represented.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Micro.delta',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.delta.html#pandas.tseries.offsets.Micro.delta',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Micro.delta',\n",
       "       'full_function': 'Micro.delta#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Micro.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.kwds.html#pandas.tseries.offsets.Micro.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Micro.kwds',\n",
       "       'full_function': 'Micro.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Micro.nanos',\n",
       "      'func_desc': 'Return an integer of the total number of nanoseconds.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.nanos.html#pandas.tseries.offsets.Micro.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Micro.nanos',\n",
       "       'full_function': 'Micro.nanos#',\n",
       "       'function_text': 'Return an integer of the total number of nanoseconds.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Micro.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.rule_code.html#pandas.tseries.offsets.Micro.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Micro.rule_code',\n",
       "       'full_function': 'Micro.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Micro.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.copy.html#pandas.tseries.offsets.Micro.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Micro.copy',\n",
       "       'full_function': 'Micro.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Micro.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.is_on_offset.html#pandas.tseries.offsets.Micro.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Micro.is_on_offset',\n",
       "       'full_function': 'Micro.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.Micro.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Micro.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.is_month_end.html#pandas.tseries.offsets.Micro.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Micro.is_month_end',\n",
       "       'full_function': 'Micro.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Micro.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.is_quarter_end.html#pandas.tseries.offsets.Micro.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Micro.is_quarter_end',\n",
       "       'full_function': 'Micro.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Micro.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.is_year_end.html#pandas.tseries.offsets.Micro.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Micro.is_year_end',\n",
       "       'full_function': 'Micro.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Micro.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.freqstr.html#pandas.tseries.offsets.Micro.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Micro.freqstr',\n",
       "       'full_function': 'Micro.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Micro.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.name.html#pandas.tseries.offsets.Micro.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Micro.name',\n",
       "       'full_function': 'Micro.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Micro.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.normalize.html#pandas.tseries.offsets.Micro.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Micro.normalize',\n",
       "       'full_function': 'Micro.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Micro.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.n.html#pandas.tseries.offsets.Micro.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Micro.n',\n",
       "       'full_function': 'Micro.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Micro.is_anchored()',\n",
       "      'func_desc': '(DEPRECATED) Return False.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.is_anchored.html#pandas.tseries.offsets.Micro.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Micro.is_anchored',\n",
       "       'full_function': 'Micro.is_anchored()#',\n",
       "       'function_text': 'Return False. Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse False instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Micro.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.is_month_start.html#pandas.tseries.offsets.Micro.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Micro.is_month_start',\n",
       "       'full_function': 'Micro.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Micro.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.is_quarter_start.html#pandas.tseries.offsets.Micro.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Micro.is_quarter_start',\n",
       "       'full_function': 'Micro.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Micro.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.is_year_start.html#pandas.tseries.offsets.Micro.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Micro.is_year_start',\n",
       "       'full_function': 'Micro.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'Nano': [{'func_name': 'Nano',\n",
       "      'func_desc': 'Offset n nanoseconds.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.html#pandas.tseries.offsets.Nano',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Nano',\n",
       "       'full_function': 'class pandas.tseries.offsets.Nano#',\n",
       "       'function_text': 'Offset n nanoseconds.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'The number of nanoseconds represented.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.Nano',\n",
       "       'descriptions': 'Offset n nanoseconds.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 1. The number of nanoseconds represented.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Nano.delta',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.delta.html#pandas.tseries.offsets.Nano.delta',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Nano.delta',\n",
       "       'full_function': 'Nano.delta#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Nano.kwds',\n",
       "      'func_desc': 'Return a dict of extra parameters for the offset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.kwds.html#pandas.tseries.offsets.Nano.kwds',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Nano.kwds',\n",
       "       'full_function': 'Nano.kwds#',\n",
       "       'function_text': 'Return a dict of extra parameters for the offset. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Nano.nanos',\n",
       "      'func_desc': 'Return an integer of the total number of nanoseconds.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.nanos.html#pandas.tseries.offsets.Nano.nanos',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Nano.nanos',\n",
       "       'full_function': 'Nano.nanos#',\n",
       "       'function_text': 'Return an integer of the total number of nanoseconds.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Nano.rule_code',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.rule_code.html#pandas.tseries.offsets.Nano.rule_code',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Nano.rule_code',\n",
       "       'full_function': 'Nano.rule_code#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Nano.copy()',\n",
       "      'func_desc': 'Return a copy of the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.copy.html#pandas.tseries.offsets.Nano.copy',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Nano.copy',\n",
       "       'full_function': 'Nano.copy()#',\n",
       "       'function_text': 'Return a copy of the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Nano.is_on_offset(dt)',\n",
       "      'func_desc': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.is_on_offset.html#pandas.tseries.offsets.Nano.is_on_offset',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Nano.is_on_offset',\n",
       "       'full_function': 'Nano.is_on_offset(dt)#',\n",
       "       'function_text': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameter_names_desc': [{'param_name': 'dt',\n",
       "         'param_type': 'datetime.datetime',\n",
       "         'param_desc': 'Timestamp to check intersections with frequency.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.tseries.offsets.Nano.is_on_offset',\n",
       "       'descriptions': 'Return boolean whether a timestamp intersects with this frequency.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dt': {'type': 'datetime.datetime',\n",
       "          'description': 'datetime.datetime. Timestamp to check intersections with frequency.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Nano.is_month_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.is_month_end.html#pandas.tseries.offsets.Nano.is_month_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Nano.is_month_end',\n",
       "       'full_function': 'Nano.is_month_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Nano.is_quarter_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.is_quarter_end.html#pandas.tseries.offsets.Nano.is_quarter_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Nano.is_quarter_end',\n",
       "       'full_function': 'Nano.is_quarter_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Nano.is_year_end(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year end.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.is_year_end.html#pandas.tseries.offsets.Nano.is_year_end',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Nano.is_year_end',\n",
       "       'full_function': 'Nano.is_year_end(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year end. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Nano.freqstr',\n",
       "      'func_desc': 'Return a string representing the frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.freqstr.html#pandas.tseries.offsets.Nano.freqstr',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Nano.freqstr',\n",
       "       'full_function': 'Nano.freqstr#',\n",
       "       'function_text': 'Return a string representing the frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Nano.name',\n",
       "      'func_desc': 'Return a string representing the base frequency.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.name.html#pandas.tseries.offsets.Nano.name',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Nano.name',\n",
       "       'full_function': 'Nano.name#',\n",
       "       'function_text': 'Return a string representing the base frequency. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Nano.normalize',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.normalize.html#pandas.tseries.offsets.Nano.normalize',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Nano.normalize',\n",
       "       'full_function': 'Nano.normalize#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Nano.n',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.n.html#pandas.tseries.offsets.Nano.n',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Nano.n',\n",
       "       'full_function': 'Nano.n#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Nano.is_anchored()',\n",
       "      'func_desc': '(DEPRECATED) Return False.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.is_anchored.html#pandas.tseries.offsets.Nano.is_anchored',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Nano.is_anchored',\n",
       "       'full_function': 'Nano.is_anchored()#',\n",
       "       'function_text': 'Return False. Deprecated since version 2.2.0: is_anchored is deprecated and will be removed in a future version.\\nUse False instead. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Nano.is_month_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the month start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.is_month_start.html#pandas.tseries.offsets.Nano.is_month_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Nano.is_month_start',\n",
       "       'full_function': 'Nano.is_month_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the month start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Nano.is_quarter_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the quarter start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.is_quarter_start.html#pandas.tseries.offsets.Nano.is_quarter_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Nano.is_quarter_start',\n",
       "       'full_function': 'Nano.is_quarter_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the quarter start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Nano.is_year_start(ts)',\n",
       "      'func_desc': 'Return boolean whether a timestamp occurs on the year start.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.is_year_start.html#pandas.tseries.offsets.Nano.is_year_start',\n",
       "      'function_definitions': {'function_name': 'pandas.tseries.offsets.Nano.is_year_start',\n",
       "       'full_function': 'Nano.is_year_start(ts)#',\n",
       "       'function_text': 'Return boolean whether a timestamp occurs on the year start. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]}],\n",
       "  'name': 'Date offsets',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/offset_frequency.html'},\n",
       " 'window.html': {'functions': [{'Rolling window functions': [{'func_name': 'Rolling.count([numeric_only])',\n",
       "      'func_desc': 'Calculate the rolling count of non NaN observations.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.count.html#pandas.core.window.rolling.Rolling.count',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.rolling.Rolling.count',\n",
       "       'full_function': 'Rolling.count(numeric_only=False)',\n",
       "       'function_text': 'Calculate the rolling count of non NaN observations.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.rolling.Rolling.count',\n",
       "       'descriptions': 'Calculate the rolling count of non NaN observations.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Rolling.mean([numeric_only,\\xa0engine,\\xa0...])',\n",
       "      'func_desc': 'Calculate the rolling mean.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.mean.html#pandas.core.window.rolling.Rolling.mean',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.rolling.Rolling.mean',\n",
       "       'full_function': 'Rolling.mean(numeric_only=False, engine=None, engine_kwargs=None)',\n",
       "       'function_text': 'Calculate the rolling mean.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': \"\\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False}\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.rolling.Rolling.mean',\n",
       "       'descriptions': 'Calculate the rolling mean.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None. \\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None',\n",
       "          'description': \"dict, default None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False}\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Rolling.var([ddof,\\xa0numeric_only,\\xa0engine,\\xa0...])',\n",
       "      'func_desc': 'Calculate the rolling variance.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.var.html#pandas.core.window.rolling.Rolling.var',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.rolling.Rolling.var',\n",
       "       'full_function': 'Rolling.var(ddof=1, numeric_only=False, engine=None, engine_kwargs=None)',\n",
       "       'function_text': 'Calculate the rolling variance.',\n",
       "       'parameter_names_desc': [{'param_name': 'ddof',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Delta Degrees of Freedom. The divisor used in calculations\\nis N - ddof, where N represents the number of elements.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': \"\\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\nNew in version 1.4.0.\\n\\n\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False}\\n\\nNew in version 1.4.0.\\n\\n\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.rolling.Rolling.var',\n",
       "       'descriptions': 'Calculate the rolling variance.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'ddof': {'type': 'integer',\n",
       "          'description': 'int, default 1. Delta Degrees of Freedom. The divisor used in calculations\\nis N - ddof, where N represents the number of elements.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None. \\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\nNew in version 1.4.0.\\n\\n\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None',\n",
       "          'description': \"dict, default None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False}\\n\\nNew in version 1.4.0.\\n\\n\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Rolling.min([numeric_only,\\xa0engine,\\xa0...])',\n",
       "      'func_desc': 'Calculate the rolling minimum.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.min.html#pandas.core.window.rolling.Rolling.min',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.rolling.Rolling.min',\n",
       "       'full_function': 'Rolling.min(numeric_only=False, engine=None, engine_kwargs=None)',\n",
       "       'function_text': 'Calculate the rolling minimum.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': \"\\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False}\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.rolling.Rolling.min',\n",
       "       'descriptions': 'Calculate the rolling minimum.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None. \\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None',\n",
       "          'description': \"dict, default None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False}\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Rolling.corr([other,\\xa0pairwise,\\xa0ddof,\\xa0...])',\n",
       "      'func_desc': 'Calculate the rolling correlation.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.corr.html#pandas.core.window.rolling.Rolling.corr',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.rolling.Rolling.corr',\n",
       "       'full_function': 'Rolling.corr(other=None, pairwise=None, ddof=1, numeric_only=False)',\n",
       "       'function_text': 'Calculate the rolling correlation.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series or DataFrame, optional',\n",
       "         'param_desc': 'If not supplied then will default to self and produce pairwise\\noutput.\\n'},\n",
       "        {'param_name': 'pairwise',\n",
       "         'param_type': 'bool, default None',\n",
       "         'param_desc': 'If False then only matching columns between self and other will be\\nused and the output will be a DataFrame.\\nIf True then all pairwise combinations will be calculated and the\\noutput will be a MultiIndexed DataFrame in the case of DataFrame\\ninputs. In the case of missing elements, only complete pairwise\\nobservations will be used.\\n'},\n",
       "        {'param_name': 'ddof',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Delta Degrees of Freedom. The divisor used in calculations\\nis N - ddof, where N represents the number of elements.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.rolling.Rolling.corr',\n",
       "       'descriptions': 'Calculate the rolling correlation.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series or DataFrame, optional',\n",
       "          'description': 'Series or DataFrame, optional. If not supplied then will default to self and produce pairwise\\noutput.\\n'},\n",
       "         'pairwise': {'type': 'boolean',\n",
       "          'description': 'bool, default None. If False then only matching columns between self and other will be\\nused and the output will be a DataFrame.\\nIf True then all pairwise combinations will be calculated and the\\noutput will be a MultiIndexed DataFrame in the case of DataFrame\\ninputs. In the case of missing elements, only complete pairwise\\nobservations will be used.\\n'},\n",
       "         'ddof': {'type': 'integer',\n",
       "          'description': 'int, default 1. Delta Degrees of Freedom. The divisor used in calculations\\nis N - ddof, where N represents the number of elements.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Rolling.skew([numeric_only])',\n",
       "      'func_desc': 'Calculate the rolling unbiased skewness.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.skew.html#pandas.core.window.rolling.Rolling.skew',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.rolling.Rolling.skew',\n",
       "       'full_function': 'Rolling.skew(numeric_only=False)',\n",
       "       'function_text': 'Calculate the rolling unbiased skewness.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.rolling.Rolling.skew',\n",
       "       'descriptions': 'Calculate the rolling unbiased skewness.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Rolling.apply(func[,\\xa0raw,\\xa0engine,\\xa0...])',\n",
       "      'func_desc': 'Calculate the rolling custom aggregation function.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.apply.html#pandas.core.window.rolling.Rolling.apply',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.rolling.Rolling.apply',\n",
       "       'full_function': 'Rolling.apply(func, raw=False, engine=None, engine_kwargs=None, args=None, kwargs=None)',\n",
       "       'function_text': 'Calculate the rolling custom aggregation function.',\n",
       "       'parameter_names_desc': [{'param_name': 'func',\n",
       "         'param_type': 'function',\n",
       "         'param_desc': \"Must produce a single value from an ndarray input if raw=True\\nor a single value from a Series if raw=False. Can also accept a\\nNumba JIT function with engine='numba' specified.\\n\"},\n",
       "        {'param_name': 'raw',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': '\\nFalse : passes each row or column as a Series to the\\nfunction.\\nTrue : the passed function will receive ndarray\\nobjects instead.\\nIf you are just applying a NumPy reduction function this will\\nachieve much better performance.\\n\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': \"\\n'cython' : Runs rolling apply through C-extensions from cython.\\n'numba' : Runs rolling apply through JIT compiled code from numba.\\nOnly available when raw is set to True.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\\napplied to both the func and the apply rolling aggregation.\\n\\n\"},\n",
       "        {'param_name': 'args',\n",
       "         'param_type': 'tuple, default None',\n",
       "         'param_desc': 'Positional arguments to be passed into func.\\n'},\n",
       "        {'param_name': 'kwargs',\n",
       "         'param_type': 'dict, default None',\n",
       "         'param_desc': 'Keyword arguments to be passed into func.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.rolling.Rolling.apply',\n",
       "       'descriptions': 'Calculate the rolling custom aggregation function.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'func': {'type': 'function',\n",
       "          'description': \"function. Must produce a single value from an ndarray input if raw=True\\nor a single value from a Series if raw=False. Can also accept a\\nNumba JIT function with engine='numba' specified.\\n\"},\n",
       "         'raw': {'type': 'boolean',\n",
       "          'description': 'bool, default False. \\nFalse : passes each row or column as a Series to the\\nfunction.\\nTrue : the passed function will receive ndarray\\nobjects instead.\\nIf you are just applying a NumPy reduction function this will\\nachieve much better performance.\\n\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None. \\n'cython' : Runs rolling apply through C-extensions from cython.\\n'numba' : Runs rolling apply through JIT compiled code from numba.\\nOnly available when raw is set to True.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None',\n",
       "          'description': \"dict, default None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\\napplied to both the func and the apply rolling aggregation.\\n\\n\"},\n",
       "         'args': {'type': 'tuple, default None',\n",
       "          'description': 'tuple, default None. Positional arguments to be passed into func.\\n'},\n",
       "         'kwargs': {'type': 'dict, default None',\n",
       "          'description': 'dict, default None. Keyword arguments to be passed into func.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Rolling.quantile(q[,\\xa0interpolation,\\xa0...])',\n",
       "      'func_desc': 'Calculate the rolling quantile.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.quantile.html#pandas.core.window.rolling.Rolling.quantile',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.rolling.Rolling.quantile',\n",
       "       'full_function': \"Rolling.quantile(q, interpolation='linear', numeric_only=False)\",\n",
       "       'function_text': 'Calculate the rolling quantile.',\n",
       "       'parameter_names_desc': [{'param_name': 'quantile',\n",
       "         'param_type': 'float',\n",
       "         'param_desc': 'Quantile to compute. 0 <= quantile <= 1.\\n\\nDeprecated since version 2.1.0: This will be renamed to ‘q’ in a future version.\\n\\n'},\n",
       "        {'param_name': 'interpolation',\n",
       "         'param_type': '{‘linear’, ‘lower’, ‘higher’, ‘midpoint’, ‘nearest’}',\n",
       "         'param_desc': 'This optional parameter specifies the interpolation method to use,\\nwhen the desired quantile lies between two data points i and j:\\n\\n\\nlinear: i + (j - i) * fraction, where fraction is the\\nfractional part of the index surrounded by i and j.\\nlower: i.\\nhigher: j.\\nnearest: i or j whichever is nearest.\\nmidpoint: (i + j) / 2.\\n\\n\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.rolling.Rolling.quantile',\n",
       "       'descriptions': 'Calculate the rolling quantile.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'quantile': {'type': 'float',\n",
       "          'description': 'float. Quantile to compute. 0 <= quantile <= 1.\\n\\nDeprecated since version 2.1.0: This will be renamed to ‘q’ in a future version.\\n\\n'},\n",
       "         'interpolation': {'type': 'integer',\n",
       "          'description': '{‘linear’, ‘lower’, ‘higher’, ‘midpoint’, ‘nearest’}. This optional parameter specifies the interpolation method to use,\\nwhen the desired quantile lies between two data points i and j:\\n\\n\\nlinear: i + (j - i) * fraction, where fraction is the\\nfractional part of the index surrounded by i and j.\\nlower: i.\\nhigher: j.\\nnearest: i or j whichever is nearest.\\nmidpoint: (i + j) / 2.\\n\\n\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Rolling.rank([method,\\xa0ascending,\\xa0pct,\\xa0...])',\n",
       "      'func_desc': 'Calculate the rolling rank.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.rank.html#pandas.core.window.rolling.Rolling.rank',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.rolling.Rolling.rank',\n",
       "       'full_function': \"Rolling.rank(method='average', ascending=True, pct=False, numeric_only=False)\",\n",
       "       'function_text': 'Calculate the rolling rank. New in version 1.4.0.',\n",
       "       'parameter_names_desc': [{'param_name': 'method',\n",
       "         'param_type': '{‘average’, ‘min’, ‘max’}, default ‘average’',\n",
       "         'param_desc': 'How to rank the group of records that have the same value (i.e. ties):\\n\\naverage: average rank of the group\\nmin: lowest rank in the group\\nmax: highest rank in the group\\n\\n'},\n",
       "        {'param_name': 'ascending',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether or not the elements should be ranked in ascending order.\\n'},\n",
       "        {'param_name': 'pct',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether or not to display the returned rankings in percentile\\nform.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.rolling.Rolling.rank',\n",
       "       'descriptions': 'Calculate the rolling rank. New in version 1.4.0.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'method': {'type': 'string',\n",
       "          'enum': ['average', ' min', ' max'],\n",
       "          'description': '{‘average’, ‘min’, ‘max’}, default ‘average’. How to rank the group of records that have the same value (i.e. ties):\\n\\naverage: average rank of the group\\nmin: lowest rank in the group\\nmax: highest rank in the group\\n\\n'},\n",
       "         'ascending': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether or not the elements should be ranked in ascending order.\\n'},\n",
       "         'pct': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether or not to display the returned rankings in percentile\\nform.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Rolling.sum([numeric_only,\\xa0engine,\\xa0...])',\n",
       "      'func_desc': 'Calculate the rolling sum.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.sum.html#pandas.core.window.rolling.Rolling.sum',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.rolling.Rolling.sum',\n",
       "       'full_function': 'Rolling.sum(numeric_only=False, engine=None, engine_kwargs=None)',\n",
       "       'function_text': 'Calculate the rolling sum.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': \"\\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False}\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.rolling.Rolling.sum',\n",
       "       'descriptions': 'Calculate the rolling sum.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None. \\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None',\n",
       "          'description': \"dict, default None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False}\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Rolling.median([numeric_only,\\xa0engine,\\xa0...])',\n",
       "      'func_desc': 'Calculate the rolling median.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.median.html#pandas.core.window.rolling.Rolling.median',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.rolling.Rolling.median',\n",
       "       'full_function': 'Rolling.median(numeric_only=False, engine=None, engine_kwargs=None)',\n",
       "       'function_text': 'Calculate the rolling median.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': \"\\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False}\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.rolling.Rolling.median',\n",
       "       'descriptions': 'Calculate the rolling median.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None. \\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None',\n",
       "          'description': \"dict, default None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False}\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Rolling.std([ddof,\\xa0numeric_only,\\xa0engine,\\xa0...])',\n",
       "      'func_desc': 'Calculate the rolling standard deviation.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.std.html#pandas.core.window.rolling.Rolling.std',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.rolling.Rolling.std',\n",
       "       'full_function': 'Rolling.std(ddof=1, numeric_only=False, engine=None, engine_kwargs=None)',\n",
       "       'function_text': 'Calculate the rolling standard deviation.',\n",
       "       'parameter_names_desc': [{'param_name': 'ddof',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Delta Degrees of Freedom. The divisor used in calculations\\nis N - ddof, where N represents the number of elements.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': \"\\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\nNew in version 1.4.0.\\n\\n\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False}\\n\\nNew in version 1.4.0.\\n\\n\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.rolling.Rolling.std',\n",
       "       'descriptions': 'Calculate the rolling standard deviation.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'ddof': {'type': 'integer',\n",
       "          'description': 'int, default 1. Delta Degrees of Freedom. The divisor used in calculations\\nis N - ddof, where N represents the number of elements.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None. \\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\nNew in version 1.4.0.\\n\\n\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None',\n",
       "          'description': \"dict, default None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False}\\n\\nNew in version 1.4.0.\\n\\n\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Rolling.max([numeric_only,\\xa0engine,\\xa0...])',\n",
       "      'func_desc': 'Calculate the rolling maximum.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.max.html#pandas.core.window.rolling.Rolling.max',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.rolling.Rolling.max',\n",
       "       'full_function': 'Rolling.max(numeric_only=False, *args, engine=None, engine_kwargs=None, **kwargs)',\n",
       "       'function_text': 'Calculate the rolling maximum.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': \"\\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False}\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.rolling.Rolling.max',\n",
       "       'descriptions': 'Calculate the rolling maximum.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None. \\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None',\n",
       "          'description': \"dict, default None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False}\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Rolling.cov([other,\\xa0pairwise,\\xa0ddof,\\xa0...])',\n",
       "      'func_desc': 'Calculate the rolling sample covariance.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.cov.html#pandas.core.window.rolling.Rolling.cov',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.rolling.Rolling.cov',\n",
       "       'full_function': 'Rolling.cov(other=None, pairwise=None, ddof=1, numeric_only=False)',\n",
       "       'function_text': 'Calculate the rolling sample covariance.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series or DataFrame, optional',\n",
       "         'param_desc': 'If not supplied then will default to self and produce pairwise\\noutput.\\n'},\n",
       "        {'param_name': 'pairwise',\n",
       "         'param_type': 'bool, default None',\n",
       "         'param_desc': 'If False then only matching columns between self and other will be\\nused and the output will be a DataFrame.\\nIf True then all pairwise combinations will be calculated and the\\noutput will be a MultiIndexed DataFrame in the case of DataFrame\\ninputs. In the case of missing elements, only complete pairwise\\nobservations will be used.\\n'},\n",
       "        {'param_name': 'ddof',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Delta Degrees of Freedom. The divisor used in calculations\\nis N - ddof, where N represents the number of elements.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.rolling.Rolling.cov',\n",
       "       'descriptions': 'Calculate the rolling sample covariance.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series or DataFrame, optional',\n",
       "          'description': 'Series or DataFrame, optional. If not supplied then will default to self and produce pairwise\\noutput.\\n'},\n",
       "         'pairwise': {'type': 'boolean',\n",
       "          'description': 'bool, default None. If False then only matching columns between self and other will be\\nused and the output will be a DataFrame.\\nIf True then all pairwise combinations will be calculated and the\\noutput will be a MultiIndexed DataFrame in the case of DataFrame\\ninputs. In the case of missing elements, only complete pairwise\\nobservations will be used.\\n'},\n",
       "         'ddof': {'type': 'integer',\n",
       "          'description': 'int, default 1. Delta Degrees of Freedom. The divisor used in calculations\\nis N - ddof, where N represents the number of elements.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Rolling.kurt([numeric_only])',\n",
       "      'func_desc': \"Calculate the rolling Fisher's definition of kurtosis without bias.\",\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.kurt.html#pandas.core.window.rolling.Rolling.kurt',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.rolling.Rolling.kurt',\n",
       "       'full_function': 'Rolling.kurt(numeric_only=False)',\n",
       "       'function_text': 'Calculate the rolling Fisher’s definition of kurtosis without bias.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.rolling.Rolling.kurt',\n",
       "       'descriptions': 'Calculate the rolling Fisher’s definition of kurtosis without bias.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Rolling.aggregate(func,\\xa0*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Aggregate using one or more operations over the specified axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.aggregate.html#pandas.core.window.rolling.Rolling.aggregate',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.rolling.Rolling.aggregate',\n",
       "       'full_function': 'Rolling.aggregate(func, *args, **kwargs)',\n",
       "       'function_text': 'Aggregate using one or more operations over the specified axis.',\n",
       "       'parameter_names_desc': [{'param_name': 'func',\n",
       "         'param_type': 'function, str, list or dict',\n",
       "         'param_desc': \"Function to use for aggregating the data. If a function, must either\\nwork when passed a Series/Dataframe or when passed to Series/Dataframe.apply.\\nAccepted combinations are:\\n\\nfunction\\nstring function name\\nlist of functions and/or function names, e.g. [np.sum, 'mean']\\ndict of axis labels -> functions, function names or list of such.\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.rolling.Rolling.aggregate',\n",
       "       'descriptions': 'Aggregate using one or more operations over the specified axis.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'func': {'type': 'string',\n",
       "          'description': \"function, str, list or dict. Function to use for aggregating the data. If a function, must either\\nwork when passed a Series/Dataframe or when passed to Series/Dataframe.apply.\\nAccepted combinations are:\\n\\nfunction\\nstring function name\\nlist of functions and/or function names, e.g. [np.sum, 'mean']\\ndict of axis labels -> functions, function names or list of such.\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Rolling.sem([ddof,\\xa0numeric_only])',\n",
       "      'func_desc': 'Calculate the rolling standard error of mean.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.sem.html#pandas.core.window.rolling.Rolling.sem',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.rolling.Rolling.sem',\n",
       "       'full_function': 'Rolling.sem(ddof=1, numeric_only=False)',\n",
       "       'function_text': 'Calculate the rolling standard error of mean.',\n",
       "       'parameter_names_desc': [{'param_name': 'ddof',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Delta Degrees of Freedom. The divisor used in calculations\\nis N - ddof, where N represents the number of elements.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.rolling.Rolling.sem',\n",
       "       'descriptions': 'Calculate the rolling standard error of mean.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'ddof': {'type': 'integer',\n",
       "          'description': 'int, default 1. Delta Degrees of Freedom. The divisor used in calculations\\nis N - ddof, where N represents the number of elements.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Weighted window functions': [{'func_name': 'Window.mean([numeric_only])',\n",
       "      'func_desc': 'Calculate the rolling weighted window mean.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Window.mean.html#pandas.core.window.rolling.Window.mean',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.rolling.Window.mean',\n",
       "       'full_function': 'Window.mean(numeric_only=False, **kwargs)',\n",
       "       'function_text': 'Calculate the rolling weighted window mean.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.rolling.Window.mean',\n",
       "       'descriptions': 'Calculate the rolling weighted window mean.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Window.var([ddof,\\xa0numeric_only])',\n",
       "      'func_desc': 'Calculate the rolling weighted window variance.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Window.var.html#pandas.core.window.rolling.Window.var',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.rolling.Window.var',\n",
       "       'full_function': 'Window.var(ddof=1, numeric_only=False, **kwargs)',\n",
       "       'function_text': 'Calculate the rolling weighted window variance.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.rolling.Window.var',\n",
       "       'descriptions': 'Calculate the rolling weighted window variance.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Window.sum([numeric_only])',\n",
       "      'func_desc': 'Calculate the rolling weighted window sum.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Window.sum.html#pandas.core.window.rolling.Window.sum',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.rolling.Window.sum',\n",
       "       'full_function': 'Window.sum(numeric_only=False, **kwargs)',\n",
       "       'function_text': 'Calculate the rolling weighted window sum.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.rolling.Window.sum',\n",
       "       'descriptions': 'Calculate the rolling weighted window sum.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Window.std([ddof,\\xa0numeric_only])',\n",
       "      'func_desc': 'Calculate the rolling weighted window standard deviation.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Window.std.html#pandas.core.window.rolling.Window.std',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.rolling.Window.std',\n",
       "       'full_function': 'Window.std(ddof=1, numeric_only=False, **kwargs)',\n",
       "       'function_text': 'Calculate the rolling weighted window standard deviation.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.rolling.Window.std',\n",
       "       'descriptions': 'Calculate the rolling weighted window standard deviation.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Expanding window functions': [{'func_name': 'Expanding.count([numeric_only])',\n",
       "      'func_desc': 'Calculate the expanding count of non NaN observations.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.count.html#pandas.core.window.expanding.Expanding.count',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.expanding.Expanding.count',\n",
       "       'full_function': 'Expanding.count(numeric_only=False)',\n",
       "       'function_text': 'Calculate the expanding count of non NaN observations.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Expanding.mean([numeric_only,\\xa0engine,\\xa0...])',\n",
       "      'func_desc': 'Calculate the expanding mean.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.mean.html#pandas.core.window.expanding.Expanding.mean',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.expanding.Expanding.mean',\n",
       "       'full_function': 'Expanding.mean(numeric_only=False, engine=None, engine_kwargs=None)',\n",
       "       'function_text': 'Calculate the expanding mean.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': \"\\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False}\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.expanding.Expanding.mean',\n",
       "       'descriptions': 'Calculate the expanding mean.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None. \\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None',\n",
       "          'description': \"dict, default None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False}\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Expanding.var([ddof,\\xa0numeric_only,\\xa0engine,\\xa0...])',\n",
       "      'func_desc': 'Calculate the expanding variance.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.var.html#pandas.core.window.expanding.Expanding.var',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.expanding.Expanding.var',\n",
       "       'full_function': 'Expanding.var(ddof=1, numeric_only=False, engine=None, engine_kwargs=None)',\n",
       "       'function_text': 'Calculate the expanding variance.',\n",
       "       'parameter_names_desc': [{'param_name': 'ddof',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Delta Degrees of Freedom. The divisor used in calculations\\nis N - ddof, where N represents the number of elements.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': \"\\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\nNew in version 1.4.0.\\n\\n\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False}\\n\\nNew in version 1.4.0.\\n\\n\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.expanding.Expanding.var',\n",
       "       'descriptions': 'Calculate the expanding variance.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'ddof': {'type': 'integer',\n",
       "          'description': 'int, default 1. Delta Degrees of Freedom. The divisor used in calculations\\nis N - ddof, where N represents the number of elements.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None. \\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\nNew in version 1.4.0.\\n\\n\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None',\n",
       "          'description': \"dict, default None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False}\\n\\nNew in version 1.4.0.\\n\\n\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Expanding.min([numeric_only,\\xa0engine,\\xa0...])',\n",
       "      'func_desc': 'Calculate the expanding minimum.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.min.html#pandas.core.window.expanding.Expanding.min',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.expanding.Expanding.min',\n",
       "       'full_function': 'Expanding.min(numeric_only=False, engine=None, engine_kwargs=None)',\n",
       "       'function_text': 'Calculate the expanding minimum.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': \"\\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False}\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.expanding.Expanding.min',\n",
       "       'descriptions': 'Calculate the expanding minimum.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None. \\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None',\n",
       "          'description': \"dict, default None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False}\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Expanding.corr([other,\\xa0pairwise,\\xa0ddof,\\xa0...])',\n",
       "      'func_desc': 'Calculate the expanding correlation.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.corr.html#pandas.core.window.expanding.Expanding.corr',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.expanding.Expanding.corr',\n",
       "       'full_function': 'Expanding.corr(other=None, pairwise=None, ddof=1, numeric_only=False)',\n",
       "       'function_text': 'Calculate the expanding correlation.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series or DataFrame, optional',\n",
       "         'param_desc': 'If not supplied then will default to self and produce pairwise\\noutput.\\n'},\n",
       "        {'param_name': 'pairwise',\n",
       "         'param_type': 'bool, default None',\n",
       "         'param_desc': 'If False then only matching columns between self and other will be\\nused and the output will be a DataFrame.\\nIf True then all pairwise combinations will be calculated and the\\noutput will be a MultiIndexed DataFrame in the case of DataFrame\\ninputs. In the case of missing elements, only complete pairwise\\nobservations will be used.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.expanding.Expanding.corr',\n",
       "       'descriptions': 'Calculate the expanding correlation.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series or DataFrame, optional',\n",
       "          'description': 'Series or DataFrame, optional. If not supplied then will default to self and produce pairwise\\noutput.\\n'},\n",
       "         'pairwise': {'type': 'boolean',\n",
       "          'description': 'bool, default None. If False then only matching columns between self and other will be\\nused and the output will be a DataFrame.\\nIf True then all pairwise combinations will be calculated and the\\noutput will be a MultiIndexed DataFrame in the case of DataFrame\\ninputs. In the case of missing elements, only complete pairwise\\nobservations will be used.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Expanding.skew([numeric_only])',\n",
       "      'func_desc': 'Calculate the expanding unbiased skewness.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.skew.html#pandas.core.window.expanding.Expanding.skew',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.expanding.Expanding.skew',\n",
       "       'full_function': 'Expanding.skew(numeric_only=False)',\n",
       "       'function_text': 'Calculate the expanding unbiased skewness.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.expanding.Expanding.skew',\n",
       "       'descriptions': 'Calculate the expanding unbiased skewness.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Expanding.apply(func[,\\xa0raw,\\xa0engine,\\xa0...])',\n",
       "      'func_desc': 'Calculate the expanding custom aggregation function.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.apply.html#pandas.core.window.expanding.Expanding.apply',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.expanding.Expanding.apply',\n",
       "       'full_function': 'Expanding.apply(func, raw=False, engine=None, engine_kwargs=None, args=None, kwargs=None)',\n",
       "       'function_text': 'Calculate the expanding custom aggregation function.',\n",
       "       'parameter_names_desc': [{'param_name': 'func',\n",
       "         'param_type': 'function',\n",
       "         'param_desc': \"Must produce a single value from an ndarray input if raw=True\\nor a single value from a Series if raw=False. Can also accept a\\nNumba JIT function with engine='numba' specified.\\n\"},\n",
       "        {'param_name': 'raw',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': '\\nFalse : passes each row or column as a Series to the\\nfunction.\\nTrue : the passed function will receive ndarray\\nobjects instead.\\nIf you are just applying a NumPy reduction function this will\\nachieve much better performance.\\n\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': \"\\n'cython' : Runs rolling apply through C-extensions from cython.\\n'numba' : Runs rolling apply through JIT compiled code from numba.\\nOnly available when raw is set to True.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\\napplied to both the func and the apply rolling aggregation.\\n\\n\"},\n",
       "        {'param_name': 'args',\n",
       "         'param_type': 'tuple, default None',\n",
       "         'param_desc': 'Positional arguments to be passed into func.\\n'},\n",
       "        {'param_name': 'kwargs',\n",
       "         'param_type': 'dict, default None',\n",
       "         'param_desc': 'Keyword arguments to be passed into func.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.expanding.Expanding.apply',\n",
       "       'descriptions': 'Calculate the expanding custom aggregation function.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'func': {'type': 'function',\n",
       "          'description': \"function. Must produce a single value from an ndarray input if raw=True\\nor a single value from a Series if raw=False. Can also accept a\\nNumba JIT function with engine='numba' specified.\\n\"},\n",
       "         'raw': {'type': 'boolean',\n",
       "          'description': 'bool, default False. \\nFalse : passes each row or column as a Series to the\\nfunction.\\nTrue : the passed function will receive ndarray\\nobjects instead.\\nIf you are just applying a NumPy reduction function this will\\nachieve much better performance.\\n\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None. \\n'cython' : Runs rolling apply through C-extensions from cython.\\n'numba' : Runs rolling apply through JIT compiled code from numba.\\nOnly available when raw is set to True.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None',\n",
       "          'description': \"dict, default None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\\napplied to both the func and the apply rolling aggregation.\\n\\n\"},\n",
       "         'args': {'type': 'tuple, default None',\n",
       "          'description': 'tuple, default None. Positional arguments to be passed into func.\\n'},\n",
       "         'kwargs': {'type': 'dict, default None',\n",
       "          'description': 'dict, default None. Keyword arguments to be passed into func.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Expanding.quantile(q[,\\xa0interpolation,\\xa0...])',\n",
       "      'func_desc': 'Calculate the expanding quantile.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.quantile.html#pandas.core.window.expanding.Expanding.quantile',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.expanding.Expanding.quantile',\n",
       "       'full_function': \"Expanding.quantile(q, interpolation='linear', numeric_only=False)\",\n",
       "       'function_text': 'Calculate the expanding quantile.',\n",
       "       'parameter_names_desc': [{'param_name': 'quantile',\n",
       "         'param_type': 'float',\n",
       "         'param_desc': 'Quantile to compute. 0 <= quantile <= 1.\\n\\nDeprecated since version 2.1.0: This will be renamed to ‘q’ in a future version.\\n\\n'},\n",
       "        {'param_name': 'interpolation',\n",
       "         'param_type': '{‘linear’, ‘lower’, ‘higher’, ‘midpoint’, ‘nearest’}',\n",
       "         'param_desc': 'This optional parameter specifies the interpolation method to use,\\nwhen the desired quantile lies between two data points i and j:\\n\\n\\nlinear: i + (j - i) * fraction, where fraction is the\\nfractional part of the index surrounded by i and j.\\nlower: i.\\nhigher: j.\\nnearest: i or j whichever is nearest.\\nmidpoint: (i + j) / 2.\\n\\n\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.expanding.Expanding.quantile',\n",
       "       'descriptions': 'Calculate the expanding quantile.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'quantile': {'type': 'float',\n",
       "          'description': 'float. Quantile to compute. 0 <= quantile <= 1.\\n\\nDeprecated since version 2.1.0: This will be renamed to ‘q’ in a future version.\\n\\n'},\n",
       "         'interpolation': {'type': 'integer',\n",
       "          'description': '{‘linear’, ‘lower’, ‘higher’, ‘midpoint’, ‘nearest’}. This optional parameter specifies the interpolation method to use,\\nwhen the desired quantile lies between two data points i and j:\\n\\n\\nlinear: i + (j - i) * fraction, where fraction is the\\nfractional part of the index surrounded by i and j.\\nlower: i.\\nhigher: j.\\nnearest: i or j whichever is nearest.\\nmidpoint: (i + j) / 2.\\n\\n\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Expanding.rank([method,\\xa0ascending,\\xa0pct,\\xa0...])',\n",
       "      'func_desc': 'Calculate the expanding rank.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.rank.html#pandas.core.window.expanding.Expanding.rank',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.expanding.Expanding.rank',\n",
       "       'full_function': \"Expanding.rank(method='average', ascending=True, pct=False, numeric_only=False)\",\n",
       "       'function_text': 'Calculate the expanding rank. New in version 1.4.0.',\n",
       "       'parameter_names_desc': [{'param_name': 'method',\n",
       "         'param_type': '{‘average’, ‘min’, ‘max’}, default ‘average’',\n",
       "         'param_desc': 'How to rank the group of records that have the same value (i.e. ties):\\n\\naverage: average rank of the group\\nmin: lowest rank in the group\\nmax: highest rank in the group\\n\\n'},\n",
       "        {'param_name': 'ascending',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether or not the elements should be ranked in ascending order.\\n'},\n",
       "        {'param_name': 'pct',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether or not to display the returned rankings in percentile\\nform.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.expanding.Expanding.rank',\n",
       "       'descriptions': 'Calculate the expanding rank. New in version 1.4.0.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'method': {'type': 'string',\n",
       "          'enum': ['average', ' min', ' max'],\n",
       "          'description': '{‘average’, ‘min’, ‘max’}, default ‘average’. How to rank the group of records that have the same value (i.e. ties):\\n\\naverage: average rank of the group\\nmin: lowest rank in the group\\nmax: highest rank in the group\\n\\n'},\n",
       "         'ascending': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether or not the elements should be ranked in ascending order.\\n'},\n",
       "         'pct': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether or not to display the returned rankings in percentile\\nform.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Expanding.sum([numeric_only,\\xa0engine,\\xa0...])',\n",
       "      'func_desc': 'Calculate the expanding sum.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.sum.html#pandas.core.window.expanding.Expanding.sum',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.expanding.Expanding.sum',\n",
       "       'full_function': 'Expanding.sum(numeric_only=False, engine=None, engine_kwargs=None)',\n",
       "       'function_text': 'Calculate the expanding sum.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': \"\\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False}\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.expanding.Expanding.sum',\n",
       "       'descriptions': 'Calculate the expanding sum.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None. \\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None',\n",
       "          'description': \"dict, default None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False}\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Expanding.median([numeric_only,\\xa0engine,\\xa0...])',\n",
       "      'func_desc': 'Calculate the expanding median.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.median.html#pandas.core.window.expanding.Expanding.median',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.expanding.Expanding.median',\n",
       "       'full_function': 'Expanding.median(numeric_only=False, engine=None, engine_kwargs=None)',\n",
       "       'function_text': 'Calculate the expanding median.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': \"\\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False}\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.expanding.Expanding.median',\n",
       "       'descriptions': 'Calculate the expanding median.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None. \\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None',\n",
       "          'description': \"dict, default None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False}\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Expanding.std([ddof,\\xa0numeric_only,\\xa0engine,\\xa0...])',\n",
       "      'func_desc': 'Calculate the expanding standard deviation.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.std.html#pandas.core.window.expanding.Expanding.std',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.expanding.Expanding.std',\n",
       "       'full_function': 'Expanding.std(ddof=1, numeric_only=False, engine=None, engine_kwargs=None)',\n",
       "       'function_text': 'Calculate the expanding standard deviation.',\n",
       "       'parameter_names_desc': [{'param_name': 'ddof',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Delta Degrees of Freedom. The divisor used in calculations\\nis N - ddof, where N represents the number of elements.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': \"\\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\nNew in version 1.4.0.\\n\\n\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False}\\n\\nNew in version 1.4.0.\\n\\n\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.expanding.Expanding.std',\n",
       "       'descriptions': 'Calculate the expanding standard deviation.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'ddof': {'type': 'integer',\n",
       "          'description': 'int, default 1. Delta Degrees of Freedom. The divisor used in calculations\\nis N - ddof, where N represents the number of elements.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None. \\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\nNew in version 1.4.0.\\n\\n\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None',\n",
       "          'description': \"dict, default None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False}\\n\\nNew in version 1.4.0.\\n\\n\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Expanding.max([numeric_only,\\xa0engine,\\xa0...])',\n",
       "      'func_desc': 'Calculate the expanding maximum.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.max.html#pandas.core.window.expanding.Expanding.max',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.expanding.Expanding.max',\n",
       "       'full_function': 'Expanding.max(numeric_only=False, engine=None, engine_kwargs=None)',\n",
       "       'function_text': 'Calculate the expanding maximum.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': \"\\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False}\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.expanding.Expanding.max',\n",
       "       'descriptions': 'Calculate the expanding maximum.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None. \\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None',\n",
       "          'description': \"dict, default None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False}\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Expanding.cov([other,\\xa0pairwise,\\xa0ddof,\\xa0...])',\n",
       "      'func_desc': 'Calculate the expanding sample covariance.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.cov.html#pandas.core.window.expanding.Expanding.cov',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.expanding.Expanding.cov',\n",
       "       'full_function': 'Expanding.cov(other=None, pairwise=None, ddof=1, numeric_only=False)',\n",
       "       'function_text': 'Calculate the expanding sample covariance.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series or DataFrame, optional',\n",
       "         'param_desc': 'If not supplied then will default to self and produce pairwise\\noutput.\\n'},\n",
       "        {'param_name': 'pairwise',\n",
       "         'param_type': 'bool, default None',\n",
       "         'param_desc': 'If False then only matching columns between self and other will be\\nused and the output will be a DataFrame.\\nIf True then all pairwise combinations will be calculated and the\\noutput will be a MultiIndexed DataFrame in the case of DataFrame\\ninputs. In the case of missing elements, only complete pairwise\\nobservations will be used.\\n'},\n",
       "        {'param_name': 'ddof',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Delta Degrees of Freedom. The divisor used in calculations\\nis N - ddof, where N represents the number of elements.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.expanding.Expanding.cov',\n",
       "       'descriptions': 'Calculate the expanding sample covariance.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series or DataFrame, optional',\n",
       "          'description': 'Series or DataFrame, optional. If not supplied then will default to self and produce pairwise\\noutput.\\n'},\n",
       "         'pairwise': {'type': 'boolean',\n",
       "          'description': 'bool, default None. If False then only matching columns between self and other will be\\nused and the output will be a DataFrame.\\nIf True then all pairwise combinations will be calculated and the\\noutput will be a MultiIndexed DataFrame in the case of DataFrame\\ninputs. In the case of missing elements, only complete pairwise\\nobservations will be used.\\n'},\n",
       "         'ddof': {'type': 'integer',\n",
       "          'description': 'int, default 1. Delta Degrees of Freedom. The divisor used in calculations\\nis N - ddof, where N represents the number of elements.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Expanding.kurt([numeric_only])',\n",
       "      'func_desc': \"Calculate the expanding Fisher's definition of kurtosis without bias.\",\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.kurt.html#pandas.core.window.expanding.Expanding.kurt',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.expanding.Expanding.kurt',\n",
       "       'full_function': 'Expanding.kurt(numeric_only=False)',\n",
       "       'function_text': 'Calculate the expanding Fisher’s definition of kurtosis without bias.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.expanding.Expanding.kurt',\n",
       "       'descriptions': 'Calculate the expanding Fisher’s definition of kurtosis without bias.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Expanding.aggregate(func,\\xa0*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Aggregate using one or more operations over the specified axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.aggregate.html#pandas.core.window.expanding.Expanding.aggregate',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.expanding.Expanding.aggregate',\n",
       "       'full_function': 'Expanding.aggregate(func, *args, **kwargs)',\n",
       "       'function_text': 'Aggregate using one or more operations over the specified axis.',\n",
       "       'parameter_names_desc': [{'param_name': 'func',\n",
       "         'param_type': 'function, str, list or dict',\n",
       "         'param_desc': \"Function to use for aggregating the data. If a function, must either\\nwork when passed a Series/Dataframe or when passed to Series/Dataframe.apply.\\nAccepted combinations are:\\n\\nfunction\\nstring function name\\nlist of functions and/or function names, e.g. [np.sum, 'mean']\\ndict of axis labels -> functions, function names or list of such.\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.expanding.Expanding.aggregate',\n",
       "       'descriptions': 'Aggregate using one or more operations over the specified axis.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'func': {'type': 'string',\n",
       "          'description': \"function, str, list or dict. Function to use for aggregating the data. If a function, must either\\nwork when passed a Series/Dataframe or when passed to Series/Dataframe.apply.\\nAccepted combinations are:\\n\\nfunction\\nstring function name\\nlist of functions and/or function names, e.g. [np.sum, 'mean']\\ndict of axis labels -> functions, function names or list of such.\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Expanding.sem([ddof,\\xa0numeric_only])',\n",
       "      'func_desc': 'Calculate the expanding standard error of mean.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.sem.html#pandas.core.window.expanding.Expanding.sem',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.expanding.Expanding.sem',\n",
       "       'full_function': 'Expanding.sem(ddof=1, numeric_only=False)',\n",
       "       'function_text': 'Calculate the expanding standard error of mean.',\n",
       "       'parameter_names_desc': [{'param_name': 'ddof',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Delta Degrees of Freedom. The divisor used in calculations\\nis N - ddof, where N represents the number of elements.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.expanding.Expanding.sem',\n",
       "       'descriptions': 'Calculate the expanding standard error of mean.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'ddof': {'type': 'integer',\n",
       "          'description': 'int, default 1. Delta Degrees of Freedom. The divisor used in calculations\\nis N - ddof, where N represents the number of elements.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Exponentially-weighted window functions': [{'func_name': 'ExponentialMovingWindow.mean([numeric_only,\\xa0...])',\n",
       "      'func_desc': 'Calculate the ewm (exponential weighted moment) mean.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.ewm.ExponentialMovingWindow.mean.html#pandas.core.window.ewm.ExponentialMovingWindow.mean',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.ewm.ExponentialMovingWindow.mean',\n",
       "       'full_function': 'ExponentialMovingWindow.mean(numeric_only=False, engine=None, engine_kwargs=None)',\n",
       "       'function_text': 'Calculate the ewm (exponential weighted moment) mean.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': \"\\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False}\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.ewm.ExponentialMovingWindow.mean',\n",
       "       'descriptions': 'Calculate the ewm (exponential weighted moment) mean.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None. \\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None',\n",
       "          'description': \"dict, default None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False}\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'ExponentialMovingWindow.std([bias,\\xa0numeric_only])',\n",
       "      'func_desc': 'Calculate the ewm (exponential weighted moment) standard deviation.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.ewm.ExponentialMovingWindow.std.html#pandas.core.window.ewm.ExponentialMovingWindow.std',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.ewm.ExponentialMovingWindow.std',\n",
       "       'full_function': 'ExponentialMovingWindow.std(bias=False, numeric_only=False)',\n",
       "       'function_text': 'Calculate the ewm (exponential weighted moment) standard deviation.',\n",
       "       'parameter_names_desc': [{'param_name': 'bias',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Use a standard estimation bias correction.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.ewm.ExponentialMovingWindow.std',\n",
       "       'descriptions': 'Calculate the ewm (exponential weighted moment) standard deviation.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'bias': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Use a standard estimation bias correction.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'ExponentialMovingWindow.corr([other,\\xa0...])',\n",
       "      'func_desc': 'Calculate the ewm (exponential weighted moment) sample correlation.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.ewm.ExponentialMovingWindow.corr.html#pandas.core.window.ewm.ExponentialMovingWindow.corr',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.ewm.ExponentialMovingWindow.corr',\n",
       "       'full_function': 'ExponentialMovingWindow.corr(other=None, pairwise=None, numeric_only=False)',\n",
       "       'function_text': 'Calculate the ewm (exponential weighted moment) sample correlation.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series or DataFrame, optional',\n",
       "         'param_desc': 'If not supplied then will default to self and produce pairwise\\noutput.\\n'},\n",
       "        {'param_name': 'pairwise',\n",
       "         'param_type': 'bool, default None',\n",
       "         'param_desc': 'If False then only matching columns between self and other will be\\nused and the output will be a DataFrame.\\nIf True then all pairwise combinations will be calculated and the\\noutput will be a MultiIndex DataFrame in the case of DataFrame\\ninputs. In the case of missing elements, only complete pairwise\\nobservations will be used.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.ewm.ExponentialMovingWindow.corr',\n",
       "       'descriptions': 'Calculate the ewm (exponential weighted moment) sample correlation.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series or DataFrame, optional',\n",
       "          'description': 'Series or DataFrame, optional. If not supplied then will default to self and produce pairwise\\noutput.\\n'},\n",
       "         'pairwise': {'type': 'boolean',\n",
       "          'description': 'bool, default None. If False then only matching columns between self and other will be\\nused and the output will be a DataFrame.\\nIf True then all pairwise combinations will be calculated and the\\noutput will be a MultiIndex DataFrame in the case of DataFrame\\ninputs. In the case of missing elements, only complete pairwise\\nobservations will be used.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'ExponentialMovingWindow.sum([numeric_only,\\xa0...])',\n",
       "      'func_desc': 'Calculate the ewm (exponential weighted moment) sum.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.ewm.ExponentialMovingWindow.sum.html#pandas.core.window.ewm.ExponentialMovingWindow.sum',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.ewm.ExponentialMovingWindow.sum',\n",
       "       'full_function': 'ExponentialMovingWindow.sum(numeric_only=False, engine=None, engine_kwargs=None)',\n",
       "       'function_text': 'Calculate the ewm (exponential weighted moment) sum.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': \"\\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False}\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.ewm.ExponentialMovingWindow.sum',\n",
       "       'descriptions': 'Calculate the ewm (exponential weighted moment) sum.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None. \\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None',\n",
       "          'description': \"dict, default None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False}\\n\\nNew in version 1.3.0.\\n\\n\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'ExponentialMovingWindow.var([bias,\\xa0numeric_only])',\n",
       "      'func_desc': 'Calculate the ewm (exponential weighted moment) variance.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.ewm.ExponentialMovingWindow.var.html#pandas.core.window.ewm.ExponentialMovingWindow.var',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.ewm.ExponentialMovingWindow.var',\n",
       "       'full_function': 'ExponentialMovingWindow.var(bias=False, numeric_only=False)',\n",
       "       'function_text': 'Calculate the ewm (exponential weighted moment) variance.',\n",
       "       'parameter_names_desc': [{'param_name': 'bias',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Use a standard estimation bias correction.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.ewm.ExponentialMovingWindow.var',\n",
       "       'descriptions': 'Calculate the ewm (exponential weighted moment) variance.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'bias': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Use a standard estimation bias correction.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'ExponentialMovingWindow.cov([other,\\xa0...])',\n",
       "      'func_desc': 'Calculate the ewm (exponential weighted moment) sample covariance.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.window.ewm.ExponentialMovingWindow.cov.html#pandas.core.window.ewm.ExponentialMovingWindow.cov',\n",
       "      'function_definitions': {'function_name': 'pandas.core.window.ewm.ExponentialMovingWindow.cov',\n",
       "       'full_function': 'ExponentialMovingWindow.cov(other=None, pairwise=None, bias=False, numeric_only=False)',\n",
       "       'function_text': 'Calculate the ewm (exponential weighted moment) sample covariance.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series or DataFrame , optional',\n",
       "         'param_desc': 'If not supplied then will default to self and produce pairwise\\noutput.\\n'},\n",
       "        {'param_name': 'pairwise',\n",
       "         'param_type': 'bool, default None',\n",
       "         'param_desc': 'If False then only matching columns between self and other will be\\nused and the output will be a DataFrame.\\nIf True then all pairwise combinations will be calculated and the\\noutput will be a MultiIndex DataFrame in the case of DataFrame\\ninputs. In the case of missing elements, only complete pairwise\\nobservations will be used.\\n'},\n",
       "        {'param_name': 'bias',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Use a standard estimation bias correction.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.window.ewm.ExponentialMovingWindow.cov',\n",
       "       'descriptions': 'Calculate the ewm (exponential weighted moment) sample covariance.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series or DataFrame , optional',\n",
       "          'description': 'Series or DataFrame , optional. If not supplied then will default to self and produce pairwise\\noutput.\\n'},\n",
       "         'pairwise': {'type': 'boolean',\n",
       "          'description': 'bool, default None. If False then only matching columns between self and other will be\\nused and the output will be a DataFrame.\\nIf True then all pairwise combinations will be calculated and the\\noutput will be a MultiIndex DataFrame in the case of DataFrame\\ninputs. In the case of missing elements, only complete pairwise\\nobservations will be used.\\n'},\n",
       "         'bias': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Use a standard estimation bias correction.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nNew in version 1.5.0.\\n\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Window indexer': [{'func_name': 'api.indexers.BaseIndexer([index_array,\\xa0...])',\n",
       "      'func_desc': 'Base class for window bounds calculations.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.indexers.BaseIndexer.html#pandas.api.indexers.BaseIndexer',\n",
       "      'function_definitions': {'function_name': 'pandas.api.indexers.BaseIndexer',\n",
       "       'full_function': 'class pandas.api.indexers.BaseIndexer(index_array=None, window_size=0, **kwargs)',\n",
       "       'function_text': 'Base class for window bounds calculations. Examples Methods get_window_bounds([num_values,\\xa0min_periods,\\xa0...]) Computes the bounds of a window.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'api.indexers.VariableOffsetWindowIndexer([...])',\n",
       "      'func_desc': 'Calculate window boundaries based on a non-fixed offset such as a BusinessDay.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.indexers.VariableOffsetWindowIndexer.html#pandas.api.indexers.VariableOffsetWindowIndexer',\n",
       "      'function_definitions': {'function_name': 'pandas.api.indexers.VariableOffsetWindowIndexer',\n",
       "       'full_function': 'class pandas.api.indexers.VariableOffsetWindowIndexer(index_array=None, window_size=0, index=None, offset=None, **kwargs)',\n",
       "       'function_text': 'Calculate window boundaries based on a non-fixed offset such as a BusinessDay. Examples Methods get_window_bounds([num_values,\\xa0min_periods,\\xa0...]) Computes the bounds of a window.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'api.indexers.FixedForwardWindowIndexer([...])',\n",
       "      'func_desc': 'Creates window boundaries for fixed-length windows that include the current row.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.indexers.FixedForwardWindowIndexer.html#pandas.api.indexers.FixedForwardWindowIndexer',\n",
       "      'function_definitions': {'function_name': 'pandas.api.indexers.FixedForwardWindowIndexer',\n",
       "       'full_function': 'class pandas.api.indexers.FixedForwardWindowIndexer(index_array=None, window_size=0, **kwargs)',\n",
       "       'function_text': 'Creates window boundaries for fixed-length windows that include the current row. Examples Methods get_window_bounds([num_values,\\xa0min_periods,\\xa0...]) Computes the bounds of a window.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]}],\n",
       "  'name': 'Window',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/window.html'},\n",
       " 'groupby.html': {'functions': [{'Indexing, iteration': [{'func_name': 'DataFrameGroupBy.__iter__()',\n",
       "      'func_desc': 'Groupby iterator.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.__iter__.html#pandas.core.groupby.DataFrameGroupBy.__iter__',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.__iter__',\n",
       "       'full_function': 'DataFrameGroupBy.__iter__()',\n",
       "       'function_text': 'Groupby iterator.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrameGroupBy.groups',\n",
       "      'func_desc': 'Dict {group name -> group labels}.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.groups.html#pandas.core.groupby.DataFrameGroupBy.groups',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.groups',\n",
       "       'full_function': 'property DataFrameGroupBy.groups',\n",
       "       'function_text': 'Dict {group name -> group labels}. Examples For SeriesGroupBy: For DataFrameGroupBy: For Resampler:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrameGroupBy.indices',\n",
       "      'func_desc': 'Dict {group name -> group indices}.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.indices.html#pandas.core.groupby.DataFrameGroupBy.indices',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.indices',\n",
       "       'full_function': 'property DataFrameGroupBy.indices',\n",
       "       'function_text': 'Dict {group name -> group indices}. Examples For SeriesGroupBy: For DataFrameGroupBy: For Resampler:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrameGroupBy.get_group(name[,\\xa0obj])',\n",
       "      'func_desc': 'Construct DataFrame from group with provided name.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.get_group.html#pandas.core.groupby.DataFrameGroupBy.get_group',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.get_group',\n",
       "       'full_function': 'DataFrameGroupBy.get_group(name, obj=None)',\n",
       "       'function_text': 'Construct DataFrame from group with provided name.',\n",
       "       'parameter_names_desc': [{'param_name': 'name',\n",
       "         'param_type': 'object',\n",
       "         'param_desc': 'The name of the group to get as a DataFrame.\\n'},\n",
       "        {'param_name': 'obj',\n",
       "         'param_type': 'DataFrame, default None',\n",
       "         'param_desc': 'The DataFrame to take the DataFrame out of. If\\nit is None, the object groupby was called on will\\nbe used.\\n\\nDeprecated since version 2.1.0: The obj is deprecated and will be removed in a future version.\\nDo df.iloc[gb.indices.get(name)]\\ninstead of gb.get_group(name, obj=df).\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.get_group',\n",
       "       'descriptions': 'Construct DataFrame from group with provided name.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'name': {'type': 'object',\n",
       "          'description': 'object. The name of the group to get as a DataFrame.\\n'},\n",
       "         'obj': {'type': 'DataFrame, default None',\n",
       "          'description': 'DataFrame, default None. The DataFrame to take the DataFrame out of. If\\nit is None, the object groupby was called on will\\nbe used.\\n\\nDeprecated since version 2.1.0: The obj is deprecated and will be removed in a future version.\\nDo df.iloc[gb.indices.get(name)]\\ninstead of gb.get_group(name, obj=df).\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Grouper(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'A Grouper allows the user to specify a groupby instruction for an object.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.Grouper.html#pandas.Grouper',\n",
       "      'function_definitions': {'function_name': 'pandas.Grouper',\n",
       "       'full_function': 'class pandas.Grouper(*args, **kwargs)',\n",
       "       'function_text': 'A Grouper allows the user to specify a groupby instruction for an object. This specification will select a column via the key parameter, or if the\\nlevel and/or axis parameters are given, a level of the index of the target\\nobject. If axis and/or level are passed as keywords to both Grouper and\\ngroupby, the values passed to Grouper take precedence.',\n",
       "       'parameter_names_desc': [{'param_name': 'key',\n",
       "         'param_type': 'str, defaults to None',\n",
       "         'param_desc': 'Groupby key, which selects the grouping column of the target.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'name/number, defaults to None',\n",
       "         'param_desc': 'The level for the target index.\\n'},\n",
       "        {'param_name': 'freq',\n",
       "         'param_type': 'str / frequency object, defaults to None',\n",
       "         'param_desc': 'This will groupby the specified frequency if the target selection\\n(via key or level) is a datetime-like object. For full specification\\nof available frequencies, please see here.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': 'str, int, defaults to 0',\n",
       "         'param_desc': 'Number/name of the axis.\\n'},\n",
       "        {'param_name': 'sort',\n",
       "         'param_type': 'bool, default to False',\n",
       "         'param_desc': 'Whether to sort the resulting labels.\\n'},\n",
       "        {'param_name': 'closed',\n",
       "         'param_type': '{‘left’ or ‘right’}',\n",
       "         'param_desc': 'Closed end of interval. Only when freq parameter is passed.\\n'},\n",
       "        {'param_name': 'label',\n",
       "         'param_type': '{‘left’ or ‘right’}',\n",
       "         'param_desc': 'Interval boundary to use for labeling.\\nOnly when freq parameter is passed.\\n'},\n",
       "        {'param_name': 'convention',\n",
       "         'param_type': '{‘start’, ‘end’, ‘e’, ‘s’}',\n",
       "         'param_desc': 'If grouper is PeriodIndex and freq parameter is passed.\\n'},\n",
       "        {'param_name': 'origin',\n",
       "         'param_type': 'Timestamp or str, default ‘start_day’',\n",
       "         'param_desc': 'The timestamp on which to adjust the grouping. The timezone of origin must\\nmatch the timezone of the index.\\nIf string, must be one of the following:\\n\\n‘epoch’: origin is 1970-01-01\\n‘start’: origin is the first value of the timeseries\\n‘start_day’: origin is the first day at midnight of the timeseries\\n‘end’: origin is the last value of the timeseries\\n‘end_day’: origin is the ceiling midnight of the last day\\n\\n\\nNew in version 1.3.0.\\n\\n'},\n",
       "        {'param_name': 'offset',\n",
       "         'param_type': 'Timedelta or str, default is None',\n",
       "         'param_desc': 'An offset timedelta added to the origin.\\n'},\n",
       "        {'param_name': 'dropna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If True, and if group keys contain NA values, NA values together with\\nrow/column will be dropped. If False, NA values will also be treated as\\nthe key in groups.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.Grouper',\n",
       "       'descriptions': 'A Grouper allows the user to specify a groupby instruction for an object. This specification will select a column via the key parameter, or if the\\nlevel and/or axis parameters are given, a level of the index of the target\\nobject. If axis and/or level are passed as keywords to both Grouper and\\ngroupby, the values passed to Grouper take precedence.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'key': {'type': 'string',\n",
       "          'description': 'str, defaults to None. Groupby key, which selects the grouping column of the target.\\n'},\n",
       "         'level': {'type': 'name/number, defaults to None',\n",
       "          'description': 'name/number, defaults to None. The level for the target index.\\n'},\n",
       "         'freq': {'type': 'string',\n",
       "          'description': 'str / frequency object, defaults to None. This will groupby the specified frequency if the target selection\\n(via key or level) is a datetime-like object. For full specification\\nof available frequencies, please see here.\\n'},\n",
       "         'axis': {'type': 'integer',\n",
       "          'description': 'str, int, defaults to 0. Number/name of the axis.\\n'},\n",
       "         'sort': {'type': 'boolean',\n",
       "          'description': 'bool, default to False. Whether to sort the resulting labels.\\n'},\n",
       "         'closed': {'type': 'string',\n",
       "          'enum': ['left or right'],\n",
       "          'description': '{‘left’ or ‘right’}. Closed end of interval. Only when freq parameter is passed.\\n'},\n",
       "         'label': {'type': 'string',\n",
       "          'enum': ['left or right'],\n",
       "          'description': '{‘left’ or ‘right’}. Interval boundary to use for labeling.\\nOnly when freq parameter is passed.\\n'},\n",
       "         'convention': {'type': 'string',\n",
       "          'enum': ['start', ' end', ' e', ' s'],\n",
       "          'description': '{‘start’, ‘end’, ‘e’, ‘s’}. If grouper is PeriodIndex and freq parameter is passed.\\n'},\n",
       "         'origin': {'type': 'string',\n",
       "          'description': 'Timestamp or str, default ‘start_day’. The timestamp on which to adjust the grouping. The timezone of origin must\\nmatch the timezone of the index.\\nIf string, must be one of the following:\\n\\n‘epoch’: origin is 1970-01-01\\n‘start’: origin is the first value of the timeseries\\n‘start_day’: origin is the first day at midnight of the timeseries\\n‘end’: origin is the last value of the timeseries\\n‘end_day’: origin is the ceiling midnight of the last day\\n\\n\\nNew in version 1.3.0.\\n\\n'},\n",
       "         'offset': {'type': 'string',\n",
       "          'description': 'Timedelta or str, default is None. An offset timedelta added to the origin.\\n'},\n",
       "         'dropna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If True, and if group keys contain NA values, NA values together with\\nrow/column will be dropped. If False, NA values will also be treated as\\nthe key in groups.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.__iter__()',\n",
       "      'func_desc': 'Groupby iterator.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.__iter__.html#pandas.core.groupby.SeriesGroupBy.__iter__',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.__iter__',\n",
       "       'full_function': 'SeriesGroupBy.__iter__()',\n",
       "       'function_text': 'Groupby iterator.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SeriesGroupBy.groups',\n",
       "      'func_desc': 'Dict {group name -> group labels}.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.groups.html#pandas.core.groupby.SeriesGroupBy.groups',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.groups',\n",
       "       'full_function': 'property SeriesGroupBy.groups',\n",
       "       'function_text': 'Dict {group name -> group labels}. Examples For SeriesGroupBy: For DataFrameGroupBy: For Resampler:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SeriesGroupBy.indices',\n",
       "      'func_desc': 'Dict {group name -> group indices}.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.indices.html#pandas.core.groupby.SeriesGroupBy.indices',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.indices',\n",
       "       'full_function': 'property SeriesGroupBy.indices',\n",
       "       'function_text': 'Dict {group name -> group indices}. Examples For SeriesGroupBy: For DataFrameGroupBy: For Resampler:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SeriesGroupBy.get_group(name[,\\xa0obj])',\n",
       "      'func_desc': 'Construct DataFrame from group with provided name.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.get_group.html#pandas.core.groupby.SeriesGroupBy.get_group',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.get_group',\n",
       "       'full_function': 'SeriesGroupBy.get_group(name, obj=None)',\n",
       "       'function_text': 'Construct DataFrame from group with provided name.',\n",
       "       'parameter_names_desc': [{'param_name': 'name',\n",
       "         'param_type': 'object',\n",
       "         'param_desc': 'The name of the group to get as a DataFrame.\\n'},\n",
       "        {'param_name': 'obj',\n",
       "         'param_type': 'DataFrame, default None',\n",
       "         'param_desc': 'The DataFrame to take the DataFrame out of. If\\nit is None, the object groupby was called on will\\nbe used.\\n\\nDeprecated since version 2.1.0: The obj is deprecated and will be removed in a future version.\\nDo df.iloc[gb.indices.get(name)]\\ninstead of gb.get_group(name, obj=df).\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.get_group',\n",
       "       'descriptions': 'Construct DataFrame from group with provided name.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'name': {'type': 'object',\n",
       "          'description': 'object. The name of the group to get as a DataFrame.\\n'},\n",
       "         'obj': {'type': 'DataFrame, default None',\n",
       "          'description': 'DataFrame, default None. The DataFrame to take the DataFrame out of. If\\nit is None, the object groupby was called on will\\nbe used.\\n\\nDeprecated since version 2.1.0: The obj is deprecated and will be removed in a future version.\\nDo df.iloc[gb.indices.get(name)]\\ninstead of gb.get_group(name, obj=df).\\n\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Function application helper': [{'func_name': 'NamedAgg(column,\\xa0aggfunc)',\n",
       "      'func_desc': 'Helper for column specific aggregation with control over output column names.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.NamedAgg.html#pandas.NamedAgg',\n",
       "      'function_definitions': {'function_name': 'pandas.NamedAgg',\n",
       "       'full_function': 'class pandas.NamedAgg(column, aggfunc)',\n",
       "       'function_text': 'Helper for column specific aggregation with control over output column names. Subclass of typing.NamedTuple.',\n",
       "       'parameter_names_desc': [{'param_name': 'column',\n",
       "         'param_type': 'Hashable',\n",
       "         'param_desc': 'Column label in the DataFrame to apply aggfunc.\\n'},\n",
       "        {'param_name': 'aggfunc',\n",
       "         'param_type': 'function or str',\n",
       "         'param_desc': 'Function to apply to the provided column. If string, the name of a built-in\\npandas function.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.NamedAgg',\n",
       "       'descriptions': 'Helper for column specific aggregation with control over output column names. Subclass of typing.NamedTuple.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'column': {'type': 'Hashable',\n",
       "          'description': 'Hashable. Column label in the DataFrame to apply aggfunc.\\n'},\n",
       "         'aggfunc': {'type': 'string',\n",
       "          'description': 'function or str. Function to apply to the provided column. If string, the name of a built-in\\npandas function.\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Function application': [{'func_name': 'SeriesGroupBy.apply(func,\\xa0*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Apply function func group-wise and combine the results together.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.apply.html#pandas.core.groupby.SeriesGroupBy.apply',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.apply',\n",
       "       'full_function': 'SeriesGroupBy.apply(func, *args, **kwargs)',\n",
       "       'function_text': 'Apply function func group-wise and combine the results together. The function passed to apply must take a series as its first\\nargument and return a DataFrame, Series or scalar. apply will\\nthen take care of combining the results back together into a single\\ndataframe or series. apply is therefore a highly flexible\\ngrouping method. While apply is a very flexible method, its downside is that\\nusing it can be quite a bit slower than using more specific methods\\nlike agg or transform. Pandas offers a wide range of method that will\\nbe much faster than using apply for their specific purposes, so try to\\nuse them before reaching for apply.',\n",
       "       'parameter_names_desc': [{'param_name': 'func',\n",
       "         'param_type': 'callable',\n",
       "         'param_desc': 'A callable that takes a series as its first argument, and\\nreturns a dataframe, a series or a scalar. In addition the\\ncallable may take positional and keyword arguments.\\n'},\n",
       "        {'param_name': 'include_groups',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'When True, will attempt to apply func to the groupings in\\nthe case that they are columns of the DataFrame. If this raises a\\nTypeError, the result will be computed with the groupings excluded.\\nWhen False, the groupings will be excluded when applying func.\\n\\nNew in version 2.2.0.\\n\\n\\nDeprecated since version 2.2.0: Setting include_groups to True is deprecated. Only the value\\nFalse will be allowed in a future version of pandas.\\n\\n'},\n",
       "        {'param_name': 'args, kwargs',\n",
       "         'param_type': 'tuple and dict',\n",
       "         'param_desc': 'Optional positional and keyword arguments to pass to func.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.apply',\n",
       "       'descriptions': 'Apply function func group-wise and combine the results together. The function passed to apply must take a series as its first\\nargument and return a DataFrame, Series or scalar. apply will\\nthen take care of combining the results back together into a single\\ndataframe or series. apply is therefore a highly flexible\\ngrouping method. While apply is a very flexible method, its downside is that\\nusing it can be quite a bit slower than using more specific methods\\nlike agg or transform. Pandas offers a wide range of method that will\\nbe much faster than using apply for their specific purposes, so try to\\nuse them before reaching for apply.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'func': {'type': 'object',\n",
       "          'description': 'callable. A callable that takes a series as its first argument, and\\nreturns a dataframe, a series or a scalar. In addition the\\ncallable may take positional and keyword arguments.\\n'},\n",
       "         'include_groups': {'type': 'boolean',\n",
       "          'description': 'bool, default True. When True, will attempt to apply func to the groupings in\\nthe case that they are columns of the DataFrame. If this raises a\\nTypeError, the result will be computed with the groupings excluded.\\nWhen False, the groupings will be excluded when applying func.\\n\\nNew in version 2.2.0.\\n\\n\\nDeprecated since version 2.2.0: Setting include_groups to True is deprecated. Only the value\\nFalse will be allowed in a future version of pandas.\\n\\n'},\n",
       "         'args, kwargs': {'type': 'tuple and dict',\n",
       "          'description': 'tuple and dict. Optional positional and keyword arguments to pass to func.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.agg([func,\\xa0engine,\\xa0engine_kwargs])',\n",
       "      'func_desc': 'Aggregate using one or more operations over the specified axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.agg.html#pandas.core.groupby.SeriesGroupBy.agg',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.agg',\n",
       "       'full_function': 'SeriesGroupBy.agg(func=None, *args, engine=None, engine_kwargs=None, **kwargs)',\n",
       "       'function_text': 'Aggregate using one or more operations over the specified axis.',\n",
       "       'parameter_names_desc': [{'param_name': 'func',\n",
       "         'param_type': 'function, str, list, dict or None',\n",
       "         'param_desc': \"Function to use for aggregating the data. If a function, must either\\nwork when passed a Series or when passed to Series.apply.\\nAccepted combinations are:\\n\\nfunction\\nstring function name\\nlist of functions and/or function names, e.g. [np.sum, 'mean']\\nNone, in which case **kwargs are used with Named Aggregation. Here the\\noutput has one column for each element in **kwargs. The name of the\\ncolumn is keyword, whereas the value determines the aggregation used to compute\\nthe values in the column.\\nCan also accept a Numba JIT function with\\nengine='numba' specified. Only passing a single function is supported\\nwith this engine.\\nIf the 'numba' engine is chosen, the function must be\\na user defined function with values and index as the\\nfirst and second arguments respectively in the function signature.\\nEach group’s index will be passed to the user defined function\\nand optionally available for use.\\n\\n\\n\\nDeprecated since version 2.1.0: Passing a dictionary is deprecated and will raise in a future version\\nof pandas. Pass a list of aggregations instead.\\n\\n\"},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': \"\\n'cython' : Runs the function through C-extensions from cython.\\n'numba' : Runs the function through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\\napplied to the function\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.agg',\n",
       "       'descriptions': 'Aggregate using one or more operations over the specified axis.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'func': {'type': 'string',\n",
       "          'description': \"function, str, list, dict or None. Function to use for aggregating the data. If a function, must either\\nwork when passed a Series or when passed to Series.apply.\\nAccepted combinations are:\\n\\nfunction\\nstring function name\\nlist of functions and/or function names, e.g. [np.sum, 'mean']\\nNone, in which case **kwargs are used with Named Aggregation. Here the\\noutput has one column for each element in **kwargs. The name of the\\ncolumn is keyword, whereas the value determines the aggregation used to compute\\nthe values in the column.\\nCan also accept a Numba JIT function with\\nengine='numba' specified. Only passing a single function is supported\\nwith this engine.\\nIf the 'numba' engine is chosen, the function must be\\na user defined function with values and index as the\\nfirst and second arguments respectively in the function signature.\\nEach group’s index will be passed to the user defined function\\nand optionally available for use.\\n\\n\\n\\nDeprecated since version 2.1.0: Passing a dictionary is deprecated and will raise in a future version\\nof pandas. Pass a list of aggregations instead.\\n\\n\"},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None. \\n'cython' : Runs the function through C-extensions from cython.\\n'numba' : Runs the function through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None',\n",
       "          'description': \"dict, default None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\\napplied to the function\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.aggregate([func,\\xa0engine,\\xa0...])',\n",
       "      'func_desc': 'Aggregate using one or more operations over the specified axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.aggregate.html#pandas.core.groupby.SeriesGroupBy.aggregate',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.aggregate',\n",
       "       'full_function': 'SeriesGroupBy.aggregate(func=None, *args, engine=None, engine_kwargs=None, **kwargs)',\n",
       "       'function_text': 'Aggregate using one or more operations over the specified axis.',\n",
       "       'parameter_names_desc': [{'param_name': 'func',\n",
       "         'param_type': 'function, str, list, dict or None',\n",
       "         'param_desc': \"Function to use for aggregating the data. If a function, must either\\nwork when passed a Series or when passed to Series.apply.\\nAccepted combinations are:\\n\\nfunction\\nstring function name\\nlist of functions and/or function names, e.g. [np.sum, 'mean']\\nNone, in which case **kwargs are used with Named Aggregation. Here the\\noutput has one column for each element in **kwargs. The name of the\\ncolumn is keyword, whereas the value determines the aggregation used to compute\\nthe values in the column.\\nCan also accept a Numba JIT function with\\nengine='numba' specified. Only passing a single function is supported\\nwith this engine.\\nIf the 'numba' engine is chosen, the function must be\\na user defined function with values and index as the\\nfirst and second arguments respectively in the function signature.\\nEach group’s index will be passed to the user defined function\\nand optionally available for use.\\n\\n\\n\\nDeprecated since version 2.1.0: Passing a dictionary is deprecated and will raise in a future version\\nof pandas. Pass a list of aggregations instead.\\n\\n\"},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': \"\\n'cython' : Runs the function through C-extensions from cython.\\n'numba' : Runs the function through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\\napplied to the function\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.aggregate',\n",
       "       'descriptions': 'Aggregate using one or more operations over the specified axis.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'func': {'type': 'string',\n",
       "          'description': \"function, str, list, dict or None. Function to use for aggregating the data. If a function, must either\\nwork when passed a Series or when passed to Series.apply.\\nAccepted combinations are:\\n\\nfunction\\nstring function name\\nlist of functions and/or function names, e.g. [np.sum, 'mean']\\nNone, in which case **kwargs are used with Named Aggregation. Here the\\noutput has one column for each element in **kwargs. The name of the\\ncolumn is keyword, whereas the value determines the aggregation used to compute\\nthe values in the column.\\nCan also accept a Numba JIT function with\\nengine='numba' specified. Only passing a single function is supported\\nwith this engine.\\nIf the 'numba' engine is chosen, the function must be\\na user defined function with values and index as the\\nfirst and second arguments respectively in the function signature.\\nEach group’s index will be passed to the user defined function\\nand optionally available for use.\\n\\n\\n\\nDeprecated since version 2.1.0: Passing a dictionary is deprecated and will raise in a future version\\nof pandas. Pass a list of aggregations instead.\\n\\n\"},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None. \\n'cython' : Runs the function through C-extensions from cython.\\n'numba' : Runs the function through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None',\n",
       "          'description': \"dict, default None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\\napplied to the function\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.transform(func,\\xa0*args[,\\xa0...])',\n",
       "      'func_desc': 'Call function producing a same-indexed Series on each group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.transform.html#pandas.core.groupby.SeriesGroupBy.transform',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.transform',\n",
       "       'full_function': 'SeriesGroupBy.transform(func, *args, engine=None, engine_kwargs=None, **kwargs)',\n",
       "       'function_text': 'Call function producing a same-indexed Series on each group. Returns a Series having the same indexes as the original object\\nfilled with the transformed values.',\n",
       "       'parameter_names_desc': [{'param_name': 'f',\n",
       "         'param_type': 'function, str',\n",
       "         'param_desc': \"Function to apply to each group. See the Notes section below for requirements.\\nAccepted inputs are:\\n\\nString\\nPython function\\nNumba JIT function with engine='numba' specified.\\n\\nOnly passing a single function is supported with this engine.\\nIf the 'numba' engine is chosen, the function must be\\na user defined function with values and index as the\\nfirst and second arguments respectively in the function signature.\\nEach group’s index will be passed to the user defined function\\nand optionally available for use.\\nIf a string is chosen, then it needs to be the name\\nof the groupby method you want to use.\\n\"},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': \"\\n'cython' : Runs the function through C-extensions from cython.\\n'numba' : Runs the function through JIT compiled code from numba.\\nNone : Defaults to 'cython' or the global setting compute.use_numba\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\\napplied to the function\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.transform',\n",
       "       'descriptions': 'Call function producing a same-indexed Series on each group. Returns a Series having the same indexes as the original object\\nfilled with the transformed values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'f': {'type': 'string',\n",
       "          'description': \"function, str. Function to apply to each group. See the Notes section below for requirements.\\nAccepted inputs are:\\n\\nString\\nPython function\\nNumba JIT function with engine='numba' specified.\\n\\nOnly passing a single function is supported with this engine.\\nIf the 'numba' engine is chosen, the function must be\\na user defined function with values and index as the\\nfirst and second arguments respectively in the function signature.\\nEach group’s index will be passed to the user defined function\\nand optionally available for use.\\nIf a string is chosen, then it needs to be the name\\nof the groupby method you want to use.\\n\"},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None. \\n'cython' : Runs the function through C-extensions from cython.\\n'numba' : Runs the function through JIT compiled code from numba.\\nNone : Defaults to 'cython' or the global setting compute.use_numba\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None',\n",
       "          'description': \"dict, default None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\\napplied to the function\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.pipe(func,\\xa0*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Apply a func with arguments to this GroupBy object and return its result.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.pipe.html#pandas.core.groupby.SeriesGroupBy.pipe',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.pipe',\n",
       "       'full_function': 'SeriesGroupBy.pipe(func, *args, **kwargs)',\n",
       "       'function_text': 'Apply a func with arguments to this GroupBy object and return its result. Use .pipe when you want to improve readability by chaining together\\nfunctions that expect Series, DataFrames, GroupBy or Resampler objects.\\nInstead of writing You can write which is much more readable.',\n",
       "       'parameter_names_desc': [{'param_name': 'func',\n",
       "         'param_type': 'callable or tuple of (callable, str)',\n",
       "         'param_desc': 'Function to apply to this GroupBy object or, alternatively,\\na (callable, data_keyword) tuple where data_keyword is a\\nstring indicating the keyword of callable that expects the\\nGroupBy object.\\n'},\n",
       "        {'param_name': 'args',\n",
       "         'param_type': 'iterable, optional',\n",
       "         'param_desc': 'Positional arguments passed into func.\\n'},\n",
       "        {'param_name': 'kwargs',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'A dictionary of keyword arguments passed into func.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.pipe',\n",
       "       'descriptions': 'Apply a func with arguments to this GroupBy object and return its result. Use .pipe when you want to improve readability by chaining together\\nfunctions that expect Series, DataFrames, GroupBy or Resampler objects.\\nInstead of writing You can write which is much more readable.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'func': {'type': 'string',\n",
       "          'description': 'callable or tuple of (callable, str). Function to apply to this GroupBy object or, alternatively,\\na (callable, data_keyword) tuple where data_keyword is a\\nstring indicating the keyword of callable that expects the\\nGroupBy object.\\n'},\n",
       "         'args': {'type': 'iterable, optional',\n",
       "          'description': 'iterable, optional. Positional arguments passed into func.\\n'},\n",
       "         'kwargs': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. A dictionary of keyword arguments passed into func.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.filter(func[,\\xa0dropna])',\n",
       "      'func_desc': \"Filter elements from groups that don't satisfy a criterion.\",\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.filter.html#pandas.core.groupby.DataFrameGroupBy.filter',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.filter',\n",
       "       'full_function': 'DataFrameGroupBy.filter(func, dropna=True, *args, **kwargs)',\n",
       "       'function_text': 'Filter elements from groups that don’t satisfy a criterion. Elements from groups are filtered if they do not satisfy the\\nboolean criterion specified by func.',\n",
       "       'parameter_names_desc': [{'param_name': 'func',\n",
       "         'param_type': 'function',\n",
       "         'param_desc': 'Criterion to apply to each group. Should return True or False.\\n'},\n",
       "        {'param_name': 'dropna',\n",
       "         'param_type': 'bool',\n",
       "         'param_desc': 'Drop groups that do not pass the filter. True by default; if False,\\ngroups that evaluate False are filled with NaNs.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.filter',\n",
       "       'descriptions': 'Filter elements from groups that don’t satisfy a criterion. Elements from groups are filtered if they do not satisfy the\\nboolean criterion specified by func.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'func': {'type': 'function',\n",
       "          'description': 'function. Criterion to apply to each group. Should return True or False.\\n'},\n",
       "         'dropna': {'type': 'boolean',\n",
       "          'description': 'bool. Drop groups that do not pass the filter. True by default; if False,\\ngroups that evaluate False are filled with NaNs.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.apply(func,\\xa0*args[,\\xa0...])',\n",
       "      'func_desc': 'Apply function func group-wise and combine the results together.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.apply.html#pandas.core.groupby.DataFrameGroupBy.apply',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.apply',\n",
       "       'full_function': 'DataFrameGroupBy.apply(func, *args, include_groups=True, **kwargs)',\n",
       "       'function_text': 'Apply function func group-wise and combine the results together. The function passed to apply must take a dataframe as its first\\nargument and return a DataFrame, Series or scalar. apply will\\nthen take care of combining the results back together into a single\\ndataframe or series. apply is therefore a highly flexible\\ngrouping method. While apply is a very flexible method, its downside is that\\nusing it can be quite a bit slower than using more specific methods\\nlike agg or transform. Pandas offers a wide range of method that will\\nbe much faster than using apply for their specific purposes, so try to\\nuse them before reaching for apply.',\n",
       "       'parameter_names_desc': [{'param_name': 'func',\n",
       "         'param_type': 'callable',\n",
       "         'param_desc': 'A callable that takes a dataframe as its first argument, and\\nreturns a dataframe, a series or a scalar. In addition the\\ncallable may take positional and keyword arguments.\\n'},\n",
       "        {'param_name': 'include_groups',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'When True, will attempt to apply func to the groupings in\\nthe case that they are columns of the DataFrame. If this raises a\\nTypeError, the result will be computed with the groupings excluded.\\nWhen False, the groupings will be excluded when applying func.\\n\\nNew in version 2.2.0.\\n\\n\\nDeprecated since version 2.2.0: Setting include_groups to True is deprecated. Only the value\\nFalse will be allowed in a future version of pandas.\\n\\n'},\n",
       "        {'param_name': 'args, kwargs',\n",
       "         'param_type': 'tuple and dict',\n",
       "         'param_desc': 'Optional positional and keyword arguments to pass to func.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.apply',\n",
       "       'descriptions': 'Apply function func group-wise and combine the results together. The function passed to apply must take a dataframe as its first\\nargument and return a DataFrame, Series or scalar. apply will\\nthen take care of combining the results back together into a single\\ndataframe or series. apply is therefore a highly flexible\\ngrouping method. While apply is a very flexible method, its downside is that\\nusing it can be quite a bit slower than using more specific methods\\nlike agg or transform. Pandas offers a wide range of method that will\\nbe much faster than using apply for their specific purposes, so try to\\nuse them before reaching for apply.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'func': {'type': 'object',\n",
       "          'description': 'callable. A callable that takes a dataframe as its first argument, and\\nreturns a dataframe, a series or a scalar. In addition the\\ncallable may take positional and keyword arguments.\\n'},\n",
       "         'include_groups': {'type': 'boolean',\n",
       "          'description': 'bool, default True. When True, will attempt to apply func to the groupings in\\nthe case that they are columns of the DataFrame. If this raises a\\nTypeError, the result will be computed with the groupings excluded.\\nWhen False, the groupings will be excluded when applying func.\\n\\nNew in version 2.2.0.\\n\\n\\nDeprecated since version 2.2.0: Setting include_groups to True is deprecated. Only the value\\nFalse will be allowed in a future version of pandas.\\n\\n'},\n",
       "         'args, kwargs': {'type': 'tuple and dict',\n",
       "          'description': 'tuple and dict. Optional positional and keyword arguments to pass to func.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.agg([func,\\xa0engine,\\xa0...])',\n",
       "      'func_desc': 'Aggregate using one or more operations over the specified axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.agg.html#pandas.core.groupby.DataFrameGroupBy.agg',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.agg',\n",
       "       'full_function': 'DataFrameGroupBy.agg(func=None, *args, engine=None, engine_kwargs=None, **kwargs)',\n",
       "       'function_text': 'Aggregate using one or more operations over the specified axis.',\n",
       "       'parameter_names_desc': [{'param_name': 'func',\n",
       "         'param_type': 'function, str, list, dict or None',\n",
       "         'param_desc': \"Function to use for aggregating the data. If a function, must either\\nwork when passed a DataFrame or when passed to DataFrame.apply.\\nAccepted combinations are:\\n\\nfunction\\nstring function name\\nlist of functions and/or function names, e.g. [np.sum, 'mean']\\ndict of axis labels -> functions, function names or list of such.\\nNone, in which case **kwargs are used with Named Aggregation. Here the\\noutput has one column for each element in **kwargs. The name of the\\ncolumn is keyword, whereas the value determines the aggregation used to compute\\nthe values in the column.\\nCan also accept a Numba JIT function with\\nengine='numba' specified. Only passing a single function is supported\\nwith this engine.\\nIf the 'numba' engine is chosen, the function must be\\na user defined function with values and index as the\\nfirst and second arguments respectively in the function signature.\\nEach group’s index will be passed to the user defined function\\nand optionally available for use.\\n\\n\\n\"},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': \"\\n'cython' : Runs the function through C-extensions from cython.\\n'numba' : Runs the function through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\\napplied to the function\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.agg',\n",
       "       'descriptions': 'Aggregate using one or more operations over the specified axis.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'func': {'type': 'string',\n",
       "          'description': \"function, str, list, dict or None. Function to use for aggregating the data. If a function, must either\\nwork when passed a DataFrame or when passed to DataFrame.apply.\\nAccepted combinations are:\\n\\nfunction\\nstring function name\\nlist of functions and/or function names, e.g. [np.sum, 'mean']\\ndict of axis labels -> functions, function names or list of such.\\nNone, in which case **kwargs are used with Named Aggregation. Here the\\noutput has one column for each element in **kwargs. The name of the\\ncolumn is keyword, whereas the value determines the aggregation used to compute\\nthe values in the column.\\nCan also accept a Numba JIT function with\\nengine='numba' specified. Only passing a single function is supported\\nwith this engine.\\nIf the 'numba' engine is chosen, the function must be\\na user defined function with values and index as the\\nfirst and second arguments respectively in the function signature.\\nEach group’s index will be passed to the user defined function\\nand optionally available for use.\\n\\n\\n\"},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None. \\n'cython' : Runs the function through C-extensions from cython.\\n'numba' : Runs the function through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None',\n",
       "          'description': \"dict, default None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\\napplied to the function\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.aggregate([func,\\xa0engine,\\xa0...])',\n",
       "      'func_desc': 'Aggregate using one or more operations over the specified axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.aggregate.html#pandas.core.groupby.DataFrameGroupBy.aggregate',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.aggregate',\n",
       "       'full_function': 'DataFrameGroupBy.aggregate(func=None, *args, engine=None, engine_kwargs=None, **kwargs)',\n",
       "       'function_text': 'Aggregate using one or more operations over the specified axis.',\n",
       "       'parameter_names_desc': [{'param_name': 'func',\n",
       "         'param_type': 'function, str, list, dict or None',\n",
       "         'param_desc': \"Function to use for aggregating the data. If a function, must either\\nwork when passed a DataFrame or when passed to DataFrame.apply.\\nAccepted combinations are:\\n\\nfunction\\nstring function name\\nlist of functions and/or function names, e.g. [np.sum, 'mean']\\ndict of axis labels -> functions, function names or list of such.\\nNone, in which case **kwargs are used with Named Aggregation. Here the\\noutput has one column for each element in **kwargs. The name of the\\ncolumn is keyword, whereas the value determines the aggregation used to compute\\nthe values in the column.\\nCan also accept a Numba JIT function with\\nengine='numba' specified. Only passing a single function is supported\\nwith this engine.\\nIf the 'numba' engine is chosen, the function must be\\na user defined function with values and index as the\\nfirst and second arguments respectively in the function signature.\\nEach group’s index will be passed to the user defined function\\nand optionally available for use.\\n\\n\\n\"},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': \"\\n'cython' : Runs the function through C-extensions from cython.\\n'numba' : Runs the function through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\\napplied to the function\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.aggregate',\n",
       "       'descriptions': 'Aggregate using one or more operations over the specified axis.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'func': {'type': 'string',\n",
       "          'description': \"function, str, list, dict or None. Function to use for aggregating the data. If a function, must either\\nwork when passed a DataFrame or when passed to DataFrame.apply.\\nAccepted combinations are:\\n\\nfunction\\nstring function name\\nlist of functions and/or function names, e.g. [np.sum, 'mean']\\ndict of axis labels -> functions, function names or list of such.\\nNone, in which case **kwargs are used with Named Aggregation. Here the\\noutput has one column for each element in **kwargs. The name of the\\ncolumn is keyword, whereas the value determines the aggregation used to compute\\nthe values in the column.\\nCan also accept a Numba JIT function with\\nengine='numba' specified. Only passing a single function is supported\\nwith this engine.\\nIf the 'numba' engine is chosen, the function must be\\na user defined function with values and index as the\\nfirst and second arguments respectively in the function signature.\\nEach group’s index will be passed to the user defined function\\nand optionally available for use.\\n\\n\\n\"},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None. \\n'cython' : Runs the function through C-extensions from cython.\\n'numba' : Runs the function through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None',\n",
       "          'description': \"dict, default None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\\napplied to the function\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.transform(func,\\xa0*args[,\\xa0...])',\n",
       "      'func_desc': 'Call function producing a same-indexed DataFrame on each group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.transform.html#pandas.core.groupby.DataFrameGroupBy.transform',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.transform',\n",
       "       'full_function': 'DataFrameGroupBy.transform(func, *args, engine=None, engine_kwargs=None, **kwargs)',\n",
       "       'function_text': 'Call function producing a same-indexed DataFrame on each group. Returns a DataFrame having the same indexes as the original object\\nfilled with the transformed values.',\n",
       "       'parameter_names_desc': [{'param_name': 'f',\n",
       "         'param_type': 'function, str',\n",
       "         'param_desc': \"Function to apply to each group. See the Notes section below for requirements.\\nAccepted inputs are:\\n\\nString\\nPython function\\nNumba JIT function with engine='numba' specified.\\n\\nOnly passing a single function is supported with this engine.\\nIf the 'numba' engine is chosen, the function must be\\na user defined function with values and index as the\\nfirst and second arguments respectively in the function signature.\\nEach group’s index will be passed to the user defined function\\nand optionally available for use.\\nIf a string is chosen, then it needs to be the name\\nof the groupby method you want to use.\\n\"},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': \"\\n'cython' : Runs the function through C-extensions from cython.\\n'numba' : Runs the function through JIT compiled code from numba.\\nNone : Defaults to 'cython' or the global setting compute.use_numba\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\\napplied to the function\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.transform',\n",
       "       'descriptions': 'Call function producing a same-indexed DataFrame on each group. Returns a DataFrame having the same indexes as the original object\\nfilled with the transformed values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'f': {'type': 'string',\n",
       "          'description': \"function, str. Function to apply to each group. See the Notes section below for requirements.\\nAccepted inputs are:\\n\\nString\\nPython function\\nNumba JIT function with engine='numba' specified.\\n\\nOnly passing a single function is supported with this engine.\\nIf the 'numba' engine is chosen, the function must be\\na user defined function with values and index as the\\nfirst and second arguments respectively in the function signature.\\nEach group’s index will be passed to the user defined function\\nand optionally available for use.\\nIf a string is chosen, then it needs to be the name\\nof the groupby method you want to use.\\n\"},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None. \\n'cython' : Runs the function through C-extensions from cython.\\n'numba' : Runs the function through JIT compiled code from numba.\\nNone : Defaults to 'cython' or the global setting compute.use_numba\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None',\n",
       "          'description': \"dict, default None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\\napplied to the function\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.pipe(func,\\xa0*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Apply a func with arguments to this GroupBy object and return its result.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.pipe.html#pandas.core.groupby.DataFrameGroupBy.pipe',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.pipe',\n",
       "       'full_function': 'DataFrameGroupBy.pipe(func, *args, **kwargs)',\n",
       "       'function_text': 'Apply a func with arguments to this GroupBy object and return its result. Use .pipe when you want to improve readability by chaining together\\nfunctions that expect Series, DataFrames, GroupBy or Resampler objects.\\nInstead of writing You can write which is much more readable.',\n",
       "       'parameter_names_desc': [{'param_name': 'func',\n",
       "         'param_type': 'callable or tuple of (callable, str)',\n",
       "         'param_desc': 'Function to apply to this GroupBy object or, alternatively,\\na (callable, data_keyword) tuple where data_keyword is a\\nstring indicating the keyword of callable that expects the\\nGroupBy object.\\n'},\n",
       "        {'param_name': 'args',\n",
       "         'param_type': 'iterable, optional',\n",
       "         'param_desc': 'Positional arguments passed into func.\\n'},\n",
       "        {'param_name': 'kwargs',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'A dictionary of keyword arguments passed into func.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.pipe',\n",
       "       'descriptions': 'Apply a func with arguments to this GroupBy object and return its result. Use .pipe when you want to improve readability by chaining together\\nfunctions that expect Series, DataFrames, GroupBy or Resampler objects.\\nInstead of writing You can write which is much more readable.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'func': {'type': 'string',\n",
       "          'description': 'callable or tuple of (callable, str). Function to apply to this GroupBy object or, alternatively,\\na (callable, data_keyword) tuple where data_keyword is a\\nstring indicating the keyword of callable that expects the\\nGroupBy object.\\n'},\n",
       "         'args': {'type': 'iterable, optional',\n",
       "          'description': 'iterable, optional. Positional arguments passed into func.\\n'},\n",
       "         'kwargs': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. A dictionary of keyword arguments passed into func.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.filter(func[,\\xa0dropna])',\n",
       "      'func_desc': \"Filter elements from groups that don't satisfy a criterion.\",\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.filter.html#pandas.core.groupby.SeriesGroupBy.filter',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.filter',\n",
       "       'full_function': 'SeriesGroupBy.filter(func, dropna=True, *args, **kwargs)',\n",
       "       'function_text': 'Filter elements from groups that don’t satisfy a criterion. Elements from groups are filtered if they do not satisfy the\\nboolean criterion specified by func.',\n",
       "       'parameter_names_desc': [{'param_name': 'func',\n",
       "         'param_type': 'function',\n",
       "         'param_desc': 'Criterion to apply to each group. Should return True or False.\\n'},\n",
       "        {'param_name': 'dropna',\n",
       "         'param_type': 'bool',\n",
       "         'param_desc': 'Drop groups that do not pass the filter. True by default; if False,\\ngroups that evaluate False are filled with NaNs.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.filter',\n",
       "       'descriptions': 'Filter elements from groups that don’t satisfy a criterion. Elements from groups are filtered if they do not satisfy the\\nboolean criterion specified by func.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'func': {'type': 'function',\n",
       "          'description': 'function. Criterion to apply to each group. Should return True or False.\\n'},\n",
       "         'dropna': {'type': 'boolean',\n",
       "          'description': 'bool. Drop groups that do not pass the filter. True by default; if False,\\ngroups that evaluate False are filled with NaNs.\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'DataFrameGroupBy computations / descriptive stats': [{'func_name': 'DataFrameGroupBy.all([skipna])',\n",
       "      'func_desc': 'Return True if all values in the group are truthful, else False.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.all.html#pandas.core.groupby.DataFrameGroupBy.all',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.all',\n",
       "       'full_function': 'DataFrameGroupBy.all(skipna=True)',\n",
       "       'function_text': 'Return True if all values in the group are truthful, else False.',\n",
       "       'parameter_names_desc': [{'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Flag to ignore nan values during truth testing.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.all',\n",
       "       'descriptions': 'Return True if all values in the group are truthful, else False.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Flag to ignore nan values during truth testing.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.bfill([limit])',\n",
       "      'func_desc': 'Backward fill the values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.bfill.html#pandas.core.groupby.DataFrameGroupBy.bfill',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.bfill',\n",
       "       'full_function': 'DataFrameGroupBy.bfill(limit=None)',\n",
       "       'function_text': 'Backward fill the values.',\n",
       "       'parameter_names_desc': [{'param_name': 'limit',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Limit of how many values to fill.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.bfill',\n",
       "       'descriptions': 'Backward fill the values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'limit': {'type': 'integer',\n",
       "          'description': 'int, optional. Limit of how many values to fill.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.corrwith(other[,\\xa0axis,\\xa0...])',\n",
       "      'func_desc': 'Compute pairwise correlation.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.corrwith.html#pandas.core.groupby.DataFrameGroupBy.corrwith',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.corrwith',\n",
       "       'full_function': \"DataFrameGroupBy.corrwith(other, axis=_NoDefault.no_default, drop=False, method='pearson', numeric_only=False)\",\n",
       "       'function_text': 'Compute pairwise correlation. Pairwise correlation is computed between rows or columns of\\nDataFrame with rows or columns of Series or DataFrame. DataFrames\\nare first aligned along both axes before computing the\\ncorrelations.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'DataFrame, Series',\n",
       "         'param_desc': 'Object with which to compute correlations.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'The axis to use. 0 or ‘index’ to compute row-wise, 1 or ‘columns’ for\\ncolumn-wise.\\n'},\n",
       "        {'param_name': 'drop',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Drop missing indices from result.\\n'},\n",
       "        {'param_name': 'method',\n",
       "         'param_type': '{‘pearson’, ‘kendall’, ‘spearman’} or callable',\n",
       "         'param_desc': 'Method of correlation:\\n\\npearson : standard correlation coefficient\\nkendall : Kendall Tau correlation coefficient\\nspearman : Spearman rank correlation\\n\\ncallable: callable with input two 1d ndarraysand returning a float.\\n\\n\\n\\n\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int or boolean data.\\n\\nNew in version 1.5.0.\\n\\n\\nChanged in version 2.0.0: The default value of numeric_only is now False.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.corrwith',\n",
       "       'descriptions': 'Compute pairwise correlation. Pairwise correlation is computed between rows or columns of\\nDataFrame with rows or columns of Series or DataFrame. DataFrames\\nare first aligned along both axes before computing the\\ncorrelations.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'DataFrame, Series',\n",
       "          'description': 'DataFrame, Series. Object with which to compute correlations.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. The axis to use. 0 or ‘index’ to compute row-wise, 1 or ‘columns’ for\\ncolumn-wise.\\n'},\n",
       "         'drop': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Drop missing indices from result.\\n'},\n",
       "         'method': {'type': 'object',\n",
       "          'description': '{‘pearson’, ‘kendall’, ‘spearman’} or callable. Method of correlation:\\n\\npearson : standard correlation coefficient\\nkendall : Kendall Tau correlation coefficient\\nspearman : Spearman rank correlation\\n\\ncallable: callable with input two 1d ndarraysand returning a float.\\n\\n\\n\\n\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int or boolean data.\\n\\nNew in version 1.5.0.\\n\\n\\nChanged in version 2.0.0: The default value of numeric_only is now False.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.cov([min_periods,\\xa0ddof,\\xa0...])',\n",
       "      'func_desc': 'Compute pairwise covariance of columns, excluding NA/null values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cov.html#pandas.core.groupby.DataFrameGroupBy.cov',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.cov',\n",
       "       'full_function': 'DataFrameGroupBy.cov(min_periods=None, ddof=1, numeric_only=False)',\n",
       "       'function_text': 'Compute pairwise covariance of columns, excluding NA/null values. Compute the pairwise covariance among the series of a DataFrame.\\nThe returned data frame is the covariance matrix of the columns\\nof the DataFrame. Both NA and null values are automatically excluded from the\\ncalculation. (See the note below about bias from missing values.)\\nA threshold can be set for the minimum number of\\nobservations for each value created. Comparisons with observations\\nbelow this threshold will be returned as NaN. This method is generally used for the analysis of time series data to\\nunderstand the relationship between different measures\\nacross time.',\n",
       "       'parameter_names_desc': [{'param_name': 'min_periods',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Minimum number of observations required per pair of columns\\nto have a valid result.\\n'},\n",
       "        {'param_name': 'ddof',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Delta degrees of freedom. The divisor used in calculations\\nis N - ddof, where N represents the number of elements.\\nThis argument is applicable only when no nan is in the dataframe.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int or boolean data.\\n\\nNew in version 1.5.0.\\n\\n\\nChanged in version 2.0.0: The default value of numeric_only is now False.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.cov',\n",
       "       'descriptions': 'Compute pairwise covariance of columns, excluding NA/null values. Compute the pairwise covariance among the series of a DataFrame.\\nThe returned data frame is the covariance matrix of the columns\\nof the DataFrame. Both NA and null values are automatically excluded from the\\ncalculation. (See the note below about bias from missing values.)\\nA threshold can be set for the minimum number of\\nobservations for each value created. Comparisons with observations\\nbelow this threshold will be returned as NaN. This method is generally used for the analysis of time series data to\\nunderstand the relationship between different measures\\nacross time.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'min_periods': {'type': 'integer',\n",
       "          'description': 'int, optional. Minimum number of observations required per pair of columns\\nto have a valid result.\\n'},\n",
       "         'ddof': {'type': 'integer',\n",
       "          'description': 'int, default 1. Delta degrees of freedom. The divisor used in calculations\\nis N - ddof, where N represents the number of elements.\\nThis argument is applicable only when no nan is in the dataframe.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int or boolean data.\\n\\nNew in version 1.5.0.\\n\\n\\nChanged in version 2.0.0: The default value of numeric_only is now False.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.cummax([axis,\\xa0numeric_only])',\n",
       "      'func_desc': 'Cumulative max for each group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cummax.html#pandas.core.groupby.DataFrameGroupBy.cummax',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.cummax',\n",
       "       'full_function': 'DataFrameGroupBy.cummax(axis=_NoDefault.no_default, numeric_only=False, **kwargs)',\n",
       "       'function_text': 'Cumulative max for each group.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrameGroupBy.cumprod([axis])',\n",
       "      'func_desc': 'Cumulative product for each group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cumprod.html#pandas.core.groupby.DataFrameGroupBy.cumprod',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.cumprod',\n",
       "       'full_function': 'DataFrameGroupBy.cumprod(axis=_NoDefault.no_default, *args, **kwargs)',\n",
       "       'function_text': 'Cumulative product for each group.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrameGroupBy.describe([percentiles,\\xa0...])',\n",
       "      'func_desc': 'Generate descriptive statistics.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.describe.html#pandas.core.groupby.DataFrameGroupBy.describe',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.describe',\n",
       "       'full_function': 'DataFrameGroupBy.describe(percentiles=None, include=None, exclude=None)',\n",
       "       'function_text': 'Generate descriptive statistics. Descriptive statistics include those that summarize the central\\ntendency, dispersion and shape of a\\ndataset’s distribution, excluding NaN values. Analyzes both numeric and object series, as well\\nas DataFrame column sets of mixed data types. The output\\nwill vary depending on what is provided. Refer to the notes\\nbelow for more detail.',\n",
       "       'parameter_names_desc': [{'param_name': 'percentiles',\n",
       "         'param_type': 'list-like of numbers, optional',\n",
       "         'param_desc': 'The percentiles to include in the output. All should\\nfall between 0 and 1. The default is\\n[.25, .5, .75], which returns the 25th, 50th, and\\n75th percentiles.\\n'},\n",
       "        {'param_name': 'include',\n",
       "         'param_type': '‘all’, list-like of dtypes or None (default), optional',\n",
       "         'param_desc': \"A white list of data types to include in the result. Ignored\\nfor Series. Here are the options:\\n\\n‘all’ : All columns of the input will be included in the output.\\nA list-like of dtypes : Limits the results to the\\nprovided data types.\\nTo limit the result to numeric types submit\\nnumpy.number. To limit it instead to object columns submit\\nthe numpy.object data type. Strings\\ncan also be used in the style of\\nselect_dtypes (e.g. df.describe(include=['O'])). To\\nselect pandas categorical columns, use 'category'\\nNone (default) : The result will include all numeric columns.\\n\\n\"},\n",
       "        {'param_name': 'exclude',\n",
       "         'param_type': 'list-like of dtypes or None (default), optional,',\n",
       "         'param_desc': \"A black list of data types to omit from the result. Ignored\\nfor Series. Here are the options:\\n\\nA list-like of dtypes : Excludes the provided data types\\nfrom the result. To exclude numeric types submit\\nnumpy.number. To exclude object columns submit the data\\ntype numpy.object. Strings can also be used in the style of\\nselect_dtypes (e.g. df.describe(exclude=['O'])). To\\nexclude pandas categorical columns, use 'category'\\nNone (default) : The result will exclude nothing.\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.describe',\n",
       "       'descriptions': 'Generate descriptive statistics. Descriptive statistics include those that summarize the central\\ntendency, dispersion and shape of a\\ndataset’s distribution, excluding NaN values. Analyzes both numeric and object series, as well\\nas DataFrame column sets of mixed data types. The output\\nwill vary depending on what is provided. Refer to the notes\\nbelow for more detail.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'percentiles': {'type': 'array',\n",
       "          'description': 'list-like of numbers, optional. The percentiles to include in the output. All should\\nfall between 0 and 1. The default is\\n[.25, .5, .75], which returns the 25th, 50th, and\\n75th percentiles.\\n'},\n",
       "         'include': {'type': 'array',\n",
       "          'description': \"‘all’, list-like of dtypes or None (default), optional. A white list of data types to include in the result. Ignored\\nfor Series. Here are the options:\\n\\n‘all’ : All columns of the input will be included in the output.\\nA list-like of dtypes : Limits the results to the\\nprovided data types.\\nTo limit the result to numeric types submit\\nnumpy.number. To limit it instead to object columns submit\\nthe numpy.object data type. Strings\\ncan also be used in the style of\\nselect_dtypes (e.g. df.describe(include=['O'])). To\\nselect pandas categorical columns, use 'category'\\nNone (default) : The result will include all numeric columns.\\n\\n\"},\n",
       "         'exclude': {'type': 'array',\n",
       "          'description': \"list-like of dtypes or None (default), optional,. A black list of data types to omit from the result. Ignored\\nfor Series. Here are the options:\\n\\nA list-like of dtypes : Excludes the provided data types\\nfrom the result. To exclude numeric types submit\\nnumpy.number. To exclude object columns submit the data\\ntype numpy.object. Strings can also be used in the style of\\nselect_dtypes (e.g. df.describe(exclude=['O'])). To\\nexclude pandas categorical columns, use 'category'\\nNone (default) : The result will exclude nothing.\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.ffill([limit])',\n",
       "      'func_desc': 'Forward fill the values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.ffill.html#pandas.core.groupby.DataFrameGroupBy.ffill',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.ffill',\n",
       "       'full_function': 'DataFrameGroupBy.ffill(limit=None)',\n",
       "       'function_text': 'Forward fill the values.',\n",
       "       'parameter_names_desc': [{'param_name': 'limit',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Limit of how many values to fill.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.ffill',\n",
       "       'descriptions': 'Forward fill the values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'limit': {'type': 'integer',\n",
       "          'description': 'int, optional. Limit of how many values to fill.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.first([numeric_only,\\xa0...])',\n",
       "      'func_desc': 'Compute the first entry of each column within each group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.first.html#pandas.core.groupby.DataFrameGroupBy.first',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.first',\n",
       "       'full_function': 'DataFrameGroupBy.first(numeric_only=False, min_count=-1, skipna=True)',\n",
       "       'function_text': 'Compute the first entry of each column within each group. Defaults to skipping NA elements.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n'},\n",
       "        {'param_name': 'min_count',\n",
       "         'param_type': 'int, default -1',\n",
       "         'param_desc': 'The required number of valid values to perform the operation. If fewer\\nthan min_count valid values are present the result will be NA.\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n\\nNew in version 2.2.1.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.first',\n",
       "       'descriptions': 'Compute the first entry of each column within each group. Defaults to skipping NA elements.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n'},\n",
       "         'min_count': {'type': 'integer',\n",
       "          'description': 'int, default -1. The required number of valid values to perform the operation. If fewer\\nthan min_count valid values are present the result will be NA.\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n\\nNew in version 2.2.1.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.idxmax([axis,\\xa0skipna,\\xa0...])',\n",
       "      'func_desc': 'Return index of first occurrence of maximum over requested axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.idxmax.html#pandas.core.groupby.DataFrameGroupBy.idxmax',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.idxmax',\n",
       "       'full_function': 'DataFrameGroupBy.idxmax(axis=_NoDefault.no_default, skipna=True, numeric_only=False)',\n",
       "       'function_text': 'Return index of first occurrence of maximum over requested axis. NA/null values are excluded.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrameGroupBy.last([numeric_only,\\xa0...])',\n",
       "      'func_desc': 'Compute the last entry of each column within each group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.last.html#pandas.core.groupby.DataFrameGroupBy.last',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.last',\n",
       "       'full_function': 'DataFrameGroupBy.last(numeric_only=False, min_count=-1, skipna=True)',\n",
       "       'function_text': 'Compute the last entry of each column within each group. Defaults to skipping NA elements.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns. If None, will attempt to use\\neverything, then use only numeric data.\\n'},\n",
       "        {'param_name': 'min_count',\n",
       "         'param_type': 'int, default -1',\n",
       "         'param_desc': 'The required number of valid values to perform the operation. If fewer\\nthan min_count valid values are present the result will be NA.\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n\\nNew in version 2.2.1.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.last',\n",
       "       'descriptions': 'Compute the last entry of each column within each group. Defaults to skipping NA elements.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns. If None, will attempt to use\\neverything, then use only numeric data.\\n'},\n",
       "         'min_count': {'type': 'integer',\n",
       "          'description': 'int, default -1. The required number of valid values to perform the operation. If fewer\\nthan min_count valid values are present the result will be NA.\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n\\nNew in version 2.2.1.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.mean([numeric_only,\\xa0...])',\n",
       "      'func_desc': 'Compute mean of groups, excluding missing values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.mean.html#pandas.core.groupby.DataFrameGroupBy.mean',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.mean',\n",
       "       'full_function': 'DataFrameGroupBy.mean(numeric_only=False, engine=None, engine_kwargs=None)',\n",
       "       'function_text': 'Compute mean of groups, excluding missing values.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nChanged in version 2.0.0: numeric_only no longer accepts None and defaults to False.\\n\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': \"\\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting\\ncompute.use_numba\\n\\n\\nNew in version 1.4.0.\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{{'nopython': True, 'nogil': False, 'parallel': False}}\\n\\n\\nNew in version 1.4.0.\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.mean',\n",
       "       'descriptions': 'Compute mean of groups, excluding missing values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nChanged in version 2.0.0: numeric_only no longer accepts None and defaults to False.\\n\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None. \\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting\\ncompute.use_numba\\n\\n\\nNew in version 1.4.0.\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None',\n",
       "          'description': \"dict, default None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{{'nopython': True, 'nogil': False, 'parallel': False}}\\n\\n\\nNew in version 1.4.0.\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.min([numeric_only,\\xa0...])',\n",
       "      'func_desc': 'Compute min of group values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.min.html#pandas.core.groupby.DataFrameGroupBy.min',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.min',\n",
       "       'full_function': 'DataFrameGroupBy.min(numeric_only=False, min_count=-1, engine=None, engine_kwargs=None)',\n",
       "       'function_text': 'Compute min of group values.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nChanged in version 2.0.0: numeric_only no longer accepts None.\\n\\n'},\n",
       "        {'param_name': 'min_count',\n",
       "         'param_type': 'int, default -1',\n",
       "         'param_desc': 'The required number of valid values to perform the operation. If fewer\\nthan min_count non-NA values are present the result will be NA.\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None None',\n",
       "         'param_desc': \"\\n'cython' : Runs rolling apply through C-extensions from cython.\\n\\n'numba'Runs rolling apply through JIT compiled code from numba.Only available when raw is set to True.\\n\\n\\n\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\n\\nFor 'numba' engine, the engine can accept nopython, nogiland parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\\napplied to both the func and the apply groupby aggregation.\\n\\n\\n\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.min',\n",
       "       'descriptions': 'Compute min of group values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nChanged in version 2.0.0: numeric_only no longer accepts None.\\n\\n'},\n",
       "         'min_count': {'type': 'integer',\n",
       "          'description': 'int, default -1. The required number of valid values to perform the operation. If fewer\\nthan min_count non-NA values are present the result will be NA.\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None None. \\n'cython' : Runs rolling apply through C-extensions from cython.\\n\\n'numba'Runs rolling apply through JIT compiled code from numba.Only available when raw is set to True.\\n\\n\\n\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None None',\n",
       "          'description': \"dict, default None None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\n\\nFor 'numba' engine, the engine can accept nopython, nogiland parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\\napplied to both the func and the apply groupby aggregation.\\n\\n\\n\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.nth',\n",
       "      'func_desc': 'Take the nth row from each group if n is an int, otherwise a subset of rows.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.nth.html#pandas.core.groupby.DataFrameGroupBy.nth',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.nth',\n",
       "       'full_function': 'property DataFrameGroupBy.nth',\n",
       "       'function_text': 'Take the nth row from each group if n is an int, otherwise a subset of rows. Can be either a call or an index. dropna is not available with index notation.\\nIndex notation accepts a comma separated list of integers and slices. If dropna, will take the nth non-null row, dropna is either\\n‘all’ or ‘any’; this is equivalent to calling dropna(how=dropna)\\nbefore the groupby.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, slice or list of ints and slices',\n",
       "         'param_desc': 'A single nth value for the row or a list of nth values or slices.\\n\\nChanged in version 1.4.0: Added slice and lists containing slices.\\nAdded index notation.\\n\\n'},\n",
       "        {'param_name': 'dropna',\n",
       "         'param_type': '{‘any’, ‘all’, None}, default None',\n",
       "         'param_desc': 'Apply the specified dropna operation before counting which row is\\nthe nth row. Only supported if n is an int.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.nth',\n",
       "       'descriptions': 'Take the nth row from each group if n is an int, otherwise a subset of rows. Can be either a call or an index. dropna is not available with index notation.\\nIndex notation accepts a comma separated list of integers and slices. If dropna, will take the nth non-null row, dropna is either\\n‘all’ or ‘any’; this is equivalent to calling dropna(how=dropna)\\nbefore the groupby.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, slice or list of ints and slices. A single nth value for the row or a list of nth values or slices.\\n\\nChanged in version 1.4.0: Added slice and lists containing slices.\\nAdded index notation.\\n\\n'},\n",
       "         'dropna': {'type': 'string',\n",
       "          'enum': ['any', ' all', ' None'],\n",
       "          'description': '{‘any’, ‘all’, None}, default None. Apply the specified dropna operation before counting which row is\\nthe nth row. Only supported if n is an int.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.ohlc()',\n",
       "      'func_desc': 'Compute open, high, low and close values of a group, excluding missing values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.ohlc.html#pandas.core.groupby.DataFrameGroupBy.ohlc',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.ohlc',\n",
       "       'full_function': 'DataFrameGroupBy.ohlc()',\n",
       "       'function_text': 'Compute open, high, low and close values of a group, excluding missing values. For multiple groupings, the result index will be a MultiIndex',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrameGroupBy.prod([numeric_only,\\xa0min_count])',\n",
       "      'func_desc': 'Compute prod of group values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.prod.html#pandas.core.groupby.DataFrameGroupBy.prod',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.prod',\n",
       "       'full_function': 'DataFrameGroupBy.prod(numeric_only=False, min_count=0)',\n",
       "       'function_text': 'Compute prod of group values.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nChanged in version 2.0.0: numeric_only no longer accepts None.\\n\\n'},\n",
       "        {'param_name': 'min_count',\n",
       "         'param_type': 'int, default 0',\n",
       "         'param_desc': 'The required number of valid values to perform the operation. If fewer\\nthan min_count non-NA values are present the result will be NA.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.prod',\n",
       "       'descriptions': 'Compute prod of group values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nChanged in version 2.0.0: numeric_only no longer accepts None.\\n\\n'},\n",
       "         'min_count': {'type': 'integer',\n",
       "          'description': 'int, default 0. The required number of valid values to perform the operation. If fewer\\nthan min_count non-NA values are present the result will be NA.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.rank([method,\\xa0ascending,\\xa0...])',\n",
       "      'func_desc': 'Provide the rank of values within each group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.rank.html#pandas.core.groupby.DataFrameGroupBy.rank',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.rank',\n",
       "       'full_function': \"DataFrameGroupBy.rank(method='average', ascending=True, na_option='keep', pct=False, axis=_NoDefault.no_default)\",\n",
       "       'function_text': 'Provide the rank of values within each group.',\n",
       "       'parameter_names_desc': [{'param_name': 'method',\n",
       "         'param_type': '{‘average’, ‘min’, ‘max’, ‘first’, ‘dense’}, default ‘average’',\n",
       "         'param_desc': '\\naverage: average rank of group.\\nmin: lowest rank in group.\\nmax: highest rank in group.\\nfirst: ranks assigned in order they appear in the array.\\ndense: like ‘min’, but rank always increases by 1 between groups.\\n\\n'},\n",
       "        {'param_name': 'ascending',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'False for ranks by high (1) to low (N).\\n'},\n",
       "        {'param_name': 'na_option',\n",
       "         'param_type': '{‘keep’, ‘top’, ‘bottom’}, default ‘keep’',\n",
       "         'param_desc': '\\nkeep: leave NA values where they are.\\ntop: smallest rank if ascending.\\nbottom: smallest rank if descending.\\n\\n'},\n",
       "        {'param_name': 'pct',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Compute percentage rank of data within each group.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': 'int, default 0',\n",
       "         'param_desc': 'The axis of the object over which to compute the rank.\\n\\nDeprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\\nthe axis keyword is not necessary.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.rank',\n",
       "       'descriptions': 'Provide the rank of values within each group.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'method': {'type': 'string',\n",
       "          'enum': ['average', ' min', ' max', ' first', ' dense'],\n",
       "          'description': '{‘average’, ‘min’, ‘max’, ‘first’, ‘dense’}, default ‘average’. \\naverage: average rank of group.\\nmin: lowest rank in group.\\nmax: highest rank in group.\\nfirst: ranks assigned in order they appear in the array.\\ndense: like ‘min’, but rank always increases by 1 between groups.\\n\\n'},\n",
       "         'ascending': {'type': 'boolean',\n",
       "          'description': 'bool, default True. False for ranks by high (1) to low (N).\\n'},\n",
       "         'na_option': {'type': 'string',\n",
       "          'enum': ['keep', ' top', ' bottom'],\n",
       "          'description': '{‘keep’, ‘top’, ‘bottom’}, default ‘keep’. \\nkeep: leave NA values where they are.\\ntop: smallest rank if ascending.\\nbottom: smallest rank if descending.\\n\\n'},\n",
       "         'pct': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Compute percentage rank of data within each group.\\n'},\n",
       "         'axis': {'type': 'integer',\n",
       "          'description': 'int, default 0. The axis of the object over which to compute the rank.\\n\\nDeprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\\nthe axis keyword is not necessary.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.rolling(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Return a rolling grouper, providing rolling functionality per group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.rolling.html#pandas.core.groupby.DataFrameGroupBy.rolling',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.rolling',\n",
       "       'full_function': 'DataFrameGroupBy.rolling(*args, **kwargs)',\n",
       "       'function_text': 'Return a rolling grouper, providing rolling functionality per group.',\n",
       "       'parameter_names_desc': [{'param_name': 'window',\n",
       "         'param_type': 'int, timedelta, str, offset, or BaseIndexer subclass',\n",
       "         'param_desc': 'Size of the moving window.\\nIf an integer, the fixed number of observations used for\\neach window.\\nIf a timedelta, str, or offset, the time period of each window. Each\\nwindow will be a variable sized based on the observations included in\\nthe time-period. This is only valid for datetimelike indexes.\\nTo learn more about the offsets & frequency strings, please see this link.\\nIf a BaseIndexer subclass, the window boundaries\\nbased on the defined get_window_bounds method. Additional rolling\\nkeyword arguments, namely min_periods, center, closed and\\nstep will be passed to get_window_bounds.\\n'},\n",
       "        {'param_name': 'min_periods',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'Minimum number of observations in window required to have a value;\\notherwise, result is np.nan.\\nFor a window that is specified by an offset,\\nmin_periods will default to 1.\\nFor a window that is specified by an integer, min_periods will default\\nto the size of the window.\\n'},\n",
       "        {'param_name': 'center',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If False, set the window labels as the right edge of the window index.\\nIf True, set the window labels as the center of the window index.\\n'},\n",
       "        {'param_name': 'win_type',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'If None, all points are evenly weighted.\\nIf a string, it must be a valid scipy.signal window function.\\nCertain Scipy window types require additional parameters to be passed\\nin the aggregation function. The additional parameters must match\\nthe keywords specified in the Scipy window type method signature.\\n'},\n",
       "        {'param_name': 'on',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'For a DataFrame, a column label or Index level on which\\nto calculate the rolling window, rather than the DataFrame’s index.\\nProvided integer column is ignored and excluded from result since\\nan integer index is not used to calculate the rolling window.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': 'int or str, default 0',\n",
       "         'param_desc': \"If 0 or 'index', roll across the rows.\\nIf 1 or 'columns', roll across the columns.\\nFor Series this parameter is unused and defaults to 0.\\n\"},\n",
       "        {'param_name': 'closed',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': \"If 'right', the first point in the window is excluded from calculations.\\nIf 'left', the last point in the window is excluded from calculations.\\nIf 'both', no points in the window are excluded from calculations.\\nIf 'neither', the first and last points in the window are excluded\\nfrom calculations.\\nDefault None ('right').\\n\"},\n",
       "        {'param_name': 'method',\n",
       "         'param_type': 'str {‘single’, ‘table’}, default ‘single’',\n",
       "         'param_desc': \"Execute the rolling operation per single column or row ('single')\\nor over the entire object ('table').\\nThis argument is only implemented when specifying engine='numba'\\nin the method call.\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.rolling',\n",
       "       'descriptions': 'Return a rolling grouper, providing rolling functionality per group.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'window': {'type': 'integer',\n",
       "          'description': 'int, timedelta, str, offset, or BaseIndexer subclass. Size of the moving window.\\nIf an integer, the fixed number of observations used for\\neach window.\\nIf a timedelta, str, or offset, the time period of each window. Each\\nwindow will be a variable sized based on the observations included in\\nthe time-period. This is only valid for datetimelike indexes.\\nTo learn more about the offsets & frequency strings, please see this link.\\nIf a BaseIndexer subclass, the window boundaries\\nbased on the defined get_window_bounds method. Additional rolling\\nkeyword arguments, namely min_periods, center, closed and\\nstep will be passed to get_window_bounds.\\n'},\n",
       "         'min_periods': {'type': 'integer',\n",
       "          'description': 'int, default None. Minimum number of observations in window required to have a value;\\notherwise, result is np.nan.\\nFor a window that is specified by an offset,\\nmin_periods will default to 1.\\nFor a window that is specified by an integer, min_periods will default\\nto the size of the window.\\n'},\n",
       "         'center': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If False, set the window labels as the right edge of the window index.\\nIf True, set the window labels as the center of the window index.\\n'},\n",
       "         'win_type': {'type': 'string',\n",
       "          'description': 'str, default None. If None, all points are evenly weighted.\\nIf a string, it must be a valid scipy.signal window function.\\nCertain Scipy window types require additional parameters to be passed\\nin the aggregation function. The additional parameters must match\\nthe keywords specified in the Scipy window type method signature.\\n'},\n",
       "         'on': {'type': 'string',\n",
       "          'description': 'str, optional. For a DataFrame, a column label or Index level on which\\nto calculate the rolling window, rather than the DataFrame’s index.\\nProvided integer column is ignored and excluded from result since\\nan integer index is not used to calculate the rolling window.\\n'},\n",
       "         'axis': {'type': 'integer',\n",
       "          'description': \"int or str, default 0. If 0 or 'index', roll across the rows.\\nIf 1 or 'columns', roll across the columns.\\nFor Series this parameter is unused and defaults to 0.\\n\"},\n",
       "         'closed': {'type': 'string',\n",
       "          'description': \"str, default None. If 'right', the first point in the window is excluded from calculations.\\nIf 'left', the last point in the window is excluded from calculations.\\nIf 'both', no points in the window are excluded from calculations.\\nIf 'neither', the first and last points in the window are excluded\\nfrom calculations.\\nDefault None ('right').\\n\"},\n",
       "         'method': {'type': 'string',\n",
       "          'description': \"str {‘single’, ‘table’}, default ‘single’. Execute the rolling operation per single column or row ('single')\\nor over the entire object ('table').\\nThis argument is only implemented when specifying engine='numba'\\nin the method call.\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.sem([ddof,\\xa0numeric_only])',\n",
       "      'func_desc': 'Compute standard error of the mean of groups, excluding missing values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.sem.html#pandas.core.groupby.DataFrameGroupBy.sem',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.sem',\n",
       "       'full_function': 'DataFrameGroupBy.sem(ddof=1, numeric_only=False)',\n",
       "       'function_text': 'Compute standard error of the mean of groups, excluding missing values. For multiple groupings, the result index will be a MultiIndex.',\n",
       "       'parameter_names_desc': [{'param_name': 'ddof',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Degrees of freedom.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int or boolean data.\\n\\nNew in version 1.5.0.\\n\\n\\nChanged in version 2.0.0: numeric_only now defaults to False.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.sem',\n",
       "       'descriptions': 'Compute standard error of the mean of groups, excluding missing values. For multiple groupings, the result index will be a MultiIndex.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'ddof': {'type': 'integer',\n",
       "          'description': 'int, default 1. Degrees of freedom.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int or boolean data.\\n\\nNew in version 1.5.0.\\n\\n\\nChanged in version 2.0.0: numeric_only now defaults to False.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.size()',\n",
       "      'func_desc': 'Compute group sizes.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.size.html#pandas.core.groupby.DataFrameGroupBy.size',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.size',\n",
       "       'full_function': 'DataFrameGroupBy.size()',\n",
       "       'function_text': 'Compute group sizes.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrameGroupBy.std([ddof,\\xa0engine,\\xa0...])',\n",
       "      'func_desc': 'Compute standard deviation of groups, excluding missing values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.std.html#pandas.core.groupby.DataFrameGroupBy.std',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.std',\n",
       "       'full_function': 'DataFrameGroupBy.std(ddof=1, engine=None, engine_kwargs=None, numeric_only=False)',\n",
       "       'function_text': 'Compute standard deviation of groups, excluding missing values. For multiple groupings, the result index will be a MultiIndex.',\n",
       "       'parameter_names_desc': [{'param_name': 'ddof',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Degrees of freedom.\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': \"\\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting\\ncompute.use_numba\\n\\n\\nNew in version 1.4.0.\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{{'nopython': True, 'nogil': False, 'parallel': False}}\\n\\n\\nNew in version 1.4.0.\\n\\n\"},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int or boolean data.\\n\\nNew in version 1.5.0.\\n\\n\\nChanged in version 2.0.0: numeric_only now defaults to False.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.std',\n",
       "       'descriptions': 'Compute standard deviation of groups, excluding missing values. For multiple groupings, the result index will be a MultiIndex.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'ddof': {'type': 'integer',\n",
       "          'description': 'int, default 1. Degrees of freedom.\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None. \\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting\\ncompute.use_numba\\n\\n\\nNew in version 1.4.0.\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None',\n",
       "          'description': \"dict, default None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{{'nopython': True, 'nogil': False, 'parallel': False}}\\n\\n\\nNew in version 1.4.0.\\n\\n\"},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int or boolean data.\\n\\nNew in version 1.5.0.\\n\\n\\nChanged in version 2.0.0: numeric_only now defaults to False.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.var([ddof,\\xa0engine,\\xa0...])',\n",
       "      'func_desc': 'Compute variance of groups, excluding missing values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.var.html#pandas.core.groupby.DataFrameGroupBy.var',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.var',\n",
       "       'full_function': 'DataFrameGroupBy.var(ddof=1, engine=None, engine_kwargs=None, numeric_only=False)',\n",
       "       'function_text': 'Compute variance of groups, excluding missing values. For multiple groupings, the result index will be a MultiIndex.',\n",
       "       'parameter_names_desc': [{'param_name': 'ddof',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Degrees of freedom.\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': \"\\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting\\ncompute.use_numba\\n\\n\\nNew in version 1.4.0.\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{{'nopython': True, 'nogil': False, 'parallel': False}}\\n\\n\\nNew in version 1.4.0.\\n\\n\"},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int or boolean data.\\n\\nNew in version 1.5.0.\\n\\n\\nChanged in version 2.0.0: numeric_only now defaults to False.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.var',\n",
       "       'descriptions': 'Compute variance of groups, excluding missing values. For multiple groupings, the result index will be a MultiIndex.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'ddof': {'type': 'integer',\n",
       "          'description': 'int, default 1. Degrees of freedom.\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None. \\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting\\ncompute.use_numba\\n\\n\\nNew in version 1.4.0.\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None',\n",
       "          'description': \"dict, default None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{{'nopython': True, 'nogil': False, 'parallel': False}}\\n\\n\\nNew in version 1.4.0.\\n\\n\"},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int or boolean data.\\n\\nNew in version 1.5.0.\\n\\n\\nChanged in version 2.0.0: numeric_only now defaults to False.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.take(indices[,\\xa0axis])',\n",
       "      'func_desc': 'Return the elements in the given positional indices in each group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.take.html#pandas.core.groupby.DataFrameGroupBy.take',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.take',\n",
       "       'full_function': 'DataFrameGroupBy.take(indices, axis=_NoDefault.no_default, **kwargs)',\n",
       "       'function_text': 'Return the elements in the given positional indices in each group. This means that we are not indexing according to actual values in\\nthe index attribute of the object. We are indexing according to the\\nactual position of the element in the object. If a requested index does not exist for some group, this method will raise.\\nTo get similar behavior that ignores indices that don’t exist, see\\nDataFrameGroupBy.nth().',\n",
       "       'parameter_names_desc': [{'param_name': 'indices',\n",
       "         'param_type': 'array-like',\n",
       "         'param_desc': 'An array of ints indicating which positions to take.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’, None}, default 0',\n",
       "         'param_desc': 'The axis on which to select elements. 0 means that we are\\nselecting rows, 1 means that we are selecting columns.\\n\\nDeprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\\nthe axis keyword is not necessary.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.take',\n",
       "       'descriptions': 'Return the elements in the given positional indices in each group. This means that we are not indexing according to actual values in\\nthe index attribute of the object. We are indexing according to the\\nactual position of the element in the object. If a requested index does not exist for some group, this method will raise.\\nTo get similar behavior that ignores indices that don’t exist, see\\nDataFrameGroupBy.nth().',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'indices': {'type': 'array',\n",
       "          'description': 'array-like. An array of ints indicating which positions to take.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns', ' None'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’, None}, default 0. The axis on which to select elements. 0 means that we are\\nselecting rows, 1 means that we are selecting columns.\\n\\nDeprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\\nthe axis keyword is not necessary.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.any([skipna])',\n",
       "      'func_desc': 'Return True if any value in the group is truthful, else False.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.any.html#pandas.core.groupby.DataFrameGroupBy.any',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.any',\n",
       "       'full_function': 'DataFrameGroupBy.any(skipna=True)',\n",
       "       'function_text': 'Return True if any value in the group is truthful, else False.',\n",
       "       'parameter_names_desc': [{'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Flag to ignore nan values during truth testing.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.any',\n",
       "       'descriptions': 'Return True if any value in the group is truthful, else False.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Flag to ignore nan values during truth testing.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.corr([method,\\xa0min_periods,\\xa0...])',\n",
       "      'func_desc': 'Compute pairwise correlation of columns, excluding NA/null values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.corr.html#pandas.core.groupby.DataFrameGroupBy.corr',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.corr',\n",
       "       'full_function': \"DataFrameGroupBy.corr(method='pearson', min_periods=1, numeric_only=False)\",\n",
       "       'function_text': 'Compute pairwise correlation of columns, excluding NA/null values.',\n",
       "       'parameter_names_desc': [{'param_name': 'method',\n",
       "         'param_type': '{‘pearson’, ‘kendall’, ‘spearman’} or callable',\n",
       "         'param_desc': 'Method of correlation:\\n\\npearson : standard correlation coefficient\\nkendall : Kendall Tau correlation coefficient\\nspearman : Spearman rank correlation\\n\\ncallable: callable with input two 1d ndarraysand returning a float. Note that the returned matrix from corr\\nwill have 1 along the diagonals and will be symmetric\\nregardless of the callable’s behavior.\\n\\n\\n\\n\\n'},\n",
       "        {'param_name': 'min_periods',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Minimum number of observations required per pair of columns\\nto have a valid result. Currently only available for Pearson\\nand Spearman correlation.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int or boolean data.\\n\\nNew in version 1.5.0.\\n\\n\\nChanged in version 2.0.0: The default value of numeric_only is now False.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.corr',\n",
       "       'descriptions': 'Compute pairwise correlation of columns, excluding NA/null values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'method': {'type': 'object',\n",
       "          'description': '{‘pearson’, ‘kendall’, ‘spearman’} or callable. Method of correlation:\\n\\npearson : standard correlation coefficient\\nkendall : Kendall Tau correlation coefficient\\nspearman : Spearman rank correlation\\n\\ncallable: callable with input two 1d ndarraysand returning a float. Note that the returned matrix from corr\\nwill have 1 along the diagonals and will be symmetric\\nregardless of the callable’s behavior.\\n\\n\\n\\n\\n'},\n",
       "         'min_periods': {'type': 'integer',\n",
       "          'description': 'int, optional. Minimum number of observations required per pair of columns\\nto have a valid result. Currently only available for Pearson\\nand Spearman correlation.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int or boolean data.\\n\\nNew in version 1.5.0.\\n\\n\\nChanged in version 2.0.0: The default value of numeric_only is now False.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.count()',\n",
       "      'func_desc': 'Compute count of group, excluding missing values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.count.html#pandas.core.groupby.DataFrameGroupBy.count',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.count',\n",
       "       'full_function': 'DataFrameGroupBy.count()',\n",
       "       'function_text': 'Compute count of group, excluding missing values.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrameGroupBy.cumcount([ascending])',\n",
       "      'func_desc': 'Number each item in each group from 0 to the length of that group - 1.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cumcount.html#pandas.core.groupby.DataFrameGroupBy.cumcount',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.cumcount',\n",
       "       'full_function': 'DataFrameGroupBy.cumcount(ascending=True)',\n",
       "       'function_text': 'Number each item in each group from 0 to the length of that group - 1. Essentially this is equivalent to',\n",
       "       'parameter_names_desc': [{'param_name': 'ascending',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If False, number in reverse, from length of group - 1 to 0.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.cumcount',\n",
       "       'descriptions': 'Number each item in each group from 0 to the length of that group - 1. Essentially this is equivalent to',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'ascending': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If False, number in reverse, from length of group - 1 to 0.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.cummin([axis,\\xa0numeric_only])',\n",
       "      'func_desc': 'Cumulative min for each group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cummin.html#pandas.core.groupby.DataFrameGroupBy.cummin',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.cummin',\n",
       "       'full_function': 'DataFrameGroupBy.cummin(axis=_NoDefault.no_default, numeric_only=False, **kwargs)',\n",
       "       'function_text': 'Cumulative min for each group.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrameGroupBy.cumsum([axis])',\n",
       "      'func_desc': 'Cumulative sum for each group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cumsum.html#pandas.core.groupby.DataFrameGroupBy.cumsum',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.cumsum',\n",
       "       'full_function': 'DataFrameGroupBy.cumsum(axis=_NoDefault.no_default, *args, **kwargs)',\n",
       "       'function_text': 'Cumulative sum for each group.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrameGroupBy.diff([periods,\\xa0axis])',\n",
       "      'func_desc': 'First discrete difference of element.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.diff.html#pandas.core.groupby.DataFrameGroupBy.diff',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.diff',\n",
       "       'full_function': 'DataFrameGroupBy.diff(periods=1, axis=_NoDefault.no_default)',\n",
       "       'function_text': 'First discrete difference of element. Calculates the difference of each element compared with another\\nelement in the group (default is element in previous row).',\n",
       "       'parameter_names_desc': [{'param_name': 'periods',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Periods to shift for calculating difference, accepts negative values.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': 'axis to shift, default 0',\n",
       "         'param_desc': 'Take difference over rows (0) or columns (1).\\n\\nDeprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\\nthe axis keyword is not necessary.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.diff',\n",
       "       'descriptions': 'First discrete difference of element. Calculates the difference of each element compared with another\\nelement in the group (default is element in previous row).',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'periods': {'type': 'integer',\n",
       "          'description': 'int, default 1. Periods to shift for calculating difference, accepts negative values.\\n'},\n",
       "         'axis': {'type': 'axis to shift, default 0',\n",
       "          'description': 'axis to shift, default 0. Take difference over rows (0) or columns (1).\\n\\nDeprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\\nthe axis keyword is not necessary.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.fillna([value,\\xa0method,\\xa0...])',\n",
       "      'func_desc': '(DEPRECATED) Fill NA/NaN values using the specified method within groups.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.fillna.html#pandas.core.groupby.DataFrameGroupBy.fillna',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.fillna',\n",
       "       'full_function': 'DataFrameGroupBy.fillna(value=None, method=None, axis=_NoDefault.no_default, inplace=False, limit=None, downcast=_NoDefault.no_default)',\n",
       "       'function_text': 'Fill NA/NaN values using the specified method within groups. Deprecated since version 2.2.0: This method is deprecated and will be removed in a future version.\\nUse the DataFrameGroupBy.ffill() or DataFrameGroupBy.bfill()\\nfor forward or backward filling instead. If you want to fill with a\\nsingle value, use DataFrame.fillna() instead.',\n",
       "       'parameter_names_desc': [{'param_name': 'value',\n",
       "         'param_type': 'scalar, dict, Series, or DataFrame',\n",
       "         'param_desc': 'Value to use to fill holes (e.g. 0), alternately a\\ndict/Series/DataFrame of values specifying which value to use for\\neach index (for a Series) or column (for a DataFrame). Values not\\nin the dict/Series/DataFrame will not be filled. This value cannot\\nbe a list. Users wanting to use the value argument and not method\\nshould prefer DataFrame.fillna() as this\\nwill produce the same result and be more performant.\\n'},\n",
       "        {'param_name': 'method',\n",
       "         'param_type': '{{‘bfill’, ‘ffill’, None}}, default None',\n",
       "         'param_desc': \"Method to use for filling holes. 'ffill' will propagate\\nthe last valid observation forward within a group.\\n'bfill' will use next valid observation to fill the gap.\\n\"},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}',\n",
       "         'param_desc': 'Axis along which to fill missing values. When the DataFrameGroupBy\\naxis argument is 0, using axis=1 here will produce\\nthe same results as DataFrame.fillna(). When the\\nDataFrameGroupBy axis argument is 1, using axis=0\\nor axis=1 here will produce the same results.\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Broken. Do not set to True.\\n'},\n",
       "        {'param_name': 'limit',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'If method is specified, this is the maximum number of consecutive\\nNaN values to forward/backward fill within a group. In other words,\\nif there is a gap with more than this number of consecutive NaNs,\\nit will only be partially filled. If method is not specified, this is the\\nmaximum number of entries along the entire axis where NaNs will be\\nfilled. Must be greater than 0 if not None.\\n'},\n",
       "        {'param_name': 'downcast',\n",
       "         'param_type': 'dict, default is None',\n",
       "         'param_desc': 'A dict of item->dtype of what to downcast if possible,\\nor the string ‘infer’ which will try to downcast to an appropriate\\nequal type (e.g. float64 to int64 if possible).\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.fillna',\n",
       "       'descriptions': 'Fill NA/NaN values using the specified method within groups. Deprecated since version 2.2.0: This method is deprecated and will be removed in a future version.\\nUse the DataFrameGroupBy.ffill() or DataFrameGroupBy.bfill()\\nfor forward or backward filling instead. If you want to fill with a\\nsingle value, use DataFrame.fillna() instead.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'value': {'type': 'scalar, dict, Series, or DataFrame',\n",
       "          'description': 'scalar, dict, Series, or DataFrame. Value to use to fill holes (e.g. 0), alternately a\\ndict/Series/DataFrame of values specifying which value to use for\\neach index (for a Series) or column (for a DataFrame). Values not\\nin the dict/Series/DataFrame will not be filled. This value cannot\\nbe a list. Users wanting to use the value argument and not method\\nshould prefer DataFrame.fillna() as this\\nwill produce the same result and be more performant.\\n'},\n",
       "         'method': {'type': 'string',\n",
       "          'enum': ['{bfill', ' ffill', ' None'],\n",
       "          'description': \"{{‘bfill’, ‘ffill’, None}}, default None. Method to use for filling holes. 'ffill' will propagate\\nthe last valid observation forward within a group.\\n'bfill' will use next valid observation to fill the gap.\\n\"},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}. Axis along which to fill missing values. When the DataFrameGroupBy\\naxis argument is 0, using axis=1 here will produce\\nthe same results as DataFrame.fillna(). When the\\nDataFrameGroupBy axis argument is 1, using axis=0\\nor axis=1 here will produce the same results.\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Broken. Do not set to True.\\n'},\n",
       "         'limit': {'type': 'integer',\n",
       "          'description': 'int, default None. If method is specified, this is the maximum number of consecutive\\nNaN values to forward/backward fill within a group. In other words,\\nif there is a gap with more than this number of consecutive NaNs,\\nit will only be partially filled. If method is not specified, this is the\\nmaximum number of entries along the entire axis where NaNs will be\\nfilled. Must be greater than 0 if not None.\\n'},\n",
       "         'downcast': {'type': 'dict, default is None',\n",
       "          'description': 'dict, default is None. A dict of item->dtype of what to downcast if possible,\\nor the string ‘infer’ which will try to downcast to an appropriate\\nequal type (e.g. float64 to int64 if possible).\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.head([n])',\n",
       "      'func_desc': 'Return first n rows of each group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.head.html#pandas.core.groupby.DataFrameGroupBy.head',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.head',\n",
       "       'full_function': 'DataFrameGroupBy.head(n=5)',\n",
       "       'function_text': 'Return first n rows of each group. Similar to .apply(lambda x: x.head(n)), but it returns a subset of rows\\nfrom the original DataFrame with original index and order preserved\\n(as_index flag is ignored).',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int',\n",
       "         'param_desc': 'If positive: number of entries to include from start of each group.\\nIf negative: number of entries to exclude from end of each group.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.head',\n",
       "       'descriptions': 'Return first n rows of each group. Similar to .apply(lambda x: x.head(n)), but it returns a subset of rows\\nfrom the original DataFrame with original index and order preserved\\n(as_index flag is ignored).',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int. If positive: number of entries to include from start of each group.\\nIf negative: number of entries to exclude from end of each group.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.idxmin([axis,\\xa0skipna,\\xa0...])',\n",
       "      'func_desc': 'Return index of first occurrence of minimum over requested axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.idxmin.html#pandas.core.groupby.DataFrameGroupBy.idxmin',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.idxmin',\n",
       "       'full_function': 'DataFrameGroupBy.idxmin(axis=_NoDefault.no_default, skipna=True, numeric_only=False)',\n",
       "       'function_text': 'Return index of first occurrence of minimum over requested axis. NA/null values are excluded.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrameGroupBy.max([numeric_only,\\xa0...])',\n",
       "      'func_desc': 'Compute max of group values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.max.html#pandas.core.groupby.DataFrameGroupBy.max',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.max',\n",
       "       'full_function': 'DataFrameGroupBy.max(numeric_only=False, min_count=-1, engine=None, engine_kwargs=None)',\n",
       "       'function_text': 'Compute max of group values.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nChanged in version 2.0.0: numeric_only no longer accepts None.\\n\\n'},\n",
       "        {'param_name': 'min_count',\n",
       "         'param_type': 'int, default -1',\n",
       "         'param_desc': 'The required number of valid values to perform the operation. If fewer\\nthan min_count non-NA values are present the result will be NA.\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None None',\n",
       "         'param_desc': \"\\n'cython' : Runs rolling apply through C-extensions from cython.\\n\\n'numba'Runs rolling apply through JIT compiled code from numba.Only available when raw is set to True.\\n\\n\\n\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\n\\nFor 'numba' engine, the engine can accept nopython, nogiland parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\\napplied to both the func and the apply groupby aggregation.\\n\\n\\n\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.max',\n",
       "       'descriptions': 'Compute max of group values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nChanged in version 2.0.0: numeric_only no longer accepts None.\\n\\n'},\n",
       "         'min_count': {'type': 'integer',\n",
       "          'description': 'int, default -1. The required number of valid values to perform the operation. If fewer\\nthan min_count non-NA values are present the result will be NA.\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None None. \\n'cython' : Runs rolling apply through C-extensions from cython.\\n\\n'numba'Runs rolling apply through JIT compiled code from numba.Only available when raw is set to True.\\n\\n\\n\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None None',\n",
       "          'description': \"dict, default None None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\n\\nFor 'numba' engine, the engine can accept nopython, nogiland parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\\napplied to both the func and the apply groupby aggregation.\\n\\n\\n\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.median([numeric_only])',\n",
       "      'func_desc': 'Compute median of groups, excluding missing values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.median.html#pandas.core.groupby.DataFrameGroupBy.median',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.median',\n",
       "       'full_function': 'DataFrameGroupBy.median(numeric_only=False)',\n",
       "       'function_text': 'Compute median of groups, excluding missing values. For multiple groupings, the result index will be a MultiIndex',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nChanged in version 2.0.0: numeric_only no longer accepts None and defaults to False.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.median',\n",
       "       'descriptions': 'Compute median of groups, excluding missing values. For multiple groupings, the result index will be a MultiIndex',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nChanged in version 2.0.0: numeric_only no longer accepts None and defaults to False.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.ngroup([ascending])',\n",
       "      'func_desc': 'Number each group from 0 to the number of groups - 1.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.ngroup.html#pandas.core.groupby.DataFrameGroupBy.ngroup',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.ngroup',\n",
       "       'full_function': 'DataFrameGroupBy.ngroup(ascending=True)',\n",
       "       'function_text': 'Number each group from 0 to the number of groups - 1. This is the enumerative complement of cumcount. Note that the\\nnumbers given to the groups match the order in which the groups\\nwould be seen when iterating over the groupby object, not the\\norder they are first observed. Groups with missing keys (where pd.isna() is True) will be labeled with NaN\\nand will be skipped from the count.',\n",
       "       'parameter_names_desc': [{'param_name': 'ascending',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If False, number in reverse, from number of group - 1 to 0.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.ngroup',\n",
       "       'descriptions': 'Number each group from 0 to the number of groups - 1. This is the enumerative complement of cumcount. Note that the\\nnumbers given to the groups match the order in which the groups\\nwould be seen when iterating over the groupby object, not the\\norder they are first observed. Groups with missing keys (where pd.isna() is True) will be labeled with NaN\\nand will be skipped from the count.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'ascending': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If False, number in reverse, from number of group - 1 to 0.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.nunique([dropna])',\n",
       "      'func_desc': 'Return DataFrame with counts of unique elements in each position.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.nunique.html#pandas.core.groupby.DataFrameGroupBy.nunique',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.nunique',\n",
       "       'full_function': 'DataFrameGroupBy.nunique(dropna=True)',\n",
       "       'function_text': 'Return DataFrame with counts of unique elements in each position.',\n",
       "       'parameter_names_desc': [{'param_name': 'dropna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Don’t include NaN in the counts.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.nunique',\n",
       "       'descriptions': 'Return DataFrame with counts of unique elements in each position.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'dropna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Don’t include NaN in the counts.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.pct_change([periods,\\xa0...])',\n",
       "      'func_desc': 'Calculate pct_change of each value to previous entry in group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.pct_change.html#pandas.core.groupby.DataFrameGroupBy.pct_change',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.pct_change',\n",
       "       'full_function': 'DataFrameGroupBy.pct_change(periods=1, fill_method=_NoDefault.no_default, limit=_NoDefault.no_default, freq=None, axis=_NoDefault.no_default)',\n",
       "       'function_text': 'Calculate pct_change of each value to previous entry in group.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'DataFrameGroupBy.quantile([q,\\xa0...])',\n",
       "      'func_desc': 'Return group values at the given quantile, a la numpy.percentile.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.quantile.html#pandas.core.groupby.DataFrameGroupBy.quantile',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.quantile',\n",
       "       'full_function': \"DataFrameGroupBy.quantile(q=0.5, interpolation='linear', numeric_only=False)\",\n",
       "       'function_text': 'Return group values at the given quantile, a la numpy.percentile.',\n",
       "       'parameter_names_desc': [{'param_name': 'q',\n",
       "         'param_type': 'float or array-like, default 0.5 (50% quantile)',\n",
       "         'param_desc': 'Value(s) between 0 and 1 providing the quantile(s) to compute.\\n'},\n",
       "        {'param_name': 'interpolation',\n",
       "         'param_type': '{‘linear’, ‘lower’, ‘higher’, ‘midpoint’, ‘nearest’}',\n",
       "         'param_desc': 'Method to use when the desired quantile falls between two points.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int or boolean data.\\n\\nNew in version 1.5.0.\\n\\n\\nChanged in version 2.0.0: numeric_only now defaults to False.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.quantile',\n",
       "       'descriptions': 'Return group values at the given quantile, a la numpy.percentile.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'q': {'type': 'float',\n",
       "          'description': 'float or array-like, default 0.5 (50% quantile). Value(s) between 0 and 1 providing the quantile(s) to compute.\\n'},\n",
       "         'interpolation': {'type': 'integer',\n",
       "          'description': '{‘linear’, ‘lower’, ‘higher’, ‘midpoint’, ‘nearest’}. Method to use when the desired quantile falls between two points.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int or boolean data.\\n\\nNew in version 1.5.0.\\n\\n\\nChanged in version 2.0.0: numeric_only now defaults to False.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.resample(rule,\\xa0*args[,\\xa0...])',\n",
       "      'func_desc': 'Provide resampling when using a TimeGrouper.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.resample.html#pandas.core.groupby.DataFrameGroupBy.resample',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.resample',\n",
       "       'full_function': 'DataFrameGroupBy.resample(rule, *args, include_groups=True, **kwargs)',\n",
       "       'function_text': 'Provide resampling when using a TimeGrouper. Given a grouper, the function resamples it according to a string\\n“string” -> “frequency”. See the frequency aliases\\ndocumentation for more details.',\n",
       "       'parameter_names_desc': [{'param_name': 'rule',\n",
       "         'param_type': 'str or DateOffset',\n",
       "         'param_desc': 'The offset string or object representing target grouper conversion.\\n'},\n",
       "        {'param_name': 'include_groups',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'When True, will attempt to include the groupings in the operation in\\nthe case that they are columns of the DataFrame. If this raises a\\nTypeError, the result will be computed with the groupings excluded.\\nWhen False, the groupings will be excluded when applying func.\\n\\nNew in version 2.2.0.\\n\\n\\nDeprecated since version 2.2.0: Setting include_groups to True is deprecated. Only the value\\nFalse will be allowed in a future version of pandas.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.resample',\n",
       "       'descriptions': 'Provide resampling when using a TimeGrouper. Given a grouper, the function resamples it according to a string\\n“string” -> “frequency”. See the frequency aliases\\ndocumentation for more details.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'rule': {'type': 'string',\n",
       "          'description': 'str or DateOffset. The offset string or object representing target grouper conversion.\\n'},\n",
       "         'include_groups': {'type': 'boolean',\n",
       "          'description': 'bool, default True. When True, will attempt to include the groupings in the operation in\\nthe case that they are columns of the DataFrame. If this raises a\\nTypeError, the result will be computed with the groupings excluded.\\nWhen False, the groupings will be excluded when applying func.\\n\\nNew in version 2.2.0.\\n\\n\\nDeprecated since version 2.2.0: Setting include_groups to True is deprecated. Only the value\\nFalse will be allowed in a future version of pandas.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.sample([n,\\xa0frac,\\xa0replace,\\xa0...])',\n",
       "      'func_desc': 'Return a random sample of items from each group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.sample.html#pandas.core.groupby.DataFrameGroupBy.sample',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.sample',\n",
       "       'full_function': 'DataFrameGroupBy.sample(n=None, frac=None, replace=False, weights=None, random_state=None)',\n",
       "       'function_text': 'Return a random sample of items from each group. You can use random_state for reproducibility.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Number of items to return for each group. Cannot be used with\\nfrac and must be no larger than the smallest group unless\\nreplace is True. Default is one if frac is None.\\n'},\n",
       "        {'param_name': 'frac',\n",
       "         'param_type': 'float, optional',\n",
       "         'param_desc': 'Fraction of items to return. Cannot be used with n.\\n'},\n",
       "        {'param_name': 'replace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Allow or disallow sampling of the same row more than once.\\n'},\n",
       "        {'param_name': 'weights',\n",
       "         'param_type': 'list-like, optional',\n",
       "         'param_desc': 'Default None results in equal probability weighting.\\nIf passed a list-like then values must have the same length as\\nthe underlying DataFrame or Series object and will be used as\\nsampling probabilities after normalization within each group.\\nValues must be non-negative with at least one positive element\\nwithin each group.\\n'},\n",
       "        {'param_name': 'random_state',\n",
       "         'param_type': 'int, array-like, BitGenerator, np.random.RandomState, np.random.Generator, optional',\n",
       "         'param_desc': 'If int, array-like, or BitGenerator, seed for random number generator.\\nIf np.random.RandomState or np.random.Generator, use as given.\\n\\nChanged in version 1.4.0: np.random.Generator objects now accepted\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.sample',\n",
       "       'descriptions': 'Return a random sample of items from each group. You can use random_state for reproducibility.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, optional. Number of items to return for each group. Cannot be used with\\nfrac and must be no larger than the smallest group unless\\nreplace is True. Default is one if frac is None.\\n'},\n",
       "         'frac': {'type': 'float',\n",
       "          'description': 'float, optional. Fraction of items to return. Cannot be used with n.\\n'},\n",
       "         'replace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Allow or disallow sampling of the same row more than once.\\n'},\n",
       "         'weights': {'type': 'array',\n",
       "          'description': 'list-like, optional. Default None results in equal probability weighting.\\nIf passed a list-like then values must have the same length as\\nthe underlying DataFrame or Series object and will be used as\\nsampling probabilities after normalization within each group.\\nValues must be non-negative with at least one positive element\\nwithin each group.\\n'},\n",
       "         'random_state': {'type': 'integer',\n",
       "          'description': 'int, array-like, BitGenerator, np.random.RandomState, np.random.Generator, optional. If int, array-like, or BitGenerator, seed for random number generator.\\nIf np.random.RandomState or np.random.Generator, use as given.\\n\\nChanged in version 1.4.0: np.random.Generator objects now accepted\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.shift([periods,\\xa0freq,\\xa0...])',\n",
       "      'func_desc': 'Shift each group by periods observations.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.shift.html#pandas.core.groupby.DataFrameGroupBy.shift',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.shift',\n",
       "       'full_function': 'DataFrameGroupBy.shift(periods=1, freq=None, axis=_NoDefault.no_default, fill_value=_NoDefault.no_default, suffix=None)',\n",
       "       'function_text': 'Shift each group by periods observations. If freq is passed, the index will be increased using the periods and the freq.',\n",
       "       'parameter_names_desc': [{'param_name': 'periods',\n",
       "         'param_type': 'int | Sequence[int], default 1',\n",
       "         'param_desc': 'Number of periods to shift. If a list of values, shift each group by\\neach period.\\n'},\n",
       "        {'param_name': 'freq',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Frequency string.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': 'axis to shift, default 0',\n",
       "         'param_desc': 'Shift direction.\\n\\nDeprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\\nthe axis keyword is not necessary.\\n\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'optional',\n",
       "         'param_desc': 'The scalar value to use for newly introduced missing values.\\n\\nChanged in version 2.1.0: Will raise a ValueError if freq is provided too.\\n\\n'},\n",
       "        {'param_name': 'suffix',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'A string to add to each shifted column if there are multiple periods.\\nIgnored otherwise.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.shift',\n",
       "       'descriptions': 'Shift each group by periods observations. If freq is passed, the index will be increased using the periods and the freq.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'periods': {'type': 'integer',\n",
       "          'description': 'int | Sequence[int], default 1. Number of periods to shift. If a list of values, shift each group by\\neach period.\\n'},\n",
       "         'freq': {'type': 'string',\n",
       "          'description': 'str, optional. Frequency string.\\n'},\n",
       "         'axis': {'type': 'axis to shift, default 0',\n",
       "          'description': 'axis to shift, default 0. Shift direction.\\n\\nDeprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\\nthe axis keyword is not necessary.\\n\\n'},\n",
       "         'fill_value': {'type': 'optional',\n",
       "          'description': 'optional. The scalar value to use for newly introduced missing values.\\n\\nChanged in version 2.1.0: Will raise a ValueError if freq is provided too.\\n\\n'},\n",
       "         'suffix': {'type': 'string',\n",
       "          'description': 'str, optional. A string to add to each shifted column if there are multiple periods.\\nIgnored otherwise.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.skew([axis,\\xa0skipna,\\xa0...])',\n",
       "      'func_desc': 'Return unbiased skew within groups.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.skew.html#pandas.core.groupby.DataFrameGroupBy.skew',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.skew',\n",
       "       'full_function': 'DataFrameGroupBy.skew(axis=_NoDefault.no_default, skipna=True, numeric_only=False, **kwargs)',\n",
       "       'function_text': 'Return unbiased skew within groups. Normalized by N-1.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’, None}, default 0',\n",
       "         'param_desc': 'Axis for the function to be applied on.\\nSpecifying axis=None will apply the aggregation across both axes.\\n\\nNew in version 2.0.0.\\n\\n\\nDeprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\\nthe axis keyword is not necessary.\\n\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values when computing the result.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.skew',\n",
       "       'descriptions': 'Return unbiased skew within groups. Normalized by N-1.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns', ' None'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’, None}, default 0. Axis for the function to be applied on.\\nSpecifying axis=None will apply the aggregation across both axes.\\n\\nNew in version 2.0.0.\\n\\n\\nDeprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\\nthe axis keyword is not necessary.\\n\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values when computing the result.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.sum([numeric_only,\\xa0...])',\n",
       "      'func_desc': 'Compute sum of group values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.sum.html#pandas.core.groupby.DataFrameGroupBy.sum',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.sum',\n",
       "       'full_function': 'DataFrameGroupBy.sum(numeric_only=False, min_count=0, engine=None, engine_kwargs=None)',\n",
       "       'function_text': 'Compute sum of group values.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nChanged in version 2.0.0: numeric_only no longer accepts None.\\n\\n'},\n",
       "        {'param_name': 'min_count',\n",
       "         'param_type': 'int, default 0',\n",
       "         'param_desc': 'The required number of valid values to perform the operation. If fewer\\nthan min_count non-NA values are present the result will be NA.\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None None',\n",
       "         'param_desc': \"\\n'cython' : Runs rolling apply through C-extensions from cython.\\n\\n'numba'Runs rolling apply through JIT compiled code from numba.Only available when raw is set to True.\\n\\n\\n\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\n\\nFor 'numba' engine, the engine can accept nopython, nogiland parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\\napplied to both the func and the apply groupby aggregation.\\n\\n\\n\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.sum',\n",
       "       'descriptions': 'Compute sum of group values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nChanged in version 2.0.0: numeric_only no longer accepts None.\\n\\n'},\n",
       "         'min_count': {'type': 'integer',\n",
       "          'description': 'int, default 0. The required number of valid values to perform the operation. If fewer\\nthan min_count non-NA values are present the result will be NA.\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None None. \\n'cython' : Runs rolling apply through C-extensions from cython.\\n\\n'numba'Runs rolling apply through JIT compiled code from numba.Only available when raw is set to True.\\n\\n\\n\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None None',\n",
       "          'description': \"dict, default None None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\n\\nFor 'numba' engine, the engine can accept nopython, nogiland parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\\napplied to both the func and the apply groupby aggregation.\\n\\n\\n\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.tail([n])',\n",
       "      'func_desc': 'Return last n rows of each group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.tail.html#pandas.core.groupby.DataFrameGroupBy.tail',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.tail',\n",
       "       'full_function': 'DataFrameGroupBy.tail(n=5)',\n",
       "       'function_text': 'Return last n rows of each group. Similar to .apply(lambda x: x.tail(n)), but it returns a subset of rows\\nfrom the original DataFrame with original index and order preserved\\n(as_index flag is ignored).',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int',\n",
       "         'param_desc': 'If positive: number of entries to include from end of each group.\\nIf negative: number of entries to exclude from start of each group.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.tail',\n",
       "       'descriptions': 'Return last n rows of each group. Similar to .apply(lambda x: x.tail(n)), but it returns a subset of rows\\nfrom the original DataFrame with original index and order preserved\\n(as_index flag is ignored).',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int. If positive: number of entries to include from end of each group.\\nIf negative: number of entries to exclude from start of each group.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.value_counts([subset,\\xa0...])',\n",
       "      'func_desc': 'Return a Series or DataFrame containing counts of unique rows.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.value_counts.html#pandas.core.groupby.DataFrameGroupBy.value_counts',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.value_counts',\n",
       "       'full_function': 'DataFrameGroupBy.value_counts(subset=None, normalize=False, sort=True, ascending=False, dropna=True)',\n",
       "       'function_text': 'Return a Series or DataFrame containing counts of unique rows. New in version 1.4.0.',\n",
       "       'parameter_names_desc': [{'param_name': 'subset',\n",
       "         'param_type': 'list-like, optional',\n",
       "         'param_desc': 'Columns to use when counting unique combinations.\\n'},\n",
       "        {'param_name': 'normalize',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Return proportions rather than frequencies.\\n'},\n",
       "        {'param_name': 'sort',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Sort by frequencies.\\n'},\n",
       "        {'param_name': 'ascending',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Sort in ascending order.\\n'},\n",
       "        {'param_name': 'dropna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Don’t include counts of rows that contain NA values.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.value_counts',\n",
       "       'descriptions': 'Return a Series or DataFrame containing counts of unique rows. New in version 1.4.0.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'subset': {'type': 'array',\n",
       "          'description': 'list-like, optional. Columns to use when counting unique combinations.\\n'},\n",
       "         'normalize': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Return proportions rather than frequencies.\\n'},\n",
       "         'sort': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Sort by frequencies.\\n'},\n",
       "         'ascending': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Sort in ascending order.\\n'},\n",
       "         'dropna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Don’t include counts of rows that contain NA values.\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'SeriesGroupBy computations / descriptive stats': [{'func_name': 'SeriesGroupBy.all([skipna])',\n",
       "      'func_desc': 'Return True if all values in the group are truthful, else False.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.all.html#pandas.core.groupby.SeriesGroupBy.all',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.all',\n",
       "       'full_function': 'SeriesGroupBy.all(skipna=True)',\n",
       "       'function_text': 'Return True if all values in the group are truthful, else False.',\n",
       "       'parameter_names_desc': [{'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Flag to ignore nan values during truth testing.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.all',\n",
       "       'descriptions': 'Return True if all values in the group are truthful, else False.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Flag to ignore nan values during truth testing.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.bfill([limit])',\n",
       "      'func_desc': 'Backward fill the values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.bfill.html#pandas.core.groupby.SeriesGroupBy.bfill',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.bfill',\n",
       "       'full_function': 'SeriesGroupBy.bfill(limit=None)',\n",
       "       'function_text': 'Backward fill the values.',\n",
       "       'parameter_names_desc': [{'param_name': 'limit',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Limit of how many values to fill.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.bfill',\n",
       "       'descriptions': 'Backward fill the values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'limit': {'type': 'integer',\n",
       "          'description': 'int, optional. Limit of how many values to fill.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.count()',\n",
       "      'func_desc': 'Compute count of group, excluding missing values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.count.html#pandas.core.groupby.SeriesGroupBy.count',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.count',\n",
       "       'full_function': 'SeriesGroupBy.count()',\n",
       "       'function_text': 'Compute count of group, excluding missing values.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SeriesGroupBy.cumcount([ascending])',\n",
       "      'func_desc': 'Number each item in each group from 0 to the length of that group - 1.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cumcount.html#pandas.core.groupby.SeriesGroupBy.cumcount',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.cumcount',\n",
       "       'full_function': 'SeriesGroupBy.cumcount(ascending=True)',\n",
       "       'function_text': 'Number each item in each group from 0 to the length of that group - 1. Essentially this is equivalent to',\n",
       "       'parameter_names_desc': [{'param_name': 'ascending',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If False, number in reverse, from length of group - 1 to 0.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.cumcount',\n",
       "       'descriptions': 'Number each item in each group from 0 to the length of that group - 1. Essentially this is equivalent to',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'ascending': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If False, number in reverse, from length of group - 1 to 0.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.cummin([axis,\\xa0numeric_only])',\n",
       "      'func_desc': 'Cumulative min for each group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cummin.html#pandas.core.groupby.SeriesGroupBy.cummin',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.cummin',\n",
       "       'full_function': 'SeriesGroupBy.cummin(axis=_NoDefault.no_default, numeric_only=False, **kwargs)',\n",
       "       'function_text': 'Cumulative min for each group.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SeriesGroupBy.cumsum([axis])',\n",
       "      'func_desc': 'Cumulative sum for each group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cumsum.html#pandas.core.groupby.SeriesGroupBy.cumsum',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.cumsum',\n",
       "       'full_function': 'SeriesGroupBy.cumsum(axis=_NoDefault.no_default, *args, **kwargs)',\n",
       "       'function_text': 'Cumulative sum for each group.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SeriesGroupBy.diff([periods,\\xa0axis])',\n",
       "      'func_desc': 'First discrete difference of element.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.diff.html#pandas.core.groupby.SeriesGroupBy.diff',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.diff',\n",
       "       'full_function': 'SeriesGroupBy.diff(periods=1, axis=_NoDefault.no_default)',\n",
       "       'function_text': 'First discrete difference of element. Calculates the difference of each element compared with another\\nelement in the group (default is element in previous row).',\n",
       "       'parameter_names_desc': [{'param_name': 'periods',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Periods to shift for calculating difference, accepts negative values.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': 'axis to shift, default 0',\n",
       "         'param_desc': 'Take difference over rows (0) or columns (1).\\n\\nDeprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\\nthe axis keyword is not necessary.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.diff',\n",
       "       'descriptions': 'First discrete difference of element. Calculates the difference of each element compared with another\\nelement in the group (default is element in previous row).',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'periods': {'type': 'integer',\n",
       "          'description': 'int, default 1. Periods to shift for calculating difference, accepts negative values.\\n'},\n",
       "         'axis': {'type': 'axis to shift, default 0',\n",
       "          'description': 'axis to shift, default 0. Take difference over rows (0) or columns (1).\\n\\nDeprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\\nthe axis keyword is not necessary.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.fillna([value,\\xa0method,\\xa0axis,\\xa0...])',\n",
       "      'func_desc': '(DEPRECATED) Fill NA/NaN values using the specified method within groups.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.fillna.html#pandas.core.groupby.SeriesGroupBy.fillna',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.fillna',\n",
       "       'full_function': 'SeriesGroupBy.fillna(value=None, method=None, axis=_NoDefault.no_default, inplace=False, limit=None, downcast=_NoDefault.no_default)',\n",
       "       'function_text': 'Fill NA/NaN values using the specified method within groups. Deprecated since version 2.2.0: This method is deprecated and will be removed in a future version.\\nUse the SeriesGroupBy.ffill() or SeriesGroupBy.bfill()\\nfor forward or backward filling instead. If you want to fill with a\\nsingle value, use Series.fillna() instead.',\n",
       "       'parameter_names_desc': [{'param_name': 'value',\n",
       "         'param_type': 'scalar, dict, Series, or DataFrame',\n",
       "         'param_desc': 'Value to use to fill holes (e.g. 0), alternately a\\ndict/Series/DataFrame of values specifying which value to use for\\neach index (for a Series) or column (for a DataFrame). Values not\\nin the dict/Series/DataFrame will not be filled. This value cannot\\nbe a list. Users wanting to use the value argument and not method\\nshould prefer Series.fillna() as this\\nwill produce the same result and be more performant.\\n'},\n",
       "        {'param_name': 'method',\n",
       "         'param_type': '{{‘bfill’, ‘ffill’, None}}, default None',\n",
       "         'param_desc': \"Method to use for filling holes. 'ffill' will propagate\\nthe last valid observation forward within a group.\\n'bfill' will use next valid observation to fill the gap.\\n\"},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}',\n",
       "         'param_desc': 'Unused, only for compatibility with DataFrameGroupBy.fillna().\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Broken. Do not set to True.\\n'},\n",
       "        {'param_name': 'limit',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'If method is specified, this is the maximum number of consecutive\\nNaN values to forward/backward fill within a group. In other words,\\nif there is a gap with more than this number of consecutive NaNs,\\nit will only be partially filled. If method is not specified, this is the\\nmaximum number of entries along the entire axis where NaNs will be\\nfilled. Must be greater than 0 if not None.\\n'},\n",
       "        {'param_name': 'downcast',\n",
       "         'param_type': 'dict, default is None',\n",
       "         'param_desc': 'A dict of item->dtype of what to downcast if possible,\\nor the string ‘infer’ which will try to downcast to an appropriate\\nequal type (e.g. float64 to int64 if possible).\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.fillna',\n",
       "       'descriptions': 'Fill NA/NaN values using the specified method within groups. Deprecated since version 2.2.0: This method is deprecated and will be removed in a future version.\\nUse the SeriesGroupBy.ffill() or SeriesGroupBy.bfill()\\nfor forward or backward filling instead. If you want to fill with a\\nsingle value, use Series.fillna() instead.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'value': {'type': 'scalar, dict, Series, or DataFrame',\n",
       "          'description': 'scalar, dict, Series, or DataFrame. Value to use to fill holes (e.g. 0), alternately a\\ndict/Series/DataFrame of values specifying which value to use for\\neach index (for a Series) or column (for a DataFrame). Values not\\nin the dict/Series/DataFrame will not be filled. This value cannot\\nbe a list. Users wanting to use the value argument and not method\\nshould prefer Series.fillna() as this\\nwill produce the same result and be more performant.\\n'},\n",
       "         'method': {'type': 'string',\n",
       "          'enum': ['{bfill', ' ffill', ' None'],\n",
       "          'description': \"{{‘bfill’, ‘ffill’, None}}, default None. Method to use for filling holes. 'ffill' will propagate\\nthe last valid observation forward within a group.\\n'bfill' will use next valid observation to fill the gap.\\n\"},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}. Unused, only for compatibility with DataFrameGroupBy.fillna().\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Broken. Do not set to True.\\n'},\n",
       "         'limit': {'type': 'integer',\n",
       "          'description': 'int, default None. If method is specified, this is the maximum number of consecutive\\nNaN values to forward/backward fill within a group. In other words,\\nif there is a gap with more than this number of consecutive NaNs,\\nit will only be partially filled. If method is not specified, this is the\\nmaximum number of entries along the entire axis where NaNs will be\\nfilled. Must be greater than 0 if not None.\\n'},\n",
       "         'downcast': {'type': 'dict, default is None',\n",
       "          'description': 'dict, default is None. A dict of item->dtype of what to downcast if possible,\\nor the string ‘infer’ which will try to downcast to an appropriate\\nequal type (e.g. float64 to int64 if possible).\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.head([n])',\n",
       "      'func_desc': 'Return first n rows of each group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.head.html#pandas.core.groupby.SeriesGroupBy.head',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.head',\n",
       "       'full_function': 'SeriesGroupBy.head(n=5)',\n",
       "       'function_text': 'Return first n rows of each group. Similar to .apply(lambda x: x.head(n)), but it returns a subset of rows\\nfrom the original DataFrame with original index and order preserved\\n(as_index flag is ignored).',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int',\n",
       "         'param_desc': 'If positive: number of entries to include from start of each group.\\nIf negative: number of entries to exclude from end of each group.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.head',\n",
       "       'descriptions': 'Return first n rows of each group. Similar to .apply(lambda x: x.head(n)), but it returns a subset of rows\\nfrom the original DataFrame with original index and order preserved\\n(as_index flag is ignored).',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int. If positive: number of entries to include from start of each group.\\nIf negative: number of entries to exclude from end of each group.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.idxmax([axis,\\xa0skipna])',\n",
       "      'func_desc': 'Return the row label of the maximum value.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.idxmax.html#pandas.core.groupby.SeriesGroupBy.idxmax',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.idxmax',\n",
       "       'full_function': 'SeriesGroupBy.idxmax(axis=_NoDefault.no_default, skipna=True)',\n",
       "       'function_text': 'Return the row label of the maximum value. If multiple values equal the maximum, the first row label with that\\nvalue is returned.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SeriesGroupBy.is_monotonic_increasing',\n",
       "      'func_desc': \"Return whether each group's values are monotonically increasing.\",\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.is_monotonic_increasing.html#pandas.core.groupby.SeriesGroupBy.is_monotonic_increasing',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.is_monotonic_increasing',\n",
       "       'full_function': 'property SeriesGroupBy.is_monotonic_increasing',\n",
       "       'function_text': 'Return whether each group’s values are monotonically increasing.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SeriesGroupBy.max([numeric_only,\\xa0min_count,\\xa0...])',\n",
       "      'func_desc': 'Compute max of group values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.max.html#pandas.core.groupby.SeriesGroupBy.max',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.max',\n",
       "       'full_function': 'SeriesGroupBy.max(numeric_only=False, min_count=-1, engine=None, engine_kwargs=None)',\n",
       "       'function_text': 'Compute max of group values.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nChanged in version 2.0.0: numeric_only no longer accepts None.\\n\\n'},\n",
       "        {'param_name': 'min_count',\n",
       "         'param_type': 'int, default -1',\n",
       "         'param_desc': 'The required number of valid values to perform the operation. If fewer\\nthan min_count non-NA values are present the result will be NA.\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None None',\n",
       "         'param_desc': \"\\n'cython' : Runs rolling apply through C-extensions from cython.\\n\\n'numba'Runs rolling apply through JIT compiled code from numba.Only available when raw is set to True.\\n\\n\\n\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\n\\nFor 'numba' engine, the engine can accept nopython, nogiland parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\\napplied to both the func and the apply groupby aggregation.\\n\\n\\n\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.max',\n",
       "       'descriptions': 'Compute max of group values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nChanged in version 2.0.0: numeric_only no longer accepts None.\\n\\n'},\n",
       "         'min_count': {'type': 'integer',\n",
       "          'description': 'int, default -1. The required number of valid values to perform the operation. If fewer\\nthan min_count non-NA values are present the result will be NA.\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None None. \\n'cython' : Runs rolling apply through C-extensions from cython.\\n\\n'numba'Runs rolling apply through JIT compiled code from numba.Only available when raw is set to True.\\n\\n\\n\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None None',\n",
       "          'description': \"dict, default None None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\n\\nFor 'numba' engine, the engine can accept nopython, nogiland parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\\napplied to both the func and the apply groupby aggregation.\\n\\n\\n\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.median([numeric_only])',\n",
       "      'func_desc': 'Compute median of groups, excluding missing values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.median.html#pandas.core.groupby.SeriesGroupBy.median',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.median',\n",
       "       'full_function': 'SeriesGroupBy.median(numeric_only=False)',\n",
       "       'function_text': 'Compute median of groups, excluding missing values. For multiple groupings, the result index will be a MultiIndex',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nChanged in version 2.0.0: numeric_only no longer accepts None and defaults to False.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.median',\n",
       "       'descriptions': 'Compute median of groups, excluding missing values. For multiple groupings, the result index will be a MultiIndex',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nChanged in version 2.0.0: numeric_only no longer accepts None and defaults to False.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.ngroup([ascending])',\n",
       "      'func_desc': 'Number each group from 0 to the number of groups - 1.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.ngroup.html#pandas.core.groupby.SeriesGroupBy.ngroup',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.ngroup',\n",
       "       'full_function': 'SeriesGroupBy.ngroup(ascending=True)',\n",
       "       'function_text': 'Number each group from 0 to the number of groups - 1. This is the enumerative complement of cumcount. Note that the\\nnumbers given to the groups match the order in which the groups\\nwould be seen when iterating over the groupby object, not the\\norder they are first observed. Groups with missing keys (where pd.isna() is True) will be labeled with NaN\\nand will be skipped from the count.',\n",
       "       'parameter_names_desc': [{'param_name': 'ascending',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If False, number in reverse, from number of group - 1 to 0.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.ngroup',\n",
       "       'descriptions': 'Number each group from 0 to the number of groups - 1. This is the enumerative complement of cumcount. Note that the\\nnumbers given to the groups match the order in which the groups\\nwould be seen when iterating over the groupby object, not the\\norder they are first observed. Groups with missing keys (where pd.isna() is True) will be labeled with NaN\\nand will be skipped from the count.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'ascending': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If False, number in reverse, from number of group - 1 to 0.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.nsmallest([n,\\xa0keep])',\n",
       "      'func_desc': 'Return the smallest n elements.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.nsmallest.html#pandas.core.groupby.SeriesGroupBy.nsmallest',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.nsmallest',\n",
       "       'full_function': \"SeriesGroupBy.nsmallest(n=5, keep='first')\",\n",
       "       'function_text': 'Return the smallest n elements.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 5',\n",
       "         'param_desc': 'Return this many ascending sorted values.\\n'},\n",
       "        {'param_name': 'keep',\n",
       "         'param_type': '{‘first’, ‘last’, ‘all’}, default ‘first’',\n",
       "         'param_desc': 'When there are duplicate values that cannot all fit in a\\nSeries of n elements:\\n\\nfirst : return the first n occurrences in order\\nof appearance.\\nlast : return the last n occurrences in reverse\\norder of appearance.\\nall : keep all occurrences. This can result in a Series of\\nsize larger than n.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.nsmallest',\n",
       "       'descriptions': 'Return the smallest n elements.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 5. Return this many ascending sorted values.\\n'},\n",
       "         'keep': {'type': 'string',\n",
       "          'enum': ['first', ' last', ' all'],\n",
       "          'description': '{‘first’, ‘last’, ‘all’}, default ‘first’. When there are duplicate values that cannot all fit in a\\nSeries of n elements:\\n\\nfirst : return the first n occurrences in order\\nof appearance.\\nlast : return the last n occurrences in reverse\\norder of appearance.\\nall : keep all occurrences. This can result in a Series of\\nsize larger than n.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.nunique([dropna])',\n",
       "      'func_desc': 'Return number of unique elements in the group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.nunique.html#pandas.core.groupby.SeriesGroupBy.nunique',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.nunique',\n",
       "       'full_function': 'SeriesGroupBy.nunique(dropna=True)',\n",
       "       'function_text': 'Return number of unique elements in the group.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SeriesGroupBy.ohlc()',\n",
       "      'func_desc': 'Compute open, high, low and close values of a group, excluding missing values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.ohlc.html#pandas.core.groupby.SeriesGroupBy.ohlc',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.ohlc',\n",
       "       'full_function': 'SeriesGroupBy.ohlc()',\n",
       "       'function_text': 'Compute open, high, low and close values of a group, excluding missing values. For multiple groupings, the result index will be a MultiIndex',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SeriesGroupBy.prod([numeric_only,\\xa0min_count])',\n",
       "      'func_desc': 'Compute prod of group values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.prod.html#pandas.core.groupby.SeriesGroupBy.prod',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.prod',\n",
       "       'full_function': 'SeriesGroupBy.prod(numeric_only=False, min_count=0)',\n",
       "       'function_text': 'Compute prod of group values.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nChanged in version 2.0.0: numeric_only no longer accepts None.\\n\\n'},\n",
       "        {'param_name': 'min_count',\n",
       "         'param_type': 'int, default 0',\n",
       "         'param_desc': 'The required number of valid values to perform the operation. If fewer\\nthan min_count non-NA values are present the result will be NA.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.prod',\n",
       "       'descriptions': 'Compute prod of group values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nChanged in version 2.0.0: numeric_only no longer accepts None.\\n\\n'},\n",
       "         'min_count': {'type': 'integer',\n",
       "          'description': 'int, default 0. The required number of valid values to perform the operation. If fewer\\nthan min_count non-NA values are present the result will be NA.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.rank([method,\\xa0ascending,\\xa0...])',\n",
       "      'func_desc': 'Provide the rank of values within each group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.rank.html#pandas.core.groupby.SeriesGroupBy.rank',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.rank',\n",
       "       'full_function': \"SeriesGroupBy.rank(method='average', ascending=True, na_option='keep', pct=False, axis=_NoDefault.no_default)\",\n",
       "       'function_text': 'Provide the rank of values within each group.',\n",
       "       'parameter_names_desc': [{'param_name': 'method',\n",
       "         'param_type': '{‘average’, ‘min’, ‘max’, ‘first’, ‘dense’}, default ‘average’',\n",
       "         'param_desc': '\\naverage: average rank of group.\\nmin: lowest rank in group.\\nmax: highest rank in group.\\nfirst: ranks assigned in order they appear in the array.\\ndense: like ‘min’, but rank always increases by 1 between groups.\\n\\n'},\n",
       "        {'param_name': 'ascending',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'False for ranks by high (1) to low (N).\\n'},\n",
       "        {'param_name': 'na_option',\n",
       "         'param_type': '{‘keep’, ‘top’, ‘bottom’}, default ‘keep’',\n",
       "         'param_desc': '\\nkeep: leave NA values where they are.\\ntop: smallest rank if ascending.\\nbottom: smallest rank if descending.\\n\\n'},\n",
       "        {'param_name': 'pct',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Compute percentage rank of data within each group.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': 'int, default 0',\n",
       "         'param_desc': 'The axis of the object over which to compute the rank.\\n\\nDeprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\\nthe axis keyword is not necessary.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.rank',\n",
       "       'descriptions': 'Provide the rank of values within each group.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'method': {'type': 'string',\n",
       "          'enum': ['average', ' min', ' max', ' first', ' dense'],\n",
       "          'description': '{‘average’, ‘min’, ‘max’, ‘first’, ‘dense’}, default ‘average’. \\naverage: average rank of group.\\nmin: lowest rank in group.\\nmax: highest rank in group.\\nfirst: ranks assigned in order they appear in the array.\\ndense: like ‘min’, but rank always increases by 1 between groups.\\n\\n'},\n",
       "         'ascending': {'type': 'boolean',\n",
       "          'description': 'bool, default True. False for ranks by high (1) to low (N).\\n'},\n",
       "         'na_option': {'type': 'string',\n",
       "          'enum': ['keep', ' top', ' bottom'],\n",
       "          'description': '{‘keep’, ‘top’, ‘bottom’}, default ‘keep’. \\nkeep: leave NA values where they are.\\ntop: smallest rank if ascending.\\nbottom: smallest rank if descending.\\n\\n'},\n",
       "         'pct': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Compute percentage rank of data within each group.\\n'},\n",
       "         'axis': {'type': 'integer',\n",
       "          'description': 'int, default 0. The axis of the object over which to compute the rank.\\n\\nDeprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\\nthe axis keyword is not necessary.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.rolling(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Return a rolling grouper, providing rolling functionality per group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.rolling.html#pandas.core.groupby.SeriesGroupBy.rolling',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.rolling',\n",
       "       'full_function': 'SeriesGroupBy.rolling(*args, **kwargs)',\n",
       "       'function_text': 'Return a rolling grouper, providing rolling functionality per group.',\n",
       "       'parameter_names_desc': [{'param_name': 'window',\n",
       "         'param_type': 'int, timedelta, str, offset, or BaseIndexer subclass',\n",
       "         'param_desc': 'Size of the moving window.\\nIf an integer, the fixed number of observations used for\\neach window.\\nIf a timedelta, str, or offset, the time period of each window. Each\\nwindow will be a variable sized based on the observations included in\\nthe time-period. This is only valid for datetimelike indexes.\\nTo learn more about the offsets & frequency strings, please see this link.\\nIf a BaseIndexer subclass, the window boundaries\\nbased on the defined get_window_bounds method. Additional rolling\\nkeyword arguments, namely min_periods, center, closed and\\nstep will be passed to get_window_bounds.\\n'},\n",
       "        {'param_name': 'min_periods',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'Minimum number of observations in window required to have a value;\\notherwise, result is np.nan.\\nFor a window that is specified by an offset,\\nmin_periods will default to 1.\\nFor a window that is specified by an integer, min_periods will default\\nto the size of the window.\\n'},\n",
       "        {'param_name': 'center',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If False, set the window labels as the right edge of the window index.\\nIf True, set the window labels as the center of the window index.\\n'},\n",
       "        {'param_name': 'win_type',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'If None, all points are evenly weighted.\\nIf a string, it must be a valid scipy.signal window function.\\nCertain Scipy window types require additional parameters to be passed\\nin the aggregation function. The additional parameters must match\\nthe keywords specified in the Scipy window type method signature.\\n'},\n",
       "        {'param_name': 'on',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'For a DataFrame, a column label or Index level on which\\nto calculate the rolling window, rather than the DataFrame’s index.\\nProvided integer column is ignored and excluded from result since\\nan integer index is not used to calculate the rolling window.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': 'int or str, default 0',\n",
       "         'param_desc': \"If 0 or 'index', roll across the rows.\\nIf 1 or 'columns', roll across the columns.\\nFor Series this parameter is unused and defaults to 0.\\n\"},\n",
       "        {'param_name': 'closed',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': \"If 'right', the first point in the window is excluded from calculations.\\nIf 'left', the last point in the window is excluded from calculations.\\nIf 'both', no points in the window are excluded from calculations.\\nIf 'neither', the first and last points in the window are excluded\\nfrom calculations.\\nDefault None ('right').\\n\"},\n",
       "        {'param_name': 'method',\n",
       "         'param_type': 'str {‘single’, ‘table’}, default ‘single’',\n",
       "         'param_desc': \"Execute the rolling operation per single column or row ('single')\\nor over the entire object ('table').\\nThis argument is only implemented when specifying engine='numba'\\nin the method call.\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.rolling',\n",
       "       'descriptions': 'Return a rolling grouper, providing rolling functionality per group.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'window': {'type': 'integer',\n",
       "          'description': 'int, timedelta, str, offset, or BaseIndexer subclass. Size of the moving window.\\nIf an integer, the fixed number of observations used for\\neach window.\\nIf a timedelta, str, or offset, the time period of each window. Each\\nwindow will be a variable sized based on the observations included in\\nthe time-period. This is only valid for datetimelike indexes.\\nTo learn more about the offsets & frequency strings, please see this link.\\nIf a BaseIndexer subclass, the window boundaries\\nbased on the defined get_window_bounds method. Additional rolling\\nkeyword arguments, namely min_periods, center, closed and\\nstep will be passed to get_window_bounds.\\n'},\n",
       "         'min_periods': {'type': 'integer',\n",
       "          'description': 'int, default None. Minimum number of observations in window required to have a value;\\notherwise, result is np.nan.\\nFor a window that is specified by an offset,\\nmin_periods will default to 1.\\nFor a window that is specified by an integer, min_periods will default\\nto the size of the window.\\n'},\n",
       "         'center': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If False, set the window labels as the right edge of the window index.\\nIf True, set the window labels as the center of the window index.\\n'},\n",
       "         'win_type': {'type': 'string',\n",
       "          'description': 'str, default None. If None, all points are evenly weighted.\\nIf a string, it must be a valid scipy.signal window function.\\nCertain Scipy window types require additional parameters to be passed\\nin the aggregation function. The additional parameters must match\\nthe keywords specified in the Scipy window type method signature.\\n'},\n",
       "         'on': {'type': 'string',\n",
       "          'description': 'str, optional. For a DataFrame, a column label or Index level on which\\nto calculate the rolling window, rather than the DataFrame’s index.\\nProvided integer column is ignored and excluded from result since\\nan integer index is not used to calculate the rolling window.\\n'},\n",
       "         'axis': {'type': 'integer',\n",
       "          'description': \"int or str, default 0. If 0 or 'index', roll across the rows.\\nIf 1 or 'columns', roll across the columns.\\nFor Series this parameter is unused and defaults to 0.\\n\"},\n",
       "         'closed': {'type': 'string',\n",
       "          'description': \"str, default None. If 'right', the first point in the window is excluded from calculations.\\nIf 'left', the last point in the window is excluded from calculations.\\nIf 'both', no points in the window are excluded from calculations.\\nIf 'neither', the first and last points in the window are excluded\\nfrom calculations.\\nDefault None ('right').\\n\"},\n",
       "         'method': {'type': 'string',\n",
       "          'description': \"str {‘single’, ‘table’}, default ‘single’. Execute the rolling operation per single column or row ('single')\\nor over the entire object ('table').\\nThis argument is only implemented when specifying engine='numba'\\nin the method call.\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.sem([ddof,\\xa0numeric_only])',\n",
       "      'func_desc': 'Compute standard error of the mean of groups, excluding missing values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.sem.html#pandas.core.groupby.SeriesGroupBy.sem',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.sem',\n",
       "       'full_function': 'SeriesGroupBy.sem(ddof=1, numeric_only=False)',\n",
       "       'function_text': 'Compute standard error of the mean of groups, excluding missing values. For multiple groupings, the result index will be a MultiIndex.',\n",
       "       'parameter_names_desc': [{'param_name': 'ddof',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Degrees of freedom.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int or boolean data.\\n\\nNew in version 1.5.0.\\n\\n\\nChanged in version 2.0.0: numeric_only now defaults to False.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.sem',\n",
       "       'descriptions': 'Compute standard error of the mean of groups, excluding missing values. For multiple groupings, the result index will be a MultiIndex.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'ddof': {'type': 'integer',\n",
       "          'description': 'int, default 1. Degrees of freedom.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int or boolean data.\\n\\nNew in version 1.5.0.\\n\\n\\nChanged in version 2.0.0: numeric_only now defaults to False.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.size()',\n",
       "      'func_desc': 'Compute group sizes.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.size.html#pandas.core.groupby.SeriesGroupBy.size',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.size',\n",
       "       'full_function': 'SeriesGroupBy.size()',\n",
       "       'function_text': 'Compute group sizes.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SeriesGroupBy.std([ddof,\\xa0engine,\\xa0...])',\n",
       "      'func_desc': 'Compute standard deviation of groups, excluding missing values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.std.html#pandas.core.groupby.SeriesGroupBy.std',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.std',\n",
       "       'full_function': 'SeriesGroupBy.std(ddof=1, engine=None, engine_kwargs=None, numeric_only=False)',\n",
       "       'function_text': 'Compute standard deviation of groups, excluding missing values. For multiple groupings, the result index will be a MultiIndex.',\n",
       "       'parameter_names_desc': [{'param_name': 'ddof',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Degrees of freedom.\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': \"\\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting\\ncompute.use_numba\\n\\n\\nNew in version 1.4.0.\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{{'nopython': True, 'nogil': False, 'parallel': False}}\\n\\n\\nNew in version 1.4.0.\\n\\n\"},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int or boolean data.\\n\\nNew in version 1.5.0.\\n\\n\\nChanged in version 2.0.0: numeric_only now defaults to False.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.std',\n",
       "       'descriptions': 'Compute standard deviation of groups, excluding missing values. For multiple groupings, the result index will be a MultiIndex.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'ddof': {'type': 'integer',\n",
       "          'description': 'int, default 1. Degrees of freedom.\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None. \\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting\\ncompute.use_numba\\n\\n\\nNew in version 1.4.0.\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None',\n",
       "          'description': \"dict, default None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{{'nopython': True, 'nogil': False, 'parallel': False}}\\n\\n\\nNew in version 1.4.0.\\n\\n\"},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int or boolean data.\\n\\nNew in version 1.5.0.\\n\\n\\nChanged in version 2.0.0: numeric_only now defaults to False.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.var([ddof,\\xa0engine,\\xa0...])',\n",
       "      'func_desc': 'Compute variance of groups, excluding missing values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.var.html#pandas.core.groupby.SeriesGroupBy.var',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.var',\n",
       "       'full_function': 'SeriesGroupBy.var(ddof=1, engine=None, engine_kwargs=None, numeric_only=False)',\n",
       "       'function_text': 'Compute variance of groups, excluding missing values. For multiple groupings, the result index will be a MultiIndex.',\n",
       "       'parameter_names_desc': [{'param_name': 'ddof',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Degrees of freedom.\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': \"\\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting\\ncompute.use_numba\\n\\n\\nNew in version 1.4.0.\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{{'nopython': True, 'nogil': False, 'parallel': False}}\\n\\n\\nNew in version 1.4.0.\\n\\n\"},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int or boolean data.\\n\\nNew in version 1.5.0.\\n\\n\\nChanged in version 2.0.0: numeric_only now defaults to False.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.var',\n",
       "       'descriptions': 'Compute variance of groups, excluding missing values. For multiple groupings, the result index will be a MultiIndex.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'ddof': {'type': 'integer',\n",
       "          'description': 'int, default 1. Degrees of freedom.\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None. \\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting\\ncompute.use_numba\\n\\n\\nNew in version 1.4.0.\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None',\n",
       "          'description': \"dict, default None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{{'nopython': True, 'nogil': False, 'parallel': False}}\\n\\n\\nNew in version 1.4.0.\\n\\n\"},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int or boolean data.\\n\\nNew in version 1.5.0.\\n\\n\\nChanged in version 2.0.0: numeric_only now defaults to False.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.take(indices[,\\xa0axis])',\n",
       "      'func_desc': 'Return the elements in the given positional indices in each group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.take.html#pandas.core.groupby.SeriesGroupBy.take',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.take',\n",
       "       'full_function': 'SeriesGroupBy.take(indices, axis=_NoDefault.no_default, **kwargs)',\n",
       "       'function_text': 'Return the elements in the given positional indices in each group. This means that we are not indexing according to actual values in\\nthe index attribute of the object. We are indexing according to the\\nactual position of the element in the object. If a requested index does not exist for some group, this method will raise.\\nTo get similar behavior that ignores indices that don’t exist, see\\nSeriesGroupBy.nth().',\n",
       "       'parameter_names_desc': [{'param_name': 'indices',\n",
       "         'param_type': 'array-like',\n",
       "         'param_desc': 'An array of ints indicating which positions to take in each group.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’, None}, default 0',\n",
       "         'param_desc': 'The axis on which to select elements. 0 means that we are\\nselecting rows, 1 means that we are selecting columns.\\nFor SeriesGroupBy this parameter is unused and defaults to 0.\\n\\nDeprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\\nthe axis keyword is not necessary.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.take',\n",
       "       'descriptions': 'Return the elements in the given positional indices in each group. This means that we are not indexing according to actual values in\\nthe index attribute of the object. We are indexing according to the\\nactual position of the element in the object. If a requested index does not exist for some group, this method will raise.\\nTo get similar behavior that ignores indices that don’t exist, see\\nSeriesGroupBy.nth().',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'indices': {'type': 'array',\n",
       "          'description': 'array-like. An array of ints indicating which positions to take in each group.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns', ' None'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’, None}, default 0. The axis on which to select elements. 0 means that we are\\nselecting rows, 1 means that we are selecting columns.\\nFor SeriesGroupBy this parameter is unused and defaults to 0.\\n\\nDeprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\\nthe axis keyword is not necessary.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.any([skipna])',\n",
       "      'func_desc': 'Return True if any value in the group is truthful, else False.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.any.html#pandas.core.groupby.SeriesGroupBy.any',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.any',\n",
       "       'full_function': 'SeriesGroupBy.any(skipna=True)',\n",
       "       'function_text': 'Return True if any value in the group is truthful, else False.',\n",
       "       'parameter_names_desc': [{'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Flag to ignore nan values during truth testing.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.any',\n",
       "       'descriptions': 'Return True if any value in the group is truthful, else False.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Flag to ignore nan values during truth testing.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.corr(other[,\\xa0method,\\xa0min_periods])',\n",
       "      'func_desc': 'Compute correlation with other Series, excluding missing values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.corr.html#pandas.core.groupby.SeriesGroupBy.corr',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.corr',\n",
       "       'full_function': \"SeriesGroupBy.corr(other, method='pearson', min_periods=None)\",\n",
       "       'function_text': 'Compute correlation with other Series, excluding missing values. The two Series objects are not required to be the same length and will be\\naligned internally before the correlation function is applied.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series',\n",
       "         'param_desc': 'Series with which to compute the correlation.\\n'},\n",
       "        {'param_name': 'method',\n",
       "         'param_type': '{‘pearson’, ‘kendall’, ‘spearman’} or callable',\n",
       "         'param_desc': 'Method used to compute correlation:\\n\\npearson : Standard correlation coefficient\\nkendall : Kendall Tau correlation coefficient\\nspearman : Spearman rank correlation\\ncallable: Callable with input two 1d ndarrays and returning a float.\\n\\n\\nWarning\\nNote that the returned matrix from corr will have 1 along the\\ndiagonals and will be symmetric regardless of the callable’s\\nbehavior.\\n\\n'},\n",
       "        {'param_name': 'min_periods',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Minimum number of observations needed to have a valid result.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.corr',\n",
       "       'descriptions': 'Compute correlation with other Series, excluding missing values. The two Series objects are not required to be the same length and will be\\naligned internally before the correlation function is applied.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series',\n",
       "          'description': 'Series. Series with which to compute the correlation.\\n'},\n",
       "         'method': {'type': 'object',\n",
       "          'description': '{‘pearson’, ‘kendall’, ‘spearman’} or callable. Method used to compute correlation:\\n\\npearson : Standard correlation coefficient\\nkendall : Kendall Tau correlation coefficient\\nspearman : Spearman rank correlation\\ncallable: Callable with input two 1d ndarrays and returning a float.\\n\\n\\nWarning\\nNote that the returned matrix from corr will have 1 along the\\ndiagonals and will be symmetric regardless of the callable’s\\nbehavior.\\n\\n'},\n",
       "         'min_periods': {'type': 'integer',\n",
       "          'description': 'int, optional. Minimum number of observations needed to have a valid result.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.cov(other[,\\xa0min_periods,\\xa0ddof])',\n",
       "      'func_desc': 'Compute covariance with Series, excluding missing values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cov.html#pandas.core.groupby.SeriesGroupBy.cov',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.cov',\n",
       "       'full_function': 'SeriesGroupBy.cov(other, min_periods=None, ddof=1)',\n",
       "       'function_text': 'Compute covariance with Series, excluding missing values. The two Series objects are not required to be the same length and\\nwill be aligned internally before the covariance is calculated.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Series',\n",
       "         'param_desc': 'Series with which to compute the covariance.\\n'},\n",
       "        {'param_name': 'min_periods',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Minimum number of observations needed to have a valid result.\\n'},\n",
       "        {'param_name': 'ddof',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Delta degrees of freedom. The divisor used in calculations\\nis N - ddof, where N represents the number of elements.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.cov',\n",
       "       'descriptions': 'Compute covariance with Series, excluding missing values. The two Series objects are not required to be the same length and\\nwill be aligned internally before the covariance is calculated.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Series',\n",
       "          'description': 'Series. Series with which to compute the covariance.\\n'},\n",
       "         'min_periods': {'type': 'integer',\n",
       "          'description': 'int, optional. Minimum number of observations needed to have a valid result.\\n'},\n",
       "         'ddof': {'type': 'integer',\n",
       "          'description': 'int, default 1. Delta degrees of freedom. The divisor used in calculations\\nis N - ddof, where N represents the number of elements.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.cummax([axis,\\xa0numeric_only])',\n",
       "      'func_desc': 'Cumulative max for each group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cummax.html#pandas.core.groupby.SeriesGroupBy.cummax',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.cummax',\n",
       "       'full_function': 'SeriesGroupBy.cummax(axis=_NoDefault.no_default, numeric_only=False, **kwargs)',\n",
       "       'function_text': 'Cumulative max for each group.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SeriesGroupBy.cumprod([axis])',\n",
       "      'func_desc': 'Cumulative product for each group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cumprod.html#pandas.core.groupby.SeriesGroupBy.cumprod',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.cumprod',\n",
       "       'full_function': 'SeriesGroupBy.cumprod(axis=_NoDefault.no_default, *args, **kwargs)',\n",
       "       'function_text': 'Cumulative product for each group.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SeriesGroupBy.describe([percentiles,\\xa0...])',\n",
       "      'func_desc': 'Generate descriptive statistics.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.describe.html#pandas.core.groupby.SeriesGroupBy.describe',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.describe',\n",
       "       'full_function': 'SeriesGroupBy.describe(percentiles=None, include=None, exclude=None)',\n",
       "       'function_text': 'Generate descriptive statistics. Descriptive statistics include those that summarize the central\\ntendency, dispersion and shape of a\\ndataset’s distribution, excluding NaN values. Analyzes both numeric and object series, as well\\nas DataFrame column sets of mixed data types. The output\\nwill vary depending on what is provided. Refer to the notes\\nbelow for more detail.',\n",
       "       'parameter_names_desc': [{'param_name': 'percentiles',\n",
       "         'param_type': 'list-like of numbers, optional',\n",
       "         'param_desc': 'The percentiles to include in the output. All should\\nfall between 0 and 1. The default is\\n[.25, .5, .75], which returns the 25th, 50th, and\\n75th percentiles.\\n'},\n",
       "        {'param_name': 'include',\n",
       "         'param_type': '‘all’, list-like of dtypes or None (default), optional',\n",
       "         'param_desc': \"A white list of data types to include in the result. Ignored\\nfor Series. Here are the options:\\n\\n‘all’ : All columns of the input will be included in the output.\\nA list-like of dtypes : Limits the results to the\\nprovided data types.\\nTo limit the result to numeric types submit\\nnumpy.number. To limit it instead to object columns submit\\nthe numpy.object data type. Strings\\ncan also be used in the style of\\nselect_dtypes (e.g. df.describe(include=['O'])). To\\nselect pandas categorical columns, use 'category'\\nNone (default) : The result will include all numeric columns.\\n\\n\"},\n",
       "        {'param_name': 'exclude',\n",
       "         'param_type': 'list-like of dtypes or None (default), optional,',\n",
       "         'param_desc': \"A black list of data types to omit from the result. Ignored\\nfor Series. Here are the options:\\n\\nA list-like of dtypes : Excludes the provided data types\\nfrom the result. To exclude numeric types submit\\nnumpy.number. To exclude object columns submit the data\\ntype numpy.object. Strings can also be used in the style of\\nselect_dtypes (e.g. df.describe(exclude=['O'])). To\\nexclude pandas categorical columns, use 'category'\\nNone (default) : The result will exclude nothing.\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.describe',\n",
       "       'descriptions': 'Generate descriptive statistics. Descriptive statistics include those that summarize the central\\ntendency, dispersion and shape of a\\ndataset’s distribution, excluding NaN values. Analyzes both numeric and object series, as well\\nas DataFrame column sets of mixed data types. The output\\nwill vary depending on what is provided. Refer to the notes\\nbelow for more detail.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'percentiles': {'type': 'array',\n",
       "          'description': 'list-like of numbers, optional. The percentiles to include in the output. All should\\nfall between 0 and 1. The default is\\n[.25, .5, .75], which returns the 25th, 50th, and\\n75th percentiles.\\n'},\n",
       "         'include': {'type': 'array',\n",
       "          'description': \"‘all’, list-like of dtypes or None (default), optional. A white list of data types to include in the result. Ignored\\nfor Series. Here are the options:\\n\\n‘all’ : All columns of the input will be included in the output.\\nA list-like of dtypes : Limits the results to the\\nprovided data types.\\nTo limit the result to numeric types submit\\nnumpy.number. To limit it instead to object columns submit\\nthe numpy.object data type. Strings\\ncan also be used in the style of\\nselect_dtypes (e.g. df.describe(include=['O'])). To\\nselect pandas categorical columns, use 'category'\\nNone (default) : The result will include all numeric columns.\\n\\n\"},\n",
       "         'exclude': {'type': 'array',\n",
       "          'description': \"list-like of dtypes or None (default), optional,. A black list of data types to omit from the result. Ignored\\nfor Series. Here are the options:\\n\\nA list-like of dtypes : Excludes the provided data types\\nfrom the result. To exclude numeric types submit\\nnumpy.number. To exclude object columns submit the data\\ntype numpy.object. Strings can also be used in the style of\\nselect_dtypes (e.g. df.describe(exclude=['O'])). To\\nexclude pandas categorical columns, use 'category'\\nNone (default) : The result will exclude nothing.\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.ffill([limit])',\n",
       "      'func_desc': 'Forward fill the values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.ffill.html#pandas.core.groupby.SeriesGroupBy.ffill',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.ffill',\n",
       "       'full_function': 'SeriesGroupBy.ffill(limit=None)',\n",
       "       'function_text': 'Forward fill the values.',\n",
       "       'parameter_names_desc': [{'param_name': 'limit',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Limit of how many values to fill.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.ffill',\n",
       "       'descriptions': 'Forward fill the values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'limit': {'type': 'integer',\n",
       "          'description': 'int, optional. Limit of how many values to fill.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.first([numeric_only,\\xa0...])',\n",
       "      'func_desc': 'Compute the first entry of each column within each group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.first.html#pandas.core.groupby.SeriesGroupBy.first',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.first',\n",
       "       'full_function': 'SeriesGroupBy.first(numeric_only=False, min_count=-1, skipna=True)',\n",
       "       'function_text': 'Compute the first entry of each column within each group. Defaults to skipping NA elements.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n'},\n",
       "        {'param_name': 'min_count',\n",
       "         'param_type': 'int, default -1',\n",
       "         'param_desc': 'The required number of valid values to perform the operation. If fewer\\nthan min_count valid values are present the result will be NA.\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n\\nNew in version 2.2.1.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.first',\n",
       "       'descriptions': 'Compute the first entry of each column within each group. Defaults to skipping NA elements.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n'},\n",
       "         'min_count': {'type': 'integer',\n",
       "          'description': 'int, default -1. The required number of valid values to perform the operation. If fewer\\nthan min_count valid values are present the result will be NA.\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n\\nNew in version 2.2.1.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.last([numeric_only,\\xa0...])',\n",
       "      'func_desc': 'Compute the last entry of each column within each group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.last.html#pandas.core.groupby.SeriesGroupBy.last',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.last',\n",
       "       'full_function': 'SeriesGroupBy.last(numeric_only=False, min_count=-1, skipna=True)',\n",
       "       'function_text': 'Compute the last entry of each column within each group. Defaults to skipping NA elements.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns. If None, will attempt to use\\neverything, then use only numeric data.\\n'},\n",
       "        {'param_name': 'min_count',\n",
       "         'param_type': 'int, default -1',\n",
       "         'param_desc': 'The required number of valid values to perform the operation. If fewer\\nthan min_count valid values are present the result will be NA.\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n\\nNew in version 2.2.1.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.last',\n",
       "       'descriptions': 'Compute the last entry of each column within each group. Defaults to skipping NA elements.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns. If None, will attempt to use\\neverything, then use only numeric data.\\n'},\n",
       "         'min_count': {'type': 'integer',\n",
       "          'description': 'int, default -1. The required number of valid values to perform the operation. If fewer\\nthan min_count valid values are present the result will be NA.\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n\\nNew in version 2.2.1.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.idxmin([axis,\\xa0skipna])',\n",
       "      'func_desc': 'Return the row label of the minimum value.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.idxmin.html#pandas.core.groupby.SeriesGroupBy.idxmin',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.idxmin',\n",
       "       'full_function': 'SeriesGroupBy.idxmin(axis=_NoDefault.no_default, skipna=True)',\n",
       "       'function_text': 'Return the row label of the minimum value. If multiple values equal the minimum, the first row label with that\\nvalue is returned.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SeriesGroupBy.is_monotonic_decreasing',\n",
       "      'func_desc': \"Return whether each group's values are monotonically decreasing.\",\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.is_monotonic_decreasing.html#pandas.core.groupby.SeriesGroupBy.is_monotonic_decreasing',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.is_monotonic_decreasing',\n",
       "       'full_function': 'property SeriesGroupBy.is_monotonic_decreasing',\n",
       "       'function_text': 'Return whether each group’s values are monotonically decreasing.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SeriesGroupBy.mean([numeric_only,\\xa0engine,\\xa0...])',\n",
       "      'func_desc': 'Compute mean of groups, excluding missing values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.mean.html#pandas.core.groupby.SeriesGroupBy.mean',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.mean',\n",
       "       'full_function': 'SeriesGroupBy.mean(numeric_only=False, engine=None, engine_kwargs=None)',\n",
       "       'function_text': 'Compute mean of groups, excluding missing values.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nChanged in version 2.0.0: numeric_only no longer accepts None and defaults to False.\\n\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': \"\\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting\\ncompute.use_numba\\n\\n\\nNew in version 1.4.0.\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{{'nopython': True, 'nogil': False, 'parallel': False}}\\n\\n\\nNew in version 1.4.0.\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.mean',\n",
       "       'descriptions': 'Compute mean of groups, excluding missing values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nChanged in version 2.0.0: numeric_only no longer accepts None and defaults to False.\\n\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None. \\n'cython' : Runs the operation through C-extensions from cython.\\n'numba' : Runs the operation through JIT compiled code from numba.\\nNone : Defaults to 'cython' or globally setting\\ncompute.use_numba\\n\\n\\nNew in version 1.4.0.\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None',\n",
       "          'description': \"dict, default None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\nFor 'numba' engine, the engine can accept nopython, nogil\\nand parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{{'nopython': True, 'nogil': False, 'parallel': False}}\\n\\n\\nNew in version 1.4.0.\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.min([numeric_only,\\xa0min_count,\\xa0...])',\n",
       "      'func_desc': 'Compute min of group values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.min.html#pandas.core.groupby.SeriesGroupBy.min',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.min',\n",
       "       'full_function': 'SeriesGroupBy.min(numeric_only=False, min_count=-1, engine=None, engine_kwargs=None)',\n",
       "       'function_text': 'Compute min of group values.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nChanged in version 2.0.0: numeric_only no longer accepts None.\\n\\n'},\n",
       "        {'param_name': 'min_count',\n",
       "         'param_type': 'int, default -1',\n",
       "         'param_desc': 'The required number of valid values to perform the operation. If fewer\\nthan min_count non-NA values are present the result will be NA.\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None None',\n",
       "         'param_desc': \"\\n'cython' : Runs rolling apply through C-extensions from cython.\\n\\n'numba'Runs rolling apply through JIT compiled code from numba.Only available when raw is set to True.\\n\\n\\n\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\n\\nFor 'numba' engine, the engine can accept nopython, nogiland parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\\napplied to both the func and the apply groupby aggregation.\\n\\n\\n\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.min',\n",
       "       'descriptions': 'Compute min of group values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nChanged in version 2.0.0: numeric_only no longer accepts None.\\n\\n'},\n",
       "         'min_count': {'type': 'integer',\n",
       "          'description': 'int, default -1. The required number of valid values to perform the operation. If fewer\\nthan min_count non-NA values are present the result will be NA.\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None None. \\n'cython' : Runs rolling apply through C-extensions from cython.\\n\\n'numba'Runs rolling apply through JIT compiled code from numba.Only available when raw is set to True.\\n\\n\\n\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None None',\n",
       "          'description': \"dict, default None None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\n\\nFor 'numba' engine, the engine can accept nopython, nogiland parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\\napplied to both the func and the apply groupby aggregation.\\n\\n\\n\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.nlargest([n,\\xa0keep])',\n",
       "      'func_desc': 'Return the largest n elements.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.nlargest.html#pandas.core.groupby.SeriesGroupBy.nlargest',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.nlargest',\n",
       "       'full_function': \"SeriesGroupBy.nlargest(n=5, keep='first')\",\n",
       "       'function_text': 'Return the largest n elements.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, default 5',\n",
       "         'param_desc': 'Return this many descending sorted values.\\n'},\n",
       "        {'param_name': 'keep',\n",
       "         'param_type': '{‘first’, ‘last’, ‘all’}, default ‘first’',\n",
       "         'param_desc': 'When there are duplicate values that cannot all fit in a\\nSeries of n elements:\\n\\nfirst : return the first n occurrences in order\\nof appearance.\\nlast : return the last n occurrences in reverse\\norder of appearance.\\nall : keep all occurrences. This can result in a Series of\\nsize larger than n.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.nlargest',\n",
       "       'descriptions': 'Return the largest n elements.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, default 5. Return this many descending sorted values.\\n'},\n",
       "         'keep': {'type': 'string',\n",
       "          'enum': ['first', ' last', ' all'],\n",
       "          'description': '{‘first’, ‘last’, ‘all’}, default ‘first’. When there are duplicate values that cannot all fit in a\\nSeries of n elements:\\n\\nfirst : return the first n occurrences in order\\nof appearance.\\nlast : return the last n occurrences in reverse\\norder of appearance.\\nall : keep all occurrences. This can result in a Series of\\nsize larger than n.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.nth',\n",
       "      'func_desc': 'Take the nth row from each group if n is an int, otherwise a subset of rows.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.nth.html#pandas.core.groupby.SeriesGroupBy.nth',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.nth',\n",
       "       'full_function': 'property SeriesGroupBy.nth',\n",
       "       'function_text': 'Take the nth row from each group if n is an int, otherwise a subset of rows. Can be either a call or an index. dropna is not available with index notation.\\nIndex notation accepts a comma separated list of integers and slices. If dropna, will take the nth non-null row, dropna is either\\n‘all’ or ‘any’; this is equivalent to calling dropna(how=dropna)\\nbefore the groupby.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, slice or list of ints and slices',\n",
       "         'param_desc': 'A single nth value for the row or a list of nth values or slices.\\n\\nChanged in version 1.4.0: Added slice and lists containing slices.\\nAdded index notation.\\n\\n'},\n",
       "        {'param_name': 'dropna',\n",
       "         'param_type': '{‘any’, ‘all’, None}, default None',\n",
       "         'param_desc': 'Apply the specified dropna operation before counting which row is\\nthe nth row. Only supported if n is an int.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.nth',\n",
       "       'descriptions': 'Take the nth row from each group if n is an int, otherwise a subset of rows. Can be either a call or an index. dropna is not available with index notation.\\nIndex notation accepts a comma separated list of integers and slices. If dropna, will take the nth non-null row, dropna is either\\n‘all’ or ‘any’; this is equivalent to calling dropna(how=dropna)\\nbefore the groupby.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, slice or list of ints and slices. A single nth value for the row or a list of nth values or slices.\\n\\nChanged in version 1.4.0: Added slice and lists containing slices.\\nAdded index notation.\\n\\n'},\n",
       "         'dropna': {'type': 'string',\n",
       "          'enum': ['any', ' all', ' None'],\n",
       "          'description': '{‘any’, ‘all’, None}, default None. Apply the specified dropna operation before counting which row is\\nthe nth row. Only supported if n is an int.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.unique()',\n",
       "      'func_desc': 'Return unique values for each group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.unique.html#pandas.core.groupby.SeriesGroupBy.unique',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.unique',\n",
       "       'full_function': 'SeriesGroupBy.unique()',\n",
       "       'function_text': 'Return unique values for each group. It returns unique values for each of the grouped values. Returned in\\norder of appearance. Hash table-based unique, therefore does NOT sort.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SeriesGroupBy.pct_change([periods,\\xa0...])',\n",
       "      'func_desc': 'Calculate pct_change of each value to previous entry in group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.pct_change.html#pandas.core.groupby.SeriesGroupBy.pct_change',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.pct_change',\n",
       "       'full_function': 'SeriesGroupBy.pct_change(periods=1, fill_method=_NoDefault.no_default, limit=_NoDefault.no_default, freq=None, axis=_NoDefault.no_default)',\n",
       "       'function_text': 'Calculate pct_change of each value to previous entry in group.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'SeriesGroupBy.quantile([q,\\xa0interpolation,\\xa0...])',\n",
       "      'func_desc': 'Return group values at the given quantile, a la numpy.percentile.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.quantile.html#pandas.core.groupby.SeriesGroupBy.quantile',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.quantile',\n",
       "       'full_function': \"SeriesGroupBy.quantile(q=0.5, interpolation='linear', numeric_only=False)\",\n",
       "       'function_text': 'Return group values at the given quantile, a la numpy.percentile.',\n",
       "       'parameter_names_desc': [{'param_name': 'q',\n",
       "         'param_type': 'float or array-like, default 0.5 (50% quantile)',\n",
       "         'param_desc': 'Value(s) between 0 and 1 providing the quantile(s) to compute.\\n'},\n",
       "        {'param_name': 'interpolation',\n",
       "         'param_type': '{‘linear’, ‘lower’, ‘higher’, ‘midpoint’, ‘nearest’}',\n",
       "         'param_desc': 'Method to use when the desired quantile falls between two points.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int or boolean data.\\n\\nNew in version 1.5.0.\\n\\n\\nChanged in version 2.0.0: numeric_only now defaults to False.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.quantile',\n",
       "       'descriptions': 'Return group values at the given quantile, a la numpy.percentile.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'q': {'type': 'float',\n",
       "          'description': 'float or array-like, default 0.5 (50% quantile). Value(s) between 0 and 1 providing the quantile(s) to compute.\\n'},\n",
       "         'interpolation': {'type': 'integer',\n",
       "          'description': '{‘linear’, ‘lower’, ‘higher’, ‘midpoint’, ‘nearest’}. Method to use when the desired quantile falls between two points.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int or boolean data.\\n\\nNew in version 1.5.0.\\n\\n\\nChanged in version 2.0.0: numeric_only now defaults to False.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.resample(rule,\\xa0*args[,\\xa0...])',\n",
       "      'func_desc': 'Provide resampling when using a TimeGrouper.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.resample.html#pandas.core.groupby.SeriesGroupBy.resample',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.resample',\n",
       "       'full_function': 'SeriesGroupBy.resample(rule, *args, include_groups=True, **kwargs)',\n",
       "       'function_text': 'Provide resampling when using a TimeGrouper. Given a grouper, the function resamples it according to a string\\n“string” -> “frequency”. See the frequency aliases\\ndocumentation for more details.',\n",
       "       'parameter_names_desc': [{'param_name': 'rule',\n",
       "         'param_type': 'str or DateOffset',\n",
       "         'param_desc': 'The offset string or object representing target grouper conversion.\\n'},\n",
       "        {'param_name': 'include_groups',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'When True, will attempt to include the groupings in the operation in\\nthe case that they are columns of the DataFrame. If this raises a\\nTypeError, the result will be computed with the groupings excluded.\\nWhen False, the groupings will be excluded when applying func.\\n\\nNew in version 2.2.0.\\n\\n\\nDeprecated since version 2.2.0: Setting include_groups to True is deprecated. Only the value\\nFalse will be allowed in a future version of pandas.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.resample',\n",
       "       'descriptions': 'Provide resampling when using a TimeGrouper. Given a grouper, the function resamples it according to a string\\n“string” -> “frequency”. See the frequency aliases\\ndocumentation for more details.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'rule': {'type': 'string',\n",
       "          'description': 'str or DateOffset. The offset string or object representing target grouper conversion.\\n'},\n",
       "         'include_groups': {'type': 'boolean',\n",
       "          'description': 'bool, default True. When True, will attempt to include the groupings in the operation in\\nthe case that they are columns of the DataFrame. If this raises a\\nTypeError, the result will be computed with the groupings excluded.\\nWhen False, the groupings will be excluded when applying func.\\n\\nNew in version 2.2.0.\\n\\n\\nDeprecated since version 2.2.0: Setting include_groups to True is deprecated. Only the value\\nFalse will be allowed in a future version of pandas.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.sample([n,\\xa0frac,\\xa0replace,\\xa0...])',\n",
       "      'func_desc': 'Return a random sample of items from each group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.sample.html#pandas.core.groupby.SeriesGroupBy.sample',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.sample',\n",
       "       'full_function': 'SeriesGroupBy.sample(n=None, frac=None, replace=False, weights=None, random_state=None)',\n",
       "       'function_text': 'Return a random sample of items from each group. You can use random_state for reproducibility.',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Number of items to return for each group. Cannot be used with\\nfrac and must be no larger than the smallest group unless\\nreplace is True. Default is one if frac is None.\\n'},\n",
       "        {'param_name': 'frac',\n",
       "         'param_type': 'float, optional',\n",
       "         'param_desc': 'Fraction of items to return. Cannot be used with n.\\n'},\n",
       "        {'param_name': 'replace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Allow or disallow sampling of the same row more than once.\\n'},\n",
       "        {'param_name': 'weights',\n",
       "         'param_type': 'list-like, optional',\n",
       "         'param_desc': 'Default None results in equal probability weighting.\\nIf passed a list-like then values must have the same length as\\nthe underlying DataFrame or Series object and will be used as\\nsampling probabilities after normalization within each group.\\nValues must be non-negative with at least one positive element\\nwithin each group.\\n'},\n",
       "        {'param_name': 'random_state',\n",
       "         'param_type': 'int, array-like, BitGenerator, np.random.RandomState, np.random.Generator, optional',\n",
       "         'param_desc': 'If int, array-like, or BitGenerator, seed for random number generator.\\nIf np.random.RandomState or np.random.Generator, use as given.\\n\\nChanged in version 1.4.0: np.random.Generator objects now accepted\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.sample',\n",
       "       'descriptions': 'Return a random sample of items from each group. You can use random_state for reproducibility.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int, optional. Number of items to return for each group. Cannot be used with\\nfrac and must be no larger than the smallest group unless\\nreplace is True. Default is one if frac is None.\\n'},\n",
       "         'frac': {'type': 'float',\n",
       "          'description': 'float, optional. Fraction of items to return. Cannot be used with n.\\n'},\n",
       "         'replace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Allow or disallow sampling of the same row more than once.\\n'},\n",
       "         'weights': {'type': 'array',\n",
       "          'description': 'list-like, optional. Default None results in equal probability weighting.\\nIf passed a list-like then values must have the same length as\\nthe underlying DataFrame or Series object and will be used as\\nsampling probabilities after normalization within each group.\\nValues must be non-negative with at least one positive element\\nwithin each group.\\n'},\n",
       "         'random_state': {'type': 'integer',\n",
       "          'description': 'int, array-like, BitGenerator, np.random.RandomState, np.random.Generator, optional. If int, array-like, or BitGenerator, seed for random number generator.\\nIf np.random.RandomState or np.random.Generator, use as given.\\n\\nChanged in version 1.4.0: np.random.Generator objects now accepted\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.shift([periods,\\xa0freq,\\xa0axis,\\xa0...])',\n",
       "      'func_desc': 'Shift each group by periods observations.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.shift.html#pandas.core.groupby.SeriesGroupBy.shift',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.shift',\n",
       "       'full_function': 'SeriesGroupBy.shift(periods=1, freq=None, axis=_NoDefault.no_default, fill_value=_NoDefault.no_default, suffix=None)',\n",
       "       'function_text': 'Shift each group by periods observations. If freq is passed, the index will be increased using the periods and the freq.',\n",
       "       'parameter_names_desc': [{'param_name': 'periods',\n",
       "         'param_type': 'int | Sequence[int], default 1',\n",
       "         'param_desc': 'Number of periods to shift. If a list of values, shift each group by\\neach period.\\n'},\n",
       "        {'param_name': 'freq',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Frequency string.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': 'axis to shift, default 0',\n",
       "         'param_desc': 'Shift direction.\\n\\nDeprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\\nthe axis keyword is not necessary.\\n\\n'},\n",
       "        {'param_name': 'fill_value',\n",
       "         'param_type': 'optional',\n",
       "         'param_desc': 'The scalar value to use for newly introduced missing values.\\n\\nChanged in version 2.1.0: Will raise a ValueError if freq is provided too.\\n\\n'},\n",
       "        {'param_name': 'suffix',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'A string to add to each shifted column if there are multiple periods.\\nIgnored otherwise.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.shift',\n",
       "       'descriptions': 'Shift each group by periods observations. If freq is passed, the index will be increased using the periods and the freq.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'periods': {'type': 'integer',\n",
       "          'description': 'int | Sequence[int], default 1. Number of periods to shift. If a list of values, shift each group by\\neach period.\\n'},\n",
       "         'freq': {'type': 'string',\n",
       "          'description': 'str, optional. Frequency string.\\n'},\n",
       "         'axis': {'type': 'axis to shift, default 0',\n",
       "          'description': 'axis to shift, default 0. Shift direction.\\n\\nDeprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\\nthe axis keyword is not necessary.\\n\\n'},\n",
       "         'fill_value': {'type': 'optional',\n",
       "          'description': 'optional. The scalar value to use for newly introduced missing values.\\n\\nChanged in version 2.1.0: Will raise a ValueError if freq is provided too.\\n\\n'},\n",
       "         'suffix': {'type': 'string',\n",
       "          'description': 'str, optional. A string to add to each shifted column if there are multiple periods.\\nIgnored otherwise.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.skew([axis,\\xa0skipna,\\xa0numeric_only])',\n",
       "      'func_desc': 'Return unbiased skew within groups.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.skew.html#pandas.core.groupby.SeriesGroupBy.skew',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.skew',\n",
       "       'full_function': 'SeriesGroupBy.skew(axis=_NoDefault.no_default, skipna=True, numeric_only=False, **kwargs)',\n",
       "       'function_text': 'Return unbiased skew within groups. Normalized by N-1.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’, None}, default 0',\n",
       "         'param_desc': 'Axis for the function to be applied on.\\nThis parameter is only for compatibility with DataFrame and is unused.\\n\\nDeprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\\nthe axis keyword is not necessary.\\n\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values when computing the result.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns. Not implemented for Series.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.skew',\n",
       "       'descriptions': 'Return unbiased skew within groups. Normalized by N-1.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns', ' None'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’, None}, default 0. Axis for the function to be applied on.\\nThis parameter is only for compatibility with DataFrame and is unused.\\n\\nDeprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\\nthe axis keyword is not necessary.\\n\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values when computing the result.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns. Not implemented for Series.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.sum([numeric_only,\\xa0min_count,\\xa0...])',\n",
       "      'func_desc': 'Compute sum of group values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.sum.html#pandas.core.groupby.SeriesGroupBy.sum',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.sum',\n",
       "       'full_function': 'SeriesGroupBy.sum(numeric_only=False, min_count=0, engine=None, engine_kwargs=None)',\n",
       "       'function_text': 'Compute sum of group values.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nChanged in version 2.0.0: numeric_only no longer accepts None.\\n\\n'},\n",
       "        {'param_name': 'min_count',\n",
       "         'param_type': 'int, default 0',\n",
       "         'param_desc': 'The required number of valid values to perform the operation. If fewer\\nthan min_count non-NA values are present the result will be NA.\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, default None None',\n",
       "         'param_desc': \"\\n'cython' : Runs rolling apply through C-extensions from cython.\\n\\n'numba'Runs rolling apply through JIT compiled code from numba.Only available when raw is set to True.\\n\\n\\n\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\n\"},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, default None None',\n",
       "         'param_desc': \"\\nFor 'cython' engine, there are no accepted engine_kwargs\\n\\nFor 'numba' engine, the engine can accept nopython, nogiland parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\\napplied to both the func and the apply groupby aggregation.\\n\\n\\n\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.sum',\n",
       "       'descriptions': 'Compute sum of group values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nChanged in version 2.0.0: numeric_only no longer accepts None.\\n\\n'},\n",
       "         'min_count': {'type': 'integer',\n",
       "          'description': 'int, default 0. The required number of valid values to perform the operation. If fewer\\nthan min_count non-NA values are present the result will be NA.\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': \"str, default None None. \\n'cython' : Runs rolling apply through C-extensions from cython.\\n\\n'numba'Runs rolling apply through JIT compiled code from numba.Only available when raw is set to True.\\n\\n\\n\\nNone : Defaults to 'cython' or globally setting compute.use_numba\\n\\n\"},\n",
       "         'engine_kwargs': {'type': 'dict, default None None',\n",
       "          'description': \"dict, default None None. \\nFor 'cython' engine, there are no accepted engine_kwargs\\n\\nFor 'numba' engine, the engine can accept nopython, nogiland parallel dictionary keys. The values must either be True or\\nFalse. The default engine_kwargs for the 'numba' engine is\\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\\napplied to both the func and the apply groupby aggregation.\\n\\n\\n\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.tail([n])',\n",
       "      'func_desc': 'Return last n rows of each group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.tail.html#pandas.core.groupby.SeriesGroupBy.tail',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.tail',\n",
       "       'full_function': 'SeriesGroupBy.tail(n=5)',\n",
       "       'function_text': 'Return last n rows of each group. Similar to .apply(lambda x: x.tail(n)), but it returns a subset of rows\\nfrom the original DataFrame with original index and order preserved\\n(as_index flag is ignored).',\n",
       "       'parameter_names_desc': [{'param_name': 'n',\n",
       "         'param_type': 'int',\n",
       "         'param_desc': 'If positive: number of entries to include from end of each group.\\nIf negative: number of entries to exclude from start of each group.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.tail',\n",
       "       'descriptions': 'Return last n rows of each group. Similar to .apply(lambda x: x.tail(n)), but it returns a subset of rows\\nfrom the original DataFrame with original index and order preserved\\n(as_index flag is ignored).',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'n': {'type': 'integer',\n",
       "          'description': 'int. If positive: number of entries to include from end of each group.\\nIf negative: number of entries to exclude from start of each group.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.value_counts([normalize,\\xa0...])',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.value_counts.html#pandas.core.groupby.SeriesGroupBy.value_counts',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.value_counts',\n",
       "       'full_function': 'SeriesGroupBy.value_counts(normalize=False, sort=True, ascending=False, bins=None, dropna=True)',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'Plotting and visualization': [{'func_name': 'DataFrameGroupBy.boxplot([subplots,\\xa0column,\\xa0...])',\n",
       "      'func_desc': 'Make box plots from DataFrameGroupBy data.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.boxplot.html#pandas.core.groupby.DataFrameGroupBy.boxplot',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.boxplot',\n",
       "       'full_function': 'DataFrameGroupBy.boxplot(subplots=True, column=None, fontsize=None, rot=0, grid=True, ax=None, figsize=None, layout=None, sharex=False, sharey=True, backend=None, **kwargs)',\n",
       "       'function_text': 'Make box plots from DataFrameGroupBy data.',\n",
       "       'parameter_names_desc': [{'param_name': 'grouped',\n",
       "         'param_type': 'Grouped DataFrame',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'subplots',\n",
       "         'param_type': 'bool',\n",
       "         'param_desc': '\\nFalse - no subplots will be used\\nTrue - create a subplot for each group.\\n\\n'},\n",
       "        {'param_name': 'column',\n",
       "         'param_type': 'column name or list of names, or vector',\n",
       "         'param_desc': 'Can be any valid input to groupby.\\n'},\n",
       "        {'param_name': 'fontsize',\n",
       "         'param_type': 'float or str',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'rot',\n",
       "         'param_type': 'label rotation angle',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'grid',\n",
       "         'param_type': 'Setting this to True will show the grid',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'ax',\n",
       "         'param_type': 'Matplotlib axis object, default None',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'figsize',\n",
       "         'param_type': 'A tuple (width, height) in inches',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'layout',\n",
       "         'param_type': 'tuple (optional)',\n",
       "         'param_desc': 'The layout of the plot: (rows, columns).\\n'},\n",
       "        {'param_name': 'sharex',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether x-axes will be shared among subplots.\\n'},\n",
       "        {'param_name': 'sharey',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether y-axes will be shared among subplots.\\n'},\n",
       "        {'param_name': 'backend',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'Backend to use instead of the backend specified in the option\\nplotting.backend. For instance, ‘matplotlib’. Alternatively, to\\nspecify the plotting.backend for the whole session, set\\npd.options.plotting.backend.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.boxplot',\n",
       "       'descriptions': 'Make box plots from DataFrameGroupBy data.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'grouped': {'type': 'Grouped DataFrame',\n",
       "          'description': 'Grouped DataFrame. '},\n",
       "         'subplots': {'type': 'boolean',\n",
       "          'description': 'bool. \\nFalse - no subplots will be used\\nTrue - create a subplot for each group.\\n\\n'},\n",
       "         'column': {'type': 'array',\n",
       "          'description': 'column name or list of names, or vector. Can be any valid input to groupby.\\n'},\n",
       "         'fontsize': {'type': 'string', 'description': 'float or str. '},\n",
       "         'rot': {'type': 'label rotation angle',\n",
       "          'description': 'label rotation angle. '},\n",
       "         'grid': {'type': 'Setting this to True will show the grid',\n",
       "          'description': 'Setting this to True will show the grid. '},\n",
       "         'ax': {'type': 'object',\n",
       "          'description': 'Matplotlib axis object, default None. '},\n",
       "         'figsize': {'type': 'A tuple (width, height) in inches',\n",
       "          'description': 'A tuple (width, height) in inches. '},\n",
       "         'layout': {'type': 'tuple (optional)',\n",
       "          'description': 'tuple (optional). The layout of the plot: (rows, columns).\\n'},\n",
       "         'sharex': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether x-axes will be shared among subplots.\\n'},\n",
       "         'sharey': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether y-axes will be shared among subplots.\\n'},\n",
       "         'backend': {'type': 'string',\n",
       "          'description': 'str, default None. Backend to use instead of the backend specified in the option\\nplotting.backend. For instance, ‘matplotlib’. Alternatively, to\\nspecify the plotting.backend for the whole session, set\\npd.options.plotting.backend.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.hist([by,\\xa0ax,\\xa0grid,\\xa0...])',\n",
       "      'func_desc': 'Draw histogram of the input series using matplotlib.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.hist.html#pandas.core.groupby.SeriesGroupBy.hist',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.hist',\n",
       "       'full_function': 'SeriesGroupBy.hist(by=None, ax=None, grid=True, xlabelsize=None, xrot=None, ylabelsize=None, yrot=None, figsize=None, bins=10, backend=None, legend=False, **kwargs)',\n",
       "       'function_text': 'Draw histogram of the input series using matplotlib.',\n",
       "       'parameter_names_desc': [{'param_name': 'by',\n",
       "         'param_type': 'object, optional',\n",
       "         'param_desc': 'If passed, then used to form histograms for separate groups.\\n'},\n",
       "        {'param_name': 'ax',\n",
       "         'param_type': 'matplotlib axis object',\n",
       "         'param_desc': 'If not passed, uses gca().\\n'},\n",
       "        {'param_name': 'grid',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to show axis grid lines.\\n'},\n",
       "        {'param_name': 'xlabelsize',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'If specified changes the x-axis label size.\\n'},\n",
       "        {'param_name': 'xrot',\n",
       "         'param_type': 'float, default None',\n",
       "         'param_desc': 'Rotation of x axis labels.\\n'},\n",
       "        {'param_name': 'ylabelsize',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'If specified changes the y-axis label size.\\n'},\n",
       "        {'param_name': 'yrot',\n",
       "         'param_type': 'float, default None',\n",
       "         'param_desc': 'Rotation of y axis labels.\\n'},\n",
       "        {'param_name': 'figsize',\n",
       "         'param_type': 'tuple, default None',\n",
       "         'param_desc': 'Figure size in inches by default.\\n'},\n",
       "        {'param_name': 'bins',\n",
       "         'param_type': 'int or sequence, default 10',\n",
       "         'param_desc': 'Number of histogram bins to be used. If an integer is given, bins + 1\\nbin edges are calculated and returned. If bins is a sequence, gives\\nbin edges, including left edge of first bin and right edge of last\\nbin. In this case, bins is returned unmodified.\\n'},\n",
       "        {'param_name': 'backend',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'Backend to use instead of the backend specified in the option\\nplotting.backend. For instance, ‘matplotlib’. Alternatively, to\\nspecify the plotting.backend for the whole session, set\\npd.options.plotting.backend.\\n'},\n",
       "        {'param_name': 'legend',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to show the legend.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.hist',\n",
       "       'descriptions': 'Draw histogram of the input series using matplotlib.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'by': {'type': 'object',\n",
       "          'description': 'object, optional. If passed, then used to form histograms for separate groups.\\n'},\n",
       "         'ax': {'type': 'object',\n",
       "          'description': 'matplotlib axis object. If not passed, uses gca().\\n'},\n",
       "         'grid': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to show axis grid lines.\\n'},\n",
       "         'xlabelsize': {'type': 'integer',\n",
       "          'description': 'int, default None. If specified changes the x-axis label size.\\n'},\n",
       "         'xrot': {'type': 'float',\n",
       "          'description': 'float, default None. Rotation of x axis labels.\\n'},\n",
       "         'ylabelsize': {'type': 'integer',\n",
       "          'description': 'int, default None. If specified changes the y-axis label size.\\n'},\n",
       "         'yrot': {'type': 'float',\n",
       "          'description': 'float, default None. Rotation of y axis labels.\\n'},\n",
       "         'figsize': {'type': 'tuple, default None',\n",
       "          'description': 'tuple, default None. Figure size in inches by default.\\n'},\n",
       "         'bins': {'type': 'integer',\n",
       "          'description': 'int or sequence, default 10. Number of histogram bins to be used. If an integer is given, bins + 1\\nbin edges are calculated and returned. If bins is a sequence, gives\\nbin edges, including left edge of first bin and right edge of last\\nbin. In this case, bins is returned unmodified.\\n'},\n",
       "         'backend': {'type': 'string',\n",
       "          'description': 'str, default None. Backend to use instead of the backend specified in the option\\nplotting.backend. For instance, ‘matplotlib’. Alternatively, to\\nspecify the plotting.backend for the whole session, set\\npd.options.plotting.backend.\\n'},\n",
       "         'legend': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to show the legend.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'SeriesGroupBy.plot',\n",
       "      'func_desc': 'Make plots of Series or DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.plot.html#pandas.core.groupby.SeriesGroupBy.plot',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.SeriesGroupBy.plot',\n",
       "       'full_function': 'property SeriesGroupBy.plot',\n",
       "       'function_text': 'Make plots of Series or DataFrame. Uses the backend specified by the\\noption plotting.backend. By default, matplotlib is used.',\n",
       "       'parameter_names_desc': [{'param_name': 'data',\n",
       "         'param_type': 'Series or DataFrame',\n",
       "         'param_desc': 'The object for which the method is called.\\n'},\n",
       "        {'param_name': 'x',\n",
       "         'param_type': 'label or position, default None',\n",
       "         'param_desc': 'Only used if data is a DataFrame.\\n'},\n",
       "        {'param_name': 'y',\n",
       "         'param_type': 'label, position or list of label, positions, default None',\n",
       "         'param_desc': 'Allows plotting of one column versus another. Only used if data is a\\nDataFrame.\\n'},\n",
       "        {'param_name': 'kind',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'The kind of plot to produce:\\n\\n‘line’ : line plot (default)\\n‘bar’ : vertical bar plot\\n‘barh’ : horizontal bar plot\\n‘hist’ : histogram\\n‘box’ : boxplot\\n‘kde’ : Kernel Density Estimation plot\\n‘density’ : same as ‘kde’\\n‘area’ : area plot\\n‘pie’ : pie plot\\n‘scatter’ : scatter plot (DataFrame only)\\n‘hexbin’ : hexbin plot (DataFrame only)\\n\\n'},\n",
       "        {'param_name': 'ax',\n",
       "         'param_type': 'matplotlib axes object, default None',\n",
       "         'param_desc': 'An axes of the current figure.\\n'},\n",
       "        {'param_name': 'subplots',\n",
       "         'param_type': 'bool or sequence of iterables, default False',\n",
       "         'param_desc': 'Whether to group columns into subplots:\\n\\nFalse : No subplots will be used\\nTrue : Make separate subplots for each column.\\nsequence of iterables of column labels: Create a subplot for each\\ngroup of columns. For example [(‘a’, ‘c’), (‘b’, ‘d’)] will\\ncreate 2 subplots: one with columns ‘a’ and ‘c’, and one\\nwith columns ‘b’ and ‘d’. Remaining columns that aren’t specified\\nwill be plotted in additional subplots (one per column).\\n\\nNew in version 1.5.0.\\n\\n\\n\\n'},\n",
       "        {'param_name': 'sharex',\n",
       "         'param_type': 'bool, default True if ax is None else False',\n",
       "         'param_desc': 'In case subplots=True, share x axis and set some x axis labels\\nto invisible; defaults to True if ax is None otherwise False if\\nan ax is passed in; Be aware, that passing in both an ax and\\nsharex=True will alter all x axis labels for all axis in a figure.\\n'},\n",
       "        {'param_name': 'sharey',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'In case subplots=True, share y axis and set some y axis labels to invisible.\\n'},\n",
       "        {'param_name': 'layout',\n",
       "         'param_type': 'tuple, optional',\n",
       "         'param_desc': '(rows, columns) for the layout of subplots.\\n'},\n",
       "        {'param_name': 'figsize',\n",
       "         'param_type': 'a tuple (width, height) in inches',\n",
       "         'param_desc': 'Size of a figure object.\\n'},\n",
       "        {'param_name': 'use_index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Use index as ticks for x axis.\\n'},\n",
       "        {'param_name': 'title',\n",
       "         'param_type': 'str or list',\n",
       "         'param_desc': 'Title to use for the plot. If a string is passed, print the string\\nat the top of the figure. If a list is passed and subplots is\\nTrue, print each item in the list above the corresponding subplot.\\n'},\n",
       "        {'param_name': 'grid',\n",
       "         'param_type': 'bool, default None (matlab style default)',\n",
       "         'param_desc': 'Axis grid lines.\\n'},\n",
       "        {'param_name': 'legend',\n",
       "         'param_type': 'bool or {‘reverse’}',\n",
       "         'param_desc': 'Place legend on axis subplots.\\n'},\n",
       "        {'param_name': 'style',\n",
       "         'param_type': 'list or dict',\n",
       "         'param_desc': 'The matplotlib line style per column.\\n'},\n",
       "        {'param_name': 'logx',\n",
       "         'param_type': 'bool or ‘sym’, default False',\n",
       "         'param_desc': 'Use log scaling or symlog scaling on x axis.\\n'},\n",
       "        {'param_name': 'logy',\n",
       "         'param_type': 'bool or ‘sym’ default False',\n",
       "         'param_desc': 'Use log scaling or symlog scaling on y axis.\\n'},\n",
       "        {'param_name': 'loglog',\n",
       "         'param_type': 'bool or ‘sym’, default False',\n",
       "         'param_desc': 'Use log scaling or symlog scaling on both x and y axes.\\n'},\n",
       "        {'param_name': 'xticks',\n",
       "         'param_type': 'sequence',\n",
       "         'param_desc': 'Values to use for the xticks.\\n'},\n",
       "        {'param_name': 'yticks',\n",
       "         'param_type': 'sequence',\n",
       "         'param_desc': 'Values to use for the yticks.\\n'},\n",
       "        {'param_name': 'xlim',\n",
       "         'param_type': '2-tuple/list',\n",
       "         'param_desc': 'Set the x limits of the current axes.\\n'},\n",
       "        {'param_name': 'ylim',\n",
       "         'param_type': '2-tuple/list',\n",
       "         'param_desc': 'Set the y limits of the current axes.\\n'},\n",
       "        {'param_name': 'xlabel',\n",
       "         'param_type': 'label, optional',\n",
       "         'param_desc': 'Name to use for the xlabel on x-axis. Default uses index name as xlabel, or the\\nx-column name for planar plots.\\n\\nChanged in version 2.0.0: Now applicable to histograms.\\n\\n'},\n",
       "        {'param_name': 'ylabel',\n",
       "         'param_type': 'label, optional',\n",
       "         'param_desc': 'Name to use for the ylabel on y-axis. Default will show no ylabel, or the\\ny-column name for planar plots.\\n\\nChanged in version 2.0.0: Now applicable to histograms.\\n\\n'},\n",
       "        {'param_name': 'rot',\n",
       "         'param_type': 'float, default None',\n",
       "         'param_desc': 'Rotation for ticks (xticks for vertical, yticks for horizontal\\nplots).\\n'},\n",
       "        {'param_name': 'fontsize',\n",
       "         'param_type': 'float, default None',\n",
       "         'param_desc': 'Font size for xticks and yticks.\\n'},\n",
       "        {'param_name': 'colormap',\n",
       "         'param_type': 'str or matplotlib colormap object, default None',\n",
       "         'param_desc': 'Colormap to select colors from. If string, load colormap with that\\nname from matplotlib.\\n'},\n",
       "        {'param_name': 'colorbar',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'If True, plot colorbar (only relevant for ‘scatter’ and ‘hexbin’\\nplots).\\n'},\n",
       "        {'param_name': 'position',\n",
       "         'param_type': 'float',\n",
       "         'param_desc': 'Specify relative alignments for bar plot layout.\\nFrom 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\\n(center).\\n'},\n",
       "        {'param_name': 'table',\n",
       "         'param_type': 'bool, Series or DataFrame, default False',\n",
       "         'param_desc': 'If True, draw a table using the data in the DataFrame and the data\\nwill be transposed to meet matplotlib’s default layout.\\nIf a Series or DataFrame is passed, use passed data to draw a\\ntable.\\n'},\n",
       "        {'param_name': 'yerr',\n",
       "         'param_type': 'DataFrame, Series, array-like, dict and str',\n",
       "         'param_desc': 'See Plotting with Error Bars for\\ndetail.\\n'},\n",
       "        {'param_name': 'xerr',\n",
       "         'param_type': 'DataFrame, Series, array-like, dict and str',\n",
       "         'param_desc': 'Equivalent to yerr.\\n'},\n",
       "        {'param_name': 'stacked',\n",
       "         'param_type': 'bool, default False in line and bar plots, and True in area plot',\n",
       "         'param_desc': 'If True, create stacked plot.\\n'},\n",
       "        {'param_name': 'secondary_y',\n",
       "         'param_type': 'bool or sequence, default False',\n",
       "         'param_desc': 'Whether to plot on the secondary y-axis if a list/tuple, which\\ncolumns to plot on secondary y-axis.\\n'},\n",
       "        {'param_name': 'mark_right',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'When using a secondary_y axis, automatically mark the column\\nlabels with “(right)” in the legend.\\n'},\n",
       "        {'param_name': 'include_bool',\n",
       "         'param_type': 'bool, default is False',\n",
       "         'param_desc': 'If True, boolean values can be plotted.\\n'},\n",
       "        {'param_name': 'backend',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'Backend to use instead of the backend specified in the option\\nplotting.backend. For instance, ‘matplotlib’. Alternatively, to\\nspecify the plotting.backend for the whole session, set\\npd.options.plotting.backend.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.SeriesGroupBy.plot',\n",
       "       'descriptions': 'Make plots of Series or DataFrame. Uses the backend specified by the\\noption plotting.backend. By default, matplotlib is used.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'data': {'type': 'Series or DataFrame',\n",
       "          'description': 'Series or DataFrame. The object for which the method is called.\\n'},\n",
       "         'x': {'type': 'label or position, default None',\n",
       "          'description': 'label or position, default None. Only used if data is a DataFrame.\\n'},\n",
       "         'y': {'type': 'array',\n",
       "          'description': 'label, position or list of label, positions, default None. Allows plotting of one column versus another. Only used if data is a\\nDataFrame.\\n'},\n",
       "         'kind': {'type': 'string',\n",
       "          'description': 'str. The kind of plot to produce:\\n\\n‘line’ : line plot (default)\\n‘bar’ : vertical bar plot\\n‘barh’ : horizontal bar plot\\n‘hist’ : histogram\\n‘box’ : boxplot\\n‘kde’ : Kernel Density Estimation plot\\n‘density’ : same as ‘kde’\\n‘area’ : area plot\\n‘pie’ : pie plot\\n‘scatter’ : scatter plot (DataFrame only)\\n‘hexbin’ : hexbin plot (DataFrame only)\\n\\n'},\n",
       "         'ax': {'type': 'object',\n",
       "          'description': 'matplotlib axes object, default None. An axes of the current figure.\\n'},\n",
       "         'subplots': {'type': 'boolean',\n",
       "          'description': 'bool or sequence of iterables, default False. Whether to group columns into subplots:\\n\\nFalse : No subplots will be used\\nTrue : Make separate subplots for each column.\\nsequence of iterables of column labels: Create a subplot for each\\ngroup of columns. For example [(‘a’, ‘c’), (‘b’, ‘d’)] will\\ncreate 2 subplots: one with columns ‘a’ and ‘c’, and one\\nwith columns ‘b’ and ‘d’. Remaining columns that aren’t specified\\nwill be plotted in additional subplots (one per column).\\n\\nNew in version 1.5.0.\\n\\n\\n\\n'},\n",
       "         'sharex': {'type': 'boolean',\n",
       "          'description': 'bool, default True if ax is None else False. In case subplots=True, share x axis and set some x axis labels\\nto invisible; defaults to True if ax is None otherwise False if\\nan ax is passed in; Be aware, that passing in both an ax and\\nsharex=True will alter all x axis labels for all axis in a figure.\\n'},\n",
       "         'sharey': {'type': 'boolean',\n",
       "          'description': 'bool, default False. In case subplots=True, share y axis and set some y axis labels to invisible.\\n'},\n",
       "         'layout': {'type': 'tuple, optional',\n",
       "          'description': 'tuple, optional. (rows, columns) for the layout of subplots.\\n'},\n",
       "         'figsize': {'type': 'a tuple (width, height) in inches',\n",
       "          'description': 'a tuple (width, height) in inches. Size of a figure object.\\n'},\n",
       "         'use_index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Use index as ticks for x axis.\\n'},\n",
       "         'title': {'type': 'string',\n",
       "          'description': 'str or list. Title to use for the plot. If a string is passed, print the string\\nat the top of the figure. If a list is passed and subplots is\\nTrue, print each item in the list above the corresponding subplot.\\n'},\n",
       "         'grid': {'type': 'boolean',\n",
       "          'description': 'bool, default None (matlab style default). Axis grid lines.\\n'},\n",
       "         'legend': {'type': 'boolean',\n",
       "          'description': 'bool or {‘reverse’}. Place legend on axis subplots.\\n'},\n",
       "         'style': {'type': 'array',\n",
       "          'description': 'list or dict. The matplotlib line style per column.\\n'},\n",
       "         'logx': {'type': 'boolean',\n",
       "          'description': 'bool or ‘sym’, default False. Use log scaling or symlog scaling on x axis.\\n'},\n",
       "         'logy': {'type': 'boolean',\n",
       "          'description': 'bool or ‘sym’ default False. Use log scaling or symlog scaling on y axis.\\n'},\n",
       "         'loglog': {'type': 'boolean',\n",
       "          'description': 'bool or ‘sym’, default False. Use log scaling or symlog scaling on both x and y axes.\\n'},\n",
       "         'xticks': {'type': 'sequence',\n",
       "          'description': 'sequence. Values to use for the xticks.\\n'},\n",
       "         'yticks': {'type': 'sequence',\n",
       "          'description': 'sequence. Values to use for the yticks.\\n'},\n",
       "         'xlim': {'type': 'array',\n",
       "          'description': '2-tuple/list. Set the x limits of the current axes.\\n'},\n",
       "         'ylim': {'type': 'array',\n",
       "          'description': '2-tuple/list. Set the y limits of the current axes.\\n'},\n",
       "         'xlabel': {'type': 'label, optional',\n",
       "          'description': 'label, optional. Name to use for the xlabel on x-axis. Default uses index name as xlabel, or the\\nx-column name for planar plots.\\n\\nChanged in version 2.0.0: Now applicable to histograms.\\n\\n'},\n",
       "         'ylabel': {'type': 'label, optional',\n",
       "          'description': 'label, optional. Name to use for the ylabel on y-axis. Default will show no ylabel, or the\\ny-column name for planar plots.\\n\\nChanged in version 2.0.0: Now applicable to histograms.\\n\\n'},\n",
       "         'rot': {'type': 'float',\n",
       "          'description': 'float, default None. Rotation for ticks (xticks for vertical, yticks for horizontal\\nplots).\\n'},\n",
       "         'fontsize': {'type': 'float',\n",
       "          'description': 'float, default None. Font size for xticks and yticks.\\n'},\n",
       "         'colormap': {'type': 'string',\n",
       "          'description': 'str or matplotlib colormap object, default None. Colormap to select colors from. If string, load colormap with that\\nname from matplotlib.\\n'},\n",
       "         'colorbar': {'type': 'boolean',\n",
       "          'description': 'bool, optional. If True, plot colorbar (only relevant for ‘scatter’ and ‘hexbin’\\nplots).\\n'},\n",
       "         'position': {'type': 'float',\n",
       "          'description': 'float. Specify relative alignments for bar plot layout.\\nFrom 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\\n(center).\\n'},\n",
       "         'table': {'type': 'boolean',\n",
       "          'description': 'bool, Series or DataFrame, default False. If True, draw a table using the data in the DataFrame and the data\\nwill be transposed to meet matplotlib’s default layout.\\nIf a Series or DataFrame is passed, use passed data to draw a\\ntable.\\n'},\n",
       "         'yerr': {'type': 'string',\n",
       "          'description': 'DataFrame, Series, array-like, dict and str. See Plotting with Error Bars for\\ndetail.\\n'},\n",
       "         'xerr': {'type': 'string',\n",
       "          'description': 'DataFrame, Series, array-like, dict and str. Equivalent to yerr.\\n'},\n",
       "         'stacked': {'type': 'boolean',\n",
       "          'description': 'bool, default False in line and bar plots, and True in area plot. If True, create stacked plot.\\n'},\n",
       "         'secondary_y': {'type': 'boolean',\n",
       "          'description': 'bool or sequence, default False. Whether to plot on the secondary y-axis if a list/tuple, which\\ncolumns to plot on secondary y-axis.\\n'},\n",
       "         'mark_right': {'type': 'boolean',\n",
       "          'description': 'bool, default True. When using a secondary_y axis, automatically mark the column\\nlabels with “(right)” in the legend.\\n'},\n",
       "         'include_bool': {'type': 'boolean',\n",
       "          'description': 'bool, default is False. If True, boolean values can be plotted.\\n'},\n",
       "         'backend': {'type': 'string',\n",
       "          'description': 'str, default None. Backend to use instead of the backend specified in the option\\nplotting.backend. For instance, ‘matplotlib’. Alternatively, to\\nspecify the plotting.backend for the whole session, set\\npd.options.plotting.backend.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.hist([column,\\xa0by,\\xa0grid,\\xa0...])',\n",
       "      'func_desc': \"Make a histogram of the DataFrame's columns.\",\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.hist.html#pandas.core.groupby.DataFrameGroupBy.hist',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.hist',\n",
       "       'full_function': 'DataFrameGroupBy.hist(column=None, by=None, grid=True, xlabelsize=None, xrot=None, ylabelsize=None, yrot=None, ax=None, sharex=False, sharey=False, figsize=None, layout=None, bins=10, backend=None, legend=False, **kwargs)',\n",
       "       'function_text': 'Make a histogram of the DataFrame’s columns. A histogram is a representation of the distribution of data.\\nThis function calls matplotlib.pyplot.hist(), on each series in\\nthe DataFrame, resulting in one histogram per column.',\n",
       "       'parameter_names_desc': [{'param_name': 'data',\n",
       "         'param_type': 'DataFrame',\n",
       "         'param_desc': 'The pandas object holding the data.\\n'},\n",
       "        {'param_name': 'column',\n",
       "         'param_type': 'str or sequence, optional',\n",
       "         'param_desc': 'If passed, will be used to limit data to a subset of columns.\\n'},\n",
       "        {'param_name': 'by',\n",
       "         'param_type': 'object, optional',\n",
       "         'param_desc': 'If passed, then used to form histograms for separate groups.\\n'},\n",
       "        {'param_name': 'grid',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to show axis grid lines.\\n'},\n",
       "        {'param_name': 'xlabelsize',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'If specified changes the x-axis label size.\\n'},\n",
       "        {'param_name': 'xrot',\n",
       "         'param_type': 'float, default None',\n",
       "         'param_desc': 'Rotation of x axis labels. For example, a value of 90 displays the\\nx labels rotated 90 degrees clockwise.\\n'},\n",
       "        {'param_name': 'ylabelsize',\n",
       "         'param_type': 'int, default None',\n",
       "         'param_desc': 'If specified changes the y-axis label size.\\n'},\n",
       "        {'param_name': 'yrot',\n",
       "         'param_type': 'float, default None',\n",
       "         'param_desc': 'Rotation of y axis labels. For example, a value of 90 displays the\\ny labels rotated 90 degrees clockwise.\\n'},\n",
       "        {'param_name': 'ax',\n",
       "         'param_type': 'Matplotlib axes object, default None',\n",
       "         'param_desc': 'The axes to plot the histogram on.\\n'},\n",
       "        {'param_name': 'sharex',\n",
       "         'param_type': 'bool, default True if ax is None else False',\n",
       "         'param_desc': 'In case subplots=True, share x axis and set some x axis labels to\\ninvisible; defaults to True if ax is None otherwise False if an ax\\nis passed in.\\nNote that passing in both an ax and sharex=True will alter all x axis\\nlabels for all subplots in a figure.\\n'},\n",
       "        {'param_name': 'sharey',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'In case subplots=True, share y axis and set some y axis labels to\\ninvisible.\\n'},\n",
       "        {'param_name': 'figsize',\n",
       "         'param_type': 'tuple, optional',\n",
       "         'param_desc': 'The size in inches of the figure to create. Uses the value in\\nmatplotlib.rcParams by default.\\n'},\n",
       "        {'param_name': 'layout',\n",
       "         'param_type': 'tuple, optional',\n",
       "         'param_desc': 'Tuple of (rows, columns) for the layout of the histograms.\\n'},\n",
       "        {'param_name': 'bins',\n",
       "         'param_type': 'int or sequence, default 10',\n",
       "         'param_desc': 'Number of histogram bins to be used. If an integer is given, bins + 1\\nbin edges are calculated and returned. If bins is a sequence, gives\\nbin edges, including left edge of first bin and right edge of last\\nbin. In this case, bins is returned unmodified.\\n'},\n",
       "        {'param_name': 'backend',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'Backend to use instead of the backend specified in the option\\nplotting.backend. For instance, ‘matplotlib’. Alternatively, to\\nspecify the plotting.backend for the whole session, set\\npd.options.plotting.backend.\\n'},\n",
       "        {'param_name': 'legend',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to show the legend.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.hist',\n",
       "       'descriptions': 'Make a histogram of the DataFrame’s columns. A histogram is a representation of the distribution of data.\\nThis function calls matplotlib.pyplot.hist(), on each series in\\nthe DataFrame, resulting in one histogram per column.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'data': {'type': 'DataFrame',\n",
       "          'description': 'DataFrame. The pandas object holding the data.\\n'},\n",
       "         'column': {'type': 'string',\n",
       "          'description': 'str or sequence, optional. If passed, will be used to limit data to a subset of columns.\\n'},\n",
       "         'by': {'type': 'object',\n",
       "          'description': 'object, optional. If passed, then used to form histograms for separate groups.\\n'},\n",
       "         'grid': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to show axis grid lines.\\n'},\n",
       "         'xlabelsize': {'type': 'integer',\n",
       "          'description': 'int, default None. If specified changes the x-axis label size.\\n'},\n",
       "         'xrot': {'type': 'float',\n",
       "          'description': 'float, default None. Rotation of x axis labels. For example, a value of 90 displays the\\nx labels rotated 90 degrees clockwise.\\n'},\n",
       "         'ylabelsize': {'type': 'integer',\n",
       "          'description': 'int, default None. If specified changes the y-axis label size.\\n'},\n",
       "         'yrot': {'type': 'float',\n",
       "          'description': 'float, default None. Rotation of y axis labels. For example, a value of 90 displays the\\ny labels rotated 90 degrees clockwise.\\n'},\n",
       "         'ax': {'type': 'object',\n",
       "          'description': 'Matplotlib axes object, default None. The axes to plot the histogram on.\\n'},\n",
       "         'sharex': {'type': 'boolean',\n",
       "          'description': 'bool, default True if ax is None else False. In case subplots=True, share x axis and set some x axis labels to\\ninvisible; defaults to True if ax is None otherwise False if an ax\\nis passed in.\\nNote that passing in both an ax and sharex=True will alter all x axis\\nlabels for all subplots in a figure.\\n'},\n",
       "         'sharey': {'type': 'boolean',\n",
       "          'description': 'bool, default False. In case subplots=True, share y axis and set some y axis labels to\\ninvisible.\\n'},\n",
       "         'figsize': {'type': 'tuple, optional',\n",
       "          'description': 'tuple, optional. The size in inches of the figure to create. Uses the value in\\nmatplotlib.rcParams by default.\\n'},\n",
       "         'layout': {'type': 'tuple, optional',\n",
       "          'description': 'tuple, optional. Tuple of (rows, columns) for the layout of the histograms.\\n'},\n",
       "         'bins': {'type': 'integer',\n",
       "          'description': 'int or sequence, default 10. Number of histogram bins to be used. If an integer is given, bins + 1\\nbin edges are calculated and returned. If bins is a sequence, gives\\nbin edges, including left edge of first bin and right edge of last\\nbin. In this case, bins is returned unmodified.\\n'},\n",
       "         'backend': {'type': 'string',\n",
       "          'description': 'str, default None. Backend to use instead of the backend specified in the option\\nplotting.backend. For instance, ‘matplotlib’. Alternatively, to\\nspecify the plotting.backend for the whole session, set\\npd.options.plotting.backend.\\n'},\n",
       "         'legend': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to show the legend.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'DataFrameGroupBy.plot',\n",
       "      'func_desc': 'Make plots of Series or DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.plot.html#pandas.core.groupby.DataFrameGroupBy.plot',\n",
       "      'function_definitions': {'function_name': 'pandas.core.groupby.DataFrameGroupBy.plot',\n",
       "       'full_function': 'property DataFrameGroupBy.plot',\n",
       "       'function_text': 'Make plots of Series or DataFrame. Uses the backend specified by the\\noption plotting.backend. By default, matplotlib is used.',\n",
       "       'parameter_names_desc': [{'param_name': 'data',\n",
       "         'param_type': 'Series or DataFrame',\n",
       "         'param_desc': 'The object for which the method is called.\\n'},\n",
       "        {'param_name': 'x',\n",
       "         'param_type': 'label or position, default None',\n",
       "         'param_desc': 'Only used if data is a DataFrame.\\n'},\n",
       "        {'param_name': 'y',\n",
       "         'param_type': 'label, position or list of label, positions, default None',\n",
       "         'param_desc': 'Allows plotting of one column versus another. Only used if data is a\\nDataFrame.\\n'},\n",
       "        {'param_name': 'kind',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'The kind of plot to produce:\\n\\n‘line’ : line plot (default)\\n‘bar’ : vertical bar plot\\n‘barh’ : horizontal bar plot\\n‘hist’ : histogram\\n‘box’ : boxplot\\n‘kde’ : Kernel Density Estimation plot\\n‘density’ : same as ‘kde’\\n‘area’ : area plot\\n‘pie’ : pie plot\\n‘scatter’ : scatter plot (DataFrame only)\\n‘hexbin’ : hexbin plot (DataFrame only)\\n\\n'},\n",
       "        {'param_name': 'ax',\n",
       "         'param_type': 'matplotlib axes object, default None',\n",
       "         'param_desc': 'An axes of the current figure.\\n'},\n",
       "        {'param_name': 'subplots',\n",
       "         'param_type': 'bool or sequence of iterables, default False',\n",
       "         'param_desc': 'Whether to group columns into subplots:\\n\\nFalse : No subplots will be used\\nTrue : Make separate subplots for each column.\\nsequence of iterables of column labels: Create a subplot for each\\ngroup of columns. For example [(‘a’, ‘c’), (‘b’, ‘d’)] will\\ncreate 2 subplots: one with columns ‘a’ and ‘c’, and one\\nwith columns ‘b’ and ‘d’. Remaining columns that aren’t specified\\nwill be plotted in additional subplots (one per column).\\n\\nNew in version 1.5.0.\\n\\n\\n\\n'},\n",
       "        {'param_name': 'sharex',\n",
       "         'param_type': 'bool, default True if ax is None else False',\n",
       "         'param_desc': 'In case subplots=True, share x axis and set some x axis labels\\nto invisible; defaults to True if ax is None otherwise False if\\nan ax is passed in; Be aware, that passing in both an ax and\\nsharex=True will alter all x axis labels for all axis in a figure.\\n'},\n",
       "        {'param_name': 'sharey',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'In case subplots=True, share y axis and set some y axis labels to invisible.\\n'},\n",
       "        {'param_name': 'layout',\n",
       "         'param_type': 'tuple, optional',\n",
       "         'param_desc': '(rows, columns) for the layout of subplots.\\n'},\n",
       "        {'param_name': 'figsize',\n",
       "         'param_type': 'a tuple (width, height) in inches',\n",
       "         'param_desc': 'Size of a figure object.\\n'},\n",
       "        {'param_name': 'use_index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Use index as ticks for x axis.\\n'},\n",
       "        {'param_name': 'title',\n",
       "         'param_type': 'str or list',\n",
       "         'param_desc': 'Title to use for the plot. If a string is passed, print the string\\nat the top of the figure. If a list is passed and subplots is\\nTrue, print each item in the list above the corresponding subplot.\\n'},\n",
       "        {'param_name': 'grid',\n",
       "         'param_type': 'bool, default None (matlab style default)',\n",
       "         'param_desc': 'Axis grid lines.\\n'},\n",
       "        {'param_name': 'legend',\n",
       "         'param_type': 'bool or {‘reverse’}',\n",
       "         'param_desc': 'Place legend on axis subplots.\\n'},\n",
       "        {'param_name': 'style',\n",
       "         'param_type': 'list or dict',\n",
       "         'param_desc': 'The matplotlib line style per column.\\n'},\n",
       "        {'param_name': 'logx',\n",
       "         'param_type': 'bool or ‘sym’, default False',\n",
       "         'param_desc': 'Use log scaling or symlog scaling on x axis.\\n'},\n",
       "        {'param_name': 'logy',\n",
       "         'param_type': 'bool or ‘sym’ default False',\n",
       "         'param_desc': 'Use log scaling or symlog scaling on y axis.\\n'},\n",
       "        {'param_name': 'loglog',\n",
       "         'param_type': 'bool or ‘sym’, default False',\n",
       "         'param_desc': 'Use log scaling or symlog scaling on both x and y axes.\\n'},\n",
       "        {'param_name': 'xticks',\n",
       "         'param_type': 'sequence',\n",
       "         'param_desc': 'Values to use for the xticks.\\n'},\n",
       "        {'param_name': 'yticks',\n",
       "         'param_type': 'sequence',\n",
       "         'param_desc': 'Values to use for the yticks.\\n'},\n",
       "        {'param_name': 'xlim',\n",
       "         'param_type': '2-tuple/list',\n",
       "         'param_desc': 'Set the x limits of the current axes.\\n'},\n",
       "        {'param_name': 'ylim',\n",
       "         'param_type': '2-tuple/list',\n",
       "         'param_desc': 'Set the y limits of the current axes.\\n'},\n",
       "        {'param_name': 'xlabel',\n",
       "         'param_type': 'label, optional',\n",
       "         'param_desc': 'Name to use for the xlabel on x-axis. Default uses index name as xlabel, or the\\nx-column name for planar plots.\\n\\nChanged in version 2.0.0: Now applicable to histograms.\\n\\n'},\n",
       "        {'param_name': 'ylabel',\n",
       "         'param_type': 'label, optional',\n",
       "         'param_desc': 'Name to use for the ylabel on y-axis. Default will show no ylabel, or the\\ny-column name for planar plots.\\n\\nChanged in version 2.0.0: Now applicable to histograms.\\n\\n'},\n",
       "        {'param_name': 'rot',\n",
       "         'param_type': 'float, default None',\n",
       "         'param_desc': 'Rotation for ticks (xticks for vertical, yticks for horizontal\\nplots).\\n'},\n",
       "        {'param_name': 'fontsize',\n",
       "         'param_type': 'float, default None',\n",
       "         'param_desc': 'Font size for xticks and yticks.\\n'},\n",
       "        {'param_name': 'colormap',\n",
       "         'param_type': 'str or matplotlib colormap object, default None',\n",
       "         'param_desc': 'Colormap to select colors from. If string, load colormap with that\\nname from matplotlib.\\n'},\n",
       "        {'param_name': 'colorbar',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'If True, plot colorbar (only relevant for ‘scatter’ and ‘hexbin’\\nplots).\\n'},\n",
       "        {'param_name': 'position',\n",
       "         'param_type': 'float',\n",
       "         'param_desc': 'Specify relative alignments for bar plot layout.\\nFrom 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\\n(center).\\n'},\n",
       "        {'param_name': 'table',\n",
       "         'param_type': 'bool, Series or DataFrame, default False',\n",
       "         'param_desc': 'If True, draw a table using the data in the DataFrame and the data\\nwill be transposed to meet matplotlib’s default layout.\\nIf a Series or DataFrame is passed, use passed data to draw a\\ntable.\\n'},\n",
       "        {'param_name': 'yerr',\n",
       "         'param_type': 'DataFrame, Series, array-like, dict and str',\n",
       "         'param_desc': 'See Plotting with Error Bars for\\ndetail.\\n'},\n",
       "        {'param_name': 'xerr',\n",
       "         'param_type': 'DataFrame, Series, array-like, dict and str',\n",
       "         'param_desc': 'Equivalent to yerr.\\n'},\n",
       "        {'param_name': 'stacked',\n",
       "         'param_type': 'bool, default False in line and bar plots, and True in area plot',\n",
       "         'param_desc': 'If True, create stacked plot.\\n'},\n",
       "        {'param_name': 'secondary_y',\n",
       "         'param_type': 'bool or sequence, default False',\n",
       "         'param_desc': 'Whether to plot on the secondary y-axis if a list/tuple, which\\ncolumns to plot on secondary y-axis.\\n'},\n",
       "        {'param_name': 'mark_right',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'When using a secondary_y axis, automatically mark the column\\nlabels with “(right)” in the legend.\\n'},\n",
       "        {'param_name': 'include_bool',\n",
       "         'param_type': 'bool, default is False',\n",
       "         'param_desc': 'If True, boolean values can be plotted.\\n'},\n",
       "        {'param_name': 'backend',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'Backend to use instead of the backend specified in the option\\nplotting.backend. For instance, ‘matplotlib’. Alternatively, to\\nspecify the plotting.backend for the whole session, set\\npd.options.plotting.backend.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.groupby.DataFrameGroupBy.plot',\n",
       "       'descriptions': 'Make plots of Series or DataFrame. Uses the backend specified by the\\noption plotting.backend. By default, matplotlib is used.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'data': {'type': 'Series or DataFrame',\n",
       "          'description': 'Series or DataFrame. The object for which the method is called.\\n'},\n",
       "         'x': {'type': 'label or position, default None',\n",
       "          'description': 'label or position, default None. Only used if data is a DataFrame.\\n'},\n",
       "         'y': {'type': 'array',\n",
       "          'description': 'label, position or list of label, positions, default None. Allows plotting of one column versus another. Only used if data is a\\nDataFrame.\\n'},\n",
       "         'kind': {'type': 'string',\n",
       "          'description': 'str. The kind of plot to produce:\\n\\n‘line’ : line plot (default)\\n‘bar’ : vertical bar plot\\n‘barh’ : horizontal bar plot\\n‘hist’ : histogram\\n‘box’ : boxplot\\n‘kde’ : Kernel Density Estimation plot\\n‘density’ : same as ‘kde’\\n‘area’ : area plot\\n‘pie’ : pie plot\\n‘scatter’ : scatter plot (DataFrame only)\\n‘hexbin’ : hexbin plot (DataFrame only)\\n\\n'},\n",
       "         'ax': {'type': 'object',\n",
       "          'description': 'matplotlib axes object, default None. An axes of the current figure.\\n'},\n",
       "         'subplots': {'type': 'boolean',\n",
       "          'description': 'bool or sequence of iterables, default False. Whether to group columns into subplots:\\n\\nFalse : No subplots will be used\\nTrue : Make separate subplots for each column.\\nsequence of iterables of column labels: Create a subplot for each\\ngroup of columns. For example [(‘a’, ‘c’), (‘b’, ‘d’)] will\\ncreate 2 subplots: one with columns ‘a’ and ‘c’, and one\\nwith columns ‘b’ and ‘d’. Remaining columns that aren’t specified\\nwill be plotted in additional subplots (one per column).\\n\\nNew in version 1.5.0.\\n\\n\\n\\n'},\n",
       "         'sharex': {'type': 'boolean',\n",
       "          'description': 'bool, default True if ax is None else False. In case subplots=True, share x axis and set some x axis labels\\nto invisible; defaults to True if ax is None otherwise False if\\nan ax is passed in; Be aware, that passing in both an ax and\\nsharex=True will alter all x axis labels for all axis in a figure.\\n'},\n",
       "         'sharey': {'type': 'boolean',\n",
       "          'description': 'bool, default False. In case subplots=True, share y axis and set some y axis labels to invisible.\\n'},\n",
       "         'layout': {'type': 'tuple, optional',\n",
       "          'description': 'tuple, optional. (rows, columns) for the layout of subplots.\\n'},\n",
       "         'figsize': {'type': 'a tuple (width, height) in inches',\n",
       "          'description': 'a tuple (width, height) in inches. Size of a figure object.\\n'},\n",
       "         'use_index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Use index as ticks for x axis.\\n'},\n",
       "         'title': {'type': 'string',\n",
       "          'description': 'str or list. Title to use for the plot. If a string is passed, print the string\\nat the top of the figure. If a list is passed and subplots is\\nTrue, print each item in the list above the corresponding subplot.\\n'},\n",
       "         'grid': {'type': 'boolean',\n",
       "          'description': 'bool, default None (matlab style default). Axis grid lines.\\n'},\n",
       "         'legend': {'type': 'boolean',\n",
       "          'description': 'bool or {‘reverse’}. Place legend on axis subplots.\\n'},\n",
       "         'style': {'type': 'array',\n",
       "          'description': 'list or dict. The matplotlib line style per column.\\n'},\n",
       "         'logx': {'type': 'boolean',\n",
       "          'description': 'bool or ‘sym’, default False. Use log scaling or symlog scaling on x axis.\\n'},\n",
       "         'logy': {'type': 'boolean',\n",
       "          'description': 'bool or ‘sym’ default False. Use log scaling or symlog scaling on y axis.\\n'},\n",
       "         'loglog': {'type': 'boolean',\n",
       "          'description': 'bool or ‘sym’, default False. Use log scaling or symlog scaling on both x and y axes.\\n'},\n",
       "         'xticks': {'type': 'sequence',\n",
       "          'description': 'sequence. Values to use for the xticks.\\n'},\n",
       "         'yticks': {'type': 'sequence',\n",
       "          'description': 'sequence. Values to use for the yticks.\\n'},\n",
       "         'xlim': {'type': 'array',\n",
       "          'description': '2-tuple/list. Set the x limits of the current axes.\\n'},\n",
       "         'ylim': {'type': 'array',\n",
       "          'description': '2-tuple/list. Set the y limits of the current axes.\\n'},\n",
       "         'xlabel': {'type': 'label, optional',\n",
       "          'description': 'label, optional. Name to use for the xlabel on x-axis. Default uses index name as xlabel, or the\\nx-column name for planar plots.\\n\\nChanged in version 2.0.0: Now applicable to histograms.\\n\\n'},\n",
       "         'ylabel': {'type': 'label, optional',\n",
       "          'description': 'label, optional. Name to use for the ylabel on y-axis. Default will show no ylabel, or the\\ny-column name for planar plots.\\n\\nChanged in version 2.0.0: Now applicable to histograms.\\n\\n'},\n",
       "         'rot': {'type': 'float',\n",
       "          'description': 'float, default None. Rotation for ticks (xticks for vertical, yticks for horizontal\\nplots).\\n'},\n",
       "         'fontsize': {'type': 'float',\n",
       "          'description': 'float, default None. Font size for xticks and yticks.\\n'},\n",
       "         'colormap': {'type': 'string',\n",
       "          'description': 'str or matplotlib colormap object, default None. Colormap to select colors from. If string, load colormap with that\\nname from matplotlib.\\n'},\n",
       "         'colorbar': {'type': 'boolean',\n",
       "          'description': 'bool, optional. If True, plot colorbar (only relevant for ‘scatter’ and ‘hexbin’\\nplots).\\n'},\n",
       "         'position': {'type': 'float',\n",
       "          'description': 'float. Specify relative alignments for bar plot layout.\\nFrom 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\\n(center).\\n'},\n",
       "         'table': {'type': 'boolean',\n",
       "          'description': 'bool, Series or DataFrame, default False. If True, draw a table using the data in the DataFrame and the data\\nwill be transposed to meet matplotlib’s default layout.\\nIf a Series or DataFrame is passed, use passed data to draw a\\ntable.\\n'},\n",
       "         'yerr': {'type': 'string',\n",
       "          'description': 'DataFrame, Series, array-like, dict and str. See Plotting with Error Bars for\\ndetail.\\n'},\n",
       "         'xerr': {'type': 'string',\n",
       "          'description': 'DataFrame, Series, array-like, dict and str. Equivalent to yerr.\\n'},\n",
       "         'stacked': {'type': 'boolean',\n",
       "          'description': 'bool, default False in line and bar plots, and True in area plot. If True, create stacked plot.\\n'},\n",
       "         'secondary_y': {'type': 'boolean',\n",
       "          'description': 'bool or sequence, default False. Whether to plot on the secondary y-axis if a list/tuple, which\\ncolumns to plot on secondary y-axis.\\n'},\n",
       "         'mark_right': {'type': 'boolean',\n",
       "          'description': 'bool, default True. When using a secondary_y axis, automatically mark the column\\nlabels with “(right)” in the legend.\\n'},\n",
       "         'include_bool': {'type': 'boolean',\n",
       "          'description': 'bool, default is False. If True, boolean values can be plotted.\\n'},\n",
       "         'backend': {'type': 'string',\n",
       "          'description': 'str, default None. Backend to use instead of the backend specified in the option\\nplotting.backend. For instance, ‘matplotlib’. Alternatively, to\\nspecify the plotting.backend for the whole session, set\\npd.options.plotting.backend.\\n'}},\n",
       "        'required': []}}}]}],\n",
       "  'name': 'GroupBy',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/groupby.html'},\n",
       " 'resampling.html': {'functions': [{'Indexing, iteration': [{'func_name': 'Resampler.__iter__()',\n",
       "      'func_desc': 'Groupby iterator.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.__iter__.html#pandas.core.resample.Resampler.__iter__',\n",
       "      'function_definitions': {'function_name': 'pandas.core.resample.Resampler.__iter__',\n",
       "       'full_function': 'Resampler.__iter__()',\n",
       "       'function_text': 'Groupby iterator.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Resampler.indices',\n",
       "      'func_desc': 'Dict {group name -> group indices}.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.indices.html#pandas.core.resample.Resampler.indices',\n",
       "      'function_definitions': {'function_name': 'pandas.core.resample.Resampler.indices',\n",
       "       'full_function': 'property Resampler.indices',\n",
       "       'function_text': 'Dict {group name -> group indices}. Examples For SeriesGroupBy: For DataFrameGroupBy: For Resampler:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Resampler.groups',\n",
       "      'func_desc': 'Dict {group name -> group labels}.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.groups.html#pandas.core.resample.Resampler.groups',\n",
       "      'function_definitions': {'function_name': 'pandas.core.resample.Resampler.groups',\n",
       "       'full_function': 'property Resampler.groups',\n",
       "       'function_text': 'Dict {group name -> group labels}. Examples For SeriesGroupBy: For DataFrameGroupBy: For Resampler:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Resampler.get_group(name[,\\xa0obj])',\n",
       "      'func_desc': 'Construct DataFrame from group with provided name.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.get_group.html#pandas.core.resample.Resampler.get_group',\n",
       "      'function_definitions': {'function_name': 'pandas.core.resample.Resampler.get_group',\n",
       "       'full_function': 'Resampler.get_group(name, obj=None)',\n",
       "       'function_text': 'Construct DataFrame from group with provided name.',\n",
       "       'parameter_names_desc': [{'param_name': 'name',\n",
       "         'param_type': 'object',\n",
       "         'param_desc': 'The name of the group to get as a DataFrame.\\n'},\n",
       "        {'param_name': 'obj',\n",
       "         'param_type': 'DataFrame, default None',\n",
       "         'param_desc': 'The DataFrame to take the DataFrame out of. If\\nit is None, the object groupby was called on will\\nbe used.\\n\\nDeprecated since version 2.1.0: The obj is deprecated and will be removed in a future version.\\nDo df.iloc[gb.indices.get(name)]\\ninstead of gb.get_group(name, obj=df).\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.resample.Resampler.get_group',\n",
       "       'descriptions': 'Construct DataFrame from group with provided name.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'name': {'type': 'object',\n",
       "          'description': 'object. The name of the group to get as a DataFrame.\\n'},\n",
       "         'obj': {'type': 'DataFrame, default None',\n",
       "          'description': 'DataFrame, default None. The DataFrame to take the DataFrame out of. If\\nit is None, the object groupby was called on will\\nbe used.\\n\\nDeprecated since version 2.1.0: The obj is deprecated and will be removed in a future version.\\nDo df.iloc[gb.indices.get(name)]\\ninstead of gb.get_group(name, obj=df).\\n\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Function application': [{'func_name': 'Resampler.apply([func])',\n",
       "      'func_desc': 'Aggregate using one or more operations over the specified axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.apply.html#pandas.core.resample.Resampler.apply',\n",
       "      'function_definitions': {'function_name': 'pandas.core.resample.Resampler.apply',\n",
       "       'full_function': 'Resampler.apply(func=None, *args, **kwargs)',\n",
       "       'function_text': 'Aggregate using one or more operations over the specified axis.',\n",
       "       'parameter_names_desc': [{'param_name': 'func',\n",
       "         'param_type': 'function, str, list or dict',\n",
       "         'param_desc': \"Function to use for aggregating the data. If a function, must either\\nwork when passed a DataFrame or when passed to DataFrame.apply.\\nAccepted combinations are:\\n\\nfunction\\nstring function name\\nlist of functions and/or function names, e.g. [np.sum, 'mean']\\ndict of axis labels -> functions, function names or list of such.\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.resample.Resampler.apply',\n",
       "       'descriptions': 'Aggregate using one or more operations over the specified axis.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'func': {'type': 'string',\n",
       "          'description': \"function, str, list or dict. Function to use for aggregating the data. If a function, must either\\nwork when passed a DataFrame or when passed to DataFrame.apply.\\nAccepted combinations are:\\n\\nfunction\\nstring function name\\nlist of functions and/or function names, e.g. [np.sum, 'mean']\\ndict of axis labels -> functions, function names or list of such.\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Resampler.transform(arg,\\xa0*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Call function producing a like-indexed Series on each group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.transform.html#pandas.core.resample.Resampler.transform',\n",
       "      'function_definitions': {'function_name': 'pandas.core.resample.Resampler.transform',\n",
       "       'full_function': 'final Resampler.transform(arg, *args, **kwargs)',\n",
       "       'function_text': 'Call function producing a like-indexed Series on each group. Return a Series with the transformed values.',\n",
       "       'parameter_names_desc': [{'param_name': 'arg',\n",
       "         'param_type': 'function',\n",
       "         'param_desc': 'To apply to each group. Should return a Series with the same index.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.resample.Resampler.transform',\n",
       "       'descriptions': 'Call function producing a like-indexed Series on each group. Return a Series with the transformed values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'arg': {'type': 'function',\n",
       "          'description': 'function. To apply to each group. Should return a Series with the same index.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Resampler.aggregate([func])',\n",
       "      'func_desc': 'Aggregate using one or more operations over the specified axis.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.aggregate.html#pandas.core.resample.Resampler.aggregate',\n",
       "      'function_definitions': {'function_name': 'pandas.core.resample.Resampler.aggregate',\n",
       "       'full_function': 'final Resampler.aggregate(func=None, *args, **kwargs)',\n",
       "       'function_text': 'Aggregate using one or more operations over the specified axis.',\n",
       "       'parameter_names_desc': [{'param_name': 'func',\n",
       "         'param_type': 'function, str, list or dict',\n",
       "         'param_desc': \"Function to use for aggregating the data. If a function, must either\\nwork when passed a DataFrame or when passed to DataFrame.apply.\\nAccepted combinations are:\\n\\nfunction\\nstring function name\\nlist of functions and/or function names, e.g. [np.sum, 'mean']\\ndict of axis labels -> functions, function names or list of such.\\n\\n\"}]},\n",
       "      'function_calling': {'name': 'pandas.core.resample.Resampler.aggregate',\n",
       "       'descriptions': 'Aggregate using one or more operations over the specified axis.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'func': {'type': 'string',\n",
       "          'description': \"function, str, list or dict. Function to use for aggregating the data. If a function, must either\\nwork when passed a DataFrame or when passed to DataFrame.apply.\\nAccepted combinations are:\\n\\nfunction\\nstring function name\\nlist of functions and/or function names, e.g. [np.sum, 'mean']\\ndict of axis labels -> functions, function names or list of such.\\n\\n\"}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Resampler.pipe(func,\\xa0*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Apply a func with arguments to this Resampler object and return its result.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.pipe.html#pandas.core.resample.Resampler.pipe',\n",
       "      'function_definitions': {'function_name': 'pandas.core.resample.Resampler.pipe',\n",
       "       'full_function': 'final Resampler.pipe(func, *args, **kwargs)',\n",
       "       'function_text': 'Apply a func with arguments to this Resampler object and return its result. Use .pipe when you want to improve readability by chaining together\\nfunctions that expect Series, DataFrames, GroupBy or Resampler objects.\\nInstead of writing You can write which is much more readable.',\n",
       "       'parameter_names_desc': [{'param_name': 'func',\n",
       "         'param_type': 'callable or tuple of (callable, str)',\n",
       "         'param_desc': 'Function to apply to this Resampler object or, alternatively,\\na (callable, data_keyword) tuple where data_keyword is a\\nstring indicating the keyword of callable that expects the\\nResampler object.\\n'},\n",
       "        {'param_name': 'args',\n",
       "         'param_type': 'iterable, optional',\n",
       "         'param_desc': 'Positional arguments passed into func.\\n'},\n",
       "        {'param_name': 'kwargs',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'A dictionary of keyword arguments passed into func.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.resample.Resampler.pipe',\n",
       "       'descriptions': 'Apply a func with arguments to this Resampler object and return its result. Use .pipe when you want to improve readability by chaining together\\nfunctions that expect Series, DataFrames, GroupBy or Resampler objects.\\nInstead of writing You can write which is much more readable.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'func': {'type': 'string',\n",
       "          'description': 'callable or tuple of (callable, str). Function to apply to this Resampler object or, alternatively,\\na (callable, data_keyword) tuple where data_keyword is a\\nstring indicating the keyword of callable that expects the\\nResampler object.\\n'},\n",
       "         'args': {'type': 'iterable, optional',\n",
       "          'description': 'iterable, optional. Positional arguments passed into func.\\n'},\n",
       "         'kwargs': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. A dictionary of keyword arguments passed into func.\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Upsampling': [{'func_name': 'Resampler.ffill([limit])',\n",
       "      'func_desc': 'Forward fill the values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.ffill.html#pandas.core.resample.Resampler.ffill',\n",
       "      'function_definitions': {'function_name': 'pandas.core.resample.Resampler.ffill',\n",
       "       'full_function': 'final Resampler.ffill(limit=None)',\n",
       "       'function_text': 'Forward fill the values.',\n",
       "       'parameter_names_desc': [{'param_name': 'limit',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Limit of how many values to fill.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.resample.Resampler.ffill',\n",
       "       'descriptions': 'Forward fill the values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'limit': {'type': 'integer',\n",
       "          'description': 'int, optional. Limit of how many values to fill.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Resampler.nearest([limit])',\n",
       "      'func_desc': 'Resample by using the nearest value.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.nearest.html#pandas.core.resample.Resampler.nearest',\n",
       "      'function_definitions': {'function_name': 'pandas.core.resample.Resampler.nearest',\n",
       "       'full_function': 'final Resampler.nearest(limit=None)',\n",
       "       'function_text': 'Resample by using the nearest value. When resampling data, missing values may appear (e.g., when the\\nresampling frequency is higher than the original frequency).\\nThe nearest method will replace NaN values that appeared in\\nthe resampled data with the value from the nearest member of the\\nsequence, based on the index value.\\nMissing values that existed in the original data will not be modified.\\nIf limit is given, fill only this many values in each direction for\\neach of the original values.',\n",
       "       'parameter_names_desc': [{'param_name': 'limit',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Limit of how many values to fill.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.resample.Resampler.nearest',\n",
       "       'descriptions': 'Resample by using the nearest value. When resampling data, missing values may appear (e.g., when the\\nresampling frequency is higher than the original frequency).\\nThe nearest method will replace NaN values that appeared in\\nthe resampled data with the value from the nearest member of the\\nsequence, based on the index value.\\nMissing values that existed in the original data will not be modified.\\nIf limit is given, fill only this many values in each direction for\\neach of the original values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'limit': {'type': 'integer',\n",
       "          'description': 'int, optional. Limit of how many values to fill.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Resampler.asfreq([fill_value])',\n",
       "      'func_desc': 'Return the values at the new freq, essentially a reindex.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.asfreq.html#pandas.core.resample.Resampler.asfreq',\n",
       "      'function_definitions': {'function_name': 'pandas.core.resample.Resampler.asfreq',\n",
       "       'full_function': 'final Resampler.asfreq(fill_value=None)',\n",
       "       'function_text': 'Return the values at the new freq, essentially a reindex.',\n",
       "       'parameter_names_desc': [{'param_name': 'fill_value',\n",
       "         'param_type': 'scalar, optional',\n",
       "         'param_desc': 'Value to use for missing values, applied during upsampling (note\\nthis does not fill NaNs that already were present).\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.resample.Resampler.asfreq',\n",
       "       'descriptions': 'Return the values at the new freq, essentially a reindex.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'fill_value': {'type': 'scalar, optional',\n",
       "          'description': 'scalar, optional. Value to use for missing values, applied during upsampling (note\\nthis does not fill NaNs that already were present).\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Resampler.bfill([limit])',\n",
       "      'func_desc': 'Backward fill the new missing values in the resampled data.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.bfill.html#pandas.core.resample.Resampler.bfill',\n",
       "      'function_definitions': {'function_name': 'pandas.core.resample.Resampler.bfill',\n",
       "       'full_function': 'final Resampler.bfill(limit=None)',\n",
       "       'function_text': 'Backward fill the new missing values in the resampled data. In statistics, imputation is the process of replacing missing data with\\nsubstituted values [1]. When resampling data, missing values may\\nappear (e.g., when the resampling frequency is higher than the original\\nfrequency). The backward fill will replace NaN values that appeared in\\nthe resampled data with the next value in the original sequence.\\nMissing values that existed in the original data will not be modified.',\n",
       "       'parameter_names_desc': [{'param_name': 'limit',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Limit of how many values to fill.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.resample.Resampler.bfill',\n",
       "       'descriptions': 'Backward fill the new missing values in the resampled data. In statistics, imputation is the process of replacing missing data with\\nsubstituted values [1]. When resampling data, missing values may\\nappear (e.g., when the resampling frequency is higher than the original\\nfrequency). The backward fill will replace NaN values that appeared in\\nthe resampled data with the next value in the original sequence.\\nMissing values that existed in the original data will not be modified.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'limit': {'type': 'integer',\n",
       "          'description': 'int, optional. Limit of how many values to fill.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Resampler.fillna(method[,\\xa0limit])',\n",
       "      'func_desc': 'Fill missing values introduced by upsampling.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.fillna.html#pandas.core.resample.Resampler.fillna',\n",
       "      'function_definitions': {'function_name': 'pandas.core.resample.Resampler.fillna',\n",
       "       'full_function': 'final Resampler.fillna(method, limit=None)',\n",
       "       'function_text': 'Fill missing values introduced by upsampling. In statistics, imputation is the process of replacing missing data with\\nsubstituted values [1]. When resampling data, missing values may\\nappear (e.g., when the resampling frequency is higher than the original\\nfrequency). Missing values that existed in the original data will\\nnot be modified.',\n",
       "       'parameter_names_desc': [{'param_name': 'method',\n",
       "         'param_type': '{‘pad’, ‘backfill’, ‘ffill’, ‘bfill’, ‘nearest’}',\n",
       "         'param_desc': 'Method to use for filling holes in resampled data\\n\\n‘pad’ or ‘ffill’: use previous valid observation to fill gap\\n(forward fill).\\n‘backfill’ or ‘bfill’: use next valid observation to fill gap.\\n‘nearest’: use nearest valid observation to fill gap.\\n\\n'},\n",
       "        {'param_name': 'limit',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Limit of how many consecutive missing values to fill.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.resample.Resampler.fillna',\n",
       "       'descriptions': 'Fill missing values introduced by upsampling. In statistics, imputation is the process of replacing missing data with\\nsubstituted values [1]. When resampling data, missing values may\\nappear (e.g., when the resampling frequency is higher than the original\\nfrequency). Missing values that existed in the original data will\\nnot be modified.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'method': {'type': 'string',\n",
       "          'enum': ['pad', ' backfill', ' ffill', ' bfill', ' nearest'],\n",
       "          'description': '{‘pad’, ‘backfill’, ‘ffill’, ‘bfill’, ‘nearest’}. Method to use for filling holes in resampled data\\n\\n‘pad’ or ‘ffill’: use previous valid observation to fill gap\\n(forward fill).\\n‘backfill’ or ‘bfill’: use next valid observation to fill gap.\\n‘nearest’: use nearest valid observation to fill gap.\\n\\n'},\n",
       "         'limit': {'type': 'integer',\n",
       "          'description': 'int, optional. Limit of how many consecutive missing values to fill.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Resampler.interpolate([method,\\xa0axis,\\xa0limit,\\xa0...])',\n",
       "      'func_desc': 'Interpolate values between target timestamps according to different methods.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.interpolate.html#pandas.core.resample.Resampler.interpolate',\n",
       "      'function_definitions': {'function_name': 'pandas.core.resample.Resampler.interpolate',\n",
       "       'full_function': \"final Resampler.interpolate(method='linear', *, axis=0, limit=None, inplace=False, limit_direction='forward', limit_area=None, downcast=_NoDefault.no_default, **kwargs)\",\n",
       "       'function_text': 'Interpolate values between target timestamps according to different methods. The original index is first reindexed to target timestamps\\n(see core.resample.Resampler.asfreq()),\\nthen the interpolation of NaN values via DataFrame.interpolate()\\nhappens.',\n",
       "       'parameter_names_desc': [{'param_name': 'method',\n",
       "         'param_type': 'str, default ‘linear’',\n",
       "         'param_desc': \"Interpolation technique to use. One of:\\n\\n‘linear’: Ignore the index and treat the values as equally\\nspaced. This is the only method supported on MultiIndexes.\\n‘time’: Works on daily and higher resolution data to interpolate\\ngiven length of interval.\\n‘index’, ‘values’: use the actual numerical values of the index.\\n‘pad’: Fill in NaNs using existing values.\\n‘nearest’, ‘zero’, ‘slinear’, ‘quadratic’, ‘cubic’,\\n‘barycentric’, ‘polynomial’: Passed to\\nscipy.interpolate.interp1d, whereas ‘spline’ is passed to\\nscipy.interpolate.UnivariateSpline. These methods use the numerical\\nvalues of the index. Both ‘polynomial’ and ‘spline’ require that\\nyou also specify an order (int), e.g.\\ndf.interpolate(method='polynomial', order=5). Note that,\\nslinear method in Pandas refers to the Scipy first order spline\\ninstead of Pandas first order spline.\\n‘krogh’, ‘piecewise_polynomial’, ‘spline’, ‘pchip’, ‘akima’,\\n‘cubicspline’: Wrappers around the SciPy interpolation methods of\\nsimilar names. See Notes.\\n‘from_derivatives’: Refers to\\nscipy.interpolate.BPoly.from_derivatives.\\n\\n\"},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{{0 or ‘index’, 1 or ‘columns’, None}}, default None',\n",
       "         'param_desc': 'Axis to interpolate along. For Series this parameter is unused\\nand defaults to 0.\\n'},\n",
       "        {'param_name': 'limit',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Maximum number of consecutive NaNs to fill. Must be greater than\\n0.\\n'},\n",
       "        {'param_name': 'inplace',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Update the data in place if possible.\\n'},\n",
       "        {'param_name': 'limit_direction',\n",
       "         'param_type': '{{‘forward’, ‘backward’, ‘both’}}, Optional',\n",
       "         'param_desc': 'Consecutive NaNs will be filled in this direction.\\n\\nIf limit is specified:\\nIf ‘method’ is ‘pad’ or ‘ffill’, ‘limit_direction’ must be ‘forward’.\\nIf ‘method’ is ‘backfill’ or ‘bfill’, ‘limit_direction’ must be\\n‘backwards’.\\n\\n\\nIf ‘limit’ is not specified:\\nIf ‘method’ is ‘backfill’ or ‘bfill’, the default is ‘backward’\\nelse the default is ‘forward’\\n\\n\\nraises ValueError if limit_direction is ‘forward’ or ‘both’ andmethod is ‘backfill’ or ‘bfill’.\\n\\nraises ValueError if limit_direction is ‘backward’ or ‘both’ andmethod is ‘pad’ or ‘ffill’.\\n\\n\\n\\n\\n'},\n",
       "        {'param_name': 'limit_area',\n",
       "         'param_type': '{{None, ‘inside’, ‘outside’}}, default None',\n",
       "         'param_desc': 'If limit is specified, consecutive NaNs will be filled with this\\nrestriction.\\n\\nNone: No fill restriction.\\n‘inside’: Only fill NaNs surrounded by valid values\\n(interpolate).\\n‘outside’: Only fill NaNs outside valid values (extrapolate).\\n\\n'},\n",
       "        {'param_name': 'downcast',\n",
       "         'param_type': 'optional, ‘infer’ or None, defaults to None',\n",
       "         'param_desc': 'Downcast dtypes if possible.\\n\\nDeprecated since version 2.1.0.\\n\\n'},\n",
       "        {'param_name': '``**kwargs``',\n",
       "         'param_type': 'optional',\n",
       "         'param_desc': 'Keyword arguments to pass on to the interpolating function.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.resample.Resampler.interpolate',\n",
       "       'descriptions': 'Interpolate values between target timestamps according to different methods. The original index is first reindexed to target timestamps\\n(see core.resample.Resampler.asfreq()),\\nthen the interpolation of NaN values via DataFrame.interpolate()\\nhappens.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'method': {'type': 'string',\n",
       "          'description': \"str, default ‘linear’. Interpolation technique to use. One of:\\n\\n‘linear’: Ignore the index and treat the values as equally\\nspaced. This is the only method supported on MultiIndexes.\\n‘time’: Works on daily and higher resolution data to interpolate\\ngiven length of interval.\\n‘index’, ‘values’: use the actual numerical values of the index.\\n‘pad’: Fill in NaNs using existing values.\\n‘nearest’, ‘zero’, ‘slinear’, ‘quadratic’, ‘cubic’,\\n‘barycentric’, ‘polynomial’: Passed to\\nscipy.interpolate.interp1d, whereas ‘spline’ is passed to\\nscipy.interpolate.UnivariateSpline. These methods use the numerical\\nvalues of the index. Both ‘polynomial’ and ‘spline’ require that\\nyou also specify an order (int), e.g.\\ndf.interpolate(method='polynomial', order=5). Note that,\\nslinear method in Pandas refers to the Scipy first order spline\\ninstead of Pandas first order spline.\\n‘krogh’, ‘piecewise_polynomial’, ‘spline’, ‘pchip’, ‘akima’,\\n‘cubicspline’: Wrappers around the SciPy interpolation methods of\\nsimilar names. See Notes.\\n‘from_derivatives’: Refers to\\nscipy.interpolate.BPoly.from_derivatives.\\n\\n\"},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['{0 or index', ' 1 or columns', ' None'],\n",
       "          'description': '{{0 or ‘index’, 1 or ‘columns’, None}}, default None. Axis to interpolate along. For Series this parameter is unused\\nand defaults to 0.\\n'},\n",
       "         'limit': {'type': 'integer',\n",
       "          'description': 'int, optional. Maximum number of consecutive NaNs to fill. Must be greater than\\n0.\\n'},\n",
       "         'inplace': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Update the data in place if possible.\\n'},\n",
       "         'limit_direction': {'type': 'string',\n",
       "          'enum': ['{forward', ' backward', ' both'],\n",
       "          'description': '{{‘forward’, ‘backward’, ‘both’}}, Optional. Consecutive NaNs will be filled in this direction.\\n\\nIf limit is specified:\\nIf ‘method’ is ‘pad’ or ‘ffill’, ‘limit_direction’ must be ‘forward’.\\nIf ‘method’ is ‘backfill’ or ‘bfill’, ‘limit_direction’ must be\\n‘backwards’.\\n\\n\\nIf ‘limit’ is not specified:\\nIf ‘method’ is ‘backfill’ or ‘bfill’, the default is ‘backward’\\nelse the default is ‘forward’\\n\\n\\nraises ValueError if limit_direction is ‘forward’ or ‘both’ andmethod is ‘backfill’ or ‘bfill’.\\n\\nraises ValueError if limit_direction is ‘backward’ or ‘both’ andmethod is ‘pad’ or ‘ffill’.\\n\\n\\n\\n\\n'},\n",
       "         'limit_area': {'type': 'string',\n",
       "          'enum': ['{None', ' inside', ' outside'],\n",
       "          'description': '{{None, ‘inside’, ‘outside’}}, default None. If limit is specified, consecutive NaNs will be filled with this\\nrestriction.\\n\\nNone: No fill restriction.\\n‘inside’: Only fill NaNs surrounded by valid values\\n(interpolate).\\n‘outside’: Only fill NaNs outside valid values (extrapolate).\\n\\n'},\n",
       "         'downcast': {'type': 'optional, ‘infer’ or None, defaults to None',\n",
       "          'description': 'optional, ‘infer’ or None, defaults to None. Downcast dtypes if possible.\\n\\nDeprecated since version 2.1.0.\\n\\n'},\n",
       "         '``**kwargs``': {'type': 'optional',\n",
       "          'description': 'optional. Keyword arguments to pass on to the interpolating function.\\n'}},\n",
       "        'required': [\"method='linear'\"]}}}]},\n",
       "   {'Computations / descriptive stats': [{'func_name': 'Resampler.count()',\n",
       "      'func_desc': 'Compute count of group, excluding missing values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.count.html#pandas.core.resample.Resampler.count',\n",
       "      'function_definitions': {'function_name': 'pandas.core.resample.Resampler.count',\n",
       "       'full_function': 'final Resampler.count()',\n",
       "       'function_text': 'Compute count of group, excluding missing values.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Resampler.first([numeric_only,\\xa0min_count,\\xa0...])',\n",
       "      'func_desc': 'Compute the first entry of each column within each group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.first.html#pandas.core.resample.Resampler.first',\n",
       "      'function_definitions': {'function_name': 'pandas.core.resample.Resampler.first',\n",
       "       'full_function': 'final Resampler.first(numeric_only=False, min_count=0, skipna=True, *args, **kwargs)',\n",
       "       'function_text': 'Compute the first entry of each column within each group. Defaults to skipping NA elements.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n'},\n",
       "        {'param_name': 'min_count',\n",
       "         'param_type': 'int, default -1',\n",
       "         'param_desc': 'The required number of valid values to perform the operation. If fewer\\nthan min_count valid values are present the result will be NA.\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n\\nNew in version 2.2.1.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.resample.Resampler.first',\n",
       "       'descriptions': 'Compute the first entry of each column within each group. Defaults to skipping NA elements.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n'},\n",
       "         'min_count': {'type': 'integer',\n",
       "          'description': 'int, default -1. The required number of valid values to perform the operation. If fewer\\nthan min_count valid values are present the result will be NA.\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n\\nNew in version 2.2.1.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Resampler.max([numeric_only,\\xa0min_count])',\n",
       "      'func_desc': 'Compute max value of group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.max.html#pandas.core.resample.Resampler.max',\n",
       "      'function_definitions': {'function_name': 'pandas.core.resample.Resampler.max',\n",
       "       'full_function': 'final Resampler.max(numeric_only=False, min_count=0, *args, **kwargs)',\n",
       "       'function_text': 'Compute max value of group.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Resampler.median([numeric_only])',\n",
       "      'func_desc': 'Compute median of groups, excluding missing values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.median.html#pandas.core.resample.Resampler.median',\n",
       "      'function_definitions': {'function_name': 'pandas.core.resample.Resampler.median',\n",
       "       'full_function': 'final Resampler.median(numeric_only=False, *args, **kwargs)',\n",
       "       'function_text': 'Compute median of groups, excluding missing values. For multiple groupings, the result index will be a MultiIndex',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nChanged in version 2.0.0: numeric_only no longer accepts None and defaults to False.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.resample.Resampler.median',\n",
       "       'descriptions': 'Compute median of groups, excluding missing values. For multiple groupings, the result index will be a MultiIndex',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nChanged in version 2.0.0: numeric_only no longer accepts None and defaults to False.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Resampler.ohlc(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Compute open, high, low and close values of a group, excluding missing values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.ohlc.html#pandas.core.resample.Resampler.ohlc',\n",
       "      'function_definitions': {'function_name': 'pandas.core.resample.Resampler.ohlc',\n",
       "       'full_function': 'final Resampler.ohlc(*args, **kwargs)',\n",
       "       'function_text': 'Compute open, high, low and close values of a group, excluding missing values. For multiple groupings, the result index will be a MultiIndex',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Resampler.size()',\n",
       "      'func_desc': 'Compute group sizes.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.size.html#pandas.core.resample.Resampler.size',\n",
       "      'function_definitions': {'function_name': 'pandas.core.resample.Resampler.size',\n",
       "       'full_function': 'final Resampler.size()',\n",
       "       'function_text': 'Compute group sizes.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Resampler.std([ddof,\\xa0numeric_only])',\n",
       "      'func_desc': 'Compute standard deviation of groups, excluding missing values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.std.html#pandas.core.resample.Resampler.std',\n",
       "      'function_definitions': {'function_name': 'pandas.core.resample.Resampler.std',\n",
       "       'full_function': 'final Resampler.std(ddof=1, numeric_only=False, *args, **kwargs)',\n",
       "       'function_text': 'Compute standard deviation of groups, excluding missing values.',\n",
       "       'parameter_names_desc': [{'param_name': 'ddof',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Degrees of freedom.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int or boolean data.\\n\\nNew in version 1.5.0.\\n\\n\\nChanged in version 2.0.0: numeric_only now defaults to False.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.resample.Resampler.std',\n",
       "       'descriptions': 'Compute standard deviation of groups, excluding missing values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'ddof': {'type': 'integer',\n",
       "          'description': 'int, default 1. Degrees of freedom.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int or boolean data.\\n\\nNew in version 1.5.0.\\n\\n\\nChanged in version 2.0.0: numeric_only now defaults to False.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Resampler.var([ddof,\\xa0numeric_only])',\n",
       "      'func_desc': 'Compute variance of groups, excluding missing values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.var.html#pandas.core.resample.Resampler.var',\n",
       "      'function_definitions': {'function_name': 'pandas.core.resample.Resampler.var',\n",
       "       'full_function': 'final Resampler.var(ddof=1, numeric_only=False, *args, **kwargs)',\n",
       "       'function_text': 'Compute variance of groups, excluding missing values.',\n",
       "       'parameter_names_desc': [{'param_name': 'ddof',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Degrees of freedom.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int or boolean data.\\n\\nNew in version 1.5.0.\\n\\n\\nChanged in version 2.0.0: numeric_only now defaults to False.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.resample.Resampler.var',\n",
       "       'descriptions': 'Compute variance of groups, excluding missing values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'ddof': {'type': 'integer',\n",
       "          'description': 'int, default 1. Degrees of freedom.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int or boolean data.\\n\\nNew in version 1.5.0.\\n\\n\\nChanged in version 2.0.0: numeric_only now defaults to False.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Resampler.nunique(*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Return number of unique elements in the group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.nunique.html#pandas.core.resample.Resampler.nunique',\n",
       "      'function_definitions': {'function_name': 'pandas.core.resample.Resampler.nunique',\n",
       "       'full_function': 'final Resampler.nunique(*args, **kwargs)',\n",
       "       'function_text': 'Return number of unique elements in the group.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Resampler.last([numeric_only,\\xa0min_count,\\xa0skipna])',\n",
       "      'func_desc': 'Compute the last entry of each column within each group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.last.html#pandas.core.resample.Resampler.last',\n",
       "      'function_definitions': {'function_name': 'pandas.core.resample.Resampler.last',\n",
       "       'full_function': 'final Resampler.last(numeric_only=False, min_count=0, skipna=True, *args, **kwargs)',\n",
       "       'function_text': 'Compute the last entry of each column within each group. Defaults to skipping NA elements.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns. If None, will attempt to use\\neverything, then use only numeric data.\\n'},\n",
       "        {'param_name': 'min_count',\n",
       "         'param_type': 'int, default -1',\n",
       "         'param_desc': 'The required number of valid values to perform the operation. If fewer\\nthan min_count valid values are present the result will be NA.\\n'},\n",
       "        {'param_name': 'skipna',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n\\nNew in version 2.2.1.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.resample.Resampler.last',\n",
       "       'descriptions': 'Compute the last entry of each column within each group. Defaults to skipping NA elements.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns. If None, will attempt to use\\neverything, then use only numeric data.\\n'},\n",
       "         'min_count': {'type': 'integer',\n",
       "          'description': 'int, default -1. The required number of valid values to perform the operation. If fewer\\nthan min_count valid values are present the result will be NA.\\n'},\n",
       "         'skipna': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Exclude NA/null values. If an entire row/column is NA, the result\\nwill be NA.\\n\\nNew in version 2.2.1.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Resampler.mean([numeric_only])',\n",
       "      'func_desc': 'Compute mean of groups, excluding missing values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.mean.html#pandas.core.resample.Resampler.mean',\n",
       "      'function_definitions': {'function_name': 'pandas.core.resample.Resampler.mean',\n",
       "       'full_function': 'final Resampler.mean(numeric_only=False, *args, **kwargs)',\n",
       "       'function_text': 'Compute mean of groups, excluding missing values.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int or boolean data.\\n\\nChanged in version 2.0.0: numeric_only now defaults to False.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.resample.Resampler.mean',\n",
       "       'descriptions': 'Compute mean of groups, excluding missing values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int or boolean data.\\n\\nChanged in version 2.0.0: numeric_only now defaults to False.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Resampler.min([numeric_only,\\xa0min_count])',\n",
       "      'func_desc': 'Compute min value of group.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.min.html#pandas.core.resample.Resampler.min',\n",
       "      'function_definitions': {'function_name': 'pandas.core.resample.Resampler.min',\n",
       "       'full_function': 'final Resampler.min(numeric_only=False, min_count=0, *args, **kwargs)',\n",
       "       'function_text': 'Compute min value of group.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Resampler.prod([numeric_only,\\xa0min_count])',\n",
       "      'func_desc': 'Compute prod of group values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.prod.html#pandas.core.resample.Resampler.prod',\n",
       "      'function_definitions': {'function_name': 'pandas.core.resample.Resampler.prod',\n",
       "       'full_function': 'final Resampler.prod(numeric_only=False, min_count=0, *args, **kwargs)',\n",
       "       'function_text': 'Compute prod of group values.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nChanged in version 2.0.0: numeric_only no longer accepts None.\\n\\n'},\n",
       "        {'param_name': 'min_count',\n",
       "         'param_type': 'int, default 0',\n",
       "         'param_desc': 'The required number of valid values to perform the operation. If fewer\\nthan min_count non-NA values are present the result will be NA.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.resample.Resampler.prod',\n",
       "       'descriptions': 'Compute prod of group values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nChanged in version 2.0.0: numeric_only no longer accepts None.\\n\\n'},\n",
       "         'min_count': {'type': 'integer',\n",
       "          'description': 'int, default 0. The required number of valid values to perform the operation. If fewer\\nthan min_count non-NA values are present the result will be NA.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Resampler.sem([ddof,\\xa0numeric_only])',\n",
       "      'func_desc': 'Compute standard error of the mean of groups, excluding missing values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.sem.html#pandas.core.resample.Resampler.sem',\n",
       "      'function_definitions': {'function_name': 'pandas.core.resample.Resampler.sem',\n",
       "       'full_function': 'final Resampler.sem(ddof=1, numeric_only=False, *args, **kwargs)',\n",
       "       'function_text': 'Compute standard error of the mean of groups, excluding missing values. For multiple groupings, the result index will be a MultiIndex.',\n",
       "       'parameter_names_desc': [{'param_name': 'ddof',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Degrees of freedom.\\n'},\n",
       "        {'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int or boolean data.\\n\\nNew in version 1.5.0.\\n\\n\\nChanged in version 2.0.0: numeric_only now defaults to False.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.resample.Resampler.sem',\n",
       "       'descriptions': 'Compute standard error of the mean of groups, excluding missing values. For multiple groupings, the result index will be a MultiIndex.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'ddof': {'type': 'integer',\n",
       "          'description': 'int, default 1. Degrees of freedom.\\n'},\n",
       "         'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int or boolean data.\\n\\nNew in version 1.5.0.\\n\\n\\nChanged in version 2.0.0: numeric_only now defaults to False.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Resampler.sum([numeric_only,\\xa0min_count])',\n",
       "      'func_desc': 'Compute sum of group values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.sum.html#pandas.core.resample.Resampler.sum',\n",
       "      'function_definitions': {'function_name': 'pandas.core.resample.Resampler.sum',\n",
       "       'full_function': 'final Resampler.sum(numeric_only=False, min_count=0, *args, **kwargs)',\n",
       "       'function_text': 'Compute sum of group values.',\n",
       "       'parameter_names_desc': [{'param_name': 'numeric_only',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Include only float, int, boolean columns.\\n\\nChanged in version 2.0.0: numeric_only no longer accepts None.\\n\\n'},\n",
       "        {'param_name': 'min_count',\n",
       "         'param_type': 'int, default 0',\n",
       "         'param_desc': 'The required number of valid values to perform the operation. If fewer\\nthan min_count non-NA values are present the result will be NA.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.core.resample.Resampler.sum',\n",
       "       'descriptions': 'Compute sum of group values.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'numeric_only': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Include only float, int, boolean columns.\\n\\nChanged in version 2.0.0: numeric_only no longer accepts None.\\n\\n'},\n",
       "         'min_count': {'type': 'integer',\n",
       "          'description': 'int, default 0. The required number of valid values to perform the operation. If fewer\\nthan min_count non-NA values are present the result will be NA.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Resampler.quantile([q])',\n",
       "      'func_desc': 'Return value at the given quantile.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.quantile.html#pandas.core.resample.Resampler.quantile',\n",
       "      'function_definitions': {'function_name': 'pandas.core.resample.Resampler.quantile',\n",
       "       'full_function': 'final Resampler.quantile(q=0.5, **kwargs)',\n",
       "       'function_text': 'Return value at the given quantile.',\n",
       "       'parameter_names_desc': [{'param_name': 'q',\n",
       "         'param_type': 'float or array-like, default 0.5 (50% quantile)',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.core.resample.Resampler.quantile',\n",
       "       'descriptions': 'Return value at the given quantile.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'q': {'type': 'float',\n",
       "          'description': 'float or array-like, default 0.5 (50% quantile). '}},\n",
       "        'required': []}}}]}],\n",
       "  'name': 'Resampling',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/resampling.html'},\n",
       " 'style.html': {'functions': [{'Styler constructor': [{'func_name': 'Styler(data[,\\xa0precision,\\xa0table_styles,\\xa0...])',\n",
       "      'func_desc': 'Helps style a DataFrame or Series according to the data with HTML and CSS.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.html#pandas.io.formats.style.Styler',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler',\n",
       "       'full_function': 'class pandas.io.formats.style.Styler(data, precision=None, table_styles=None, uuid=None, caption=None, table_attributes=None, cell_ids=True, na_rep=None, uuid_len=5, decimal=None, thousands=None, escape=None, formatter=None)',\n",
       "       'function_text': 'Helps style a DataFrame or Series according to the data with HTML and CSS.',\n",
       "       'parameter_names_desc': [{'param_name': 'data',\n",
       "         'param_type': 'Series or DataFrame',\n",
       "         'param_desc': 'Data to be styled - either a Series or DataFrame.\\n'},\n",
       "        {'param_name': 'precision',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Precision to round floats to. If not given defaults to\\npandas.options.styler.format.precision.\\n\\nChanged in version 1.4.0.\\n\\n'},\n",
       "        {'param_name': 'table_styles',\n",
       "         'param_type': 'list-like, default None',\n",
       "         'param_desc': 'List of {selector: (attr, value)} dicts; see Notes.\\n'},\n",
       "        {'param_name': 'uuid',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'A unique identifier to avoid CSS collisions; generated automatically.\\n'},\n",
       "        {'param_name': 'caption',\n",
       "         'param_type': 'str, tuple, default None',\n",
       "         'param_desc': 'String caption to attach to the table. Tuple only used for LaTeX dual captions.\\n'},\n",
       "        {'param_name': 'table_attributes',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'Items that show up in the opening <table> tag\\nin addition to automatic (by default) id.\\n'},\n",
       "        {'param_name': 'cell_ids',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If True, each cell will have an id attribute in their HTML tag.\\nThe id takes the form T_<uuid>_row<num_row>_col<num_col>\\nwhere <uuid> is the unique identifier, <num_row> is the row\\nnumber and <num_col> is the column number.\\n'},\n",
       "        {'param_name': 'na_rep',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Representation for missing values.\\nIf na_rep is None, no special formatting is applied, and falls back to\\npandas.options.styler.format.na_rep.\\n'},\n",
       "        {'param_name': 'uuid_len',\n",
       "         'param_type': 'int, default 5',\n",
       "         'param_desc': 'If uuid is not specified, the length of the uuid to randomly generate\\nexpressed in hex characters, in range [0, 32].\\n'},\n",
       "        {'param_name': 'decimal',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Character used as decimal separator for floats, complex and integers. If not\\ngiven uses pandas.options.styler.format.decimal.\\n\\nNew in version 1.3.0.\\n\\n'},\n",
       "        {'param_name': 'thousands',\n",
       "         'param_type': 'str, optional, default None',\n",
       "         'param_desc': 'Character used as thousands separator for floats, complex and integers. If not\\ngiven uses pandas.options.styler.format.thousands.\\n\\nNew in version 1.3.0.\\n\\n'},\n",
       "        {'param_name': 'escape',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Use ‘html’ to replace the characters &, <, >, \\', and \"\\nin cell display string with HTML-safe sequences.\\nUse ‘latex’ to replace the characters &, %, $, #, _,\\n{, }, ~, ^, and \\\\ in the cell display string with\\nLaTeX-safe sequences. Use ‘latex-math’ to replace the characters\\nthe same way as in ‘latex’ mode, except for math substrings,\\nwhich either are surrounded by two characters $ or start with\\nthe character \\\\( and end with \\\\).\\nIf not given uses pandas.options.styler.format.escape.\\n\\nNew in version 1.3.0.\\n\\n'},\n",
       "        {'param_name': 'formatter',\n",
       "         'param_type': 'str, callable, dict, optional',\n",
       "         'param_desc': 'Object to define how values are displayed. See Styler.format. If not given\\nuses pandas.options.styler.format.formatter.\\n\\nNew in version 1.4.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler',\n",
       "       'descriptions': 'Helps style a DataFrame or Series according to the data with HTML and CSS.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'data': {'type': 'Series or DataFrame',\n",
       "          'description': 'Series or DataFrame. Data to be styled - either a Series or DataFrame.\\n'},\n",
       "         'precision': {'type': 'integer',\n",
       "          'description': 'int, optional. Precision to round floats to. If not given defaults to\\npandas.options.styler.format.precision.\\n\\nChanged in version 1.4.0.\\n\\n'},\n",
       "         'table_styles': {'type': 'array',\n",
       "          'description': 'list-like, default None. List of {selector: (attr, value)} dicts; see Notes.\\n'},\n",
       "         'uuid': {'type': 'string',\n",
       "          'description': 'str, default None. A unique identifier to avoid CSS collisions; generated automatically.\\n'},\n",
       "         'caption': {'type': 'string',\n",
       "          'description': 'str, tuple, default None. String caption to attach to the table. Tuple only used for LaTeX dual captions.\\n'},\n",
       "         'table_attributes': {'type': 'string',\n",
       "          'description': 'str, default None. Items that show up in the opening <table> tag\\nin addition to automatic (by default) id.\\n'},\n",
       "         'cell_ids': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If True, each cell will have an id attribute in their HTML tag.\\nThe id takes the form T_<uuid>_row<num_row>_col<num_col>\\nwhere <uuid> is the unique identifier, <num_row> is the row\\nnumber and <num_col> is the column number.\\n'},\n",
       "         'na_rep': {'type': 'string',\n",
       "          'description': 'str, optional. Representation for missing values.\\nIf na_rep is None, no special formatting is applied, and falls back to\\npandas.options.styler.format.na_rep.\\n'},\n",
       "         'uuid_len': {'type': 'integer',\n",
       "          'description': 'int, default 5. If uuid is not specified, the length of the uuid to randomly generate\\nexpressed in hex characters, in range [0, 32].\\n'},\n",
       "         'decimal': {'type': 'string',\n",
       "          'description': 'str, optional. Character used as decimal separator for floats, complex and integers. If not\\ngiven uses pandas.options.styler.format.decimal.\\n\\nNew in version 1.3.0.\\n\\n'},\n",
       "         'thousands': {'type': 'string',\n",
       "          'description': 'str, optional, default None. Character used as thousands separator for floats, complex and integers. If not\\ngiven uses pandas.options.styler.format.thousands.\\n\\nNew in version 1.3.0.\\n\\n'},\n",
       "         'escape': {'type': 'string',\n",
       "          'description': 'str, optional. Use ‘html’ to replace the characters &, <, >, \\', and \"\\nin cell display string with HTML-safe sequences.\\nUse ‘latex’ to replace the characters &, %, $, #, _,\\n{, }, ~, ^, and \\\\ in the cell display string with\\nLaTeX-safe sequences. Use ‘latex-math’ to replace the characters\\nthe same way as in ‘latex’ mode, except for math substrings,\\nwhich either are surrounded by two characters $ or start with\\nthe character \\\\( and end with \\\\).\\nIf not given uses pandas.options.styler.format.escape.\\n\\nNew in version 1.3.0.\\n\\n'},\n",
       "         'formatter': {'type': 'string',\n",
       "          'description': 'str, callable, dict, optional. Object to define how values are displayed. See Styler.format. If not given\\nuses pandas.options.styler.format.formatter.\\n\\nNew in version 1.4.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Styler.from_custom_template(searchpath[,\\xa0...])',\n",
       "      'func_desc': 'Factory function for creating a subclass of Styler.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.from_custom_template.html#pandas.io.formats.style.Styler.from_custom_template',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.from_custom_template',\n",
       "       'full_function': 'classmethod Styler.from_custom_template(searchpath, html_table=None, html_style=None)',\n",
       "       'function_text': 'Factory function for creating a subclass of Styler. Uses custom templates and Jinja environment. Changed in version 1.3.0.',\n",
       "       'parameter_names_desc': [{'param_name': 'searchpath',\n",
       "         'param_type': 'str or list',\n",
       "         'param_desc': 'Path or paths of directories containing the templates.\\n'},\n",
       "        {'param_name': 'html_table',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'Name of your custom template to replace the html_table template.\\n\\nNew in version 1.3.0.\\n\\n'},\n",
       "        {'param_name': 'html_style',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'Name of your custom template to replace the html_style template.\\n\\nNew in version 1.3.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.from_custom_template',\n",
       "       'descriptions': 'Factory function for creating a subclass of Styler. Uses custom templates and Jinja environment. Changed in version 1.3.0.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'searchpath': {'type': 'string',\n",
       "          'description': 'str or list. Path or paths of directories containing the templates.\\n'},\n",
       "         'html_table': {'type': 'string',\n",
       "          'description': 'str. Name of your custom template to replace the html_table template.\\n\\nNew in version 1.3.0.\\n\\n'},\n",
       "         'html_style': {'type': 'string',\n",
       "          'description': 'str. Name of your custom template to replace the html_style template.\\n\\nNew in version 1.3.0.\\n\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Styler properties': [{'func_name': 'Styler.env',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.env.html#pandas.io.formats.style.Styler.env',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.env',\n",
       "       'full_function': 'Styler.env = <jinja2.environment.Environment object>#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Styler.template_html_style',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.template_html_style.html#pandas.io.formats.style.Styler.template_html_style',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.template_html_style',\n",
       "       'full_function': \"Styler.template_html_style = <Template 'html_style.tpl'>#\",\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Styler.template_latex',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.template_latex.html#pandas.io.formats.style.Styler.template_latex',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.template_latex',\n",
       "       'full_function': \"Styler.template_latex = <Template 'latex.tpl'>#\",\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Styler.loader',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.loader.html#pandas.io.formats.style.Styler.loader',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.loader',\n",
       "       'full_function': 'Styler.loader = <jinja2.loaders.PackageLoader object>#',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Styler.template_html',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.template_html.html#pandas.io.formats.style.Styler.template_html',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.template_html',\n",
       "       'full_function': \"Styler.template_html = <Template 'html.tpl'>#\",\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Styler.template_html_table',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.template_html_table.html#pandas.io.formats.style.Styler.template_html_table',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.template_html_table',\n",
       "       'full_function': \"Styler.template_html_table = <Template 'html_table.tpl'>#\",\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Styler.template_string',\n",
       "      'func_desc': '',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.template_string.html#pandas.io.formats.style.Styler.template_string',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.template_string',\n",
       "       'full_function': \"Styler.template_string = <Template 'string.tpl'>#\",\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'Style application': [{'func_name': 'Styler.apply(func[,\\xa0axis,\\xa0subset])',\n",
       "      'func_desc': 'Apply a CSS-styling function column-wise, row-wise, or table-wise.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.apply.html#pandas.io.formats.style.Styler.apply',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.apply',\n",
       "       'full_function': 'Styler.apply(func, axis=0, subset=None, **kwargs)',\n",
       "       'function_text': 'Apply a CSS-styling function column-wise, row-wise, or table-wise. Updates the HTML representation with the result.',\n",
       "       'parameter_names_desc': [{'param_name': 'func',\n",
       "         'param_type': 'function',\n",
       "         'param_desc': 'func should take a Series if axis in [0,1] and return a list-like\\nobject of same length, or a Series, not necessarily of same length, with\\nvalid index labels considering subset.\\nfunc should take a DataFrame if axis is None and return either\\nan ndarray with the same shape or a DataFrame, not necessarily of the same\\nshape, with valid index and columns labels considering subset.\\n\\nChanged in version 1.3.0.\\n\\n\\nChanged in version 1.4.0.\\n\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’, None}, default 0',\n",
       "         'param_desc': \"Apply to each column (axis=0 or 'index'), to each row\\n(axis=1 or 'columns'), or to the entire DataFrame at once\\nwith axis=None.\\n\"},\n",
       "        {'param_name': 'subset',\n",
       "         'param_type': 'label, array-like, IndexSlice, optional',\n",
       "         'param_desc': 'A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\\nor single key, to DataFrame.loc[:, <subset>] where the columns are\\nprioritised, to limit data to before applying the function.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.apply',\n",
       "       'descriptions': 'Apply a CSS-styling function column-wise, row-wise, or table-wise. Updates the HTML representation with the result.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'func': {'type': 'function',\n",
       "          'description': 'function. func should take a Series if axis in [0,1] and return a list-like\\nobject of same length, or a Series, not necessarily of same length, with\\nvalid index labels considering subset.\\nfunc should take a DataFrame if axis is None and return either\\nan ndarray with the same shape or a DataFrame, not necessarily of the same\\nshape, with valid index and columns labels considering subset.\\n\\nChanged in version 1.3.0.\\n\\n\\nChanged in version 1.4.0.\\n\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns', ' None'],\n",
       "          'description': \"{0 or ‘index’, 1 or ‘columns’, None}, default 0. Apply to each column (axis=0 or 'index'), to each row\\n(axis=1 or 'columns'), or to the entire DataFrame at once\\nwith axis=None.\\n\"},\n",
       "         'subset': {'type': 'array',\n",
       "          'description': 'label, array-like, IndexSlice, optional. A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\\nor single key, to DataFrame.loc[:, <subset>] where the columns are\\nprioritised, to limit data to before applying the function.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Styler.apply_index(func[,\\xa0axis,\\xa0level])',\n",
       "      'func_desc': 'Apply a CSS-styling function to the index or column headers, level-wise.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.apply_index.html#pandas.io.formats.style.Styler.apply_index',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.apply_index',\n",
       "       'full_function': 'Styler.apply_index(func, axis=0, level=None, **kwargs)',\n",
       "       'function_text': 'Apply a CSS-styling function to the index or column headers, level-wise. Updates the HTML representation with the result. New in version 1.4.0. New in version 2.1.0: Styler.applymap_index was deprecated and renamed to Styler.map_index.',\n",
       "       'parameter_names_desc': [{'param_name': 'func',\n",
       "         'param_type': 'function',\n",
       "         'param_desc': 'func should take a Series and return a string array of the same length.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0, 1, “index”, “columns”}',\n",
       "         'param_desc': 'The headers over which to apply the function.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int, str, list, optional',\n",
       "         'param_desc': 'If index is MultiIndex the level(s) over which to apply the function.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.apply_index',\n",
       "       'descriptions': 'Apply a CSS-styling function to the index or column headers, level-wise. Updates the HTML representation with the result. New in version 1.4.0. New in version 2.1.0: Styler.applymap_index was deprecated and renamed to Styler.map_index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'func': {'type': 'function',\n",
       "          'description': 'function. func should take a Series and return a string array of the same length.\\n'},\n",
       "         'axis': {'type': '{0, 1, “index”, “columns”}',\n",
       "          'description': '{0, 1, “index”, “columns”}. The headers over which to apply the function.\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int, str, list, optional. If index is MultiIndex the level(s) over which to apply the function.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Styler.format([formatter,\\xa0subset,\\xa0na_rep,\\xa0...])',\n",
       "      'func_desc': 'Format the text display value of cells.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.format.html#pandas.io.formats.style.Styler.format',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.format',\n",
       "       'full_function': \"Styler.format(formatter=None, subset=None, na_rep=None, precision=None, decimal='.', thousands=None, escape=None, hyperlinks=None)\",\n",
       "       'function_text': 'Format the text display value of cells.',\n",
       "       'parameter_names_desc': [{'param_name': 'formatter',\n",
       "         'param_type': 'str, callable, dict or None',\n",
       "         'param_desc': 'Object to define how values are displayed. See notes.\\n'},\n",
       "        {'param_name': 'subset',\n",
       "         'param_type': 'label, array-like, IndexSlice, optional',\n",
       "         'param_desc': 'A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\\nor single key, to DataFrame.loc[:, <subset>] where the columns are\\nprioritised, to limit data to before applying the function.\\n'},\n",
       "        {'param_name': 'na_rep',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Representation for missing values.\\nIf na_rep is None, no special formatting is applied.\\n'},\n",
       "        {'param_name': 'precision',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Floating point precision to use for display purposes, if not determined by\\nthe specified formatter.\\n\\nNew in version 1.3.0.\\n\\n'},\n",
       "        {'param_name': 'decimal',\n",
       "         'param_type': 'str, default “.”',\n",
       "         'param_desc': 'Character used as decimal separator for floats, complex and integers.\\n\\nNew in version 1.3.0.\\n\\n'},\n",
       "        {'param_name': 'thousands',\n",
       "         'param_type': 'str, optional, default None',\n",
       "         'param_desc': 'Character used as thousands separator for floats, complex and integers.\\n\\nNew in version 1.3.0.\\n\\n'},\n",
       "        {'param_name': 'escape',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Use ‘html’ to replace the characters &, <, >, \\', and \"\\nin cell display string with HTML-safe sequences.\\nUse ‘latex’ to replace the characters &, %, $, #, _,\\n{, }, ~, ^, and \\\\ in the cell display string with\\nLaTeX-safe sequences.\\nUse ‘latex-math’ to replace the characters the same way as in ‘latex’ mode,\\nexcept for math substrings, which either are surrounded\\nby two characters $ or start with the character \\\\( and\\nend with \\\\). Escaping is done before formatter.\\n\\nNew in version 1.3.0.\\n\\n'},\n",
       "        {'param_name': 'hyperlinks',\n",
       "         'param_type': '{“html”, “latex”}, optional',\n",
       "         'param_desc': 'Convert string patterns containing https://, http://, ftp:// or www. to\\nHTML <a> tags as clickable URL hyperlinks if “html”, or LaTeX href\\ncommands if “latex”.\\n\\nNew in version 1.4.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.format',\n",
       "       'descriptions': 'Format the text display value of cells.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'formatter': {'type': 'string',\n",
       "          'description': 'str, callable, dict or None. Object to define how values are displayed. See notes.\\n'},\n",
       "         'subset': {'type': 'array',\n",
       "          'description': 'label, array-like, IndexSlice, optional. A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\\nor single key, to DataFrame.loc[:, <subset>] where the columns are\\nprioritised, to limit data to before applying the function.\\n'},\n",
       "         'na_rep': {'type': 'string',\n",
       "          'description': 'str, optional. Representation for missing values.\\nIf na_rep is None, no special formatting is applied.\\n'},\n",
       "         'precision': {'type': 'integer',\n",
       "          'description': 'int, optional. Floating point precision to use for display purposes, if not determined by\\nthe specified formatter.\\n\\nNew in version 1.3.0.\\n\\n'},\n",
       "         'decimal': {'type': 'string',\n",
       "          'description': 'str, default “.”. Character used as decimal separator for floats, complex and integers.\\n\\nNew in version 1.3.0.\\n\\n'},\n",
       "         'thousands': {'type': 'string',\n",
       "          'description': 'str, optional, default None. Character used as thousands separator for floats, complex and integers.\\n\\nNew in version 1.3.0.\\n\\n'},\n",
       "         'escape': {'type': 'string',\n",
       "          'description': 'str, optional. Use ‘html’ to replace the characters &, <, >, \\', and \"\\nin cell display string with HTML-safe sequences.\\nUse ‘latex’ to replace the characters &, %, $, #, _,\\n{, }, ~, ^, and \\\\ in the cell display string with\\nLaTeX-safe sequences.\\nUse ‘latex-math’ to replace the characters the same way as in ‘latex’ mode,\\nexcept for math substrings, which either are surrounded\\nby two characters $ or start with the character \\\\( and\\nend with \\\\). Escaping is done before formatter.\\n\\nNew in version 1.3.0.\\n\\n'},\n",
       "         'hyperlinks': {'type': '{“html”, “latex”}, optional',\n",
       "          'description': '{“html”, “latex”}, optional. Convert string patterns containing https://, http://, ftp:// or www. to\\nHTML <a> tags as clickable URL hyperlinks if “html”, or LaTeX href\\ncommands if “latex”.\\n\\nNew in version 1.4.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Styler.relabel_index(labels[,\\xa0axis,\\xa0level])',\n",
       "      'func_desc': 'Relabel the index, or column header, keys to display a set of specified values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.relabel_index.html#pandas.io.formats.style.Styler.relabel_index',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.relabel_index',\n",
       "       'full_function': 'Styler.relabel_index(labels, axis=0, level=None)',\n",
       "       'function_text': 'Relabel the index, or column header, keys to display a set of specified values. New in version 1.5.0.',\n",
       "       'parameter_names_desc': [{'param_name': 'labels',\n",
       "         'param_type': 'list-like or Index',\n",
       "         'param_desc': 'New labels to display. Must have same length as the underlying values not\\nhidden.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{“index”, 0, “columns”, 1}',\n",
       "         'param_desc': 'Apply to the index or columns.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int, str, list, optional',\n",
       "         'param_desc': 'The level(s) over which to apply the new labels. If None will apply\\nto all levels of an Index or MultiIndex which are not hidden.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.relabel_index',\n",
       "       'descriptions': 'Relabel the index, or column header, keys to display a set of specified values. New in version 1.5.0.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'labels': {'type': 'array',\n",
       "          'description': 'list-like or Index. New labels to display. Must have same length as the underlying values not\\nhidden.\\n'},\n",
       "         'axis': {'type': '{“index”, 0, “columns”, 1}',\n",
       "          'description': '{“index”, 0, “columns”, 1}. Apply to the index or columns.\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int, str, list, optional. The level(s) over which to apply the new labels. If None will apply\\nto all levels of an Index or MultiIndex which are not hidden.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Styler.concat(other)',\n",
       "      'func_desc': 'Append another Styler to combine the output into a single table.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.concat.html#pandas.io.formats.style.Styler.concat',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.concat',\n",
       "       'full_function': 'Styler.concat(other)',\n",
       "       'function_text': 'Append another Styler to combine the output into a single table. New in version 1.5.0.',\n",
       "       'parameter_names_desc': [{'param_name': 'other',\n",
       "         'param_type': 'Styler',\n",
       "         'param_desc': 'The other Styler object which has already been styled and formatted. The\\ndata for this Styler must have the same columns as the original, and the\\nnumber of index levels must also be the same to render correctly.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.concat',\n",
       "       'descriptions': 'Append another Styler to combine the output into a single table. New in version 1.5.0.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'other': {'type': 'Styler',\n",
       "          'description': 'Styler. The other Styler object which has already been styled and formatted. The\\ndata for this Styler must have the same columns as the original, and the\\nnumber of index levels must also be the same to render correctly.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Styler.set_table_styles([table_styles,\\xa0...])',\n",
       "      'func_desc': 'Set the table styles included within the <style> HTML element.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.set_table_styles.html#pandas.io.formats.style.Styler.set_table_styles',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.set_table_styles',\n",
       "       'full_function': 'Styler.set_table_styles(table_styles=None, axis=0, overwrite=True, css_class_names=None)',\n",
       "       'function_text': 'Set the table styles included within the <style> HTML element. This function can be used to style the entire table, columns, rows or\\nspecific HTML selectors.',\n",
       "       'parameter_names_desc': [{'param_name': 'table_styles',\n",
       "         'param_type': 'list or dict',\n",
       "         'param_desc': 'If supplying a list, each individual table_style should be a\\ndictionary with selector and props keys. selector\\nshould be a CSS selector that the style will be applied to\\n(automatically prefixed by the table’s UUID) and props\\nshould be a list of tuples with (attribute, value).\\nIf supplying a dict, the dict keys should correspond to\\ncolumn names or index values, depending upon the specified\\naxis argument. These will be mapped to row or col CSS\\nselectors. MultiIndex values as dict keys should be\\nin their respective tuple form. The dict values should be\\na list as specified in the form with CSS selectors and\\nprops that will be applied to the specified row or column.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’, None}, default 0',\n",
       "         'param_desc': \"Apply to each column (axis=0 or 'index'), to each row\\n(axis=1 or 'columns'). Only used if table_styles is\\ndict.\\n\"},\n",
       "        {'param_name': 'overwrite',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Styles are replaced if True, or extended if False. CSS\\nrules are preserved so most recent styles set will dominate\\nif selectors intersect.\\n'},\n",
       "        {'param_name': 'css_class_names',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'A dict of strings used to replace the default CSS classes described below.\\n\\nNew in version 1.4.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.set_table_styles',\n",
       "       'descriptions': 'Set the table styles included within the <style> HTML element. This function can be used to style the entire table, columns, rows or\\nspecific HTML selectors.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'table_styles': {'type': 'array',\n",
       "          'description': 'list or dict. If supplying a list, each individual table_style should be a\\ndictionary with selector and props keys. selector\\nshould be a CSS selector that the style will be applied to\\n(automatically prefixed by the table’s UUID) and props\\nshould be a list of tuples with (attribute, value).\\nIf supplying a dict, the dict keys should correspond to\\ncolumn names or index values, depending upon the specified\\naxis argument. These will be mapped to row or col CSS\\nselectors. MultiIndex values as dict keys should be\\nin their respective tuple form. The dict values should be\\na list as specified in the form with CSS selectors and\\nprops that will be applied to the specified row or column.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns', ' None'],\n",
       "          'description': \"{0 or ‘index’, 1 or ‘columns’, None}, default 0. Apply to each column (axis=0 or 'index'), to each row\\n(axis=1 or 'columns'). Only used if table_styles is\\ndict.\\n\"},\n",
       "         'overwrite': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Styles are replaced if True, or extended if False. CSS\\nrules are preserved so most recent styles set will dominate\\nif selectors intersect.\\n'},\n",
       "         'css_class_names': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. A dict of strings used to replace the default CSS classes described below.\\n\\nNew in version 1.4.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Styler.set_tooltips(ttips[,\\xa0props,\\xa0css_class])',\n",
       "      'func_desc': 'Set the DataFrame of strings on Styler generating :hover tooltips.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.set_tooltips.html#pandas.io.formats.style.Styler.set_tooltips',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.set_tooltips',\n",
       "       'full_function': 'Styler.set_tooltips(ttips, props=None, css_class=None)',\n",
       "       'function_text': 'Set the DataFrame of strings on Styler generating :hover tooltips. These string based tooltips are only applicable to <td> HTML elements,\\nand cannot be used for column or index headers. New in version 1.3.0.',\n",
       "       'parameter_names_desc': [{'param_name': 'ttips',\n",
       "         'param_type': 'DataFrame',\n",
       "         'param_desc': 'DataFrame containing strings that will be translated to tooltips, mapped\\nby identical column and index values that must exist on the underlying\\nStyler data. None, NaN values, and empty strings will be ignored and\\nnot affect the rendered HTML.\\n'},\n",
       "        {'param_name': 'props',\n",
       "         'param_type': 'list-like or str, optional',\n",
       "         'param_desc': 'List of (attr, value) tuples or a valid CSS string. If None adopts\\nthe internal default values described in notes.\\n'},\n",
       "        {'param_name': 'css_class',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Name of the tooltip class used in CSS, should conform to HTML standards.\\nOnly useful if integrating tooltips with external CSS. If None uses the\\ninternal default value ‘pd-t’.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.set_tooltips',\n",
       "       'descriptions': 'Set the DataFrame of strings on Styler generating :hover tooltips. These string based tooltips are only applicable to <td> HTML elements,\\nand cannot be used for column or index headers. New in version 1.3.0.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'ttips': {'type': 'DataFrame',\n",
       "          'description': 'DataFrame. DataFrame containing strings that will be translated to tooltips, mapped\\nby identical column and index values that must exist on the underlying\\nStyler data. None, NaN values, and empty strings will be ignored and\\nnot affect the rendered HTML.\\n'},\n",
       "         'props': {'type': 'string',\n",
       "          'description': 'list-like or str, optional. List of (attr, value) tuples or a valid CSS string. If None adopts\\nthe internal default values described in notes.\\n'},\n",
       "         'css_class': {'type': 'string',\n",
       "          'description': 'str, optional. Name of the tooltip class used in CSS, should conform to HTML standards.\\nOnly useful if integrating tooltips with external CSS. If None uses the\\ninternal default value ‘pd-t’.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Styler.set_sticky([axis,\\xa0pixel_size,\\xa0levels])',\n",
       "      'func_desc': 'Add CSS to permanently display the index or column headers in a scrolling frame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.set_sticky.html#pandas.io.formats.style.Styler.set_sticky',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.set_sticky',\n",
       "       'full_function': 'Styler.set_sticky(axis=0, pixel_size=None, levels=None)',\n",
       "       'function_text': 'Add CSS to permanently display the index or column headers in a scrolling frame.',\n",
       "       'parameter_names_desc': [{'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’}, default 0',\n",
       "         'param_desc': 'Whether to make the index or column headers sticky.\\n'},\n",
       "        {'param_name': 'pixel_size',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Required to configure the width of index cells or the height of column\\nheader cells when sticking a MultiIndex (or with a named Index).\\nDefaults to 75 and 25 respectively.\\n'},\n",
       "        {'param_name': 'levels',\n",
       "         'param_type': 'int, str, list, optional',\n",
       "         'param_desc': 'If axis is a MultiIndex the specific levels to stick. If None will\\nstick all levels.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.set_sticky',\n",
       "       'descriptions': 'Add CSS to permanently display the index or column headers in a scrolling frame.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’}, default 0. Whether to make the index or column headers sticky.\\n'},\n",
       "         'pixel_size': {'type': 'integer',\n",
       "          'description': 'int, optional. Required to configure the width of index cells or the height of column\\nheader cells when sticking a MultiIndex (or with a named Index).\\nDefaults to 75 and 25 respectively.\\n'},\n",
       "         'levels': {'type': 'integer',\n",
       "          'description': 'int, str, list, optional. If axis is a MultiIndex the specific levels to stick. If None will\\nstick all levels.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Styler.set_uuid(uuid)',\n",
       "      'func_desc': 'Set the uuid applied to id attributes of HTML elements.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.set_uuid.html#pandas.io.formats.style.Styler.set_uuid',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.set_uuid',\n",
       "       'full_function': 'Styler.set_uuid(uuid)',\n",
       "       'function_text': 'Set the uuid applied to id attributes of HTML elements.',\n",
       "       'parameter_names_desc': [{'param_name': 'uuid',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.set_uuid',\n",
       "       'descriptions': 'Set the uuid applied to id attributes of HTML elements.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'uuid': {'type': 'string', 'description': 'str. '}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Styler.pipe(func,\\xa0*args,\\xa0**kwargs)',\n",
       "      'func_desc': 'Apply func(self, *args, **kwargs), and return the result.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.pipe.html#pandas.io.formats.style.Styler.pipe',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.pipe',\n",
       "       'full_function': 'Styler.pipe(func, *args, **kwargs)',\n",
       "       'function_text': 'Apply func(self, *args, **kwargs), and return the result.',\n",
       "       'parameter_names_desc': [{'param_name': 'func',\n",
       "         'param_type': 'function',\n",
       "         'param_desc': 'Function to apply to the Styler. Alternatively, a\\n(callable, keyword) tuple where keyword is a string\\nindicating the keyword of callable that expects the Styler.\\n'},\n",
       "        {'param_name': '*args',\n",
       "         'param_type': 'optional',\n",
       "         'param_desc': 'Arguments passed to func.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.pipe',\n",
       "       'descriptions': 'Apply func(self, *args, **kwargs), and return the result.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'func': {'type': 'function',\n",
       "          'description': 'function. Function to apply to the Styler. Alternatively, a\\n(callable, keyword) tuple where keyword is a string\\nindicating the keyword of callable that expects the Styler.\\n'},\n",
       "         '*args': {'type': 'optional',\n",
       "          'description': 'optional. Arguments passed to func.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Styler.map(func[,\\xa0subset])',\n",
       "      'func_desc': 'Apply a CSS-styling function elementwise.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.map.html#pandas.io.formats.style.Styler.map',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.map',\n",
       "       'full_function': 'Styler.map(func, subset=None, **kwargs)',\n",
       "       'function_text': 'Apply a CSS-styling function elementwise. Updates the HTML representation with the result.',\n",
       "       'parameter_names_desc': [{'param_name': 'func',\n",
       "         'param_type': 'function',\n",
       "         'param_desc': 'func should take a scalar and return a string.\\n'},\n",
       "        {'param_name': 'subset',\n",
       "         'param_type': 'label, array-like, IndexSlice, optional',\n",
       "         'param_desc': 'A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\\nor single key, to DataFrame.loc[:, <subset>] where the columns are\\nprioritised, to limit data to before applying the function.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.map',\n",
       "       'descriptions': 'Apply a CSS-styling function elementwise. Updates the HTML representation with the result.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'func': {'type': 'function',\n",
       "          'description': 'function. func should take a scalar and return a string.\\n'},\n",
       "         'subset': {'type': 'array',\n",
       "          'description': 'label, array-like, IndexSlice, optional. A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\\nor single key, to DataFrame.loc[:, <subset>] where the columns are\\nprioritised, to limit data to before applying the function.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Styler.map_index(func[,\\xa0axis,\\xa0level])',\n",
       "      'func_desc': 'Apply a CSS-styling function to the index or column headers, elementwise.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.map_index.html#pandas.io.formats.style.Styler.map_index',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.map_index',\n",
       "       'full_function': 'Styler.map_index(func, axis=0, level=None, **kwargs)',\n",
       "       'function_text': 'Apply a CSS-styling function to the index or column headers, elementwise. Updates the HTML representation with the result. New in version 1.4.0. New in version 2.1.0: Styler.applymap_index was deprecated and renamed to Styler.map_index.',\n",
       "       'parameter_names_desc': [{'param_name': 'func',\n",
       "         'param_type': 'function',\n",
       "         'param_desc': 'func should take a scalar and return a string.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0, 1, “index”, “columns”}',\n",
       "         'param_desc': 'The headers over which to apply the function.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int, str, list, optional',\n",
       "         'param_desc': 'If index is MultiIndex the level(s) over which to apply the function.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.map_index',\n",
       "       'descriptions': 'Apply a CSS-styling function to the index or column headers, elementwise. Updates the HTML representation with the result. New in version 1.4.0. New in version 2.1.0: Styler.applymap_index was deprecated and renamed to Styler.map_index.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'func': {'type': 'function',\n",
       "          'description': 'function. func should take a scalar and return a string.\\n'},\n",
       "         'axis': {'type': '{0, 1, “index”, “columns”}',\n",
       "          'description': '{0, 1, “index”, “columns”}. The headers over which to apply the function.\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int, str, list, optional. If index is MultiIndex the level(s) over which to apply the function.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Styler.format_index([formatter,\\xa0axis,\\xa0...])',\n",
       "      'func_desc': 'Format the text display value of index labels or column headers.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.format_index.html#pandas.io.formats.style.Styler.format_index',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.format_index',\n",
       "       'full_function': \"Styler.format_index(formatter=None, axis=0, level=None, na_rep=None, precision=None, decimal='.', thousands=None, escape=None, hyperlinks=None)\",\n",
       "       'function_text': 'Format the text display value of index labels or column headers. New in version 1.4.0.',\n",
       "       'parameter_names_desc': [{'param_name': 'formatter',\n",
       "         'param_type': 'str, callable, dict or None',\n",
       "         'param_desc': 'Object to define how values are displayed. See notes.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0, “index”, 1, “columns”}',\n",
       "         'param_desc': 'Whether to apply the formatter to the index or column headers.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int, str, list',\n",
       "         'param_desc': 'The level(s) over which to apply the generic formatter.\\n'},\n",
       "        {'param_name': 'na_rep',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Representation for missing values.\\nIf na_rep is None, no special formatting is applied.\\n'},\n",
       "        {'param_name': 'precision',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'Floating point precision to use for display purposes, if not determined by\\nthe specified formatter.\\n'},\n",
       "        {'param_name': 'decimal',\n",
       "         'param_type': 'str, default “.”',\n",
       "         'param_desc': 'Character used as decimal separator for floats, complex and integers.\\n'},\n",
       "        {'param_name': 'thousands',\n",
       "         'param_type': 'str, optional, default None',\n",
       "         'param_desc': 'Character used as thousands separator for floats, complex and integers.\\n'},\n",
       "        {'param_name': 'escape',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Use ‘html’ to replace the characters &, <, >, \\', and \"\\nin cell display string with HTML-safe sequences.\\nUse ‘latex’ to replace the characters &, %, $, #, _,\\n{, }, ~, ^, and \\\\ in the cell display string with\\nLaTeX-safe sequences.\\nEscaping is done before formatter.\\n'},\n",
       "        {'param_name': 'hyperlinks',\n",
       "         'param_type': '{“html”, “latex”}, optional',\n",
       "         'param_desc': 'Convert string patterns containing https://, http://, ftp:// or www. to\\nHTML <a> tags as clickable URL hyperlinks if “html”, or LaTeX href\\ncommands if “latex”.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.format_index',\n",
       "       'descriptions': 'Format the text display value of index labels or column headers. New in version 1.4.0.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'formatter': {'type': 'string',\n",
       "          'description': 'str, callable, dict or None. Object to define how values are displayed. See notes.\\n'},\n",
       "         'axis': {'type': '{0, “index”, 1, “columns”}',\n",
       "          'description': '{0, “index”, 1, “columns”}. Whether to apply the formatter to the index or column headers.\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int, str, list. The level(s) over which to apply the generic formatter.\\n'},\n",
       "         'na_rep': {'type': 'string',\n",
       "          'description': 'str, optional. Representation for missing values.\\nIf na_rep is None, no special formatting is applied.\\n'},\n",
       "         'precision': {'type': 'integer',\n",
       "          'description': 'int, optional. Floating point precision to use for display purposes, if not determined by\\nthe specified formatter.\\n'},\n",
       "         'decimal': {'type': 'string',\n",
       "          'description': 'str, default “.”. Character used as decimal separator for floats, complex and integers.\\n'},\n",
       "         'thousands': {'type': 'string',\n",
       "          'description': 'str, optional, default None. Character used as thousands separator for floats, complex and integers.\\n'},\n",
       "         'escape': {'type': 'string',\n",
       "          'description': 'str, optional. Use ‘html’ to replace the characters &, <, >, \\', and \"\\nin cell display string with HTML-safe sequences.\\nUse ‘latex’ to replace the characters &, %, $, #, _,\\n{, }, ~, ^, and \\\\ in the cell display string with\\nLaTeX-safe sequences.\\nEscaping is done before formatter.\\n'},\n",
       "         'hyperlinks': {'type': '{“html”, “latex”}, optional',\n",
       "          'description': '{“html”, “latex”}, optional. Convert string patterns containing https://, http://, ftp:// or www. to\\nHTML <a> tags as clickable URL hyperlinks if “html”, or LaTeX href\\ncommands if “latex”.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Styler.hide([subset,\\xa0axis,\\xa0level,\\xa0names])',\n",
       "      'func_desc': 'Hide the entire index / column headers, or specific rows / columns from display.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.hide.html#pandas.io.formats.style.Styler.hide',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.hide',\n",
       "       'full_function': 'Styler.hide(subset=None, axis=0, level=None, names=False)',\n",
       "       'function_text': 'Hide the entire index / column headers, or specific rows / columns from display. New in version 1.4.0.',\n",
       "       'parameter_names_desc': [{'param_name': 'subset',\n",
       "         'param_type': 'label, array-like, IndexSlice, optional',\n",
       "         'param_desc': 'A valid 1d input or single key along the axis within\\nDataFrame.loc[<subset>, :] or DataFrame.loc[:, <subset>] depending\\nupon axis, to limit data to select hidden rows / columns.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{“index”, 0, “columns”, 1}',\n",
       "         'param_desc': 'Apply to the index or columns.\\n'},\n",
       "        {'param_name': 'level',\n",
       "         'param_type': 'int, str, list',\n",
       "         'param_desc': 'The level(s) to hide in a MultiIndex if hiding the entire index / column\\nheaders. Cannot be used simultaneously with subset.\\n'},\n",
       "        {'param_name': 'names',\n",
       "         'param_type': 'bool',\n",
       "         'param_desc': 'Whether to hide the level name(s) of the index / columns headers in the case\\nit (or at least one the levels) remains visible.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.hide',\n",
       "       'descriptions': 'Hide the entire index / column headers, or specific rows / columns from display. New in version 1.4.0.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'subset': {'type': 'array',\n",
       "          'description': 'label, array-like, IndexSlice, optional. A valid 1d input or single key along the axis within\\nDataFrame.loc[<subset>, :] or DataFrame.loc[:, <subset>] depending\\nupon axis, to limit data to select hidden rows / columns.\\n'},\n",
       "         'axis': {'type': '{“index”, 0, “columns”, 1}',\n",
       "          'description': '{“index”, 0, “columns”, 1}. Apply to the index or columns.\\n'},\n",
       "         'level': {'type': 'integer',\n",
       "          'description': 'int, str, list. The level(s) to hide in a MultiIndex if hiding the entire index / column\\nheaders. Cannot be used simultaneously with subset.\\n'},\n",
       "         'names': {'type': 'boolean',\n",
       "          'description': 'bool. Whether to hide the level name(s) of the index / columns headers in the case\\nit (or at least one the levels) remains visible.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Styler.set_td_classes(classes)',\n",
       "      'func_desc': 'Set the class attribute of <td> HTML elements.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.set_td_classes.html#pandas.io.formats.style.Styler.set_td_classes',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.set_td_classes',\n",
       "       'full_function': 'Styler.set_td_classes(classes)',\n",
       "       'function_text': 'Set the class attribute of <td> HTML elements.',\n",
       "       'parameter_names_desc': [{'param_name': 'classes',\n",
       "         'param_type': 'DataFrame',\n",
       "         'param_desc': 'DataFrame containing strings that will be translated to CSS classes,\\nmapped by identical column and index key values that must exist on the\\nunderlying Styler data. None, NaN values, and empty strings will\\nbe ignored and not affect the rendered HTML.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.set_td_classes',\n",
       "       'descriptions': 'Set the class attribute of <td> HTML elements.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'classes': {'type': 'DataFrame',\n",
       "          'description': 'DataFrame. DataFrame containing strings that will be translated to CSS classes,\\nmapped by identical column and index key values that must exist on the\\nunderlying Styler data. None, NaN values, and empty strings will\\nbe ignored and not affect the rendered HTML.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Styler.set_table_attributes(attributes)',\n",
       "      'func_desc': 'Set the table attributes added to the <table> HTML element.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.set_table_attributes.html#pandas.io.formats.style.Styler.set_table_attributes',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.set_table_attributes',\n",
       "       'full_function': 'Styler.set_table_attributes(attributes)',\n",
       "       'function_text': 'Set the table attributes added to the <table> HTML element. These are items in addition to automatic (by default) id attribute.',\n",
       "       'parameter_names_desc': [{'param_name': 'attributes',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.set_table_attributes',\n",
       "       'descriptions': 'Set the table attributes added to the <table> HTML element. These are items in addition to automatic (by default) id attribute.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'attributes': {'type': 'string',\n",
       "          'description': 'str. '}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Styler.set_caption(caption)',\n",
       "      'func_desc': 'Set the text added to a <caption> HTML element.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.set_caption.html#pandas.io.formats.style.Styler.set_caption',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.set_caption',\n",
       "       'full_function': 'Styler.set_caption(caption)',\n",
       "       'function_text': 'Set the text added to a <caption> HTML element.',\n",
       "       'parameter_names_desc': [{'param_name': 'caption',\n",
       "         'param_type': 'str, tuple, list',\n",
       "         'param_desc': 'For HTML output either the string input is used or the first element of the\\ntuple. For LaTeX the string input provides a caption and the additional\\ntuple input allows for full captions and short captions, in that order.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.set_caption',\n",
       "       'descriptions': 'Set the text added to a <caption> HTML element.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'caption': {'type': 'string',\n",
       "          'description': 'str, tuple, list. For HTML output either the string input is used or the first element of the\\ntuple. For LaTeX the string input provides a caption and the additional\\ntuple input allows for full captions and short captions, in that order.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Styler.set_properties([subset])',\n",
       "      'func_desc': 'Set defined CSS-properties to each <td> HTML element for the given subset.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.set_properties.html#pandas.io.formats.style.Styler.set_properties',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.set_properties',\n",
       "       'full_function': 'Styler.set_properties(subset=None, **kwargs)',\n",
       "       'function_text': 'Set defined CSS-properties to each <td> HTML element for the given subset.',\n",
       "       'parameter_names_desc': [{'param_name': 'subset',\n",
       "         'param_type': 'label, array-like, IndexSlice, optional',\n",
       "         'param_desc': 'A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\\nor single key, to DataFrame.loc[:, <subset>] where the columns are\\nprioritised, to limit data to before applying the function.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.set_properties',\n",
       "       'descriptions': 'Set defined CSS-properties to each <td> HTML element for the given subset.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'subset': {'type': 'array',\n",
       "          'description': 'label, array-like, IndexSlice, optional. A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\\nor single key, to DataFrame.loc[:, <subset>] where the columns are\\nprioritised, to limit data to before applying the function.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Styler.clear()',\n",
       "      'func_desc': 'Reset the Styler, removing any previously applied styles.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.clear.html#pandas.io.formats.style.Styler.clear',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.clear',\n",
       "       'full_function': 'Styler.clear()',\n",
       "       'function_text': 'Reset the Styler, removing any previously applied styles. Returns None. Examples After any added style: Remove it with: Please see:\\nTable Visualization for more examples.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'Builtin styles': [{'func_name': 'Styler.highlight_null([color,\\xa0subset,\\xa0props])',\n",
       "      'func_desc': 'Highlight missing values with a style.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.highlight_null.html#pandas.io.formats.style.Styler.highlight_null',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.highlight_null',\n",
       "       'full_function': \"Styler.highlight_null(color='red', subset=None, props=None)\",\n",
       "       'function_text': 'Highlight missing values with a style.',\n",
       "       'parameter_names_desc': [{'param_name': 'color',\n",
       "         'param_type': 'str, default ‘red’',\n",
       "         'param_desc': 'Background color to use for highlighting.\\n\\n\\nNew in version 1.5.0.\\n\\n\\n'},\n",
       "        {'param_name': 'subset',\n",
       "         'param_type': 'label, array-like, IndexSlice, optional',\n",
       "         'param_desc': 'A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\\nor single key, to DataFrame.loc[:, <subset>] where the columns are\\nprioritised, to limit data to before applying the function.\\n'},\n",
       "        {'param_name': 'props',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'CSS properties to use for highlighting. If props is given, color\\nis not used.\\n\\n\\nNew in version 1.3.0.\\n\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.highlight_null',\n",
       "       'descriptions': 'Highlight missing values with a style.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'color': {'type': 'string',\n",
       "          'description': 'str, default ‘red’. Background color to use for highlighting.\\n\\n\\nNew in version 1.5.0.\\n\\n\\n'},\n",
       "         'subset': {'type': 'array',\n",
       "          'description': 'label, array-like, IndexSlice, optional. A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\\nor single key, to DataFrame.loc[:, <subset>] where the columns are\\nprioritised, to limit data to before applying the function.\\n'},\n",
       "         'props': {'type': 'string',\n",
       "          'description': 'str, default None. CSS properties to use for highlighting. If props is given, color\\nis not used.\\n\\n\\nNew in version 1.3.0.\\n\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Styler.highlight_min([subset,\\xa0color,\\xa0axis,\\xa0...])',\n",
       "      'func_desc': 'Highlight the minimum with a style.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.highlight_min.html#pandas.io.formats.style.Styler.highlight_min',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.highlight_min',\n",
       "       'full_function': \"Styler.highlight_min(subset=None, color='yellow', axis=0, props=None)\",\n",
       "       'function_text': 'Highlight the minimum with a style.',\n",
       "       'parameter_names_desc': [{'param_name': 'subset',\n",
       "         'param_type': 'label, array-like, IndexSlice, optional',\n",
       "         'param_desc': 'A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\\nor single key, to DataFrame.loc[:, <subset>] where the columns are\\nprioritised, to limit data to before applying the function.\\n'},\n",
       "        {'param_name': 'color',\n",
       "         'param_type': 'str, default ‘yellow’',\n",
       "         'param_desc': 'Background color to use for highlighting.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’, None}, default 0',\n",
       "         'param_desc': \"Apply to each column (axis=0 or 'index'), to each row\\n(axis=1 or 'columns'), or to the entire DataFrame at once\\nwith axis=None.\\n\"},\n",
       "        {'param_name': 'props',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'CSS properties to use for highlighting. If props is given, color\\nis not used.\\n\\n\\nNew in version 1.3.0.\\n\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.highlight_min',\n",
       "       'descriptions': 'Highlight the minimum with a style.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'subset': {'type': 'array',\n",
       "          'description': 'label, array-like, IndexSlice, optional. A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\\nor single key, to DataFrame.loc[:, <subset>] where the columns are\\nprioritised, to limit data to before applying the function.\\n'},\n",
       "         'color': {'type': 'string',\n",
       "          'description': 'str, default ‘yellow’. Background color to use for highlighting.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns', ' None'],\n",
       "          'description': \"{0 or ‘index’, 1 or ‘columns’, None}, default 0. Apply to each column (axis=0 or 'index'), to each row\\n(axis=1 or 'columns'), or to the entire DataFrame at once\\nwith axis=None.\\n\"},\n",
       "         'props': {'type': 'string',\n",
       "          'description': 'str, default None. CSS properties to use for highlighting. If props is given, color\\nis not used.\\n\\n\\nNew in version 1.3.0.\\n\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Styler.highlight_quantile([subset,\\xa0color,\\xa0...])',\n",
       "      'func_desc': 'Highlight values defined by a quantile with a style.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.highlight_quantile.html#pandas.io.formats.style.Styler.highlight_quantile',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.highlight_quantile',\n",
       "       'full_function': \"Styler.highlight_quantile(subset=None, color='yellow', axis=0, q_left=0.0, q_right=1.0, interpolation='linear', inclusive='both', props=None)\",\n",
       "       'function_text': 'Highlight values defined by a quantile with a style. New in version 1.3.0.',\n",
       "       'parameter_names_desc': [{'param_name': 'subset',\n",
       "         'param_type': 'label, array-like, IndexSlice, optional',\n",
       "         'param_desc': 'A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\\nor single key, to DataFrame.loc[:, <subset>] where the columns are\\nprioritised, to limit data to before applying the function.\\n'},\n",
       "        {'param_name': 'color',\n",
       "         'param_type': 'str, default ‘yellow’',\n",
       "         'param_desc': 'Background color to use for highlighting.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’, None}, default 0',\n",
       "         'param_desc': 'Axis along which to determine and highlight quantiles. If None quantiles\\nare measured over the entire DataFrame. See examples.\\n'},\n",
       "        {'param_name': 'q_left',\n",
       "         'param_type': 'float, default 0',\n",
       "         'param_desc': 'Left bound, in [0, q_right), for the target quantile range.\\n'},\n",
       "        {'param_name': 'q_right',\n",
       "         'param_type': 'float, default 1',\n",
       "         'param_desc': 'Right bound, in (q_left, 1], for the target quantile range.\\n'},\n",
       "        {'param_name': 'interpolation',\n",
       "         'param_type': '{‘linear’, ‘lower’, ‘higher’, ‘midpoint’, ‘nearest’}',\n",
       "         'param_desc': 'Argument passed to Series.quantile or DataFrame.quantile for\\nquantile estimation.\\n'},\n",
       "        {'param_name': 'inclusive',\n",
       "         'param_type': '{‘both’, ‘neither’, ‘left’, ‘right’}',\n",
       "         'param_desc': 'Identify whether quantile bounds are closed or open.\\n'},\n",
       "        {'param_name': 'props',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'CSS properties to use for highlighting. If props is given, color\\nis not used.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.highlight_quantile',\n",
       "       'descriptions': 'Highlight values defined by a quantile with a style. New in version 1.3.0.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'subset': {'type': 'array',\n",
       "          'description': 'label, array-like, IndexSlice, optional. A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\\nor single key, to DataFrame.loc[:, <subset>] where the columns are\\nprioritised, to limit data to before applying the function.\\n'},\n",
       "         'color': {'type': 'string',\n",
       "          'description': 'str, default ‘yellow’. Background color to use for highlighting.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns', ' None'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’, None}, default 0. Axis along which to determine and highlight quantiles. If None quantiles\\nare measured over the entire DataFrame. See examples.\\n'},\n",
       "         'q_left': {'type': 'float',\n",
       "          'description': 'float, default 0. Left bound, in [0, q_right), for the target quantile range.\\n'},\n",
       "         'q_right': {'type': 'float',\n",
       "          'description': 'float, default 1. Right bound, in (q_left, 1], for the target quantile range.\\n'},\n",
       "         'interpolation': {'type': 'integer',\n",
       "          'description': '{‘linear’, ‘lower’, ‘higher’, ‘midpoint’, ‘nearest’}. Argument passed to Series.quantile or DataFrame.quantile for\\nquantile estimation.\\n'},\n",
       "         'inclusive': {'type': 'string',\n",
       "          'enum': ['both', ' neither', ' left', ' right'],\n",
       "          'description': '{‘both’, ‘neither’, ‘left’, ‘right’}. Identify whether quantile bounds are closed or open.\\n'},\n",
       "         'props': {'type': 'string',\n",
       "          'description': 'str, default None. CSS properties to use for highlighting. If props is given, color\\nis not used.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Styler.text_gradient([cmap,\\xa0low,\\xa0high,\\xa0...])',\n",
       "      'func_desc': 'Color the text in a gradient style.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.text_gradient.html#pandas.io.formats.style.Styler.text_gradient',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.text_gradient',\n",
       "       'full_function': \"Styler.text_gradient(cmap='PuBu', low=0, high=0, axis=0, subset=None, vmin=None, vmax=None, gmap=None)\",\n",
       "       'function_text': 'Color the text in a gradient style. The text color is determined according\\nto the data in each column, row or frame, or by a given\\ngradient map. Requires matplotlib.',\n",
       "       'parameter_names_desc': [{'param_name': 'cmap',\n",
       "         'param_type': 'str or colormap',\n",
       "         'param_desc': 'Matplotlib colormap.\\n'},\n",
       "        {'param_name': 'low',\n",
       "         'param_type': 'float',\n",
       "         'param_desc': 'Compress the color range at the low end. This is a multiple of the data\\nrange to extend below the minimum; good values usually in [0, 1],\\ndefaults to 0.\\n'},\n",
       "        {'param_name': 'high',\n",
       "         'param_type': 'float',\n",
       "         'param_desc': 'Compress the color range at the high end. This is a multiple of the data\\nrange to extend above the maximum; good values usually in [0, 1],\\ndefaults to 0.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0, 1, “index”, “columns”, None}, default 0',\n",
       "         'param_desc': \"Apply to each column (axis=0 or 'index'), to each row\\n(axis=1 or 'columns'), or to the entire DataFrame at once\\nwith axis=None.\\n\"},\n",
       "        {'param_name': 'subset',\n",
       "         'param_type': 'label, array-like, IndexSlice, optional',\n",
       "         'param_desc': 'A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\\nor single key, to DataFrame.loc[:, <subset>] where the columns are\\nprioritised, to limit data to before applying the function.\\n'},\n",
       "        {'param_name': 'vmin',\n",
       "         'param_type': 'float, optional',\n",
       "         'param_desc': 'Minimum data value that corresponds to colormap minimum value.\\nIf not specified the minimum value of the data (or gmap) will be used.\\n'},\n",
       "        {'param_name': 'vmax',\n",
       "         'param_type': 'float, optional',\n",
       "         'param_desc': 'Maximum data value that corresponds to colormap maximum value.\\nIf not specified the maximum value of the data (or gmap) will be used.\\n'},\n",
       "        {'param_name': 'gmap',\n",
       "         'param_type': 'array-like, optional',\n",
       "         'param_desc': 'Gradient map for determining the text colors. If not supplied\\nwill use the underlying data from rows, columns or frame. If given as an\\nndarray or list-like must be an identical shape to the underlying data\\nconsidering axis and subset. If given as DataFrame or Series must\\nhave same index and column labels considering axis and subset.\\nIf supplied, vmin and vmax should be given relative to this\\ngradient map.\\n\\nNew in version 1.3.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.text_gradient',\n",
       "       'descriptions': 'Color the text in a gradient style. The text color is determined according\\nto the data in each column, row or frame, or by a given\\ngradient map. Requires matplotlib.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'cmap': {'type': 'string',\n",
       "          'description': 'str or colormap. Matplotlib colormap.\\n'},\n",
       "         'low': {'type': 'float',\n",
       "          'description': 'float. Compress the color range at the low end. This is a multiple of the data\\nrange to extend below the minimum; good values usually in [0, 1],\\ndefaults to 0.\\n'},\n",
       "         'high': {'type': 'float',\n",
       "          'description': 'float. Compress the color range at the high end. This is a multiple of the data\\nrange to extend above the maximum; good values usually in [0, 1],\\ndefaults to 0.\\n'},\n",
       "         'axis': {'type': '{0, 1, “index”, “columns”, None}, default 0',\n",
       "          'description': \"{0, 1, “index”, “columns”, None}, default 0. Apply to each column (axis=0 or 'index'), to each row\\n(axis=1 or 'columns'), or to the entire DataFrame at once\\nwith axis=None.\\n\"},\n",
       "         'subset': {'type': 'array',\n",
       "          'description': 'label, array-like, IndexSlice, optional. A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\\nor single key, to DataFrame.loc[:, <subset>] where the columns are\\nprioritised, to limit data to before applying the function.\\n'},\n",
       "         'vmin': {'type': 'float',\n",
       "          'description': 'float, optional. Minimum data value that corresponds to colormap minimum value.\\nIf not specified the minimum value of the data (or gmap) will be used.\\n'},\n",
       "         'vmax': {'type': 'float',\n",
       "          'description': 'float, optional. Maximum data value that corresponds to colormap maximum value.\\nIf not specified the maximum value of the data (or gmap) will be used.\\n'},\n",
       "         'gmap': {'type': 'array',\n",
       "          'description': 'array-like, optional. Gradient map for determining the text colors. If not supplied\\nwill use the underlying data from rows, columns or frame. If given as an\\nndarray or list-like must be an identical shape to the underlying data\\nconsidering axis and subset. If given as DataFrame or Series must\\nhave same index and column labels considering axis and subset.\\nIf supplied, vmin and vmax should be given relative to this\\ngradient map.\\n\\nNew in version 1.3.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Styler.highlight_max([subset,\\xa0color,\\xa0axis,\\xa0...])',\n",
       "      'func_desc': 'Highlight the maximum with a style.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.highlight_max.html#pandas.io.formats.style.Styler.highlight_max',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.highlight_max',\n",
       "       'full_function': \"Styler.highlight_max(subset=None, color='yellow', axis=0, props=None)\",\n",
       "       'function_text': 'Highlight the maximum with a style.',\n",
       "       'parameter_names_desc': [{'param_name': 'subset',\n",
       "         'param_type': 'label, array-like, IndexSlice, optional',\n",
       "         'param_desc': 'A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\\nor single key, to DataFrame.loc[:, <subset>] where the columns are\\nprioritised, to limit data to before applying the function.\\n'},\n",
       "        {'param_name': 'color',\n",
       "         'param_type': 'str, default ‘yellow’',\n",
       "         'param_desc': 'Background color to use for highlighting.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’, None}, default 0',\n",
       "         'param_desc': \"Apply to each column (axis=0 or 'index'), to each row\\n(axis=1 or 'columns'), or to the entire DataFrame at once\\nwith axis=None.\\n\"},\n",
       "        {'param_name': 'props',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'CSS properties to use for highlighting. If props is given, color\\nis not used.\\n\\n\\nNew in version 1.3.0.\\n\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.highlight_max',\n",
       "       'descriptions': 'Highlight the maximum with a style.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'subset': {'type': 'array',\n",
       "          'description': 'label, array-like, IndexSlice, optional. A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\\nor single key, to DataFrame.loc[:, <subset>] where the columns are\\nprioritised, to limit data to before applying the function.\\n'},\n",
       "         'color': {'type': 'string',\n",
       "          'description': 'str, default ‘yellow’. Background color to use for highlighting.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns', ' None'],\n",
       "          'description': \"{0 or ‘index’, 1 or ‘columns’, None}, default 0. Apply to each column (axis=0 or 'index'), to each row\\n(axis=1 or 'columns'), or to the entire DataFrame at once\\nwith axis=None.\\n\"},\n",
       "         'props': {'type': 'string',\n",
       "          'description': 'str, default None. CSS properties to use for highlighting. If props is given, color\\nis not used.\\n\\n\\nNew in version 1.3.0.\\n\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Styler.highlight_between([subset,\\xa0color,\\xa0...])',\n",
       "      'func_desc': 'Highlight a defined range with a style.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.highlight_between.html#pandas.io.formats.style.Styler.highlight_between',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.highlight_between',\n",
       "       'full_function': \"Styler.highlight_between(subset=None, color='yellow', axis=0, left=None, right=None, inclusive='both', props=None)\",\n",
       "       'function_text': 'Highlight a defined range with a style. New in version 1.3.0.',\n",
       "       'parameter_names_desc': [{'param_name': 'subset',\n",
       "         'param_type': 'label, array-like, IndexSlice, optional',\n",
       "         'param_desc': 'A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\\nor single key, to DataFrame.loc[:, <subset>] where the columns are\\nprioritised, to limit data to before applying the function.\\n'},\n",
       "        {'param_name': 'color',\n",
       "         'param_type': 'str, default ‘yellow’',\n",
       "         'param_desc': 'Background color to use for highlighting.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’, None}, default 0',\n",
       "         'param_desc': 'If left or right given as sequence, axis along which to apply those\\nboundaries. See examples.\\n'},\n",
       "        {'param_name': 'left',\n",
       "         'param_type': 'scalar or datetime-like, or sequence or array-like, default None',\n",
       "         'param_desc': 'Left bound for defining the range.\\n'},\n",
       "        {'param_name': 'right',\n",
       "         'param_type': 'scalar or datetime-like, or sequence or array-like, default None',\n",
       "         'param_desc': 'Right bound for defining the range.\\n'},\n",
       "        {'param_name': 'inclusive',\n",
       "         'param_type': '{‘both’, ‘neither’, ‘left’, ‘right’}',\n",
       "         'param_desc': 'Identify whether bounds are closed or open.\\n'},\n",
       "        {'param_name': 'props',\n",
       "         'param_type': 'str, default None',\n",
       "         'param_desc': 'CSS properties to use for highlighting. If props is given, color\\nis not used.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.highlight_between',\n",
       "       'descriptions': 'Highlight a defined range with a style. New in version 1.3.0.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'subset': {'type': 'array',\n",
       "          'description': 'label, array-like, IndexSlice, optional. A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\\nor single key, to DataFrame.loc[:, <subset>] where the columns are\\nprioritised, to limit data to before applying the function.\\n'},\n",
       "         'color': {'type': 'string',\n",
       "          'description': 'str, default ‘yellow’. Background color to use for highlighting.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns', ' None'],\n",
       "          'description': '{0 or ‘index’, 1 or ‘columns’, None}, default 0. If left or right given as sequence, axis along which to apply those\\nboundaries. See examples.\\n'},\n",
       "         'left': {'type': 'array',\n",
       "          'description': 'scalar or datetime-like, or sequence or array-like, default None. Left bound for defining the range.\\n'},\n",
       "         'right': {'type': 'array',\n",
       "          'description': 'scalar or datetime-like, or sequence or array-like, default None. Right bound for defining the range.\\n'},\n",
       "         'inclusive': {'type': 'string',\n",
       "          'enum': ['both', ' neither', ' left', ' right'],\n",
       "          'description': '{‘both’, ‘neither’, ‘left’, ‘right’}. Identify whether bounds are closed or open.\\n'},\n",
       "         'props': {'type': 'string',\n",
       "          'description': 'str, default None. CSS properties to use for highlighting. If props is given, color\\nis not used.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Styler.background_gradient([cmap,\\xa0low,\\xa0...])',\n",
       "      'func_desc': 'Color the background in a gradient style.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.background_gradient.html#pandas.io.formats.style.Styler.background_gradient',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.background_gradient',\n",
       "       'full_function': \"Styler.background_gradient(cmap='PuBu', low=0, high=0, axis=0, subset=None, text_color_threshold=0.408, vmin=None, vmax=None, gmap=None)\",\n",
       "       'function_text': 'Color the background in a gradient style. The background color is determined according\\nto the data in each column, row or frame, or by a given\\ngradient map. Requires matplotlib.',\n",
       "       'parameter_names_desc': [{'param_name': 'cmap',\n",
       "         'param_type': 'str or colormap',\n",
       "         'param_desc': 'Matplotlib colormap.\\n'},\n",
       "        {'param_name': 'low',\n",
       "         'param_type': 'float',\n",
       "         'param_desc': 'Compress the color range at the low end. This is a multiple of the data\\nrange to extend below the minimum; good values usually in [0, 1],\\ndefaults to 0.\\n'},\n",
       "        {'param_name': 'high',\n",
       "         'param_type': 'float',\n",
       "         'param_desc': 'Compress the color range at the high end. This is a multiple of the data\\nrange to extend above the maximum; good values usually in [0, 1],\\ndefaults to 0.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0, 1, “index”, “columns”, None}, default 0',\n",
       "         'param_desc': \"Apply to each column (axis=0 or 'index'), to each row\\n(axis=1 or 'columns'), or to the entire DataFrame at once\\nwith axis=None.\\n\"},\n",
       "        {'param_name': 'subset',\n",
       "         'param_type': 'label, array-like, IndexSlice, optional',\n",
       "         'param_desc': 'A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\\nor single key, to DataFrame.loc[:, <subset>] where the columns are\\nprioritised, to limit data to before applying the function.\\n'},\n",
       "        {'param_name': 'text_color_threshold',\n",
       "         'param_type': 'float or int',\n",
       "         'param_desc': 'Luminance threshold for determining text color in [0, 1]. Facilitates text\\nvisibility across varying background colors. All text is dark if 0, and\\nlight if 1, defaults to 0.408.\\n'},\n",
       "        {'param_name': 'vmin',\n",
       "         'param_type': 'float, optional',\n",
       "         'param_desc': 'Minimum data value that corresponds to colormap minimum value.\\nIf not specified the minimum value of the data (or gmap) will be used.\\n'},\n",
       "        {'param_name': 'vmax',\n",
       "         'param_type': 'float, optional',\n",
       "         'param_desc': 'Maximum data value that corresponds to colormap maximum value.\\nIf not specified the maximum value of the data (or gmap) will be used.\\n'},\n",
       "        {'param_name': 'gmap',\n",
       "         'param_type': 'array-like, optional',\n",
       "         'param_desc': 'Gradient map for determining the background colors. If not supplied\\nwill use the underlying data from rows, columns or frame. If given as an\\nndarray or list-like must be an identical shape to the underlying data\\nconsidering axis and subset. If given as DataFrame or Series must\\nhave same index and column labels considering axis and subset.\\nIf supplied, vmin and vmax should be given relative to this\\ngradient map.\\n\\nNew in version 1.3.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.background_gradient',\n",
       "       'descriptions': 'Color the background in a gradient style. The background color is determined according\\nto the data in each column, row or frame, or by a given\\ngradient map. Requires matplotlib.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'cmap': {'type': 'string',\n",
       "          'description': 'str or colormap. Matplotlib colormap.\\n'},\n",
       "         'low': {'type': 'float',\n",
       "          'description': 'float. Compress the color range at the low end. This is a multiple of the data\\nrange to extend below the minimum; good values usually in [0, 1],\\ndefaults to 0.\\n'},\n",
       "         'high': {'type': 'float',\n",
       "          'description': 'float. Compress the color range at the high end. This is a multiple of the data\\nrange to extend above the maximum; good values usually in [0, 1],\\ndefaults to 0.\\n'},\n",
       "         'axis': {'type': '{0, 1, “index”, “columns”, None}, default 0',\n",
       "          'description': \"{0, 1, “index”, “columns”, None}, default 0. Apply to each column (axis=0 or 'index'), to each row\\n(axis=1 or 'columns'), or to the entire DataFrame at once\\nwith axis=None.\\n\"},\n",
       "         'subset': {'type': 'array',\n",
       "          'description': 'label, array-like, IndexSlice, optional. A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\\nor single key, to DataFrame.loc[:, <subset>] where the columns are\\nprioritised, to limit data to before applying the function.\\n'},\n",
       "         'text_color_threshold': {'type': 'integer',\n",
       "          'description': 'float or int. Luminance threshold for determining text color in [0, 1]. Facilitates text\\nvisibility across varying background colors. All text is dark if 0, and\\nlight if 1, defaults to 0.408.\\n'},\n",
       "         'vmin': {'type': 'float',\n",
       "          'description': 'float, optional. Minimum data value that corresponds to colormap minimum value.\\nIf not specified the minimum value of the data (or gmap) will be used.\\n'},\n",
       "         'vmax': {'type': 'float',\n",
       "          'description': 'float, optional. Maximum data value that corresponds to colormap maximum value.\\nIf not specified the maximum value of the data (or gmap) will be used.\\n'},\n",
       "         'gmap': {'type': 'array',\n",
       "          'description': 'array-like, optional. Gradient map for determining the background colors. If not supplied\\nwill use the underlying data from rows, columns or frame. If given as an\\nndarray or list-like must be an identical shape to the underlying data\\nconsidering axis and subset. If given as DataFrame or Series must\\nhave same index and column labels considering axis and subset.\\nIf supplied, vmin and vmax should be given relative to this\\ngradient map.\\n\\nNew in version 1.3.0.\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Styler.bar([subset,\\xa0axis,\\xa0color,\\xa0cmap,\\xa0...])',\n",
       "      'func_desc': 'Draw bar chart in the cell backgrounds.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.bar.html#pandas.io.formats.style.Styler.bar',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.bar',\n",
       "       'full_function': \"Styler.bar(subset=None, axis=0, *, color=None, cmap=None, width=100, height=100, align='mid', vmin=None, vmax=None, props='width: 10em;')\",\n",
       "       'function_text': 'Draw bar chart in the cell backgrounds. Changed in version 1.4.0.',\n",
       "       'parameter_names_desc': [{'param_name': 'subset',\n",
       "         'param_type': 'label, array-like, IndexSlice, optional',\n",
       "         'param_desc': 'A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\\nor single key, to DataFrame.loc[:, <subset>] where the columns are\\nprioritised, to limit data to before applying the function.\\n'},\n",
       "        {'param_name': 'axis',\n",
       "         'param_type': '{0 or ‘index’, 1 or ‘columns’, None}, default 0',\n",
       "         'param_desc': \"Apply to each column (axis=0 or 'index'), to each row\\n(axis=1 or 'columns'), or to the entire DataFrame at once\\nwith axis=None.\\n\"},\n",
       "        {'param_name': 'color',\n",
       "         'param_type': 'str or 2-tuple/list',\n",
       "         'param_desc': 'If a str is passed, the color is the same for both\\nnegative and positive numbers. If 2-tuple/list is used, the\\nfirst element is the color_negative and the second is the\\ncolor_positive (eg: [‘#d65f5f’, ‘#5fba7d’]).\\n'},\n",
       "        {'param_name': 'cmap',\n",
       "         'param_type': 'str, matplotlib.cm.ColorMap',\n",
       "         'param_desc': 'A string name of a matplotlib Colormap, or a Colormap object. Cannot be\\nused together with color.\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "        {'param_name': 'width',\n",
       "         'param_type': 'float, default 100',\n",
       "         'param_desc': 'The percentage of the cell, measured from the left, in which to draw the\\nbars, in [0, 100].\\n'},\n",
       "        {'param_name': 'height',\n",
       "         'param_type': 'float, default 100',\n",
       "         'param_desc': 'The percentage height of the bar in the cell, centrally aligned, in [0,100].\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "        {'param_name': 'align',\n",
       "         'param_type': 'str, int, float, callable, default ‘mid’',\n",
       "         'param_desc': 'How to align the bars within the cells relative to a width adjusted center.\\nIf string must be one of:\\n\\n‘left’ : bars are drawn rightwards from the minimum data value.\\n‘right’ : bars are drawn leftwards from the maximum data value.\\n‘zero’ : a value of zero is located at the center of the cell.\\n‘mid’ : a value of (max-min)/2 is located at the center of the cell,\\nor if all values are negative (positive) the zero is\\naligned at the right (left) of the cell.\\n‘mean’ : the mean value of the data is located at the center of the cell.\\n\\nIf a float or integer is given this will indicate the center of the cell.\\nIf a callable should take a 1d or 2d array and return a scalar.\\n\\nChanged in version 1.4.0.\\n\\n'},\n",
       "        {'param_name': 'vmin',\n",
       "         'param_type': 'float, optional',\n",
       "         'param_desc': 'Minimum bar value, defining the left hand limit\\nof the bar drawing range, lower values are clipped to vmin.\\nWhen None (default): the minimum value of the data will be used.\\n'},\n",
       "        {'param_name': 'vmax',\n",
       "         'param_type': 'float, optional',\n",
       "         'param_desc': 'Maximum bar value, defining the right hand limit\\nof the bar drawing range, higher values are clipped to vmax.\\nWhen None (default): the maximum value of the data will be used.\\n'},\n",
       "        {'param_name': 'props',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'The base CSS of the cell that is extended to add the bar chart. Defaults to\\n“width: 10em;”.\\n\\nNew in version 1.4.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.bar',\n",
       "       'descriptions': 'Draw bar chart in the cell backgrounds. Changed in version 1.4.0.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'subset': {'type': 'array',\n",
       "          'description': 'label, array-like, IndexSlice, optional. A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\\nor single key, to DataFrame.loc[:, <subset>] where the columns are\\nprioritised, to limit data to before applying the function.\\n'},\n",
       "         'axis': {'type': 'string',\n",
       "          'enum': ['0 or index', ' 1 or columns', ' None'],\n",
       "          'description': \"{0 or ‘index’, 1 or ‘columns’, None}, default 0. Apply to each column (axis=0 or 'index'), to each row\\n(axis=1 or 'columns'), or to the entire DataFrame at once\\nwith axis=None.\\n\"},\n",
       "         'color': {'type': 'string',\n",
       "          'description': 'str or 2-tuple/list. If a str is passed, the color is the same for both\\nnegative and positive numbers. If 2-tuple/list is used, the\\nfirst element is the color_negative and the second is the\\ncolor_positive (eg: [‘#d65f5f’, ‘#5fba7d’]).\\n'},\n",
       "         'cmap': {'type': 'string',\n",
       "          'description': 'str, matplotlib.cm.ColorMap. A string name of a matplotlib Colormap, or a Colormap object. Cannot be\\nused together with color.\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "         'width': {'type': 'float',\n",
       "          'description': 'float, default 100. The percentage of the cell, measured from the left, in which to draw the\\nbars, in [0, 100].\\n'},\n",
       "         'height': {'type': 'float',\n",
       "          'description': 'float, default 100. The percentage height of the bar in the cell, centrally aligned, in [0,100].\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "         'align': {'type': 'integer',\n",
       "          'description': 'str, int, float, callable, default ‘mid’. How to align the bars within the cells relative to a width adjusted center.\\nIf string must be one of:\\n\\n‘left’ : bars are drawn rightwards from the minimum data value.\\n‘right’ : bars are drawn leftwards from the maximum data value.\\n‘zero’ : a value of zero is located at the center of the cell.\\n‘mid’ : a value of (max-min)/2 is located at the center of the cell,\\nor if all values are negative (positive) the zero is\\naligned at the right (left) of the cell.\\n‘mean’ : the mean value of the data is located at the center of the cell.\\n\\nIf a float or integer is given this will indicate the center of the cell.\\nIf a callable should take a 1d or 2d array and return a scalar.\\n\\nChanged in version 1.4.0.\\n\\n'},\n",
       "         'vmin': {'type': 'float',\n",
       "          'description': 'float, optional. Minimum bar value, defining the left hand limit\\nof the bar drawing range, lower values are clipped to vmin.\\nWhen None (default): the minimum value of the data will be used.\\n'},\n",
       "         'vmax': {'type': 'float',\n",
       "          'description': 'float, optional. Maximum bar value, defining the right hand limit\\nof the bar drawing range, higher values are clipped to vmax.\\nWhen None (default): the maximum value of the data will be used.\\n'},\n",
       "         'props': {'type': 'string',\n",
       "          'description': 'str, optional. The base CSS of the cell that is extended to add the bar chart. Defaults to\\n“width: 10em;”.\\n\\nNew in version 1.4.0.\\n\\n'}},\n",
       "        'required': ['subset=None', 'axis=0']}}}]},\n",
       "   {'Style export and import': [{'func_name': 'Styler.to_html([buf,\\xa0table_uuid,\\xa0...])',\n",
       "      'func_desc': 'Write Styler to a file, buffer or string in HTML-CSS format.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_html.html#pandas.io.formats.style.Styler.to_html',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.to_html',\n",
       "       'full_function': 'Styler.to_html(buf=None, *, table_uuid=None, table_attributes=None, sparse_index=None, sparse_columns=None, bold_headers=False, caption=None, max_rows=None, max_columns=None, encoding=None, doctype_html=False, exclude_styles=False, **kwargs)',\n",
       "       'function_text': 'Write Styler to a file, buffer or string in HTML-CSS format. New in version 1.3.0.',\n",
       "       'parameter_names_desc': [{'param_name': 'buf',\n",
       "         'param_type': 'str, path object, file-like object, optional',\n",
       "         'param_desc': 'String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a string write() function. If None, the result is\\nreturned as a string.\\n'},\n",
       "        {'param_name': 'table_uuid',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Id attribute assigned to the <table> HTML element in the format:\\n<table id=\"T_<table_uuid>\" ..>\\nIf not given uses Styler’s initially assigned value.\\n'},\n",
       "        {'param_name': 'table_attributes',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Attributes to assign within the <table> HTML element in the format:\\n<table .. <table_attributes> >\\nIf not given defaults to Styler’s preexisting value.\\n'},\n",
       "        {'param_name': 'sparse_index',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'Whether to sparsify the display of a hierarchical index. Setting to False\\nwill display each explicit level element in a hierarchical key for each row.\\nDefaults to pandas.options.styler.sparse.index value.\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "        {'param_name': 'sparse_columns',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'Whether to sparsify the display of a hierarchical index. Setting to False\\nwill display each explicit level element in a hierarchical key for each\\ncolumn. Defaults to pandas.options.styler.sparse.columns value.\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "        {'param_name': 'bold_headers',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'Adds “font-weight: bold;” as a CSS property to table style header cells.\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "        {'param_name': 'caption',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Set, or overwrite, the caption on Styler before rendering.\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "        {'param_name': 'max_rows',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'The maximum number of rows that will be rendered. Defaults to\\npandas.options.styler.render.max_rows/max_columns.\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "        {'param_name': 'max_columns',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'The maximum number of columns that will be rendered. Defaults to\\npandas.options.styler.render.max_columns, which is None.\\nRows and columns may be reduced if the number of total elements is\\nlarge. This value is set to pandas.options.styler.render.max_elements,\\nwhich is 262144 (18 bit browser rendering).\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "        {'param_name': 'encoding',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Character encoding setting for file output (and meta tags if available).\\nDefaults to pandas.options.styler.render.encoding value of “utf-8”.\\n'},\n",
       "        {'param_name': 'doctype_html',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to output a fully structured HTML file including all\\nHTML elements, or just the core <style> and <table> elements.\\n'},\n",
       "        {'param_name': 'exclude_styles',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to include the <style> element and all associated element\\nclass and id identifiers, or solely the <table> element without\\nstyling identifiers.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.to_html',\n",
       "       'descriptions': 'Write Styler to a file, buffer or string in HTML-CSS format. New in version 1.3.0.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'buf': {'type': 'string',\n",
       "          'description': 'str, path object, file-like object, optional. String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a string write() function. If None, the result is\\nreturned as a string.\\n'},\n",
       "         'table_uuid': {'type': 'string',\n",
       "          'description': 'str, optional. Id attribute assigned to the <table> HTML element in the format:\\n<table id=\"T_<table_uuid>\" ..>\\nIf not given uses Styler’s initially assigned value.\\n'},\n",
       "         'table_attributes': {'type': 'string',\n",
       "          'description': 'str, optional. Attributes to assign within the <table> HTML element in the format:\\n<table .. <table_attributes> >\\nIf not given defaults to Styler’s preexisting value.\\n'},\n",
       "         'sparse_index': {'type': 'boolean',\n",
       "          'description': 'bool, optional. Whether to sparsify the display of a hierarchical index. Setting to False\\nwill display each explicit level element in a hierarchical key for each row.\\nDefaults to pandas.options.styler.sparse.index value.\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "         'sparse_columns': {'type': 'boolean',\n",
       "          'description': 'bool, optional. Whether to sparsify the display of a hierarchical index. Setting to False\\nwill display each explicit level element in a hierarchical key for each\\ncolumn. Defaults to pandas.options.styler.sparse.columns value.\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "         'bold_headers': {'type': 'boolean',\n",
       "          'description': 'bool, optional. Adds “font-weight: bold;” as a CSS property to table style header cells.\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "         'caption': {'type': 'string',\n",
       "          'description': 'str, optional. Set, or overwrite, the caption on Styler before rendering.\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "         'max_rows': {'type': 'integer',\n",
       "          'description': 'int, optional. The maximum number of rows that will be rendered. Defaults to\\npandas.options.styler.render.max_rows/max_columns.\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "         'max_columns': {'type': 'integer',\n",
       "          'description': 'int, optional. The maximum number of columns that will be rendered. Defaults to\\npandas.options.styler.render.max_columns, which is None.\\nRows and columns may be reduced if the number of total elements is\\nlarge. This value is set to pandas.options.styler.render.max_elements,\\nwhich is 262144 (18 bit browser rendering).\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "         'encoding': {'type': 'string',\n",
       "          'description': 'str, optional. Character encoding setting for file output (and meta tags if available).\\nDefaults to pandas.options.styler.render.encoding value of “utf-8”.\\n'},\n",
       "         'doctype_html': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to output a fully structured HTML file including all\\nHTML elements, or just the core <style> and <table> elements.\\n'},\n",
       "         'exclude_styles': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to include the <style> element and all associated element\\nclass and id identifiers, or solely the <table> element without\\nstyling identifiers.\\n'}},\n",
       "        'required': ['buf=None']}}},\n",
       "     {'func_name': 'Styler.to_excel(excel_writer[,\\xa0sheet_name,\\xa0...])',\n",
       "      'func_desc': 'Write Styler to an Excel sheet.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_excel.html#pandas.io.formats.style.Styler.to_excel',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.to_excel',\n",
       "       'full_function': \"Styler.to_excel(excel_writer, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, encoding=None, inf_rep='inf', verbose=True, freeze_panes=None, storage_options=None)\",\n",
       "       'function_text': 'Write Styler to an Excel sheet. To write a single Styler to an Excel .xlsx file it is only necessary to\\nspecify a target file name. To write to multiple sheets it is necessary to\\ncreate an ExcelWriter object with a target file name, and specify a sheet\\nin the file to write to. Multiple sheets may be written to by specifying unique sheet_name.\\nWith all data written to the file it is necessary to save the changes.\\nNote that creating an ExcelWriter object with a file name that already\\nexists will result in the contents of the existing file being erased.',\n",
       "       'parameter_names_desc': [{'param_name': 'excel_writer',\n",
       "         'param_type': 'path-like, file-like, or ExcelWriter object',\n",
       "         'param_desc': 'File path or existing ExcelWriter.\\n'},\n",
       "        {'param_name': 'sheet_name',\n",
       "         'param_type': 'str, default ‘Sheet1’',\n",
       "         'param_desc': 'Name of sheet which will contain DataFrame.\\n'},\n",
       "        {'param_name': 'na_rep',\n",
       "         'param_type': 'str, default ‘’',\n",
       "         'param_desc': 'Missing data representation.\\n'},\n",
       "        {'param_name': 'float_format',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Format string for floating point numbers. For example\\nfloat_format=\"%.2f\" will format 0.1234 to 0.12.\\n'},\n",
       "        {'param_name': 'columns',\n",
       "         'param_type': 'sequence or list of str, optional',\n",
       "         'param_desc': 'Columns to write.\\n'},\n",
       "        {'param_name': 'header',\n",
       "         'param_type': 'bool or list of str, default True',\n",
       "         'param_desc': 'Write out the column names. If a list of string is given it is\\nassumed to be aliases for the column names.\\n'},\n",
       "        {'param_name': 'index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Write row names (index).\\n'},\n",
       "        {'param_name': 'index_label',\n",
       "         'param_type': 'str or sequence, optional',\n",
       "         'param_desc': 'Column label for index column(s) if desired. If not specified, and\\nheader and index are True, then the index names are used. A\\nsequence should be given if the DataFrame uses MultiIndex.\\n'},\n",
       "        {'param_name': 'startrow',\n",
       "         'param_type': 'int, default 0',\n",
       "         'param_desc': 'Upper left cell row to dump data frame.\\n'},\n",
       "        {'param_name': 'startcol',\n",
       "         'param_type': 'int, default 0',\n",
       "         'param_desc': 'Upper left cell column to dump data frame.\\n'},\n",
       "        {'param_name': 'engine',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Write engine to use, ‘openpyxl’ or ‘xlsxwriter’. You can also set this\\nvia the options io.excel.xlsx.writer or\\nio.excel.xlsm.writer.\\n'},\n",
       "        {'param_name': 'merge_cells',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Write MultiIndex and Hierarchical Rows as merged cells.\\n'},\n",
       "        {'param_name': 'inf_rep',\n",
       "         'param_type': 'str, default ‘inf’',\n",
       "         'param_desc': 'Representation for infinity (there is no native representation for\\ninfinity in Excel).\\n'},\n",
       "        {'param_name': 'freeze_panes',\n",
       "         'param_type': 'tuple of int (length 2), optional',\n",
       "         'param_desc': 'Specifies the one-based bottommost row and rightmost column that\\nis to be frozen.\\n'},\n",
       "        {'param_name': 'storage_options',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "        {'param_name': 'engine_kwargs',\n",
       "         'param_type': 'dict, optional',\n",
       "         'param_desc': 'Arbitrary keyword arguments passed to excel engine.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.to_excel',\n",
       "       'descriptions': 'Write Styler to an Excel sheet. To write a single Styler to an Excel .xlsx file it is only necessary to\\nspecify a target file name. To write to multiple sheets it is necessary to\\ncreate an ExcelWriter object with a target file name, and specify a sheet\\nin the file to write to. Multiple sheets may be written to by specifying unique sheet_name.\\nWith all data written to the file it is necessary to save the changes.\\nNote that creating an ExcelWriter object with a file name that already\\nexists will result in the contents of the existing file being erased.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'excel_writer': {'type': 'object',\n",
       "          'description': 'path-like, file-like, or ExcelWriter object. File path or existing ExcelWriter.\\n'},\n",
       "         'sheet_name': {'type': 'string',\n",
       "          'description': 'str, default ‘Sheet1’. Name of sheet which will contain DataFrame.\\n'},\n",
       "         'na_rep': {'type': 'string',\n",
       "          'description': 'str, default ‘’. Missing data representation.\\n'},\n",
       "         'float_format': {'type': 'string',\n",
       "          'description': 'str, optional. Format string for floating point numbers. For example\\nfloat_format=\"%.2f\" will format 0.1234 to 0.12.\\n'},\n",
       "         'columns': {'type': 'string',\n",
       "          'description': 'sequence or list of str, optional. Columns to write.\\n'},\n",
       "         'header': {'type': 'string',\n",
       "          'description': 'bool or list of str, default True. Write out the column names. If a list of string is given it is\\nassumed to be aliases for the column names.\\n'},\n",
       "         'index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Write row names (index).\\n'},\n",
       "         'index_label': {'type': 'string',\n",
       "          'description': 'str or sequence, optional. Column label for index column(s) if desired. If not specified, and\\nheader and index are True, then the index names are used. A\\nsequence should be given if the DataFrame uses MultiIndex.\\n'},\n",
       "         'startrow': {'type': 'integer',\n",
       "          'description': 'int, default 0. Upper left cell row to dump data frame.\\n'},\n",
       "         'startcol': {'type': 'integer',\n",
       "          'description': 'int, default 0. Upper left cell column to dump data frame.\\n'},\n",
       "         'engine': {'type': 'string',\n",
       "          'description': 'str, optional. Write engine to use, ‘openpyxl’ or ‘xlsxwriter’. You can also set this\\nvia the options io.excel.xlsx.writer or\\nio.excel.xlsm.writer.\\n'},\n",
       "         'merge_cells': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Write MultiIndex and Hierarchical Rows as merged cells.\\n'},\n",
       "         'inf_rep': {'type': 'string',\n",
       "          'description': 'str, default ‘inf’. Representation for infinity (there is no native representation for\\ninfinity in Excel).\\n'},\n",
       "         'freeze_panes': {'type': 'integer',\n",
       "          'description': 'tuple of int (length 2), optional. Specifies the one-based bottommost row and rightmost column that\\nis to be frozen.\\n'},\n",
       "         'storage_options': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Extra options that make sense for a particular storage connection, e.g.\\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\\nare forwarded to urllib.request.Request as header options. For other\\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\\nforwarded to fsspec.open. Please see fsspec and urllib for more\\ndetails, and for more examples on storage options refer here.\\n\\nNew in version 1.5.0.\\n\\n'},\n",
       "         'engine_kwargs': {'type': 'dict, optional',\n",
       "          'description': 'dict, optional. Arbitrary keyword arguments passed to excel engine.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'Styler.export()',\n",
       "      'func_desc': 'Export the styles applied to the current Styler.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.export.html#pandas.io.formats.style.Styler.export',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.export',\n",
       "       'full_function': 'Styler.export()',\n",
       "       'function_text': 'Export the styles applied to the current Styler. Can be applied to a second Styler with Styler.use.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'Styler.to_latex([buf,\\xa0column_format,\\xa0...])',\n",
       "      'func_desc': 'Write Styler to a file, buffer or string in LaTeX format.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_latex.html#pandas.io.formats.style.Styler.to_latex',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.to_latex',\n",
       "       'full_function': 'Styler.to_latex(buf=None, *, column_format=None, position=None, position_float=None, hrules=None, clines=None, label=None, caption=None, sparse_index=None, sparse_columns=None, multirow_align=None, multicol_align=None, siunitx=False, environment=None, encoding=None, convert_css=False)',\n",
       "       'function_text': 'Write Styler to a file, buffer or string in LaTeX format. New in version 1.3.0.',\n",
       "       'parameter_names_desc': [{'param_name': 'buf',\n",
       "         'param_type': 'str, path object, file-like object, or None, default None',\n",
       "         'param_desc': 'String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a string write() function. If None, the result is\\nreturned as a string.\\n'},\n",
       "        {'param_name': 'column_format',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'The LaTeX column specification placed in location:\\n\\\\begin{tabular}{<column_format>}\\nDefaults to ‘l’ for index and\\nnon-numeric data columns, and, for numeric data columns,\\nto ‘r’ by default, or ‘S’ if siunitx is True.\\n'},\n",
       "        {'param_name': 'position',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'The LaTeX positional argument (e.g. ‘h!’) for tables, placed in location:\\n\\\\\\\\begin{table}[<position>].\\n'},\n",
       "        {'param_name': 'position_float',\n",
       "         'param_type': '{“centering”, “raggedleft”, “raggedright”}, optional',\n",
       "         'param_desc': 'The LaTeX float command placed in location:\\n\\\\begin{table}[<position>]\\n\\\\<position_float>\\nCannot be used if environment is “longtable”.\\n'},\n",
       "        {'param_name': 'hrules',\n",
       "         'param_type': 'bool',\n",
       "         'param_desc': 'Set to True to add \\\\toprule, \\\\midrule and \\\\bottomrule from the\\n{booktabs} LaTeX package.\\nDefaults to pandas.options.styler.latex.hrules, which is False.\\n\\nChanged in version 1.4.0.\\n\\n'},\n",
       "        {'param_name': 'clines',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Use to control adding \\\\cline commands for the index labels separation.\\nPossible values are:\\n\\n\\nNone: no cline commands are added (default).\\n“all;data”: a cline is added for every index value extending the\\nwidth of the table, including data entries.\\n“all;index”: as above with lines extending only the width of the\\nindex entries.\\n“skip-last;data”: a cline is added for each index value except the\\nlast level (which is never sparsified), extending the widtn of the\\ntable.\\n“skip-last;index”: as above with lines extending only the width of the\\nindex entries.\\n\\n\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "        {'param_name': 'label',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'The LaTeX label included as: \\\\label{<label>}.\\nThis is used with \\\\ref{<label>} in the main .tex file.\\n'},\n",
       "        {'param_name': 'caption',\n",
       "         'param_type': 'str, tuple, optional',\n",
       "         'param_desc': 'If string, the LaTeX table caption included as: \\\\caption{<caption>}.\\nIf tuple, i.e (“full caption”, “short caption”), the caption included\\nas: \\\\caption[<caption[1]>]{<caption[0]>}.\\n'},\n",
       "        {'param_name': 'sparse_index',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'Whether to sparsify the display of a hierarchical index. Setting to False\\nwill display each explicit level element in a hierarchical key for each row.\\nDefaults to pandas.options.styler.sparse.index, which is True.\\n'},\n",
       "        {'param_name': 'sparse_columns',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'Whether to sparsify the display of a hierarchical index. Setting to False\\nwill display each explicit level element in a hierarchical key for each\\ncolumn. Defaults to pandas.options.styler.sparse.columns, which\\nis True.\\n'},\n",
       "        {'param_name': 'multirow_align',\n",
       "         'param_type': '{“c”, “t”, “b”, “naive”}, optional',\n",
       "         'param_desc': 'If sparsifying hierarchical MultiIndexes whether to align text centrally,\\nat the top or bottom using the multirow package. If not given defaults to\\npandas.options.styler.latex.multirow_align, which is “c”.\\nIf “naive” is given renders without multirow.\\n\\nChanged in version 1.4.0.\\n\\n'},\n",
       "        {'param_name': 'multicol_align',\n",
       "         'param_type': '{“r”, “c”, “l”, “naive-l”, “naive-r”}, optional',\n",
       "         'param_desc': 'If sparsifying hierarchical MultiIndex columns whether to align text at\\nthe left, centrally, or at the right. If not given defaults to\\npandas.options.styler.latex.multicol_align, which is “r”.\\nIf a naive option is given renders without multicol.\\nPipe decorators can also be added to non-naive values to draw vertical\\nrules, e.g. “|r” will draw a rule on the left side of right aligned merged\\ncells.\\n\\nChanged in version 1.4.0.\\n\\n'},\n",
       "        {'param_name': 'siunitx',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Set to True to structure LaTeX compatible with the {siunitx} package.\\n'},\n",
       "        {'param_name': 'environment',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'If given, the environment that will replace ‘table’ in \\\\\\\\begin{table}.\\nIf ‘longtable’ is specified then a more suitable template is\\nrendered. If not given defaults to\\npandas.options.styler.latex.environment, which is None.\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "        {'param_name': 'encoding',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Character encoding setting. Defaults\\nto pandas.options.styler.render.encoding, which is “utf-8”.\\n'},\n",
       "        {'param_name': 'convert_css',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Convert simple cell-styles from CSS to LaTeX format. Any CSS not found in\\nconversion table is dropped. A style can be forced by adding option\\n–latex. See notes.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.to_latex',\n",
       "       'descriptions': 'Write Styler to a file, buffer or string in LaTeX format. New in version 1.3.0.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'buf': {'type': 'string',\n",
       "          'description': 'str, path object, file-like object, or None, default None. String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a string write() function. If None, the result is\\nreturned as a string.\\n'},\n",
       "         'column_format': {'type': 'string',\n",
       "          'description': 'str, optional. The LaTeX column specification placed in location:\\n\\\\begin{tabular}{<column_format>}\\nDefaults to ‘l’ for index and\\nnon-numeric data columns, and, for numeric data columns,\\nto ‘r’ by default, or ‘S’ if siunitx is True.\\n'},\n",
       "         'position': {'type': 'string',\n",
       "          'description': 'str, optional. The LaTeX positional argument (e.g. ‘h!’) for tables, placed in location:\\n\\\\\\\\begin{table}[<position>].\\n'},\n",
       "         'position_float': {'type': '{“centering”, “raggedleft”, “raggedright”}, optional',\n",
       "          'description': '{“centering”, “raggedleft”, “raggedright”}, optional. The LaTeX float command placed in location:\\n\\\\begin{table}[<position>]\\n\\\\<position_float>\\nCannot be used if environment is “longtable”.\\n'},\n",
       "         'hrules': {'type': 'boolean',\n",
       "          'description': 'bool. Set to True to add \\\\toprule, \\\\midrule and \\\\bottomrule from the\\n{booktabs} LaTeX package.\\nDefaults to pandas.options.styler.latex.hrules, which is False.\\n\\nChanged in version 1.4.0.\\n\\n'},\n",
       "         'clines': {'type': 'string',\n",
       "          'description': 'str, optional. Use to control adding \\\\cline commands for the index labels separation.\\nPossible values are:\\n\\n\\nNone: no cline commands are added (default).\\n“all;data”: a cline is added for every index value extending the\\nwidth of the table, including data entries.\\n“all;index”: as above with lines extending only the width of the\\nindex entries.\\n“skip-last;data”: a cline is added for each index value except the\\nlast level (which is never sparsified), extending the widtn of the\\ntable.\\n“skip-last;index”: as above with lines extending only the width of the\\nindex entries.\\n\\n\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "         'label': {'type': 'string',\n",
       "          'description': 'str, optional. The LaTeX label included as: \\\\label{<label>}.\\nThis is used with \\\\ref{<label>} in the main .tex file.\\n'},\n",
       "         'caption': {'type': 'string',\n",
       "          'description': 'str, tuple, optional. If string, the LaTeX table caption included as: \\\\caption{<caption>}.\\nIf tuple, i.e (“full caption”, “short caption”), the caption included\\nas: \\\\caption[<caption[1]>]{<caption[0]>}.\\n'},\n",
       "         'sparse_index': {'type': 'boolean',\n",
       "          'description': 'bool, optional. Whether to sparsify the display of a hierarchical index. Setting to False\\nwill display each explicit level element in a hierarchical key for each row.\\nDefaults to pandas.options.styler.sparse.index, which is True.\\n'},\n",
       "         'sparse_columns': {'type': 'boolean',\n",
       "          'description': 'bool, optional. Whether to sparsify the display of a hierarchical index. Setting to False\\nwill display each explicit level element in a hierarchical key for each\\ncolumn. Defaults to pandas.options.styler.sparse.columns, which\\nis True.\\n'},\n",
       "         'multirow_align': {'type': '{“c”, “t”, “b”, “naive”}, optional',\n",
       "          'description': '{“c”, “t”, “b”, “naive”}, optional. If sparsifying hierarchical MultiIndexes whether to align text centrally,\\nat the top or bottom using the multirow package. If not given defaults to\\npandas.options.styler.latex.multirow_align, which is “c”.\\nIf “naive” is given renders without multirow.\\n\\nChanged in version 1.4.0.\\n\\n'},\n",
       "         'multicol_align': {'type': '{“r”, “c”, “l”, “naive-l”, “naive-r”}, optional',\n",
       "          'description': '{“r”, “c”, “l”, “naive-l”, “naive-r”}, optional. If sparsifying hierarchical MultiIndex columns whether to align text at\\nthe left, centrally, or at the right. If not given defaults to\\npandas.options.styler.latex.multicol_align, which is “r”.\\nIf a naive option is given renders without multicol.\\nPipe decorators can also be added to non-naive values to draw vertical\\nrules, e.g. “|r” will draw a rule on the left side of right aligned merged\\ncells.\\n\\nChanged in version 1.4.0.\\n\\n'},\n",
       "         'siunitx': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Set to True to structure LaTeX compatible with the {siunitx} package.\\n'},\n",
       "         'environment': {'type': 'string',\n",
       "          'description': 'str, optional. If given, the environment that will replace ‘table’ in \\\\\\\\begin{table}.\\nIf ‘longtable’ is specified then a more suitable template is\\nrendered. If not given defaults to\\npandas.options.styler.latex.environment, which is None.\\n\\nNew in version 1.4.0.\\n\\n'},\n",
       "         'encoding': {'type': 'string',\n",
       "          'description': 'str, optional. Character encoding setting. Defaults\\nto pandas.options.styler.render.encoding, which is “utf-8”.\\n'},\n",
       "         'convert_css': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Convert simple cell-styles from CSS to LaTeX format. Any CSS not found in\\nconversion table is dropped. A style can be forced by adding option\\n–latex. See notes.\\n'}},\n",
       "        'required': ['buf=None']}}},\n",
       "     {'func_name': 'Styler.to_string([buf,\\xa0encoding,\\xa0...])',\n",
       "      'func_desc': 'Write Styler to a file, buffer or string in text format.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_string.html#pandas.io.formats.style.Styler.to_string',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.to_string',\n",
       "       'full_function': \"Styler.to_string(buf=None, *, encoding=None, sparse_index=None, sparse_columns=None, max_rows=None, max_columns=None, delimiter=' ')\",\n",
       "       'function_text': 'Write Styler to a file, buffer or string in text format. New in version 1.5.0.',\n",
       "       'parameter_names_desc': [{'param_name': 'buf',\n",
       "         'param_type': 'str, path object, file-like object, optional',\n",
       "         'param_desc': 'String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a string write() function. If None, the result is\\nreturned as a string.\\n'},\n",
       "        {'param_name': 'encoding',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Character encoding setting for file output (and meta tags if available).\\nDefaults to pandas.options.styler.render.encoding value of “utf-8”.\\n'},\n",
       "        {'param_name': 'sparse_index',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'Whether to sparsify the display of a hierarchical index. Setting to False\\nwill display each explicit level element in a hierarchical key for each row.\\nDefaults to pandas.options.styler.sparse.index value.\\n'},\n",
       "        {'param_name': 'sparse_columns',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'Whether to sparsify the display of a hierarchical index. Setting to False\\nwill display each explicit level element in a hierarchical key for each\\ncolumn. Defaults to pandas.options.styler.sparse.columns value.\\n'},\n",
       "        {'param_name': 'max_rows',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'The maximum number of rows that will be rendered. Defaults to\\npandas.options.styler.render.max_rows, which is None.\\n'},\n",
       "        {'param_name': 'max_columns',\n",
       "         'param_type': 'int, optional',\n",
       "         'param_desc': 'The maximum number of columns that will be rendered. Defaults to\\npandas.options.styler.render.max_columns, which is None.\\nRows and columns may be reduced if the number of total elements is\\nlarge. This value is set to pandas.options.styler.render.max_elements,\\nwhich is 262144 (18 bit browser rendering).\\n'},\n",
       "        {'param_name': 'delimiter',\n",
       "         'param_type': 'str, default single space',\n",
       "         'param_desc': 'The separator between data elements.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.to_string',\n",
       "       'descriptions': 'Write Styler to a file, buffer or string in text format. New in version 1.5.0.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'buf': {'type': 'string',\n",
       "          'description': 'str, path object, file-like object, optional. String, path object (implementing os.PathLike[str]), or file-like\\nobject implementing a string write() function. If None, the result is\\nreturned as a string.\\n'},\n",
       "         'encoding': {'type': 'string',\n",
       "          'description': 'str, optional. Character encoding setting for file output (and meta tags if available).\\nDefaults to pandas.options.styler.render.encoding value of “utf-8”.\\n'},\n",
       "         'sparse_index': {'type': 'boolean',\n",
       "          'description': 'bool, optional. Whether to sparsify the display of a hierarchical index. Setting to False\\nwill display each explicit level element in a hierarchical key for each row.\\nDefaults to pandas.options.styler.sparse.index value.\\n'},\n",
       "         'sparse_columns': {'type': 'boolean',\n",
       "          'description': 'bool, optional. Whether to sparsify the display of a hierarchical index. Setting to False\\nwill display each explicit level element in a hierarchical key for each\\ncolumn. Defaults to pandas.options.styler.sparse.columns value.\\n'},\n",
       "         'max_rows': {'type': 'integer',\n",
       "          'description': 'int, optional. The maximum number of rows that will be rendered. Defaults to\\npandas.options.styler.render.max_rows, which is None.\\n'},\n",
       "         'max_columns': {'type': 'integer',\n",
       "          'description': 'int, optional. The maximum number of columns that will be rendered. Defaults to\\npandas.options.styler.render.max_columns, which is None.\\nRows and columns may be reduced if the number of total elements is\\nlarge. This value is set to pandas.options.styler.render.max_elements,\\nwhich is 262144 (18 bit browser rendering).\\n'},\n",
       "         'delimiter': {'type': 'string',\n",
       "          'description': 'str, default single space. The separator between data elements.\\n'}},\n",
       "        'required': ['buf=None']}}},\n",
       "     {'func_name': 'Styler.use(styles)',\n",
       "      'func_desc': 'Set the styles on the current Styler.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.use.html#pandas.io.formats.style.Styler.use',\n",
       "      'function_definitions': {'function_name': 'pandas.io.formats.style.Styler.use',\n",
       "       'full_function': 'Styler.use(styles)',\n",
       "       'function_text': 'Set the styles on the current Styler. Possibly uses styles from Styler.export.',\n",
       "       'parameter_names_desc': [{'param_name': 'styles',\n",
       "         'param_type': 'dict(str, Any)',\n",
       "         'param_desc': '\\nList of attributes to add to Styler. Dict keys should contain only:\\n“apply”: list of styler functions, typically added with apply or\\nmap.\\n“table_attributes”: HTML attributes, typically added with\\nset_table_attributes.\\n“table_styles”: CSS selectors and properties, typically added with\\nset_table_styles.\\n“hide_index”: whether the index is hidden, typically added with\\nhide_index, or a boolean list for hidden levels.\\n“hide_columns”: whether column headers are hidden, typically added with\\nhide_columns, or a boolean list for hidden levels.\\n“hide_index_names”: whether index names are hidden.\\n“hide_column_names”: whether column header names are hidden.\\n“css”: the css class names used.\\n\\n\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.io.formats.style.Styler.use',\n",
       "       'descriptions': 'Set the styles on the current Styler. Possibly uses styles from Styler.export.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'styles': {'type': 'string',\n",
       "          'description': 'dict(str, Any). \\nList of attributes to add to Styler. Dict keys should contain only:\\n“apply”: list of styler functions, typically added with apply or\\nmap.\\n“table_attributes”: HTML attributes, typically added with\\nset_table_attributes.\\n“table_styles”: CSS selectors and properties, typically added with\\nset_table_styles.\\n“hide_index”: whether the index is hidden, typically added with\\nhide_index, or a boolean list for hidden levels.\\n“hide_columns”: whether column headers are hidden, typically added with\\nhide_columns, or a boolean list for hidden levels.\\n“hide_index_names”: whether index names are hidden.\\n“hide_column_names”: whether column header names are hidden.\\n“css”: the css class names used.\\n\\n\\n\\n'}},\n",
       "        'required': []}}}]}],\n",
       "  'name': 'Style',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/style.html'},\n",
       " 'plotting.html': {'functions': [{'defaults': [{'func_name': 'andrews_curves(frame,\\xa0class_column[,\\xa0ax,\\xa0...])',\n",
       "      'func_desc': 'Generate a matplotlib plot for visualizing clusters of multivariate data.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.plotting.andrews_curves.html#pandas.plotting.andrews_curves',\n",
       "      'function_definitions': {'function_name': 'pandas.plotting.andrews_curves',\n",
       "       'full_function': 'pandas.plotting.andrews_curves(frame, class_column, ax=None, samples=200, color=None, colormap=None, **kwargs)',\n",
       "       'function_text': 'Generate a matplotlib plot for visualizing clusters of multivariate data. Andrews curves have the functional form: Where \\\\(x\\\\) coefficients correspond to the values of each dimension\\nand \\\\(t\\\\) is linearly spaced between \\\\(-\\\\pi\\\\) and \\\\(+\\\\pi\\\\).\\nEach row of frame then corresponds to a single curve.',\n",
       "       'parameter_names_desc': [{'param_name': 'frame',\n",
       "         'param_type': 'DataFrame',\n",
       "         'param_desc': 'Data to be plotted, preferably normalized to (0.0, 1.0).\\n'},\n",
       "        {'param_name': 'class_column',\n",
       "         'param_type': 'label',\n",
       "         'param_desc': 'Name of the column containing class names.\\n'},\n",
       "        {'param_name': 'ax',\n",
       "         'param_type': 'axes object, default None',\n",
       "         'param_desc': 'Axes to use.\\n'},\n",
       "        {'param_name': 'samples',\n",
       "         'param_type': 'int',\n",
       "         'param_desc': 'Number of points to plot in each curve.\\n'},\n",
       "        {'param_name': 'color',\n",
       "         'param_type': 'str, list[str] or tuple[str], optional',\n",
       "         'param_desc': 'Colors to use for the different classes. Colors can be strings\\nor 3-element floating point RGB values.\\n'},\n",
       "        {'param_name': 'colormap',\n",
       "         'param_type': 'str or matplotlib colormap object, default None',\n",
       "         'param_desc': 'Colormap to select colors from. If a string, load colormap with that\\nname from matplotlib.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.plotting.andrews_curves',\n",
       "       'descriptions': 'Generate a matplotlib plot for visualizing clusters of multivariate data. Andrews curves have the functional form: Where \\\\(x\\\\) coefficients correspond to the values of each dimension\\nand \\\\(t\\\\) is linearly spaced between \\\\(-\\\\pi\\\\) and \\\\(+\\\\pi\\\\).\\nEach row of frame then corresponds to a single curve.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'frame': {'type': 'DataFrame',\n",
       "          'description': 'DataFrame. Data to be plotted, preferably normalized to (0.0, 1.0).\\n'},\n",
       "         'class_column': {'type': 'label',\n",
       "          'description': 'label. Name of the column containing class names.\\n'},\n",
       "         'ax': {'type': 'object',\n",
       "          'description': 'axes object, default None. Axes to use.\\n'},\n",
       "         'samples': {'type': 'integer',\n",
       "          'description': 'int. Number of points to plot in each curve.\\n'},\n",
       "         'color': {'type': 'string',\n",
       "          'description': 'str, list[str] or tuple[str], optional. Colors to use for the different classes. Colors can be strings\\nor 3-element floating point RGB values.\\n'},\n",
       "         'colormap': {'type': 'string',\n",
       "          'description': 'str or matplotlib colormap object, default None. Colormap to select colors from. If a string, load colormap with that\\nname from matplotlib.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'bootstrap_plot(series[,\\xa0fig,\\xa0size,\\xa0samples])',\n",
       "      'func_desc': 'Bootstrap plot on mean, median and mid-range statistics.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.plotting.bootstrap_plot.html#pandas.plotting.bootstrap_plot',\n",
       "      'function_definitions': {'function_name': 'pandas.plotting.bootstrap_plot',\n",
       "       'full_function': 'pandas.plotting.bootstrap_plot(series, fig=None, size=50, samples=500, **kwds)',\n",
       "       'function_text': 'Bootstrap plot on mean, median and mid-range statistics. The bootstrap plot is used to estimate the uncertainty of a statistic\\nby relying on random sampling with replacement [1]. This function will\\ngenerate bootstrapping plots for mean, median and mid-range statistics\\nfor the given number of samples of the given size. “Bootstrapping (statistics)” in https://en.wikipedia.org/wiki/Bootstrapping_%28statistics%29',\n",
       "       'parameter_names_desc': [{'param_name': 'series',\n",
       "         'param_type': 'pandas.Series',\n",
       "         'param_desc': 'Series from where to get the samplings for the bootstrapping.\\n'},\n",
       "        {'param_name': 'fig',\n",
       "         'param_type': 'matplotlib.figure.Figure, default None',\n",
       "         'param_desc': 'If given, it will use the fig reference for plotting instead of\\ncreating a new one with default parameters.\\n'},\n",
       "        {'param_name': 'size',\n",
       "         'param_type': 'int, default 50',\n",
       "         'param_desc': 'Number of data points to consider during each sampling. It must be\\nless than or equal to the length of the series.\\n'},\n",
       "        {'param_name': 'samples',\n",
       "         'param_type': 'int, default 500',\n",
       "         'param_desc': 'Number of times the bootstrap procedure is performed.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.plotting.bootstrap_plot',\n",
       "       'descriptions': 'Bootstrap plot on mean, median and mid-range statistics. The bootstrap plot is used to estimate the uncertainty of a statistic\\nby relying on random sampling with replacement [1]. This function will\\ngenerate bootstrapping plots for mean, median and mid-range statistics\\nfor the given number of samples of the given size. “Bootstrapping (statistics)” in https://en.wikipedia.org/wiki/Bootstrapping_%28statistics%29',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'series': {'type': 'pandas.Series',\n",
       "          'description': 'pandas.Series. Series from where to get the samplings for the bootstrapping.\\n'},\n",
       "         'fig': {'type': 'matplotlib.figure.Figure, default None',\n",
       "          'description': 'matplotlib.figure.Figure, default None. If given, it will use the fig reference for plotting instead of\\ncreating a new one with default parameters.\\n'},\n",
       "         'size': {'type': 'integer',\n",
       "          'description': 'int, default 50. Number of data points to consider during each sampling. It must be\\nless than or equal to the length of the series.\\n'},\n",
       "         'samples': {'type': 'integer',\n",
       "          'description': 'int, default 500. Number of times the bootstrap procedure is performed.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'deregister_matplotlib_converters()',\n",
       "      'func_desc': 'Remove pandas formatters and converters.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.plotting.deregister_matplotlib_converters.html#pandas.plotting.deregister_matplotlib_converters',\n",
       "      'function_definitions': {'function_name': 'pandas.plotting.deregister_matplotlib_converters',\n",
       "       'full_function': 'pandas.plotting.deregister_matplotlib_converters()',\n",
       "       'function_text': 'Remove pandas formatters and converters. Removes the custom converters added by register(). This\\nattempts to set the state of the registry back to the state before\\npandas registered its own units. Converters for pandas’ own types like\\nTimestamp and Period are removed completely. Converters for types\\npandas overwrites, like datetime.datetime, are restored to their\\noriginal value. See also Register pandas formatters and converters with matplotlib. Examples The following line is done automatically by pandas so\\nthe plot can be rendered: Unsetting the register manually an error will be raised:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'parallel_coordinates(frame,\\xa0class_column[,\\xa0...])',\n",
       "      'func_desc': 'Parallel coordinates plotting.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.plotting.parallel_coordinates.html#pandas.plotting.parallel_coordinates',\n",
       "      'function_definitions': {'function_name': 'pandas.plotting.parallel_coordinates',\n",
       "       'full_function': 'pandas.plotting.parallel_coordinates(frame, class_column, cols=None, ax=None, color=None, use_columns=False, xticks=None, colormap=None, axvlines=True, axvlines_kwds=None, sort_labels=False, **kwargs)',\n",
       "       'function_text': 'Parallel coordinates plotting.',\n",
       "       'parameter_names_desc': [{'param_name': 'frame',\n",
       "         'param_type': 'DataFrame',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'class_column',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'Column name containing class names.\\n'},\n",
       "        {'param_name': 'cols',\n",
       "         'param_type': 'list, optional',\n",
       "         'param_desc': 'A list of column names to use.\\n'},\n",
       "        {'param_name': 'ax',\n",
       "         'param_type': 'matplotlib.axis, optional',\n",
       "         'param_desc': 'Matplotlib axis object.\\n'},\n",
       "        {'param_name': 'color',\n",
       "         'param_type': 'list or tuple, optional',\n",
       "         'param_desc': 'Colors to use for the different classes.\\n'},\n",
       "        {'param_name': 'use_columns',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'If true, columns will be used as xticks.\\n'},\n",
       "        {'param_name': 'xticks',\n",
       "         'param_type': 'list or tuple, optional',\n",
       "         'param_desc': 'A list of values to use for xticks.\\n'},\n",
       "        {'param_name': 'colormap',\n",
       "         'param_type': 'str or matplotlib colormap, default None',\n",
       "         'param_desc': 'Colormap to use for line colors.\\n'},\n",
       "        {'param_name': 'axvlines',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'If true, vertical lines will be added at each xtick.\\n'},\n",
       "        {'param_name': 'axvlines_kwds',\n",
       "         'param_type': 'keywords, optional',\n",
       "         'param_desc': 'Options to be passed to axvline method for vertical lines.\\n'},\n",
       "        {'param_name': 'sort_labels',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Sort class_column labels, useful when assigning colors.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.plotting.parallel_coordinates',\n",
       "       'descriptions': 'Parallel coordinates plotting.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'frame': {'type': 'DataFrame',\n",
       "          'description': 'DataFrame. '},\n",
       "         'class_column': {'type': 'string',\n",
       "          'description': 'str. Column name containing class names.\\n'},\n",
       "         'cols': {'type': 'array',\n",
       "          'description': 'list, optional. A list of column names to use.\\n'},\n",
       "         'ax': {'type': 'matplotlib.axis, optional',\n",
       "          'description': 'matplotlib.axis, optional. Matplotlib axis object.\\n'},\n",
       "         'color': {'type': 'array',\n",
       "          'description': 'list or tuple, optional. Colors to use for the different classes.\\n'},\n",
       "         'use_columns': {'type': 'boolean',\n",
       "          'description': 'bool, optional. If true, columns will be used as xticks.\\n'},\n",
       "         'xticks': {'type': 'array',\n",
       "          'description': 'list or tuple, optional. A list of values to use for xticks.\\n'},\n",
       "         'colormap': {'type': 'string',\n",
       "          'description': 'str or matplotlib colormap, default None. Colormap to use for line colors.\\n'},\n",
       "         'axvlines': {'type': 'boolean',\n",
       "          'description': 'bool, optional. If true, vertical lines will be added at each xtick.\\n'},\n",
       "         'axvlines_kwds': {'type': 'keywords, optional',\n",
       "          'description': 'keywords, optional. Options to be passed to axvline method for vertical lines.\\n'},\n",
       "         'sort_labels': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Sort class_column labels, useful when assigning colors.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'radviz(frame,\\xa0class_column[,\\xa0ax,\\xa0color,\\xa0...])',\n",
       "      'func_desc': 'Plot a multidimensional dataset in 2D.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.plotting.radviz.html#pandas.plotting.radviz',\n",
       "      'function_definitions': {'function_name': 'pandas.plotting.radviz',\n",
       "       'full_function': 'pandas.plotting.radviz(frame, class_column, ax=None, color=None, colormap=None, **kwds)',\n",
       "       'function_text': 'Plot a multidimensional dataset in 2D. Each Series in the DataFrame is represented as a evenly distributed\\nslice on a circle. Each data point is rendered in the circle according to\\nthe value on each Series. Highly correlated Series in the DataFrame\\nare placed closer on the unit circle. RadViz allow to project a N-dimensional data set into a 2D space where the\\ninfluence of each dimension can be interpreted as a balance between the\\ninfluence of all dimensions. More info available at the original article\\ndescribing RadViz.',\n",
       "       'parameter_names_desc': [{'param_name': 'frame',\n",
       "         'param_type': 'DataFrame',\n",
       "         'param_desc': 'Object holding the data.\\n'},\n",
       "        {'param_name': 'class_column',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'Column name containing the name of the data point category.\\n'},\n",
       "        {'param_name': 'ax',\n",
       "         'param_type': 'matplotlib.axes.Axes, optional',\n",
       "         'param_desc': 'A plot instance to which to add the information.\\n'},\n",
       "        {'param_name': 'color',\n",
       "         'param_type': 'list[str] or tuple[str], optional',\n",
       "         'param_desc': 'Assign a color to each category. Example: [‘blue’, ‘green’].\\n'},\n",
       "        {'param_name': 'colormap',\n",
       "         'param_type': 'str or matplotlib.colors.Colormap, default None',\n",
       "         'param_desc': 'Colormap to select colors from. If string, load colormap with that\\nname from matplotlib.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.plotting.radviz',\n",
       "       'descriptions': 'Plot a multidimensional dataset in 2D. Each Series in the DataFrame is represented as a evenly distributed\\nslice on a circle. Each data point is rendered in the circle according to\\nthe value on each Series. Highly correlated Series in the DataFrame\\nare placed closer on the unit circle. RadViz allow to project a N-dimensional data set into a 2D space where the\\ninfluence of each dimension can be interpreted as a balance between the\\ninfluence of all dimensions. More info available at the original article\\ndescribing RadViz.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'frame': {'type': 'DataFrame',\n",
       "          'description': 'DataFrame. Object holding the data.\\n'},\n",
       "         'class_column': {'type': 'string',\n",
       "          'description': 'str. Column name containing the name of the data point category.\\n'},\n",
       "         'ax': {'type': 'matplotlib.axes.Axes, optional',\n",
       "          'description': 'matplotlib.axes.Axes, optional. A plot instance to which to add the information.\\n'},\n",
       "         'color': {'type': 'string',\n",
       "          'description': 'list[str] or tuple[str], optional. Assign a color to each category. Example: [‘blue’, ‘green’].\\n'},\n",
       "         'colormap': {'type': 'string',\n",
       "          'description': 'str or matplotlib.colors.Colormap, default None. Colormap to select colors from. If string, load colormap with that\\nname from matplotlib.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'scatter_matrix(frame[,\\xa0alpha,\\xa0figsize,\\xa0ax,\\xa0...])',\n",
       "      'func_desc': 'Draw a matrix of scatter plots.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.plotting.scatter_matrix.html#pandas.plotting.scatter_matrix',\n",
       "      'function_definitions': {'function_name': 'pandas.plotting.scatter_matrix',\n",
       "       'full_function': \"pandas.plotting.scatter_matrix(frame, alpha=0.5, figsize=None, ax=None, grid=False, diagonal='hist', marker='.', density_kwds=None, hist_kwds=None, range_padding=0.05, **kwargs)\",\n",
       "       'function_text': 'Draw a matrix of scatter plots.',\n",
       "       'parameter_names_desc': [{'param_name': 'frame',\n",
       "         'param_type': 'DataFrame',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'alpha',\n",
       "         'param_type': 'float, optional',\n",
       "         'param_desc': 'Amount of transparency applied.\\n'},\n",
       "        {'param_name': 'figsize',\n",
       "         'param_type': '(float,float), optional',\n",
       "         'param_desc': 'A tuple (width, height) in inches.\\n'},\n",
       "        {'param_name': 'ax',\n",
       "         'param_type': 'Matplotlib axis object, optional',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'grid',\n",
       "         'param_type': 'bool, optional',\n",
       "         'param_desc': 'Setting this to True will show the grid.\\n'},\n",
       "        {'param_name': 'diagonal',\n",
       "         'param_type': '{‘hist’, ‘kde’}',\n",
       "         'param_desc': 'Pick between ‘kde’ and ‘hist’ for either Kernel Density Estimation or\\nHistogram plot in the diagonal.\\n'},\n",
       "        {'param_name': 'marker',\n",
       "         'param_type': 'str, optional',\n",
       "         'param_desc': 'Matplotlib marker type, default ‘.’.\\n'},\n",
       "        {'param_name': 'density_kwds',\n",
       "         'param_type': 'keywords',\n",
       "         'param_desc': 'Keyword arguments to be passed to kernel density estimate plot.\\n'},\n",
       "        {'param_name': 'hist_kwds',\n",
       "         'param_type': 'keywords',\n",
       "         'param_desc': 'Keyword arguments to be passed to hist function.\\n'},\n",
       "        {'param_name': 'range_padding',\n",
       "         'param_type': 'float, default 0.05',\n",
       "         'param_desc': 'Relative extension of axis range in x and y with respect to\\n(x_max - x_min) or (y_max - y_min).\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.plotting.scatter_matrix',\n",
       "       'descriptions': 'Draw a matrix of scatter plots.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'frame': {'type': 'DataFrame',\n",
       "          'description': 'DataFrame. '},\n",
       "         'alpha': {'type': 'float',\n",
       "          'description': 'float, optional. Amount of transparency applied.\\n'},\n",
       "         'figsize': {'type': 'float',\n",
       "          'description': '(float,float), optional. A tuple (width, height) in inches.\\n'},\n",
       "         'ax': {'type': 'object',\n",
       "          'description': 'Matplotlib axis object, optional. '},\n",
       "         'grid': {'type': 'boolean',\n",
       "          'description': 'bool, optional. Setting this to True will show the grid.\\n'},\n",
       "         'diagonal': {'type': 'string',\n",
       "          'enum': ['hist', ' kde'],\n",
       "          'description': '{‘hist’, ‘kde’}. Pick between ‘kde’ and ‘hist’ for either Kernel Density Estimation or\\nHistogram plot in the diagonal.\\n'},\n",
       "         'marker': {'type': 'string',\n",
       "          'description': 'str, optional. Matplotlib marker type, default ‘.’.\\n'},\n",
       "         'density_kwds': {'type': 'keywords',\n",
       "          'description': 'keywords. Keyword arguments to be passed to kernel density estimate plot.\\n'},\n",
       "         'hist_kwds': {'type': 'keywords',\n",
       "          'description': 'keywords. Keyword arguments to be passed to hist function.\\n'},\n",
       "         'range_padding': {'type': 'float',\n",
       "          'description': 'float, default 0.05. Relative extension of axis range in x and y with respect to\\n(x_max - x_min) or (y_max - y_min).\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'autocorrelation_plot(series[,\\xa0ax])',\n",
       "      'func_desc': 'Autocorrelation plot for time series.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.plotting.autocorrelation_plot.html#pandas.plotting.autocorrelation_plot',\n",
       "      'function_definitions': {'function_name': 'pandas.plotting.autocorrelation_plot',\n",
       "       'full_function': 'pandas.plotting.autocorrelation_plot(series, ax=None, **kwargs)',\n",
       "       'function_text': 'Autocorrelation plot for time series.',\n",
       "       'parameter_names_desc': [{'param_name': 'series',\n",
       "         'param_type': 'Series',\n",
       "         'param_desc': 'The time series to visualize.\\n'},\n",
       "        {'param_name': 'ax',\n",
       "         'param_type': 'Matplotlib axis object, optional',\n",
       "         'param_desc': 'The matplotlib axis object to use.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.plotting.autocorrelation_plot',\n",
       "       'descriptions': 'Autocorrelation plot for time series.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'series': {'type': 'Series',\n",
       "          'description': 'Series. The time series to visualize.\\n'},\n",
       "         'ax': {'type': 'object',\n",
       "          'description': 'Matplotlib axis object, optional. The matplotlib axis object to use.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'boxplot(data[,\\xa0column,\\xa0by,\\xa0ax,\\xa0fontsize,\\xa0...])',\n",
       "      'func_desc': 'Make a box plot from DataFrame columns.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.plotting.boxplot.html#pandas.plotting.boxplot',\n",
       "      'function_definitions': {'function_name': 'pandas.plotting.boxplot',\n",
       "       'full_function': 'pandas.plotting.boxplot(data, column=None, by=None, ax=None, fontsize=None, rot=0, grid=True, figsize=None, layout=None, return_type=None, **kwargs)',\n",
       "       'function_text': 'Make a box plot from DataFrame columns. Make a box-and-whisker plot from DataFrame columns, optionally grouped\\nby some other columns. A box plot is a method for graphically depicting\\ngroups of numerical data through their quartiles.\\nThe box extends from the Q1 to Q3 quartile values of the data,\\nwith a line at the median (Q2). The whiskers extend from the edges\\nof box to show the range of the data. By default, they extend no more than\\n1.5 * IQR (IQR = Q3 - Q1) from the edges of the box, ending at the farthest\\ndata point within that interval. Outliers are plotted as separate dots. For further details see\\nWikipedia’s entry for boxplot.',\n",
       "       'parameter_names_desc': [{'param_name': 'data',\n",
       "         'param_type': 'DataFrame',\n",
       "         'param_desc': 'The data to visualize.\\n'},\n",
       "        {'param_name': 'column',\n",
       "         'param_type': 'str or list of str, optional',\n",
       "         'param_desc': 'Column name or list of names, or vector.\\nCan be any valid input to pandas.DataFrame.groupby().\\n'},\n",
       "        {'param_name': 'by',\n",
       "         'param_type': 'str or array-like, optional',\n",
       "         'param_desc': 'Column in the DataFrame to pandas.DataFrame.groupby().\\nOne box-plot will be done per value of columns in by.\\n'},\n",
       "        {'param_name': 'ax',\n",
       "         'param_type': 'object of class matplotlib.axes.Axes, optional',\n",
       "         'param_desc': 'The matplotlib axes to be used by boxplot.\\n'},\n",
       "        {'param_name': 'fontsize',\n",
       "         'param_type': 'float or str',\n",
       "         'param_desc': 'Tick label font size in points or as a string (e.g., large).\\n'},\n",
       "        {'param_name': 'rot',\n",
       "         'param_type': 'float, default 0',\n",
       "         'param_desc': 'The rotation angle of labels (in degrees)\\nwith respect to the screen coordinate system.\\n'},\n",
       "        {'param_name': 'grid',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Setting this to True will show the grid.\\n'},\n",
       "        {'param_name': 'figsize',\n",
       "         'param_type': 'A tuple (width, height) in inches',\n",
       "         'param_desc': 'The size of the figure to create in matplotlib.\\n'},\n",
       "        {'param_name': 'layout',\n",
       "         'param_type': 'tuple (rows, columns), optional',\n",
       "         'param_desc': 'For example, (3, 5) will display the subplots\\nusing 3 rows and 5 columns, starting from the top-left.\\n'},\n",
       "        {'param_name': 'return_type',\n",
       "         'param_type': '{‘axes’, ‘dict’, ‘both’} or None, default ‘axes’',\n",
       "         'param_desc': 'The kind of object to return. The default is axes.\\n\\n‘axes’ returns the matplotlib axes the boxplot is drawn on.\\n‘dict’ returns a dictionary whose values are the matplotlib\\nLines of the boxplot.\\n‘both’ returns a namedtuple with the axes and dict.\\nwhen grouping with by, a Series mapping columns to\\nreturn_type is returned.\\nIf return_type is None, a NumPy array\\nof axes with the same shape as layout is returned.\\n\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.plotting.boxplot',\n",
       "       'descriptions': 'Make a box plot from DataFrame columns. Make a box-and-whisker plot from DataFrame columns, optionally grouped\\nby some other columns. A box plot is a method for graphically depicting\\ngroups of numerical data through their quartiles.\\nThe box extends from the Q1 to Q3 quartile values of the data,\\nwith a line at the median (Q2). The whiskers extend from the edges\\nof box to show the range of the data. By default, they extend no more than\\n1.5 * IQR (IQR = Q3 - Q1) from the edges of the box, ending at the farthest\\ndata point within that interval. Outliers are plotted as separate dots. For further details see\\nWikipedia’s entry for boxplot.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'data': {'type': 'DataFrame',\n",
       "          'description': 'DataFrame. The data to visualize.\\n'},\n",
       "         'column': {'type': 'string',\n",
       "          'description': 'str or list of str, optional. Column name or list of names, or vector.\\nCan be any valid input to pandas.DataFrame.groupby().\\n'},\n",
       "         'by': {'type': 'string',\n",
       "          'description': 'str or array-like, optional. Column in the DataFrame to pandas.DataFrame.groupby().\\nOne box-plot will be done per value of columns in by.\\n'},\n",
       "         'ax': {'type': 'object',\n",
       "          'description': 'object of class matplotlib.axes.Axes, optional. The matplotlib axes to be used by boxplot.\\n'},\n",
       "         'fontsize': {'type': 'string',\n",
       "          'description': 'float or str. Tick label font size in points or as a string (e.g., large).\\n'},\n",
       "         'rot': {'type': 'float',\n",
       "          'description': 'float, default 0. The rotation angle of labels (in degrees)\\nwith respect to the screen coordinate system.\\n'},\n",
       "         'grid': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Setting this to True will show the grid.\\n'},\n",
       "         'figsize': {'type': 'A tuple (width, height) in inches',\n",
       "          'description': 'A tuple (width, height) in inches. The size of the figure to create in matplotlib.\\n'},\n",
       "         'layout': {'type': 'tuple (rows, columns), optional',\n",
       "          'description': 'tuple (rows, columns), optional. For example, (3, 5) will display the subplots\\nusing 3 rows and 5 columns, starting from the top-left.\\n'},\n",
       "         'return_type': {'type': 'string',\n",
       "          'enum': ['axes', ' dict', ' both'],\n",
       "          'description': '{‘axes’, ‘dict’, ‘both’} or None, default ‘axes’. The kind of object to return. The default is axes.\\n\\n‘axes’ returns the matplotlib axes the boxplot is drawn on.\\n‘dict’ returns a dictionary whose values are the matplotlib\\nLines of the boxplot.\\n‘both’ returns a namedtuple with the axes and dict.\\nwhen grouping with by, a Series mapping columns to\\nreturn_type is returned.\\nIf return_type is None, a NumPy array\\nof axes with the same shape as layout is returned.\\n\\n\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'lag_plot(series[,\\xa0lag,\\xa0ax])',\n",
       "      'func_desc': 'Lag plot for time series.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.plotting.lag_plot.html#pandas.plotting.lag_plot',\n",
       "      'function_definitions': {'function_name': 'pandas.plotting.lag_plot',\n",
       "       'full_function': 'pandas.plotting.lag_plot(series, lag=1, ax=None, **kwds)',\n",
       "       'function_text': 'Lag plot for time series.',\n",
       "       'parameter_names_desc': [{'param_name': 'series',\n",
       "         'param_type': 'Series',\n",
       "         'param_desc': 'The time series to visualize.\\n'},\n",
       "        {'param_name': 'lag',\n",
       "         'param_type': 'int, default 1',\n",
       "         'param_desc': 'Lag length of the scatter plot.\\n'},\n",
       "        {'param_name': 'ax',\n",
       "         'param_type': 'Matplotlib axis object, optional',\n",
       "         'param_desc': 'The matplotlib axis object to use.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.plotting.lag_plot',\n",
       "       'descriptions': 'Lag plot for time series.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'series': {'type': 'Series',\n",
       "          'description': 'Series. The time series to visualize.\\n'},\n",
       "         'lag': {'type': 'integer',\n",
       "          'description': 'int, default 1. Lag length of the scatter plot.\\n'},\n",
       "         'ax': {'type': 'object',\n",
       "          'description': 'Matplotlib axis object, optional. The matplotlib axis object to use.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'plot_params',\n",
       "      'func_desc': 'Stores pandas plotting options.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.plotting.plot_params.html#pandas.plotting.plot_params',\n",
       "      'function_definitions': {'function_name': 'pandas.plotting.plot_params',\n",
       "       'full_function': \"pandas.plotting.plot_params = {'xaxis.compat': False}#\",\n",
       "       'function_text': 'Stores pandas plotting options. Allows for parameter aliasing so you can just use parameter names that are\\nthe same as the plot function parameters, but is stored in a canonical\\nformat that makes it easy to breakdown into groups later. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'register_matplotlib_converters()',\n",
       "      'func_desc': 'Register pandas formatters and converters with matplotlib.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.plotting.register_matplotlib_converters.html#pandas.plotting.register_matplotlib_converters',\n",
       "      'function_definitions': {'function_name': 'pandas.plotting.register_matplotlib_converters',\n",
       "       'full_function': 'pandas.plotting.register_matplotlib_converters()',\n",
       "       'function_text': 'Register pandas formatters and converters with matplotlib. This function modifies the global matplotlib.units.registry\\ndictionary. pandas adds custom converters for pd.Timestamp pd.Period np.datetime64 datetime.datetime datetime.date datetime.time See also Remove pandas formatters and converters. Examples The following line is done automatically by pandas so\\nthe plot can be rendered: Unsetting the register manually an error will be raised:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'table(ax,\\xa0data,\\xa0**kwargs)',\n",
       "      'func_desc': 'Helper function to convert DataFrame and Series to matplotlib.table.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.plotting.table.html#pandas.plotting.table',\n",
       "      'function_definitions': {'function_name': 'pandas.plotting.table',\n",
       "       'full_function': 'pandas.plotting.table(ax, data, **kwargs)',\n",
       "       'function_text': 'Helper function to convert DataFrame and Series to matplotlib.table.',\n",
       "       'parameter_names_desc': [{'param_name': 'ax',\n",
       "         'param_type': 'Matplotlib axes object',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'data',\n",
       "         'param_type': 'DataFrame or Series',\n",
       "         'param_desc': 'Data for table contents.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.plotting.table',\n",
       "       'descriptions': 'Helper function to convert DataFrame and Series to matplotlib.table.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'ax': {'type': 'object',\n",
       "          'description': 'Matplotlib axes object. '},\n",
       "         'data': {'type': 'DataFrame or Series',\n",
       "          'description': 'DataFrame or Series. Data for table contents.\\n'}},\n",
       "        'required': []}}}]}],\n",
       "  'name': 'Plotting',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/plotting.html'},\n",
       " 'options.html': {'functions': [{'Working with options': [{'func_name': 'describe_option(pat[,\\xa0_print_desc])',\n",
       "      'func_desc': 'Prints the description for one or more registered options.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.describe_option.html#pandas.describe_option',\n",
       "      'function_definitions': {'function_name': 'pandas.describe_option',\n",
       "       'full_function': 'pandas.describe_option(pat, _print_desc=False) = <pandas._config.config.CallableDynamicDoc object>#',\n",
       "       'function_text': 'Prints the description for one or more registered options. Call with no arguments to get a listing for all registered options. Available options: compute.[use_bottleneck, use_numba, use_numexpr] display.[chop_threshold, colheader_justify, date_dayfirst, date_yearfirst,\\nencoding, expand_frame_repr, float_format] display.html.[border, table_schema, use_mathjax] display.[large_repr, max_categories, max_columns, max_colwidth, max_dir_items,\\nmax_info_columns, max_info_rows, max_rows, max_seq_items, memory_usage,\\nmin_rows, multi_sparse, notebook_repr_html, pprint_nest_depth, precision,\\nshow_dimensions] display.unicode.[ambiguous_as_wide, east_asian_width] display.[width] future.[infer_string, no_silent_downcasting] io.excel.ods.[reader, writer] io.excel.xls.[reader] io.excel.xlsb.[reader] io.excel.xlsm.[reader, writer] io.excel.xlsx.[reader, writer] io.hdf.[default_format, dropna_table] io.parquet.[engine] io.sql.[engine] mode.[chained_assignment, copy_on_write, data_manager, sim_interactive,\\nstring_storage, use_inf_as_na] plotting.[backend] plotting.matplotlib.[register_converters] styler.format.[decimal, escape, formatter, na_rep, precision, thousands] styler.html.[mathjax] styler.latex.[environment, hrules, multicol_align, multirow_align] styler.render.[encoding, max_columns, max_elements, max_rows, repr] styler.sparse.[columns, index]',\n",
       "       'parameter_names_desc': [{'param_name': 'pat',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'Regexp pattern. All matching keys will have their description displayed.\\n'},\n",
       "        {'param_name': '_print_desc',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'If True (default) the description(s) will be printed to stdout.\\nOtherwise, the description(s) will be returned as a unicode string\\n(for testing).\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.describe_option',\n",
       "       'descriptions': 'Prints the description for one or more registered options. Call with no arguments to get a listing for all registered options. Available options: compute.[use_bottleneck, use_numba, use_numexpr] display.[chop_threshold, colheader_justify, date_dayfirst, date_yearfirst,\\nencoding, expand_frame_repr, float_format] display.html.[border, table_schema, use_mathjax] display.[large_repr, max_categories, max_columns, max_colwidth, max_dir_items,\\nmax_info_columns, max_info_rows, max_rows, max_seq_items, memory_usage,\\nmin_rows, multi_sparse, notebook_repr_html, pprint_nest_depth, precision,\\nshow_dimensions] display.unicode.[ambiguous_as_wide, east_asian_width] display.[width] future.[infer_string, no_silent_downcasting] io.excel.ods.[reader, writer] io.excel.xls.[reader] io.excel.xlsb.[reader] io.excel.xlsm.[reader, writer] io.excel.xlsx.[reader, writer] io.hdf.[default_format, dropna_table] io.parquet.[engine] io.sql.[engine] mode.[chained_assignment, copy_on_write, data_manager, sim_interactive,\\nstring_storage, use_inf_as_na] plotting.[backend] plotting.matplotlib.[register_converters] styler.format.[decimal, escape, formatter, na_rep, precision, thousands] styler.html.[mathjax] styler.latex.[environment, hrules, multicol_align, multirow_align] styler.render.[encoding, max_columns, max_elements, max_rows, repr] styler.sparse.[columns, index]',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'pat': {'type': 'string',\n",
       "          'description': 'str. Regexp pattern. All matching keys will have their description displayed.\\n'},\n",
       "         '_print_desc': {'type': 'boolean',\n",
       "          'description': 'bool, default True. If True (default) the description(s) will be printed to stdout.\\nOtherwise, the description(s) will be returned as a unicode string\\n(for testing).\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'get_option(pat)',\n",
       "      'func_desc': 'Retrieves the value of the specified option.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.get_option.html#pandas.get_option',\n",
       "      'function_definitions': {'function_name': 'pandas.get_option',\n",
       "       'full_function': 'pandas.get_option(pat) = <pandas._config.config.CallableDynamicDoc object>#',\n",
       "       'function_text': 'Retrieves the value of the specified option. Available options: compute.[use_bottleneck, use_numba, use_numexpr] display.[chop_threshold, colheader_justify, date_dayfirst, date_yearfirst,\\nencoding, expand_frame_repr, float_format] display.html.[border, table_schema, use_mathjax] display.[large_repr, max_categories, max_columns, max_colwidth, max_dir_items,\\nmax_info_columns, max_info_rows, max_rows, max_seq_items, memory_usage,\\nmin_rows, multi_sparse, notebook_repr_html, pprint_nest_depth, precision,\\nshow_dimensions] display.unicode.[ambiguous_as_wide, east_asian_width] display.[width] future.[infer_string, no_silent_downcasting] io.excel.ods.[reader, writer] io.excel.xls.[reader] io.excel.xlsb.[reader] io.excel.xlsm.[reader, writer] io.excel.xlsx.[reader, writer] io.hdf.[default_format, dropna_table] io.parquet.[engine] io.sql.[engine] mode.[chained_assignment, copy_on_write, data_manager, sim_interactive,\\nstring_storage, use_inf_as_na] plotting.[backend] plotting.matplotlib.[register_converters] styler.format.[decimal, escape, formatter, na_rep, precision, thousands] styler.html.[mathjax] styler.latex.[environment, hrules, multicol_align, multirow_align] styler.render.[encoding, max_columns, max_elements, max_rows, repr] styler.sparse.[columns, index]',\n",
       "       'parameter_names_desc': [{'param_name': 'OptionError',\n",
       "         'param_type': 'if no such option exists',\n",
       "         'param_desc': ''}]},\n",
       "      'function_calling': {'name': 'pandas.get_option',\n",
       "       'descriptions': 'Retrieves the value of the specified option. Available options: compute.[use_bottleneck, use_numba, use_numexpr] display.[chop_threshold, colheader_justify, date_dayfirst, date_yearfirst,\\nencoding, expand_frame_repr, float_format] display.html.[border, table_schema, use_mathjax] display.[large_repr, max_categories, max_columns, max_colwidth, max_dir_items,\\nmax_info_columns, max_info_rows, max_rows, max_seq_items, memory_usage,\\nmin_rows, multi_sparse, notebook_repr_html, pprint_nest_depth, precision,\\nshow_dimensions] display.unicode.[ambiguous_as_wide, east_asian_width] display.[width] future.[infer_string, no_silent_downcasting] io.excel.ods.[reader, writer] io.excel.xls.[reader] io.excel.xlsb.[reader] io.excel.xlsm.[reader, writer] io.excel.xlsx.[reader, writer] io.hdf.[default_format, dropna_table] io.parquet.[engine] io.sql.[engine] mode.[chained_assignment, copy_on_write, data_manager, sim_interactive,\\nstring_storage, use_inf_as_na] plotting.[backend] plotting.matplotlib.[register_converters] styler.format.[decimal, escape, formatter, na_rep, precision, thousands] styler.html.[mathjax] styler.latex.[environment, hrules, multicol_align, multirow_align] styler.render.[encoding, max_columns, max_elements, max_rows, repr] styler.sparse.[columns, index]',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'OptionError': {'type': 'if no such option exists',\n",
       "          'description': 'if no such option exists. '}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'option_context(*args)',\n",
       "      'func_desc': 'Context manager to temporarily set options in the with statement context.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.option_context.html#pandas.option_context',\n",
       "      'function_definitions': {'function_name': 'pandas.option_context',\n",
       "       'full_function': 'class pandas.option_context(*args)',\n",
       "       'function_text': 'Context manager to temporarily set options in the with statement context. You need to invoke as option_context(pat, val, [(pat, val), ...]). Examples Methods',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'reset_option(pat)',\n",
       "      'func_desc': 'Reset one or more options to their default value.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.reset_option.html#pandas.reset_option',\n",
       "      'function_definitions': {'function_name': 'pandas.reset_option',\n",
       "       'full_function': 'pandas.reset_option(pat) = <pandas._config.config.CallableDynamicDoc object>#',\n",
       "       'function_text': 'Reset one or more options to their default value. Pass “all” as argument to reset all options. Available options: compute.[use_bottleneck, use_numba, use_numexpr] display.[chop_threshold, colheader_justify, date_dayfirst, date_yearfirst,\\nencoding, expand_frame_repr, float_format] display.html.[border, table_schema, use_mathjax] display.[large_repr, max_categories, max_columns, max_colwidth, max_dir_items,\\nmax_info_columns, max_info_rows, max_rows, max_seq_items, memory_usage,\\nmin_rows, multi_sparse, notebook_repr_html, pprint_nest_depth, precision,\\nshow_dimensions] display.unicode.[ambiguous_as_wide, east_asian_width] display.[width] future.[infer_string, no_silent_downcasting] io.excel.ods.[reader, writer] io.excel.xls.[reader] io.excel.xlsb.[reader] io.excel.xlsm.[reader, writer] io.excel.xlsx.[reader, writer] io.hdf.[default_format, dropna_table] io.parquet.[engine] io.sql.[engine] mode.[chained_assignment, copy_on_write, data_manager, sim_interactive,\\nstring_storage, use_inf_as_na] plotting.[backend] plotting.matplotlib.[register_converters] styler.format.[decimal, escape, formatter, na_rep, precision, thousands] styler.html.[mathjax] styler.latex.[environment, hrules, multicol_align, multirow_align] styler.render.[encoding, max_columns, max_elements, max_rows, repr] styler.sparse.[columns, index]',\n",
       "       'parameter_names_desc': [{'param_name': 'pat',\n",
       "         'param_type': 'str/regex',\n",
       "         'param_desc': 'If specified only options matching prefix* will be reset.\\nNote: partial matches are supported for convenience, but unless you\\nuse the full option name (e.g. x.y.z.option_name), your code may break\\nin future versions if new options with similar names are introduced.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.reset_option',\n",
       "       'descriptions': 'Reset one or more options to their default value. Pass “all” as argument to reset all options. Available options: compute.[use_bottleneck, use_numba, use_numexpr] display.[chop_threshold, colheader_justify, date_dayfirst, date_yearfirst,\\nencoding, expand_frame_repr, float_format] display.html.[border, table_schema, use_mathjax] display.[large_repr, max_categories, max_columns, max_colwidth, max_dir_items,\\nmax_info_columns, max_info_rows, max_rows, max_seq_items, memory_usage,\\nmin_rows, multi_sparse, notebook_repr_html, pprint_nest_depth, precision,\\nshow_dimensions] display.unicode.[ambiguous_as_wide, east_asian_width] display.[width] future.[infer_string, no_silent_downcasting] io.excel.ods.[reader, writer] io.excel.xls.[reader] io.excel.xlsb.[reader] io.excel.xlsm.[reader, writer] io.excel.xlsx.[reader, writer] io.hdf.[default_format, dropna_table] io.parquet.[engine] io.sql.[engine] mode.[chained_assignment, copy_on_write, data_manager, sim_interactive,\\nstring_storage, use_inf_as_na] plotting.[backend] plotting.matplotlib.[register_converters] styler.format.[decimal, escape, formatter, na_rep, precision, thousands] styler.html.[mathjax] styler.latex.[environment, hrules, multicol_align, multirow_align] styler.render.[encoding, max_columns, max_elements, max_rows, repr] styler.sparse.[columns, index]',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'pat': {'type': 'string',\n",
       "          'description': 'str/regex. If specified only options matching prefix* will be reset.\\nNote: partial matches are supported for convenience, but unless you\\nuse the full option name (e.g. x.y.z.option_name), your code may break\\nin future versions if new options with similar names are introduced.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'set_option(pat,\\xa0value)',\n",
       "      'func_desc': 'Sets the value of the specified option.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.set_option.html#pandas.set_option',\n",
       "      'function_definitions': {'function_name': 'pandas.set_option',\n",
       "       'full_function': 'pandas.set_option(pat, value) = <pandas._config.config.CallableDynamicDoc object>#',\n",
       "       'function_text': 'Sets the value of the specified option. Available options: compute.[use_bottleneck, use_numba, use_numexpr] display.[chop_threshold, colheader_justify, date_dayfirst, date_yearfirst,\\nencoding, expand_frame_repr, float_format] display.html.[border, table_schema, use_mathjax] display.[large_repr, max_categories, max_columns, max_colwidth, max_dir_items,\\nmax_info_columns, max_info_rows, max_rows, max_seq_items, memory_usage,\\nmin_rows, multi_sparse, notebook_repr_html, pprint_nest_depth, precision,\\nshow_dimensions] display.unicode.[ambiguous_as_wide, east_asian_width] display.[width] future.[infer_string, no_silent_downcasting] io.excel.ods.[reader, writer] io.excel.xls.[reader] io.excel.xlsb.[reader] io.excel.xlsm.[reader, writer] io.excel.xlsx.[reader, writer] io.hdf.[default_format, dropna_table] io.parquet.[engine] io.sql.[engine] mode.[chained_assignment, copy_on_write, data_manager, sim_interactive,\\nstring_storage, use_inf_as_na] plotting.[backend] plotting.matplotlib.[register_converters] styler.format.[decimal, escape, formatter, na_rep, precision, thousands] styler.html.[mathjax] styler.latex.[environment, hrules, multicol_align, multirow_align] styler.render.[encoding, max_columns, max_elements, max_rows, repr] styler.sparse.[columns, index]',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'Numeric formatting': [{'func_name': 'set_eng_float_format([accuracy,\\xa0use_eng_prefix])',\n",
       "      'func_desc': 'Format float representation in DataFrame with SI notation.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.set_eng_float_format.html#pandas.set_eng_float_format',\n",
       "      'function_definitions': {'function_name': 'pandas.set_eng_float_format',\n",
       "       'full_function': 'pandas.set_eng_float_format(accuracy=3, use_eng_prefix=False)',\n",
       "       'function_text': 'Format float representation in DataFrame with SI notation.',\n",
       "       'parameter_names_desc': [{'param_name': 'accuracy',\n",
       "         'param_type': 'int, default 3',\n",
       "         'param_desc': 'Number of decimal digits after the floating point.\\n'},\n",
       "        {'param_name': 'use_eng_prefix',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to represent a value with SI prefixes.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.set_eng_float_format',\n",
       "       'descriptions': 'Format float representation in DataFrame with SI notation.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'accuracy': {'type': 'integer',\n",
       "          'description': 'int, default 3. Number of decimal digits after the floating point.\\n'},\n",
       "         'use_eng_prefix': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to represent a value with SI prefixes.\\n'}},\n",
       "        'required': []}}}]}],\n",
       "  'name': 'Options and settings',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/options.html'},\n",
       " 'extensions.html': {'functions': [{'defaults': [{'func_name': 'api.extensions.register_extension_dtype(cls)',\n",
       "      'func_desc': 'Register an ExtensionType with pandas as class decorator.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.register_extension_dtype.html#pandas.api.extensions.register_extension_dtype',\n",
       "      'function_definitions': {'function_name': 'pandas.api.extensions.register_extension_dtype',\n",
       "       'full_function': 'pandas.api.extensions.register_extension_dtype(cls)',\n",
       "       'function_text': 'Register an ExtensionType with pandas as class decorator. This enables operations like .astype(name) for the name\\nof the ExtensionDtype.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'api.extensions.register_series_accessor(name)',\n",
       "      'func_desc': 'Register a custom accessor on Series objects.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.register_series_accessor.html#pandas.api.extensions.register_series_accessor',\n",
       "      'function_definitions': {'function_name': 'pandas.api.extensions.register_series_accessor',\n",
       "       'full_function': 'pandas.api.extensions.register_series_accessor(name)',\n",
       "       'function_text': 'Register a custom accessor on Series objects.',\n",
       "       'parameter_names_desc': [{'param_name': 'name',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'Name under which the accessor should be registered. A warning is issued\\nif this name conflicts with a preexisting attribute.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.api.extensions.register_series_accessor',\n",
       "       'descriptions': 'Register a custom accessor on Series objects.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'name': {'type': 'string',\n",
       "          'description': 'str. Name under which the accessor should be registered. A warning is issued\\nif this name conflicts with a preexisting attribute.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'api.extensions.ExtensionDtype()',\n",
       "      'func_desc': 'A custom data type, to be paired with an ExtensionArray.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionDtype.html#pandas.api.extensions.ExtensionDtype',\n",
       "      'function_definitions': {'function_name': 'pandas.api.extensions.ExtensionDtype',\n",
       "       'full_function': 'class pandas.api.extensions.ExtensionDtype',\n",
       "       'function_text': \"A custom data type, to be paired with an ExtensionArray. See also Register an ExtensionType with pandas as class decorator. Abstract base class for custom 1-D array types. Notes The interface includes the following abstract methods that must\\nbe implemented by subclasses: type name construct_array_type The following attributes and methods influence the behavior of the dtype in\\npandas operations _is_numeric _is_boolean _get_common_dtype The na_value class attribute can be used to set the default NA value\\nfor this type. numpy.nan is used by default. ExtensionDtypes are required to be hashable. The base class provides\\na default implementation, which relies on the _metadata class\\nattribute. _metadata should be a tuple containing the strings\\nthat define your data type. For example, with PeriodDtype that’s\\nthe freq attribute. If you have a parametrized dtype you should set the ``_metadata``\\nclass property. Ideally, the attributes in _metadata will match the\\nparameters to your ExtensionDtype.__init__ (if any). If any of\\nthe attributes in _metadata don’t implement the standard\\n__eq__ or __hash__, the default implementations here will not\\nwork. Examples For interaction with Apache Arrow (pyarrow), a __from_arrow__ method\\ncan be implemented: this method receives a pyarrow Array or ChunkedArray\\nas only argument and is expected to return the appropriate pandas\\nExtensionArray for this dtype and the passed values: This class does not inherit from ‘abc.ABCMeta’ for performance reasons.\\nMethods and properties required by the interface raise\\npandas.errors.AbstractMethodError and no register method is\\nprovided for registering virtual subclasses. Attributes index_class The Index subclass to return from Index.__new__ when this dtype is encountered. kind A character code (one of 'biufcmMOSUV'), default 'O' na_value Default NA value to use for this type. name A string identifying the data type. names Ordered list of field names, or None if there are no fields. type The scalar type for the array, e.g. int. Methods construct_array_type() Return the array type associated with this dtype. construct_from_string(string) Construct this type from a string. empty(shape) Construct an ExtensionArray of this dtype with the given shape. is_dtype(dtype) Check if we match 'dtype'.\",\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'api.extensions.register_dataframe_accessor(name)',\n",
       "      'func_desc': 'Register a custom accessor on DataFrame objects.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.register_dataframe_accessor.html#pandas.api.extensions.register_dataframe_accessor',\n",
       "      'function_definitions': {'function_name': 'pandas.api.extensions.register_dataframe_accessor',\n",
       "       'full_function': 'pandas.api.extensions.register_dataframe_accessor(name)',\n",
       "       'function_text': 'Register a custom accessor on DataFrame objects.',\n",
       "       'parameter_names_desc': [{'param_name': 'name',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'Name under which the accessor should be registered. A warning is issued\\nif this name conflicts with a preexisting attribute.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.api.extensions.register_dataframe_accessor',\n",
       "       'descriptions': 'Register a custom accessor on DataFrame objects.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'name': {'type': 'string',\n",
       "          'description': 'str. Name under which the accessor should be registered. A warning is issued\\nif this name conflicts with a preexisting attribute.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'api.extensions.register_index_accessor(name)',\n",
       "      'func_desc': 'Register a custom accessor on Index objects.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.register_index_accessor.html#pandas.api.extensions.register_index_accessor',\n",
       "      'function_definitions': {'function_name': 'pandas.api.extensions.register_index_accessor',\n",
       "       'full_function': 'pandas.api.extensions.register_index_accessor(name)',\n",
       "       'function_text': 'Register a custom accessor on Index objects.',\n",
       "       'parameter_names_desc': [{'param_name': 'name',\n",
       "         'param_type': 'str',\n",
       "         'param_desc': 'Name under which the accessor should be registered. A warning is issued\\nif this name conflicts with a preexisting attribute.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.api.extensions.register_index_accessor',\n",
       "       'descriptions': 'Register a custom accessor on Index objects.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'name': {'type': 'string',\n",
       "          'description': 'str. Name under which the accessor should be registered. A warning is issued\\nif this name conflicts with a preexisting attribute.\\n'}},\n",
       "        'required': []}}}]}],\n",
       "  'name': 'Extensions',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/extensions.html'},\n",
       " 'testing.html': {'functions': [{'Assertion functions': [{'func_name': 'testing.assert_frame_equal(left,\\xa0right[,\\xa0...])',\n",
       "      'func_desc': 'Check that left and right DataFrame are equal.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.testing.assert_frame_equal.html#pandas.testing.assert_frame_equal',\n",
       "      'function_definitions': {'function_name': 'pandas.testing.assert_frame_equal',\n",
       "       'full_function': \"pandas.testing.assert_frame_equal(left, right, check_dtype=True, check_index_type='equiv', check_column_type='equiv', check_frame_type=True, check_names=True, by_blocks=False, check_exact=_NoDefault.no_default, check_datetimelike_compat=False, check_categorical=True, check_like=False, check_freq=True, check_flags=True, rtol=_NoDefault.no_default, atol=_NoDefault.no_default, obj='DataFrame')\",\n",
       "       'function_text': 'Check that left and right DataFrame are equal. This function is intended to compare two DataFrames and output any\\ndifferences. It is mostly intended for use in unit tests.\\nAdditional parameters allow varying the strictness of the\\nequality checks performed.',\n",
       "       'parameter_names_desc': [{'param_name': 'left',\n",
       "         'param_type': 'DataFrame',\n",
       "         'param_desc': 'First DataFrame to compare.\\n'},\n",
       "        {'param_name': 'right',\n",
       "         'param_type': 'DataFrame',\n",
       "         'param_desc': 'Second DataFrame to compare.\\n'},\n",
       "        {'param_name': 'check_dtype',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to check the DataFrame dtype is identical.\\n'},\n",
       "        {'param_name': 'check_index_type',\n",
       "         'param_type': 'bool or {‘equiv’}, default ‘equiv’',\n",
       "         'param_desc': 'Whether to check the Index class, dtype and inferred_type\\nare identical.\\n'},\n",
       "        {'param_name': 'check_column_type',\n",
       "         'param_type': 'bool or {‘equiv’}, default ‘equiv’',\n",
       "         'param_desc': 'Whether to check the columns class, dtype and inferred_type\\nare identical. Is passed as the exact argument of\\nassert_index_equal().\\n'},\n",
       "        {'param_name': 'check_frame_type',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to check the DataFrame class is identical.\\n'},\n",
       "        {'param_name': 'check_names',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to check that the names attribute for both the index\\nand column attributes of the DataFrame is identical.\\n'},\n",
       "        {'param_name': 'by_blocks',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Specify how to compare internal data. If False, compare by columns.\\nIf True, compare by blocks.\\n'},\n",
       "        {'param_name': 'check_exact',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to compare number exactly.\\n\\nChanged in version 2.2.0: Defaults to True for integer dtypes if none of\\ncheck_exact, rtol and atol are specified.\\n\\n'},\n",
       "        {'param_name': 'check_datetimelike_compat',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Compare datetime-like which is comparable ignoring dtype.\\n'},\n",
       "        {'param_name': 'check_categorical',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to compare internal Categorical exactly.\\n'},\n",
       "        {'param_name': 'check_like',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True, ignore the order of index & columns.\\nNote: index labels must match their respective rows\\n(same as in columns) - same labels must be with the same data.\\n'},\n",
       "        {'param_name': 'check_freq',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to check the freq attribute on a DatetimeIndex or TimedeltaIndex.\\n'},\n",
       "        {'param_name': 'check_flags',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to check the flags attribute.\\n'},\n",
       "        {'param_name': 'rtol',\n",
       "         'param_type': 'float, default 1e-5',\n",
       "         'param_desc': 'Relative tolerance. Only used when check_exact is False.\\n'},\n",
       "        {'param_name': 'atol',\n",
       "         'param_type': 'float, default 1e-8',\n",
       "         'param_desc': 'Absolute tolerance. Only used when check_exact is False.\\n'},\n",
       "        {'param_name': 'obj',\n",
       "         'param_type': 'str, default ‘DataFrame’',\n",
       "         'param_desc': 'Specify object name being compared, internally used to show appropriate\\nassertion message.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.testing.assert_frame_equal',\n",
       "       'descriptions': 'Check that left and right DataFrame are equal. This function is intended to compare two DataFrames and output any\\ndifferences. It is mostly intended for use in unit tests.\\nAdditional parameters allow varying the strictness of the\\nequality checks performed.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'left': {'type': 'DataFrame',\n",
       "          'description': 'DataFrame. First DataFrame to compare.\\n'},\n",
       "         'right': {'type': 'DataFrame',\n",
       "          'description': 'DataFrame. Second DataFrame to compare.\\n'},\n",
       "         'check_dtype': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to check the DataFrame dtype is identical.\\n'},\n",
       "         'check_index_type': {'type': 'boolean',\n",
       "          'description': 'bool or {‘equiv’}, default ‘equiv’. Whether to check the Index class, dtype and inferred_type\\nare identical.\\n'},\n",
       "         'check_column_type': {'type': 'boolean',\n",
       "          'description': 'bool or {‘equiv’}, default ‘equiv’. Whether to check the columns class, dtype and inferred_type\\nare identical. Is passed as the exact argument of\\nassert_index_equal().\\n'},\n",
       "         'check_frame_type': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to check the DataFrame class is identical.\\n'},\n",
       "         'check_names': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to check that the names attribute for both the index\\nand column attributes of the DataFrame is identical.\\n'},\n",
       "         'by_blocks': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Specify how to compare internal data. If False, compare by columns.\\nIf True, compare by blocks.\\n'},\n",
       "         'check_exact': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to compare number exactly.\\n\\nChanged in version 2.2.0: Defaults to True for integer dtypes if none of\\ncheck_exact, rtol and atol are specified.\\n\\n'},\n",
       "         'check_datetimelike_compat': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Compare datetime-like which is comparable ignoring dtype.\\n'},\n",
       "         'check_categorical': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to compare internal Categorical exactly.\\n'},\n",
       "         'check_like': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True, ignore the order of index & columns.\\nNote: index labels must match their respective rows\\n(same as in columns) - same labels must be with the same data.\\n'},\n",
       "         'check_freq': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to check the freq attribute on a DatetimeIndex or TimedeltaIndex.\\n'},\n",
       "         'check_flags': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to check the flags attribute.\\n'},\n",
       "         'rtol': {'type': 'float',\n",
       "          'description': 'float, default 1e-5. Relative tolerance. Only used when check_exact is False.\\n'},\n",
       "         'atol': {'type': 'float',\n",
       "          'description': 'float, default 1e-8. Absolute tolerance. Only used when check_exact is False.\\n'},\n",
       "         'obj': {'type': 'string',\n",
       "          'description': 'str, default ‘DataFrame’. Specify object name being compared, internally used to show appropriate\\nassertion message.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'testing.assert_index_equal(left,\\xa0right[,\\xa0...])',\n",
       "      'func_desc': 'Check that left and right Index are equal.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.testing.assert_index_equal.html#pandas.testing.assert_index_equal',\n",
       "      'function_definitions': {'function_name': 'pandas.testing.assert_index_equal',\n",
       "       'full_function': \"pandas.testing.assert_index_equal(left, right, exact='equiv', check_names=True, check_exact=True, check_categorical=True, check_order=True, rtol=1e-05, atol=1e-08, obj='Index')\",\n",
       "       'function_text': 'Check that left and right Index are equal.',\n",
       "       'parameter_names_desc': [{'param_name': 'left',\n",
       "         'param_type': 'Index',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'right', 'param_type': 'Index', 'param_desc': ''},\n",
       "        {'param_name': 'exact',\n",
       "         'param_type': 'bool or {‘equiv’}, default ‘equiv’',\n",
       "         'param_desc': 'Whether to check the Index class, dtype and inferred_type\\nare identical. If ‘equiv’, then RangeIndex can be substituted for\\nIndex with an int64 dtype as well.\\n'},\n",
       "        {'param_name': 'check_names',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to check the names attribute.\\n'},\n",
       "        {'param_name': 'check_exact',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to compare number exactly.\\n'},\n",
       "        {'param_name': 'check_categorical',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to compare internal Categorical exactly.\\n'},\n",
       "        {'param_name': 'check_order',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to compare the order of index entries as well as their values.\\nIf True, both indexes must contain the same elements, in the same order.\\nIf False, both indexes must contain the same elements, but in any order.\\n'},\n",
       "        {'param_name': 'rtol',\n",
       "         'param_type': 'float, default 1e-5',\n",
       "         'param_desc': 'Relative tolerance. Only used when check_exact is False.\\n'},\n",
       "        {'param_name': 'atol',\n",
       "         'param_type': 'float, default 1e-8',\n",
       "         'param_desc': 'Absolute tolerance. Only used when check_exact is False.\\n'},\n",
       "        {'param_name': 'obj',\n",
       "         'param_type': 'str, default ‘Index’',\n",
       "         'param_desc': 'Specify object name being compared, internally used to show appropriate\\nassertion message.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.testing.assert_index_equal',\n",
       "       'descriptions': 'Check that left and right Index are equal.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'left': {'type': 'Index', 'description': 'Index. '},\n",
       "         'right': {'type': 'Index', 'description': 'Index. '},\n",
       "         'exact': {'type': 'boolean',\n",
       "          'description': 'bool or {‘equiv’}, default ‘equiv’. Whether to check the Index class, dtype and inferred_type\\nare identical. If ‘equiv’, then RangeIndex can be substituted for\\nIndex with an int64 dtype as well.\\n'},\n",
       "         'check_names': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to check the names attribute.\\n'},\n",
       "         'check_exact': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to compare number exactly.\\n'},\n",
       "         'check_categorical': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to compare internal Categorical exactly.\\n'},\n",
       "         'check_order': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to compare the order of index entries as well as their values.\\nIf True, both indexes must contain the same elements, in the same order.\\nIf False, both indexes must contain the same elements, but in any order.\\n'},\n",
       "         'rtol': {'type': 'float',\n",
       "          'description': 'float, default 1e-5. Relative tolerance. Only used when check_exact is False.\\n'},\n",
       "         'atol': {'type': 'float',\n",
       "          'description': 'float, default 1e-8. Absolute tolerance. Only used when check_exact is False.\\n'},\n",
       "         'obj': {'type': 'string',\n",
       "          'description': 'str, default ‘Index’. Specify object name being compared, internally used to show appropriate\\nassertion message.\\n'}},\n",
       "        'required': []}}},\n",
       "     {'func_name': 'testing.assert_series_equal(left,\\xa0right[,\\xa0...])',\n",
       "      'func_desc': 'Check that left and right Series are equal.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.testing.assert_series_equal.html#pandas.testing.assert_series_equal',\n",
       "      'function_definitions': {'function_name': 'pandas.testing.assert_series_equal',\n",
       "       'full_function': \"pandas.testing.assert_series_equal(left, right, check_dtype=True, check_index_type='equiv', check_series_type=True, check_names=True, check_exact=_NoDefault.no_default, check_datetimelike_compat=False, check_categorical=True, check_category_order=True, check_freq=True, check_flags=True, rtol=_NoDefault.no_default, atol=_NoDefault.no_default, obj='Series', *, check_index=True, check_like=False)\",\n",
       "       'function_text': 'Check that left and right Series are equal.',\n",
       "       'parameter_names_desc': [{'param_name': 'left',\n",
       "         'param_type': 'Series',\n",
       "         'param_desc': ''},\n",
       "        {'param_name': 'right', 'param_type': 'Series', 'param_desc': ''},\n",
       "        {'param_name': 'check_dtype',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to check the Series dtype is identical.\\n'},\n",
       "        {'param_name': 'check_index_type',\n",
       "         'param_type': 'bool or {‘equiv’}, default ‘equiv’',\n",
       "         'param_desc': 'Whether to check the Index class, dtype and inferred_type\\nare identical.\\n'},\n",
       "        {'param_name': 'check_series_type',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to check the Series class is identical.\\n'},\n",
       "        {'param_name': 'check_names',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to check the Series and Index names attribute.\\n'},\n",
       "        {'param_name': 'check_exact',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to compare number exactly.\\n\\nChanged in version 2.2.0: Defaults to True for integer dtypes if none of\\ncheck_exact, rtol and atol are specified.\\n\\n'},\n",
       "        {'param_name': 'check_datetimelike_compat',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Compare datetime-like which is comparable ignoring dtype.\\n'},\n",
       "        {'param_name': 'check_categorical',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to compare internal Categorical exactly.\\n'},\n",
       "        {'param_name': 'check_category_order',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to compare category order of internal Categoricals.\\n'},\n",
       "        {'param_name': 'check_freq',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to check the freq attribute on a DatetimeIndex or TimedeltaIndex.\\n'},\n",
       "        {'param_name': 'check_flags',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to check the flags attribute.\\n'},\n",
       "        {'param_name': 'rtol',\n",
       "         'param_type': 'float, default 1e-5',\n",
       "         'param_desc': 'Relative tolerance. Only used when check_exact is False.\\n'},\n",
       "        {'param_name': 'atol',\n",
       "         'param_type': 'float, default 1e-8',\n",
       "         'param_desc': 'Absolute tolerance. Only used when check_exact is False.\\n'},\n",
       "        {'param_name': 'obj',\n",
       "         'param_type': 'str, default ‘Series’',\n",
       "         'param_desc': 'Specify object name being compared, internally used to show appropriate\\nassertion message.\\n'},\n",
       "        {'param_name': 'check_index',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to check index equivalence. If False, then compare only values.\\n\\nNew in version 1.3.0.\\n\\n'},\n",
       "        {'param_name': 'check_like',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'If True, ignore the order of the index. Must be False if check_index is False.\\nNote: same labels must be with the same data.\\n\\nNew in version 1.5.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.testing.assert_series_equal',\n",
       "       'descriptions': 'Check that left and right Series are equal.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'left': {'type': 'Series', 'description': 'Series. '},\n",
       "         'right': {'type': 'Series', 'description': 'Series. '},\n",
       "         'check_dtype': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to check the Series dtype is identical.\\n'},\n",
       "         'check_index_type': {'type': 'boolean',\n",
       "          'description': 'bool or {‘equiv’}, default ‘equiv’. Whether to check the Index class, dtype and inferred_type\\nare identical.\\n'},\n",
       "         'check_series_type': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to check the Series class is identical.\\n'},\n",
       "         'check_names': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to check the Series and Index names attribute.\\n'},\n",
       "         'check_exact': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to compare number exactly.\\n\\nChanged in version 2.2.0: Defaults to True for integer dtypes if none of\\ncheck_exact, rtol and atol are specified.\\n\\n'},\n",
       "         'check_datetimelike_compat': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Compare datetime-like which is comparable ignoring dtype.\\n'},\n",
       "         'check_categorical': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to compare internal Categorical exactly.\\n'},\n",
       "         'check_category_order': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to compare category order of internal Categoricals.\\n'},\n",
       "         'check_freq': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to check the freq attribute on a DatetimeIndex or TimedeltaIndex.\\n'},\n",
       "         'check_flags': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to check the flags attribute.\\n'},\n",
       "         'rtol': {'type': 'float',\n",
       "          'description': 'float, default 1e-5. Relative tolerance. Only used when check_exact is False.\\n'},\n",
       "         'atol': {'type': 'float',\n",
       "          'description': 'float, default 1e-8. Absolute tolerance. Only used when check_exact is False.\\n'},\n",
       "         'obj': {'type': 'string',\n",
       "          'description': 'str, default ‘Series’. Specify object name being compared, internally used to show appropriate\\nassertion message.\\n'},\n",
       "         'check_index': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to check index equivalence. If False, then compare only values.\\n\\nNew in version 1.3.0.\\n\\n'},\n",
       "         'check_like': {'type': 'boolean',\n",
       "          'description': 'bool, default False. If True, ignore the order of the index. Must be False if check_index is False.\\nNote: same labels must be with the same data.\\n\\nNew in version 1.5.0.\\n\\n'}},\n",
       "        'required': ['left',\n",
       "         'right',\n",
       "         'check_dtype=True',\n",
       "         \"check_index_type='equiv'\",\n",
       "         'check_series_type=True',\n",
       "         'check_names=True',\n",
       "         'check_exact=_NoDefault.no_default',\n",
       "         'check_datetimelike_compat=False',\n",
       "         'check_categorical=True',\n",
       "         'check_category_order=True',\n",
       "         'check_freq=True',\n",
       "         'check_flags=True',\n",
       "         'rtol=_NoDefault.no_default',\n",
       "         'atol=_NoDefault.no_default',\n",
       "         \"obj='Series'\"]}}},\n",
       "     {'func_name': 'testing.assert_extension_array_equal(left,\\xa0right)',\n",
       "      'func_desc': 'Check that left and right ExtensionArrays are equal.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.testing.assert_extension_array_equal.html#pandas.testing.assert_extension_array_equal',\n",
       "      'function_definitions': {'function_name': 'pandas.testing.assert_extension_array_equal',\n",
       "       'full_function': \"pandas.testing.assert_extension_array_equal(left, right, check_dtype=True, index_values=None, check_exact=_NoDefault.no_default, rtol=_NoDefault.no_default, atol=_NoDefault.no_default, obj='ExtensionArray')\",\n",
       "       'function_text': 'Check that left and right ExtensionArrays are equal.',\n",
       "       'parameter_names_desc': [{'param_name': 'left, right',\n",
       "         'param_type': 'ExtensionArray',\n",
       "         'param_desc': 'The two arrays to compare.\\n'},\n",
       "        {'param_name': 'check_dtype',\n",
       "         'param_type': 'bool, default True',\n",
       "         'param_desc': 'Whether to check if the ExtensionArray dtypes are identical.\\n'},\n",
       "        {'param_name': 'index_values',\n",
       "         'param_type': 'Index | numpy.ndarray, default None',\n",
       "         'param_desc': 'Optional index (shared by both left and right), used in output.\\n'},\n",
       "        {'param_name': 'check_exact',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to compare number exactly.\\n\\nChanged in version 2.2.0: Defaults to True for integer dtypes if none of\\ncheck_exact, rtol and atol are specified.\\n\\n'},\n",
       "        {'param_name': 'rtol',\n",
       "         'param_type': 'float, default 1e-5',\n",
       "         'param_desc': 'Relative tolerance. Only used when check_exact is False.\\n'},\n",
       "        {'param_name': 'atol',\n",
       "         'param_type': 'float, default 1e-8',\n",
       "         'param_desc': 'Absolute tolerance. Only used when check_exact is False.\\n'},\n",
       "        {'param_name': 'obj',\n",
       "         'param_type': 'str, default ‘ExtensionArray’',\n",
       "         'param_desc': 'Specify object name being compared, internally used to show appropriate\\nassertion message.\\n\\nNew in version 2.0.0.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.testing.assert_extension_array_equal',\n",
       "       'descriptions': 'Check that left and right ExtensionArrays are equal.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'left, right': {'type': 'ExtensionArray',\n",
       "          'description': 'ExtensionArray. The two arrays to compare.\\n'},\n",
       "         'check_dtype': {'type': 'boolean',\n",
       "          'description': 'bool, default True. Whether to check if the ExtensionArray dtypes are identical.\\n'},\n",
       "         'index_values': {'type': 'array',\n",
       "          'description': 'Index | numpy.ndarray, default None. Optional index (shared by both left and right), used in output.\\n'},\n",
       "         'check_exact': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to compare number exactly.\\n\\nChanged in version 2.2.0: Defaults to True for integer dtypes if none of\\ncheck_exact, rtol and atol are specified.\\n\\n'},\n",
       "         'rtol': {'type': 'float',\n",
       "          'description': 'float, default 1e-5. Relative tolerance. Only used when check_exact is False.\\n'},\n",
       "         'atol': {'type': 'float',\n",
       "          'description': 'float, default 1e-8. Absolute tolerance. Only used when check_exact is False.\\n'},\n",
       "         'obj': {'type': 'string',\n",
       "          'description': 'str, default ‘ExtensionArray’. Specify object name being compared, internally used to show appropriate\\nassertion message.\\n\\nNew in version 2.0.0.\\n\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Exceptions and warnings': [{'func_name': 'errors.AbstractMethodError(class_instance[,\\xa0...])',\n",
       "      'func_desc': 'Raise this error instead of NotImplementedError for abstract methods.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.AbstractMethodError.html#pandas.errors.AbstractMethodError',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.AbstractMethodError',\n",
       "       'full_function': \"exception pandas.errors.AbstractMethodError(class_instance, methodtype='method')\",\n",
       "       'function_text': 'Raise this error instead of NotImplementedError for abstract methods. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.CategoricalConversionWarning',\n",
       "      'func_desc': 'Warning is raised when reading a partial labeled Stata file using a iterator.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.CategoricalConversionWarning.html#pandas.errors.CategoricalConversionWarning',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.CategoricalConversionWarning',\n",
       "       'full_function': 'exception pandas.errors.CategoricalConversionWarning',\n",
       "       'function_text': 'Warning is raised when reading a partial labeled Stata file using a iterator. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.ClosedFileError',\n",
       "      'func_desc': 'Exception is raised when trying to perform an operation on a closed HDFStore file.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.ClosedFileError.html#pandas.errors.ClosedFileError',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.ClosedFileError',\n",
       "       'full_function': 'exception pandas.errors.ClosedFileError',\n",
       "       'function_text': 'Exception is raised when trying to perform an operation on a closed HDFStore file. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.DatabaseError',\n",
       "      'func_desc': 'Error is raised when executing sql with bad syntax or sql that throws an error.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.DatabaseError.html#pandas.errors.DatabaseError',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.DatabaseError',\n",
       "       'full_function': 'exception pandas.errors.DatabaseError',\n",
       "       'function_text': 'Error is raised when executing sql with bad syntax or sql that throws an error. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.DtypeWarning',\n",
       "      'func_desc': 'Warning raised when reading different dtypes in a column from a file.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.DtypeWarning.html#pandas.errors.DtypeWarning',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.DtypeWarning',\n",
       "       'full_function': 'exception pandas.errors.DtypeWarning',\n",
       "       'function_text': 'Warning raised when reading different dtypes in a column from a file. Raised for a dtype incompatibility. This can happen whenever read_csv\\nor read_table encounter non-uniform dtypes in a column(s) of a given\\nCSV file. See also Read CSV (comma-separated) file into a DataFrame. Read general delimited file into a DataFrame. Notes This warning is issued when dealing with larger files because the dtype\\nchecking happens per chunk read. Despite the warning, the CSV file is read with mixed types in a single\\ncolumn which will be an object type. See the examples below to better\\nunderstand this issue. Examples This example creates and reads a large CSV file with a column that contains\\nint and str. Important to notice that df2 will contain both str and int for the\\nsame input, ‘1’. One way to solve this issue is using the dtype parameter in the\\nread_csv and read_table functions to explicit the conversion: No warning was issued.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.EmptyDataError',\n",
       "      'func_desc': 'Exception raised in pd.read_csv when empty data or header is encountered.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.EmptyDataError.html#pandas.errors.EmptyDataError',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.EmptyDataError',\n",
       "       'full_function': 'exception pandas.errors.EmptyDataError',\n",
       "       'function_text': 'Exception raised in pd.read_csv when empty data or header is encountered. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.IndexingError',\n",
       "      'func_desc': 'Exception is raised when trying to index and there is a mismatch in dimensions.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.IndexingError.html#pandas.errors.IndexingError',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.IndexingError',\n",
       "       'full_function': 'exception pandas.errors.IndexingError',\n",
       "       'function_text': 'Exception is raised when trying to index and there is a mismatch in dimensions. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.InvalidComparison',\n",
       "      'func_desc': 'Exception is raised by _validate_comparison_value to indicate an invalid comparison.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.InvalidComparison.html#pandas.errors.InvalidComparison',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.InvalidComparison',\n",
       "       'full_function': 'exception pandas.errors.InvalidComparison',\n",
       "       'function_text': 'Exception is raised by _validate_comparison_value to indicate an invalid comparison. Notes This is an internal error.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.InvalidVersion',\n",
       "      'func_desc': 'An invalid version was found, users should refer to PEP 440.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.InvalidVersion.html#pandas.errors.InvalidVersion',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.InvalidVersion',\n",
       "       'full_function': 'exception pandas.errors.InvalidVersion',\n",
       "       'function_text': 'An invalid version was found, users should refer to PEP 440. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.LossySetitemError',\n",
       "      'func_desc': 'Raised when trying to do a __setitem__ on an np.ndarray that is not lossless.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.LossySetitemError.html#pandas.errors.LossySetitemError',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.LossySetitemError',\n",
       "       'full_function': 'exception pandas.errors.LossySetitemError',\n",
       "       'function_text': 'Raised when trying to do a __setitem__ on an np.ndarray that is not lossless. Notes This is an internal error.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.NoBufferPresent',\n",
       "      'func_desc': 'Exception is raised in _get_data_buffer to signal that there is no requested buffer.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.NoBufferPresent.html#pandas.errors.NoBufferPresent',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.NoBufferPresent',\n",
       "       'full_function': 'exception pandas.errors.NoBufferPresent',\n",
       "       'function_text': 'Exception is raised in _get_data_buffer to signal that there is no requested buffer.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.NumbaUtilError',\n",
       "      'func_desc': 'Error raised for unsupported Numba engine routines.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.NumbaUtilError.html#pandas.errors.NumbaUtilError',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.NumbaUtilError',\n",
       "       'full_function': 'exception pandas.errors.NumbaUtilError',\n",
       "       'function_text': 'Error raised for unsupported Numba engine routines. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.OptionError',\n",
       "      'func_desc': 'Exception raised for pandas.options.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.OptionError.html#pandas.errors.OptionError',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.OptionError',\n",
       "       'full_function': 'exception pandas.errors.OptionError',\n",
       "       'function_text': 'Exception raised for pandas.options. Backwards compatible with KeyError checks. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.OutOfBoundsTimedelta',\n",
       "      'func_desc': 'Raised when encountering a timedelta value that cannot be represented.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.OutOfBoundsTimedelta.html#pandas.errors.OutOfBoundsTimedelta',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.OutOfBoundsTimedelta',\n",
       "       'full_function': 'exception pandas.errors.OutOfBoundsTimedelta#',\n",
       "       'function_text': 'Raised when encountering a timedelta value that cannot be represented. Representation should be within a timedelta64[ns]. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.ParserWarning',\n",
       "      'func_desc': \"Warning raised when reading a file that doesn't use the default 'c' parser.\",\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.ParserWarning.html#pandas.errors.ParserWarning',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.ParserWarning',\n",
       "       'full_function': 'exception pandas.errors.ParserWarning',\n",
       "       'function_text': 'Warning raised when reading a file that doesn’t use the default ‘c’ parser. Raised by pd.read_csv and pd.read_table when it is necessary to change\\nparsers, generally from the default ‘c’ parser to ‘python’. It happens due to a lack of support or functionality for parsing a\\nparticular attribute of a CSV file with the requested engine. Currently, ‘c’ unsupported options include the following parameters: sep other than a single character (e.g. regex separators) skipfooter higher than 0 sep=None with delim_whitespace=False The warning can be avoided by adding engine=’python’ as a parameter in\\npd.read_csv and pd.read_table methods. See also Read CSV (comma-separated) file into DataFrame. Read general delimited file into DataFrame. Examples Using a sep in pd.read_csv other than a single character: Adding engine=’python’ to pd.read_csv removes the Warning:',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.PossibleDataLossError',\n",
       "      'func_desc': 'Exception raised when trying to open a HDFStore file when already opened.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.PossibleDataLossError.html#pandas.errors.PossibleDataLossError',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.PossibleDataLossError',\n",
       "       'full_function': 'exception pandas.errors.PossibleDataLossError',\n",
       "       'function_text': 'Exception raised when trying to open a HDFStore file when already opened. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.PyperclipException',\n",
       "      'func_desc': 'Exception raised when clipboard functionality is unsupported.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.PyperclipException.html#pandas.errors.PyperclipException',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.PyperclipException',\n",
       "       'full_function': 'exception pandas.errors.PyperclipException',\n",
       "       'function_text': 'Exception raised when clipboard functionality is unsupported. Raised by to_clipboard() and read_clipboard().',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.SettingWithCopyError',\n",
       "      'func_desc': 'Exception raised when trying to set on a copied slice from a DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.SettingWithCopyError.html#pandas.errors.SettingWithCopyError',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.SettingWithCopyError',\n",
       "       'full_function': 'exception pandas.errors.SettingWithCopyError',\n",
       "       'function_text': 'Exception raised when trying to set on a copied slice from a DataFrame. The mode.chained_assignment needs to be set to set to ‘raise.’ This can\\nhappen unintentionally when chained indexing. For more information on evaluation order,\\nsee the user guide. For more information on view vs. copy,\\nsee the user guide. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.SpecificationError',\n",
       "      'func_desc': 'Exception raised by agg when the functions are ill-specified.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.SpecificationError.html#pandas.errors.SpecificationError',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.SpecificationError',\n",
       "       'full_function': 'exception pandas.errors.SpecificationError',\n",
       "       'function_text': 'Exception raised by agg when the functions are ill-specified. The exception raised in two scenarios. The first way is calling agg on a\\nDataframe or Series using a nested renamer (dict-of-dict). The second way is calling agg on a Dataframe with duplicated functions\\nnames without assigning column name. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.UnsortedIndexError',\n",
       "      'func_desc': 'Error raised when slicing a MultiIndex which has not been lexsorted.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.UnsortedIndexError.html#pandas.errors.UnsortedIndexError',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.UnsortedIndexError',\n",
       "       'full_function': 'exception pandas.errors.UnsortedIndexError',\n",
       "       'function_text': 'Error raised when slicing a MultiIndex which has not been lexsorted. Subclass of KeyError. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.ValueLabelTypeMismatch',\n",
       "      'func_desc': 'Warning raised by to_stata on a category column that contains non-string values.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.ValueLabelTypeMismatch.html#pandas.errors.ValueLabelTypeMismatch',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.ValueLabelTypeMismatch',\n",
       "       'full_function': 'exception pandas.errors.ValueLabelTypeMismatch',\n",
       "       'function_text': 'Warning raised by to_stata on a category column that contains non-string values. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.AttributeConflictWarning',\n",
       "      'func_desc': 'Warning raised when index attributes conflict when using HDFStore.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.AttributeConflictWarning.html#pandas.errors.AttributeConflictWarning',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.AttributeConflictWarning',\n",
       "       'full_function': 'exception pandas.errors.AttributeConflictWarning',\n",
       "       'function_text': 'Warning raised when index attributes conflict when using HDFStore. Occurs when attempting to append an index with a different\\nname than the existing index on an HDFStore or attempting to append an index with a\\ndifferent frequency than the existing index on an HDFStore. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.ChainedAssignmentError',\n",
       "      'func_desc': 'Warning raised when trying to set using chained assignment.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.ChainedAssignmentError.html#pandas.errors.ChainedAssignmentError',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.ChainedAssignmentError',\n",
       "       'full_function': 'exception pandas.errors.ChainedAssignmentError',\n",
       "       'function_text': 'Warning raised when trying to set using chained assignment. When the mode.copy_on_write option is enabled, chained assignment can\\nnever work. In such a situation, we are always setting into a temporary\\nobject that is the result of an indexing operation (getitem), which under\\nCopy-on-Write always behaves as a copy. Thus, assigning through a chain\\ncan never update the original Series or DataFrame. For more information on view vs. copy,\\nsee the user guide. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.CSSWarning',\n",
       "      'func_desc': 'Warning is raised when converting css styling fails.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.CSSWarning.html#pandas.errors.CSSWarning',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.CSSWarning',\n",
       "       'full_function': 'exception pandas.errors.CSSWarning',\n",
       "       'function_text': 'Warning is raised when converting css styling fails. This can be due to the styling not having an equivalent value or because the\\nstyling isn’t properly formatted. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.DataError',\n",
       "      'func_desc': 'Exceptionn raised when performing an operation on non-numerical data.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.DataError.html#pandas.errors.DataError',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.DataError',\n",
       "       'full_function': 'exception pandas.errors.DataError',\n",
       "       'function_text': 'Exceptionn raised when performing an operation on non-numerical data. For example, calling ohlc on a non-numerical column or a function\\non a rolling window. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.DuplicateLabelError',\n",
       "      'func_desc': 'Error raised when an operation would introduce duplicate labels.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.DuplicateLabelError.html#pandas.errors.DuplicateLabelError',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.DuplicateLabelError',\n",
       "       'full_function': 'exception pandas.errors.DuplicateLabelError',\n",
       "       'function_text': 'Error raised when an operation would introduce duplicate labels. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.IncompatibilityWarning',\n",
       "      'func_desc': 'Warning raised when trying to use where criteria on an incompatible HDF5 file.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.IncompatibilityWarning.html#pandas.errors.IncompatibilityWarning',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.IncompatibilityWarning',\n",
       "       'full_function': 'exception pandas.errors.IncompatibilityWarning',\n",
       "       'function_text': 'Warning raised when trying to use where criteria on an incompatible HDF5 file.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.InvalidColumnName',\n",
       "      'func_desc': 'Warning raised by to_stata the column contains a non-valid stata name.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.InvalidColumnName.html#pandas.errors.InvalidColumnName',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.InvalidColumnName',\n",
       "       'full_function': 'exception pandas.errors.InvalidColumnName',\n",
       "       'function_text': 'Warning raised by to_stata the column contains a non-valid stata name. Because the column name is an invalid Stata variable, the name needs to be\\nconverted. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.InvalidIndexError',\n",
       "      'func_desc': 'Exception raised when attempting to use an invalid index key.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.InvalidIndexError.html#pandas.errors.InvalidIndexError',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.InvalidIndexError',\n",
       "       'full_function': 'exception pandas.errors.InvalidIndexError',\n",
       "       'function_text': 'Exception raised when attempting to use an invalid index key. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.IntCastingNaNError',\n",
       "      'func_desc': 'Exception raised when converting (astype) an array with NaN to an integer type.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.IntCastingNaNError.html#pandas.errors.IntCastingNaNError',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.IntCastingNaNError',\n",
       "       'full_function': 'exception pandas.errors.IntCastingNaNError',\n",
       "       'function_text': 'Exception raised when converting (astype) an array with NaN to an integer type. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.MergeError',\n",
       "      'func_desc': 'Exception raised when merging data.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.MergeError.html#pandas.errors.MergeError',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.MergeError',\n",
       "       'full_function': 'exception pandas.errors.MergeError',\n",
       "       'function_text': 'Exception raised when merging data. Subclass of ValueError. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.NullFrequencyError',\n",
       "      'func_desc': 'Exception raised when a freq cannot be null.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.NullFrequencyError.html#pandas.errors.NullFrequencyError',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.NullFrequencyError',\n",
       "       'full_function': 'exception pandas.errors.NullFrequencyError',\n",
       "       'function_text': 'Exception raised when a freq cannot be null. Particularly DatetimeIndex.shift, TimedeltaIndex.shift,\\nPeriodIndex.shift. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.NumExprClobberingError',\n",
       "      'func_desc': 'Exception raised when trying to use a built-in numexpr name as a variable name.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.NumExprClobberingError.html#pandas.errors.NumExprClobberingError',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.NumExprClobberingError',\n",
       "       'full_function': 'exception pandas.errors.NumExprClobberingError',\n",
       "       'function_text': 'Exception raised when trying to use a built-in numexpr name as a variable name. eval or query will throw the error if the engine is set\\nto ‘numexpr’. ‘numexpr’ is the default engine value for these methods if the\\nnumexpr package is installed. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.OutOfBoundsDatetime',\n",
       "      'func_desc': 'Raised when the datetime is outside the range that can be represented.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.OutOfBoundsDatetime.html#pandas.errors.OutOfBoundsDatetime',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.OutOfBoundsDatetime',\n",
       "       'full_function': 'exception pandas.errors.OutOfBoundsDatetime#',\n",
       "       'function_text': 'Raised when the datetime is outside the range that can be represented. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.ParserError',\n",
       "      'func_desc': 'Exception that is raised by an error encountered in parsing file contents.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.ParserError.html#pandas.errors.ParserError',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.ParserError',\n",
       "       'full_function': 'exception pandas.errors.ParserError',\n",
       "       'function_text': 'Exception that is raised by an error encountered in parsing file contents. This is a generic error raised for errors encountered when functions like\\nread_csv or read_html are parsing contents of a file. See also Read CSV (comma-separated) file into a DataFrame. Read HTML table into a DataFrame. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.PerformanceWarning',\n",
       "      'func_desc': 'Warning raised when there is a possible performance impact.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.PerformanceWarning.html#pandas.errors.PerformanceWarning',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.PerformanceWarning',\n",
       "       'full_function': 'exception pandas.errors.PerformanceWarning',\n",
       "       'function_text': 'Warning raised when there is a possible performance impact. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.PossiblePrecisionLoss',\n",
       "      'func_desc': 'Warning raised by to_stata on a column with a value outside or equal to int64.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.PossiblePrecisionLoss.html#pandas.errors.PossiblePrecisionLoss',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.PossiblePrecisionLoss',\n",
       "       'full_function': 'exception pandas.errors.PossiblePrecisionLoss',\n",
       "       'function_text': 'Warning raised by to_stata on a column with a value outside or equal to int64. When the column value is outside or equal to the int64 value the column is\\nconverted to a float64 dtype. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.PyperclipWindowsException(message)',\n",
       "      'func_desc': 'Exception raised when clipboard functionality is unsupported by Windows.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.PyperclipWindowsException.html#pandas.errors.PyperclipWindowsException',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.PyperclipWindowsException',\n",
       "       'full_function': 'exception pandas.errors.PyperclipWindowsException(message)',\n",
       "       'function_text': 'Exception raised when clipboard functionality is unsupported by Windows. Access to the clipboard handle would be denied due to some other\\nwindow process is accessing it.',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.SettingWithCopyWarning',\n",
       "      'func_desc': 'Warning raised when trying to set on a copied slice from a DataFrame.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.SettingWithCopyWarning.html#pandas.errors.SettingWithCopyWarning',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.SettingWithCopyWarning',\n",
       "       'full_function': 'exception pandas.errors.SettingWithCopyWarning',\n",
       "       'function_text': 'Warning raised when trying to set on a copied slice from a DataFrame. The mode.chained_assignment needs to be set to set to ‘warn.’\\n‘Warn’ is the default option. This can happen unintentionally when\\nchained indexing. For more information on evaluation order,\\nsee the user guide. For more information on view vs. copy,\\nsee the user guide. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.UndefinedVariableError(name[,\\xa0is_local])',\n",
       "      'func_desc': 'Exception raised by query or eval when using an undefined variable name.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.UndefinedVariableError.html#pandas.errors.UndefinedVariableError',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.UndefinedVariableError',\n",
       "       'full_function': 'exception pandas.errors.UndefinedVariableError(name, is_local=None)',\n",
       "       'function_text': 'Exception raised by query or eval when using an undefined variable name. It will also specify whether the undefined variable is local or not. Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'errors.UnsupportedFunctionCall',\n",
       "      'func_desc': 'Exception raised when attempting to call a unsupported numpy function.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.errors.UnsupportedFunctionCall.html#pandas.errors.UnsupportedFunctionCall',\n",
       "      'function_definitions': {'function_name': 'pandas.errors.UnsupportedFunctionCall',\n",
       "       'full_function': 'exception pandas.errors.UnsupportedFunctionCall',\n",
       "       'function_text': 'Exception raised when attempting to call a unsupported numpy function. For example, np.cumsum(groupby_object). Examples',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]},\n",
       "   {'Bug report function': [{'func_name': 'show_versions([as_json])',\n",
       "      'func_desc': 'Provide useful information, important for bug reports.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.show_versions.html#pandas.show_versions',\n",
       "      'function_definitions': {'function_name': 'pandas.show_versions',\n",
       "       'full_function': 'pandas.show_versions(as_json=False)',\n",
       "       'function_text': 'Provide useful information, important for bug reports. It comprises info about hosting operation system, pandas version,\\nand versions of other installed relative packages.',\n",
       "       'parameter_names_desc': [{'param_name': 'as_json',\n",
       "         'param_type': 'str or bool, default False',\n",
       "         'param_desc': '\\nIf False, outputs info in a human readable form to the console.\\nIf str, it will be considered as a path to a file.\\nInfo will be written to that file in JSON format.\\nIf True, outputs info in JSON format to the console.\\n\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.show_versions',\n",
       "       'descriptions': 'Provide useful information, important for bug reports. It comprises info about hosting operation system, pandas version,\\nand versions of other installed relative packages.',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'as_json': {'type': 'string',\n",
       "          'description': 'str or bool, default False. \\nIf False, outputs info in a human readable form to the console.\\nIf str, it will be considered as a path to a file.\\nInfo will be written to that file in JSON format.\\nIf True, outputs info in JSON format to the console.\\n\\n'}},\n",
       "        'required': []}}}]},\n",
       "   {'Test suite runner': [{'func_name': 'test([extra_args,\\xa0run_doctests])',\n",
       "      'func_desc': 'Run the pandas test suite using pytest.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.test.html#pandas.test',\n",
       "      'function_definitions': {'function_name': 'pandas.test',\n",
       "       'full_function': 'pandas.test(extra_args=None, run_doctests=False)',\n",
       "       'function_text': 'Run the pandas test suite using pytest. By default, runs with the marks -m “not slow and not network and not db”',\n",
       "       'parameter_names_desc': [{'param_name': 'extra_args',\n",
       "         'param_type': 'list[str], default None',\n",
       "         'param_desc': 'Extra marks to run the tests.\\n'},\n",
       "        {'param_name': 'run_doctests',\n",
       "         'param_type': 'bool, default False',\n",
       "         'param_desc': 'Whether to only run the Python and Cython doctests. If you would like to run\\nboth doctests/regular tests, just append “–doctest-modules”/”–doctest-cython”\\nto extra_args.\\n'}]},\n",
       "      'function_calling': {'name': 'pandas.test',\n",
       "       'descriptions': 'Run the pandas test suite using pytest. By default, runs with the marks -m “not slow and not network and not db”',\n",
       "       'parameters': {'type': 'object',\n",
       "        'properties': {'extra_args': {'type': 'string',\n",
       "          'description': 'list[str], default None. Extra marks to run the tests.\\n'},\n",
       "         'run_doctests': {'type': 'boolean',\n",
       "          'description': 'bool, default False. Whether to only run the Python and Cython doctests. If you would like to run\\nboth doctests/regular tests, just append “–doctest-modules”/”–doctest-cython”\\nto extra_args.\\n'}},\n",
       "        'required': []}}}]}],\n",
       "  'name': 'Testing',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/testing.html'},\n",
       " 'missing_value.html': {'functions': [{'defaults': [{'func_name': 'NA',\n",
       "      'func_desc': 'NA (\"not available\") missing value indicator.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/api/pandas.NA.html#pandas.NA',\n",
       "      'function_definitions': {'function_name': 'pandas.NA',\n",
       "       'full_function': 'pandas.NA#',\n",
       "       'function_text': 'alias of <NA>',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]}],\n",
       "  'name': 'Missing values',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/missing_value.html'},\n",
       " 'api/pandas.tseries.frequencies.to_offset.html': {'functions': [{'defaults': []}],\n",
       "  'name': 'pandas.tseries.frequencies.to_offset',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/api/pandas.tseries.frequencies.to_offset.html'},\n",
       " 'api/pandas.plotting.andrews_curves.html': {'functions': [{'defaults': []}],\n",
       "  'name': 'pandas.plotting.andrews_curves',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/api/pandas.plotting.andrews_curves.html'},\n",
       " 'api/pandas.plotting.autocorrelation_plot.html': {'functions': [{'defaults': []}],\n",
       "  'name': 'pandas.plotting.autocorrelation_plot',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/api/pandas.plotting.autocorrelation_plot.html'},\n",
       " 'api/pandas.plotting.bootstrap_plot.html': {'functions': [{'defaults': []}],\n",
       "  'name': 'pandas.plotting.bootstrap_plot',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/api/pandas.plotting.bootstrap_plot.html'},\n",
       " 'api/pandas.plotting.boxplot.html': {'functions': [{'defaults': []}],\n",
       "  'name': 'pandas.plotting.boxplot',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/api/pandas.plotting.boxplot.html'},\n",
       " 'api/pandas.plotting.deregister_matplotlib_converters.html': {'functions': [{'defaults': []}],\n",
       "  'name': 'pandas.plotting.deregister_matplotlib_converters',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/api/pandas.plotting.deregister_matplotlib_converters.html'},\n",
       " 'api/pandas.plotting.lag_plot.html': {'functions': [{'defaults': []}],\n",
       "  'name': 'pandas.plotting.lag_plot',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/api/pandas.plotting.lag_plot.html'},\n",
       " 'api/pandas.plotting.parallel_coordinates.html': {'functions': [{'defaults': []}],\n",
       "  'name': 'pandas.plotting.parallel_coordinates',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/api/pandas.plotting.parallel_coordinates.html'},\n",
       " 'api/pandas.plotting.plot_params.html': {'functions': [{'defaults': []}],\n",
       "  'name': 'pandas.plotting.plot_params',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/api/pandas.plotting.plot_params.html'},\n",
       " 'api/pandas.plotting.radviz.html': {'functions': [{'defaults': []}],\n",
       "  'name': 'pandas.plotting.radviz',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/api/pandas.plotting.radviz.html'},\n",
       " 'api/pandas.plotting.register_matplotlib_converters.html': {'functions': [{'defaults': []}],\n",
       "  'name': 'pandas.plotting.register_matplotlib_converters',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/api/pandas.plotting.register_matplotlib_converters.html'},\n",
       " 'api/pandas.plotting.scatter_matrix.html': {'functions': [{'defaults': []}],\n",
       "  'name': 'pandas.plotting.scatter_matrix',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/api/pandas.plotting.scatter_matrix.html'},\n",
       " 'api/pandas.plotting.table.html': {'functions': [{'defaults': []}],\n",
       "  'name': 'pandas.plotting.table',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/api/pandas.plotting.table.html'},\n",
       " 'api/pandas.api.extensions.register_extension_dtype.html': {'functions': [{'defaults': []}],\n",
       "  'name': 'pandas.api.extensions.register_extension_dtype',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.register_extension_dtype.html'},\n",
       " 'api/pandas.api.extensions.register_dataframe_accessor.html': {'functions': [{'defaults': []}],\n",
       "  'name': 'pandas.api.extensions.register_dataframe_accessor',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.register_dataframe_accessor.html'},\n",
       " 'api/pandas.api.extensions.register_series_accessor.html': {'functions': [{'defaults': []}],\n",
       "  'name': 'pandas.api.extensions.register_series_accessor',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.register_series_accessor.html'},\n",
       " 'api/pandas.api.extensions.register_index_accessor.html': {'functions': [{'defaults': []}],\n",
       "  'name': 'pandas.api.extensions.register_index_accessor',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.register_index_accessor.html'},\n",
       " 'api/pandas.api.extensions.ExtensionDtype.html': {'functions': [{'defaults': []}],\n",
       "  'name': 'pandas.api.extensions.ExtensionDtype',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionDtype.html'},\n",
       " 'api/pandas.api.extensions.ExtensionArray.html': {'functions': [{'defaults': [{'func_name': 'dtype',\n",
       "      'func_desc': 'An instance of ExtensionDtype.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/pandas.api.extensions.ExtensionArray.dtype.html#pandas.api.extensions.ExtensionArray.dtype',\n",
       "      'function_definitions': {'function_name': '',\n",
       "       'full_function': '',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'ndim',\n",
       "      'func_desc': 'Extension Arrays are only allowed to be 1-dimensional.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/pandas.api.extensions.ExtensionArray.ndim.html#pandas.api.extensions.ExtensionArray.ndim',\n",
       "      'function_definitions': {'function_name': '',\n",
       "       'full_function': '',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'nbytes',\n",
       "      'func_desc': 'The number of bytes needed to store this object in memory.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/pandas.api.extensions.ExtensionArray.nbytes.html#pandas.api.extensions.ExtensionArray.nbytes',\n",
       "      'function_definitions': {'function_name': '',\n",
       "       'full_function': '',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}},\n",
       "     {'func_name': 'shape',\n",
       "      'func_desc': 'Return a tuple of the array dimensions.',\n",
       "      'func_url': 'https://pandas.pydata.org/docs/reference/pandas.api.extensions.ExtensionArray.shape.html#pandas.api.extensions.ExtensionArray.shape',\n",
       "      'function_definitions': {'function_name': '',\n",
       "       'full_function': '',\n",
       "       'function_text': '',\n",
       "       'parameter_names_desc': []},\n",
       "      'function_calling': {}}]}],\n",
       "  'name': 'pandas.api.extensions.ExtensionArray',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray.html'},\n",
       " 'api/pandas.arrays.NumpyExtensionArray.html': {'functions': [{'defaults': []}],\n",
       "  'name': 'pandas.arrays.NumpyExtensionArray',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/api/pandas.arrays.NumpyExtensionArray.html'},\n",
       " 'api/pandas.api.indexers.check_array_indexer.html': {'functions': [{'defaults': []}],\n",
       "  'name': 'pandas.api.indexers.check_array_indexer',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/api/pandas.api.indexers.check_array_indexer.html'},\n",
       " 'api/pandas.NA.html': {'functions': [{'defaults': []}],\n",
       "  'name': 'pandas.NA',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/api/pandas.NA.html'},\n",
       " 'api/pandas.NaT.html': {'functions': [{'defaults': []}],\n",
       "  'name': 'pandas.NaT',\n",
       "  'url': 'https://pandas.pydata.org/docs/reference/api/pandas.NaT.html'}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from agent.scrape import scrape_pandas_website\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "scrape_pandas_website()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent.database import build_docs_metadata\n",
    "\n",
    "docs,metadata = build_docs_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1944, 1944)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs),len(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = [len(doc.split(\" \")) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,nw in enumerate(num_words):\n",
    "    if nw==0:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 1944 artists>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar([i for i in range(len(docs))],num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from agent.database import build_database\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "load_dotenv(find_dotenv(),override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"'$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mbuild_database\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOPENAI_API_KEY\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Function Calling/hierarchical-function-calling-agent/pandas-agent/pandas-agent-new/agent/database.py:145\u001b[0m, in \u001b[0;36mbuild_database\u001b[0;34m(docs, metadata, api_key)\u001b[0m\n\u001b[1;32m    141\u001b[0m batches \u001b[38;5;241m=\u001b[39m create_batches(\n\u001b[1;32m    142\u001b[0m     api\u001b[38;5;241m=\u001b[39mclient, ids\u001b[38;5;241m=\u001b[39msklearn_ids, documents\u001b[38;5;241m=\u001b[39mdocs, metadatas\u001b[38;5;241m=\u001b[39mmetadata\n\u001b[1;32m    143\u001b[0m )\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m batches:\n\u001b[0;32m--> 145\u001b[0m     \u001b[43msklearn_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sklearn_collection\n",
      "File \u001b[0;32m~/Function Calling/openbb-env/lib/python3.10/site-packages/chromadb/api/models/Collection.py:154\u001b[0m, in \u001b[0;36mCollection.add\u001b[0;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m embeddings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# At this point, we know that one of documents or images are provided from the validation above\u001b[39;00m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m documents \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m         embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m images \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    156\u001b[0m         embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mimages)\n",
      "File \u001b[0;32m~/Function Calling/openbb-env/lib/python3.10/site-packages/chromadb/api/models/Collection.py:633\u001b[0m, in \u001b[0;36mCollection._embed\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    630\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must provide an embedding function to compute embeddings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.trychroma.com/embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    632\u001b[0m     )\n\u001b[0;32m--> 633\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Function Calling/openbb-env/lib/python3.10/site-packages/chromadb/api/types.py:193\u001b[0m, in \u001b[0;36mEmbeddingFunction.__init_subclass__.<locals>.__call__\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m: EmbeddingFunction[D], \u001b[38;5;28minput\u001b[39m: D) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Embeddings:\n\u001b[0;32m--> 193\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m validate_embeddings(maybe_cast_one_to_many_embedding(result))\n",
      "File \u001b[0;32m~/Function Calling/openbb-env/lib/python3.10/site-packages/chromadb/utils/embedding_functions.py:188\u001b[0m, in \u001b[0;36mOpenAIEmbeddingFunction.__call__\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# Call the OpenAI Embedding API\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_v1:\n\u001b[0;32m--> 188\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_deployment_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_name\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# Sort resulting embeddings by index\u001b[39;00m\n\u001b[1;32m    193\u001b[0m     sorted_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(embeddings, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m e: e\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/Function Calling/openbb-env/lib/python3.10/site-packages/openai/resources/embeddings.py:114\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[0;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    108\u001b[0m         embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[1;32m    109\u001b[0m             base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m         )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Function Calling/openbb-env/lib/python3.10/site-packages/openai/_base_client.py:1240\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1228\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1235\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1236\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1237\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1238\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1239\u001b[0m     )\n\u001b[0;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Function Calling/openbb-env/lib/python3.10/site-packages/openai/_base_client.py:921\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    914\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    920\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Function Calling/openbb-env/lib/python3.10/site-packages/openai/_base_client.py:1020\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1017\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1019\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1023\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1024\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1027\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1028\u001b[0m )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"'$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}"
     ]
    }
   ],
   "source": [
    "import os\n",
    "build_database(docs,metadata,os.environ['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.database\n",
    "pandas_docs = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openbb-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
