{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "filename = \"pandas_function_openai.json\"\n",
    "\n",
    "with open(filename, \"r\", encoding=\"utf-8\") as json_file:\n",
    "        # Load the JSON data from the file\n",
    "        data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"parent_summary_dict.json\"\n",
    "\n",
    "with open(filename, \"r\", encoding=\"utf-8\") as json_file:\n",
    "        # Load the JSON data from the file\n",
    "        parent_summary_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "pandas_graph = nx.DiGraph()\n",
    "\n",
    "parent_names = [(data[d]['name'],{\"url\":data[d]['url'],\"url\":data[d]['url'],\"type\":\"parent_node\",\"node_description\":parent_summary_dict[data[d]['name']]}) for d in data]\n",
    "pandas_graph.add_nodes_from(parent_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for parent in data:\n",
    "    parent_name = data[parent]['name']\n",
    "    for sub_level in data[parent]['functions']:\n",
    "        for func in sub_level['function_definitions']:\n",
    "            func_name = func['function_name']\n",
    "            # parent_trail = parent.split(\".\")[0]\n",
    "            pandas_graph.add_nodes_from([(func_name,{'metadata':func,'trail':f\"{parent_name}\",\"type\":\"function_node\"})])\n",
    "            pandas_graph.add_edge(parent_name,func_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chromadb\n",
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "import os\n",
    "from chromadb.utils.batch_utils import create_batches\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv(),override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "docs = []\n",
    "metadata = []\n",
    "\n",
    "for node, attributes in pandas_graph.nodes(data=True):\n",
    "    if attributes['type'] == 'function_node':\n",
    "        docs.append(attributes['metadata']['function_text'])\n",
    "        metadata.append(str(attributes['metadata']))\n",
    "\n",
    "    elif attributes['type'] == 'parent_node':\n",
    "        docs.append(attributes['node_description'])\n",
    "        attributes['name'] = node\n",
    "        metadata.append(str(attributes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pprint\n",
    "# pp = pprint.PrettyPrinter(depth=4)\n",
    "# pp.pprint(attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The pandas library in Python provides a wide range of functions for reading and writing data in various formats. These functions include loading pickled objects, reading delimited files, CSV files, fixed-width formatted lines, Excel files, JSON strings, HTML tables, XML documents, and more. There are also functions for working with HDFStore, feather-format objects, parquet objects, ORC objects, SAS files, SPSS files, SQL databases, Google BigQuery, and Stata files. Additionally, there are functions for creating table schemas, normalizing JSON data, rendering DataFrames to XML documents, and exporting DataFrames to Stata dta format. These functions allow for seamless data manipulation and analysis across different data sources and formats. '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'function_name': 'pandas.test', 'full_function': 'pandas.test(extra_args=None, run_doctests=False)', 'function_text': 'Run the pandas test suite using pytest.', 'parameter_names_desc': [{'param_name': 'extra_args', 'param_type': 'list[str], default None', 'param_desc': 'Extra marks to run the tests.\\\\n'}, {'param_name': 'run_doctests', 'param_type': 'bool, default False', 'param_desc': 'Whether to only run the Python and Cython doctests. If you would like to run\\\\nboth doctests/regular tests, just append “–doctest-modules”/”–doctest-cython”\\\\nto extra_args.\\\\n'}], 'function_url': 'https://pandas.pydata.org/docs/reference/api/pandas.test.html#pandas.test'}\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openbb-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
