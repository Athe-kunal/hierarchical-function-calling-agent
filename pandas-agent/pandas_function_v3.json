{"io.html": {"functions": [{"name": "Pickling", "url": "https://pandas.pydata.org/docs/reference/io.html#pickling", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.read_pickle.html#pandas.read_pickle", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_pickle.html#pandas.DataFrame.to_pickle"], "function_definitions": [{"function_name": "pandas.read_pickle", "full_function": "pandas.read_pickle(filepath_or_buffer, compression='infer', storage_options=None)", "function_text": "Load pickled pandas object (or any object) from file.", "parameter_names_desc": [{"param_name": "filepath_or_buffer", "param_type": "str, path object, or file-like object", "param_desc": "String, path object (implementing os.PathLike[str]), or file-like\nobject implementing a binary readlines() function.\nAlso accepts URL. URL is not limited to S3 and GCS.\n"}, {"param_name": "compression", "param_type": "str or dict, default ‘infer’", "param_desc": "For on-the-fly decompression of on-disk data. If ‘infer’ and ‘filepath_or_buffer’ is\npath-like, then detect compression from the following extensions: ‘.gz’,\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\n(otherwise no compression).\nIf using ‘zip’ or ‘tar’, the ZIP file must contain only one data file to be read in.\nSet to None for no decompression.\nCan also be a dict with key 'method' set\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\nother key-value pairs are forwarded to\nzipfile.ZipFile, gzip.GzipFile,\nbz2.BZ2File, zstandard.ZstdDecompressor, lzma.LZMAFile or\ntarfile.TarFile, respectively.\nAs an example, the following could be passed for Zstandard decompression using a\ncustom compression dictionary:\ncompression={'method': 'zstd', 'dict_data': my_compression_dict}.\n\nNew in version 1.5.0: Added support for .tar files.\n\n\nChanged in version 1.4.0: Zstandard support.\n\n"}, {"param_name": "storage_options", "param_type": "dict, optional", "param_desc": "Extra options that make sense for a particular storage connection, e.g.\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\nare forwarded to urllib.request.Request as header options. For other\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\nforwarded to fsspec.open. Please see fsspec and urllib for more\ndetails, and for more examples on storage options refer here.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.read_pickle.html#pandas.read_pickle"}, {"function_name": "pandas.DataFrame.to_pickle", "full_function": "DataFrame.to_pickle(path, *, compression='infer', protocol=5, storage_options=None)", "function_text": "Pickle (serialize) object to file.", "parameter_names_desc": [{"param_name": "path", "param_type": "str, path object, or file-like object", "param_desc": "String, path object (implementing os.PathLike[str]), or file-like\nobject implementing a binary write() function. File path where\nthe pickled object will be stored.\n"}, {"param_name": "compression", "param_type": "str or dict, default ‘infer’", "param_desc": "For on-the-fly compression of the output data. If ‘infer’ and ‘path’ is\npath-like, then detect compression from the following extensions: ‘.gz’,\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\n(otherwise no compression).\nSet to None for no compression.\nCan also be a dict with key 'method' set\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\nother key-value pairs are forwarded to\nzipfile.ZipFile, gzip.GzipFile,\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\ntarfile.TarFile, respectively.\nAs an example, the following could be passed for faster compression and to create\na reproducible gzip archive:\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\n\nNew in version 1.5.0: Added support for .tar files.\n\n"}, {"param_name": "protocol", "param_type": "int", "param_desc": "Int which indicates which protocol should be used by the pickler,\ndefault HIGHEST_PROTOCOL (see [1] paragraph 12.1.2). The possible\nvalues are 0, 1, 2, 3, 4, 5. A negative value for the protocol\nparameter is equivalent to setting its value to HIGHEST_PROTOCOL.\n\n\n[1]\nhttps://docs.python.org/3/library/pickle.html.\n\n\n"}, {"param_name": "storage_options", "param_type": "dict, optional", "param_desc": "Extra options that make sense for a particular storage connection, e.g.\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\nare forwarded to urllib.request.Request as header options. For other\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\nforwarded to fsspec.open. Please see fsspec and urllib for more\ndetails, and for more examples on storage options refer here.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_pickle.html#pandas.DataFrame.to_pickle"}]}, {"name": "Flat file", "url": "https://pandas.pydata.org/docs/reference/io.html#flat-file", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.read_table.html#pandas.read_table", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html#pandas.DataFrame.to_csv", "https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html#pandas.read_csv", "https://pandas.pydata.org/docs/reference/api/pandas.read_fwf.html#pandas.read_fwf"], "function_definitions": [{"function_name": "pandas.read_table", "full_function": "pandas.read_table(filepath_or_buffer, *, sep=_NoDefault.no_default, delimiter=None, header='infer', names=_NoDefault.no_default, index_col=None, usecols=None, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skipinitialspace=False, skiprows=None, skipfooter=0, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=_NoDefault.no_default, skip_blank_lines=True, parse_dates=False, infer_datetime_format=_NoDefault.no_default, keep_date_col=_NoDefault.no_default, date_parser=_NoDefault.no_default, date_format=None, dayfirst=False, cache_dates=True, iterator=False, chunksize=None, compression='infer', thousands=None, decimal='.', lineterminator=None, quotechar='\"', quoting=0, doublequote=True, escapechar=None, comment=None, encoding=None, encoding_errors='strict', dialect=None, on_bad_lines='error', delim_whitespace=_NoDefault.no_default, low_memory=True, memory_map=False, float_precision=None, storage_options=None, dtype_backend=_NoDefault.no_default)", "function_text": "Read general delimited file into DataFrame.", "parameter_names_desc": [{"param_name": "filepath_or_buffer", "param_type": "str, path object or file-like object", "param_desc": "Any valid string path is acceptable. The string could be a URL. Valid\nURL schemes include http, ftp, s3, gs, and file. For file URLs, a host is\nexpected. A local file could be: file://localhost/path/to/table.csv.\nIf you want to pass in a path object, pandas accepts any os.PathLike.\nBy file-like object, we refer to objects with a read() method, such as\na file handle (e.g. via builtin open function) or StringIO.\n"}, {"param_name": "sep", "param_type": "str, default ‘\\t’ (tab-stop)", "param_desc": "Character or regex pattern to treat as the delimiter. If sep=None, the\nC engine cannot automatically detect\nthe separator, but the Python parsing engine can, meaning the latter will\nbe used and automatically detect the separator from only the first valid\nrow of the file by Python’s builtin sniffer tool, csv.Sniffer.\nIn addition, separators longer than 1 character and different from\n'\\s+' will be interpreted as regular expressions and will also force\nthe use of the Python parsing engine. Note that regex delimiters are prone\nto ignoring quoted data. Regex example: '\\r\\t'.\n"}, {"param_name": "delimiter", "param_type": "str, optional", "param_desc": "Alias for sep.\n"}, {"param_name": "header", "param_type": "int, Sequence of int, ‘infer’ or None, default ‘infer’", "param_desc": "Row number(s) containing column labels and marking the start of the\ndata (zero-indexed). Default behavior is to infer the column names: if no names\nare passed the behavior is identical to header=0 and column\nnames are inferred from the first line of the file, if column\nnames are passed explicitly to names then the behavior is identical to\nheader=None. Explicitly pass header=0 to be able to\nreplace existing names. The header can be a list of integers that\nspecify row locations for a MultiIndex on the columns\ne.g. [0, 1, 3]. Intervening rows that are not specified will be\nskipped (e.g. 2 in this example is skipped). Note that this\nparameter ignores commented lines and empty lines if\nskip_blank_lines=True, so header=0 denotes the first line of\ndata rather than the first line of the file.\n"}, {"param_name": "names", "param_type": "Sequence of Hashable, optional", "param_desc": "Sequence of column labels to apply. If the file contains a header row,\nthen you should explicitly pass header=0 to override the column names.\nDuplicates in this list are not allowed.\n"}, {"param_name": "index_col", "param_type": "Hashable, Sequence of Hashable or False, optional", "param_desc": "Column(s) to use as row label(s), denoted either by column labels or column\nindices. If a sequence of labels or indices is given, MultiIndex\nwill be formed for the row labels.\nNote: index_col=False can be used to force pandas to not use the first\ncolumn as the index, e.g., when you have a malformed file with delimiters at\nthe end of each line.\n"}, {"param_name": "usecols", "param_type": "Sequence of Hashable or Callable, optional", "param_desc": "Subset of columns to select, denoted either by column labels or column indices.\nIf list-like, all elements must either\nbe positional (i.e. integer indices into the document columns) or strings\nthat correspond to column names provided either by the user in names or\ninferred from the document header row(s). If names are given, the document\nheader row(s) are not taken into account. For example, a valid list-like\nusecols parameter would be [0, 1, 2] or ['foo', 'bar', 'baz'].\nElement order is ignored, so usecols=[0, 1] is the same as [1, 0].\nTo instantiate a DataFrame from data with element order\npreserved use pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]\nfor columns in ['foo', 'bar'] order or\npd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]\nfor ['bar', 'foo'] order.\nIf callable, the callable function will be evaluated against the column\nnames, returning names where the callable function evaluates to True. An\nexample of a valid callable argument would be lambda x: x.upper() in\n['AAA', 'BBB', 'DDD']. Using this parameter results in much faster\nparsing time and lower memory usage.\n"}, {"param_name": "dtype", "param_type": "dtype or dict of {Hashable", "param_desc": "Data type(s) to apply to either the whole dataset or individual columns.\nE.g., {'a': np.float64, 'b': np.int32, 'c': 'Int64'}\nUse str or object together with suitable na_values settings\nto preserve and not interpret dtype.\nIf converters are specified, they will be applied INSTEAD\nof dtype conversion.\n\nNew in version 1.5.0: Support for defaultdict was added. Specify a defaultdict as input where\nthe default determines the dtype of the columns which are not explicitly\nlisted.\n\n"}, {"param_name": "engine", "param_type": "{‘c’, ‘python’, ‘pyarrow’}, optional", "param_desc": "Parser engine to use. The C and pyarrow engines are faster, while the python engine\nis currently more feature-complete. Multithreading is currently only supported by\nthe pyarrow engine.\n\nNew in version 1.4.0: The ‘pyarrow’ engine was added as an experimental engine, and some features\nare unsupported, or may not work correctly, with this engine.\n\n"}, {"param_name": "converters", "param_type": "dict of {Hashable", "param_desc": "Functions for converting values in specified columns. Keys can either\nbe column labels or column indices.\n"}, {"param_name": "true_values", "param_type": "list, optional", "param_desc": "Values to consider as True in addition to case-insensitive variants of ‘True’.\n"}, {"param_name": "false_values", "param_type": "list, optional", "param_desc": "Values to consider as False in addition to case-insensitive variants of ‘False’.\n"}, {"param_name": "skipinitialspace", "param_type": "bool, default False", "param_desc": "Skip spaces after delimiter.\n"}, {"param_name": "skiprows", "param_type": "int, list of int or Callable, optional", "param_desc": "Line numbers to skip (0-indexed) or number of lines to skip (int)\nat the start of the file.\nIf callable, the callable function will be evaluated against the row\nindices, returning True if the row should be skipped and False otherwise.\nAn example of a valid callable argument would be lambda x: x in [0, 2].\n"}, {"param_name": "skipfooter", "param_type": "int, default 0", "param_desc": "Number of lines at bottom of file to skip (Unsupported with engine='c').\n"}, {"param_name": "nrows", "param_type": "int, optional", "param_desc": "Number of rows of file to read. Useful for reading pieces of large files.\n"}, {"param_name": "na_values", "param_type": "Hashable, Iterable of Hashable or dict of {Hashable", "param_desc": "Additional strings to recognize as NA/NaN. If dict passed, specific\nper-column NA values. By default the following values are interpreted as\nNaN: “ “, “#N/A”, “#N/A N/A”, “#NA”, “-1.#IND”, “-1.#QNAN”, “-NaN”, “-nan”,\n“1.#IND”, “1.#QNAN”, “<NA>”, “N/A”, “NA”, “NULL”, “NaN”, “None”,\n“n/a”, “nan”, “null “.\n"}, {"param_name": "keep_default_na", "param_type": "bool, default True", "param_desc": "Whether or not to include the default NaN values when parsing the data.\nDepending on whether na_values is passed in, the behavior is as follows:\n\nIf keep_default_na is True, and na_values are specified, na_values\nis appended to the default NaN values used for parsing.\nIf keep_default_na is True, and na_values are not specified, only\nthe default NaN values are used for parsing.\nIf keep_default_na is False, and na_values are specified, only\nthe NaN values specified na_values are used for parsing.\nIf keep_default_na is False, and na_values are not specified, no\nstrings will be parsed as NaN.\n\nNote that if na_filter is passed in as False, the keep_default_na and\nna_values parameters will be ignored.\n"}, {"param_name": "na_filter", "param_type": "bool, default True", "param_desc": "Detect missing value markers (empty strings and the value of na_values). In\ndata without any NA values, passing na_filter=False can improve the\nperformance of reading a large file.\n"}, {"param_name": "verbose", "param_type": "bool, default False", "param_desc": "Indicate number of NA values placed in non-numeric columns.\n\nDeprecated since version 2.2.0.\n\n"}, {"param_name": "skip_blank_lines", "param_type": "bool, default True", "param_desc": "If True, skip over blank lines rather than interpreting as NaN values.\n"}, {"param_name": "parse_dates", "param_type": "bool, list of Hashable, list of lists or dict of {Hashable", "param_desc": "The behavior is as follows:\n\nbool. If True -> try parsing the index. Note: Automatically set to\nTrue if date_format or date_parser arguments have been passed.\nlist of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\neach as a separate date column.\nlist of list. e.g. If [[1, 3]] -> combine columns 1 and 3 and parse\nas a single date column. Values are joined with a space before parsing.\ndict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call\nresult ‘foo’. Values are joined with a space before parsing.\n\nIf a column or index cannot be represented as an array of datetime,\nsay because of an unparsable value or a mixture of timezones, the column\nor index will be returned unaltered as an object data type. For\nnon-standard datetime parsing, use to_datetime() after\nread_csv().\nNote: A fast-path exists for iso8601-formatted dates.\n"}, {"param_name": "infer_datetime_format", "param_type": "bool, default False", "param_desc": "If True and parse_dates is enabled, pandas will attempt to infer the\nformat of the datetime strings in the columns, and if it can be inferred,\nswitch to a faster method of parsing them. In some cases this can increase\nthe parsing speed by 5-10x.\n\nDeprecated since version 2.0.0: A strict version of this argument is now the default, passing it has no effect.\n\n"}, {"param_name": "keep_date_col", "param_type": "bool, default False", "param_desc": "If True and parse_dates specifies combining multiple columns then\nkeep the original columns.\n"}, {"param_name": "date_parser", "param_type": "Callable, optional", "param_desc": "Function to use for converting a sequence of string columns to an array of\ndatetime instances. The default uses dateutil.parser.parser to do the\nconversion. pandas will try to call date_parser in three different ways,\nadvancing to the next if an exception occurs: 1) Pass one or more arrays\n(as defined by parse_dates) as arguments; 2) concatenate (row-wise) the\nstring values from the columns defined by parse_dates into a single array\nand pass that; and 3) call date_parser once for each row using one or\nmore strings (corresponding to the columns defined by parse_dates) as\narguments.\n\nDeprecated since version 2.0.0: Use date_format instead, or read in as object and then apply\nto_datetime() as-needed.\n\n"}, {"param_name": "date_format", "param_type": "str or dict of column -> format, optional", "param_desc": "Format to use for parsing dates when used in conjunction with parse_dates.\nThe strftime to parse time, e.g. \"%d/%m/%Y\". See\nstrftime documentation for more information on choices, though\nnote that \"%f\" will parse all the way up to nanoseconds.\nYou can also pass:\n\n\n“ISO8601”, to parse any ISO8601time string (not necessarily in exactly the same format);\n\n\n\n\n“mixed”, to infer the format for each element individually. This is risky,and you should probably use it along with dayfirst.\n\n\n\n\n\nNew in version 2.0.0.\n\n"}, {"param_name": "dayfirst", "param_type": "bool, default False", "param_desc": "DD/MM format dates, international and European format.\n"}, {"param_name": "cache_dates", "param_type": "bool, default True", "param_desc": "If True, use a cache of unique, converted dates to apply the datetime\nconversion. May produce significant speed-up when parsing duplicate\ndate strings, especially ones with timezone offsets.\n"}, {"param_name": "iterator", "param_type": "bool, default False", "param_desc": "Return TextFileReader object for iteration or getting chunks with\nget_chunk().\n"}, {"param_name": "chunksize", "param_type": "int, optional", "param_desc": "Number of lines to read from the file per chunk. Passing a value will cause the\nfunction to return a TextFileReader object for iteration.\nSee the IO Tools docs\nfor more information on iterator and chunksize.\n"}, {"param_name": "compression", "param_type": "str or dict, default ‘infer’", "param_desc": "For on-the-fly decompression of on-disk data. If ‘infer’ and ‘filepath_or_buffer’ is\npath-like, then detect compression from the following extensions: ‘.gz’,\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\n(otherwise no compression).\nIf using ‘zip’ or ‘tar’, the ZIP file must contain only one data file to be read in.\nSet to None for no decompression.\nCan also be a dict with key 'method' set\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\nother key-value pairs are forwarded to\nzipfile.ZipFile, gzip.GzipFile,\nbz2.BZ2File, zstandard.ZstdDecompressor, lzma.LZMAFile or\ntarfile.TarFile, respectively.\nAs an example, the following could be passed for Zstandard decompression using a\ncustom compression dictionary:\ncompression={'method': 'zstd', 'dict_data': my_compression_dict}.\n\nNew in version 1.5.0: Added support for .tar files.\n\n\nChanged in version 1.4.0: Zstandard support.\n\n"}, {"param_name": "thousands", "param_type": "str (length 1), optional", "param_desc": "Character acting as the thousands separator in numerical values.\n"}, {"param_name": "decimal", "param_type": "str (length 1), default ‘.’", "param_desc": "Character to recognize as decimal point (e.g., use ‘,’ for European data).\n"}, {"param_name": "lineterminator", "param_type": "str (length 1), optional", "param_desc": "Character used to denote a line break. Only valid with C parser.\n"}, {"param_name": "quotechar", "param_type": "str (length 1), optional", "param_desc": "Character used to denote the start and end of a quoted item. Quoted\nitems can include the delimiter and it will be ignored.\n"}, {"param_name": "quoting", "param_type": "{0 or csv.QUOTE_MINIMAL, 1 or csv.QUOTE_ALL, 2 or csv.QUOTE_NONNUMERIC, 3 or csv.QUOTE_NONE}, default csv.QUOTE_MINIMAL", "param_desc": "Control field quoting behavior per csv.QUOTE_* constants. Default is\ncsv.QUOTE_MINIMAL (i.e., 0) which implies that only fields containing special\ncharacters are quoted (e.g., characters defined in quotechar, delimiter,\nor lineterminator.\n"}, {"param_name": "doublequote", "param_type": "bool, default True", "param_desc": "When quotechar is specified and quoting is not QUOTE_NONE, indicate\nwhether or not to interpret two consecutive quotechar elements INSIDE a\nfield as a single quotechar element.\n"}, {"param_name": "escapechar", "param_type": "str (length 1), optional", "param_desc": "Character used to escape other characters.\n"}, {"param_name": "comment", "param_type": "str (length 1), optional", "param_desc": "Character indicating that the remainder of line should not be parsed.\nIf found at the beginning\nof a line, the line will be ignored altogether. This parameter must be a\nsingle character. Like empty lines (as long as skip_blank_lines=True),\nfully commented lines are ignored by the parameter header but not by\nskiprows. For example, if comment='#', parsing\n#empty\\na,b,c\\n1,2,3 with header=0 will result in 'a,b,c' being\ntreated as the header.\n"}, {"param_name": "encoding", "param_type": "str, optional, default ‘utf-8’", "param_desc": "Encoding to use for UTF when reading/writing (ex. 'utf-8'). List of Python\nstandard encodings .\n"}, {"param_name": "encoding_errors", "param_type": "str, optional, default ‘strict’", "param_desc": "How encoding errors are treated. List of possible values .\n\nNew in version 1.3.0.\n\n"}, {"param_name": "dialect", "param_type": "str or csv.Dialect, optional", "param_desc": "If provided, this parameter will override values (default or not) for the\nfollowing parameters: delimiter, doublequote, escapechar,\nskipinitialspace, quotechar, and quoting. If it is necessary to\noverride values, a ParserWarning will be issued. See csv.Dialect\ndocumentation for more details.\n"}, {"param_name": "on_bad_lines", "param_type": "{‘error’, ‘warn’, ‘skip’} or Callable, default ‘error’", "param_desc": "Specifies what to do upon encountering a bad line (a line with too many fields).\nAllowed values are :\n\n'error', raise an Exception when a bad line is encountered.\n'warn', raise a warning when a bad line is encountered and skip that line.\n'skip', skip bad lines without raising or warning when they are encountered.\n\n\nNew in version 1.3.0.\n\n\nNew in version 1.4.0: \n\nCallable, function with signature\n(bad_line: list[str]) -> list[str] | None that will process a single\nbad line. bad_line is a list of strings split by the sep.\nIf the function returns None, the bad line will be ignored.\nIf the function returns a new list of strings with more elements than\nexpected, a ParserWarning will be emitted while dropping extra elements.\nOnly supported when engine='python'\n\n\n\nChanged in version 2.2.0: \n\nCallable, function with signature\nas described in pyarrow documentation when engine='pyarrow'\n\n\n"}, {"param_name": "delim_whitespace", "param_type": "bool, default False", "param_desc": "Specifies whether or not whitespace (e.g. ' ' or '\\t') will be\nused as the sep delimiter. Equivalent to setting sep='\\s+'. If this option\nis set to True, nothing should be passed in for the delimiter\nparameter.\n\nDeprecated since version 2.2.0: Use sep=\"\\s+\" instead.\n\n"}, {"param_name": "low_memory", "param_type": "bool, default True", "param_desc": "Internally process the file in chunks, resulting in lower memory use\nwhile parsing, but possibly mixed type inference. To ensure no mixed\ntypes either set False, or specify the type with the dtype parameter.\nNote that the entire file is read into a single DataFrame\nregardless, use the chunksize or iterator parameter to return the data in\nchunks. (Only valid with C parser).\n"}, {"param_name": "memory_map", "param_type": "bool, default False", "param_desc": "If a filepath is provided for filepath_or_buffer, map the file object\ndirectly onto memory and access the data directly from there. Using this\noption can improve performance because there is no longer any I/O overhead.\n"}, {"param_name": "float_precision", "param_type": "{‘high’, ‘legacy’, ‘round_trip’}, optional", "param_desc": "Specifies which converter the C engine should use for floating-point\nvalues. The options are None or 'high' for the ordinary converter,\n'legacy' for the original lower precision pandas converter, and\n'round_trip' for the round-trip converter.\n"}, {"param_name": "storage_options", "param_type": "dict, optional", "param_desc": "Extra options that make sense for a particular storage connection, e.g.\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\nare forwarded to urllib.request.Request as header options. For other\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\nforwarded to fsspec.open. Please see fsspec and urllib for more\ndetails, and for more examples on storage options refer here.\n"}, {"param_name": "dtype_backend", "param_type": "{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’", "param_desc": "Back-end data type applied to the resultant DataFrame\n(still experimental). Behaviour is as follows:\n\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\n(default).\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\nDataFrame.\n\n\nNew in version 2.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.read_table.html#pandas.read_table"}, {"function_name": "pandas.DataFrame.to_csv", "full_function": "DataFrame.to_csv(path_or_buf=None, *, sep=',', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, mode='w', encoding=None, compression='infer', quoting=None, quotechar='\"', lineterminator=None, chunksize=None, date_format=None, doublequote=True, escapechar=None, decimal='.', errors='strict', storage_options=None)", "function_text": "Write object to a comma-separated values (csv) file.", "parameter_names_desc": [{"param_name": "path_or_buf", "param_type": "str, path object, file-like object, or None, default None", "param_desc": "String, path object (implementing os.PathLike[str]), or file-like\nobject implementing a write() function. If None, the result is\nreturned as a string. If a non-binary file object is passed, it should\nbe opened with newline=’’, disabling universal newlines. If a binary\nfile object is passed, mode might need to contain a ‘b’.\n"}, {"param_name": "sep", "param_type": "str, default ‘,’", "param_desc": "String of length 1. Field delimiter for the output file.\n"}, {"param_name": "na_rep", "param_type": "str, default ‘’", "param_desc": "Missing data representation.\n"}, {"param_name": "float_format", "param_type": "str, Callable, default None", "param_desc": "Format string for floating point numbers. If a Callable is given, it takes\nprecedence over other numeric formatting parameters, like decimal.\n"}, {"param_name": "columns", "param_type": "sequence, optional", "param_desc": "Columns to write.\n"}, {"param_name": "header", "param_type": "bool or list of str, default True", "param_desc": "Write out the column names. If a list of strings is given it is\nassumed to be aliases for the column names.\n"}, {"param_name": "index", "param_type": "bool, default True", "param_desc": "Write row names (index).\n"}, {"param_name": "index_label", "param_type": "str or sequence, or False, default None", "param_desc": "Column label for index column(s) if desired. If None is given, and\nheader and index are True, then the index names are used. A\nsequence should be given if the object uses MultiIndex. If\nFalse do not print fields for index names. Use index_label=False\nfor easier importing in R.\n"}, {"param_name": "mode", "param_type": "{‘w’, ‘x’, ‘a’}, default ‘w’", "param_desc": "Forwarded to either open(mode=) or fsspec.open(mode=) to control\nthe file opening. Typical values include:\n\n‘w’, truncate the file first.\n‘x’, exclusive creation, failing if the file already exists.\n‘a’, append to the end of file if it exists.\n\n"}, {"param_name": "encoding", "param_type": "str, optional", "param_desc": "A string representing the encoding to use in the output file,\ndefaults to ‘utf-8’. encoding is not supported if path_or_buf\nis a non-binary file object.\n"}, {"param_name": "compression", "param_type": "str or dict, default ‘infer’", "param_desc": "For on-the-fly compression of the output data. If ‘infer’ and ‘path_or_buf’ is\npath-like, then detect compression from the following extensions: ‘.gz’,\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\n(otherwise no compression).\nSet to None for no compression.\nCan also be a dict with key 'method' set\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\nother key-value pairs are forwarded to\nzipfile.ZipFile, gzip.GzipFile,\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\ntarfile.TarFile, respectively.\nAs an example, the following could be passed for faster compression and to create\na reproducible gzip archive:\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\n\nNew in version 1.5.0: Added support for .tar files.\nMay be a dict with key ‘method’ as compression mode\nand other entries as additional compression options if\ncompression mode is ‘zip’.\nPassing compression options as keys in dict is\nsupported for compression modes ‘gzip’, ‘bz2’, ‘zstd’, and ‘zip’.\n\n"}, {"param_name": "quoting", "param_type": "optional constant from csv module", "param_desc": "Defaults to csv.QUOTE_MINIMAL. If you have set a float_format\nthen floats are converted to strings and thus csv.QUOTE_NONNUMERIC\nwill treat them as non-numeric.\n"}, {"param_name": "quotechar", "param_type": "str, default ‘\"’", "param_desc": "String of length 1. Character used to quote fields.\n"}, {"param_name": "lineterminator", "param_type": "str, optional", "param_desc": "The newline character or character sequence to use in the output\nfile. Defaults to os.linesep, which depends on the OS in which\nthis method is called (’\\n’ for linux, ‘\\r\\n’ for Windows, i.e.).\n\nChanged in version 1.5.0: Previously was line_terminator, changed for consistency with\nread_csv and the standard library ‘csv’ module.\n\n"}, {"param_name": "chunksize", "param_type": "int or None", "param_desc": "Rows to write at a time.\n"}, {"param_name": "date_format", "param_type": "str, default None", "param_desc": "Format string for datetime objects.\n"}, {"param_name": "doublequote", "param_type": "bool, default True", "param_desc": "Control quoting of quotechar inside a field.\n"}, {"param_name": "escapechar", "param_type": "str, default None", "param_desc": "String of length 1. Character used to escape sep and quotechar\nwhen appropriate.\n"}, {"param_name": "decimal", "param_type": "str, default ‘.’", "param_desc": "Character recognized as decimal separator. E.g. use ‘,’ for\nEuropean data.\n"}, {"param_name": "errors", "param_type": "str, default ‘strict’", "param_desc": "Specifies how encoding and decoding errors are to be handled.\nSee the errors argument for open() for a full list\nof options.\n"}, {"param_name": "storage_options", "param_type": "dict, optional", "param_desc": "Extra options that make sense for a particular storage connection, e.g.\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\nare forwarded to urllib.request.Request as header options. For other\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\nforwarded to fsspec.open. Please see fsspec and urllib for more\ndetails, and for more examples on storage options refer here.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html#pandas.DataFrame.to_csv"}, {"function_name": "pandas.read_csv", "full_function": "pandas.read_csv(filepath_or_buffer, *, sep=_NoDefault.no_default, delimiter=None, header='infer', names=_NoDefault.no_default, index_col=None, usecols=None, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skipinitialspace=False, skiprows=None, skipfooter=0, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=_NoDefault.no_default, skip_blank_lines=True, parse_dates=None, infer_datetime_format=_NoDefault.no_default, keep_date_col=_NoDefault.no_default, date_parser=_NoDefault.no_default, date_format=None, dayfirst=False, cache_dates=True, iterator=False, chunksize=None, compression='infer', thousands=None, decimal='.', lineterminator=None, quotechar='\"', quoting=0, doublequote=True, escapechar=None, comment=None, encoding=None, encoding_errors='strict', dialect=None, on_bad_lines='error', delim_whitespace=_NoDefault.no_default, low_memory=True, memory_map=False, float_precision=None, storage_options=None, dtype_backend=_NoDefault.no_default)", "function_text": "Read a comma-separated values (csv) file into DataFrame.", "parameter_names_desc": [{"param_name": "filepath_or_buffer", "param_type": "str, path object or file-like object", "param_desc": "Any valid string path is acceptable. The string could be a URL. Valid\nURL schemes include http, ftp, s3, gs, and file. For file URLs, a host is\nexpected. A local file could be: file://localhost/path/to/table.csv.\nIf you want to pass in a path object, pandas accepts any os.PathLike.\nBy file-like object, we refer to objects with a read() method, such as\na file handle (e.g. via builtin open function) or StringIO.\n"}, {"param_name": "sep", "param_type": "str, default ‘,’", "param_desc": "Character or regex pattern to treat as the delimiter. If sep=None, the\nC engine cannot automatically detect\nthe separator, but the Python parsing engine can, meaning the latter will\nbe used and automatically detect the separator from only the first valid\nrow of the file by Python’s builtin sniffer tool, csv.Sniffer.\nIn addition, separators longer than 1 character and different from\n'\\s+' will be interpreted as regular expressions and will also force\nthe use of the Python parsing engine. Note that regex delimiters are prone\nto ignoring quoted data. Regex example: '\\r\\t'.\n"}, {"param_name": "delimiter", "param_type": "str, optional", "param_desc": "Alias for sep.\n"}, {"param_name": "header", "param_type": "int, Sequence of int, ‘infer’ or None, default ‘infer’", "param_desc": "Row number(s) containing column labels and marking the start of the\ndata (zero-indexed). Default behavior is to infer the column names: if no names\nare passed the behavior is identical to header=0 and column\nnames are inferred from the first line of the file, if column\nnames are passed explicitly to names then the behavior is identical to\nheader=None. Explicitly pass header=0 to be able to\nreplace existing names. The header can be a list of integers that\nspecify row locations for a MultiIndex on the columns\ne.g. [0, 1, 3]. Intervening rows that are not specified will be\nskipped (e.g. 2 in this example is skipped). Note that this\nparameter ignores commented lines and empty lines if\nskip_blank_lines=True, so header=0 denotes the first line of\ndata rather than the first line of the file.\n"}, {"param_name": "names", "param_type": "Sequence of Hashable, optional", "param_desc": "Sequence of column labels to apply. If the file contains a header row,\nthen you should explicitly pass header=0 to override the column names.\nDuplicates in this list are not allowed.\n"}, {"param_name": "index_col", "param_type": "Hashable, Sequence of Hashable or False, optional", "param_desc": "Column(s) to use as row label(s), denoted either by column labels or column\nindices. If a sequence of labels or indices is given, MultiIndex\nwill be formed for the row labels.\nNote: index_col=False can be used to force pandas to not use the first\ncolumn as the index, e.g., when you have a malformed file with delimiters at\nthe end of each line.\n"}, {"param_name": "usecols", "param_type": "Sequence of Hashable or Callable, optional", "param_desc": "Subset of columns to select, denoted either by column labels or column indices.\nIf list-like, all elements must either\nbe positional (i.e. integer indices into the document columns) or strings\nthat correspond to column names provided either by the user in names or\ninferred from the document header row(s). If names are given, the document\nheader row(s) are not taken into account. For example, a valid list-like\nusecols parameter would be [0, 1, 2] or ['foo', 'bar', 'baz'].\nElement order is ignored, so usecols=[0, 1] is the same as [1, 0].\nTo instantiate a DataFrame from data with element order\npreserved use pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]\nfor columns in ['foo', 'bar'] order or\npd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]\nfor ['bar', 'foo'] order.\nIf callable, the callable function will be evaluated against the column\nnames, returning names where the callable function evaluates to True. An\nexample of a valid callable argument would be lambda x: x.upper() in\n['AAA', 'BBB', 'DDD']. Using this parameter results in much faster\nparsing time and lower memory usage.\n"}, {"param_name": "dtype", "param_type": "dtype or dict of {Hashable", "param_desc": "Data type(s) to apply to either the whole dataset or individual columns.\nE.g., {'a': np.float64, 'b': np.int32, 'c': 'Int64'}\nUse str or object together with suitable na_values settings\nto preserve and not interpret dtype.\nIf converters are specified, they will be applied INSTEAD\nof dtype conversion.\n\nNew in version 1.5.0: Support for defaultdict was added. Specify a defaultdict as input where\nthe default determines the dtype of the columns which are not explicitly\nlisted.\n\n"}, {"param_name": "engine", "param_type": "{‘c’, ‘python’, ‘pyarrow’}, optional", "param_desc": "Parser engine to use. The C and pyarrow engines are faster, while the python engine\nis currently more feature-complete. Multithreading is currently only supported by\nthe pyarrow engine.\n\nNew in version 1.4.0: The ‘pyarrow’ engine was added as an experimental engine, and some features\nare unsupported, or may not work correctly, with this engine.\n\n"}, {"param_name": "converters", "param_type": "dict of {Hashable", "param_desc": "Functions for converting values in specified columns. Keys can either\nbe column labels or column indices.\n"}, {"param_name": "true_values", "param_type": "list, optional", "param_desc": "Values to consider as True in addition to case-insensitive variants of ‘True’.\n"}, {"param_name": "false_values", "param_type": "list, optional", "param_desc": "Values to consider as False in addition to case-insensitive variants of ‘False’.\n"}, {"param_name": "skipinitialspace", "param_type": "bool, default False", "param_desc": "Skip spaces after delimiter.\n"}, {"param_name": "skiprows", "param_type": "int, list of int or Callable, optional", "param_desc": "Line numbers to skip (0-indexed) or number of lines to skip (int)\nat the start of the file.\nIf callable, the callable function will be evaluated against the row\nindices, returning True if the row should be skipped and False otherwise.\nAn example of a valid callable argument would be lambda x: x in [0, 2].\n"}, {"param_name": "skipfooter", "param_type": "int, default 0", "param_desc": "Number of lines at bottom of file to skip (Unsupported with engine='c').\n"}, {"param_name": "nrows", "param_type": "int, optional", "param_desc": "Number of rows of file to read. Useful for reading pieces of large files.\n"}, {"param_name": "na_values", "param_type": "Hashable, Iterable of Hashable or dict of {Hashable", "param_desc": "Additional strings to recognize as NA/NaN. If dict passed, specific\nper-column NA values. By default the following values are interpreted as\nNaN: “ “, “#N/A”, “#N/A N/A”, “#NA”, “-1.#IND”, “-1.#QNAN”, “-NaN”, “-nan”,\n“1.#IND”, “1.#QNAN”, “<NA>”, “N/A”, “NA”, “NULL”, “NaN”, “None”,\n“n/a”, “nan”, “null “.\n"}, {"param_name": "keep_default_na", "param_type": "bool, default True", "param_desc": "Whether or not to include the default NaN values when parsing the data.\nDepending on whether na_values is passed in, the behavior is as follows:\n\nIf keep_default_na is True, and na_values are specified, na_values\nis appended to the default NaN values used for parsing.\nIf keep_default_na is True, and na_values are not specified, only\nthe default NaN values are used for parsing.\nIf keep_default_na is False, and na_values are specified, only\nthe NaN values specified na_values are used for parsing.\nIf keep_default_na is False, and na_values are not specified, no\nstrings will be parsed as NaN.\n\nNote that if na_filter is passed in as False, the keep_default_na and\nna_values parameters will be ignored.\n"}, {"param_name": "na_filter", "param_type": "bool, default True", "param_desc": "Detect missing value markers (empty strings and the value of na_values). In\ndata without any NA values, passing na_filter=False can improve the\nperformance of reading a large file.\n"}, {"param_name": "verbose", "param_type": "bool, default False", "param_desc": "Indicate number of NA values placed in non-numeric columns.\n\nDeprecated since version 2.2.0.\n\n"}, {"param_name": "skip_blank_lines", "param_type": "bool, default True", "param_desc": "If True, skip over blank lines rather than interpreting as NaN values.\n"}, {"param_name": "parse_dates", "param_type": "bool, list of Hashable, list of lists or dict of {Hashable", "param_desc": "The behavior is as follows:\n\nbool. If True -> try parsing the index. Note: Automatically set to\nTrue if date_format or date_parser arguments have been passed.\nlist of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\neach as a separate date column.\nlist of list. e.g. If [[1, 3]] -> combine columns 1 and 3 and parse\nas a single date column. Values are joined with a space before parsing.\ndict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call\nresult ‘foo’. Values are joined with a space before parsing.\n\nIf a column or index cannot be represented as an array of datetime,\nsay because of an unparsable value or a mixture of timezones, the column\nor index will be returned unaltered as an object data type. For\nnon-standard datetime parsing, use to_datetime() after\nread_csv().\nNote: A fast-path exists for iso8601-formatted dates.\n"}, {"param_name": "infer_datetime_format", "param_type": "bool, default False", "param_desc": "If True and parse_dates is enabled, pandas will attempt to infer the\nformat of the datetime strings in the columns, and if it can be inferred,\nswitch to a faster method of parsing them. In some cases this can increase\nthe parsing speed by 5-10x.\n\nDeprecated since version 2.0.0: A strict version of this argument is now the default, passing it has no effect.\n\n"}, {"param_name": "keep_date_col", "param_type": "bool, default False", "param_desc": "If True and parse_dates specifies combining multiple columns then\nkeep the original columns.\n"}, {"param_name": "date_parser", "param_type": "Callable, optional", "param_desc": "Function to use for converting a sequence of string columns to an array of\ndatetime instances. The default uses dateutil.parser.parser to do the\nconversion. pandas will try to call date_parser in three different ways,\nadvancing to the next if an exception occurs: 1) Pass one or more arrays\n(as defined by parse_dates) as arguments; 2) concatenate (row-wise) the\nstring values from the columns defined by parse_dates into a single array\nand pass that; and 3) call date_parser once for each row using one or\nmore strings (corresponding to the columns defined by parse_dates) as\narguments.\n\nDeprecated since version 2.0.0: Use date_format instead, or read in as object and then apply\nto_datetime() as-needed.\n\n"}, {"param_name": "date_format", "param_type": "str or dict of column -> format, optional", "param_desc": "Format to use for parsing dates when used in conjunction with parse_dates.\nThe strftime to parse time, e.g. \"%d/%m/%Y\". See\nstrftime documentation for more information on choices, though\nnote that \"%f\" will parse all the way up to nanoseconds.\nYou can also pass:\n\n\n“ISO8601”, to parse any ISO8601time string (not necessarily in exactly the same format);\n\n\n\n\n“mixed”, to infer the format for each element individually. This is risky,and you should probably use it along with dayfirst.\n\n\n\n\n\nNew in version 2.0.0.\n\n"}, {"param_name": "dayfirst", "param_type": "bool, default False", "param_desc": "DD/MM format dates, international and European format.\n"}, {"param_name": "cache_dates", "param_type": "bool, default True", "param_desc": "If True, use a cache of unique, converted dates to apply the datetime\nconversion. May produce significant speed-up when parsing duplicate\ndate strings, especially ones with timezone offsets.\n"}, {"param_name": "iterator", "param_type": "bool, default False", "param_desc": "Return TextFileReader object for iteration or getting chunks with\nget_chunk().\n"}, {"param_name": "chunksize", "param_type": "int, optional", "param_desc": "Number of lines to read from the file per chunk. Passing a value will cause the\nfunction to return a TextFileReader object for iteration.\nSee the IO Tools docs\nfor more information on iterator and chunksize.\n"}, {"param_name": "compression", "param_type": "str or dict, default ‘infer’", "param_desc": "For on-the-fly decompression of on-disk data. If ‘infer’ and ‘filepath_or_buffer’ is\npath-like, then detect compression from the following extensions: ‘.gz’,\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\n(otherwise no compression).\nIf using ‘zip’ or ‘tar’, the ZIP file must contain only one data file to be read in.\nSet to None for no decompression.\nCan also be a dict with key 'method' set\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\nother key-value pairs are forwarded to\nzipfile.ZipFile, gzip.GzipFile,\nbz2.BZ2File, zstandard.ZstdDecompressor, lzma.LZMAFile or\ntarfile.TarFile, respectively.\nAs an example, the following could be passed for Zstandard decompression using a\ncustom compression dictionary:\ncompression={'method': 'zstd', 'dict_data': my_compression_dict}.\n\nNew in version 1.5.0: Added support for .tar files.\n\n\nChanged in version 1.4.0: Zstandard support.\n\n"}, {"param_name": "thousands", "param_type": "str (length 1), optional", "param_desc": "Character acting as the thousands separator in numerical values.\n"}, {"param_name": "decimal", "param_type": "str (length 1), default ‘.’", "param_desc": "Character to recognize as decimal point (e.g., use ‘,’ for European data).\n"}, {"param_name": "lineterminator", "param_type": "str (length 1), optional", "param_desc": "Character used to denote a line break. Only valid with C parser.\n"}, {"param_name": "quotechar", "param_type": "str (length 1), optional", "param_desc": "Character used to denote the start and end of a quoted item. Quoted\nitems can include the delimiter and it will be ignored.\n"}, {"param_name": "quoting", "param_type": "{0 or csv.QUOTE_MINIMAL, 1 or csv.QUOTE_ALL, 2 or csv.QUOTE_NONNUMERIC, 3 or csv.QUOTE_NONE}, default csv.QUOTE_MINIMAL", "param_desc": "Control field quoting behavior per csv.QUOTE_* constants. Default is\ncsv.QUOTE_MINIMAL (i.e., 0) which implies that only fields containing special\ncharacters are quoted (e.g., characters defined in quotechar, delimiter,\nor lineterminator.\n"}, {"param_name": "doublequote", "param_type": "bool, default True", "param_desc": "When quotechar is specified and quoting is not QUOTE_NONE, indicate\nwhether or not to interpret two consecutive quotechar elements INSIDE a\nfield as a single quotechar element.\n"}, {"param_name": "escapechar", "param_type": "str (length 1), optional", "param_desc": "Character used to escape other characters.\n"}, {"param_name": "comment", "param_type": "str (length 1), optional", "param_desc": "Character indicating that the remainder of line should not be parsed.\nIf found at the beginning\nof a line, the line will be ignored altogether. This parameter must be a\nsingle character. Like empty lines (as long as skip_blank_lines=True),\nfully commented lines are ignored by the parameter header but not by\nskiprows. For example, if comment='#', parsing\n#empty\\na,b,c\\n1,2,3 with header=0 will result in 'a,b,c' being\ntreated as the header.\n"}, {"param_name": "encoding", "param_type": "str, optional, default ‘utf-8’", "param_desc": "Encoding to use for UTF when reading/writing (ex. 'utf-8'). List of Python\nstandard encodings .\n"}, {"param_name": "encoding_errors", "param_type": "str, optional, default ‘strict’", "param_desc": "How encoding errors are treated. List of possible values .\n\nNew in version 1.3.0.\n\n"}, {"param_name": "dialect", "param_type": "str or csv.Dialect, optional", "param_desc": "If provided, this parameter will override values (default or not) for the\nfollowing parameters: delimiter, doublequote, escapechar,\nskipinitialspace, quotechar, and quoting. If it is necessary to\noverride values, a ParserWarning will be issued. See csv.Dialect\ndocumentation for more details.\n"}, {"param_name": "on_bad_lines", "param_type": "{‘error’, ‘warn’, ‘skip’} or Callable, default ‘error’", "param_desc": "Specifies what to do upon encountering a bad line (a line with too many fields).\nAllowed values are :\n\n'error', raise an Exception when a bad line is encountered.\n'warn', raise a warning when a bad line is encountered and skip that line.\n'skip', skip bad lines without raising or warning when they are encountered.\n\n\nNew in version 1.3.0.\n\n\nNew in version 1.4.0: \n\nCallable, function with signature\n(bad_line: list[str]) -> list[str] | None that will process a single\nbad line. bad_line is a list of strings split by the sep.\nIf the function returns None, the bad line will be ignored.\nIf the function returns a new list of strings with more elements than\nexpected, a ParserWarning will be emitted while dropping extra elements.\nOnly supported when engine='python'\n\n\n\nChanged in version 2.2.0: \n\nCallable, function with signature\nas described in pyarrow documentation when engine='pyarrow'\n\n\n"}, {"param_name": "delim_whitespace", "param_type": "bool, default False", "param_desc": "Specifies whether or not whitespace (e.g. ' ' or '\\t') will be\nused as the sep delimiter. Equivalent to setting sep='\\s+'. If this option\nis set to True, nothing should be passed in for the delimiter\nparameter.\n\nDeprecated since version 2.2.0: Use sep=\"\\s+\" instead.\n\n"}, {"param_name": "low_memory", "param_type": "bool, default True", "param_desc": "Internally process the file in chunks, resulting in lower memory use\nwhile parsing, but possibly mixed type inference. To ensure no mixed\ntypes either set False, or specify the type with the dtype parameter.\nNote that the entire file is read into a single DataFrame\nregardless, use the chunksize or iterator parameter to return the data in\nchunks. (Only valid with C parser).\n"}, {"param_name": "memory_map", "param_type": "bool, default False", "param_desc": "If a filepath is provided for filepath_or_buffer, map the file object\ndirectly onto memory and access the data directly from there. Using this\noption can improve performance because there is no longer any I/O overhead.\n"}, {"param_name": "float_precision", "param_type": "{‘high’, ‘legacy’, ‘round_trip’}, optional", "param_desc": "Specifies which converter the C engine should use for floating-point\nvalues. The options are None or 'high' for the ordinary converter,\n'legacy' for the original lower precision pandas converter, and\n'round_trip' for the round-trip converter.\n"}, {"param_name": "storage_options", "param_type": "dict, optional", "param_desc": "Extra options that make sense for a particular storage connection, e.g.\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\nare forwarded to urllib.request.Request as header options. For other\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\nforwarded to fsspec.open. Please see fsspec and urllib for more\ndetails, and for more examples on storage options refer here.\n"}, {"param_name": "dtype_backend", "param_type": "{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’", "param_desc": "Back-end data type applied to the resultant DataFrame\n(still experimental). Behaviour is as follows:\n\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\n(default).\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\nDataFrame.\n\n\nNew in version 2.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html#pandas.read_csv"}, {"function_name": "pandas.read_fwf", "full_function": "pandas.read_fwf(filepath_or_buffer, *, colspecs='infer', widths=None, infer_nrows=100, dtype_backend=_NoDefault.no_default, iterator=False, chunksize=None, **kwds)", "function_text": "Read a table of fixed-width formatted lines into DataFrame.", "parameter_names_desc": [{"param_name": "filepath_or_buffer", "param_type": "str, path object, or file-like object", "param_desc": "String, path object (implementing os.PathLike[str]), or file-like\nobject implementing a text read() function.The string could be a URL.\nValid URL schemes include http, ftp, s3, and file. For file URLs, a host is\nexpected. A local file could be:\nfile://localhost/path/to/table.csv.\n"}, {"param_name": "colspecs", "param_type": "list of tuple (int, int) or ‘infer’. optional", "param_desc": "A list of tuples giving the extents of the fixed-width\nfields of each line as half-open intervals (i.e., [from, to[ ).\nString value ‘infer’ can be used to instruct the parser to try\ndetecting the column specifications from the first 100 rows of\nthe data which are not being skipped via skiprows (default=’infer’).\n"}, {"param_name": "widths", "param_type": "list of int, optional", "param_desc": "A list of field widths which can be used instead of ‘colspecs’ if\nthe intervals are contiguous.\n"}, {"param_name": "infer_nrows", "param_type": "int, default 100", "param_desc": "The number of rows to consider when letting the parser determine the\ncolspecs.\n"}, {"param_name": "dtype_backend", "param_type": "{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’", "param_desc": "Back-end data type applied to the resultant DataFrame\n(still experimental). Behaviour is as follows:\n\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\n(default).\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\nDataFrame.\n\n\nNew in version 2.0.\n\n"}, {"param_name": "**kwds", "param_type": "optional", "param_desc": "Optional keyword arguments can be passed to TextFileReader.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.read_fwf.html#pandas.read_fwf"}]}, {"name": "Clipboard", "url": "https://pandas.pydata.org/docs/reference/io.html#clipboard", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.read_clipboard.html#pandas.read_clipboard", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_clipboard.html#pandas.DataFrame.to_clipboard"], "function_definitions": [{"function_name": "pandas.read_clipboard", "full_function": "pandas.read_clipboard(sep='\\\\s+', dtype_backend=_NoDefault.no_default, **kwargs)", "function_text": "Read text from clipboard and pass to read_csv().", "parameter_names_desc": [{"param_name": "sep", "param_type": "str, default ‘\\s+’", "param_desc": "A string or regex delimiter. The default of '\\\\s+' denotes\none or more whitespace characters.\n"}, {"param_name": "dtype_backend", "param_type": "{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’", "param_desc": "Back-end data type applied to the resultant DataFrame\n(still experimental). Behaviour is as follows:\n\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\n(default).\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\nDataFrame.\n\n\nNew in version 2.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.read_clipboard.html#pandas.read_clipboard"}, {"function_name": "pandas.DataFrame.to_clipboard", "full_function": "DataFrame.to_clipboard(*, excel=True, sep=None, **kwargs)", "function_text": "Copy object to the system clipboard.", "parameter_names_desc": [{"param_name": "excel", "param_type": "bool, default True", "param_desc": "Produce output in a csv format for easy pasting into excel.\n\nTrue, use the provided separator for csv pasting.\nFalse, write a string representation of the object to the clipboard.\n\n"}, {"param_name": "sep", "param_type": "str, default '\\t'", "param_desc": "Field delimiter.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_clipboard.html#pandas.DataFrame.to_clipboard"}]}, {"name": "Excel", "url": "https://pandas.pydata.org/docs/reference/io.html#excel", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html#pandas.read_excel", "https://pandas.pydata.org/docs/reference/api/pandas.ExcelFile.html#pandas.ExcelFile", "https://pandas.pydata.org/docs/reference/api/pandas.ExcelFile.sheet_names.html#pandas.ExcelFile.sheet_names", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_excel.html#pandas.io.formats.style.Styler.to_excel", "https://pandas.pydata.org/docs/reference/api/pandas.ExcelWriter.html#pandas.ExcelWriter", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_excel.html#pandas.DataFrame.to_excel", "https://pandas.pydata.org/docs/reference/api/pandas.ExcelFile.book.html#pandas.ExcelFile.book", "https://pandas.pydata.org/docs/reference/api/pandas.ExcelFile.parse.html#pandas.ExcelFile.parse"], "function_definitions": [{"function_name": "pandas.read_excel", "full_function": "pandas.read_excel(io, sheet_name=0, *, header=0, names=None, index_col=None, usecols=None, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skiprows=None, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=False, parse_dates=False, date_parser=_NoDefault.no_default, date_format=None, thousands=None, decimal='.', comment=None, skipfooter=0, storage_options=None, dtype_backend=_NoDefault.no_default, engine_kwargs=None)", "function_text": "Read an Excel file into a pandas DataFrame.", "parameter_names_desc": [{"param_name": "io", "param_type": "str, bytes, ExcelFile, xlrd.Book, path object, or file-like object", "param_desc": "Any valid string path is acceptable. The string could be a URL. Valid\nURL schemes include http, ftp, s3, and file. For file URLs, a host is\nexpected. A local file could be: file://localhost/path/to/table.xlsx.\nIf you want to pass in a path object, pandas accepts any os.PathLike.\nBy file-like object, we refer to objects with a read() method,\nsuch as a file handle (e.g. via builtin open function)\nor StringIO.\n\nDeprecated since version 2.1.0: Passing byte strings is deprecated. To read from a\nbyte string, wrap it in a BytesIO object.\n\n"}, {"param_name": "sheet_name", "param_type": "str, int, list, or None, default 0", "param_desc": "Strings are used for sheet names. Integers are used in zero-indexed\nsheet positions (chart sheets do not count as a sheet position).\nLists of strings/integers are used to request multiple sheets.\nSpecify None to get all worksheets.\nAvailable cases:\n\nDefaults to 0: 1st sheet as a DataFrame\n1: 2nd sheet as a DataFrame\n\"Sheet1\": Load sheet with name “Sheet1”\n[0, 1, \"Sheet5\"]: Load first, second and sheet named “Sheet5”\nas a dict of DataFrame\nNone: All worksheets.\n\n"}, {"param_name": "header", "param_type": "int, list of int, default 0", "param_desc": "Row (0-indexed) to use for the column labels of the parsed\nDataFrame. If a list of integers is passed those row positions will\nbe combined into a MultiIndex. Use None if there is no header.\n"}, {"param_name": "names", "param_type": "array-like, default None", "param_desc": "List of column names to use. If file contains no header row,\nthen you should explicitly pass header=None.\n"}, {"param_name": "index_col", "param_type": "int, str, list of int, default None", "param_desc": "Column (0-indexed) to use as the row labels of the DataFrame.\nPass None if there is no such column. If a list is passed,\nthose columns will be combined into a MultiIndex. If a\nsubset of data is selected with usecols, index_col\nis based on the subset.\nMissing values will be forward filled to allow roundtripping with\nto_excel for merged_cells=True. To avoid forward filling the\nmissing values use set_index after reading the data instead of\nindex_col.\n"}, {"param_name": "usecols", "param_type": "str, list-like, or callable, default None", "param_desc": "\nIf None, then parse all columns.\nIf str, then indicates comma separated list of Excel column letters\nand column ranges (e.g. “A:E” or “A,C,E:F”). Ranges are inclusive of\nboth sides.\nIf list of int, then indicates list of column numbers to be parsed\n(0-indexed).\nIf list of string, then indicates list of column names to be parsed.\nIf callable, then evaluate each column name against it and parse the\ncolumn if the callable returns True.\n\nReturns a subset of the columns according to behavior above.\n"}, {"param_name": "dtype", "param_type": "Type name or dict of column -> type, default None", "param_desc": "Data type for data or columns. E.g. {‘a’: np.float64, ‘b’: np.int32}\nUse object to preserve data as stored in Excel and not interpret dtype,\nwhich will necessarily result in object dtype.\nIf converters are specified, they will be applied INSTEAD\nof dtype conversion.\nIf you use None, it will infer the dtype of each column based on the data.\n"}, {"param_name": "engine", "param_type": "{‘openpyxl’, ‘calamine’, ‘odf’, ‘pyxlsb’, ‘xlrd’}, default None", "param_desc": "If io is not a buffer or path, this must be set to identify io.\nEngine compatibility :\n\nopenpyxl supports newer Excel file formats.\ncalamine supports Excel (.xls, .xlsx, .xlsm, .xlsb)\nand OpenDocument (.ods) file formats.\nodf supports OpenDocument file formats (.odf, .ods, .odt).\npyxlsb supports Binary Excel files.\nxlrd supports old-style Excel files (.xls).\n\nWhen engine=None, the following logic will be used to determine the engine:\n\nIf path_or_buffer is an OpenDocument format (.odf, .ods, .odt),\nthen odf will be used.\nOtherwise if path_or_buffer is an xls format, xlrd will be used.\nOtherwise if path_or_buffer is in xlsb format, pyxlsb will be used.\nOtherwise openpyxl will be used.\n\n"}, {"param_name": "converters", "param_type": "dict, default None", "param_desc": "Dict of functions for converting values in certain columns. Keys can\neither be integers or column labels, values are functions that take one\ninput argument, the Excel cell content, and return the transformed\ncontent.\n"}, {"param_name": "true_values", "param_type": "list, default None", "param_desc": "Values to consider as True.\n"}, {"param_name": "false_values", "param_type": "list, default None", "param_desc": "Values to consider as False.\n"}, {"param_name": "skiprows", "param_type": "list-like, int, or callable, optional", "param_desc": "Line numbers to skip (0-indexed) or number of lines to skip (int) at the\nstart of the file. If callable, the callable function will be evaluated\nagainst the row indices, returning True if the row should be skipped and\nFalse otherwise. An example of a valid callable argument would be lambda\nx: x in [0, 2].\n"}, {"param_name": "nrows", "param_type": "int, default None", "param_desc": "Number of rows to parse.\n"}, {"param_name": "na_values", "param_type": "scalar, str, list-like, or dict, default None", "param_desc": "Additional strings to recognize as NA/NaN. If dict passed, specific\nper-column NA values. By default the following values are interpreted\nas NaN: ‘’, ‘#N/A’, ‘#N/A N/A’, ‘#NA’, ‘-1.#IND’, ‘-1.#QNAN’, ‘-NaN’, ‘-nan’,\n‘1.#IND’, ‘1.#QNAN’, ‘<NA>’, ‘N/A’, ‘NA’, ‘NULL’, ‘NaN’, ‘None’,\n‘n/a’, ‘nan’, ‘null’.\n"}, {"param_name": "keep_default_na", "param_type": "bool, default True", "param_desc": "Whether or not to include the default NaN values when parsing the data.\nDepending on whether na_values is passed in, the behavior is as follows:\n\nIf keep_default_na is True, and na_values are specified,\nna_values is appended to the default NaN values used for parsing.\nIf keep_default_na is True, and na_values are not specified, only\nthe default NaN values are used for parsing.\nIf keep_default_na is False, and na_values are specified, only\nthe NaN values specified na_values are used for parsing.\nIf keep_default_na is False, and na_values are not specified, no\nstrings will be parsed as NaN.\n\nNote that if na_filter is passed in as False, the keep_default_na and\nna_values parameters will be ignored.\n"}, {"param_name": "na_filter", "param_type": "bool, default True", "param_desc": "Detect missing value markers (empty strings and the value of na_values). In\ndata without any NAs, passing na_filter=False can improve the\nperformance of reading a large file.\n"}, {"param_name": "verbose", "param_type": "bool, default False", "param_desc": "Indicate number of NA values placed in non-numeric columns.\n"}, {"param_name": "parse_dates", "param_type": "bool, list-like, or dict, default False", "param_desc": "The behavior is as follows:\n\nbool. If True -> try parsing the index.\nlist of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\neach as a separate date column.\nlist of lists. e.g. If [[1, 3]] -> combine columns 1 and 3 and parse as\na single date column.\ndict, e.g. {‘foo’ : [1, 3]} -> parse columns 1, 3 as date and call\nresult ‘foo’\n\nIf a column or index contains an unparsable date, the entire column or\nindex will be returned unaltered as an object data type. If you don`t want to\nparse some cells as date just change their type in Excel to “Text”.\nFor non-standard datetime parsing, use pd.to_datetime after pd.read_excel.\nNote: A fast-path exists for iso8601-formatted dates.\n"}, {"param_name": "date_parser", "param_type": "function, optional", "param_desc": "Function to use for converting a sequence of string columns to an array of\ndatetime instances. The default uses dateutil.parser.parser to do the\nconversion. Pandas will try to call date_parser in three different ways,\nadvancing to the next if an exception occurs: 1) Pass one or more arrays\n(as defined by parse_dates) as arguments; 2) concatenate (row-wise) the\nstring values from the columns defined by parse_dates into a single array\nand pass that; and 3) call date_parser once for each row using one or\nmore strings (corresponding to the columns defined by parse_dates) as\narguments.\n\nDeprecated since version 2.0.0: Use date_format instead, or read in as object and then apply\nto_datetime() as-needed.\n\n"}, {"param_name": "date_format", "param_type": "str or dict of column -> format, default None", "param_desc": "If used in conjunction with parse_dates, will parse dates according to this\nformat. For anything more complex,\nplease read in as object and then apply to_datetime() as-needed.\n\nNew in version 2.0.0.\n\n"}, {"param_name": "thousands", "param_type": "str, default None", "param_desc": "Thousands separator for parsing string columns to numeric. Note that\nthis parameter is only necessary for columns stored as TEXT in Excel,\nany numeric columns will automatically be parsed, regardless of display\nformat.\n"}, {"param_name": "decimal", "param_type": "str, default ‘.’", "param_desc": "Character to recognize as decimal point for parsing string columns to numeric.\nNote that this parameter is only necessary for columns stored as TEXT in Excel,\nany numeric columns will automatically be parsed, regardless of display\nformat.(e.g. use ‘,’ for European data).\n\nNew in version 1.4.0.\n\n"}, {"param_name": "comment", "param_type": "str, default None", "param_desc": "Comments out remainder of line. Pass a character or characters to this\nargument to indicate comments in the input file. Any data between the\ncomment string and the end of the current line is ignored.\n"}, {"param_name": "skipfooter", "param_type": "int, default 0", "param_desc": "Rows at the end to skip (0-indexed).\n"}, {"param_name": "storage_options", "param_type": "dict, optional", "param_desc": "Extra options that make sense for a particular storage connection, e.g.\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\nare forwarded to urllib.request.Request as header options. For other\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\nforwarded to fsspec.open. Please see fsspec and urllib for more\ndetails, and for more examples on storage options refer here.\n"}, {"param_name": "dtype_backend", "param_type": "{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’", "param_desc": "Back-end data type applied to the resultant DataFrame\n(still experimental). Behaviour is as follows:\n\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\n(default).\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\nDataFrame.\n\n\nNew in version 2.0.\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, optional", "param_desc": "Arbitrary keyword arguments passed to excel engine.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html#pandas.read_excel"}, {"function_name": "pandas.ExcelFile", "full_function": "class pandas.ExcelFile(path_or_buffer, engine=None, storage_options=None, engine_kwargs=None)", "function_text": "Class for parsing tabular Excel sheets into DataFrame objects.", "parameter_names_desc": [{"param_name": "path_or_buffer", "param_type": "str, bytes, path object (pathlib.Path or py._path.local.LocalPath),", "param_desc": "A file-like object, xlrd workbook or openpyxl workbook.\nIf a string or path object, expected to be a path to a\n.xls, .xlsx, .xlsb, .xlsm, .odf, .ods, or .odt file.\n"}, {"param_name": "engine", "param_type": "str, default None", "param_desc": "If io is not a buffer or path, this must be set to identify io.\nSupported engines: xlrd, openpyxl, odf, pyxlsb, calamine\nEngine compatibility :\n\nxlrd supports old-style Excel files (.xls).\nopenpyxl supports newer Excel file formats.\nodf supports OpenDocument file formats (.odf, .ods, .odt).\npyxlsb supports Binary Excel files.\ncalamine supports Excel (.xls, .xlsx, .xlsm, .xlsb)\nand OpenDocument (.ods) file formats.\n\n\nChanged in version 1.2.0: The engine xlrd\nnow only supports old-style .xls files.\nWhen engine=None, the following logic will be\nused to determine the engine:\n\nIf path_or_buffer is an OpenDocument format (.odf, .ods, .odt),\nthen odf will be used.\nOtherwise if path_or_buffer is an xls format,\nxlrd will be used.\nOtherwise if path_or_buffer is in xlsb format,\npyxlsb will be used.\n\n\nNew in version 1.3.0.\n\n\nOtherwise if openpyxl is installed,\nthen openpyxl will be used.\nOtherwise if xlrd >= 2.0 is installed, a ValueError will be raised.\n\n\nWarning\nPlease do not report issues when using xlrd to read .xlsx files.\nThis is not supported, switch to using openpyxl instead.\n\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, optional", "param_desc": "Arbitrary keyword arguments passed to excel engine.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.ExcelFile.html#pandas.ExcelFile"}, {"function_name": "pandas.ExcelFile", "full_function": "class pandas.ExcelFile(path_or_buffer, engine=None, storage_options=None, engine_kwargs=None)", "function_text": "Class for parsing tabular Excel sheets into DataFrame objects.", "parameter_names_desc": [{"param_name": "path_or_buffer", "param_type": "str, bytes, path object (pathlib.Path or py._path.local.LocalPath),", "param_desc": "A file-like object, xlrd workbook or openpyxl workbook.\nIf a string or path object, expected to be a path to a\n.xls, .xlsx, .xlsb, .xlsm, .odf, .ods, or .odt file.\n"}, {"param_name": "engine", "param_type": "str, default None", "param_desc": "If io is not a buffer or path, this must be set to identify io.\nSupported engines: xlrd, openpyxl, odf, pyxlsb, calamine\nEngine compatibility :\n\nxlrd supports old-style Excel files (.xls).\nopenpyxl supports newer Excel file formats.\nodf supports OpenDocument file formats (.odf, .ods, .odt).\npyxlsb supports Binary Excel files.\ncalamine supports Excel (.xls, .xlsx, .xlsm, .xlsb)\nand OpenDocument (.ods) file formats.\n\n\nChanged in version 1.2.0: The engine xlrd\nnow only supports old-style .xls files.\nWhen engine=None, the following logic will be\nused to determine the engine:\n\nIf path_or_buffer is an OpenDocument format (.odf, .ods, .odt),\nthen odf will be used.\nOtherwise if path_or_buffer is an xls format,\nxlrd will be used.\nOtherwise if path_or_buffer is in xlsb format,\npyxlsb will be used.\n\n\nNew in version 1.3.0.\n\n\nOtherwise if openpyxl is installed,\nthen openpyxl will be used.\nOtherwise if xlrd >= 2.0 is installed, a ValueError will be raised.\n\n\nWarning\nPlease do not report issues when using xlrd to read .xlsx files.\nThis is not supported, switch to using openpyxl instead.\n\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, optional", "param_desc": "Arbitrary keyword arguments passed to excel engine.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.ExcelFile.html#pandas.ExcelFile"}, {"function_name": "pandas.io.formats.style.Styler.to_excel", "full_function": "Styler.to_excel(excel_writer, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, encoding=None, inf_rep='inf', verbose=True, freeze_panes=None, storage_options=None)", "function_text": "Write Styler to an Excel sheet.", "parameter_names_desc": [{"param_name": "excel_writer", "param_type": "path-like, file-like, or ExcelWriter object", "param_desc": "File path or existing ExcelWriter.\n"}, {"param_name": "sheet_name", "param_type": "str, default ‘Sheet1’", "param_desc": "Name of sheet which will contain DataFrame.\n"}, {"param_name": "na_rep", "param_type": "str, default ‘’", "param_desc": "Missing data representation.\n"}, {"param_name": "float_format", "param_type": "str, optional", "param_desc": "Format string for floating point numbers. For example\nfloat_format=\"%.2f\" will format 0.1234 to 0.12.\n"}, {"param_name": "columns", "param_type": "sequence or list of str, optional", "param_desc": "Columns to write.\n"}, {"param_name": "header", "param_type": "bool or list of str, default True", "param_desc": "Write out the column names. If a list of string is given it is\nassumed to be aliases for the column names.\n"}, {"param_name": "index", "param_type": "bool, default True", "param_desc": "Write row names (index).\n"}, {"param_name": "index_label", "param_type": "str or sequence, optional", "param_desc": "Column label for index column(s) if desired. If not specified, and\nheader and index are True, then the index names are used. A\nsequence should be given if the DataFrame uses MultiIndex.\n"}, {"param_name": "startrow", "param_type": "int, default 0", "param_desc": "Upper left cell row to dump data frame.\n"}, {"param_name": "startcol", "param_type": "int, default 0", "param_desc": "Upper left cell column to dump data frame.\n"}, {"param_name": "engine", "param_type": "str, optional", "param_desc": "Write engine to use, ‘openpyxl’ or ‘xlsxwriter’. You can also set this\nvia the options io.excel.xlsx.writer or\nio.excel.xlsm.writer.\n"}, {"param_name": "merge_cells", "param_type": "bool, default True", "param_desc": "Write MultiIndex and Hierarchical Rows as merged cells.\n"}, {"param_name": "inf_rep", "param_type": "str, default ‘inf’", "param_desc": "Representation for infinity (there is no native representation for\ninfinity in Excel).\n"}, {"param_name": "freeze_panes", "param_type": "tuple of int (length 2), optional", "param_desc": "Specifies the one-based bottommost row and rightmost column that\nis to be frozen.\n"}, {"param_name": "storage_options", "param_type": "dict, optional", "param_desc": "Extra options that make sense for a particular storage connection, e.g.\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\nare forwarded to urllib.request.Request as header options. For other\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\nforwarded to fsspec.open. Please see fsspec and urllib for more\ndetails, and for more examples on storage options refer here.\n\nNew in version 1.5.0.\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, optional", "param_desc": "Arbitrary keyword arguments passed to excel engine.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_excel.html#pandas.io.formats.style.Styler.to_excel"}, {"function_name": "pandas.ExcelWriter", "full_function": "class pandas.ExcelWriter(path, engine=None, date_format=None, datetime_format=None, mode='w', storage_options=None, if_sheet_exists=None, engine_kwargs=None)", "function_text": "Class for writing DataFrame objects into excel sheets.", "parameter_names_desc": [{"param_name": "path", "param_type": "str or typing.BinaryIO", "param_desc": "Path to xls or xlsx or ods file.\n"}, {"param_name": "engine", "param_type": "str (optional)", "param_desc": "Engine to use for writing. If None, defaults to\nio.excel.<extension>.writer. NOTE: can only be passed as a keyword\nargument.\n"}, {"param_name": "date_format", "param_type": "str, default None", "param_desc": "Format string for dates written into Excel files (e.g. ‘YYYY-MM-DD’).\n"}, {"param_name": "datetime_format", "param_type": "str, default None", "param_desc": "Format string for datetime objects written into Excel files.\n(e.g. ‘YYYY-MM-DD HH:MM:SS’).\n"}, {"param_name": "mode", "param_type": "{‘w’, ‘a’}, default ‘w’", "param_desc": "File mode to use (write or append). Append does not work with fsspec URLs.\n"}, {"param_name": "storage_options", "param_type": "dict, optional", "param_desc": "Extra options that make sense for a particular storage connection, e.g.\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\nare forwarded to urllib.request.Request as header options. For other\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\nforwarded to fsspec.open. Please see fsspec and urllib for more\ndetails, and for more examples on storage options refer here.\n"}, {"param_name": "if_sheet_exists", "param_type": "{‘error’, ‘new’, ‘replace’, ‘overlay’}, default ‘error’", "param_desc": "How to behave when trying to write to a sheet that already\nexists (append mode only).\n\nerror: raise a ValueError.\nnew: Create a new sheet, with a name determined by the engine.\nreplace: Delete the contents of the sheet before writing to it.\noverlay: Write contents to the existing sheet without first removing,\nbut possibly over top of, the existing contents.\n\n\nNew in version 1.3.0.\n\n\nChanged in version 1.4.0: Added overlay option\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, optional", "param_desc": "Keyword arguments to be passed into the engine. These will be passed to\nthe following functions of the respective engines:\n\nxlsxwriter: xlsxwriter.Workbook(file, **engine_kwargs)\nopenpyxl (write mode): openpyxl.Workbook(**engine_kwargs)\nopenpyxl (append mode): openpyxl.load_workbook(file, **engine_kwargs)\nodswriter: odf.opendocument.OpenDocumentSpreadsheet(**engine_kwargs)\n\n\nNew in version 1.3.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.ExcelWriter.html#pandas.ExcelWriter"}, {"function_name": "pandas.DataFrame.to_excel", "full_function": "DataFrame.to_excel(excel_writer, *, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, inf_rep='inf', freeze_panes=None, storage_options=None, engine_kwargs=None)", "function_text": "Write object to an Excel sheet.", "parameter_names_desc": [{"param_name": "excel_writer", "param_type": "path-like, file-like, or ExcelWriter object", "param_desc": "File path or existing ExcelWriter.\n"}, {"param_name": "sheet_name", "param_type": "str, default ‘Sheet1’", "param_desc": "Name of sheet which will contain DataFrame.\n"}, {"param_name": "na_rep", "param_type": "str, default ‘’", "param_desc": "Missing data representation.\n"}, {"param_name": "float_format", "param_type": "str, optional", "param_desc": "Format string for floating point numbers. For example\nfloat_format=\"%.2f\" will format 0.1234 to 0.12.\n"}, {"param_name": "columns", "param_type": "sequence or list of str, optional", "param_desc": "Columns to write.\n"}, {"param_name": "header", "param_type": "bool or list of str, default True", "param_desc": "Write out the column names. If a list of string is given it is\nassumed to be aliases for the column names.\n"}, {"param_name": "index", "param_type": "bool, default True", "param_desc": "Write row names (index).\n"}, {"param_name": "index_label", "param_type": "str or sequence, optional", "param_desc": "Column label for index column(s) if desired. If not specified, and\nheader and index are True, then the index names are used. A\nsequence should be given if the DataFrame uses MultiIndex.\n"}, {"param_name": "startrow", "param_type": "int, default 0", "param_desc": "Upper left cell row to dump data frame.\n"}, {"param_name": "startcol", "param_type": "int, default 0", "param_desc": "Upper left cell column to dump data frame.\n"}, {"param_name": "engine", "param_type": "str, optional", "param_desc": "Write engine to use, ‘openpyxl’ or ‘xlsxwriter’. You can also set this\nvia the options io.excel.xlsx.writer or\nio.excel.xlsm.writer.\n"}, {"param_name": "merge_cells", "param_type": "bool, default True", "param_desc": "Write MultiIndex and Hierarchical Rows as merged cells.\n"}, {"param_name": "inf_rep", "param_type": "str, default ‘inf’", "param_desc": "Representation for infinity (there is no native representation for\ninfinity in Excel).\n"}, {"param_name": "freeze_panes", "param_type": "tuple of int (length 2), optional", "param_desc": "Specifies the one-based bottommost row and rightmost column that\nis to be frozen.\n"}, {"param_name": "storage_options", "param_type": "dict, optional", "param_desc": "Extra options that make sense for a particular storage connection, e.g.\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\nare forwarded to urllib.request.Request as header options. For other\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\nforwarded to fsspec.open. Please see fsspec and urllib for more\ndetails, and for more examples on storage options refer here.\n\nNew in version 1.2.0.\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, optional", "param_desc": "Arbitrary keyword arguments passed to excel engine.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_excel.html#pandas.DataFrame.to_excel"}, {"function_name": "pandas.DataFrame.to_excel", "full_function": "DataFrame.to_excel(excel_writer, *, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, inf_rep='inf', freeze_panes=None, storage_options=None, engine_kwargs=None)", "function_text": "Write object to an Excel sheet.", "parameter_names_desc": [{"param_name": "excel_writer", "param_type": "path-like, file-like, or ExcelWriter object", "param_desc": "File path or existing ExcelWriter.\n"}, {"param_name": "sheet_name", "param_type": "str, default ‘Sheet1’", "param_desc": "Name of sheet which will contain DataFrame.\n"}, {"param_name": "na_rep", "param_type": "str, default ‘’", "param_desc": "Missing data representation.\n"}, {"param_name": "float_format", "param_type": "str, optional", "param_desc": "Format string for floating point numbers. For example\nfloat_format=\"%.2f\" will format 0.1234 to 0.12.\n"}, {"param_name": "columns", "param_type": "sequence or list of str, optional", "param_desc": "Columns to write.\n"}, {"param_name": "header", "param_type": "bool or list of str, default True", "param_desc": "Write out the column names. If a list of string is given it is\nassumed to be aliases for the column names.\n"}, {"param_name": "index", "param_type": "bool, default True", "param_desc": "Write row names (index).\n"}, {"param_name": "index_label", "param_type": "str or sequence, optional", "param_desc": "Column label for index column(s) if desired. If not specified, and\nheader and index are True, then the index names are used. A\nsequence should be given if the DataFrame uses MultiIndex.\n"}, {"param_name": "startrow", "param_type": "int, default 0", "param_desc": "Upper left cell row to dump data frame.\n"}, {"param_name": "startcol", "param_type": "int, default 0", "param_desc": "Upper left cell column to dump data frame.\n"}, {"param_name": "engine", "param_type": "str, optional", "param_desc": "Write engine to use, ‘openpyxl’ or ‘xlsxwriter’. You can also set this\nvia the options io.excel.xlsx.writer or\nio.excel.xlsm.writer.\n"}, {"param_name": "merge_cells", "param_type": "bool, default True", "param_desc": "Write MultiIndex and Hierarchical Rows as merged cells.\n"}, {"param_name": "inf_rep", "param_type": "str, default ‘inf’", "param_desc": "Representation for infinity (there is no native representation for\ninfinity in Excel).\n"}, {"param_name": "freeze_panes", "param_type": "tuple of int (length 2), optional", "param_desc": "Specifies the one-based bottommost row and rightmost column that\nis to be frozen.\n"}, {"param_name": "storage_options", "param_type": "dict, optional", "param_desc": "Extra options that make sense for a particular storage connection, e.g.\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\nare forwarded to urllib.request.Request as header options. For other\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\nforwarded to fsspec.open. Please see fsspec and urllib for more\ndetails, and for more examples on storage options refer here.\n\nNew in version 1.2.0.\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, optional", "param_desc": "Arbitrary keyword arguments passed to excel engine.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_excel.html#pandas.DataFrame.to_excel"}, {"function_name": "pandas.ExcelFile.parse", "full_function": "ExcelFile.parse(sheet_name=0, header=0, names=None, index_col=None, usecols=None, converters=None, true_values=None, false_values=None, skiprows=None, nrows=None, na_values=None, parse_dates=False, date_parser=_NoDefault.no_default, date_format=None, thousands=None, comment=None, skipfooter=0, dtype_backend=_NoDefault.no_default, **kwds)", "function_text": "Parse specified sheet(s) into a DataFrame.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.ExcelFile.parse.html#pandas.ExcelFile.parse"}]}, {"name": "JSON", "url": "https://pandas.pydata.org/docs/reference/io.html#json", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.read_json.html#pandas.read_json", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_json.html#pandas.DataFrame.to_json", "https://pandas.pydata.org/docs/reference/api/pandas.io.json.build_table_schema.html#pandas.io.json.build_table_schema", "https://pandas.pydata.org/docs/reference/api/pandas.json_normalize.html#pandas.json_normalize"], "function_definitions": [{"function_name": "pandas.read_json", "full_function": "pandas.read_json(path_or_buf, *, orient=None, typ='frame', dtype=None, convert_axes=None, convert_dates=True, keep_default_dates=True, precise_float=False, date_unit=None, encoding=None, encoding_errors='strict', lines=False, chunksize=None, compression='infer', nrows=None, storage_options=None, dtype_backend=_NoDefault.no_default, engine='ujson')", "function_text": "Convert a JSON string to pandas object.", "parameter_names_desc": [{"param_name": "path_or_buf", "param_type": "a valid JSON str, path object or file-like object", "param_desc": "Any valid string path is acceptable. The string could be a URL. Valid\nURL schemes include http, ftp, s3, and file. For file URLs, a host is\nexpected. A local file could be:\nfile://localhost/path/to/table.json.\nIf you want to pass in a path object, pandas accepts any\nos.PathLike.\nBy file-like object, we refer to objects with a read() method,\nsuch as a file handle (e.g. via builtin open function)\nor StringIO.\n\nDeprecated since version 2.1.0: Passing json literal strings is deprecated.\n\n"}, {"param_name": "orient", "param_type": "str, optional", "param_desc": "Indication of expected JSON string format.\nCompatible JSON strings can be produced by to_json() with a\ncorresponding orient value.\nThe set of possible orients is:\n\n'split' : dict like\n{index -> [index], columns -> [columns], data -> [values]}\n'records' : list like\n[{column -> value}, ... , {column -> value}]\n'index' : dict like {index -> {column -> value}}\n'columns' : dict like {column -> {index -> value}}\n'values' : just the values array\n'table' : dict like {'schema': {schema}, 'data': {data}}\n\nThe allowed and default values depend on the value\nof the typ parameter.\n\nwhen typ == 'series',\n\nallowed orients are {'split','records','index'}\ndefault is 'index'\nThe Series index must be unique for orient 'index'.\n\n\nwhen typ == 'frame',\n\nallowed orients are {'split','records','index',\n'columns','values', 'table'}\ndefault is 'columns'\nThe DataFrame index must be unique for orients 'index' and\n'columns'.\nThe DataFrame columns must be unique for orients 'index',\n'columns', and 'records'.\n\n\n\n"}, {"param_name": "typ", "param_type": "{‘frame’, ‘series’}, default ‘frame’", "param_desc": "The type of object to recover.\n"}, {"param_name": "dtype", "param_type": "bool or dict, default None", "param_desc": "If True, infer dtypes; if a dict of column to dtype, then use those;\nif False, then don’t infer dtypes at all, applies only to the data.\nFor all orient values except 'table', default is True.\n"}, {"param_name": "convert_axes", "param_type": "bool, default None", "param_desc": "Try to convert the axes to the proper dtypes.\nFor all orient values except 'table', default is True.\n"}, {"param_name": "convert_dates", "param_type": "bool or list of str, default True", "param_desc": "If True then default datelike columns may be converted (depending on\nkeep_default_dates).\nIf False, no dates will be converted.\nIf a list of column names, then those columns will be converted and\ndefault datelike columns may also be converted (depending on\nkeep_default_dates).\n"}, {"param_name": "keep_default_dates", "param_type": "bool, default True", "param_desc": "If parsing dates (convert_dates is not False), then try to parse the\ndefault datelike columns.\nA column label is datelike if\n\nit ends with '_at',\nit ends with '_time',\nit begins with 'timestamp',\nit is 'modified', or\nit is 'date'.\n\n"}, {"param_name": "precise_float", "param_type": "bool, default False", "param_desc": "Set to enable usage of higher precision (strtod) function when\ndecoding string to double values. Default (False) is to use fast but\nless precise builtin functionality.\n"}, {"param_name": "date_unit", "param_type": "str, default None", "param_desc": "The timestamp unit to detect if converting dates. The default behaviour\nis to try and detect the correct precision, but if this is not desired\nthen pass one of ‘s’, ‘ms’, ‘us’ or ‘ns’ to force parsing only seconds,\nmilliseconds, microseconds or nanoseconds respectively.\n"}, {"param_name": "encoding", "param_type": "str, default is ‘utf-8’", "param_desc": "The encoding to use to decode py3 bytes.\n"}, {"param_name": "encoding_errors", "param_type": "str, optional, default “strict”", "param_desc": "How encoding errors are treated. List of possible values .\n\nNew in version 1.3.0.\n\n"}, {"param_name": "lines", "param_type": "bool, default False", "param_desc": "Read the file as a json object per line.\n"}, {"param_name": "chunksize", "param_type": "int, optional", "param_desc": "Return JsonReader object for iteration.\nSee the line-delimited json docs\nfor more information on chunksize.\nThis can only be passed if lines=True.\nIf this is None, the file will be read into memory all at once.\n"}, {"param_name": "compression", "param_type": "str or dict, default ‘infer’", "param_desc": "For on-the-fly decompression of on-disk data. If ‘infer’ and ‘path_or_buf’ is\npath-like, then detect compression from the following extensions: ‘.gz’,\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\n(otherwise no compression).\nIf using ‘zip’ or ‘tar’, the ZIP file must contain only one data file to be read in.\nSet to None for no decompression.\nCan also be a dict with key 'method' set\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\nother key-value pairs are forwarded to\nzipfile.ZipFile, gzip.GzipFile,\nbz2.BZ2File, zstandard.ZstdDecompressor, lzma.LZMAFile or\ntarfile.TarFile, respectively.\nAs an example, the following could be passed for Zstandard decompression using a\ncustom compression dictionary:\ncompression={'method': 'zstd', 'dict_data': my_compression_dict}.\n\nNew in version 1.5.0: Added support for .tar files.\n\n\nChanged in version 1.4.0: Zstandard support.\n\n"}, {"param_name": "nrows", "param_type": "int, optional", "param_desc": "The number of lines from the line-delimited jsonfile that has to be read.\nThis can only be passed if lines=True.\nIf this is None, all the rows will be returned.\n"}, {"param_name": "storage_options", "param_type": "dict, optional", "param_desc": "Extra options that make sense for a particular storage connection, e.g.\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\nare forwarded to urllib.request.Request as header options. For other\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\nforwarded to fsspec.open. Please see fsspec and urllib for more\ndetails, and for more examples on storage options refer here.\n"}, {"param_name": "dtype_backend", "param_type": "{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’", "param_desc": "Back-end data type applied to the resultant DataFrame\n(still experimental). Behaviour is as follows:\n\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\n(default).\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\nDataFrame.\n\n\nNew in version 2.0.\n\n"}, {"param_name": "engine", "param_type": "{“ujson”, “pyarrow”}, default “ujson”", "param_desc": "Parser engine to use. The \"pyarrow\" engine is only available when\nlines=True.\n\nNew in version 2.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.read_json.html#pandas.read_json"}, {"function_name": "pandas.DataFrame.to_json", "full_function": "DataFrame.to_json(path_or_buf=None, *, orient=None, date_format=None, double_precision=10, force_ascii=True, date_unit='ms', default_handler=None, lines=False, compression='infer', index=None, indent=None, storage_options=None, mode='w')", "function_text": "Convert the object to a JSON string.", "parameter_names_desc": [{"param_name": "path_or_buf", "param_type": "str, path object, file-like object, or None, default None", "param_desc": "String, path object (implementing os.PathLike[str]), or file-like\nobject implementing a write() function. If None, the result is\nreturned as a string.\n"}, {"param_name": "orient", "param_type": "str", "param_desc": "Indication of expected JSON string format.\n\nSeries:\n\n\ndefault is ‘index’\nallowed values are: {‘split’, ‘records’, ‘index’, ‘table’}.\n\n\n\nDataFrame:\n\n\ndefault is ‘columns’\nallowed values are: {‘split’, ‘records’, ‘index’, ‘columns’,\n‘values’, ‘table’}.\n\n\n\nThe format of the JSON string:\n\n\n‘split’ : dict like {‘index’ -> [index], ‘columns’ -> [columns],\n‘data’ -> [values]}\n‘records’ : list like [{column -> value}, … , {column -> value}]\n‘index’ : dict like {index -> {column -> value}}\n‘columns’ : dict like {column -> {index -> value}}\n‘values’ : just the values array\n‘table’ : dict like {‘schema’: {schema}, ‘data’: {data}}\n\nDescribing the data, where data component is like orient='records'.\n\n\n\n"}, {"param_name": "date_format", "param_type": "{None, ‘epoch’, ‘iso’}", "param_desc": "Type of date conversion. ‘epoch’ = epoch milliseconds,\n‘iso’ = ISO8601. The default depends on the orient. For\norient='table', the default is ‘iso’. For all other orients,\nthe default is ‘epoch’.\n"}, {"param_name": "double_precision", "param_type": "int, default 10", "param_desc": "The number of decimal places to use when encoding\nfloating point values. The possible maximal value is 15.\nPassing double_precision greater than 15 will raise a ValueError.\n"}, {"param_name": "force_ascii", "param_type": "bool, default True", "param_desc": "Force encoded string to be ASCII.\n"}, {"param_name": "date_unit", "param_type": "str, default ‘ms’ (milliseconds)", "param_desc": "The time unit to encode to, governs timestamp and ISO8601\nprecision. One of ‘s’, ‘ms’, ‘us’, ‘ns’ for second, millisecond,\nmicrosecond, and nanosecond respectively.\n"}, {"param_name": "default_handler", "param_type": "callable, default None", "param_desc": "Handler to call if object cannot otherwise be converted to a\nsuitable format for JSON. Should receive a single argument which is\nthe object to convert and return a serialisable object.\n"}, {"param_name": "lines", "param_type": "bool, default False", "param_desc": "If ‘orient’ is ‘records’ write out line-delimited json format. Will\nthrow ValueError if incorrect ‘orient’ since others are not\nlist-like.\n"}, {"param_name": "compression", "param_type": "str or dict, default ‘infer’", "param_desc": "For on-the-fly compression of the output data. If ‘infer’ and ‘path_or_buf’ is\npath-like, then detect compression from the following extensions: ‘.gz’,\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\n(otherwise no compression).\nSet to None for no compression.\nCan also be a dict with key 'method' set\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\nother key-value pairs are forwarded to\nzipfile.ZipFile, gzip.GzipFile,\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\ntarfile.TarFile, respectively.\nAs an example, the following could be passed for faster compression and to create\na reproducible gzip archive:\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\n\nNew in version 1.5.0: Added support for .tar files.\n\n\nChanged in version 1.4.0: Zstandard support.\n\n"}, {"param_name": "index", "param_type": "bool or None, default None", "param_desc": "The index is only used when ‘orient’ is ‘split’, ‘index’, ‘column’,\nor ‘table’. Of these, ‘index’ and ‘column’ do not support\nindex=False.\n"}, {"param_name": "indent", "param_type": "int, optional", "param_desc": "Length of whitespace used to indent each record.\n"}, {"param_name": "storage_options", "param_type": "dict, optional", "param_desc": "Extra options that make sense for a particular storage connection, e.g.\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\nare forwarded to urllib.request.Request as header options. For other\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\nforwarded to fsspec.open. Please see fsspec and urllib for more\ndetails, and for more examples on storage options refer here.\n"}, {"param_name": "mode", "param_type": "str, default ‘w’ (writing)", "param_desc": "Specify the IO mode for output when supplying a path_or_buf.\nAccepted args are ‘w’ (writing) and ‘a’ (append) only.\nmode=’a’ is only supported when lines is True and orient is ‘records’.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_json.html#pandas.DataFrame.to_json"}, {"function_name": "pandas.io.json.build_table_schema", "full_function": "pandas.io.json.build_table_schema(data, index=True, primary_key=None, version=True)", "function_text": "Create a Table schema from data.", "parameter_names_desc": [{"param_name": "data", "param_type": "Series, DataFrame", "param_desc": ""}, {"param_name": "index", "param_type": "bool, default True", "param_desc": "Whether to include data.index in the schema.\n"}, {"param_name": "primary_key", "param_type": "bool or None, default True", "param_desc": "Column names to designate as the primary key.\nThe default None will set ‘primaryKey’ to the index\nlevel or levels if the index is unique.\n"}, {"param_name": "version", "param_type": "bool, default True", "param_desc": "Whether to include a field pandas_version with the version\nof pandas that last revised the table schema. This version\ncan be different from the installed pandas version.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.json.build_table_schema.html#pandas.io.json.build_table_schema"}, {"function_name": "pandas.json_normalize", "full_function": "pandas.json_normalize(data, record_path=None, meta=None, meta_prefix=None, record_prefix=None, errors='raise', sep='.', max_level=None)", "function_text": "Normalize semi-structured JSON data into a flat table.", "parameter_names_desc": [{"param_name": "data", "param_type": "dict or list of dicts", "param_desc": "Unserialized JSON objects.\n"}, {"param_name": "record_path", "param_type": "str or list of str, default None", "param_desc": "Path in each object to list of records. If not passed, data will be\nassumed to be an array of records.\n"}, {"param_name": "meta", "param_type": "list of paths (str or list of str), default None", "param_desc": "Fields to use as metadata for each record in resulting table.\n"}, {"param_name": "meta_prefix", "param_type": "str, default None", "param_desc": "If True, prefix records with dotted (?) path, e.g. foo.bar.field if\nmeta is [‘foo’, ‘bar’].\n"}, {"param_name": "record_prefix", "param_type": "str, default None", "param_desc": "If True, prefix records with dotted (?) path, e.g. foo.bar.field if\npath to records is [‘foo’, ‘bar’].\n"}, {"param_name": "errors", "param_type": "{‘raise’, ‘ignore’}, default ‘raise’", "param_desc": "Configures error handling.\n\n‘ignore’ : will ignore KeyError if keys listed in meta are not\nalways present.\n‘raise’ : will raise KeyError if keys listed in meta are not\nalways present.\n\n"}, {"param_name": "sep", "param_type": "str, default ‘.’", "param_desc": "Nested records will generate names separated by sep.\ne.g., for sep=’.’, {‘foo’: {‘bar’: 0}} -> foo.bar.\n"}, {"param_name": "max_level", "param_type": "int, default None", "param_desc": "Max number of levels(depth of dict) to normalize.\nif None, normalizes all levels.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.json_normalize.html#pandas.json_normalize"}]}, {"name": "HTML", "url": "https://pandas.pydata.org/docs/reference/io.html#html", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.read_html.html#pandas.read_html", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_html.html#pandas.io.formats.style.Styler.to_html", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_html.html#pandas.DataFrame.to_html"], "function_definitions": [{"function_name": "pandas.read_html", "full_function": "pandas.read_html(io, *, match='.+', flavor=None, header=None, index_col=None, skiprows=None, attrs=None, parse_dates=False, thousands=',', encoding=None, decimal='.', converters=None, na_values=None, keep_default_na=True, displayed_only=True, extract_links=None, dtype_backend=_NoDefault.no_default, storage_options=None)", "function_text": "Read HTML tables into a list of DataFrame objects.", "parameter_names_desc": [{"param_name": "io", "param_type": "str, path object, or file-like object", "param_desc": "String, path object (implementing os.PathLike[str]), or file-like\nobject implementing a string read() function.\nThe string can represent a URL or the HTML itself. Note that\nlxml only accepts the http, ftp and file url protocols. If you have a\nURL that starts with 'https' you might try removing the 's'.\n\nDeprecated since version 2.1.0: Passing html literal strings is deprecated.\nWrap literal string/bytes input in io.StringIO/io.BytesIO instead.\n\n"}, {"param_name": "match", "param_type": "str or compiled regular expression, optional", "param_desc": "The set of tables containing text matching this regex or string will be\nreturned. Unless the HTML is extremely simple you will probably need to\npass a non-empty string here. Defaults to ‘.+’ (match any non-empty\nstring). The default value will return all tables contained on a page.\nThis value is converted to a regular expression so that there is\nconsistent behavior between Beautiful Soup and lxml.\n"}, {"param_name": "flavor", "param_type": "{“lxml”, “html5lib”, “bs4”} or list-like, optional", "param_desc": "The parsing engine (or list of parsing engines) to use. ‘bs4’ and\n‘html5lib’ are synonymous with each other, they are both there for\nbackwards compatibility. The default of None tries to use lxml\nto parse and if that fails it falls back on bs4 + html5lib.\n"}, {"param_name": "header", "param_type": "int or list-like, optional", "param_desc": "The row (or list of rows for a MultiIndex) to use to\nmake the columns headers.\n"}, {"param_name": "index_col", "param_type": "int or list-like, optional", "param_desc": "The column (or list of columns) to use to create the index.\n"}, {"param_name": "skiprows", "param_type": "int, list-like or slice, optional", "param_desc": "Number of rows to skip after parsing the column integer. 0-based. If a\nsequence of integers or a slice is given, will skip the rows indexed by\nthat sequence. Note that a single element sequence means ‘skip the nth\nrow’ whereas an integer means ‘skip n rows’.\n"}, {"param_name": "attrs", "param_type": "dict, optional", "param_desc": "This is a dictionary of attributes that you can pass to use to identify\nthe table in the HTML. These are not checked for validity before being\npassed to lxml or Beautiful Soup. However, these attributes must be\nvalid HTML table attributes to work correctly. For example,\nattrs = {'id': 'table'}\n\n\nis a valid attribute dictionary because the ‘id’ HTML tag attribute is\na valid HTML attribute for any HTML tag as per this document.\nattrs = {'asdf': 'table'}\n\n\nis not a valid attribute dictionary because ‘asdf’ is not a valid\nHTML attribute even if it is a valid XML attribute. Valid HTML 4.01\ntable attributes can be found here. A\nworking draft of the HTML 5 spec can be found here. It contains the\nlatest information on table attributes for the modern web.\n"}, {"param_name": "parse_dates", "param_type": "bool, optional", "param_desc": "See read_csv() for more details.\n"}, {"param_name": "thousands", "param_type": "str, optional", "param_desc": "Separator to use to parse thousands. Defaults to ','.\n"}, {"param_name": "encoding", "param_type": "str, optional", "param_desc": "The encoding used to decode the web page. Defaults to None.``None``\npreserves the previous encoding behavior, which depends on the\nunderlying parser library (e.g., the parser library will try to use\nthe encoding provided by the document).\n"}, {"param_name": "decimal", "param_type": "str, default ‘.’", "param_desc": "Character to recognize as decimal point (e.g. use ‘,’ for European\ndata).\n"}, {"param_name": "converters", "param_type": "dict, default None", "param_desc": "Dict of functions for converting values in certain columns. Keys can\neither be integers or column labels, values are functions that take one\ninput argument, the cell (not column) content, and return the\ntransformed content.\n"}, {"param_name": "na_values", "param_type": "iterable, default None", "param_desc": "Custom NA values.\n"}, {"param_name": "keep_default_na", "param_type": "bool, default True", "param_desc": "If na_values are specified and keep_default_na is False the default NaN\nvalues are overridden, otherwise they’re appended to.\n"}, {"param_name": "displayed_only", "param_type": "bool, default True", "param_desc": "Whether elements with “display: none” should be parsed.\n"}, {"param_name": "extract_links", "param_type": "{None, “all”, “header”, “body”, “footer”}", "param_desc": "Table elements in the specified section(s) with <a> tags will have their\nhref extracted.\n\nNew in version 1.5.0.\n\n"}, {"param_name": "dtype_backend", "param_type": "{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’", "param_desc": "Back-end data type applied to the resultant DataFrame\n(still experimental). Behaviour is as follows:\n\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\n(default).\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\nDataFrame.\n\n\nNew in version 2.0.\n\n"}, {"param_name": "storage_options", "param_type": "dict, optional", "param_desc": "Extra options that make sense for a particular storage connection, e.g.\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\nare forwarded to urllib.request.Request as header options. For other\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\nforwarded to fsspec.open. Please see fsspec and urllib for more\ndetails, and for more examples on storage options refer here.\n\nNew in version 2.1.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.read_html.html#pandas.read_html"}, {"function_name": "pandas.io.formats.style.Styler.to_html", "full_function": "Styler.to_html(buf=None, *, table_uuid=None, table_attributes=None, sparse_index=None, sparse_columns=None, bold_headers=False, caption=None, max_rows=None, max_columns=None, encoding=None, doctype_html=False, exclude_styles=False, **kwargs)", "function_text": "Write Styler to a file, buffer or string in HTML-CSS format.", "parameter_names_desc": [{"param_name": "buf", "param_type": "str, path object, file-like object, optional", "param_desc": "String, path object (implementing os.PathLike[str]), or file-like\nobject implementing a string write() function. If None, the result is\nreturned as a string.\n"}, {"param_name": "table_uuid", "param_type": "str, optional", "param_desc": "Id attribute assigned to the <table> HTML element in the format:\n<table id=\"T_<table_uuid>\" ..>\nIf not given uses Styler’s initially assigned value.\n"}, {"param_name": "table_attributes", "param_type": "str, optional", "param_desc": "Attributes to assign within the <table> HTML element in the format:\n<table .. <table_attributes> >\nIf not given defaults to Styler’s preexisting value.\n"}, {"param_name": "sparse_index", "param_type": "bool, optional", "param_desc": "Whether to sparsify the display of a hierarchical index. Setting to False\nwill display each explicit level element in a hierarchical key for each row.\nDefaults to pandas.options.styler.sparse.index value.\n\nNew in version 1.4.0.\n\n"}, {"param_name": "sparse_columns", "param_type": "bool, optional", "param_desc": "Whether to sparsify the display of a hierarchical index. Setting to False\nwill display each explicit level element in a hierarchical key for each\ncolumn. Defaults to pandas.options.styler.sparse.columns value.\n\nNew in version 1.4.0.\n\n"}, {"param_name": "bold_headers", "param_type": "bool, optional", "param_desc": "Adds “font-weight: bold;” as a CSS property to table style header cells.\n\nNew in version 1.4.0.\n\n"}, {"param_name": "caption", "param_type": "str, optional", "param_desc": "Set, or overwrite, the caption on Styler before rendering.\n\nNew in version 1.4.0.\n\n"}, {"param_name": "max_rows", "param_type": "int, optional", "param_desc": "The maximum number of rows that will be rendered. Defaults to\npandas.options.styler.render.max_rows/max_columns.\n\nNew in version 1.4.0.\n\n"}, {"param_name": "max_columns", "param_type": "int, optional", "param_desc": "The maximum number of columns that will be rendered. Defaults to\npandas.options.styler.render.max_columns, which is None.\nRows and columns may be reduced if the number of total elements is\nlarge. This value is set to pandas.options.styler.render.max_elements,\nwhich is 262144 (18 bit browser rendering).\n\nNew in version 1.4.0.\n\n"}, {"param_name": "encoding", "param_type": "str, optional", "param_desc": "Character encoding setting for file output (and meta tags if available).\nDefaults to pandas.options.styler.render.encoding value of “utf-8”.\n"}, {"param_name": "doctype_html", "param_type": "bool, default False", "param_desc": "Whether to output a fully structured HTML file including all\nHTML elements, or just the core <style> and <table> elements.\n"}, {"param_name": "exclude_styles", "param_type": "bool, default False", "param_desc": "Whether to include the <style> element and all associated element\nclass and id identifiers, or solely the <table> element without\nstyling identifiers.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_html.html#pandas.io.formats.style.Styler.to_html"}, {"function_name": "pandas.DataFrame.to_html", "full_function": "DataFrame.to_html(buf=None, *, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, justify=None, max_rows=None, max_cols=None, show_dimensions=False, decimal='.', bold_rows=True, classes=None, escape=True, notebook=False, border=None, table_id=None, render_links=False, encoding=None)", "function_text": "Render a DataFrame as an HTML table.", "parameter_names_desc": [{"param_name": "buf", "param_type": "str, Path or StringIO-like, optional, default None", "param_desc": "Buffer to write to. If None, the output is returned as a string.\n"}, {"param_name": "columns", "param_type": "array-like, optional, default None", "param_desc": "The subset of columns to write. Writes all columns by default.\n"}, {"param_name": "col_space", "param_type": "str or int, list or dict of int or str, optional", "param_desc": "The minimum width of each column in CSS length units. An int is assumed to be px units..\n"}, {"param_name": "header", "param_type": "bool, optional", "param_desc": "Whether to print column labels, default True.\n"}, {"param_name": "index", "param_type": "bool, optional, default True", "param_desc": "Whether to print index (row) labels.\n"}, {"param_name": "na_rep", "param_type": "str, optional, default ‘NaN’", "param_desc": "String representation of NaN to use.\n"}, {"param_name": "formatters", "param_type": "list, tuple or dict of one-param. functions, optional", "param_desc": "Formatter functions to apply to columns’ elements by position or\nname.\nThe result of each function must be a unicode string.\nList/tuple must be of length equal to the number of columns.\n"}, {"param_name": "float_format", "param_type": "one-parameter function, optional, default None", "param_desc": "Formatter function to apply to columns’ elements if they are\nfloats. This function must return a unicode string and will be\napplied only to the non-NaN elements, with NaN being\nhandled by na_rep.\n"}, {"param_name": "sparsify", "param_type": "bool, optional, default True", "param_desc": "Set to False for a DataFrame with a hierarchical index to print\nevery multiindex key at each row.\n"}, {"param_name": "index_names", "param_type": "bool, optional, default True", "param_desc": "Prints the names of the indexes.\n"}, {"param_name": "justify", "param_type": "str, default None", "param_desc": "How to justify the column labels. If None uses the option from\nthe print configuration (controlled by set_option), ‘right’ out\nof the box. Valid values are\n\nleft\nright\ncenter\njustify\njustify-all\nstart\nend\ninherit\nmatch-parent\ninitial\nunset.\n\n"}, {"param_name": "max_rows", "param_type": "int, optional", "param_desc": "Maximum number of rows to display in the console.\n"}, {"param_name": "max_cols", "param_type": "int, optional", "param_desc": "Maximum number of columns to display in the console.\n"}, {"param_name": "show_dimensions", "param_type": "bool, default False", "param_desc": "Display DataFrame dimensions (number of rows by number of columns).\n"}, {"param_name": "decimal", "param_type": "str, default ‘.’", "param_desc": "Character recognized as decimal separator, e.g. ‘,’ in Europe.\n"}, {"param_name": "bold_rows", "param_type": "bool, default True", "param_desc": "Make the row labels bold in the output.\n"}, {"param_name": "classes", "param_type": "str or list or tuple, default None", "param_desc": "CSS class(es) to apply to the resulting html table.\n"}, {"param_name": "escape", "param_type": "bool, default True", "param_desc": "Convert the characters <, >, and & to HTML-safe sequences.\n"}, {"param_name": "notebook", "param_type": "{True, False}, default False", "param_desc": "Whether the generated HTML is for IPython Notebook.\n"}, {"param_name": "border", "param_type": "int", "param_desc": "A border=border attribute is included in the opening\n<table> tag. Default pd.options.display.html.border.\n"}, {"param_name": "table_id", "param_type": "str, optional", "param_desc": "A css id is included in the opening <table> tag if specified.\n"}, {"param_name": "render_links", "param_type": "bool, default False", "param_desc": "Convert URLs to HTML links.\n"}, {"param_name": "encoding", "param_type": "str, default “utf-8”", "param_desc": "Set character encoding.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_html.html#pandas.DataFrame.to_html"}]}, {"name": "XML", "url": "https://pandas.pydata.org/docs/reference/io.html#xml", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.read_xml.html#pandas.read_xml", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_xml.html#pandas.DataFrame.to_xml"], "function_definitions": [{"function_name": "pandas.read_xml", "full_function": "pandas.read_xml(path_or_buffer, *, xpath='./*', namespaces=None, elems_only=False, attrs_only=False, names=None, dtype=None, converters=None, parse_dates=None, encoding='utf-8', parser='lxml', stylesheet=None, iterparse=None, compression='infer', storage_options=None, dtype_backend=_NoDefault.no_default)", "function_text": "Read XML document into a DataFrame object.", "parameter_names_desc": [{"param_name": "path_or_buffer", "param_type": "str, path object, or file-like object", "param_desc": "String, path object (implementing os.PathLike[str]), or file-like\nobject implementing a read() function. The string can be any valid XML\nstring or a path. The string can further be a URL. Valid URL schemes\ninclude http, ftp, s3, and file.\n\nDeprecated since version 2.1.0: Passing xml literal strings is deprecated.\nWrap literal xml input in io.StringIO or io.BytesIO instead.\n\n"}, {"param_name": "xpath", "param_type": "str, optional, default ‘./*’", "param_desc": "The XPath to parse required set of nodes for migration to\nDataFrame.``XPath`` should return a collection of elements\nand not a single element. Note: The etree parser supports limited XPath\nexpressions. For more complex XPath, use lxml which requires\ninstallation.\n"}, {"param_name": "namespaces", "param_type": "dict, optional", "param_desc": "The namespaces defined in XML document as dicts with key being\nnamespace prefix and value the URI. There is no need to include all\nnamespaces in XML, only the ones used in xpath expression.\nNote: if XML document uses default namespace denoted as\nxmlns=’<URI>’ without a prefix, you must assign any temporary\nnamespace prefix such as ‘doc’ to the URI in order to parse\nunderlying nodes and/or attributes. For example,\nnamespaces = {\"doc\": \"https://example.com\"}\n\n\n"}, {"param_name": "elems_only", "param_type": "bool, optional, default False", "param_desc": "Parse only the child elements at the specified xpath. By default,\nall child elements and non-empty text nodes are returned.\n"}, {"param_name": "attrs_only", "param_type": "bool, optional, default False", "param_desc": "Parse only the attributes at the specified xpath.\nBy default, all attributes are returned.\n"}, {"param_name": "names", "param_type": "list-like, optional", "param_desc": "Column names for DataFrame of parsed XML data. Use this parameter to\nrename original element names and distinguish same named elements and\nattributes.\n"}, {"param_name": "dtype", "param_type": "Type name or dict of column -> type, optional", "param_desc": "Data type for data or columns. E.g. {‘a’: np.float64, ‘b’: np.int32,\n‘c’: ‘Int64’}\nUse str or object together with suitable na_values settings\nto preserve and not interpret dtype.\nIf converters are specified, they will be applied INSTEAD\nof dtype conversion.\n\nNew in version 1.5.0.\n\n"}, {"param_name": "converters", "param_type": "dict, optional", "param_desc": "Dict of functions for converting values in certain columns. Keys can either\nbe integers or column labels.\n\nNew in version 1.5.0.\n\n"}, {"param_name": "parse_dates", "param_type": "bool or list of int or names or list of lists or dict, default False", "param_desc": "Identifiers to parse index or columns to datetime. The behavior is as follows:\n\nboolean. If True -> try parsing the index.\nlist of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\neach as a separate date column.\nlist of lists. e.g. If [[1, 3]] -> combine columns 1 and 3 and parse as\na single date column.\ndict, e.g. {‘foo’ : [1, 3]} -> parse columns 1, 3 as date and call\nresult ‘foo’\n\n\nNew in version 1.5.0.\n\n"}, {"param_name": "encoding", "param_type": "str, optional, default ‘utf-8’", "param_desc": "Encoding of XML document.\n"}, {"param_name": "parser", "param_type": "{‘lxml’,’etree’}, default ‘lxml’", "param_desc": "Parser module to use for retrieval of data. Only ‘lxml’ and\n‘etree’ are supported. With ‘lxml’ more complex XPath searches\nand ability to use XSLT stylesheet are supported.\n"}, {"param_name": "stylesheet", "param_type": "str, path object or file-like object", "param_desc": "A URL, file-like object, or a raw string containing an XSLT script.\nThis stylesheet should flatten complex, deeply nested XML documents\nfor easier parsing. To use this feature you must have lxml module\ninstalled and specify ‘lxml’ as parser. The xpath must\nreference nodes of transformed XML document generated after XSLT\ntransformation and not the original XML document. Only XSLT 1.0\nscripts and not later versions is currently supported.\n"}, {"param_name": "iterparse", "param_type": "dict, optional", "param_desc": "The nodes or attributes to retrieve in iterparsing of XML document\nas a dict with key being the name of repeating element and value being\nlist of elements or attribute names that are descendants of the repeated\nelement. Note: If this option is used, it will replace xpath parsing\nand unlike xpath, descendants do not need to relate to each other but can\nexist any where in document under the repeating element. This memory-\nefficient method should be used for very large XML files (500MB, 1GB, or 5GB+).\nFor example,\niterparse = {\"row_element\": [\"child_elem\", \"attr\", \"grandchild_elem\"]}\n\n\n\nNew in version 1.5.0.\n\n"}, {"param_name": "compression", "param_type": "str or dict, default ‘infer’", "param_desc": "For on-the-fly decompression of on-disk data. If ‘infer’ and ‘path_or_buffer’ is\npath-like, then detect compression from the following extensions: ‘.gz’,\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\n(otherwise no compression).\nIf using ‘zip’ or ‘tar’, the ZIP file must contain only one data file to be read in.\nSet to None for no decompression.\nCan also be a dict with key 'method' set\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\nother key-value pairs are forwarded to\nzipfile.ZipFile, gzip.GzipFile,\nbz2.BZ2File, zstandard.ZstdDecompressor, lzma.LZMAFile or\ntarfile.TarFile, respectively.\nAs an example, the following could be passed for Zstandard decompression using a\ncustom compression dictionary:\ncompression={'method': 'zstd', 'dict_data': my_compression_dict}.\n\nNew in version 1.5.0: Added support for .tar files.\n\n\nChanged in version 1.4.0: Zstandard support.\n\n"}, {"param_name": "storage_options", "param_type": "dict, optional", "param_desc": "Extra options that make sense for a particular storage connection, e.g.\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\nare forwarded to urllib.request.Request as header options. For other\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\nforwarded to fsspec.open. Please see fsspec and urllib for more\ndetails, and for more examples on storage options refer here.\n"}, {"param_name": "dtype_backend", "param_type": "{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’", "param_desc": "Back-end data type applied to the resultant DataFrame\n(still experimental). Behaviour is as follows:\n\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\n(default).\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\nDataFrame.\n\n\nNew in version 2.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.read_xml.html#pandas.read_xml"}, {"function_name": "pandas.DataFrame.to_xml", "full_function": "DataFrame.to_xml(path_or_buffer=None, *, index=True, root_name='data', row_name='row', na_rep=None, attr_cols=None, elem_cols=None, namespaces=None, prefix=None, encoding='utf-8', xml_declaration=True, pretty_print=True, parser='lxml', stylesheet=None, compression='infer', storage_options=None)", "function_text": "Render a DataFrame to an XML document.", "parameter_names_desc": [{"param_name": "path_or_buffer", "param_type": "str, path object, file-like object, or None, default None", "param_desc": "String, path object (implementing os.PathLike[str]), or file-like\nobject implementing a write() function. If None, the result is returned\nas a string.\n"}, {"param_name": "index", "param_type": "bool, default True", "param_desc": "Whether to include index in XML document.\n"}, {"param_name": "root_name", "param_type": "str, default ‘data’", "param_desc": "The name of root element in XML document.\n"}, {"param_name": "row_name", "param_type": "str, default ‘row’", "param_desc": "The name of row element in XML document.\n"}, {"param_name": "na_rep", "param_type": "str, optional", "param_desc": "Missing data representation.\n"}, {"param_name": "attr_cols", "param_type": "list-like, optional", "param_desc": "List of columns to write as attributes in row element.\nHierarchical columns will be flattened with underscore\ndelimiting the different levels.\n"}, {"param_name": "elem_cols", "param_type": "list-like, optional", "param_desc": "List of columns to write as children in row element. By default,\nall columns output as children of row element. Hierarchical\ncolumns will be flattened with underscore delimiting the\ndifferent levels.\n"}, {"param_name": "namespaces", "param_type": "dict, optional", "param_desc": "All namespaces to be defined in root element. Keys of dict\nshould be prefix names and values of dict corresponding URIs.\nDefault namespaces should be given empty string key. For\nexample,\nnamespaces = {\"\": \"https://example.com\"}\n\n\n"}, {"param_name": "prefix", "param_type": "str, optional", "param_desc": "Namespace prefix to be used for every element and/or attribute\nin document. This should be one of the keys in namespaces\ndict.\n"}, {"param_name": "encoding", "param_type": "str, default ‘utf-8’", "param_desc": "Encoding of the resulting document.\n"}, {"param_name": "xml_declaration", "param_type": "bool, default True", "param_desc": "Whether to include the XML declaration at start of document.\n"}, {"param_name": "pretty_print", "param_type": "bool, default True", "param_desc": "Whether output should be pretty printed with indentation and\nline breaks.\n"}, {"param_name": "parser", "param_type": "{‘lxml’,’etree’}, default ‘lxml’", "param_desc": "Parser module to use for building of tree. Only ‘lxml’ and\n‘etree’ are supported. With ‘lxml’, the ability to use XSLT\nstylesheet is supported.\n"}, {"param_name": "stylesheet", "param_type": "str, path object or file-like object, optional", "param_desc": "A URL, file-like object, or a raw string containing an XSLT\nscript used to transform the raw XML output. Script should use\nlayout of elements and attributes from original output. This\nargument requires lxml to be installed. Only XSLT 1.0\nscripts and not later versions is currently supported.\n"}, {"param_name": "compression", "param_type": "str or dict, default ‘infer’", "param_desc": "For on-the-fly compression of the output data. If ‘infer’ and ‘path_or_buffer’ is\npath-like, then detect compression from the following extensions: ‘.gz’,\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\n(otherwise no compression).\nSet to None for no compression.\nCan also be a dict with key 'method' set\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\nother key-value pairs are forwarded to\nzipfile.ZipFile, gzip.GzipFile,\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\ntarfile.TarFile, respectively.\nAs an example, the following could be passed for faster compression and to create\na reproducible gzip archive:\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\n\nNew in version 1.5.0: Added support for .tar files.\n\n\nChanged in version 1.4.0: Zstandard support.\n\n"}, {"param_name": "storage_options", "param_type": "dict, optional", "param_desc": "Extra options that make sense for a particular storage connection, e.g.\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\nare forwarded to urllib.request.Request as header options. For other\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\nforwarded to fsspec.open. Please see fsspec and urllib for more\ndetails, and for more examples on storage options refer here.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_xml.html#pandas.DataFrame.to_xml"}]}, {"name": "Latex", "url": "https://pandas.pydata.org/docs/reference/io.html#latex", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_latex.html#pandas.DataFrame.to_latex", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_latex.html#pandas.io.formats.style.Styler.to_latex"], "function_definitions": [{"function_name": "pandas.DataFrame.to_latex", "full_function": "DataFrame.to_latex(buf=None, *, columns=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, bold_rows=False, column_format=None, longtable=None, escape=None, encoding=None, decimal='.', multicolumn=None, multicolumn_format=None, multirow=None, caption=None, label=None, position=None)", "function_text": "Render object to a LaTeX tabular, longtable, or nested table.", "parameter_names_desc": [{"param_name": "buf", "param_type": "str, Path or StringIO-like, optional, default None", "param_desc": "Buffer to write to. If None, the output is returned as a string.\n"}, {"param_name": "columns", "param_type": "list of label, optional", "param_desc": "The subset of columns to write. Writes all columns by default.\n"}, {"param_name": "header", "param_type": "bool or list of str, default True", "param_desc": "Write out the column names. If a list of strings is given,\nit is assumed to be aliases for the column names.\n"}, {"param_name": "index", "param_type": "bool, default True", "param_desc": "Write row names (index).\n"}, {"param_name": "na_rep", "param_type": "str, default ‘NaN’", "param_desc": "Missing data representation.\n"}, {"param_name": "formatters", "param_type": "list of functions or dict of {{str: function}}, optional", "param_desc": "Formatter functions to apply to columns’ elements by position or\nname. The result of each function must be a unicode string.\nList must be of length equal to the number of columns.\n"}, {"param_name": "float_format", "param_type": "one-parameter function or str, optional, default None", "param_desc": "Formatter for floating point numbers. For example\nfloat_format=\"%.2f\" and float_format=\"{{:0.2f}}\".format will\nboth result in 0.1234 being formatted as 0.12.\n"}, {"param_name": "sparsify", "param_type": "bool, optional", "param_desc": "Set to False for a DataFrame with a hierarchical index to print\nevery multiindex key at each row. By default, the value will be\nread from the config module.\n"}, {"param_name": "index_names", "param_type": "bool, default True", "param_desc": "Prints the names of the indexes.\n"}, {"param_name": "bold_rows", "param_type": "bool, default False", "param_desc": "Make the row labels bold in the output.\n"}, {"param_name": "column_format", "param_type": "str, optional", "param_desc": "The columns format as specified in LaTeX table format e.g. ‘rcl’ for 3\ncolumns. By default, ‘l’ will be used for all columns except\ncolumns of numbers, which default to ‘r’.\n"}, {"param_name": "longtable", "param_type": "bool, optional", "param_desc": "Use a longtable environment instead of tabular. Requires\nadding a usepackage{{longtable}} to your LaTeX preamble.\nBy default, the value will be read from the pandas config\nmodule, and set to True if the option styler.latex.environment is\n“longtable”.\n\nChanged in version 2.0.0: The pandas option affecting this argument has changed.\n\n"}, {"param_name": "escape", "param_type": "bool, optional", "param_desc": "By default, the value will be read from the pandas config\nmodule and set to True if the option styler.format.escape is\n“latex”. When set to False prevents from escaping latex special\ncharacters in column names.\n\nChanged in version 2.0.0: The pandas option affecting this argument has changed, as has the\ndefault value to False.\n\n"}, {"param_name": "encoding", "param_type": "str, optional", "param_desc": "A string representing the encoding to use in the output file,\ndefaults to ‘utf-8’.\n"}, {"param_name": "decimal", "param_type": "str, default ‘.’", "param_desc": "Character recognized as decimal separator, e.g. ‘,’ in Europe.\n"}, {"param_name": "multicolumn", "param_type": "bool, default True", "param_desc": "Use multicolumn to enhance MultiIndex columns.\nThe default will be read from the config module, and is set\nas the option styler.sparse.columns.\n\nChanged in version 2.0.0: The pandas option affecting this argument has changed.\n\n"}, {"param_name": "multicolumn_format", "param_type": "str, default ‘r’", "param_desc": "The alignment for multicolumns, similar to column_format\nThe default will be read from the config module, and is set as the option\nstyler.latex.multicol_align.\n\nChanged in version 2.0.0: The pandas option affecting this argument has changed, as has the\ndefault value to “r”.\n\n"}, {"param_name": "multirow", "param_type": "bool, default True", "param_desc": "Use multirow to enhance MultiIndex rows. Requires adding a\nusepackage{{multirow}} to your LaTeX preamble. Will print\ncentered labels (instead of top-aligned) across the contained\nrows, separating groups via clines. The default will be read\nfrom the pandas config module, and is set as the option\nstyler.sparse.index.\n\nChanged in version 2.0.0: The pandas option affecting this argument has changed, as has the\ndefault value to True.\n\n"}, {"param_name": "caption", "param_type": "str or tuple, optional", "param_desc": "Tuple (full_caption, short_caption),\nwhich results in \\caption[short_caption]{{full_caption}};\nif a single string is passed, no short caption will be set.\n"}, {"param_name": "label", "param_type": "str, optional", "param_desc": "The LaTeX label to be placed inside \\label{{}} in the output.\nThis is used with \\ref{{}} in the main .tex file.\n"}, {"param_name": "position", "param_type": "str, optional", "param_desc": "The LaTeX positional argument for tables, to be placed after\n\\begin{{}} in the output.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_latex.html#pandas.DataFrame.to_latex"}, {"function_name": "pandas.io.formats.style.Styler.to_latex", "full_function": "Styler.to_latex(buf=None, *, column_format=None, position=None, position_float=None, hrules=None, clines=None, label=None, caption=None, sparse_index=None, sparse_columns=None, multirow_align=None, multicol_align=None, siunitx=False, environment=None, encoding=None, convert_css=False)", "function_text": "Write Styler to a file, buffer or string in LaTeX format.", "parameter_names_desc": [{"param_name": "buf", "param_type": "str, path object, file-like object, or None, default None", "param_desc": "String, path object (implementing os.PathLike[str]), or file-like\nobject implementing a string write() function. If None, the result is\nreturned as a string.\n"}, {"param_name": "column_format", "param_type": "str, optional", "param_desc": "The LaTeX column specification placed in location:\n\\begin{tabular}{<column_format>}\nDefaults to ‘l’ for index and\nnon-numeric data columns, and, for numeric data columns,\nto ‘r’ by default, or ‘S’ if siunitx is True.\n"}, {"param_name": "position", "param_type": "str, optional", "param_desc": "The LaTeX positional argument (e.g. ‘h!’) for tables, placed in location:\n\\\\begin{table}[<position>].\n"}, {"param_name": "position_float", "param_type": "{“centering”, “raggedleft”, “raggedright”}, optional", "param_desc": "The LaTeX float command placed in location:\n\\begin{table}[<position>]\n\\<position_float>\nCannot be used if environment is “longtable”.\n"}, {"param_name": "hrules", "param_type": "bool", "param_desc": "Set to True to add \\toprule, \\midrule and \\bottomrule from the\n{booktabs} LaTeX package.\nDefaults to pandas.options.styler.latex.hrules, which is False.\n\nChanged in version 1.4.0.\n\n"}, {"param_name": "clines", "param_type": "str, optional", "param_desc": "Use to control adding \\cline commands for the index labels separation.\nPossible values are:\n\n\nNone: no cline commands are added (default).\n“all;data”: a cline is added for every index value extending the\nwidth of the table, including data entries.\n“all;index”: as above with lines extending only the width of the\nindex entries.\n“skip-last;data”: a cline is added for each index value except the\nlast level (which is never sparsified), extending the widtn of the\ntable.\n“skip-last;index”: as above with lines extending only the width of the\nindex entries.\n\n\n\nNew in version 1.4.0.\n\n"}, {"param_name": "label", "param_type": "str, optional", "param_desc": "The LaTeX label included as: \\label{<label>}.\nThis is used with \\ref{<label>} in the main .tex file.\n"}, {"param_name": "caption", "param_type": "str, tuple, optional", "param_desc": "If string, the LaTeX table caption included as: \\caption{<caption>}.\nIf tuple, i.e (“full caption”, “short caption”), the caption included\nas: \\caption[<caption[1]>]{<caption[0]>}.\n"}, {"param_name": "sparse_index", "param_type": "bool, optional", "param_desc": "Whether to sparsify the display of a hierarchical index. Setting to False\nwill display each explicit level element in a hierarchical key for each row.\nDefaults to pandas.options.styler.sparse.index, which is True.\n"}, {"param_name": "sparse_columns", "param_type": "bool, optional", "param_desc": "Whether to sparsify the display of a hierarchical index. Setting to False\nwill display each explicit level element in a hierarchical key for each\ncolumn. Defaults to pandas.options.styler.sparse.columns, which\nis True.\n"}, {"param_name": "multirow_align", "param_type": "{“c”, “t”, “b”, “naive”}, optional", "param_desc": "If sparsifying hierarchical MultiIndexes whether to align text centrally,\nat the top or bottom using the multirow package. If not given defaults to\npandas.options.styler.latex.multirow_align, which is “c”.\nIf “naive” is given renders without multirow.\n\nChanged in version 1.4.0.\n\n"}, {"param_name": "multicol_align", "param_type": "{“r”, “c”, “l”, “naive-l”, “naive-r”}, optional", "param_desc": "If sparsifying hierarchical MultiIndex columns whether to align text at\nthe left, centrally, or at the right. If not given defaults to\npandas.options.styler.latex.multicol_align, which is “r”.\nIf a naive option is given renders without multicol.\nPipe decorators can also be added to non-naive values to draw vertical\nrules, e.g. “|r” will draw a rule on the left side of right aligned merged\ncells.\n\nChanged in version 1.4.0.\n\n"}, {"param_name": "siunitx", "param_type": "bool, default False", "param_desc": "Set to True to structure LaTeX compatible with the {siunitx} package.\n"}, {"param_name": "environment", "param_type": "str, optional", "param_desc": "If given, the environment that will replace ‘table’ in \\\\begin{table}.\nIf ‘longtable’ is specified then a more suitable template is\nrendered. If not given defaults to\npandas.options.styler.latex.environment, which is None.\n\nNew in version 1.4.0.\n\n"}, {"param_name": "encoding", "param_type": "str, optional", "param_desc": "Character encoding setting. Defaults\nto pandas.options.styler.render.encoding, which is “utf-8”.\n"}, {"param_name": "convert_css", "param_type": "bool, default False", "param_desc": "Convert simple cell-styles from CSS to LaTeX format. Any CSS not found in\nconversion table is dropped. A style can be forced by adding option\n–latex. See notes.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_latex.html#pandas.io.formats.style.Styler.to_latex"}]}, {"name": "HDFStore: PyTables (HDF5)", "url": "https://pandas.pydata.org/docs/reference/io.html#hdfstore-pytables-hdf5", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.read_hdf.html#pandas.read_hdf", "https://pandas.pydata.org/docs/reference/api/pandas.HDFStore.append.html#pandas.HDFStore.append", "https://pandas.pydata.org/docs/reference/api/pandas.HDFStore.select.html#pandas.HDFStore.select", "https://pandas.pydata.org/docs/reference/api/pandas.HDFStore.keys.html#pandas.HDFStore.keys", "https://pandas.pydata.org/docs/reference/api/pandas.HDFStore.walk.html#pandas.HDFStore.walk", "https://pandas.pydata.org/docs/reference/api/pandas.HDFStore.put.html#pandas.HDFStore.put", "https://pandas.pydata.org/docs/reference/api/pandas.HDFStore.get.html#pandas.HDFStore.get", "https://pandas.pydata.org/docs/reference/api/pandas.HDFStore.info.html#pandas.HDFStore.info", "https://pandas.pydata.org/docs/reference/api/pandas.HDFStore.groups.html#pandas.HDFStore.groups"], "function_definitions": [{"function_name": "pandas.read_hdf", "full_function": "pandas.read_hdf(path_or_buf, key=None, mode='r', errors='strict', where=None, start=None, stop=None, columns=None, iterator=False, chunksize=None, **kwargs)", "function_text": "Read from the store, close it if we opened it.", "parameter_names_desc": [{"param_name": "path_or_buf", "param_type": "str, path object, pandas.HDFStore", "param_desc": "Any valid string path is acceptable. Only supports the local file system,\nremote URLs and file-like objects are not supported.\nIf you want to pass in a path object, pandas accepts any\nos.PathLike.\nAlternatively, pandas accepts an open pandas.HDFStore object.\n"}, {"param_name": "key", "param_type": "object, optional", "param_desc": "The group identifier in the store. Can be omitted if the HDF file\ncontains a single pandas object.\n"}, {"param_name": "mode", "param_type": "{‘r’, ‘r+’, ‘a’}, default ‘r’", "param_desc": "Mode to use when opening the file. Ignored if path_or_buf is a\npandas.HDFStore. Default is ‘r’.\n"}, {"param_name": "errors", "param_type": "str, default ‘strict’", "param_desc": "Specifies how encoding and decoding errors are to be handled.\nSee the errors argument for open() for a full list\nof options.\n"}, {"param_name": "where", "param_type": "list, optional", "param_desc": "A list of Term (or convertible) objects.\n"}, {"param_name": "start", "param_type": "int, optional", "param_desc": "Row number to start selection.\n"}, {"param_name": "stop", "param_type": "int, optional", "param_desc": "Row number to stop selection.\n"}, {"param_name": "columns", "param_type": "list, optional", "param_desc": "A list of columns names to return.\n"}, {"param_name": "iterator", "param_type": "bool, optional", "param_desc": "Return an iterator object.\n"}, {"param_name": "chunksize", "param_type": "int, optional", "param_desc": "Number of rows to include in an iteration when using an iterator.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.read_hdf.html#pandas.read_hdf"}, {"function_name": "pandas.HDFStore.append", "full_function": "HDFStore.append(key, value, format=None, axes=None, index=True, append=True, complib=None, complevel=None, columns=None, min_itemsize=None, nan_rep=None, chunksize=None, expectedrows=None, dropna=None, data_columns=None, encoding=None, errors='strict')", "function_text": "Append to Table in file.", "parameter_names_desc": [{"param_name": "key", "param_type": "str", "param_desc": ""}, {"param_name": "value", "param_type": "{Series, DataFrame}", "param_desc": ""}, {"param_name": "format", "param_type": "‘table’ is the default", "param_desc": "Format to use when storing object in HDFStore. Value can be one of:\n\n'table'Table format. Write as a PyTables Table structure which may perform\nworse but allow more flexible operations like searching / selecting\nsubsets of the data.\n\n\n"}, {"param_name": "index", "param_type": "bool, default True", "param_desc": "Write DataFrame index as a column.\n"}, {"param_name": "append", "param_type": "bool, default True", "param_desc": "Append the input data to the existing.\n"}, {"param_name": "data_columns", "param_type": "list of columns, or True, default None", "param_desc": "List of columns to create as indexed data columns for on-disk\nqueries, or True to use all columns. By default only the axes\nof the object are indexed. See here.\n"}, {"param_name": "min_itemsize", "param_type": "dict of columns that specify minimum str sizes", "param_desc": ""}, {"param_name": "nan_rep", "param_type": "str to use as str nan representation", "param_desc": ""}, {"param_name": "chunksize", "param_type": "size to chunk the writing", "param_desc": ""}, {"param_name": "expectedrows", "param_type": "expected TOTAL row size of this table", "param_desc": ""}, {"param_name": "encoding", "param_type": "default None, provide an encoding for str", "param_desc": ""}, {"param_name": "dropna", "param_type": "bool, default False, optional", "param_desc": "Do not write an ALL nan row to the store settable\nby the option ‘io.hdf.dropna_table’.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.HDFStore.append.html#pandas.HDFStore.append"}, {"function_name": "pandas.HDFStore.select", "full_function": "HDFStore.select(key, where=None, start=None, stop=None, columns=None, iterator=False, chunksize=None, auto_close=False)", "function_text": "Retrieve pandas object stored in file, optionally based on where criteria.", "parameter_names_desc": [{"param_name": "key", "param_type": "str", "param_desc": "Object being retrieved from file.\n"}, {"param_name": "where", "param_type": "list or None", "param_desc": "List of Term (or convertible) objects, optional.\n"}, {"param_name": "start", "param_type": "int or None", "param_desc": "Row number to start selection.\n"}, {"param_name": "stop", "param_type": "int, default None", "param_desc": "Row number to stop selection.\n"}, {"param_name": "columns", "param_type": "list or None", "param_desc": "A list of columns that if not None, will limit the return columns.\n"}, {"param_name": "iterator", "param_type": "bool or False", "param_desc": "Returns an iterator.\n"}, {"param_name": "chunksize", "param_type": "int or None", "param_desc": "Number or rows to include in iteration, return an iterator.\n"}, {"param_name": "auto_close", "param_type": "bool or False", "param_desc": "Should automatically close the store when finished.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.HDFStore.select.html#pandas.HDFStore.select"}, {"function_name": "pandas.HDFStore.keys", "full_function": "HDFStore.keys(include='pandas')", "function_text": "Return a list of keys corresponding to objects stored in HDFStore.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.HDFStore.keys.html#pandas.HDFStore.keys"}, {"function_name": "pandas.HDFStore.walk", "full_function": "HDFStore.walk(where='/')", "function_text": "Walk the pytables group hierarchy for pandas objects.", "parameter_names_desc": [{"param_name": "where", "param_type": "str, default “/”", "param_desc": "Group where to start walking.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.HDFStore.walk.html#pandas.HDFStore.walk"}, {"function_name": "pandas.HDFStore.put", "full_function": "HDFStore.put(key, value, format=None, index=True, append=False, complib=None, complevel=None, min_itemsize=None, nan_rep=None, data_columns=None, encoding=None, errors='strict', track_times=True, dropna=False)", "function_text": "Store object in HDFStore.", "parameter_names_desc": [{"param_name": "key", "param_type": "str", "param_desc": ""}, {"param_name": "value", "param_type": "{Series, DataFrame}", "param_desc": ""}, {"param_name": "format", "param_type": "‘fixed(f)|table(t)’, default is ‘fixed’", "param_desc": "Format to use when storing object in HDFStore. Value can be one of:\n\n'fixed'Fixed format. Fast writing/reading. Not-appendable, nor searchable.\n\n'table'Table format. Write as a PyTables Table structure which may perform\nworse but allow more flexible operations like searching / selecting\nsubsets of the data.\n\n\n"}, {"param_name": "index", "param_type": "bool, default True", "param_desc": "Write DataFrame index as a column.\n"}, {"param_name": "append", "param_type": "bool, default False", "param_desc": "This will force Table format, append the input data to the existing.\n"}, {"param_name": "data_columns", "param_type": "list of columns or True, default None", "param_desc": "List of columns to create as data columns, or True to use all columns.\nSee here.\n"}, {"param_name": "encoding", "param_type": "str, default None", "param_desc": "Provide an encoding for strings.\n"}, {"param_name": "track_times", "param_type": "bool, default True", "param_desc": "Parameter is propagated to ‘create_table’ method of ‘PyTables’.\nIf set to False it enables to have the same h5 files (same hashes)\nindependent on creation time.\n"}, {"param_name": "dropna", "param_type": "bool, default False, optional", "param_desc": "Remove missing values.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.HDFStore.put.html#pandas.HDFStore.put"}, {"function_name": "pandas.HDFStore.get", "full_function": "HDFStore.get(key)", "function_text": "Retrieve pandas object stored in file.", "parameter_names_desc": [{"param_name": "key", "param_type": "str", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.HDFStore.get.html#pandas.HDFStore.get"}, {"function_name": "pandas.HDFStore.info", "full_function": "HDFStore.info()", "function_text": "Print detailed information on the store.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.HDFStore.info.html#pandas.HDFStore.info"}, {"function_name": "pandas.HDFStore.groups", "full_function": "HDFStore.groups()", "function_text": "Return a list of all the top-level nodes.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.HDFStore.groups.html#pandas.HDFStore.groups"}]}, {"name": "Feather", "url": "https://pandas.pydata.org/docs/reference/io.html#feather", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.read_feather.html#pandas.read_feather", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_feather.html#pandas.DataFrame.to_feather"], "function_definitions": [{"function_name": "pandas.read_feather", "full_function": "pandas.read_feather(path, columns=None, use_threads=True, storage_options=None, dtype_backend=_NoDefault.no_default)", "function_text": "Load a feather-format object from the file path.", "parameter_names_desc": [{"param_name": "path", "param_type": "str, path object, or file-like object", "param_desc": "String, path object (implementing os.PathLike[str]), or file-like\nobject implementing a binary read() function. The string could be a URL.\nValid URL schemes include http, ftp, s3, and file. For file URLs, a host is\nexpected. A local file could be: file://localhost/path/to/table.feather.\n"}, {"param_name": "columns", "param_type": "sequence, default None", "param_desc": "If not provided, all columns are read.\n"}, {"param_name": "use_threads", "param_type": "bool, default True", "param_desc": "Whether to parallelize reading using multiple threads.\n"}, {"param_name": "storage_options", "param_type": "dict, optional", "param_desc": "Extra options that make sense for a particular storage connection, e.g.\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\nare forwarded to urllib.request.Request as header options. For other\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\nforwarded to fsspec.open. Please see fsspec and urllib for more\ndetails, and for more examples on storage options refer here.\n"}, {"param_name": "dtype_backend", "param_type": "{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’", "param_desc": "Back-end data type applied to the resultant DataFrame\n(still experimental). Behaviour is as follows:\n\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\n(default).\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\nDataFrame.\n\n\nNew in version 2.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.read_feather.html#pandas.read_feather"}, {"function_name": "pandas.DataFrame.to_feather", "full_function": "DataFrame.to_feather(path, **kwargs)", "function_text": "Write a DataFrame to the binary Feather format.", "parameter_names_desc": [{"param_name": "path", "param_type": "str, path object, file-like object", "param_desc": "String, path object (implementing os.PathLike[str]), or file-like\nobject implementing a binary write() function. If a string or a path,\nit will be used as Root Directory path when writing a partitioned dataset.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_feather.html#pandas.DataFrame.to_feather"}]}, {"name": "Parquet", "url": "https://pandas.pydata.org/docs/reference/io.html#parquet", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.read_parquet.html#pandas.read_parquet", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_parquet.html#pandas.DataFrame.to_parquet"], "function_definitions": [{"function_name": "pandas.read_parquet", "full_function": "pandas.read_parquet(path, engine='auto', columns=None, storage_options=None, use_nullable_dtypes=_NoDefault.no_default, dtype_backend=_NoDefault.no_default, filesystem=None, filters=None, **kwargs)", "function_text": "Load a parquet object from the file path, returning a DataFrame.", "parameter_names_desc": [{"param_name": "path", "param_type": "str, path object or file-like object", "param_desc": "String, path object (implementing os.PathLike[str]), or file-like\nobject implementing a binary read() function.\nThe string could be a URL. Valid URL schemes include http, ftp, s3,\ngs, and file. For file URLs, a host is expected. A local file could be:\nfile://localhost/path/to/table.parquet.\nA file URL can also be a path to a directory that contains multiple\npartitioned parquet files. Both pyarrow and fastparquet support\npaths to directories as well as file URLs. A directory path could be:\nfile://localhost/path/to/tables or s3://bucket/partition_dir.\n"}, {"param_name": "engine", "param_type": "{‘auto’, ‘pyarrow’, ‘fastparquet’}, default ‘auto’", "param_desc": "Parquet library to use. If ‘auto’, then the option\nio.parquet.engine is used. The default io.parquet.engine\nbehavior is to try ‘pyarrow’, falling back to ‘fastparquet’ if\n‘pyarrow’ is unavailable.\nWhen using the 'pyarrow' engine and no storage options are provided\nand a filesystem is implemented by both pyarrow.fs and fsspec\n(e.g. “s3://”), then the pyarrow.fs filesystem is attempted first.\nUse the filesystem keyword with an instantiated fsspec filesystem\nif you wish to use its implementation.\n"}, {"param_name": "columns", "param_type": "list, default=None", "param_desc": "If not None, only these columns will be read from the file.\n"}, {"param_name": "storage_options", "param_type": "dict, optional", "param_desc": "Extra options that make sense for a particular storage connection, e.g.\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\nare forwarded to urllib.request.Request as header options. For other\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\nforwarded to fsspec.open. Please see fsspec and urllib for more\ndetails, and for more examples on storage options refer here.\n\nNew in version 1.3.0.\n\n"}, {"param_name": "use_nullable_dtypes", "param_type": "bool, default False", "param_desc": "If True, use dtypes that use pd.NA as missing value indicator\nfor the resulting DataFrame. (only applicable for the pyarrow\nengine)\nAs new dtypes are added that support pd.NA in the future, the\noutput with this option will change to use those dtypes.\nNote: this is an experimental option, and behaviour (e.g. additional\nsupport dtypes) may change without notice.\n\nDeprecated since version 2.0.\n\n"}, {"param_name": "dtype_backend", "param_type": "{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’", "param_desc": "Back-end data type applied to the resultant DataFrame\n(still experimental). Behaviour is as follows:\n\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\n(default).\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\nDataFrame.\n\n\nNew in version 2.0.\n\n"}, {"param_name": "filesystem", "param_type": "fsspec or pyarrow filesystem, default None", "param_desc": "Filesystem object to use when reading the parquet file. Only implemented\nfor engine=\"pyarrow\".\n\nNew in version 2.1.0.\n\n"}, {"param_name": "filters", "param_type": "List[Tuple] or List[List[Tuple]], default None", "param_desc": "To filter out data.\nFilter syntax: [[(column, op, val), …],…]\nwhere op is [==, =, >, >=, <, <=, !=, in, not in]\nThe innermost tuples are transposed into a set of filters applied\nthrough an AND operation.\nThe outer list combines these sets of filters through an OR\noperation.\nA single list of tuples can also be used, meaning that no OR\noperation between set of filters is to be conducted.\nUsing this argument will NOT result in row-wise filtering of the final\npartitions unless engine=\"pyarrow\" is also specified. For\nother engines, filtering is only performed at the partition level, that is,\nto prevent the loading of some row-groups and/or files.\n\nNew in version 2.1.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.read_parquet.html#pandas.read_parquet"}, {"function_name": "pandas.DataFrame.to_parquet", "full_function": "DataFrame.to_parquet(path=None, *, engine='auto', compression='snappy', index=None, partition_cols=None, storage_options=None, **kwargs)", "function_text": "Write a DataFrame to the binary parquet format.", "parameter_names_desc": [{"param_name": "path", "param_type": "str, path object, file-like object, or None, default None", "param_desc": "String, path object (implementing os.PathLike[str]), or file-like\nobject implementing a binary write() function. If None, the result is\nreturned as bytes. If a string or path, it will be used as Root Directory\npath when writing a partitioned dataset.\n"}, {"param_name": "engine", "param_type": "{‘auto’, ‘pyarrow’, ‘fastparquet’}, default ‘auto’", "param_desc": "Parquet library to use. If ‘auto’, then the option\nio.parquet.engine is used. The default io.parquet.engine\nbehavior is to try ‘pyarrow’, falling back to ‘fastparquet’ if\n‘pyarrow’ is unavailable.\n"}, {"param_name": "compression", "param_type": "str or None, default ‘snappy’", "param_desc": "Name of the compression to use. Use None for no compression.\nSupported options: ‘snappy’, ‘gzip’, ‘brotli’, ‘lz4’, ‘zstd’.\n"}, {"param_name": "index", "param_type": "bool, default None", "param_desc": "If True, include the dataframe’s index(es) in the file output.\nIf False, they will not be written to the file.\nIf None, similar to True the dataframe’s index(es)\nwill be saved. However, instead of being saved as values,\nthe RangeIndex will be stored as a range in the metadata so it\ndoesn’t require much space and is faster. Other indexes will\nbe included as columns in the file output.\n"}, {"param_name": "partition_cols", "param_type": "list, optional, default None", "param_desc": "Column names by which to partition the dataset.\nColumns are partitioned in the order they are given.\nMust be None if path is not a string.\n"}, {"param_name": "storage_options", "param_type": "dict, optional", "param_desc": "Extra options that make sense for a particular storage connection, e.g.\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\nare forwarded to urllib.request.Request as header options. For other\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\nforwarded to fsspec.open. Please see fsspec and urllib for more\ndetails, and for more examples on storage options refer here.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_parquet.html#pandas.DataFrame.to_parquet"}]}, {"name": "ORC", "url": "https://pandas.pydata.org/docs/reference/io.html#orc", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.read_orc.html#pandas.read_orc", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_orc.html#pandas.DataFrame.to_orc"], "function_definitions": [{"function_name": "pandas.read_orc", "full_function": "pandas.read_orc(path, columns=None, dtype_backend=_NoDefault.no_default, filesystem=None, **kwargs)", "function_text": "Load an ORC object from the file path, returning a DataFrame.", "parameter_names_desc": [{"param_name": "path", "param_type": "str, path object, or file-like object", "param_desc": "String, path object (implementing os.PathLike[str]), or file-like\nobject implementing a binary read() function. The string could be a URL.\nValid URL schemes include http, ftp, s3, and file. For file URLs, a host is\nexpected. A local file could be:\nfile://localhost/path/to/table.orc.\n"}, {"param_name": "columns", "param_type": "list, default None", "param_desc": "If not None, only these columns will be read from the file.\nOutput always follows the ordering of the file and not the columns list.\nThis mirrors the original behaviour of\npyarrow.orc.ORCFile.read().\n"}, {"param_name": "dtype_backend", "param_type": "{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’", "param_desc": "Back-end data type applied to the resultant DataFrame\n(still experimental). Behaviour is as follows:\n\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\n(default).\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\nDataFrame.\n\n\nNew in version 2.0.\n\n"}, {"param_name": "filesystem", "param_type": "fsspec or pyarrow filesystem, default None", "param_desc": "Filesystem object to use when reading the parquet file.\n\nNew in version 2.1.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.read_orc.html#pandas.read_orc"}, {"function_name": "pandas.DataFrame.to_orc", "full_function": "DataFrame.to_orc(path=None, *, engine='pyarrow', index=None, engine_kwargs=None)", "function_text": "Write a DataFrame to the ORC format.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_orc.html#pandas.DataFrame.to_orc"}]}, {"name": "SAS", "url": "https://pandas.pydata.org/docs/reference/io.html#sas", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.read_sas.html#pandas.read_sas"], "function_definitions": [{"function_name": "pandas.read_sas", "full_function": "pandas.read_sas(filepath_or_buffer, *, format=None, index=None, encoding=None, chunksize=None, iterator=False, compression='infer')", "function_text": "Read SAS files stored as either XPORT or SAS7BDAT format files.", "parameter_names_desc": [{"param_name": "filepath_or_buffer", "param_type": "str, path object, or file-like object", "param_desc": "String, path object (implementing os.PathLike[str]), or file-like\nobject implementing a binary read() function. The string could be a URL.\nValid URL schemes include http, ftp, s3, and file. For file URLs, a host is\nexpected. A local file could be:\nfile://localhost/path/to/table.sas7bdat.\n"}, {"param_name": "format", "param_type": "str {‘xport’, ‘sas7bdat’} or None", "param_desc": "If None, file format is inferred from file extension. If ‘xport’ or\n‘sas7bdat’, uses the corresponding format.\n"}, {"param_name": "index", "param_type": "identifier of index column, defaults to None", "param_desc": "Identifier of column that should be used as index of the DataFrame.\n"}, {"param_name": "encoding", "param_type": "str, default is None", "param_desc": "Encoding for text data. If None, text data are stored as raw bytes.\n"}, {"param_name": "chunksize", "param_type": "int", "param_desc": "Read file chunksize lines at a time, returns iterator.\n"}, {"param_name": "iterator", "param_type": "bool, defaults to False", "param_desc": "If True, returns an iterator for reading the file incrementally.\n"}, {"param_name": "compression", "param_type": "str or dict, default ‘infer’", "param_desc": "For on-the-fly decompression of on-disk data. If ‘infer’ and ‘filepath_or_buffer’ is\npath-like, then detect compression from the following extensions: ‘.gz’,\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\n(otherwise no compression).\nIf using ‘zip’ or ‘tar’, the ZIP file must contain only one data file to be read in.\nSet to None for no decompression.\nCan also be a dict with key 'method' set\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\nother key-value pairs are forwarded to\nzipfile.ZipFile, gzip.GzipFile,\nbz2.BZ2File, zstandard.ZstdDecompressor, lzma.LZMAFile or\ntarfile.TarFile, respectively.\nAs an example, the following could be passed for Zstandard decompression using a\ncustom compression dictionary:\ncompression={'method': 'zstd', 'dict_data': my_compression_dict}.\n\nNew in version 1.5.0: Added support for .tar files.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.read_sas.html#pandas.read_sas"}]}, {"name": "SPSS", "url": "https://pandas.pydata.org/docs/reference/io.html#spss", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.read_spss.html#pandas.read_spss"], "function_definitions": [{"function_name": "pandas.read_spss", "full_function": "pandas.read_spss(path, usecols=None, convert_categoricals=True, dtype_backend=_NoDefault.no_default)", "function_text": "Load an SPSS file from the file path, returning a DataFrame.", "parameter_names_desc": [{"param_name": "path", "param_type": "str or Path", "param_desc": "File path.\n"}, {"param_name": "usecols", "param_type": "list-like, optional", "param_desc": "Return a subset of the columns. If None, return all columns.\n"}, {"param_name": "convert_categoricals", "param_type": "bool, default is True", "param_desc": "Convert categorical columns into pd.Categorical.\n"}, {"param_name": "dtype_backend", "param_type": "{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’", "param_desc": "Back-end data type applied to the resultant DataFrame\n(still experimental). Behaviour is as follows:\n\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\n(default).\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\nDataFrame.\n\n\nNew in version 2.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.read_spss.html#pandas.read_spss"}]}, {"name": "SQL", "url": "https://pandas.pydata.org/docs/reference/io.html#sql", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.read_sql_table.html#pandas.read_sql_table", "https://pandas.pydata.org/docs/reference/api/pandas.read_sql.html#pandas.read_sql", "https://pandas.pydata.org/docs/reference/api/pandas.read_sql_query.html#pandas.read_sql_query", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_sql.html#pandas.DataFrame.to_sql"], "function_definitions": [{"function_name": "pandas.read_sql_table", "full_function": "pandas.read_sql_table(table_name, con, schema=None, index_col=None, coerce_float=True, parse_dates=None, columns=None, chunksize=None, dtype_backend=_NoDefault.no_default)", "function_text": "Read SQL database table into a DataFrame.", "parameter_names_desc": [{"param_name": "table_name", "param_type": "str", "param_desc": "Name of SQL table in database.\n"}, {"param_name": "con", "param_type": "SQLAlchemy connectable or str", "param_desc": "A database URI could be provided as str.\nSQLite DBAPI connection mode not supported.\n"}, {"param_name": "schema", "param_type": "str, default None", "param_desc": "Name of SQL schema in database to query (if database flavor\nsupports this). Uses default schema if None (default).\n"}, {"param_name": "index_col", "param_type": "str or list of str, optional, default: None", "param_desc": "Column(s) to set as index(MultiIndex).\n"}, {"param_name": "coerce_float", "param_type": "bool, default True", "param_desc": "Attempts to convert values of non-string, non-numeric objects (like\ndecimal.Decimal) to floating point. Can result in loss of Precision.\n"}, {"param_name": "parse_dates", "param_type": "list or dict, default None", "param_desc": "\nList of column names to parse as dates.\nDict of {column_name: format string} where format string is\nstrftime compatible in case of parsing string times or is one of\n(D, s, ns, ms, us) in case of parsing integer timestamps.\nDict of {column_name: arg dict}, where the arg dict corresponds\nto the keyword arguments of pandas.to_datetime()\nEspecially useful with databases without native Datetime support,\nsuch as SQLite.\n\n"}, {"param_name": "columns", "param_type": "list, default None", "param_desc": "List of column names to select from SQL table.\n"}, {"param_name": "chunksize", "param_type": "int, default None", "param_desc": "If specified, returns an iterator where chunksize is the number of\nrows to include in each chunk.\n"}, {"param_name": "dtype_backend", "param_type": "{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’", "param_desc": "Back-end data type applied to the resultant DataFrame\n(still experimental). Behaviour is as follows:\n\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\n(default).\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\nDataFrame.\n\n\nNew in version 2.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.read_sql_table.html#pandas.read_sql_table"}, {"function_name": "pandas.read_sql", "full_function": "pandas.read_sql(sql, con, index_col=None, coerce_float=True, params=None, parse_dates=None, columns=None, chunksize=None, dtype_backend=_NoDefault.no_default, dtype=None)", "function_text": "Read SQL query or database table into a DataFrame.", "parameter_names_desc": [{"param_name": "sql", "param_type": "str or SQLAlchemy Selectable (select or text object)", "param_desc": "SQL query to be executed or a table name.\n"}, {"param_name": "con", "param_type": "ADBC Connection, SQLAlchemy connectable, str, or sqlite3 connection", "param_desc": "ADBC provides high performance I/O with native type support, where available.\nUsing SQLAlchemy makes it possible to use any DB supported by that\nlibrary. If a DBAPI2 object, only sqlite3 is supported. The user is responsible\nfor engine disposal and connection closure for the ADBC connection and\nSQLAlchemy connectable; str connections are closed automatically. See\nhere.\n"}, {"param_name": "index_col", "param_type": "str or list of str, optional, default: None", "param_desc": "Column(s) to set as index(MultiIndex).\n"}, {"param_name": "coerce_float", "param_type": "bool, default True", "param_desc": "Attempts to convert values of non-string, non-numeric objects (like\ndecimal.Decimal) to floating point, useful for SQL result sets.\n"}, {"param_name": "params", "param_type": "list, tuple or dict, optional, default: None", "param_desc": "List of parameters to pass to execute method. The syntax used\nto pass parameters is database driver dependent. Check your\ndatabase driver documentation for which of the five syntax styles,\ndescribed in PEP 249’s paramstyle, is supported.\nEg. for psycopg2, uses %(name)s so use params={‘name’ : ‘value’}.\n"}, {"param_name": "parse_dates", "param_type": "list or dict, default: None", "param_desc": "\nList of column names to parse as dates.\nDict of {column_name: format string} where format string is\nstrftime compatible in case of parsing string times, or is one of\n(D, s, ns, ms, us) in case of parsing integer timestamps.\nDict of {column_name: arg dict}, where the arg dict corresponds\nto the keyword arguments of pandas.to_datetime()\nEspecially useful with databases without native Datetime support,\nsuch as SQLite.\n\n"}, {"param_name": "columns", "param_type": "list, default: None", "param_desc": "List of column names to select from SQL table (only used when reading\na table).\n"}, {"param_name": "chunksize", "param_type": "int, default None", "param_desc": "If specified, return an iterator where chunksize is the\nnumber of rows to include in each chunk.\n"}, {"param_name": "dtype_backend", "param_type": "{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’", "param_desc": "Back-end data type applied to the resultant DataFrame\n(still experimental). Behaviour is as follows:\n\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\n(default).\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\nDataFrame.\n\n\nNew in version 2.0.\n\n"}, {"param_name": "dtype", "param_type": "Type name or dict of columns", "param_desc": "Data type for data or columns. E.g. np.float64 or\n{‘a’: np.float64, ‘b’: np.int32, ‘c’: ‘Int64’}.\nThe argument is ignored if a table is passed instead of a query.\n\nNew in version 2.0.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.read_sql.html#pandas.read_sql"}, {"function_name": "pandas.read_sql_query", "full_function": "pandas.read_sql_query(sql, con, index_col=None, coerce_float=True, params=None, parse_dates=None, chunksize=None, dtype=None, dtype_backend=_NoDefault.no_default)", "function_text": "Read SQL query into a DataFrame.", "parameter_names_desc": [{"param_name": "sql", "param_type": "str SQL query or SQLAlchemy Selectable (select or text object)", "param_desc": "SQL query to be executed.\n"}, {"param_name": "con", "param_type": "SQLAlchemy connectable, str, or sqlite3 connection", "param_desc": "Using SQLAlchemy makes it possible to use any DB supported by that\nlibrary. If a DBAPI2 object, only sqlite3 is supported.\n"}, {"param_name": "index_col", "param_type": "str or list of str, optional, default: None", "param_desc": "Column(s) to set as index(MultiIndex).\n"}, {"param_name": "coerce_float", "param_type": "bool, default True", "param_desc": "Attempts to convert values of non-string, non-numeric objects (like\ndecimal.Decimal) to floating point. Useful for SQL result sets.\n"}, {"param_name": "params", "param_type": "list, tuple or mapping, optional, default: None", "param_desc": "List of parameters to pass to execute method. The syntax used\nto pass parameters is database driver dependent. Check your\ndatabase driver documentation for which of the five syntax styles,\ndescribed in PEP 249’s paramstyle, is supported.\nEg. for psycopg2, uses %(name)s so use params={‘name’ : ‘value’}.\n"}, {"param_name": "parse_dates", "param_type": "list or dict, default: None", "param_desc": "\nList of column names to parse as dates.\nDict of {column_name: format string} where format string is\nstrftime compatible in case of parsing string times, or is one of\n(D, s, ns, ms, us) in case of parsing integer timestamps.\nDict of {column_name: arg dict}, where the arg dict corresponds\nto the keyword arguments of pandas.to_datetime()\nEspecially useful with databases without native Datetime support,\nsuch as SQLite.\n\n"}, {"param_name": "chunksize", "param_type": "int, default None", "param_desc": "If specified, return an iterator where chunksize is the number of\nrows to include in each chunk.\n"}, {"param_name": "dtype", "param_type": "Type name or dict of columns", "param_desc": "Data type for data or columns. E.g. np.float64 or\n{‘a’: np.float64, ‘b’: np.int32, ‘c’: ‘Int64’}.\n\nNew in version 1.3.0.\n\n"}, {"param_name": "dtype_backend", "param_type": "{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’", "param_desc": "Back-end data type applied to the resultant DataFrame\n(still experimental). Behaviour is as follows:\n\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\n(default).\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\nDataFrame.\n\n\nNew in version 2.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.read_sql_query.html#pandas.read_sql_query"}, {"function_name": "pandas.DataFrame.to_sql", "full_function": "DataFrame.to_sql(name, con, *, schema=None, if_exists='fail', index=True, index_label=None, chunksize=None, dtype=None, method=None)", "function_text": "Write records stored in a DataFrame to a SQL database.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_sql.html#pandas.DataFrame.to_sql"}]}, {"name": "Google BigQuery", "url": "https://pandas.pydata.org/docs/reference/io.html#google-bigquery", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.read_gbq.html#pandas.read_gbq"], "function_definitions": [{"function_name": "pandas.read_gbq", "full_function": "pandas.read_gbq(query, project_id=None, index_col=None, col_order=None, reauth=False, auth_local_webserver=True, dialect=None, location=None, configuration=None, credentials=None, use_bqstorage_api=None, max_results=None, progress_bar_type=None)", "function_text": "Load data from Google BigQuery.", "parameter_names_desc": [{"param_name": "query", "param_type": "str", "param_desc": "SQL-Like Query to return data values.\n"}, {"param_name": "project_id", "param_type": "str, optional", "param_desc": "Google BigQuery Account project ID. Optional when available from\nthe environment.\n"}, {"param_name": "index_col", "param_type": "str, optional", "param_desc": "Name of result column to use for index in results DataFrame.\n"}, {"param_name": "col_order", "param_type": "list(str), optional", "param_desc": "List of BigQuery column names in the desired order for results\nDataFrame.\n"}, {"param_name": "reauth", "param_type": "bool, default False", "param_desc": "Force Google BigQuery to re-authenticate the user. This is useful\nif multiple accounts are used.\n"}, {"param_name": "auth_local_webserver", "param_type": "bool, default True", "param_desc": "Use the local webserver flow instead of the console flow\nwhen getting user credentials.\nNew in version 0.2.0 of pandas-gbq.\n\nChanged in version 1.5.0: Default value is changed to True. Google has deprecated the\nauth_local_webserver = False “out of band” (copy-paste)\nflow.\n\n"}, {"param_name": "dialect", "param_type": "str, default ‘legacy’", "param_desc": "Note: The default value is changing to ‘standard’ in a future version.\nSQL syntax dialect to use. Value can be one of:\n\n'legacy'Use BigQuery’s legacy SQL dialect. For more information see\nBigQuery Legacy SQL Reference.\n\n'standard'Use BigQuery’s standard SQL, which is\ncompliant with the SQL 2011 standard. For more information\nsee BigQuery Standard SQL Reference.\n\n\n"}, {"param_name": "location", "param_type": "str, optional", "param_desc": "Location where the query job should run. See the BigQuery locations\ndocumentation for a\nlist of available locations. The location must match that of any\ndatasets used in the query.\nNew in version 0.5.0 of pandas-gbq.\n"}, {"param_name": "configuration", "param_type": "dict, optional", "param_desc": "Query config parameters for job processing.\nFor example:\n\nconfiguration = {‘query’: {‘useQueryCache’: False}}\n\nFor more information see BigQuery REST API Reference.\n"}, {"param_name": "credentials", "param_type": "google.auth.credentials.Credentials, optional", "param_desc": "Credentials for accessing Google APIs. Use this parameter to override\ndefault credentials, such as to use Compute Engine\ngoogle.auth.compute_engine.Credentials or Service Account\ngoogle.oauth2.service_account.Credentials directly.\nNew in version 0.8.0 of pandas-gbq.\n"}, {"param_name": "use_bqstorage_api", "param_type": "bool, default False", "param_desc": "Use the BigQuery Storage API to\ndownload query results quickly, but at an increased cost. To use this\nAPI, first enable it in the Cloud Console.\nYou must also have the bigquery.readsessions.create\npermission on the project you are billing queries to.\nThis feature requires version 0.10.0 or later of the pandas-gbq\npackage. It also requires the google-cloud-bigquery-storage and\nfastavro packages.\n"}, {"param_name": "max_results", "param_type": "int, optional", "param_desc": "If set, limit the maximum number of rows to fetch from the query\nresults.\n"}, {"param_name": "progress_bar_type", "param_type": "Optional, str", "param_desc": "If set, use the tqdm library to\ndisplay a progress bar while the data downloads. Install the\ntqdm package to use this feature.\nPossible values of progress_bar_type include:\n\nNoneNo progress bar.\n\n'tqdm'Use the tqdm.tqdm() function to print a progress bar\nto sys.stderr.\n\n'tqdm_notebook'Use the tqdm.tqdm_notebook() function to display a\nprogress bar as a Jupyter notebook widget.\n\n'tqdm_gui'Use the tqdm.tqdm_gui() function to display a\nprogress bar as a graphical dialog box.\n\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.read_gbq.html#pandas.read_gbq"}]}, {"name": "STATA", "url": "https://pandas.pydata.org/docs/reference/io.html#stata", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.read_stata.html#pandas.read_stata", "https://pandas.pydata.org/docs/reference/api/pandas.io.stata.StataReader.data_label.html#pandas.io.stata.StataReader.data_label", "https://pandas.pydata.org/docs/reference/api/pandas.io.stata.StataReader.variable_labels.html#pandas.io.stata.StataReader.variable_labels", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_stata.html#pandas.DataFrame.to_stata", "https://pandas.pydata.org/docs/reference/api/pandas.io.stata.StataReader.value_labels.html#pandas.io.stata.StataReader.value_labels", "https://pandas.pydata.org/docs/reference/api/pandas.io.stata.StataWriter.write_file.html#pandas.io.stata.StataWriter.write_file"], "function_definitions": [{"function_name": "pandas.read_stata", "full_function": "pandas.read_stata(filepath_or_buffer, *, convert_dates=True, convert_categoricals=True, index_col=None, convert_missing=False, preserve_dtypes=True, columns=None, order_categoricals=True, chunksize=None, iterator=False, compression='infer', storage_options=None)", "function_text": "Read Stata file into DataFrame.", "parameter_names_desc": [{"param_name": "filepath_or_buffer", "param_type": "str, path object or file-like object", "param_desc": "Any valid string path is acceptable. The string could be a URL. Valid\nURL schemes include http, ftp, s3, and file. For file URLs, a host is\nexpected. A local file could be: file://localhost/path/to/table.dta.\nIf you want to pass in a path object, pandas accepts any os.PathLike.\nBy file-like object, we refer to objects with a read() method,\nsuch as a file handle (e.g. via builtin open function)\nor StringIO.\n"}, {"param_name": "convert_dates", "param_type": "bool, default True", "param_desc": "Convert date variables to DataFrame time values.\n"}, {"param_name": "convert_categoricals", "param_type": "bool, default True", "param_desc": "Read value labels and convert columns to Categorical/Factor variables.\n"}, {"param_name": "index_col", "param_type": "str, optional", "param_desc": "Column to set as index.\n"}, {"param_name": "convert_missing", "param_type": "bool, default False", "param_desc": "Flag indicating whether to convert missing values to their Stata\nrepresentations. If False, missing values are replaced with nan.\nIf True, columns containing missing values are returned with\nobject data types and missing values are represented by\nStataMissingValue objects.\n"}, {"param_name": "preserve_dtypes", "param_type": "bool, default True", "param_desc": "Preserve Stata datatypes. If False, numeric data are upcast to pandas\ndefault types for foreign data (float64 or int64).\n"}, {"param_name": "columns", "param_type": "list or None", "param_desc": "Columns to retain. Columns will be returned in the given order. None\nreturns all columns.\n"}, {"param_name": "order_categoricals", "param_type": "bool, default True", "param_desc": "Flag indicating whether converted categorical data are ordered.\n"}, {"param_name": "chunksize", "param_type": "int, default None", "param_desc": "Return StataReader object for iterations, returns chunks with\ngiven number of lines.\n"}, {"param_name": "iterator", "param_type": "bool, default False", "param_desc": "Return StataReader object.\n"}, {"param_name": "compression", "param_type": "str or dict, default ‘infer’", "param_desc": "For on-the-fly decompression of on-disk data. If ‘infer’ and ‘filepath_or_buffer’ is\npath-like, then detect compression from the following extensions: ‘.gz’,\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\n(otherwise no compression).\nIf using ‘zip’ or ‘tar’, the ZIP file must contain only one data file to be read in.\nSet to None for no decompression.\nCan also be a dict with key 'method' set\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\nother key-value pairs are forwarded to\nzipfile.ZipFile, gzip.GzipFile,\nbz2.BZ2File, zstandard.ZstdDecompressor, lzma.LZMAFile or\ntarfile.TarFile, respectively.\nAs an example, the following could be passed for Zstandard decompression using a\ncustom compression dictionary:\ncompression={'method': 'zstd', 'dict_data': my_compression_dict}.\n\nNew in version 1.5.0: Added support for .tar files.\n\n"}, {"param_name": "storage_options", "param_type": "dict, optional", "param_desc": "Extra options that make sense for a particular storage connection, e.g.\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\nare forwarded to urllib.request.Request as header options. For other\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\nforwarded to fsspec.open. Please see fsspec and urllib for more\ndetails, and for more examples on storage options refer here.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.read_stata.html#pandas.read_stata"}, {"function_name": "pandas.io.stata.StataReader.data_label", "full_function": "property StataReader.data_label", "function_text": "Return data label of Stata file.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.stata.StataReader.data_label.html#pandas.io.stata.StataReader.data_label"}, {"function_name": "pandas.io.stata.StataReader.variable_labels", "full_function": "StataReader.variable_labels()", "function_text": "Return a dict associating each variable name with corresponding label.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.stata.StataReader.variable_labels.html#pandas.io.stata.StataReader.variable_labels"}, {"function_name": "pandas.DataFrame.to_stata", "full_function": "DataFrame.to_stata(path, *, convert_dates=None, write_index=True, byteorder=None, time_stamp=None, data_label=None, variable_labels=None, version=114, convert_strl=None, compression='infer', storage_options=None, value_labels=None)", "function_text": "Export DataFrame object to Stata dta format.", "parameter_names_desc": [{"param_name": "path", "param_type": "str, path object, or buffer", "param_desc": "String, path object (implementing os.PathLike[str]), or file-like\nobject implementing a binary write() function.\n"}, {"param_name": "convert_dates", "param_type": "dict", "param_desc": "Dictionary mapping columns containing datetime types to stata\ninternal format to use when writing the dates. Options are ‘tc’,\n‘td’, ‘tm’, ‘tw’, ‘th’, ‘tq’, ‘ty’. Column can be either an integer\nor a name. Datetime columns that do not have a conversion type\nspecified will be converted to ‘tc’. Raises NotImplementedError if\na datetime column has timezone information.\n"}, {"param_name": "write_index", "param_type": "bool", "param_desc": "Write the index to Stata dataset.\n"}, {"param_name": "byteorder", "param_type": "str", "param_desc": "Can be “>”, “<”, “little”, or “big”. default is sys.byteorder.\n"}, {"param_name": "time_stamp", "param_type": "datetime", "param_desc": "A datetime to use as file creation date. Default is the current\ntime.\n"}, {"param_name": "data_label", "param_type": "str, optional", "param_desc": "A label for the data set. Must be 80 characters or smaller.\n"}, {"param_name": "variable_labels", "param_type": "dict", "param_desc": "Dictionary containing columns as keys and variable labels as\nvalues. Each label must be 80 characters or smaller.\n"}, {"param_name": "version", "param_type": "{114, 117, 118, 119, None}, default 114", "param_desc": "Version to use in the output dta file. Set to None to let pandas\ndecide between 118 or 119 formats depending on the number of\ncolumns in the frame. Version 114 can be read by Stata 10 and\nlater. Version 117 can be read by Stata 13 or later. Version 118\nis supported in Stata 14 and later. Version 119 is supported in\nStata 15 and later. Version 114 limits string variables to 244\ncharacters or fewer while versions 117 and later allow strings\nwith lengths up to 2,000,000 characters. Versions 118 and 119\nsupport Unicode characters, and version 119 supports more than\n32,767 variables.\nVersion 119 should usually only be used when the number of\nvariables exceeds the capacity of dta format 118. Exporting\nsmaller datasets in format 119 may have unintended consequences,\nand, as of November 2020, Stata SE cannot read version 119 files.\n"}, {"param_name": "convert_strl", "param_type": "list, optional", "param_desc": "List of column names to convert to string columns to Stata StrL\nformat. Only available if version is 117. Storing strings in the\nStrL format can produce smaller dta files if strings have more than\n8 characters and values are repeated.\n"}, {"param_name": "compression", "param_type": "str or dict, default ‘infer’", "param_desc": "For on-the-fly compression of the output data. If ‘infer’ and ‘path’ is\npath-like, then detect compression from the following extensions: ‘.gz’,\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\n(otherwise no compression).\nSet to None for no compression.\nCan also be a dict with key 'method' set\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\nother key-value pairs are forwarded to\nzipfile.ZipFile, gzip.GzipFile,\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\ntarfile.TarFile, respectively.\nAs an example, the following could be passed for faster compression and to create\na reproducible gzip archive:\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\n\nNew in version 1.5.0: Added support for .tar files.\n\n\nChanged in version 1.4.0: Zstandard support.\n\n"}, {"param_name": "storage_options", "param_type": "dict, optional", "param_desc": "Extra options that make sense for a particular storage connection, e.g.\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\nare forwarded to urllib.request.Request as header options. For other\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\nforwarded to fsspec.open. Please see fsspec and urllib for more\ndetails, and for more examples on storage options refer here.\n"}, {"param_name": "value_labels", "param_type": "dict of dicts", "param_desc": "Dictionary containing columns as keys and dictionaries of column value\nto labels as values. Labels for a single variable must be 32,000\ncharacters or smaller.\n\nNew in version 1.4.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_stata.html#pandas.DataFrame.to_stata"}, {"function_name": "pandas.io.stata.StataReader.value_labels", "full_function": "StataReader.value_labels()", "function_text": "Return a nested dict associating each variable name to its value and label.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.stata.StataReader.value_labels.html#pandas.io.stata.StataReader.value_labels"}, {"function_name": "pandas.io.stata.StataWriter.write_file", "full_function": "StataWriter.write_file()", "function_text": "Export DataFrame object to Stata dta format.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.stata.StataWriter.write_file.html#pandas.io.stata.StataWriter.write_file"}]}], "name": "Input/output", "url": "https://pandas.pydata.org/docs/reference/io.html"}, "general_functions.html": {"functions": [{"name": "Data manipulations", "url": "https://pandas.pydata.org/docs/reference/general_functions.html#data-manipulations", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.melt.html#pandas.melt", "https://pandas.pydata.org/docs/reference/api/pandas.pivot_table.html#pandas.pivot_table", "https://pandas.pydata.org/docs/reference/api/pandas.cut.html#pandas.cut", "https://pandas.pydata.org/docs/reference/api/pandas.merge.html#pandas.merge", "https://pandas.pydata.org/docs/reference/api/pandas.merge_asof.html#pandas.merge_asof", "https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html#pandas.get_dummies", "https://pandas.pydata.org/docs/reference/api/pandas.factorize.html#pandas.factorize", "https://pandas.pydata.org/docs/reference/api/pandas.lreshape.html#pandas.lreshape", "https://pandas.pydata.org/docs/reference/api/pandas.pivot.html#pandas.pivot", "https://pandas.pydata.org/docs/reference/api/pandas.crosstab.html#pandas.crosstab", "https://pandas.pydata.org/docs/reference/api/pandas.qcut.html#pandas.qcut", "https://pandas.pydata.org/docs/reference/api/pandas.merge_ordered.html#pandas.merge_ordered", "https://pandas.pydata.org/docs/reference/api/pandas.concat.html#pandas.concat", "https://pandas.pydata.org/docs/reference/api/pandas.from_dummies.html#pandas.from_dummies", "https://pandas.pydata.org/docs/reference/api/pandas.unique.html#pandas.unique", "https://pandas.pydata.org/docs/reference/api/pandas.wide_to_long.html#pandas.wide_to_long"], "function_definitions": [{"function_name": "pandas.melt", "full_function": "pandas.melt(frame, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None, ignore_index=True)", "function_text": "Unpivot a DataFrame from wide to long format, optionally leaving identifiers set.", "parameter_names_desc": [{"param_name": "id_vars", "param_type": "scalar, tuple, list, or ndarray, optional", "param_desc": "Column(s) to use as identifier variables.\n"}, {"param_name": "value_vars", "param_type": "scalar, tuple, list, or ndarray, optional", "param_desc": "Column(s) to unpivot. If not specified, uses all columns that\nare not set as id_vars.\n"}, {"param_name": "var_name", "param_type": "scalar, default None", "param_desc": "Name to use for the ‘variable’ column. If None it uses\nframe.columns.name or ‘variable’.\n"}, {"param_name": "value_name", "param_type": "scalar, default ‘value’", "param_desc": "Name to use for the ‘value’ column, can’t be an existing column label.\n"}, {"param_name": "col_level", "param_type": "scalar, optional", "param_desc": "If columns are a MultiIndex then use this level to melt.\n"}, {"param_name": "ignore_index", "param_type": "bool, default True", "param_desc": "If True, original index is ignored. If False, the original index is retained.\nIndex labels will be repeated as necessary.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.melt.html#pandas.melt"}, {"function_name": "pandas.pivot_table", "full_function": "pandas.pivot_table(data, values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All', observed=_NoDefault.no_default, sort=True)", "function_text": "Create a spreadsheet-style pivot table as a DataFrame.", "parameter_names_desc": [{"param_name": "data", "param_type": "DataFrame", "param_desc": ""}, {"param_name": "values", "param_type": "list-like or scalar, optional", "param_desc": "Column or columns to aggregate.\n"}, {"param_name": "index", "param_type": "column, Grouper, array, or list of the previous", "param_desc": "Keys to group by on the pivot table index. If a list is passed,\nit can contain any of the other types (except list). If an array is\npassed, it must be the same length as the data and will be used in\nthe same manner as column values.\n"}, {"param_name": "columns", "param_type": "column, Grouper, array, or list of the previous", "param_desc": "Keys to group by on the pivot table column. If a list is passed,\nit can contain any of the other types (except list). If an array is\npassed, it must be the same length as the data and will be used in\nthe same manner as column values.\n"}, {"param_name": "aggfunc", "param_type": "function, list of functions, dict, default “mean”", "param_desc": "If a list of functions is passed, the resulting pivot table will have\nhierarchical columns whose top level are the function names\n(inferred from the function objects themselves).\nIf a dict is passed, the key is column to aggregate and the value is\nfunction or list of functions. If margin=True, aggfunc will be\nused to calculate the partial aggregates.\n"}, {"param_name": "fill_value", "param_type": "scalar, default None", "param_desc": "Value to replace missing values with (in the resulting pivot table,\nafter aggregation).\n"}, {"param_name": "margins", "param_type": "bool, default False", "param_desc": "If margins=True, special All columns and rows\nwill be added with partial group aggregates across the categories\non the rows and columns.\n"}, {"param_name": "dropna", "param_type": "bool, default True", "param_desc": "Do not include columns whose entries are all NaN. If True,\nrows with a NaN value in any column will be omitted before\ncomputing margins.\n"}, {"param_name": "margins_name", "param_type": "str, default ‘All’", "param_desc": "Name of the row / column that will contain the totals\nwhen margins is True.\n"}, {"param_name": "observed", "param_type": "bool, default False", "param_desc": "This only applies if any of the groupers are Categoricals.\nIf True: only show observed values for categorical groupers.\nIf False: show all values for categorical groupers.\n\nDeprecated since version 2.2.0: The default value of False is deprecated and will change to\nTrue in a future version of pandas.\n\n"}, {"param_name": "sort", "param_type": "bool, default True", "param_desc": "Specifies if the result should be sorted.\n\nNew in version 1.3.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.pivot_table.html#pandas.pivot_table"}, {"function_name": "pandas.cut", "full_function": "pandas.cut(x, bins, right=True, labels=None, retbins=False, precision=3, include_lowest=False, duplicates='raise', ordered=True)", "function_text": "Bin values into discrete intervals.", "parameter_names_desc": [{"param_name": "x", "param_type": "array-like", "param_desc": "The input array to be binned. Must be 1-dimensional.\n"}, {"param_name": "bins", "param_type": "int, sequence of scalars, or IntervalIndex", "param_desc": "The criteria to bin by.\n\nint : Defines the number of equal-width bins in the range of x. The\nrange of x is extended by .1% on each side to include the minimum\nand maximum values of x.\nsequence of scalars : Defines the bin edges allowing for non-uniform\nwidth. No extension of the range of x is done.\nIntervalIndex : Defines the exact bins to be used. Note that\nIntervalIndex for bins must be non-overlapping.\n\n"}, {"param_name": "right", "param_type": "bool, default True", "param_desc": "Indicates whether bins includes the rightmost edge or not. If\nright == True (the default), then the bins [1, 2, 3, 4]\nindicate (1,2], (2,3], (3,4]. This argument is ignored when\nbins is an IntervalIndex.\n"}, {"param_name": "labels", "param_type": "array or False, default None", "param_desc": "Specifies the labels for the returned bins. Must be the same length as\nthe resulting bins. If False, returns only integer indicators of the\nbins. This affects the type of the output container (see below).\nThis argument is ignored when bins is an IntervalIndex. If True,\nraises an error. When ordered=False, labels must be provided.\n"}, {"param_name": "retbins", "param_type": "bool, default False", "param_desc": "Whether to return the bins or not. Useful when bins is provided\nas a scalar.\n"}, {"param_name": "precision", "param_type": "int, default 3", "param_desc": "The precision at which to store and display the bins labels.\n"}, {"param_name": "include_lowest", "param_type": "bool, default False", "param_desc": "Whether the first interval should be left-inclusive or not.\n"}, {"param_name": "duplicates", "param_type": "{default ‘raise’, ‘drop’}, optional", "param_desc": "If bin edges are not unique, raise ValueError or drop non-uniques.\n"}, {"param_name": "ordered", "param_type": "bool, default True", "param_desc": "Whether the labels are ordered or not. Applies to returned types\nCategorical and Series (with Categorical dtype). If True,\nthe resulting categorical will be ordered. If False, the resulting\ncategorical will be unordered (labels must be provided).\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.cut.html#pandas.cut"}, {"function_name": "pandas.merge", "full_function": "pandas.merge(left, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=None, indicator=False, validate=None)", "function_text": "Merge DataFrame or named Series objects with a database-style join.", "parameter_names_desc": [{"param_name": "left", "param_type": "DataFrame or named Series", "param_desc": ""}, {"param_name": "right", "param_type": "DataFrame or named Series", "param_desc": "Object to merge with.\n"}, {"param_name": "how", "param_type": "{‘left’, ‘right’, ‘outer’, ‘inner’, ‘cross’}, default ‘inner’", "param_desc": "Type of merge to be performed.\n\nleft: use only keys from left frame, similar to a SQL left outer join;\npreserve key order.\nright: use only keys from right frame, similar to a SQL right outer join;\npreserve key order.\nouter: use union of keys from both frames, similar to a SQL full outer\njoin; sort keys lexicographically.\ninner: use intersection of keys from both frames, similar to a SQL inner\njoin; preserve the order of the left keys.\ncross: creates the cartesian product from both frames, preserves the order\nof the left keys.\n\n"}, {"param_name": "on", "param_type": "label or list", "param_desc": "Column or index level names to join on. These must be found in both\nDataFrames. If on is None and not merging on indexes then this defaults\nto the intersection of the columns in both DataFrames.\n"}, {"param_name": "left_on", "param_type": "label or list, or array-like", "param_desc": "Column or index level names to join on in the left DataFrame. Can also\nbe an array or list of arrays of the length of the left DataFrame.\nThese arrays are treated as if they are columns.\n"}, {"param_name": "right_on", "param_type": "label or list, or array-like", "param_desc": "Column or index level names to join on in the right DataFrame. Can also\nbe an array or list of arrays of the length of the right DataFrame.\nThese arrays are treated as if they are columns.\n"}, {"param_name": "left_index", "param_type": "bool, default False", "param_desc": "Use the index from the left DataFrame as the join key(s). If it is a\nMultiIndex, the number of keys in the other DataFrame (either the index\nor a number of columns) must match the number of levels.\n"}, {"param_name": "right_index", "param_type": "bool, default False", "param_desc": "Use the index from the right DataFrame as the join key. Same caveats as\nleft_index.\n"}, {"param_name": "sort", "param_type": "bool, default False", "param_desc": "Sort the join keys lexicographically in the result DataFrame. If False,\nthe order of the join keys depends on the join type (how keyword).\n"}, {"param_name": "suffixes", "param_type": "list-like, default is (“_x”, “_y”)", "param_desc": "A length-2 sequence where each element is optionally a string\nindicating the suffix to add to overlapping column names in\nleft and right respectively. Pass a value of None instead\nof a string to indicate that the column name from left or\nright should be left as-is, with no suffix. At least one of the\nvalues must not be None.\n"}, {"param_name": "copy", "param_type": "bool, default True", "param_desc": "If False, avoid copy if possible.\n\nNote\nThe copy keyword will change behavior in pandas 3.0.\nCopy-on-Write\nwill be enabled by default, which means that all methods with a\ncopy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas.\nYou can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True\n\n"}, {"param_name": "indicator", "param_type": "bool or str, default False", "param_desc": "If True, adds a column to the output DataFrame called “_merge” with\ninformation on the source of each row. The column can be given a different\nname by providing a string argument. The column will have a Categorical\ntype with the value of “left_only” for observations whose merge key only\nappears in the left DataFrame, “right_only” for observations\nwhose merge key only appears in the right DataFrame, and “both”\nif the observation’s merge key is found in both DataFrames.\n"}, {"param_name": "validate", "param_type": "str, optional", "param_desc": "If specified, checks if merge is of specified type.\n\n“one_to_one” or “1:1”: check if merge keys are unique in both\nleft and right datasets.\n“one_to_many” or “1:m”: check if merge keys are unique in left\ndataset.\n“many_to_one” or “m:1”: check if merge keys are unique in right\ndataset.\n“many_to_many” or “m:m”: allowed, but does not result in checks.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.merge.html#pandas.merge"}, {"function_name": "pandas.merge_asof", "full_function": "pandas.merge_asof(left, right, on=None, left_on=None, right_on=None, left_index=False, right_index=False, by=None, left_by=None, right_by=None, suffixes=('_x', '_y'), tolerance=None, allow_exact_matches=True, direction='backward')", "function_text": "Perform a merge by key distance.", "parameter_names_desc": [{"param_name": "left", "param_type": "DataFrame or named Series", "param_desc": ""}, {"param_name": "right", "param_type": "DataFrame or named Series", "param_desc": ""}, {"param_name": "on", "param_type": "label", "param_desc": "Field name to join on. Must be found in both DataFrames.\nThe data MUST be ordered. Furthermore this must be a numeric column,\nsuch as datetimelike, integer, or float. On or left_on/right_on\nmust be given.\n"}, {"param_name": "left_on", "param_type": "label", "param_desc": "Field name to join on in left DataFrame.\n"}, {"param_name": "right_on", "param_type": "label", "param_desc": "Field name to join on in right DataFrame.\n"}, {"param_name": "left_index", "param_type": "bool", "param_desc": "Use the index of the left DataFrame as the join key.\n"}, {"param_name": "right_index", "param_type": "bool", "param_desc": "Use the index of the right DataFrame as the join key.\n"}, {"param_name": "by", "param_type": "column name or list of column names", "param_desc": "Match on these columns before performing merge operation.\n"}, {"param_name": "left_by", "param_type": "column name", "param_desc": "Field names to match on in the left DataFrame.\n"}, {"param_name": "right_by", "param_type": "column name", "param_desc": "Field names to match on in the right DataFrame.\n"}, {"param_name": "suffixes", "param_type": "2-length sequence (tuple, list, …)", "param_desc": "Suffix to apply to overlapping column names in the left and right\nside, respectively.\n"}, {"param_name": "tolerance", "param_type": "int or Timedelta, optional, default None", "param_desc": "Select asof tolerance within this range; must be compatible\nwith the merge index.\n"}, {"param_name": "allow_exact_matches", "param_type": "bool, default True", "param_desc": "\nIf True, allow matching with the same ‘on’ value\n(i.e. less-than-or-equal-to / greater-than-or-equal-to)\nIf False, don’t match the same ‘on’ value\n(i.e., strictly less-than / strictly greater-than).\n\n"}, {"param_name": "direction", "param_type": "‘backward’ (default), ‘forward’, or ‘nearest’", "param_desc": "Whether to search for prior, subsequent, or closest matches.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.merge_asof.html#pandas.merge_asof"}, {"function_name": "pandas.get_dummies", "full_function": "pandas.get_dummies(data, prefix=None, prefix_sep='_', dummy_na=False, columns=None, sparse=False, drop_first=False, dtype=None)", "function_text": "Convert categorical variable into dummy/indicator variables.", "parameter_names_desc": [{"param_name": "data", "param_type": "array-like, Series, or DataFrame", "param_desc": "Data of which to get dummy indicators.\n"}, {"param_name": "prefix", "param_type": "str, list of str, or dict of str, default None", "param_desc": "String to append DataFrame column names.\nPass a list with length equal to the number of columns\nwhen calling get_dummies on a DataFrame. Alternatively, prefix\ncan be a dictionary mapping column names to prefixes.\n"}, {"param_name": "prefix_sep", "param_type": "str, default ‘_’", "param_desc": "If appending prefix, separator/delimiter to use. Or pass a\nlist or dictionary as with prefix.\n"}, {"param_name": "dummy_na", "param_type": "bool, default False", "param_desc": "Add a column to indicate NaNs, if False NaNs are ignored.\n"}, {"param_name": "columns", "param_type": "list-like, default None", "param_desc": "Column names in the DataFrame to be encoded.\nIf columns is None then all the columns with\nobject, string, or category dtype will be converted.\n"}, {"param_name": "sparse", "param_type": "bool, default False", "param_desc": "Whether the dummy-encoded columns should be backed by\na SparseArray (True) or a regular NumPy array (False).\n"}, {"param_name": "drop_first", "param_type": "bool, default False", "param_desc": "Whether to get k-1 dummies out of k categorical levels by removing the\nfirst level.\n"}, {"param_name": "dtype", "param_type": "dtype, default bool", "param_desc": "Data type for new columns. Only a single dtype is allowed.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html#pandas.get_dummies"}, {"function_name": "pandas.factorize", "full_function": "pandas.factorize(values, sort=False, use_na_sentinel=True, size_hint=None)", "function_text": "Encode the object as an enumerated type or categorical variable.", "parameter_names_desc": [{"param_name": "values", "param_type": "sequence", "param_desc": "A 1-D sequence. Sequences that aren’t pandas objects are\ncoerced to ndarrays before factorization.\n"}, {"param_name": "sort", "param_type": "bool, default False", "param_desc": "Sort uniques and shuffle codes to maintain the\nrelationship.\n"}, {"param_name": "use_na_sentinel", "param_type": "bool, default True", "param_desc": "If True, the sentinel -1 will be used for NaN values. If False,\nNaN values will be encoded as non-negative integers and will not drop the\nNaN from the uniques of the values.\n\nNew in version 1.5.0.\n\n"}, {"param_name": "size_hint", "param_type": "int, optional", "param_desc": "Hint to the hashtable sizer.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.factorize.html#pandas.factorize"}, {"function_name": "pandas.lreshape", "full_function": "pandas.lreshape(data, groups, dropna=True)", "function_text": "Reshape wide-format data to long. Generalized inverse of DataFrame.pivot.", "parameter_names_desc": [{"param_name": "data", "param_type": "DataFrame", "param_desc": "The wide-format DataFrame.\n"}, {"param_name": "groups", "param_type": "dict", "param_desc": "{new_name : list_of_columns}.\n"}, {"param_name": "dropna", "param_type": "bool, default True", "param_desc": "Do not include columns whose entries are all NaN.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.lreshape.html#pandas.lreshape"}, {"function_name": "pandas.pivot", "full_function": "pandas.pivot(data, *, columns, index=_NoDefault.no_default, values=_NoDefault.no_default)", "function_text": "Return reshaped DataFrame organized by given index / column values.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.pivot.html#pandas.pivot"}, {"function_name": "pandas.crosstab", "full_function": "pandas.crosstab(index, columns, values=None, rownames=None, colnames=None, aggfunc=None, margins=False, margins_name='All', dropna=True, normalize=False)", "function_text": "Compute a simple cross tabulation of two (or more) factors.", "parameter_names_desc": [{"param_name": "index", "param_type": "array-like, Series, or list of arrays/Series", "param_desc": "Values to group by in the rows.\n"}, {"param_name": "columns", "param_type": "array-like, Series, or list of arrays/Series", "param_desc": "Values to group by in the columns.\n"}, {"param_name": "values", "param_type": "array-like, optional", "param_desc": "Array of values to aggregate according to the factors.\nRequires aggfunc be specified.\n"}, {"param_name": "rownames", "param_type": "sequence, default None", "param_desc": "If passed, must match number of row arrays passed.\n"}, {"param_name": "colnames", "param_type": "sequence, default None", "param_desc": "If passed, must match number of column arrays passed.\n"}, {"param_name": "aggfunc", "param_type": "function, optional", "param_desc": "If specified, requires values be specified as well.\n"}, {"param_name": "margins", "param_type": "bool, default False", "param_desc": "Add row/column margins (subtotals).\n"}, {"param_name": "margins_name", "param_type": "str, default ‘All’", "param_desc": "Name of the row/column that will contain the totals\nwhen margins is True.\n"}, {"param_name": "dropna", "param_type": "bool, default True", "param_desc": "Do not include columns whose entries are all NaN.\n"}, {"param_name": "normalize", "param_type": "bool, {‘all’, ‘index’, ‘columns’}, or {0,1}, default False", "param_desc": "Normalize by dividing all values by the sum of values.\n\nIf passed ‘all’ or True, will normalize over all values.\nIf passed ‘index’ will normalize over each row.\nIf passed ‘columns’ will normalize over each column.\nIf margins is True, will also normalize margin values.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.crosstab.html#pandas.crosstab"}, {"function_name": "pandas.qcut", "full_function": "pandas.qcut(x, q, labels=None, retbins=False, precision=3, duplicates='raise')", "function_text": "Quantile-based discretization function.", "parameter_names_desc": [{"param_name": "x", "param_type": "1d ndarray or Series", "param_desc": ""}, {"param_name": "q", "param_type": "int or list-like of float", "param_desc": "Number of quantiles. 10 for deciles, 4 for quartiles, etc. Alternately\narray of quantiles, e.g. [0, .25, .5, .75, 1.] for quartiles.\n"}, {"param_name": "labels", "param_type": "array or False, default None", "param_desc": "Used as labels for the resulting bins. Must be of the same length as\nthe resulting bins. If False, return only integer indicators of the\nbins. If True, raises an error.\n"}, {"param_name": "retbins", "param_type": "bool, optional", "param_desc": "Whether to return the (bins, labels) or not. Can be useful if bins\nis given as a scalar.\n"}, {"param_name": "precision", "param_type": "int, optional", "param_desc": "The precision at which to store and display the bins labels.\n"}, {"param_name": "duplicates", "param_type": "{default ‘raise’, ‘drop’}, optional", "param_desc": "If bin edges are not unique, raise ValueError or drop non-uniques.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.qcut.html#pandas.qcut"}, {"function_name": "pandas.merge_ordered", "full_function": "pandas.merge_ordered(left, right, on=None, left_on=None, right_on=None, left_by=None, right_by=None, fill_method=None, suffixes=('_x', '_y'), how='outer')", "function_text": "Perform a merge for ordered data with optional filling/interpolation.", "parameter_names_desc": [{"param_name": "left", "param_type": "DataFrame or named Series", "param_desc": ""}, {"param_name": "right", "param_type": "DataFrame or named Series", "param_desc": ""}, {"param_name": "on", "param_type": "label or list", "param_desc": "Field names to join on. Must be found in both DataFrames.\n"}, {"param_name": "left_on", "param_type": "label or list, or array-like", "param_desc": "Field names to join on in left DataFrame. Can be a vector or list of\nvectors of the length of the DataFrame to use a particular vector as\nthe join key instead of columns.\n"}, {"param_name": "right_on", "param_type": "label or list, or array-like", "param_desc": "Field names to join on in right DataFrame or vector/list of vectors per\nleft_on docs.\n"}, {"param_name": "left_by", "param_type": "column name or list of column names", "param_desc": "Group left DataFrame by group columns and merge piece by piece with\nright DataFrame. Must be None if either left or right are a Series.\n"}, {"param_name": "right_by", "param_type": "column name or list of column names", "param_desc": "Group right DataFrame by group columns and merge piece by piece with\nleft DataFrame. Must be None if either left or right are a Series.\n"}, {"param_name": "fill_method", "param_type": "{‘ffill’, None}, default None", "param_desc": "Interpolation method for data.\n"}, {"param_name": "suffixes", "param_type": "list-like, default is (“_x”, “_y”)", "param_desc": "A length-2 sequence where each element is optionally a string\nindicating the suffix to add to overlapping column names in\nleft and right respectively. Pass a value of None instead\nof a string to indicate that the column name from left or\nright should be left as-is, with no suffix. At least one of the\nvalues must not be None.\n"}, {"param_name": "how", "param_type": "{‘left’, ‘right’, ‘outer’, ‘inner’}, default ‘outer’", "param_desc": "\nleft: use only keys from left frame (SQL: left outer join)\nright: use only keys from right frame (SQL: right outer join)\nouter: use union of keys from both frames (SQL: full outer join)\ninner: use intersection of keys from both frames (SQL: inner join).\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.merge_ordered.html#pandas.merge_ordered"}, {"function_name": "pandas.concat", "full_function": "pandas.concat(objs, *, axis=0, join='outer', ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, sort=False, copy=None)", "function_text": "Concatenate pandas objects along a particular axis.", "parameter_names_desc": [{"param_name": "objs", "param_type": "a sequence or mapping of Series or DataFrame objects", "param_desc": "If a mapping is passed, the sorted keys will be used as the keys\nargument, unless it is passed, in which case the values will be\nselected (see below). Any None objects will be dropped silently unless\nthey are all None in which case a ValueError will be raised.\n"}, {"param_name": "axis", "param_type": "{0/’index’, 1/’columns’}, default 0", "param_desc": "The axis to concatenate along.\n"}, {"param_name": "join", "param_type": "{‘inner’, ‘outer’}, default ‘outer’", "param_desc": "How to handle indexes on other axis (or axes).\n"}, {"param_name": "ignore_index", "param_type": "bool, default False", "param_desc": "If True, do not use the index values along the concatenation axis. The\nresulting axis will be labeled 0, …, n - 1. This is useful if you are\nconcatenating objects where the concatenation axis does not have\nmeaningful indexing information. Note the index values on the other\naxes are still respected in the join.\n"}, {"param_name": "keys", "param_type": "sequence, default None", "param_desc": "If multiple levels passed, should contain tuples. Construct\nhierarchical index using the passed keys as the outermost level.\n"}, {"param_name": "levels", "param_type": "list of sequences, default None", "param_desc": "Specific levels (unique values) to use for constructing a\nMultiIndex. Otherwise they will be inferred from the keys.\n"}, {"param_name": "names", "param_type": "list, default None", "param_desc": "Names for the levels in the resulting hierarchical index.\n"}, {"param_name": "verify_integrity", "param_type": "bool, default False", "param_desc": "Check whether the new concatenated axis contains duplicates. This can\nbe very expensive relative to the actual data concatenation.\n"}, {"param_name": "sort", "param_type": "bool, default False", "param_desc": "Sort non-concatenation axis if it is not already aligned. One exception to\nthis is when the non-concatentation axis is a DatetimeIndex and join=’outer’\nand the axis is not already aligned. In that case, the non-concatenation\naxis is always sorted lexicographically.\n"}, {"param_name": "copy", "param_type": "bool, default True", "param_desc": "If False, do not copy data unnecessarily.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.concat.html#pandas.concat"}, {"function_name": "pandas.from_dummies", "full_function": "pandas.from_dummies(data, sep=None, default_category=None)", "function_text": "Create a categorical DataFrame from a DataFrame of dummy variables.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.from_dummies.html#pandas.from_dummies"}, {"function_name": "pandas.unique", "full_function": "pandas.unique(values)", "function_text": "Return unique values based on a hash table.", "parameter_names_desc": [{"param_name": "values", "param_type": "1d array-like", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.unique.html#pandas.unique"}, {"function_name": "pandas.wide_to_long", "full_function": "pandas.wide_to_long(df, stubnames, i, j, sep='', suffix='\\\\d+')", "function_text": "Unpivot a DataFrame from wide to long format.", "parameter_names_desc": [{"param_name": "df", "param_type": "DataFrame", "param_desc": "The wide-format DataFrame.\n"}, {"param_name": "stubnames", "param_type": "str or list-like", "param_desc": "The stub name(s). The wide format variables are assumed to\nstart with the stub names.\n"}, {"param_name": "i", "param_type": "str or list-like", "param_desc": "Column(s) to use as id variable(s).\n"}, {"param_name": "j", "param_type": "str", "param_desc": "The name of the sub-observation variable. What you wish to name your\nsuffix in the long format.\n"}, {"param_name": "sep", "param_type": "str, default “”", "param_desc": "A character indicating the separation of the variable names\nin the wide format, to be stripped from the names in the long format.\nFor example, if your column names are A-suffix1, A-suffix2, you\ncan strip the hyphen by specifying sep=’-’.\n"}, {"param_name": "suffix", "param_type": "str, default ‘\\d+’", "param_desc": "A regular expression capturing the wanted suffixes. ‘\\d+’ captures\nnumeric suffixes. Suffixes with no numbers could be specified with the\nnegated character class ‘\\D+’. You can also further disambiguate\nsuffixes, for example, if your wide variables are of the form A-one,\nB-two,.., and you have an unrelated column A-rating, you can ignore the\nlast one by specifying suffix=’(!?one|two)’. When all suffixes are\nnumeric, they are cast to int64/float64.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.wide_to_long.html#pandas.wide_to_long"}]}, {"name": "Top-level missing data", "url": "https://pandas.pydata.org/docs/reference/general_functions.html#top-level-missing-data", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.isna.html#pandas.isna", "https://pandas.pydata.org/docs/reference/api/pandas.notna.html#pandas.notna", "https://pandas.pydata.org/docs/reference/api/pandas.isnull.html#pandas.isnull", "https://pandas.pydata.org/docs/reference/api/pandas.notnull.html#pandas.notnull"], "function_definitions": [{"function_name": "pandas.isna", "full_function": "pandas.isna(obj)", "function_text": "Detect missing values for an array-like object.", "parameter_names_desc": [{"param_name": "obj", "param_type": "scalar or array-like", "param_desc": "Object to check for null or missing values.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.isna.html#pandas.isna"}, {"function_name": "pandas.notna", "full_function": "pandas.notna(obj)", "function_text": "Detect non-missing values for an array-like object.", "parameter_names_desc": [{"param_name": "obj", "param_type": "array-like or object value", "param_desc": "Object to check for not null or non-missing values.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.notna.html#pandas.notna"}, {"function_name": "pandas.isnull", "full_function": "pandas.isnull(obj)", "function_text": "Detect missing values for an array-like object.", "parameter_names_desc": [{"param_name": "obj", "param_type": "scalar or array-like", "param_desc": "Object to check for null or missing values.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.isnull.html#pandas.isnull"}, {"function_name": "pandas.notnull", "full_function": "pandas.notnull(obj)", "function_text": "Detect non-missing values for an array-like object.", "parameter_names_desc": [{"param_name": "obj", "param_type": "array-like or object value", "param_desc": "Object to check for not null or non-missing values.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.notnull.html#pandas.notnull"}]}, {"name": "Top-level dealing with numeric data", "url": "https://pandas.pydata.org/docs/reference/general_functions.html#top-level-dealing-with-numeric-data", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.to_numeric.html#pandas.to_numeric"], "function_definitions": [{"function_name": "pandas.to_numeric", "full_function": "pandas.to_numeric(arg, errors='raise', downcast=None, dtype_backend=_NoDefault.no_default)", "function_text": "Convert argument to a numeric type.", "parameter_names_desc": [{"param_name": "arg", "param_type": "scalar, list, tuple, 1-d array, or Series", "param_desc": "Argument to be converted.\n"}, {"param_name": "errors", "param_type": "{‘ignore’, ‘raise’, ‘coerce’}, default ‘raise’", "param_desc": "\nIf ‘raise’, then invalid parsing will raise an exception.\nIf ‘coerce’, then invalid parsing will be set as NaN.\nIf ‘ignore’, then invalid parsing will return the input.\n\n\nChanged in version 2.2.\n\n“ignore” is deprecated. Catch exceptions explicitly instead.\n"}, {"param_name": "downcast", "param_type": "str, default None", "param_desc": "Can be ‘integer’, ‘signed’, ‘unsigned’, or ‘float’.\nIf not None, and if the data has been successfully cast to a\nnumerical dtype (or if the data was numeric to begin with),\ndowncast that resulting data to the smallest numerical dtype\npossible according to the following rules:\n\n‘integer’ or ‘signed’: smallest signed int dtype (min.: np.int8)\n‘unsigned’: smallest unsigned int dtype (min.: np.uint8)\n‘float’: smallest float dtype (min.: np.float32)\n\nAs this behaviour is separate from the core conversion to\nnumeric values, any errors raised during the downcasting\nwill be surfaced regardless of the value of the ‘errors’ input.\nIn addition, downcasting will only occur if the size\nof the resulting data’s dtype is strictly larger than\nthe dtype it is to be cast to, so if none of the dtypes\nchecked satisfy that specification, no downcasting will be\nperformed on the data.\n"}, {"param_name": "dtype_backend", "param_type": "{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’", "param_desc": "Back-end data type applied to the resultant DataFrame\n(still experimental). Behaviour is as follows:\n\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\n(default).\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\nDataFrame.\n\n\nNew in version 2.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.to_numeric.html#pandas.to_numeric"}]}, {"name": "Top-level dealing with datetimelike data", "url": "https://pandas.pydata.org/docs/reference/general_functions.html#top-level-dealing-with-datetimelike-data", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html#pandas.to_datetime", "https://pandas.pydata.org/docs/reference/api/pandas.date_range.html#pandas.date_range", "https://pandas.pydata.org/docs/reference/api/pandas.period_range.html#pandas.period_range", "https://pandas.pydata.org/docs/reference/api/pandas.infer_freq.html#pandas.infer_freq", "https://pandas.pydata.org/docs/reference/api/pandas.to_timedelta.html#pandas.to_timedelta", "https://pandas.pydata.org/docs/reference/api/pandas.bdate_range.html#pandas.bdate_range", "https://pandas.pydata.org/docs/reference/api/pandas.timedelta_range.html#pandas.timedelta_range"], "function_definitions": [{"function_name": "pandas.to_datetime", "full_function": "pandas.to_datetime(arg, errors='raise', dayfirst=False, yearfirst=False, utc=False, format=None, exact=_NoDefault.no_default, unit=None, infer_datetime_format=_NoDefault.no_default, origin='unix', cache=True)", "function_text": "Convert argument to datetime.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html#pandas.to_datetime"}, {"function_name": "pandas.date_range", "full_function": "pandas.date_range(start=None, end=None, periods=None, freq=None, tz=None, normalize=False, name=None, inclusive='both', *, unit=None, **kwargs)", "function_text": "Return a fixed frequency DatetimeIndex.", "parameter_names_desc": [{"param_name": "start", "param_type": "str or datetime-like, optional", "param_desc": "Left bound for generating dates.\n"}, {"param_name": "end", "param_type": "str or datetime-like, optional", "param_desc": "Right bound for generating dates.\n"}, {"param_name": "periods", "param_type": "int, optional", "param_desc": "Number of periods to generate.\n"}, {"param_name": "freq", "param_type": "str, Timedelta, datetime.timedelta, or DateOffset, default ‘D’", "param_desc": "Frequency strings can have multiples, e.g. ‘5h’. See\nhere for a list of\nfrequency aliases.\n"}, {"param_name": "tz", "param_type": "str or tzinfo, optional", "param_desc": "Time zone name for returning localized DatetimeIndex, for example\n‘Asia/Hong_Kong’. By default, the resulting DatetimeIndex is\ntimezone-naive unless timezone-aware datetime-likes are passed.\n"}, {"param_name": "normalize", "param_type": "bool, default False", "param_desc": "Normalize start/end dates to midnight before generating date range.\n"}, {"param_name": "name", "param_type": "str, default None", "param_desc": "Name of the resulting DatetimeIndex.\n"}, {"param_name": "inclusive", "param_type": "{“both”, “neither”, “left”, “right”}, default “both”", "param_desc": "Include boundaries; Whether to set each bound as closed or open.\n\nNew in version 1.4.0.\n\n"}, {"param_name": "unit", "param_type": "str, default None", "param_desc": "Specify the desired resolution of the result.\n\nNew in version 2.0.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.date_range.html#pandas.date_range"}, {"function_name": "pandas.period_range", "full_function": "pandas.period_range(start=None, end=None, periods=None, freq=None, name=None)", "function_text": "Return a fixed frequency PeriodIndex.", "parameter_names_desc": [{"param_name": "start", "param_type": "str, datetime, date, pandas.Timestamp, or period-like, default None", "param_desc": "Left bound for generating periods.\n"}, {"param_name": "end", "param_type": "str, datetime, date, pandas.Timestamp, or period-like, default None", "param_desc": "Right bound for generating periods.\n"}, {"param_name": "periods", "param_type": "int, default None", "param_desc": "Number of periods to generate.\n"}, {"param_name": "freq", "param_type": "str or DateOffset, optional", "param_desc": "Frequency alias. By default the freq is taken from start or end\nif those are Period objects. Otherwise, the default is \"D\" for\ndaily frequency.\n"}, {"param_name": "name", "param_type": "str, default None", "param_desc": "Name of the resulting PeriodIndex.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.period_range.html#pandas.period_range"}, {"function_name": "pandas.infer_freq", "full_function": "pandas.infer_freq(index)", "function_text": "Infer the most likely frequency given the input index.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.infer_freq.html#pandas.infer_freq"}, {"function_name": "pandas.to_timedelta", "full_function": "pandas.to_timedelta(arg, unit=None, errors='raise')", "function_text": "Convert argument to timedelta.", "parameter_names_desc": [{"param_name": "arg", "param_type": "str, timedelta, list-like or Series", "param_desc": "The data to be converted to timedelta.\n\nChanged in version 2.0: Strings with units ‘M’, ‘Y’ and ‘y’ do not represent\nunambiguous timedelta values and will raise an exception.\n\n"}, {"param_name": "unit", "param_type": "str, optional", "param_desc": "Denotes the unit of the arg for numeric arg. Defaults to \"ns\".\nPossible values:\n\n‘W’\n‘D’ / ‘days’ / ‘day’\n‘hours’ / ‘hour’ / ‘hr’ / ‘h’ / ‘H’\n‘m’ / ‘minute’ / ‘min’ / ‘minutes’ / ‘T’\n‘s’ / ‘seconds’ / ‘sec’ / ‘second’ / ‘S’\n‘ms’ / ‘milliseconds’ / ‘millisecond’ / ‘milli’ / ‘millis’ / ‘L’\n‘us’ / ‘microseconds’ / ‘microsecond’ / ‘micro’ / ‘micros’ / ‘U’\n‘ns’ / ‘nanoseconds’ / ‘nano’ / ‘nanos’ / ‘nanosecond’ / ‘N’\n\nMust not be specified when arg contains strings and errors=\"raise\".\n\nDeprecated since version 2.2.0: Units ‘H’, ‘T’, ‘S’, ‘L’, ‘U’ and ‘N’ are deprecated and will be removed\nin a future version. Please use ‘h’, ‘min’, ‘s’, ‘ms’, ‘us’, and ‘ns’\ninstead of ‘H’, ‘T’, ‘S’, ‘L’, ‘U’ and ‘N’.\n\n"}, {"param_name": "errors", "param_type": "{‘ignore’, ‘raise’, ‘coerce’}, default ‘raise’", "param_desc": "\nIf ‘raise’, then invalid parsing will raise an exception.\nIf ‘coerce’, then invalid parsing will be set as NaT.\nIf ‘ignore’, then invalid parsing will return the input.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.to_timedelta.html#pandas.to_timedelta"}, {"function_name": "pandas.bdate_range", "full_function": "pandas.bdate_range(start=None, end=None, periods=None, freq='B', tz=None, normalize=True, name=None, weekmask=None, holidays=None, inclusive='both', **kwargs)", "function_text": "Return a fixed frequency DatetimeIndex with business day as the default.", "parameter_names_desc": [{"param_name": "start", "param_type": "str or datetime-like, default None", "param_desc": "Left bound for generating dates.\n"}, {"param_name": "end", "param_type": "str or datetime-like, default None", "param_desc": "Right bound for generating dates.\n"}, {"param_name": "periods", "param_type": "int, default None", "param_desc": "Number of periods to generate.\n"}, {"param_name": "freq", "param_type": "str, Timedelta, datetime.timedelta, or DateOffset, default ‘B’", "param_desc": "Frequency strings can have multiples, e.g. ‘5h’. The default is\nbusiness daily (‘B’).\n"}, {"param_name": "tz", "param_type": "str or None", "param_desc": "Time zone name for returning localized DatetimeIndex, for example\nAsia/Beijing.\n"}, {"param_name": "normalize", "param_type": "bool, default False", "param_desc": "Normalize start/end dates to midnight before generating date range.\n"}, {"param_name": "name", "param_type": "str, default None", "param_desc": "Name of the resulting DatetimeIndex.\n"}, {"param_name": "weekmask", "param_type": "str or None, default None", "param_desc": "Weekmask of valid business days, passed to numpy.busdaycalendar,\nonly used when custom frequency strings are passed. The default\nvalue None is equivalent to ‘Mon Tue Wed Thu Fri’.\n"}, {"param_name": "holidays", "param_type": "list-like or None, default None", "param_desc": "Dates to exclude from the set of valid business days, passed to\nnumpy.busdaycalendar, only used when custom frequency strings\nare passed.\n"}, {"param_name": "inclusive", "param_type": "{“both”, “neither”, “left”, “right”}, default “both”", "param_desc": "Include boundaries; Whether to set each bound as closed or open.\n\nNew in version 1.4.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.bdate_range.html#pandas.bdate_range"}, {"function_name": "pandas.timedelta_range", "full_function": "pandas.timedelta_range(start=None, end=None, periods=None, freq=None, name=None, closed=None, *, unit=None)", "function_text": "Return a fixed frequency TimedeltaIndex with day as the default.", "parameter_names_desc": [{"param_name": "start", "param_type": "str or timedelta-like, default None", "param_desc": "Left bound for generating timedeltas.\n"}, {"param_name": "end", "param_type": "str or timedelta-like, default None", "param_desc": "Right bound for generating timedeltas.\n"}, {"param_name": "periods", "param_type": "int, default None", "param_desc": "Number of periods to generate.\n"}, {"param_name": "freq", "param_type": "str, Timedelta, datetime.timedelta, or DateOffset, default ‘D’", "param_desc": "Frequency strings can have multiples, e.g. ‘5h’.\n"}, {"param_name": "name", "param_type": "str, default None", "param_desc": "Name of the resulting TimedeltaIndex.\n"}, {"param_name": "closed", "param_type": "str, default None", "param_desc": "Make the interval closed with respect to the given frequency to\nthe ‘left’, ‘right’, or both sides (None).\n"}, {"param_name": "unit", "param_type": "str, default None", "param_desc": "Specify the desired resolution of the result.\n\nNew in version 2.0.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.timedelta_range.html#pandas.timedelta_range"}]}, {"name": "Top-level dealing with Interval data", "url": "https://pandas.pydata.org/docs/reference/general_functions.html#top-level-dealing-with-interval-data", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.interval_range.html#pandas.interval_range"], "function_definitions": [{"function_name": "pandas.interval_range", "full_function": "pandas.interval_range(start=None, end=None, periods=None, freq=None, name=None, closed='right')", "function_text": "Return a fixed frequency IntervalIndex.", "parameter_names_desc": [{"param_name": "start", "param_type": "numeric or datetime-like, default None", "param_desc": "Left bound for generating intervals.\n"}, {"param_name": "end", "param_type": "numeric or datetime-like, default None", "param_desc": "Right bound for generating intervals.\n"}, {"param_name": "periods", "param_type": "int, default None", "param_desc": "Number of periods to generate.\n"}, {"param_name": "freq", "param_type": "numeric, str, Timedelta, datetime.timedelta, or DateOffset, default None", "param_desc": "The length of each interval. Must be consistent with the type of start\nand end, e.g. 2 for numeric, or ‘5H’ for datetime-like. Default is 1\nfor numeric and ‘D’ for datetime-like.\n"}, {"param_name": "name", "param_type": "str, default None", "param_desc": "Name of the resulting IntervalIndex.\n"}, {"param_name": "closed", "param_type": "{‘left’, ‘right’, ‘both’, ‘neither’}, default ‘right’", "param_desc": "Whether the intervals are closed on the left-side, right-side, both\nor neither.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.interval_range.html#pandas.interval_range"}]}, {"name": "Top-level evaluation", "url": "https://pandas.pydata.org/docs/reference/general_functions.html#top-level-evaluation", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.eval.html#pandas.eval"], "function_definitions": [{"function_name": "pandas.eval", "full_function": "pandas.eval(expr, parser='pandas', engine=None, local_dict=None, global_dict=None, resolvers=(), level=0, target=None, inplace=False)", "function_text": "Evaluate a Python expression as a string using various backends.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.eval.html#pandas.eval"}]}, {"name": "Datetime formats", "url": "https://pandas.pydata.org/docs/reference/general_functions.html#datetime-formats", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.api.guess_datetime_format.html#pandas.tseries.api.guess_datetime_format"], "function_definitions": [{"function_name": "pandas.tseries.api.guess_datetime_format", "full_function": "pandas.tseries.api.guess_datetime_format(dt_str, dayfirst=False)#", "function_text": "Guess the datetime format of a given datetime string.", "parameter_names_desc": [{"param_name": "dt_str", "param_type": "str", "param_desc": "Datetime string to guess the format of.\n"}, {"param_name": "dayfirst", "param_type": "bool, default False", "param_desc": "If True parses dates with the day first, eg 20/01/2005\n\nWarning\ndayfirst=True is not strict, but will prefer to parse\nwith day first (this is a known bug).\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.api.guess_datetime_format.html#pandas.tseries.api.guess_datetime_format"}]}, {"name": "Hashing", "url": "https://pandas.pydata.org/docs/reference/general_functions.html#hashing", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.util.hash_array.html#pandas.util.hash_array", "https://pandas.pydata.org/docs/reference/api/pandas.util.hash_pandas_object.html#pandas.util.hash_pandas_object"], "function_definitions": [{"function_name": "pandas.util.hash_array", "full_function": "pandas.util.hash_array(vals, encoding='utf8', hash_key='0123456789123456', categorize=True)", "function_text": "Given a 1d array, return an array of deterministic integers.", "parameter_names_desc": [{"param_name": "vals", "param_type": "ndarray or ExtensionArray", "param_desc": ""}, {"param_name": "encoding", "param_type": "str, default ‘utf8’", "param_desc": "Encoding for data & key when strings.\n"}, {"param_name": "hash_key", "param_type": "str, default _default_hash_key", "param_desc": "Hash_key for string key to encode.\n"}, {"param_name": "categorize", "param_type": "bool, default True", "param_desc": "Whether to first categorize object arrays before hashing. This is more\nefficient when the array contains duplicate values.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.util.hash_array.html#pandas.util.hash_array"}, {"function_name": "pandas.util.hash_pandas_object", "full_function": "pandas.util.hash_pandas_object(obj, index=True, encoding='utf8', hash_key='0123456789123456', categorize=True)", "function_text": "Return a data hash of the Index/Series/DataFrame.", "parameter_names_desc": [{"param_name": "obj", "param_type": "Index, Series, or DataFrame", "param_desc": ""}, {"param_name": "index", "param_type": "bool, default True", "param_desc": "Include the index in the hash (if Series/DataFrame).\n"}, {"param_name": "encoding", "param_type": "str, default ‘utf8’", "param_desc": "Encoding for data & key when strings.\n"}, {"param_name": "hash_key", "param_type": "str, default _default_hash_key", "param_desc": "Hash_key for string key to encode.\n"}, {"param_name": "categorize", "param_type": "bool, default True", "param_desc": "Whether to first categorize object arrays before hashing. This is more\nefficient when the array contains duplicate values.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.util.hash_pandas_object.html#pandas.util.hash_pandas_object"}]}, {"name": "Importing from other DataFrame libraries", "url": "https://pandas.pydata.org/docs/reference/general_functions.html#importing-from-other-dataframe-libraries", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.api.interchange.from_dataframe.html#pandas.api.interchange.from_dataframe"], "function_definitions": [{"function_name": "pandas.api.interchange.from_dataframe", "full_function": "pandas.api.interchange.from_dataframe(df, allow_copy=True)", "function_text": "Build a pd.DataFrame from any DataFrame supporting the interchange protocol.", "parameter_names_desc": [{"param_name": "df", "param_type": "DataFrameXchg", "param_desc": "Object supporting the interchange protocol, i.e. __dataframe__ method.\n"}, {"param_name": "allow_copy", "param_type": "bool, default: True", "param_desc": "Whether to allow copying the memory to perform the conversion\n(if false then zero-copy approach is requested).\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.interchange.from_dataframe.html#pandas.api.interchange.from_dataframe"}]}], "name": "General functions", "url": "https://pandas.pydata.org/docs/reference/general_functions.html"}, "series.html": {"functions": [{"name": "Constructor", "url": "https://pandas.pydata.org/docs/reference/series.html#constructor", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.html#pandas.Series"], "function_definitions": [{"function_name": "pandas.Series", "full_function": "class pandas.Series(data=None, index=None, dtype=None, name=None, copy=None, fastpath=_NoDefault.no_default)", "function_text": "One-dimensional ndarray with axis labels (including time series).", "parameter_names_desc": [{"param_name": "data", "param_type": "array-like, Iterable, dict, or scalar value", "param_desc": "Contains data stored in Series. If data is a dict, argument order is\nmaintained.\n"}, {"param_name": "index", "param_type": "array-like or Index (1d)", "param_desc": "Values must be hashable and have the same length as data.\nNon-unique index values are allowed. Will default to\nRangeIndex (0, 1, 2, …, n) if not provided. If data is dict-like\nand index is None, then the keys in the data are used as the index. If the\nindex is not None, the resulting Series is reindexed with the index values.\n"}, {"param_name": "dtype", "param_type": "str, numpy.dtype, or ExtensionDtype, optional", "param_desc": "Data type for the output Series. If not specified, this will be\ninferred from data.\nSee the user guide for more usages.\n"}, {"param_name": "name", "param_type": "Hashable, default None", "param_desc": "The name to give to the Series.\n"}, {"param_name": "copy", "param_type": "bool, default False", "param_desc": "Copy input data. Only affects Series or 1d ndarray input. See examples.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.html#pandas.Series"}]}, {"name": "Attributes", "url": "https://pandas.pydata.org/docs/reference/series.html#attributes", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.index.html#pandas.Series.index", "https://pandas.pydata.org/docs/reference/api/pandas.Series.values.html#pandas.Series.values", "https://pandas.pydata.org/docs/reference/api/pandas.Series.shape.html#pandas.Series.shape", "https://pandas.pydata.org/docs/reference/api/pandas.Series.ndim.html#pandas.Series.ndim", "https://pandas.pydata.org/docs/reference/api/pandas.Series.T.html#pandas.Series.T", "https://pandas.pydata.org/docs/reference/api/pandas.Series.hasnans.html#pandas.Series.hasnans", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dtypes.html#pandas.Series.dtypes", "https://pandas.pydata.org/docs/reference/api/pandas.Series.flags.html#pandas.Series.flags", "https://pandas.pydata.org/docs/reference/api/pandas.Series.array.html#pandas.Series.array", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dtype.html#pandas.Series.dtype", "https://pandas.pydata.org/docs/reference/api/pandas.Series.nbytes.html#pandas.Series.nbytes", "https://pandas.pydata.org/docs/reference/api/pandas.Series.size.html#pandas.Series.size", "https://pandas.pydata.org/docs/reference/api/pandas.Series.memory_usage.html#pandas.Series.memory_usage", "https://pandas.pydata.org/docs/reference/api/pandas.Series.empty.html#pandas.Series.empty", "https://pandas.pydata.org/docs/reference/api/pandas.Series.name.html#pandas.Series.name", "https://pandas.pydata.org/docs/reference/api/pandas.Series.set_flags.html#pandas.Series.set_flags"], "function_definitions": [{"function_name": "pandas.Series.index", "full_function": "Series.index#", "function_text": "The index (axis labels) of the Series.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.index.html#pandas.Series.index"}, {"function_name": "pandas.Series.values", "full_function": "property Series.values", "function_text": "Return Series as ndarray or ndarray-like depending on the dtype.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.values.html#pandas.Series.values"}, {"function_name": "pandas.Series.shape", "full_function": "property Series.shape", "function_text": "Return a tuple of the shape of the underlying data.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.shape.html#pandas.Series.shape"}, {"function_name": "pandas.Series.ndim", "full_function": "property Series.ndim", "function_text": "Number of dimensions of the underlying data, by definition 1.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.ndim.html#pandas.Series.ndim"}, {"function_name": "pandas.Series.T", "full_function": "property Series.T", "function_text": "Return the transpose, which is by definition self.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.T.html#pandas.Series.T"}, {"function_name": "pandas.Series.hasnans", "full_function": "property Series.hasnans", "function_text": "Return True if there are any NaNs.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.hasnans.html#pandas.Series.hasnans"}, {"function_name": "pandas.Series.dtypes", "full_function": "property Series.dtypes", "function_text": "Return the dtype object of the underlying data.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dtypes.html#pandas.Series.dtypes"}, {"function_name": "pandas.Series.flags", "full_function": "property Series.flags", "function_text": "Get the properties associated with this pandas object.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.flags.html#pandas.Series.flags"}, {"function_name": "pandas.Series.array", "full_function": "property Series.array", "function_text": "The ExtensionArray of the data backing this Series or Index.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.array.html#pandas.Series.array"}, {"function_name": "pandas.Series.dtype", "full_function": "property Series.dtype", "function_text": "Return the dtype object of the underlying data.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dtype.html#pandas.Series.dtype"}, {"function_name": "pandas.Series.nbytes", "full_function": "property Series.nbytes", "function_text": "Return the number of bytes in the underlying data.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.nbytes.html#pandas.Series.nbytes"}, {"function_name": "pandas.Series.size", "full_function": "property Series.size", "function_text": "Return the number of elements in the underlying data.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.size.html#pandas.Series.size"}, {"function_name": "pandas.Series.memory_usage", "full_function": "Series.memory_usage(index=True, deep=False)", "function_text": "Return the memory usage of the Series.", "parameter_names_desc": [{"param_name": "index", "param_type": "bool, default True", "param_desc": "Specifies whether to include the memory usage of the Series index.\n"}, {"param_name": "deep", "param_type": "bool, default False", "param_desc": "If True, introspect the data deeply by interrogating\nobject dtypes for system-level memory consumption, and include\nit in the returned value.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.memory_usage.html#pandas.Series.memory_usage"}, {"function_name": "pandas.Series.empty", "full_function": "property Series.empty", "function_text": "Indicator whether Series/DataFrame is empty.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.empty.html#pandas.Series.empty"}, {"function_name": "pandas.Series.name", "full_function": "property Series.name", "function_text": "Return the name of the Series.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.name.html#pandas.Series.name"}, {"function_name": "pandas.Series.set_flags", "full_function": "Series.set_flags(*, copy=False, allows_duplicate_labels=None)", "function_text": "Return a new object with updated flags.", "parameter_names_desc": [{"param_name": "copy", "param_type": "bool, default False", "param_desc": "Specify if a copy of the object should be made.\n\nNote\nThe copy keyword will change behavior in pandas 3.0.\nCopy-on-Write\nwill be enabled by default, which means that all methods with a\ncopy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas.\nYou can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True\n\n"}, {"param_name": "allows_duplicate_labels", "param_type": "bool, optional", "param_desc": "Whether the returned object allows duplicate labels.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.set_flags.html#pandas.Series.set_flags"}]}, {"name": "Conversion", "url": "https://pandas.pydata.org/docs/reference/series.html#conversion", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.astype.html#pandas.Series.astype", "https://pandas.pydata.org/docs/reference/api/pandas.Series.infer_objects.html#pandas.Series.infer_objects", "https://pandas.pydata.org/docs/reference/api/pandas.Series.bool.html#pandas.Series.bool", "https://pandas.pydata.org/docs/reference/api/pandas.Series.to_period.html#pandas.Series.to_period", "https://pandas.pydata.org/docs/reference/api/pandas.Series.to_list.html#pandas.Series.to_list", "https://pandas.pydata.org/docs/reference/api/pandas.Series.convert_dtypes.html#pandas.Series.convert_dtypes", "https://pandas.pydata.org/docs/reference/api/pandas.Series.copy.html#pandas.Series.copy", "https://pandas.pydata.org/docs/reference/api/pandas.Series.to_numpy.html#pandas.Series.to_numpy", "https://pandas.pydata.org/docs/reference/api/pandas.Series.to_timestamp.html#pandas.Series.to_timestamp", "https://pandas.pydata.org/docs/reference/api/pandas.Series.__array__.html#pandas.Series.__array__"], "function_definitions": [{"function_name": "pandas.Series.astype", "full_function": "Series.astype(dtype, copy=None, errors='raise')", "function_text": "Cast a pandas object to a specified dtype dtype.", "parameter_names_desc": [{"param_name": "dtype", "param_type": "str, data type, Series or Mapping of column name -> data type", "param_desc": "Use a str, numpy.dtype, pandas.ExtensionDtype or Python type to\ncast entire pandas object to the same type. Alternatively, use a\nmapping, e.g. {col: dtype, …}, where col is a column label and dtype is\na numpy.dtype or Python type to cast one or more of the DataFrame’s\ncolumns to column-specific types.\n"}, {"param_name": "copy", "param_type": "bool, default True", "param_desc": "Return a copy when copy=True (be very careful setting\ncopy=False as changes to values then may propagate to other\npandas objects).\n\nNote\nThe copy keyword will change behavior in pandas 3.0.\nCopy-on-Write\nwill be enabled by default, which means that all methods with a\ncopy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas.\nYou can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True\n\n"}, {"param_name": "errors", "param_type": "{‘raise’, ‘ignore’}, default ‘raise’", "param_desc": "Control raising of exceptions on invalid data for provided dtype.\n\nraise : allow exceptions to be raised\nignore : suppress exceptions. On error return original object.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.astype.html#pandas.Series.astype"}, {"function_name": "pandas.Series.infer_objects", "full_function": "Series.infer_objects(copy=None)", "function_text": "Attempt to infer better dtypes for object columns.", "parameter_names_desc": [{"param_name": "copy", "param_type": "bool, default True", "param_desc": "Whether to make a copy for non-object or non-inferable columns\nor Series.\n\nNote\nThe copy keyword will change behavior in pandas 3.0.\nCopy-on-Write\nwill be enabled by default, which means that all methods with a\ncopy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas.\nYou can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.infer_objects.html#pandas.Series.infer_objects"}, {"function_name": "pandas.Series.bool", "full_function": "Series.bool()", "function_text": "Return the bool of a single element Series or DataFrame.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.bool.html#pandas.Series.bool"}, {"function_name": "pandas.Series.to_period", "full_function": "Series.to_period(freq=None, copy=None)", "function_text": "Convert Series from DatetimeIndex to PeriodIndex.", "parameter_names_desc": [{"param_name": "freq", "param_type": "str, default None", "param_desc": "Frequency associated with the PeriodIndex.\n"}, {"param_name": "copy", "param_type": "bool, default True", "param_desc": "Whether or not to return a copy.\n\nNote\nThe copy keyword will change behavior in pandas 3.0.\nCopy-on-Write\nwill be enabled by default, which means that all methods with a\ncopy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas.\nYou can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.to_period.html#pandas.Series.to_period"}, {"function_name": "pandas.Series.to_list", "full_function": "Series.to_list()", "function_text": "Return a list of the values.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.to_list.html#pandas.Series.to_list"}, {"function_name": "pandas.Series.convert_dtypes", "full_function": "Series.convert_dtypes(infer_objects=True, convert_string=True, convert_integer=True, convert_boolean=True, convert_floating=True, dtype_backend='numpy_nullable')", "function_text": "Convert columns to the best possible dtypes using dtypes supporting pd.NA.", "parameter_names_desc": [{"param_name": "infer_objects", "param_type": "bool, default True", "param_desc": "Whether object dtypes should be converted to the best possible types.\n"}, {"param_name": "convert_string", "param_type": "bool, default True", "param_desc": "Whether object dtypes should be converted to StringDtype().\n"}, {"param_name": "convert_integer", "param_type": "bool, default True", "param_desc": "Whether, if possible, conversion can be done to integer extension types.\n"}, {"param_name": "convert_boolean", "param_type": "bool, defaults True", "param_desc": "Whether object dtypes should be converted to BooleanDtypes().\n"}, {"param_name": "convert_floating", "param_type": "bool, defaults True", "param_desc": "Whether, if possible, conversion can be done to floating extension types.\nIf convert_integer is also True, preference will be give to integer\ndtypes if the floats can be faithfully casted to integers.\n"}, {"param_name": "dtype_backend", "param_type": "{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’", "param_desc": "Back-end data type applied to the resultant DataFrame\n(still experimental). Behaviour is as follows:\n\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\n(default).\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\nDataFrame.\n\n\nNew in version 2.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.convert_dtypes.html#pandas.Series.convert_dtypes"}, {"function_name": "pandas.Series.copy", "full_function": "Series.copy(deep=True)", "function_text": "Make a copy of this object’s indices and data.", "parameter_names_desc": [{"param_name": "deep", "param_type": "bool, default True", "param_desc": "Make a deep copy, including a copy of the data and the indices.\nWith deep=False neither the indices nor the data are copied.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.copy.html#pandas.Series.copy"}, {"function_name": "pandas.Series.to_numpy", "full_function": "Series.to_numpy(dtype=None, copy=False, na_value=_NoDefault.no_default, **kwargs)", "function_text": "A NumPy ndarray representing the values in this Series or Index.", "parameter_names_desc": [{"param_name": "dtype", "param_type": "str or numpy.dtype, optional", "param_desc": "The dtype to pass to numpy.asarray().\n"}, {"param_name": "copy", "param_type": "bool, default False", "param_desc": "Whether to ensure that the returned value is not a view on\nanother array. Note that copy=False does not ensure that\nto_numpy() is no-copy. Rather, copy=True ensure that\na copy is made, even if not strictly necessary.\n"}, {"param_name": "na_value", "param_type": "Any, optional", "param_desc": "The value to use for missing values. The default value depends\non dtype and the type of the array.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.to_numpy.html#pandas.Series.to_numpy"}, {"function_name": "pandas.Series.to_timestamp", "full_function": "Series.to_timestamp(freq=None, how='start', copy=None)", "function_text": "Cast to DatetimeIndex of Timestamps, at beginning of period.", "parameter_names_desc": [{"param_name": "freq", "param_type": "str, default frequency of PeriodIndex", "param_desc": "Desired frequency.\n"}, {"param_name": "how", "param_type": "{‘s’, ‘e’, ‘start’, ‘end’}", "param_desc": "Convention for converting period to timestamp; start of period\nvs. end.\n"}, {"param_name": "copy", "param_type": "bool, default True", "param_desc": "Whether or not to return a copy.\n\nNote\nThe copy keyword will change behavior in pandas 3.0.\nCopy-on-Write\nwill be enabled by default, which means that all methods with a\ncopy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas.\nYou can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.to_timestamp.html#pandas.Series.to_timestamp"}, {"function_name": "pandas.Series.__array__", "full_function": "Series.__array__(dtype=None, copy=None)", "function_text": "Return the values as a NumPy array.", "parameter_names_desc": [{"param_name": "dtype", "param_type": "str or numpy.dtype, optional", "param_desc": "The dtype to use for the resulting NumPy array. By default,\nthe dtype is inferred from the data.\n"}, {"param_name": "copy", "param_type": "bool or None, optional", "param_desc": "Unused.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.__array__.html#pandas.Series.__array__"}]}, {"name": "Indexing, iteration", "url": "https://pandas.pydata.org/docs/reference/series.html#indexing-iteration", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.get.html#pandas.Series.get", "https://pandas.pydata.org/docs/reference/api/pandas.Series.iat.html#pandas.Series.iat", "https://pandas.pydata.org/docs/reference/api/pandas.Series.iloc.html#pandas.Series.iloc", "https://pandas.pydata.org/docs/reference/api/pandas.Series.items.html#pandas.Series.items", "https://pandas.pydata.org/docs/reference/api/pandas.Series.pop.html#pandas.Series.pop", "https://pandas.pydata.org/docs/reference/api/pandas.Series.xs.html#pandas.Series.xs", "https://pandas.pydata.org/docs/reference/api/pandas.Series.at.html#pandas.Series.at", "https://pandas.pydata.org/docs/reference/api/pandas.Series.loc.html#pandas.Series.loc", "https://pandas.pydata.org/docs/reference/api/pandas.Series.__iter__.html#pandas.Series.__iter__", "https://pandas.pydata.org/docs/reference/api/pandas.Series.keys.html#pandas.Series.keys", "https://pandas.pydata.org/docs/reference/api/pandas.Series.item.html#pandas.Series.item"], "function_definitions": [{"function_name": "pandas.Series.get", "full_function": "Series.get(key, default=None)", "function_text": "Get item from object for given key (ex: DataFrame column).", "parameter_names_desc": [{"param_name": "key", "param_type": "object", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.get.html#pandas.Series.get"}, {"function_name": "pandas.Series.iat", "full_function": "property Series.iat", "function_text": "Access a single value for a row/column pair by integer position.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.iat.html#pandas.Series.iat"}, {"function_name": "pandas.Series.iloc", "full_function": "property Series.iloc", "function_text": "Purely integer-location based indexing for selection by position.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.iloc.html#pandas.Series.iloc"}, {"function_name": "pandas.Series.items", "full_function": "Series.items()", "function_text": "Lazily iterate over (index, value) tuples.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.items.html#pandas.Series.items"}, {"function_name": "pandas.Series.pop", "full_function": "Series.pop(item)", "function_text": "Return item and drops from series. Raise KeyError if not found.", "parameter_names_desc": [{"param_name": "item", "param_type": "label", "param_desc": "Index of the element that needs to be removed.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.pop.html#pandas.Series.pop"}, {"function_name": "pandas.Series.xs", "full_function": "Series.xs(key, axis=0, level=None, drop_level=True)", "function_text": "Return cross-section from the Series/DataFrame.", "parameter_names_desc": [{"param_name": "key", "param_type": "label or tuple of label", "param_desc": "Label contained in the index, or partially in a MultiIndex.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "Axis to retrieve cross-section on.\n"}, {"param_name": "level", "param_type": "object, defaults to first n levels (n=1 or len(key))", "param_desc": "In case of a key partially contained in a MultiIndex, indicate\nwhich levels are used. Levels can be referred by label or position.\n"}, {"param_name": "drop_level", "param_type": "bool, default True", "param_desc": "If False, returns object with same levels as self.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.xs.html#pandas.Series.xs"}, {"function_name": "pandas.Series.at", "full_function": "property Series.at", "function_text": "Access a single value for a row/column label pair.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.at.html#pandas.Series.at"}, {"function_name": "pandas.Series.loc", "full_function": "property Series.loc", "function_text": "Access a group of rows and columns by label(s) or a boolean array.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.loc.html#pandas.Series.loc"}, {"function_name": "pandas.Series.__iter__", "full_function": "Series.__iter__()", "function_text": "Return an iterator of the values.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.__iter__.html#pandas.Series.__iter__"}, {"function_name": "pandas.Series.keys", "full_function": "Series.keys()", "function_text": "Return alias for index.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.keys.html#pandas.Series.keys"}, {"function_name": "pandas.Series.item", "full_function": "Series.item()", "function_text": "Return the first element of the underlying data as a Python scalar.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.item.html#pandas.Series.item"}]}, {"name": "Binary operator functions", "url": "https://pandas.pydata.org/docs/reference/series.html#binary-operator-functions", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.add.html#pandas.Series.add", "https://pandas.pydata.org/docs/reference/api/pandas.Series.mul.html#pandas.Series.mul", "https://pandas.pydata.org/docs/reference/api/pandas.Series.truediv.html#pandas.Series.truediv", "https://pandas.pydata.org/docs/reference/api/pandas.Series.mod.html#pandas.Series.mod", "https://pandas.pydata.org/docs/reference/api/pandas.Series.radd.html#pandas.Series.radd", "https://pandas.pydata.org/docs/reference/api/pandas.Series.rmul.html#pandas.Series.rmul", "https://pandas.pydata.org/docs/reference/api/pandas.Series.rtruediv.html#pandas.Series.rtruediv", "https://pandas.pydata.org/docs/reference/api/pandas.Series.rmod.html#pandas.Series.rmod", "https://pandas.pydata.org/docs/reference/api/pandas.Series.combine.html#pandas.Series.combine", "https://pandas.pydata.org/docs/reference/api/pandas.Series.round.html#pandas.Series.round", "https://pandas.pydata.org/docs/reference/api/pandas.Series.gt.html#pandas.Series.gt", "https://pandas.pydata.org/docs/reference/api/pandas.Series.ge.html#pandas.Series.ge", "https://pandas.pydata.org/docs/reference/api/pandas.Series.eq.html#pandas.Series.eq", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dot.html#pandas.Series.dot", "https://pandas.pydata.org/docs/reference/api/pandas.Series.sub.html#pandas.Series.sub", "https://pandas.pydata.org/docs/reference/api/pandas.Series.div.html#pandas.Series.div", "https://pandas.pydata.org/docs/reference/api/pandas.Series.floordiv.html#pandas.Series.floordiv", "https://pandas.pydata.org/docs/reference/api/pandas.Series.pow.html#pandas.Series.pow", "https://pandas.pydata.org/docs/reference/api/pandas.Series.rsub.html#pandas.Series.rsub", "https://pandas.pydata.org/docs/reference/api/pandas.Series.rdiv.html#pandas.Series.rdiv", "https://pandas.pydata.org/docs/reference/api/pandas.Series.rfloordiv.html#pandas.Series.rfloordiv", "https://pandas.pydata.org/docs/reference/api/pandas.Series.rpow.html#pandas.Series.rpow", "https://pandas.pydata.org/docs/reference/api/pandas.Series.combine_first.html#pandas.Series.combine_first", "https://pandas.pydata.org/docs/reference/api/pandas.Series.lt.html#pandas.Series.lt", "https://pandas.pydata.org/docs/reference/api/pandas.Series.le.html#pandas.Series.le", "https://pandas.pydata.org/docs/reference/api/pandas.Series.ne.html#pandas.Series.ne", "https://pandas.pydata.org/docs/reference/api/pandas.Series.product.html#pandas.Series.product"], "function_definitions": [{"function_name": "pandas.Series.add", "full_function": "Series.add(other, level=None, fill_value=None, axis=0)", "function_text": "Return Addition of series and other, element-wise (binary operator add).", "parameter_names_desc": [{"param_name": "other", "param_type": "Series or scalar value", "param_desc": ""}, {"param_name": "level", "param_type": "int or name", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "None or float value, default None (NaN)", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’}", "param_desc": "Unused. Parameter needed for compatibility with DataFrame.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.add.html#pandas.Series.add"}, {"function_name": "pandas.Series.mul", "full_function": "Series.mul(other, level=None, fill_value=None, axis=0)", "function_text": "Return Multiplication of series and other, element-wise (binary operator mul).", "parameter_names_desc": [{"param_name": "other", "param_type": "Series or scalar value", "param_desc": ""}, {"param_name": "level", "param_type": "int or name", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "None or float value, default None (NaN)", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’}", "param_desc": "Unused. Parameter needed for compatibility with DataFrame.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.mul.html#pandas.Series.mul"}, {"function_name": "pandas.Series.truediv", "full_function": "Series.truediv(other, level=None, fill_value=None, axis=0)", "function_text": "Return Floating division of series and other, element-wise (binary operator truediv).", "parameter_names_desc": [{"param_name": "other", "param_type": "Series or scalar value", "param_desc": ""}, {"param_name": "level", "param_type": "int or name", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "None or float value, default None (NaN)", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’}", "param_desc": "Unused. Parameter needed for compatibility with DataFrame.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.truediv.html#pandas.Series.truediv"}, {"function_name": "pandas.Series.mod", "full_function": "Series.mod(other, level=None, fill_value=None, axis=0)", "function_text": "Return Modulo of series and other, element-wise (binary operator mod).", "parameter_names_desc": [{"param_name": "other", "param_type": "Series or scalar value", "param_desc": ""}, {"param_name": "level", "param_type": "int or name", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "None or float value, default None (NaN)", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’}", "param_desc": "Unused. Parameter needed for compatibility with DataFrame.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.mod.html#pandas.Series.mod"}, {"function_name": "pandas.Series.radd", "full_function": "Series.radd(other, level=None, fill_value=None, axis=0)", "function_text": "Return Addition of series and other, element-wise (binary operator radd).", "parameter_names_desc": [{"param_name": "other", "param_type": "Series or scalar value", "param_desc": ""}, {"param_name": "level", "param_type": "int or name", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "None or float value, default None (NaN)", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’}", "param_desc": "Unused. Parameter needed for compatibility with DataFrame.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.radd.html#pandas.Series.radd"}, {"function_name": "pandas.Series.rmul", "full_function": "Series.rmul(other, level=None, fill_value=None, axis=0)", "function_text": "Return Multiplication of series and other, element-wise (binary operator rmul).", "parameter_names_desc": [{"param_name": "other", "param_type": "Series or scalar value", "param_desc": ""}, {"param_name": "level", "param_type": "int or name", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "None or float value, default None (NaN)", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’}", "param_desc": "Unused. Parameter needed for compatibility with DataFrame.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.rmul.html#pandas.Series.rmul"}, {"function_name": "pandas.Series.rtruediv", "full_function": "Series.rtruediv(other, level=None, fill_value=None, axis=0)", "function_text": "Return Floating division of series and other, element-wise (binary operator rtruediv).", "parameter_names_desc": [{"param_name": "other", "param_type": "Series or scalar value", "param_desc": ""}, {"param_name": "level", "param_type": "int or name", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "None or float value, default None (NaN)", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’}", "param_desc": "Unused. Parameter needed for compatibility with DataFrame.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.rtruediv.html#pandas.Series.rtruediv"}, {"function_name": "pandas.Series.rmod", "full_function": "Series.rmod(other, level=None, fill_value=None, axis=0)", "function_text": "Return Modulo of series and other, element-wise (binary operator rmod).", "parameter_names_desc": [{"param_name": "other", "param_type": "Series or scalar value", "param_desc": ""}, {"param_name": "level", "param_type": "int or name", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "None or float value, default None (NaN)", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’}", "param_desc": "Unused. Parameter needed for compatibility with DataFrame.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.rmod.html#pandas.Series.rmod"}, {"function_name": "pandas.Series.combine", "full_function": "Series.combine(other, func, fill_value=None)", "function_text": "Combine the Series with a Series or scalar according to func.", "parameter_names_desc": [{"param_name": "other", "param_type": "Series or scalar", "param_desc": "The value(s) to be combined with the Series.\n"}, {"param_name": "func", "param_type": "function", "param_desc": "Function that takes two scalars as inputs and returns an element.\n"}, {"param_name": "fill_value", "param_type": "scalar, optional", "param_desc": "The value to assume when an index is missing from\none Series or the other. The default specifies to use the\nappropriate NaN value for the underlying dtype of the Series.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.combine.html#pandas.Series.combine"}, {"function_name": "pandas.Series.round", "full_function": "Series.round(decimals=0, *args, **kwargs)", "function_text": "Round each value in a Series to the given number of decimals.", "parameter_names_desc": [{"param_name": "decimals", "param_type": "int, default 0", "param_desc": "Number of decimal places to round to. If decimals is negative,\nit specifies the number of positions to the left of the decimal point.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.round.html#pandas.Series.round"}, {"function_name": "pandas.Series.gt", "full_function": "Series.gt(other, level=None, fill_value=None, axis=0)", "function_text": "Return Greater than of series and other, element-wise (binary operator gt).", "parameter_names_desc": [{"param_name": "other", "param_type": "Series or scalar value", "param_desc": ""}, {"param_name": "level", "param_type": "int or name", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "None or float value, default None (NaN)", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’}", "param_desc": "Unused. Parameter needed for compatibility with DataFrame.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.gt.html#pandas.Series.gt"}, {"function_name": "pandas.Series.ge", "full_function": "Series.ge(other, level=None, fill_value=None, axis=0)", "function_text": "Return Greater than or equal to of series and other, element-wise (binary operator ge).", "parameter_names_desc": [{"param_name": "other", "param_type": "Series or scalar value", "param_desc": ""}, {"param_name": "level", "param_type": "int or name", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "None or float value, default None (NaN)", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’}", "param_desc": "Unused. Parameter needed for compatibility with DataFrame.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.ge.html#pandas.Series.ge"}, {"function_name": "pandas.Series.eq", "full_function": "Series.eq(other, level=None, fill_value=None, axis=0)", "function_text": "Return Equal to of series and other, element-wise (binary operator eq).", "parameter_names_desc": [{"param_name": "other", "param_type": "Series or scalar value", "param_desc": ""}, {"param_name": "level", "param_type": "int or name", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "None or float value, default None (NaN)", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’}", "param_desc": "Unused. Parameter needed for compatibility with DataFrame.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.eq.html#pandas.Series.eq"}, {"function_name": "pandas.Series.dot", "full_function": "Series.dot(other)", "function_text": "Compute the dot product between the Series and the columns of other.", "parameter_names_desc": [{"param_name": "other", "param_type": "Series, DataFrame or array-like", "param_desc": "The other object to compute the dot product with its columns.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dot.html#pandas.Series.dot"}, {"function_name": "pandas.Series.sub", "full_function": "Series.sub(other, level=None, fill_value=None, axis=0)", "function_text": "Return Subtraction of series and other, element-wise (binary operator sub).", "parameter_names_desc": [{"param_name": "other", "param_type": "Series or scalar value", "param_desc": ""}, {"param_name": "level", "param_type": "int or name", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "None or float value, default None (NaN)", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’}", "param_desc": "Unused. Parameter needed for compatibility with DataFrame.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.sub.html#pandas.Series.sub"}, {"function_name": "pandas.Series.div", "full_function": "Series.div(other, level=None, fill_value=None, axis=0)", "function_text": "Return Floating division of series and other, element-wise (binary operator truediv).", "parameter_names_desc": [{"param_name": "other", "param_type": "Series or scalar value", "param_desc": ""}, {"param_name": "level", "param_type": "int or name", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "None or float value, default None (NaN)", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’}", "param_desc": "Unused. Parameter needed for compatibility with DataFrame.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.div.html#pandas.Series.div"}, {"function_name": "pandas.Series.floordiv", "full_function": "Series.floordiv(other, level=None, fill_value=None, axis=0)", "function_text": "Return Integer division of series and other, element-wise (binary operator floordiv).", "parameter_names_desc": [{"param_name": "other", "param_type": "Series or scalar value", "param_desc": ""}, {"param_name": "level", "param_type": "int or name", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "None or float value, default None (NaN)", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’}", "param_desc": "Unused. Parameter needed for compatibility with DataFrame.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.floordiv.html#pandas.Series.floordiv"}, {"function_name": "pandas.Series.pow", "full_function": "Series.pow(other, level=None, fill_value=None, axis=0)", "function_text": "Return Exponential power of series and other, element-wise (binary operator pow).", "parameter_names_desc": [{"param_name": "other", "param_type": "Series or scalar value", "param_desc": ""}, {"param_name": "level", "param_type": "int or name", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "None or float value, default None (NaN)", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’}", "param_desc": "Unused. Parameter needed for compatibility with DataFrame.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.pow.html#pandas.Series.pow"}, {"function_name": "pandas.Series.rsub", "full_function": "Series.rsub(other, level=None, fill_value=None, axis=0)", "function_text": "Return Subtraction of series and other, element-wise (binary operator rsub).", "parameter_names_desc": [{"param_name": "other", "param_type": "Series or scalar value", "param_desc": ""}, {"param_name": "level", "param_type": "int or name", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "None or float value, default None (NaN)", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’}", "param_desc": "Unused. Parameter needed for compatibility with DataFrame.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.rsub.html#pandas.Series.rsub"}, {"function_name": "pandas.Series.rdiv", "full_function": "Series.rdiv(other, level=None, fill_value=None, axis=0)", "function_text": "Return Floating division of series and other, element-wise (binary operator rtruediv).", "parameter_names_desc": [{"param_name": "other", "param_type": "Series or scalar value", "param_desc": ""}, {"param_name": "level", "param_type": "int or name", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "None or float value, default None (NaN)", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’}", "param_desc": "Unused. Parameter needed for compatibility with DataFrame.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.rdiv.html#pandas.Series.rdiv"}, {"function_name": "pandas.Series.rfloordiv", "full_function": "Series.rfloordiv(other, level=None, fill_value=None, axis=0)", "function_text": "Return Integer division of series and other, element-wise (binary operator rfloordiv).", "parameter_names_desc": [{"param_name": "other", "param_type": "Series or scalar value", "param_desc": ""}, {"param_name": "level", "param_type": "int or name", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "None or float value, default None (NaN)", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’}", "param_desc": "Unused. Parameter needed for compatibility with DataFrame.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.rfloordiv.html#pandas.Series.rfloordiv"}, {"function_name": "pandas.Series.rpow", "full_function": "Series.rpow(other, level=None, fill_value=None, axis=0)", "function_text": "Return Exponential power of series and other, element-wise (binary operator rpow).", "parameter_names_desc": [{"param_name": "other", "param_type": "Series or scalar value", "param_desc": ""}, {"param_name": "level", "param_type": "int or name", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "None or float value, default None (NaN)", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’}", "param_desc": "Unused. Parameter needed for compatibility with DataFrame.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.rpow.html#pandas.Series.rpow"}, {"function_name": "pandas.Series.combine_first", "full_function": "Series.combine_first(other)", "function_text": "Update null elements with value in the same location in ‘other’.", "parameter_names_desc": [{"param_name": "other", "param_type": "Series", "param_desc": "The value(s) to be used for filling null values.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.combine_first.html#pandas.Series.combine_first"}, {"function_name": "pandas.Series.lt", "full_function": "Series.lt(other, level=None, fill_value=None, axis=0)", "function_text": "Return Less than of series and other, element-wise (binary operator lt).", "parameter_names_desc": [{"param_name": "other", "param_type": "Series or scalar value", "param_desc": ""}, {"param_name": "level", "param_type": "int or name", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "None or float value, default None (NaN)", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’}", "param_desc": "Unused. Parameter needed for compatibility with DataFrame.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.lt.html#pandas.Series.lt"}, {"function_name": "pandas.Series.le", "full_function": "Series.le(other, level=None, fill_value=None, axis=0)", "function_text": "Return Less than or equal to of series and other, element-wise (binary operator le).", "parameter_names_desc": [{"param_name": "other", "param_type": "Series or scalar value", "param_desc": ""}, {"param_name": "level", "param_type": "int or name", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "None or float value, default None (NaN)", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’}", "param_desc": "Unused. Parameter needed for compatibility with DataFrame.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.le.html#pandas.Series.le"}, {"function_name": "pandas.Series.ne", "full_function": "Series.ne(other, level=None, fill_value=None, axis=0)", "function_text": "Return Not equal to of series and other, element-wise (binary operator ne).", "parameter_names_desc": [{"param_name": "other", "param_type": "Series or scalar value", "param_desc": ""}, {"param_name": "level", "param_type": "int or name", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "None or float value, default None (NaN)", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’}", "param_desc": "Unused. Parameter needed for compatibility with DataFrame.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.ne.html#pandas.Series.ne"}, {"function_name": "pandas.Series.product", "full_function": "Series.product(axis=None, skipna=True, numeric_only=False, min_count=0, **kwargs)", "function_text": "Return the product of the values over the requested axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{index (0)}", "param_desc": "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0.\n\nWarning\nThe behavior of DataFrame.prod with axis=None is deprecated,\nin a future version this will reduce over both axes and return a scalar\nTo retain the old behavior, pass axis=0 (or do not pass axis).\n\n\nNew in version 2.0.0.\n\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values when computing the result.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns. Not implemented for Series.\n"}, {"param_name": "min_count", "param_type": "int, default 0", "param_desc": "The required number of valid values to perform the operation. If fewer than\nmin_count non-NA values are present the result will be NA.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.product.html#pandas.Series.product"}]}, {"name": "Function application, GroupBy & window", "url": "https://pandas.pydata.org/docs/reference/series.html#function-application-groupby-window", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.apply.html#pandas.Series.apply", "https://pandas.pydata.org/docs/reference/api/pandas.Series.aggregate.html#pandas.Series.aggregate", "https://pandas.pydata.org/docs/reference/api/pandas.Series.map.html#pandas.Series.map", "https://pandas.pydata.org/docs/reference/api/pandas.Series.rolling.html#pandas.Series.rolling", "https://pandas.pydata.org/docs/reference/api/pandas.Series.ewm.html#pandas.Series.ewm", "https://pandas.pydata.org/docs/reference/api/pandas.Series.agg.html#pandas.Series.agg", "https://pandas.pydata.org/docs/reference/api/pandas.Series.transform.html#pandas.Series.transform", "https://pandas.pydata.org/docs/reference/api/pandas.Series.groupby.html#pandas.Series.groupby", "https://pandas.pydata.org/docs/reference/api/pandas.Series.expanding.html#pandas.Series.expanding", "https://pandas.pydata.org/docs/reference/api/pandas.Series.pipe.html#pandas.Series.pipe"], "function_definitions": [{"function_name": "pandas.Series.apply", "full_function": "Series.apply(func, convert_dtype=_NoDefault.no_default, args=(), *, by_row='compat', **kwargs)", "function_text": "Invoke function on values of Series.", "parameter_names_desc": [{"param_name": "func", "param_type": "function", "param_desc": "Python function or NumPy ufunc to apply.\n"}, {"param_name": "convert_dtype", "param_type": "bool, default True", "param_desc": "Try to find better dtype for elementwise function results. If\nFalse, leave as dtype=object. Note that the dtype is always\npreserved for some extension array dtypes, such as Categorical.\n\nDeprecated since version 2.1.0: convert_dtype has been deprecated. Do ser.astype(object).apply()\ninstead if you want convert_dtype=False.\n\n"}, {"param_name": "args", "param_type": "tuple", "param_desc": "Positional arguments passed to func after the series value.\n"}, {"param_name": "by_row", "param_type": "False or “compat”, default “compat”", "param_desc": "If \"compat\" and func is a callable, func will be passed each element of\nthe Series, like Series.map. If func is a list or dict of\ncallables, will first try to translate each func into pandas methods. If\nthat doesn’t work, will try call to apply again with by_row=\"compat\"\nand if that fails, will call apply again with by_row=False\n(backward compatible).\nIf False, the func will be passed the whole Series at once.\nby_row has no effect when func is a string.\n\nNew in version 2.1.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.apply.html#pandas.Series.apply"}, {"function_name": "pandas.Series.aggregate", "full_function": "Series.aggregate(func=None, axis=0, *args, **kwargs)", "function_text": "Aggregate using one or more operations over the specified axis.", "parameter_names_desc": [{"param_name": "func", "param_type": "function, str, list or dict", "param_desc": "Function to use for aggregating the data. If a function, must either\nwork when passed a Series or when passed to Series.apply.\nAccepted combinations are:\n\nfunction\nstring function name\nlist of functions and/or function names, e.g. [np.sum, 'mean']\ndict of axis labels -> functions, function names or list of such.\n\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’}", "param_desc": "Unused. Parameter needed for compatibility with DataFrame.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.aggregate.html#pandas.Series.aggregate"}, {"function_name": "pandas.Series.map", "full_function": "Series.map(arg, na_action=None)", "function_text": "Map values of Series according to an input mapping or function.", "parameter_names_desc": [{"param_name": "arg", "param_type": "function, collections.abc.Mapping subclass or Series", "param_desc": "Mapping correspondence.\n"}, {"param_name": "na_action", "param_type": "{None, ‘ignore’}, default None", "param_desc": "If ‘ignore’, propagate NaN values, without passing them to the\nmapping correspondence.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.map.html#pandas.Series.map"}, {"function_name": "pandas.Series.rolling", "full_function": "Series.rolling(window, min_periods=None, center=False, win_type=None, on=None, axis=_NoDefault.no_default, closed=None, step=None, method='single')", "function_text": "Provide rolling window calculations.", "parameter_names_desc": [{"param_name": "window", "param_type": "int, timedelta, str, offset, or BaseIndexer subclass", "param_desc": "Size of the moving window.\nIf an integer, the fixed number of observations used for\neach window.\nIf a timedelta, str, or offset, the time period of each window. Each\nwindow will be a variable sized based on the observations included in\nthe time-period. This is only valid for datetimelike indexes.\nTo learn more about the offsets & frequency strings, please see this link.\nIf a BaseIndexer subclass, the window boundaries\nbased on the defined get_window_bounds method. Additional rolling\nkeyword arguments, namely min_periods, center, closed and\nstep will be passed to get_window_bounds.\n"}, {"param_name": "min_periods", "param_type": "int, default None", "param_desc": "Minimum number of observations in window required to have a value;\notherwise, result is np.nan.\nFor a window that is specified by an offset, min_periods will default to 1.\nFor a window that is specified by an integer, min_periods will default\nto the size of the window.\n"}, {"param_name": "center", "param_type": "bool, default False", "param_desc": "If False, set the window labels as the right edge of the window index.\nIf True, set the window labels as the center of the window index.\n"}, {"param_name": "win_type", "param_type": "str, default None", "param_desc": "If None, all points are evenly weighted.\nIf a string, it must be a valid scipy.signal window function.\nCertain Scipy window types require additional parameters to be passed\nin the aggregation function. The additional parameters must match\nthe keywords specified in the Scipy window type method signature.\n"}, {"param_name": "on", "param_type": "str, optional", "param_desc": "For a DataFrame, a column label or Index level on which\nto calculate the rolling window, rather than the DataFrame’s index.\nProvided integer column is ignored and excluded from result since\nan integer index is not used to calculate the rolling window.\n"}, {"param_name": "axis", "param_type": "int or str, default 0", "param_desc": "If 0 or 'index', roll across the rows.\nIf 1 or 'columns', roll across the columns.\nFor Series this parameter is unused and defaults to 0.\n\nDeprecated since version 2.1.0: The axis keyword is deprecated. For axis=1,\ntranspose the DataFrame first instead.\n\n"}, {"param_name": "closed", "param_type": "str, default None", "param_desc": "If 'right', the first point in the window is excluded from calculations.\nIf 'left', the last point in the window is excluded from calculations.\nIf 'both', the no points in the window are excluded from calculations.\nIf 'neither', the first and last points in the window are excluded\nfrom calculations.\nDefault None ('right').\n"}, {"param_name": "step", "param_type": "int, default None", "param_desc": "\nNew in version 1.5.0.\n\nEvaluate the window at every step result, equivalent to slicing as\n[::step]. window must be an integer. Using a step argument other\nthan None or 1 will produce a result with a different shape than the input.\n"}, {"param_name": "method", "param_type": "str {‘single’, ‘table’}, default ‘single’", "param_desc": "\nNew in version 1.3.0.\n\nExecute the rolling operation per single column or row ('single')\nor over the entire object ('table').\nThis argument is only implemented when specifying engine='numba'\nin the method call.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.rolling.html#pandas.Series.rolling"}, {"function_name": "pandas.Series.ewm", "full_function": "Series.ewm(com=None, span=None, halflife=None, alpha=None, min_periods=0, adjust=True, ignore_na=False, axis=_NoDefault.no_default, times=None, method='single')", "function_text": "Provide exponentially weighted (EW) calculations.", "parameter_names_desc": [{"param_name": "com", "param_type": "float, optional", "param_desc": "Specify decay in terms of center of mass\n\\(\\alpha = 1 / (1 + com)\\), for \\(com \\geq 0\\).\n"}, {"param_name": "span", "param_type": "float, optional", "param_desc": "Specify decay in terms of span\n\\(\\alpha = 2 / (span + 1)\\), for \\(span \\geq 1\\).\n"}, {"param_name": "halflife", "param_type": "float, str, timedelta, optional", "param_desc": "Specify decay in terms of half-life\n\\(\\alpha = 1 - \\exp\\left(-\\ln(2) / halflife\\right)\\), for\n\\(halflife > 0\\).\nIf times is specified, a timedelta convertible unit over which an\nobservation decays to half its value. Only applicable to mean(),\nand halflife value will not apply to the other functions.\n"}, {"param_name": "alpha", "param_type": "float, optional", "param_desc": "Specify smoothing factor \\(\\alpha\\) directly\n\\(0 < \\alpha \\leq 1\\).\n"}, {"param_name": "min_periods", "param_type": "int, default 0", "param_desc": "Minimum number of observations in window required to have a value;\notherwise, result is np.nan.\n"}, {"param_name": "adjust", "param_type": "bool, default True", "param_desc": "Divide by decaying adjustment factor in beginning periods to account\nfor imbalance in relative weightings (viewing EWMA as a moving average).\n\nWhen adjust=True (default), the EW function is calculated using weights\n\\(w_i = (1 - \\alpha)^i\\). For example, the EW moving average of the series\n[\\(x_0, x_1, ..., x_t\\)] would be:\n\n\n\\[y_t = \\frac{x_t + (1 - \\alpha)x_{t-1} + (1 - \\alpha)^2 x_{t-2} + ... + (1 -\n\\alpha)^t x_0}{1 + (1 - \\alpha) + (1 - \\alpha)^2 + ... + (1 - \\alpha)^t}\\]\n\nWhen adjust=False, the exponentially weighted function is calculated\nrecursively:\n\n\n\\[\\begin{split}\\begin{split}\ny_0 &= x_0\\\\\ny_t &= (1 - \\alpha) y_{t-1} + \\alpha x_t,\n\\end{split}\\end{split}\\]\n"}, {"param_name": "ignore_na", "param_type": "bool, default False", "param_desc": "Ignore missing values when calculating weights.\n\nWhen ignore_na=False (default), weights are based on absolute positions.\nFor example, the weights of \\(x_0\\) and \\(x_2\\) used in calculating\nthe final weighted average of [\\(x_0\\), None, \\(x_2\\)] are\n\\((1-\\alpha)^2\\) and \\(1\\) if adjust=True, and\n\\((1-\\alpha)^2\\) and \\(\\alpha\\) if adjust=False.\nWhen ignore_na=True, weights are based\non relative positions. For example, the weights of \\(x_0\\) and \\(x_2\\)\nused in calculating the final weighted average of\n[\\(x_0\\), None, \\(x_2\\)] are \\(1-\\alpha\\) and \\(1\\) if\nadjust=True, and \\(1-\\alpha\\) and \\(\\alpha\\) if adjust=False.\n\n"}, {"param_name": "axis", "param_type": "{0, 1}, default 0", "param_desc": "If 0 or 'index', calculate across the rows.\nIf 1 or 'columns', calculate across the columns.\nFor Series this parameter is unused and defaults to 0.\n"}, {"param_name": "times", "param_type": "np.ndarray, Series, default None", "param_desc": "Only applicable to mean().\nTimes corresponding to the observations. Must be monotonically increasing and\ndatetime64[ns] dtype.\nIf 1-D array like, a sequence with the same shape as the observations.\n"}, {"param_name": "method", "param_type": "str {‘single’, ‘table’}, default ‘single’", "param_desc": "\nNew in version 1.4.0.\n\nExecute the rolling operation per single column or row ('single')\nor over the entire object ('table').\nThis argument is only implemented when specifying engine='numba'\nin the method call.\nOnly applicable to mean()\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.ewm.html#pandas.Series.ewm"}, {"function_name": "pandas.Series.agg", "full_function": "Series.agg(func=None, axis=0, *args, **kwargs)", "function_text": "Aggregate using one or more operations over the specified axis.", "parameter_names_desc": [{"param_name": "func", "param_type": "function, str, list or dict", "param_desc": "Function to use for aggregating the data. If a function, must either\nwork when passed a Series or when passed to Series.apply.\nAccepted combinations are:\n\nfunction\nstring function name\nlist of functions and/or function names, e.g. [np.sum, 'mean']\ndict of axis labels -> functions, function names or list of such.\n\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’}", "param_desc": "Unused. Parameter needed for compatibility with DataFrame.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.agg.html#pandas.Series.agg"}, {"function_name": "pandas.Series.transform", "full_function": "Series.transform(func, axis=0, *args, **kwargs)", "function_text": "Call func on self producing a Series with the same axis shape as self.", "parameter_names_desc": [{"param_name": "ValueError", "param_type": "If the returned Series has a different length than self.", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.transform.html#pandas.Series.transform"}, {"function_name": "pandas.Series.groupby", "full_function": "Series.groupby(by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, observed=_NoDefault.no_default, dropna=True)", "function_text": "Group Series using a mapper or by a Series of columns.", "parameter_names_desc": [{"param_name": "by", "param_type": "mapping, function, label, pd.Grouper or list of such", "param_desc": "Used to determine the groups for the groupby.\nIf by is a function, it’s called on each value of the object’s\nindex. If a dict or Series is passed, the Series or dict VALUES\nwill be used to determine the groups (the Series’ values are first\naligned; see .align() method). If a list or ndarray of length\nequal to the selected axis is passed (see the groupby user guide),\nthe values are used as-is to determine the groups. A label or list\nof labels may be passed to group by the columns in self.\nNotice that a tuple is interpreted as a (single) key.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "Split along rows (0) or columns (1). For Series this parameter\nis unused and defaults to 0.\n\nDeprecated since version 2.1.0: Will be removed and behave like axis=0 in a future version.\nFor axis=1, do frame.T.groupby(...) instead.\n\n"}, {"param_name": "level", "param_type": "int, level name, or sequence of such, default None", "param_desc": "If the axis is a MultiIndex (hierarchical), group by a particular\nlevel or levels. Do not specify both by and level.\n"}, {"param_name": "as_index", "param_type": "bool, default True", "param_desc": "Return object with group labels as the\nindex. Only relevant for DataFrame input. as_index=False is\neffectively “SQL-style” grouped output. This argument has no effect\non filtrations (see the filtrations in the user guide),\nsuch as head(), tail(), nth() and in transformations\n(see the transformations in the user guide).\n"}, {"param_name": "sort", "param_type": "bool, default True", "param_desc": "Sort group keys. Get better performance by turning this off.\nNote this does not influence the order of observations within each\ngroup. Groupby preserves the order of rows within each group. If False,\nthe groups will appear in the same order as they did in the original DataFrame.\nThis argument has no effect on filtrations (see the filtrations in the user guide),\nsuch as head(), tail(), nth() and in transformations\n(see the transformations in the user guide).\n\nChanged in version 2.0.0: Specifying sort=False with an ordered categorical grouper will no\nlonger sort the values.\n\n"}, {"param_name": "group_keys", "param_type": "bool, default True", "param_desc": "When calling apply and the by argument produces a like-indexed\n(i.e. a transform) result, add group keys to\nindex to identify pieces. By default group keys are not included\nwhen the result’s index (and column) labels match the inputs, and\nare included otherwise.\n\nChanged in version 1.5.0: Warns that group_keys will no longer be ignored when the\nresult from apply is a like-indexed Series or DataFrame.\nSpecify group_keys explicitly to include the group keys or\nnot.\n\n\nChanged in version 2.0.0: group_keys now defaults to True.\n\n"}, {"param_name": "observed", "param_type": "bool, default False", "param_desc": "This only applies if any of the groupers are Categoricals.\nIf True: only show observed values for categorical groupers.\nIf False: show all values for categorical groupers.\n\nDeprecated since version 2.1.0: The default value will change to True in a future version of pandas.\n\n"}, {"param_name": "dropna", "param_type": "bool, default True", "param_desc": "If True, and if group keys contain NA values, NA values together\nwith row/column will be dropped.\nIf False, NA values will also be treated as the key in groups.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.groupby.html#pandas.Series.groupby"}, {"function_name": "pandas.Series.expanding", "full_function": "Series.expanding(min_periods=1, axis=_NoDefault.no_default, method='single')", "function_text": "Provide expanding window calculations.", "parameter_names_desc": [{"param_name": "min_periods", "param_type": "int, default 1", "param_desc": "Minimum number of observations in window required to have a value;\notherwise, result is np.nan.\n"}, {"param_name": "axis", "param_type": "int or str, default 0", "param_desc": "If 0 or 'index', roll across the rows.\nIf 1 or 'columns', roll across the columns.\nFor Series this parameter is unused and defaults to 0.\n"}, {"param_name": "method", "param_type": "str {‘single’, ‘table’}, default ‘single’", "param_desc": "Execute the rolling operation per single column or row ('single')\nor over the entire object ('table').\nThis argument is only implemented when specifying engine='numba'\nin the method call.\n\nNew in version 1.3.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.expanding.html#pandas.Series.expanding"}, {"function_name": "pandas.Series.pipe", "full_function": "Series.pipe(func, *args, **kwargs)", "function_text": "Apply chainable functions that expect Series or DataFrames.", "parameter_names_desc": [{"param_name": "func", "param_type": "function", "param_desc": "Function to apply to the Series/DataFrame.\nargs, and kwargs are passed into func.\nAlternatively a (callable, data_keyword) tuple where\ndata_keyword is a string indicating the keyword of\ncallable that expects the Series/DataFrame.\n"}, {"param_name": "*args", "param_type": "iterable, optional", "param_desc": "Positional arguments passed into func.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.pipe.html#pandas.Series.pipe"}]}, {"name": "Computations / descriptive stats", "url": "https://pandas.pydata.org/docs/reference/series.html#computations-descriptive-stats", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.abs.html#pandas.Series.abs", "https://pandas.pydata.org/docs/reference/api/pandas.Series.any.html#pandas.Series.any", "https://pandas.pydata.org/docs/reference/api/pandas.Series.between.html#pandas.Series.between", "https://pandas.pydata.org/docs/reference/api/pandas.Series.corr.html#pandas.Series.corr", "https://pandas.pydata.org/docs/reference/api/pandas.Series.cov.html#pandas.Series.cov", "https://pandas.pydata.org/docs/reference/api/pandas.Series.cummin.html#pandas.Series.cummin", "https://pandas.pydata.org/docs/reference/api/pandas.Series.cumsum.html#pandas.Series.cumsum", "https://pandas.pydata.org/docs/reference/api/pandas.Series.diff.html#pandas.Series.diff", "https://pandas.pydata.org/docs/reference/api/pandas.Series.kurt.html#pandas.Series.kurt", "https://pandas.pydata.org/docs/reference/api/pandas.Series.mean.html#pandas.Series.mean", "https://pandas.pydata.org/docs/reference/api/pandas.Series.min.html#pandas.Series.min", "https://pandas.pydata.org/docs/reference/api/pandas.Series.nlargest.html#pandas.Series.nlargest", "https://pandas.pydata.org/docs/reference/api/pandas.Series.pct_change.html#pandas.Series.pct_change", "https://pandas.pydata.org/docs/reference/api/pandas.Series.quantile.html#pandas.Series.quantile", "https://pandas.pydata.org/docs/reference/api/pandas.Series.sem.html#pandas.Series.sem", "https://pandas.pydata.org/docs/reference/api/pandas.Series.std.html#pandas.Series.std", "https://pandas.pydata.org/docs/reference/api/pandas.Series.var.html#pandas.Series.var", "https://pandas.pydata.org/docs/reference/api/pandas.Series.unique.html#pandas.Series.unique", "https://pandas.pydata.org/docs/reference/api/pandas.Series.is_unique.html#pandas.Series.is_unique", "https://pandas.pydata.org/docs/reference/api/pandas.Series.is_monotonic_decreasing.html#pandas.Series.is_monotonic_decreasing", "https://pandas.pydata.org/docs/reference/api/pandas.Series.all.html#pandas.Series.all", "https://pandas.pydata.org/docs/reference/api/pandas.Series.autocorr.html#pandas.Series.autocorr", "https://pandas.pydata.org/docs/reference/api/pandas.Series.clip.html#pandas.Series.clip", "https://pandas.pydata.org/docs/reference/api/pandas.Series.count.html#pandas.Series.count", "https://pandas.pydata.org/docs/reference/api/pandas.Series.cummax.html#pandas.Series.cummax", "https://pandas.pydata.org/docs/reference/api/pandas.Series.cumprod.html#pandas.Series.cumprod", "https://pandas.pydata.org/docs/reference/api/pandas.Series.describe.html#pandas.Series.describe", "https://pandas.pydata.org/docs/reference/api/pandas.Series.factorize.html#pandas.Series.factorize", "https://pandas.pydata.org/docs/reference/api/pandas.Series.max.html#pandas.Series.max", "https://pandas.pydata.org/docs/reference/api/pandas.Series.median.html#pandas.Series.median", "https://pandas.pydata.org/docs/reference/api/pandas.Series.mode.html#pandas.Series.mode", "https://pandas.pydata.org/docs/reference/api/pandas.Series.nsmallest.html#pandas.Series.nsmallest", "https://pandas.pydata.org/docs/reference/api/pandas.Series.prod.html#pandas.Series.prod", "https://pandas.pydata.org/docs/reference/api/pandas.Series.rank.html#pandas.Series.rank", "https://pandas.pydata.org/docs/reference/api/pandas.Series.skew.html#pandas.Series.skew", "https://pandas.pydata.org/docs/reference/api/pandas.Series.sum.html#pandas.Series.sum", "https://pandas.pydata.org/docs/reference/api/pandas.Series.kurtosis.html#pandas.Series.kurtosis", "https://pandas.pydata.org/docs/reference/api/pandas.Series.nunique.html#pandas.Series.nunique", "https://pandas.pydata.org/docs/reference/api/pandas.Series.is_monotonic_increasing.html#pandas.Series.is_monotonic_increasing", "https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html#pandas.Series.value_counts"], "function_definitions": [{"function_name": "pandas.Series.abs", "full_function": "Series.abs()", "function_text": "Return a Series/DataFrame with absolute numeric value of each element.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.abs.html#pandas.Series.abs"}, {"function_name": "pandas.Series.any", "full_function": "Series.any(*, axis=0, bool_only=False, skipna=True, **kwargs)", "function_text": "Return whether any element is True, potentially over an axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’, None}, default 0", "param_desc": "Indicate which axis or axes should be reduced. For Series this parameter\nis unused and defaults to 0.\n\n0 / ‘index’ : reduce the index, return a Series whose index is the\noriginal column labels.\n1 / ‘columns’ : reduce the columns, return a Series whose index is the\noriginal index.\nNone : reduce all axes, return a scalar.\n\n"}, {"param_name": "bool_only", "param_type": "bool, default False", "param_desc": "Include only boolean columns. Not implemented for Series.\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values. If the entire row/column is NA and skipna is\nTrue, then the result will be False, as for an empty row/column.\nIf skipna is False, then NA are treated as True, because these are not\nequal to zero.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.any.html#pandas.Series.any"}, {"function_name": "pandas.Series.between", "full_function": "Series.between(left, right, inclusive='both')", "function_text": "Return boolean Series equivalent to left <= series <= right.", "parameter_names_desc": [{"param_name": "left", "param_type": "scalar or list-like", "param_desc": "Left boundary.\n"}, {"param_name": "right", "param_type": "scalar or list-like", "param_desc": "Right boundary.\n"}, {"param_name": "inclusive", "param_type": "{“both”, “neither”, “left”, “right”}", "param_desc": "Include boundaries. Whether to set each bound as closed or open.\n\nChanged in version 1.3.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.between.html#pandas.Series.between"}, {"function_name": "pandas.Series.corr", "full_function": "Series.corr(other, method='pearson', min_periods=None)", "function_text": "Compute correlation with other Series, excluding missing values.", "parameter_names_desc": [{"param_name": "other", "param_type": "Series", "param_desc": "Series with which to compute the correlation.\n"}, {"param_name": "method", "param_type": "{‘pearson’, ‘kendall’, ‘spearman’} or callable", "param_desc": "Method used to compute correlation:\n\npearson : Standard correlation coefficient\nkendall : Kendall Tau correlation coefficient\nspearman : Spearman rank correlation\ncallable: Callable with input two 1d ndarrays and returning a float.\n\n\nWarning\nNote that the returned matrix from corr will have 1 along the\ndiagonals and will be symmetric regardless of the callable’s\nbehavior.\n\n"}, {"param_name": "min_periods", "param_type": "int, optional", "param_desc": "Minimum number of observations needed to have a valid result.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.corr.html#pandas.Series.corr"}, {"function_name": "pandas.Series.cov", "full_function": "Series.cov(other, min_periods=None, ddof=1)", "function_text": "Compute covariance with Series, excluding missing values.", "parameter_names_desc": [{"param_name": "other", "param_type": "Series", "param_desc": "Series with which to compute the covariance.\n"}, {"param_name": "min_periods", "param_type": "int, optional", "param_desc": "Minimum number of observations needed to have a valid result.\n"}, {"param_name": "ddof", "param_type": "int, default 1", "param_desc": "Delta degrees of freedom. The divisor used in calculations\nis N - ddof, where N represents the number of elements.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.cov.html#pandas.Series.cov"}, {"function_name": "pandas.Series.cummin", "full_function": "Series.cummin(axis=None, skipna=True, *args, **kwargs)", "function_text": "Return cumulative minimum over a DataFrame or Series axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "The index or the name of the axis. 0 is equivalent to None or ‘index’.\nFor Series this parameter is unused and defaults to 0.\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.cummin.html#pandas.Series.cummin"}, {"function_name": "pandas.Series.cumsum", "full_function": "Series.cumsum(axis=None, skipna=True, *args, **kwargs)", "function_text": "Return cumulative sum over a DataFrame or Series axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "The index or the name of the axis. 0 is equivalent to None or ‘index’.\nFor Series this parameter is unused and defaults to 0.\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.cumsum.html#pandas.Series.cumsum"}, {"function_name": "pandas.Series.diff", "full_function": "Series.diff(periods=1)", "function_text": "First discrete difference of element.", "parameter_names_desc": [{"param_name": "periods", "param_type": "int, default 1", "param_desc": "Periods to shift for calculating difference, accepts negative\nvalues.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.diff.html#pandas.Series.diff"}, {"function_name": "pandas.Series.kurt", "full_function": "Series.kurt(axis=0, skipna=True, numeric_only=False, **kwargs)", "function_text": "Return unbiased kurtosis over requested axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{index (0)}", "param_desc": "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0.\nFor DataFrames, specifying axis=None will apply the aggregation\nacross both axes.\n\nNew in version 2.0.0.\n\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values when computing the result.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns. Not implemented for Series.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.kurt.html#pandas.Series.kurt"}, {"function_name": "pandas.Series.mean", "full_function": "Series.mean(axis=0, skipna=True, numeric_only=False, **kwargs)", "function_text": "Return the mean of the values over the requested axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{index (0)}", "param_desc": "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0.\nFor DataFrames, specifying axis=None will apply the aggregation\nacross both axes.\n\nNew in version 2.0.0.\n\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values when computing the result.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns. Not implemented for Series.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.mean.html#pandas.Series.mean"}, {"function_name": "pandas.Series.min", "full_function": "Series.min(axis=0, skipna=True, numeric_only=False, **kwargs)", "function_text": "Return the minimum of the values over the requested axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{index (0)}", "param_desc": "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0.\nFor DataFrames, specifying axis=None will apply the aggregation\nacross both axes.\n\nNew in version 2.0.0.\n\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values when computing the result.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns. Not implemented for Series.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.min.html#pandas.Series.min"}, {"function_name": "pandas.Series.nlargest", "full_function": "Series.nlargest(n=5, keep='first')", "function_text": "Return the largest n elements.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 5", "param_desc": "Return this many descending sorted values.\n"}, {"param_name": "keep", "param_type": "{‘first’, ‘last’, ‘all’}, default ‘first’", "param_desc": "When there are duplicate values that cannot all fit in a\nSeries of n elements:\n\nfirst : return the first n occurrences in order\nof appearance.\nlast : return the last n occurrences in reverse\norder of appearance.\nall : keep all occurrences. This can result in a Series of\nsize larger than n.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.nlargest.html#pandas.Series.nlargest"}, {"function_name": "pandas.Series.pct_change", "full_function": "Series.pct_change(periods=1, fill_method=_NoDefault.no_default, limit=_NoDefault.no_default, freq=None, **kwargs)", "function_text": "Fractional change between the current and a prior element.", "parameter_names_desc": [{"param_name": "periods", "param_type": "int, default 1", "param_desc": "Periods to shift for forming percent change.\n"}, {"param_name": "fill_method", "param_type": "{‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}, default ‘pad’", "param_desc": "How to handle NAs before computing percent changes.\n\nDeprecated since version 2.1: All options of fill_method are deprecated except fill_method=None.\n\n"}, {"param_name": "limit", "param_type": "int, default None", "param_desc": "The number of consecutive NAs to fill before stopping.\n\nDeprecated since version 2.1.\n\n"}, {"param_name": "freq", "param_type": "DateOffset, timedelta, or str, optional", "param_desc": "Increment to use from time series API (e.g. ‘ME’ or BDay()).\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.pct_change.html#pandas.Series.pct_change"}, {"function_name": "pandas.Series.quantile", "full_function": "Series.quantile(q=0.5, interpolation='linear')", "function_text": "Return value at the given quantile.", "parameter_names_desc": [{"param_name": "q", "param_type": "float or array-like, default 0.5 (50% quantile)", "param_desc": "The quantile(s) to compute, which can lie in range: 0 <= q <= 1.\n"}, {"param_name": "interpolation", "param_type": "{‘linear’, ‘lower’, ‘higher’, ‘midpoint’, ‘nearest’}", "param_desc": "This optional parameter specifies the interpolation method to use,\nwhen the desired quantile lies between two data points i and j:\n\n\nlinear: i + (j - i) * (x-i)/(j-i), where (x-i)/(j-i) is\nthe fractional part of the index surrounded by i > j.\nlower: i.\nhigher: j.\nnearest: i or j whichever is nearest.\nmidpoint: (i + j) / 2.\n\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.quantile.html#pandas.Series.quantile"}, {"function_name": "pandas.Series.sem", "full_function": "Series.sem(axis=None, skipna=True, ddof=1, numeric_only=False, **kwargs)", "function_text": "Return unbiased standard error of the mean over requested axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{index (0)}", "param_desc": "For Series this parameter is unused and defaults to 0.\n\nWarning\nThe behavior of DataFrame.sem with axis=None is deprecated,\nin a future version this will reduce over both axes and return a scalar\nTo retain the old behavior, pass axis=0 (or do not pass axis).\n\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA.\n"}, {"param_name": "ddof", "param_type": "int, default 1", "param_desc": "Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\nwhere N represents the number of elements.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns. Not implemented for Series.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.sem.html#pandas.Series.sem"}, {"function_name": "pandas.Series.std", "full_function": "Series.std(axis=None, skipna=True, ddof=1, numeric_only=False, **kwargs)", "function_text": "Return sample standard deviation over requested axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{index (0)}", "param_desc": "For Series this parameter is unused and defaults to 0.\n\nWarning\nThe behavior of DataFrame.std with axis=None is deprecated,\nin a future version this will reduce over both axes and return a scalar\nTo retain the old behavior, pass axis=0 (or do not pass axis).\n\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA.\n"}, {"param_name": "ddof", "param_type": "int, default 1", "param_desc": "Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\nwhere N represents the number of elements.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns. Not implemented for Series.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.std.html#pandas.Series.std"}, {"function_name": "pandas.Series.var", "full_function": "Series.var(axis=None, skipna=True, ddof=1, numeric_only=False, **kwargs)", "function_text": "Return unbiased variance over requested axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{index (0)}", "param_desc": "For Series this parameter is unused and defaults to 0.\n\nWarning\nThe behavior of DataFrame.var with axis=None is deprecated,\nin a future version this will reduce over both axes and return a scalar\nTo retain the old behavior, pass axis=0 (or do not pass axis).\n\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA.\n"}, {"param_name": "ddof", "param_type": "int, default 1", "param_desc": "Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\nwhere N represents the number of elements.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns. Not implemented for Series.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.var.html#pandas.Series.var"}, {"function_name": "pandas.Series.unique", "full_function": "Series.unique()", "function_text": "Return unique values of Series object.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.unique.html#pandas.Series.unique"}, {"function_name": "pandas.Series.is_unique", "full_function": "property Series.is_unique", "function_text": "Return boolean if values in the object are unique.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.is_unique.html#pandas.Series.is_unique"}, {"function_name": "pandas.Series.is_monotonic_decreasing", "full_function": "property Series.is_monotonic_decreasing", "function_text": "Return boolean if values in the object are monotonically decreasing.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.is_monotonic_decreasing.html#pandas.Series.is_monotonic_decreasing"}, {"function_name": "pandas.Series.all", "full_function": "Series.all(axis=0, bool_only=False, skipna=True, **kwargs)", "function_text": "Return whether all elements are True, potentially over an axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’, None}, default 0", "param_desc": "Indicate which axis or axes should be reduced. For Series this parameter\nis unused and defaults to 0.\n\n0 / ‘index’ : reduce the index, return a Series whose index is the\noriginal column labels.\n1 / ‘columns’ : reduce the columns, return a Series whose index is the\noriginal index.\nNone : reduce all axes, return a scalar.\n\n"}, {"param_name": "bool_only", "param_type": "bool, default False", "param_desc": "Include only boolean columns. Not implemented for Series.\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values. If the entire row/column is NA and skipna is\nTrue, then the result will be True, as for an empty row/column.\nIf skipna is False, then NA are treated as True, because these are not\nequal to zero.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.all.html#pandas.Series.all"}, {"function_name": "pandas.Series.autocorr", "full_function": "Series.autocorr(lag=1)", "function_text": "Compute the lag-N autocorrelation.", "parameter_names_desc": [{"param_name": "lag", "param_type": "int, default 1", "param_desc": "Number of lags to apply before performing autocorrelation.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.autocorr.html#pandas.Series.autocorr"}, {"function_name": "pandas.Series.clip", "full_function": "Series.clip(lower=None, upper=None, *, axis=None, inplace=False, **kwargs)", "function_text": "Trim values at input threshold(s).", "parameter_names_desc": [{"param_name": "lower", "param_type": "float or array-like, default None", "param_desc": "Minimum threshold value. All values below this\nthreshold will be set to it. A missing\nthreshold (e.g NA) will not clip the value.\n"}, {"param_name": "upper", "param_type": "float or array-like, default None", "param_desc": "Maximum threshold value. All values above this\nthreshold will be set to it. A missing\nthreshold (e.g NA) will not clip the value.\n"}, {"param_name": "axis", "param_type": "{{0 or ‘index’, 1 or ‘columns’, None}}, default None", "param_desc": "Align object with lower and upper along the given axis.\nFor Series this parameter is unused and defaults to None.\n"}, {"param_name": "inplace", "param_type": "bool, default False", "param_desc": "Whether to perform the operation in place on the data.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.clip.html#pandas.Series.clip"}, {"function_name": "pandas.Series.count", "full_function": "Series.count()", "function_text": "Return number of non-NA/null observations in the Series.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.count.html#pandas.Series.count"}, {"function_name": "pandas.Series.cummax", "full_function": "Series.cummax(axis=None, skipna=True, *args, **kwargs)", "function_text": "Return cumulative maximum over a DataFrame or Series axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "The index or the name of the axis. 0 is equivalent to None or ‘index’.\nFor Series this parameter is unused and defaults to 0.\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.cummax.html#pandas.Series.cummax"}, {"function_name": "pandas.Series.cumprod", "full_function": "Series.cumprod(axis=None, skipna=True, *args, **kwargs)", "function_text": "Return cumulative product over a DataFrame or Series axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "The index or the name of the axis. 0 is equivalent to None or ‘index’.\nFor Series this parameter is unused and defaults to 0.\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.cumprod.html#pandas.Series.cumprod"}, {"function_name": "pandas.Series.describe", "full_function": "Series.describe(percentiles=None, include=None, exclude=None)", "function_text": "Generate descriptive statistics.", "parameter_names_desc": [{"param_name": "percentiles", "param_type": "list-like of numbers, optional", "param_desc": "The percentiles to include in the output. All should\nfall between 0 and 1. The default is\n[.25, .5, .75], which returns the 25th, 50th, and\n75th percentiles.\n"}, {"param_name": "include", "param_type": "‘all’, list-like of dtypes or None (default), optional", "param_desc": "A white list of data types to include in the result. Ignored\nfor Series. Here are the options:\n\n‘all’ : All columns of the input will be included in the output.\nA list-like of dtypes : Limits the results to the\nprovided data types.\nTo limit the result to numeric types submit\nnumpy.number. To limit it instead to object columns submit\nthe numpy.object data type. Strings\ncan also be used in the style of\nselect_dtypes (e.g. df.describe(include=['O'])). To\nselect pandas categorical columns, use 'category'\nNone (default) : The result will include all numeric columns.\n\n"}, {"param_name": "exclude", "param_type": "list-like of dtypes or None (default), optional,", "param_desc": "A black list of data types to omit from the result. Ignored\nfor Series. Here are the options:\n\nA list-like of dtypes : Excludes the provided data types\nfrom the result. To exclude numeric types submit\nnumpy.number. To exclude object columns submit the data\ntype numpy.object. Strings can also be used in the style of\nselect_dtypes (e.g. df.describe(exclude=['O'])). To\nexclude pandas categorical columns, use 'category'\nNone (default) : The result will exclude nothing.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.describe.html#pandas.Series.describe"}, {"function_name": "pandas.Series.factorize", "full_function": "Series.factorize(sort=False, use_na_sentinel=True)", "function_text": "Encode the object as an enumerated type or categorical variable.", "parameter_names_desc": [{"param_name": "sort", "param_type": "bool, default False", "param_desc": "Sort uniques and shuffle codes to maintain the\nrelationship.\n"}, {"param_name": "use_na_sentinel", "param_type": "bool, default True", "param_desc": "If True, the sentinel -1 will be used for NaN values. If False,\nNaN values will be encoded as non-negative integers and will not drop the\nNaN from the uniques of the values.\n\nNew in version 1.5.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.factorize.html#pandas.Series.factorize"}, {"function_name": "pandas.Series.max", "full_function": "Series.max(axis=0, skipna=True, numeric_only=False, **kwargs)", "function_text": "Return the maximum of the values over the requested axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{index (0)}", "param_desc": "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0.\nFor DataFrames, specifying axis=None will apply the aggregation\nacross both axes.\n\nNew in version 2.0.0.\n\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values when computing the result.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns. Not implemented for Series.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.max.html#pandas.Series.max"}, {"function_name": "pandas.Series.median", "full_function": "Series.median(axis=0, skipna=True, numeric_only=False, **kwargs)", "function_text": "Return the median of the values over the requested axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{index (0)}", "param_desc": "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0.\nFor DataFrames, specifying axis=None will apply the aggregation\nacross both axes.\n\nNew in version 2.0.0.\n\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values when computing the result.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns. Not implemented for Series.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.median.html#pandas.Series.median"}, {"function_name": "pandas.Series.mode", "full_function": "Series.mode(dropna=True)", "function_text": "Return the mode(s) of the Series.", "parameter_names_desc": [{"param_name": "dropna", "param_type": "bool, default True", "param_desc": "Don’t consider counts of NaN/NaT.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.mode.html#pandas.Series.mode"}, {"function_name": "pandas.Series.nsmallest", "full_function": "Series.nsmallest(n=5, keep='first')", "function_text": "Return the smallest n elements.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 5", "param_desc": "Return this many ascending sorted values.\n"}, {"param_name": "keep", "param_type": "{‘first’, ‘last’, ‘all’}, default ‘first’", "param_desc": "When there are duplicate values that cannot all fit in a\nSeries of n elements:\n\nfirst : return the first n occurrences in order\nof appearance.\nlast : return the last n occurrences in reverse\norder of appearance.\nall : keep all occurrences. This can result in a Series of\nsize larger than n.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.nsmallest.html#pandas.Series.nsmallest"}, {"function_name": "pandas.Series.prod", "full_function": "Series.prod(axis=None, skipna=True, numeric_only=False, min_count=0, **kwargs)", "function_text": "Return the product of the values over the requested axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{index (0)}", "param_desc": "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0.\n\nWarning\nThe behavior of DataFrame.prod with axis=None is deprecated,\nin a future version this will reduce over both axes and return a scalar\nTo retain the old behavior, pass axis=0 (or do not pass axis).\n\n\nNew in version 2.0.0.\n\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values when computing the result.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns. Not implemented for Series.\n"}, {"param_name": "min_count", "param_type": "int, default 0", "param_desc": "The required number of valid values to perform the operation. If fewer than\nmin_count non-NA values are present the result will be NA.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.prod.html#pandas.Series.prod"}, {"function_name": "pandas.Series.rank", "full_function": "Series.rank(axis=0, method='average', numeric_only=False, na_option='keep', ascending=True, pct=False)", "function_text": "Compute numerical data ranks (1 through n) along axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "Index to direct ranking.\nFor Series this parameter is unused and defaults to 0.\n"}, {"param_name": "method", "param_type": "{‘average’, ‘min’, ‘max’, ‘first’, ‘dense’}, default ‘average’", "param_desc": "How to rank the group of records that have the same value (i.e. ties):\n\naverage: average rank of the group\nmin: lowest rank in the group\nmax: highest rank in the group\nfirst: ranks assigned in order they appear in the array\ndense: like ‘min’, but rank always increases by 1 between groups.\n\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "For DataFrame objects, rank only numeric columns if set to True.\n\nChanged in version 2.0.0: The default value of numeric_only is now False.\n\n"}, {"param_name": "na_option", "param_type": "{‘keep’, ‘top’, ‘bottom’}, default ‘keep’", "param_desc": "How to rank NaN values:\n\nkeep: assign NaN rank to NaN values\ntop: assign lowest rank to NaN values\nbottom: assign highest rank to NaN values\n\n"}, {"param_name": "ascending", "param_type": "bool, default True", "param_desc": "Whether or not the elements should be ranked in ascending order.\n"}, {"param_name": "pct", "param_type": "bool, default False", "param_desc": "Whether or not to display the returned rankings in percentile\nform.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.rank.html#pandas.Series.rank"}, {"function_name": "pandas.Series.skew", "full_function": "Series.skew(axis=0, skipna=True, numeric_only=False, **kwargs)", "function_text": "Return unbiased skew over requested axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{index (0)}", "param_desc": "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0.\nFor DataFrames, specifying axis=None will apply the aggregation\nacross both axes.\n\nNew in version 2.0.0.\n\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values when computing the result.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns. Not implemented for Series.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.skew.html#pandas.Series.skew"}, {"function_name": "pandas.Series.sum", "full_function": "Series.sum(axis=None, skipna=True, numeric_only=False, min_count=0, **kwargs)", "function_text": "Return the sum of the values over the requested axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{index (0)}", "param_desc": "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0.\n\nWarning\nThe behavior of DataFrame.sum with axis=None is deprecated,\nin a future version this will reduce over both axes and return a scalar\nTo retain the old behavior, pass axis=0 (or do not pass axis).\n\n\nNew in version 2.0.0.\n\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values when computing the result.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns. Not implemented for Series.\n"}, {"param_name": "min_count", "param_type": "int, default 0", "param_desc": "The required number of valid values to perform the operation. If fewer than\nmin_count non-NA values are present the result will be NA.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.sum.html#pandas.Series.sum"}, {"function_name": "pandas.Series.kurtosis", "full_function": "Series.kurtosis(axis=0, skipna=True, numeric_only=False, **kwargs)", "function_text": "Return unbiased kurtosis over requested axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{index (0)}", "param_desc": "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0.\nFor DataFrames, specifying axis=None will apply the aggregation\nacross both axes.\n\nNew in version 2.0.0.\n\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values when computing the result.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns. Not implemented for Series.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.kurtosis.html#pandas.Series.kurtosis"}, {"function_name": "pandas.Series.nunique", "full_function": "Series.nunique(dropna=True)", "function_text": "Return number of unique elements in the object.", "parameter_names_desc": [{"param_name": "dropna", "param_type": "bool, default True", "param_desc": "Don’t include NaN in the count.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.nunique.html#pandas.Series.nunique"}, {"function_name": "pandas.Series.is_monotonic_increasing", "full_function": "property Series.is_monotonic_increasing", "function_text": "Return boolean if values in the object are monotonically increasing.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.is_monotonic_increasing.html#pandas.Series.is_monotonic_increasing"}, {"function_name": "pandas.Series.value_counts", "full_function": "Series.value_counts(normalize=False, sort=True, ascending=False, bins=None, dropna=True)", "function_text": "Return a Series containing counts of unique values.", "parameter_names_desc": [{"param_name": "normalize", "param_type": "bool, default False", "param_desc": "If True then the object returned will contain the relative\nfrequencies of the unique values.\n"}, {"param_name": "sort", "param_type": "bool, default True", "param_desc": "Sort by frequencies when True. Preserve the order of the data when False.\n"}, {"param_name": "ascending", "param_type": "bool, default False", "param_desc": "Sort in ascending order.\n"}, {"param_name": "bins", "param_type": "int, optional", "param_desc": "Rather than count values, group them into half-open bins,\na convenience for pd.cut, only works with numeric data.\n"}, {"param_name": "dropna", "param_type": "bool, default True", "param_desc": "Don’t include counts of NaN.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html#pandas.Series.value_counts"}]}, {"name": "Reindexing / selection / label manipulation", "url": "https://pandas.pydata.org/docs/reference/series.html#reindexing-selection-label-manipulation", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.align.html#pandas.Series.align", "https://pandas.pydata.org/docs/reference/api/pandas.Series.drop.html#pandas.Series.drop", "https://pandas.pydata.org/docs/reference/api/pandas.Series.drop_duplicates.html#pandas.Series.drop_duplicates", "https://pandas.pydata.org/docs/reference/api/pandas.Series.equals.html#pandas.Series.equals", "https://pandas.pydata.org/docs/reference/api/pandas.Series.head.html#pandas.Series.head", "https://pandas.pydata.org/docs/reference/api/pandas.Series.idxmin.html#pandas.Series.idxmin", "https://pandas.pydata.org/docs/reference/api/pandas.Series.last.html#pandas.Series.last", "https://pandas.pydata.org/docs/reference/api/pandas.Series.reindex_like.html#pandas.Series.reindex_like", "https://pandas.pydata.org/docs/reference/api/pandas.Series.rename_axis.html#pandas.Series.rename_axis", "https://pandas.pydata.org/docs/reference/api/pandas.Series.sample.html#pandas.Series.sample", "https://pandas.pydata.org/docs/reference/api/pandas.Series.take.html#pandas.Series.take", "https://pandas.pydata.org/docs/reference/api/pandas.Series.truncate.html#pandas.Series.truncate", "https://pandas.pydata.org/docs/reference/api/pandas.Series.mask.html#pandas.Series.mask", "https://pandas.pydata.org/docs/reference/api/pandas.Series.add_suffix.html#pandas.Series.add_suffix", "https://pandas.pydata.org/docs/reference/api/pandas.Series.case_when.html#pandas.Series.case_when", "https://pandas.pydata.org/docs/reference/api/pandas.Series.droplevel.html#pandas.Series.droplevel", "https://pandas.pydata.org/docs/reference/api/pandas.Series.duplicated.html#pandas.Series.duplicated", "https://pandas.pydata.org/docs/reference/api/pandas.Series.first.html#pandas.Series.first", "https://pandas.pydata.org/docs/reference/api/pandas.Series.idxmax.html#pandas.Series.idxmax", "https://pandas.pydata.org/docs/reference/api/pandas.Series.isin.html#pandas.Series.isin", "https://pandas.pydata.org/docs/reference/api/pandas.Series.reindex.html#pandas.Series.reindex", "https://pandas.pydata.org/docs/reference/api/pandas.Series.rename.html#pandas.Series.rename", "https://pandas.pydata.org/docs/reference/api/pandas.Series.reset_index.html#pandas.Series.reset_index", "https://pandas.pydata.org/docs/reference/api/pandas.Series.set_axis.html#pandas.Series.set_axis", "https://pandas.pydata.org/docs/reference/api/pandas.Series.tail.html#pandas.Series.tail", "https://pandas.pydata.org/docs/reference/api/pandas.Series.where.html#pandas.Series.where", "https://pandas.pydata.org/docs/reference/api/pandas.Series.add_prefix.html#pandas.Series.add_prefix", "https://pandas.pydata.org/docs/reference/api/pandas.Series.filter.html#pandas.Series.filter"], "function_definitions": [{"function_name": "pandas.Series.align", "full_function": "Series.align(other, join='outer', axis=None, level=None, copy=None, fill_value=None, method=_NoDefault.no_default, limit=_NoDefault.no_default, fill_axis=_NoDefault.no_default, broadcast_axis=_NoDefault.no_default)", "function_text": "Align two objects on their axes with the specified join method.", "parameter_names_desc": [{"param_name": "other", "param_type": "DataFrame or Series", "param_desc": ""}, {"param_name": "join", "param_type": "{‘outer’, ‘inner’, ‘left’, ‘right’}, default ‘outer’", "param_desc": "Type of alignment to be performed.\n\nleft: use only keys from left frame, preserve key order.\nright: use only keys from right frame, preserve key order.\nouter: use union of keys from both frames, sort keys lexicographically.\ninner: use intersection of keys from both frames,\npreserve the order of the left keys.\n\n"}, {"param_name": "axis", "param_type": "allowed axis of the other object, default None", "param_desc": "Align on index (0), columns (1), or both (None).\n"}, {"param_name": "level", "param_type": "int or level name, default None", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "copy", "param_type": "bool, default True", "param_desc": "Always returns new objects. If copy=False and no reindexing is\nrequired then original objects are returned.\n\nNote\nThe copy keyword will change behavior in pandas 3.0.\nCopy-on-Write\nwill be enabled by default, which means that all methods with a\ncopy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas.\nYou can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True\n\n"}, {"param_name": "fill_value", "param_type": "scalar, default np.nan", "param_desc": "Value to use for missing values. Defaults to NaN, but can be any\n“compatible” value.\n"}, {"param_name": "method", "param_type": "{‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}, default None", "param_desc": "Method to use for filling holes in reindexed Series:\n\npad / ffill: propagate last valid observation forward to next valid.\nbackfill / bfill: use NEXT valid observation to fill gap.\n\n\nDeprecated since version 2.1.\n\n"}, {"param_name": "limit", "param_type": "int, default None", "param_desc": "If method is specified, this is the maximum number of consecutive\nNaN values to forward/backward fill. In other words, if there is\na gap with more than this number of consecutive NaNs, it will only\nbe partially filled. If method is not specified, this is the\nmaximum number of entries along the entire axis where NaNs will be\nfilled. Must be greater than 0 if not None.\n\nDeprecated since version 2.1.\n\n"}, {"param_name": "fill_axis", "param_type": "{0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame, default 0", "param_desc": "Filling axis, method and limit.\n\nDeprecated since version 2.1.\n\n"}, {"param_name": "broadcast_axis", "param_type": "{0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame, default None", "param_desc": "Broadcast values along this axis, if aligning two objects of\ndifferent dimensions.\n\nDeprecated since version 2.1.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.align.html#pandas.Series.align"}, {"function_name": "pandas.Series.drop", "full_function": "Series.drop(labels=None, *, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')", "function_text": "Return Series with specified index labels removed.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.drop.html#pandas.Series.drop"}, {"function_name": "pandas.Series.drop_duplicates", "full_function": "Series.drop_duplicates(*, keep='first', inplace=False, ignore_index=False)", "function_text": "Return Series with duplicate values removed.", "parameter_names_desc": [{"param_name": "keep", "param_type": "{‘first’, ‘last’, False}, default ‘first’", "param_desc": "Method to handle dropping duplicates:\n\n‘first’ : Drop duplicates except for the first occurrence.\n‘last’ : Drop duplicates except for the last occurrence.\nFalse : Drop all duplicates.\n\n"}, {"param_name": "inplace", "param_type": "bool, default False", "param_desc": "If True, performs operation inplace and returns None.\n"}, {"param_name": "ignore_index", "param_type": "bool, default False", "param_desc": "If True, the resulting axis will be labeled 0, 1, …, n - 1.\n\nNew in version 2.0.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.drop_duplicates.html#pandas.Series.drop_duplicates"}, {"function_name": "pandas.Series.equals", "full_function": "Series.equals(other)", "function_text": "Test whether two objects contain the same elements.", "parameter_names_desc": [{"param_name": "other", "param_type": "Series or DataFrame", "param_desc": "The other Series or DataFrame to be compared with the first.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.equals.html#pandas.Series.equals"}, {"function_name": "pandas.Series.head", "full_function": "Series.head(n=5)", "function_text": "Return the first n rows.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 5", "param_desc": "Number of rows to select.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.head.html#pandas.Series.head"}, {"function_name": "pandas.Series.idxmin", "full_function": "Series.idxmin(axis=0, skipna=True, *args, **kwargs)", "function_text": "Return the row label of the minimum value.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.idxmin.html#pandas.Series.idxmin"}, {"function_name": "pandas.Series.last", "full_function": "Series.last(offset)", "function_text": "Select final periods of time series data based on a date offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.last.html#pandas.Series.last"}, {"function_name": "pandas.Series.reindex_like", "full_function": "Series.reindex_like(other, method=None, copy=None, limit=None, tolerance=None)", "function_text": "Return an object with matching indices as other object.", "parameter_names_desc": [{"param_name": "other", "param_type": "Object of the same data type", "param_desc": "Its row and column indices are used to define the new indices\nof this object.\n"}, {"param_name": "method", "param_type": "{None, ‘backfill’/’bfill’, ‘pad’/’ffill’, ‘nearest’}", "param_desc": "Method to use for filling holes in reindexed DataFrame.\nPlease note: this is only applicable to DataFrames/Series with a\nmonotonically increasing/decreasing index.\n\nNone (default): don’t fill gaps\npad / ffill: propagate last valid observation forward to next\nvalid\nbackfill / bfill: use next valid observation to fill gap\nnearest: use nearest valid observations to fill gap.\n\n"}, {"param_name": "copy", "param_type": "bool, default True", "param_desc": "Return a new object, even if the passed indexes are the same.\n\nNote\nThe copy keyword will change behavior in pandas 3.0.\nCopy-on-Write\nwill be enabled by default, which means that all methods with a\ncopy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas.\nYou can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True\n\n"}, {"param_name": "limit", "param_type": "int, default None", "param_desc": "Maximum number of consecutive labels to fill for inexact matches.\n"}, {"param_name": "tolerance", "param_type": "optional", "param_desc": "Maximum distance between original and new labels for inexact\nmatches. The values of the index at the matching locations must\nsatisfy the equation abs(index[indexer] - target) <= tolerance.\nTolerance may be a scalar value, which applies the same tolerance\nto all values, or list-like, which applies variable tolerance per\nelement. List-like includes list, tuple, array, Series, and must be\nthe same size as the index and its dtype must exactly match the\nindex’s type.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.reindex_like.html#pandas.Series.reindex_like"}, {"function_name": "pandas.Series.rename_axis", "full_function": "Series.rename_axis(mapper=_NoDefault.no_default, *, index=_NoDefault.no_default, axis=0, copy=True, inplace=False)", "function_text": "Set the name of the axis for the index or columns.", "parameter_names_desc": [{"param_name": "mapper", "param_type": "scalar, list-like, optional", "param_desc": "Value to set the axis name attribute.\n"}, {"param_name": "index, columns", "param_type": "scalar, list-like, dict-like or function, optional", "param_desc": "A scalar, list-like, dict-like or functions transformations to\napply to that axis’ values.\nNote that the columns parameter is not allowed if the\nobject is a Series. This parameter only apply for DataFrame\ntype objects.\nUse either mapper and axis to\nspecify the axis to target with mapper, or index\nand/or columns.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "The axis to rename. For Series this parameter is unused and defaults to 0.\n"}, {"param_name": "copy", "param_type": "bool, default None", "param_desc": "Also copy underlying data.\n\nNote\nThe copy keyword will change behavior in pandas 3.0.\nCopy-on-Write\nwill be enabled by default, which means that all methods with a\ncopy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas.\nYou can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True\n\n"}, {"param_name": "inplace", "param_type": "bool, default False", "param_desc": "Modifies the object directly, instead of creating a new Series\nor DataFrame.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.rename_axis.html#pandas.Series.rename_axis"}, {"function_name": "pandas.Series.sample", "full_function": "Series.sample(n=None, frac=None, replace=False, weights=None, random_state=None, axis=None, ignore_index=False)", "function_text": "Return a random sample of items from an axis of object.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, optional", "param_desc": "Number of items from axis to return. Cannot be used with frac.\nDefault = 1 if frac = None.\n"}, {"param_name": "frac", "param_type": "float, optional", "param_desc": "Fraction of axis items to return. Cannot be used with n.\n"}, {"param_name": "replace", "param_type": "bool, default False", "param_desc": "Allow or disallow sampling of the same row more than once.\n"}, {"param_name": "weights", "param_type": "str or ndarray-like, optional", "param_desc": "Default ‘None’ results in equal probability weighting.\nIf passed a Series, will align with target object on index. Index\nvalues in weights not found in sampled object will be ignored and\nindex values in sampled object not in weights will be assigned\nweights of zero.\nIf called on a DataFrame, will accept the name of a column\nwhen axis = 0.\nUnless weights are a Series, weights must be same length as axis\nbeing sampled.\nIf weights do not sum to 1, they will be normalized to sum to 1.\nMissing values in the weights column will be treated as zero.\nInfinite values not allowed.\n"}, {"param_name": "random_state", "param_type": "int, array-like, BitGenerator, np.random.RandomState, np.random.Generator, optional", "param_desc": "If int, array-like, or BitGenerator, seed for random number generator.\nIf np.random.RandomState or np.random.Generator, use as given.\n\nChanged in version 1.4.0: np.random.Generator objects now accepted\n\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’, None}, default None", "param_desc": "Axis to sample. Accepts axis number or name. Default is stat axis\nfor given data type. For Series this parameter is unused and defaults to None.\n"}, {"param_name": "ignore_index", "param_type": "bool, default False", "param_desc": "If True, the resulting index will be labeled 0, 1, …, n - 1.\n\nNew in version 1.3.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.sample.html#pandas.Series.sample"}, {"function_name": "pandas.Series.take", "full_function": "Series.take(indices, axis=0, **kwargs)", "function_text": "Return the elements in the given positional indices along an axis.", "parameter_names_desc": [{"param_name": "indices", "param_type": "array-like", "param_desc": "An array of ints indicating which positions to take.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’, None}, default 0", "param_desc": "The axis on which to select elements. 0 means that we are\nselecting rows, 1 means that we are selecting columns.\nFor Series this parameter is unused and defaults to 0.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.take.html#pandas.Series.take"}, {"function_name": "pandas.Series.truncate", "full_function": "Series.truncate(before=None, after=None, axis=None, copy=None)", "function_text": "Truncate a Series or DataFrame before and after some index value.", "parameter_names_desc": [{"param_name": "before", "param_type": "date, str, int", "param_desc": "Truncate all rows before this index value.\n"}, {"param_name": "after", "param_type": "date, str, int", "param_desc": "Truncate all rows after this index value.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, optional", "param_desc": "Axis to truncate. Truncates the index (rows) by default.\nFor Series this parameter is unused and defaults to 0.\n"}, {"param_name": "copy", "param_type": "bool, default is True,", "param_desc": "Return a copy of the truncated section.\n\nNote\nThe copy keyword will change behavior in pandas 3.0.\nCopy-on-Write\nwill be enabled by default, which means that all methods with a\ncopy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas.\nYou can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.truncate.html#pandas.Series.truncate"}, {"function_name": "pandas.Series.mask", "full_function": "Series.mask(cond, other=_NoDefault.no_default, *, inplace=False, axis=None, level=None)", "function_text": "Replace values where the condition is True.", "parameter_names_desc": [{"param_name": "cond", "param_type": "bool Series/DataFrame, array-like, or callable", "param_desc": "Where cond is False, keep the original value. Where\nTrue, replace with corresponding value from other.\nIf cond is callable, it is computed on the Series/DataFrame and\nshould return boolean Series/DataFrame or array. The callable must\nnot change input Series/DataFrame (though pandas doesn’t check it).\n"}, {"param_name": "other", "param_type": "scalar, Series/DataFrame, or callable", "param_desc": "Entries where cond is True are replaced with\ncorresponding value from other.\nIf other is callable, it is computed on the Series/DataFrame and\nshould return scalar or Series/DataFrame. The callable must not\nchange input Series/DataFrame (though pandas doesn’t check it).\nIf not specified, entries will be filled with the corresponding\nNULL value (np.nan for numpy dtypes, pd.NA for extension\ndtypes).\n"}, {"param_name": "inplace", "param_type": "bool, default False", "param_desc": "Whether to perform the operation in place on the data.\n"}, {"param_name": "axis", "param_type": "int, default None", "param_desc": "Alignment axis if needed. For Series this parameter is\nunused and defaults to 0.\n"}, {"param_name": "level", "param_type": "int, default None", "param_desc": "Alignment level if needed.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.mask.html#pandas.Series.mask"}, {"function_name": "pandas.Series.add_suffix", "full_function": "Series.add_suffix(suffix, axis=None)", "function_text": "Suffix labels with string suffix.", "parameter_names_desc": [{"param_name": "suffix", "param_type": "str", "param_desc": "The string to add after each label.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’, None}, default None", "param_desc": "Axis to add suffix on\n\nNew in version 2.0.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.add_suffix.html#pandas.Series.add_suffix"}, {"function_name": "pandas.Series.case_when", "full_function": "Series.case_when(caselist)", "function_text": "Replace values where the conditions are True.", "parameter_names_desc": [{"param_name": "caselist", "param_type": "A list of tuples of conditions and expected replacements", "param_desc": "Takes the form: (condition0, replacement0),\n(condition1, replacement1), … .\ncondition should be a 1-D boolean array-like object\nor a callable. If condition is a callable,\nit is computed on the Series\nand should return a boolean Series or array.\nThe callable must not change the input Series\n(though pandas doesn`t check it). replacement should be a\n1-D array-like object, a scalar or a callable.\nIf replacement is a callable, it is computed on the Series\nand should return a scalar or Series. The callable\nmust not change the input Series\n(though pandas doesn`t check it).\n\nNew in version 2.2.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.case_when.html#pandas.Series.case_when"}, {"function_name": "pandas.Series.droplevel", "full_function": "Series.droplevel(level, axis=0)", "function_text": "Return Series/DataFrame with requested index / column level(s) removed.", "parameter_names_desc": [{"param_name": "level", "param_type": "int, str, or list-like", "param_desc": "If a string is given, must be the name of a level\nIf list-like, elements must be names or positional indexes\nof levels.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "Axis along which the level(s) is removed:\n\n0 or ‘index’: remove level(s) in column.\n1 or ‘columns’: remove level(s) in row.\n\nFor Series this parameter is unused and defaults to 0.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.droplevel.html#pandas.Series.droplevel"}, {"function_name": "pandas.Series.duplicated", "full_function": "Series.duplicated(keep='first')", "function_text": "Indicate duplicate Series values.", "parameter_names_desc": [{"param_name": "keep", "param_type": "{‘first’, ‘last’, False}, default ‘first’", "param_desc": "Method to handle dropping duplicates:\n\n‘first’ : Mark duplicates as True except for the first\noccurrence.\n‘last’ : Mark duplicates as True except for the last\noccurrence.\nFalse : Mark all duplicates as True.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.duplicated.html#pandas.Series.duplicated"}, {"function_name": "pandas.Series.first", "full_function": "Series.first(offset)", "function_text": "Select initial periods of time series data based on a date offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.first.html#pandas.Series.first"}, {"function_name": "pandas.Series.idxmax", "full_function": "Series.idxmax(axis=0, skipna=True, *args, **kwargs)", "function_text": "Return the row label of the maximum value.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.idxmax.html#pandas.Series.idxmax"}, {"function_name": "pandas.Series.isin", "full_function": "Series.isin(values)", "function_text": "Whether elements in Series are contained in values.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.isin.html#pandas.Series.isin"}, {"function_name": "pandas.Series.reindex", "full_function": "Series.reindex(index=None, *, axis=None, method=None, copy=None, level=None, fill_value=None, limit=None, tolerance=None)", "function_text": "Conform Series to new index with optional filling logic.", "parameter_names_desc": [{"param_name": "index", "param_type": "array-like, optional", "param_desc": "New labels for the index. Preferably an Index object to avoid\nduplicating data.\n"}, {"param_name": "axis", "param_type": "int or str, optional", "param_desc": "Unused.\n"}, {"param_name": "method", "param_type": "{None, ‘backfill’/’bfill’, ‘pad’/’ffill’, ‘nearest’}", "param_desc": "Method to use for filling holes in reindexed DataFrame.\nPlease note: this is only applicable to DataFrames/Series with a\nmonotonically increasing/decreasing index.\n\nNone (default): don’t fill gaps\npad / ffill: Propagate last valid observation forward to next\nvalid.\nbackfill / bfill: Use next valid observation to fill gap.\nnearest: Use nearest valid observations to fill gap.\n\n"}, {"param_name": "copy", "param_type": "bool, default True", "param_desc": "Return a new object, even if the passed indexes are the same.\n\nNote\nThe copy keyword will change behavior in pandas 3.0.\nCopy-on-Write\nwill be enabled by default, which means that all methods with a\ncopy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas.\nYou can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True\n\n"}, {"param_name": "level", "param_type": "int or name", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "scalar, default np.nan", "param_desc": "Value to use for missing values. Defaults to NaN, but can be any\n“compatible” value.\n"}, {"param_name": "limit", "param_type": "int, default None", "param_desc": "Maximum number of consecutive elements to forward or backward fill.\n"}, {"param_name": "tolerance", "param_type": "optional", "param_desc": "Maximum distance between original and new labels for inexact\nmatches. The values of the index at the matching locations most\nsatisfy the equation abs(index[indexer] - target) <= tolerance.\nTolerance may be a scalar value, which applies the same tolerance\nto all values, or list-like, which applies variable tolerance per\nelement. List-like includes list, tuple, array, Series, and must be\nthe same size as the index and its dtype must exactly match the\nindex’s type.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.reindex.html#pandas.Series.reindex"}, {"function_name": "pandas.Series.rename", "full_function": "Series.rename(index=None, *, axis=None, copy=None, inplace=False, level=None, errors='ignore')", "function_text": "Alter Series index labels or name.", "parameter_names_desc": [{"param_name": "index", "param_type": "scalar, hashable sequence, dict-like or function optional", "param_desc": "Functions or dict-like are transformations to apply to\nthe index.\nScalar or hashable sequence-like will alter the Series.name\nattribute.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’}", "param_desc": "Unused. Parameter needed for compatibility with DataFrame.\n"}, {"param_name": "copy", "param_type": "bool, default True", "param_desc": "Also copy underlying data.\n\nNote\nThe copy keyword will change behavior in pandas 3.0.\nCopy-on-Write\nwill be enabled by default, which means that all methods with a\ncopy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas.\nYou can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True\n\n"}, {"param_name": "inplace", "param_type": "bool, default False", "param_desc": "Whether to return a new Series. If True the value of copy is ignored.\n"}, {"param_name": "level", "param_type": "int or level name, default None", "param_desc": "In case of MultiIndex, only rename labels in the specified level.\n"}, {"param_name": "errors", "param_type": "{‘ignore’, ‘raise’}, default ‘ignore’", "param_desc": "If ‘raise’, raise KeyError when a dict-like mapper or\nindex contains labels that are not present in the index being transformed.\nIf ‘ignore’, existing keys will be renamed and extra keys will be ignored.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.rename.html#pandas.Series.rename"}, {"function_name": "pandas.Series.reset_index", "full_function": "Series.reset_index(level=None, *, drop=False, name=_NoDefault.no_default, inplace=False, allow_duplicates=False)", "function_text": "Generate a new DataFrame or Series with the index reset.", "parameter_names_desc": [{"param_name": "level", "param_type": "int, str, tuple, or list, default optional", "param_desc": "For a Series with a MultiIndex, only remove the specified levels\nfrom the index. Removes all levels by default.\n"}, {"param_name": "drop", "param_type": "bool, default False", "param_desc": "Just reset the index, without inserting it as a column in\nthe new DataFrame.\n"}, {"param_name": "name", "param_type": "object, optional", "param_desc": "The name to use for the column containing the original Series\nvalues. Uses self.name by default. This argument is ignored\nwhen drop is True.\n"}, {"param_name": "inplace", "param_type": "bool, default False", "param_desc": "Modify the Series in place (do not create a new object).\n"}, {"param_name": "allow_duplicates", "param_type": "bool, default False", "param_desc": "Allow duplicate column labels to be created.\n\nNew in version 1.5.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.reset_index.html#pandas.Series.reset_index"}, {"function_name": "pandas.Series.set_axis", "full_function": "Series.set_axis(labels, *, axis=0, copy=None)", "function_text": "Assign desired index to given axis.", "parameter_names_desc": [{"param_name": "labels", "param_type": "list-like, Index", "param_desc": "The values for the new index.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’}, default 0", "param_desc": "The axis to update. The value 0 identifies the rows. For Series\nthis parameter is unused and defaults to 0.\n"}, {"param_name": "copy", "param_type": "bool, default True", "param_desc": "Whether to make a copy of the underlying data.\n\nNote\nThe copy keyword will change behavior in pandas 3.0.\nCopy-on-Write\nwill be enabled by default, which means that all methods with a\ncopy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas.\nYou can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.set_axis.html#pandas.Series.set_axis"}, {"function_name": "pandas.Series.tail", "full_function": "Series.tail(n=5)", "function_text": "Return the last n rows.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 5", "param_desc": "Number of rows to select.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.tail.html#pandas.Series.tail"}, {"function_name": "pandas.Series.where", "full_function": "Series.where(cond, other=nan, *, inplace=False, axis=None, level=None)", "function_text": "Replace values where the condition is False.", "parameter_names_desc": [{"param_name": "cond", "param_type": "bool Series/DataFrame, array-like, or callable", "param_desc": "Where cond is True, keep the original value. Where\nFalse, replace with corresponding value from other.\nIf cond is callable, it is computed on the Series/DataFrame and\nshould return boolean Series/DataFrame or array. The callable must\nnot change input Series/DataFrame (though pandas doesn’t check it).\n"}, {"param_name": "other", "param_type": "scalar, Series/DataFrame, or callable", "param_desc": "Entries where cond is False are replaced with\ncorresponding value from other.\nIf other is callable, it is computed on the Series/DataFrame and\nshould return scalar or Series/DataFrame. The callable must not\nchange input Series/DataFrame (though pandas doesn’t check it).\nIf not specified, entries will be filled with the corresponding\nNULL value (np.nan for numpy dtypes, pd.NA for extension\ndtypes).\n"}, {"param_name": "inplace", "param_type": "bool, default False", "param_desc": "Whether to perform the operation in place on the data.\n"}, {"param_name": "axis", "param_type": "int, default None", "param_desc": "Alignment axis if needed. For Series this parameter is\nunused and defaults to 0.\n"}, {"param_name": "level", "param_type": "int, default None", "param_desc": "Alignment level if needed.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.where.html#pandas.Series.where"}, {"function_name": "pandas.Series.add_prefix", "full_function": "Series.add_prefix(prefix, axis=None)", "function_text": "Prefix labels with string prefix.", "parameter_names_desc": [{"param_name": "prefix", "param_type": "str", "param_desc": "The string to add before each label.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’, None}, default None", "param_desc": "Axis to add prefix on\n\nNew in version 2.0.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.add_prefix.html#pandas.Series.add_prefix"}, {"function_name": "pandas.Series.filter", "full_function": "Series.filter(items=None, like=None, regex=None, axis=None)", "function_text": "Subset the dataframe rows or columns according to the specified index labels.", "parameter_names_desc": [{"param_name": "items", "param_type": "list-like", "param_desc": "Keep labels from axis which are in items.\n"}, {"param_name": "like", "param_type": "str", "param_desc": "Keep labels from axis for which “like in label == True”.\n"}, {"param_name": "regex", "param_type": "str (regular expression)", "param_desc": "Keep labels from axis for which re.search(regex, label) == True.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’, None}, default None", "param_desc": "The axis to filter on, expressed either as an index (int)\nor axis name (str). By default this is the info axis, ‘columns’ for\nDataFrame. For Series this parameter is unused and defaults to None.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.filter.html#pandas.Series.filter"}]}, {"name": "Missing data handling", "url": "https://pandas.pydata.org/docs/reference/series.html#missing-data-handling", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.backfill.html#pandas.Series.backfill", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dropna.html#pandas.Series.dropna", "https://pandas.pydata.org/docs/reference/api/pandas.Series.fillna.html#pandas.Series.fillna", "https://pandas.pydata.org/docs/reference/api/pandas.Series.isna.html#pandas.Series.isna", "https://pandas.pydata.org/docs/reference/api/pandas.Series.notna.html#pandas.Series.notna", "https://pandas.pydata.org/docs/reference/api/pandas.Series.pad.html#pandas.Series.pad", "https://pandas.pydata.org/docs/reference/api/pandas.Series.bfill.html#pandas.Series.bfill", "https://pandas.pydata.org/docs/reference/api/pandas.Series.ffill.html#pandas.Series.ffill", "https://pandas.pydata.org/docs/reference/api/pandas.Series.interpolate.html#pandas.Series.interpolate", "https://pandas.pydata.org/docs/reference/api/pandas.Series.isnull.html#pandas.Series.isnull", "https://pandas.pydata.org/docs/reference/api/pandas.Series.notnull.html#pandas.Series.notnull", "https://pandas.pydata.org/docs/reference/api/pandas.Series.replace.html#pandas.Series.replace"], "function_definitions": [{"function_name": "pandas.Series.backfill", "full_function": "Series.backfill(*, axis=None, inplace=False, limit=None, downcast=_NoDefault.no_default)", "function_text": "Fill NA/NaN values by using the next valid observation to fill the gap.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.backfill.html#pandas.Series.backfill"}, {"function_name": "pandas.Series.dropna", "full_function": "Series.dropna(*, axis=0, inplace=False, how=None, ignore_index=False)", "function_text": "Return a new Series with missing values removed.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{0 or ‘index’}", "param_desc": "Unused. Parameter needed for compatibility with DataFrame.\n"}, {"param_name": "inplace", "param_type": "bool, default False", "param_desc": "If True, do operation inplace and return None.\n"}, {"param_name": "how", "param_type": "str, optional", "param_desc": "Not in use. Kept for compatibility.\n"}, {"param_name": "ignore_index", "param_type": "bool, default False", "param_desc": "If True, the resulting axis will be labeled 0, 1, …, n - 1.\n\nNew in version 2.0.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dropna.html#pandas.Series.dropna"}, {"function_name": "pandas.Series.fillna", "full_function": "Series.fillna(value=None, *, method=None, axis=None, inplace=False, limit=None, downcast=_NoDefault.no_default)", "function_text": "Fill NA/NaN values using the specified method.", "parameter_names_desc": [{"param_name": "value", "param_type": "scalar, dict, Series, or DataFrame", "param_desc": "Value to use to fill holes (e.g. 0), alternately a\ndict/Series/DataFrame of values specifying which value to use for\neach index (for a Series) or column (for a DataFrame). Values not\nin the dict/Series/DataFrame will not be filled. This value cannot\nbe a list.\n"}, {"param_name": "method", "param_type": "{‘backfill’, ‘bfill’, ‘ffill’, None}, default None", "param_desc": "Method to use for filling holes in reindexed Series:\n\nffill: propagate last valid observation forward to next valid.\nbackfill / bfill: use next valid observation to fill gap.\n\n\nDeprecated since version 2.1.0: Use ffill or bfill instead.\n\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame", "param_desc": "Axis along which to fill missing values. For Series\nthis parameter is unused and defaults to 0.\n"}, {"param_name": "inplace", "param_type": "bool, default False", "param_desc": "If True, fill in-place. Note: this will modify any\nother views on this object (e.g., a no-copy slice for a column in a\nDataFrame).\n"}, {"param_name": "limit", "param_type": "int, default None", "param_desc": "If method is specified, this is the maximum number of consecutive\nNaN values to forward/backward fill. In other words, if there is\na gap with more than this number of consecutive NaNs, it will only\nbe partially filled. If method is not specified, this is the\nmaximum number of entries along the entire axis where NaNs will be\nfilled. Must be greater than 0 if not None.\n"}, {"param_name": "downcast", "param_type": "dict, default is None", "param_desc": "A dict of item->dtype of what to downcast if possible,\nor the string ‘infer’ which will try to downcast to an appropriate\nequal type (e.g. float64 to int64 if possible).\n\nDeprecated since version 2.2.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.fillna.html#pandas.Series.fillna"}, {"function_name": "pandas.Series.isna", "full_function": "Series.isna()", "function_text": "Detect missing values.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.isna.html#pandas.Series.isna"}, {"function_name": "pandas.Series.notna", "full_function": "Series.notna()", "function_text": "Detect existing (non-missing) values.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.notna.html#pandas.Series.notna"}, {"function_name": "pandas.Series.pad", "full_function": "Series.pad(*, axis=None, inplace=False, limit=None, downcast=_NoDefault.no_default)", "function_text": "Fill NA/NaN values by propagating the last valid observation to next valid.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.pad.html#pandas.Series.pad"}, {"function_name": "pandas.Series.bfill", "full_function": "Series.bfill(*, axis=None, inplace=False, limit=None, limit_area=None, downcast=_NoDefault.no_default)", "function_text": "Fill NA/NaN values by using the next valid observation to fill the gap.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame", "param_desc": "Axis along which to fill missing values. For Series\nthis parameter is unused and defaults to 0.\n"}, {"param_name": "inplace", "param_type": "bool, default False", "param_desc": "If True, fill in-place. Note: this will modify any\nother views on this object (e.g., a no-copy slice for a column in a\nDataFrame).\n"}, {"param_name": "limit", "param_type": "int, default None", "param_desc": "If method is specified, this is the maximum number of consecutive\nNaN values to forward/backward fill. In other words, if there is\na gap with more than this number of consecutive NaNs, it will only\nbe partially filled. If method is not specified, this is the\nmaximum number of entries along the entire axis where NaNs will be\nfilled. Must be greater than 0 if not None.\n"}, {"param_name": "limit_area", "param_type": "{None, ‘inside’, ‘outside’}, default None", "param_desc": "If limit is specified, consecutive NaNs will be filled with this\nrestriction.\n\nNone: No fill restriction.\n‘inside’: Only fill NaNs surrounded by valid values\n(interpolate).\n‘outside’: Only fill NaNs outside valid values (extrapolate).\n\n\nNew in version 2.2.0.\n\n"}, {"param_name": "downcast", "param_type": "dict, default is None", "param_desc": "A dict of item->dtype of what to downcast if possible,\nor the string ‘infer’ which will try to downcast to an appropriate\nequal type (e.g. float64 to int64 if possible).\n\nDeprecated since version 2.2.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.bfill.html#pandas.Series.bfill"}, {"function_name": "pandas.Series.ffill", "full_function": "Series.ffill(*, axis=None, inplace=False, limit=None, limit_area=None, downcast=_NoDefault.no_default)", "function_text": "Fill NA/NaN values by propagating the last valid observation to next valid.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame", "param_desc": "Axis along which to fill missing values. For Series\nthis parameter is unused and defaults to 0.\n"}, {"param_name": "inplace", "param_type": "bool, default False", "param_desc": "If True, fill in-place. Note: this will modify any\nother views on this object (e.g., a no-copy slice for a column in a\nDataFrame).\n"}, {"param_name": "limit", "param_type": "int, default None", "param_desc": "If method is specified, this is the maximum number of consecutive\nNaN values to forward/backward fill. In other words, if there is\na gap with more than this number of consecutive NaNs, it will only\nbe partially filled. If method is not specified, this is the\nmaximum number of entries along the entire axis where NaNs will be\nfilled. Must be greater than 0 if not None.\n"}, {"param_name": "limit_area", "param_type": "{None, ‘inside’, ‘outside’}, default None", "param_desc": "If limit is specified, consecutive NaNs will be filled with this\nrestriction.\n\nNone: No fill restriction.\n‘inside’: Only fill NaNs surrounded by valid values\n(interpolate).\n‘outside’: Only fill NaNs outside valid values (extrapolate).\n\n\nNew in version 2.2.0.\n\n"}, {"param_name": "downcast", "param_type": "dict, default is None", "param_desc": "A dict of item->dtype of what to downcast if possible,\nor the string ‘infer’ which will try to downcast to an appropriate\nequal type (e.g. float64 to int64 if possible).\n\nDeprecated since version 2.2.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.ffill.html#pandas.Series.ffill"}, {"function_name": "pandas.Series.interpolate", "full_function": "Series.interpolate(method='linear', *, axis=0, limit=None, inplace=False, limit_direction=None, limit_area=None, downcast=_NoDefault.no_default, **kwargs)", "function_text": "Fill NaN values using an interpolation method.", "parameter_names_desc": [{"param_name": "method", "param_type": "str, default ‘linear’", "param_desc": "Interpolation technique to use. One of:\n\n‘linear’: Ignore the index and treat the values as equally\nspaced. This is the only method supported on MultiIndexes.\n‘time’: Works on daily and higher resolution data to interpolate\ngiven length of interval.\n‘index’, ‘values’: use the actual numerical values of the index.\n‘pad’: Fill in NaNs using existing values.\n‘nearest’, ‘zero’, ‘slinear’, ‘quadratic’, ‘cubic’,\n‘barycentric’, ‘polynomial’: Passed to\nscipy.interpolate.interp1d, whereas ‘spline’ is passed to\nscipy.interpolate.UnivariateSpline. These methods use the numerical\nvalues of the index. Both ‘polynomial’ and ‘spline’ require that\nyou also specify an order (int), e.g.\ndf.interpolate(method='polynomial', order=5). Note that,\nslinear method in Pandas refers to the Scipy first order spline\ninstead of Pandas first order spline.\n‘krogh’, ‘piecewise_polynomial’, ‘spline’, ‘pchip’, ‘akima’,\n‘cubicspline’: Wrappers around the SciPy interpolation methods of\nsimilar names. See Notes.\n‘from_derivatives’: Refers to\nscipy.interpolate.BPoly.from_derivatives.\n\n"}, {"param_name": "axis", "param_type": "{{0 or ‘index’, 1 or ‘columns’, None}}, default None", "param_desc": "Axis to interpolate along. For Series this parameter is unused\nand defaults to 0.\n"}, {"param_name": "limit", "param_type": "int, optional", "param_desc": "Maximum number of consecutive NaNs to fill. Must be greater than\n0.\n"}, {"param_name": "inplace", "param_type": "bool, default False", "param_desc": "Update the data in place if possible.\n"}, {"param_name": "limit_direction", "param_type": "{{‘forward’, ‘backward’, ‘both’}}, Optional", "param_desc": "Consecutive NaNs will be filled in this direction.\n\nIf limit is specified:\nIf ‘method’ is ‘pad’ or ‘ffill’, ‘limit_direction’ must be ‘forward’.\nIf ‘method’ is ‘backfill’ or ‘bfill’, ‘limit_direction’ must be\n‘backwards’.\n\n\nIf ‘limit’ is not specified:\nIf ‘method’ is ‘backfill’ or ‘bfill’, the default is ‘backward’\nelse the default is ‘forward’\n\n\nraises ValueError if limit_direction is ‘forward’ or ‘both’ andmethod is ‘backfill’ or ‘bfill’.\n\nraises ValueError if limit_direction is ‘backward’ or ‘both’ andmethod is ‘pad’ or ‘ffill’.\n\n\n"}, {"param_name": "limit_area", "param_type": "{{None, ‘inside’, ‘outside’}}, default None", "param_desc": "If limit is specified, consecutive NaNs will be filled with this\nrestriction.\n\nNone: No fill restriction.\n‘inside’: Only fill NaNs surrounded by valid values\n(interpolate).\n‘outside’: Only fill NaNs outside valid values (extrapolate).\n\n"}, {"param_name": "downcast", "param_type": "optional, ‘infer’ or None, defaults to None", "param_desc": "Downcast dtypes if possible.\n\nDeprecated since version 2.1.0.\n\n"}, {"param_name": "``**kwargs``", "param_type": "optional", "param_desc": "Keyword arguments to pass on to the interpolating function.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.interpolate.html#pandas.Series.interpolate"}, {"function_name": "pandas.Series.isnull", "full_function": "Series.isnull()", "function_text": "Series.isnull is an alias for Series.isna.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.isnull.html#pandas.Series.isnull"}, {"function_name": "pandas.Series.notnull", "full_function": "Series.notnull()", "function_text": "Series.notnull is an alias for Series.notna.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.notnull.html#pandas.Series.notnull"}, {"function_name": "pandas.Series.replace", "full_function": "Series.replace(to_replace=None, value=_NoDefault.no_default, *, inplace=False, limit=None, regex=False, method=_NoDefault.no_default)", "function_text": "Replace values given in to_replace with value.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.replace.html#pandas.Series.replace"}]}, {"name": "Reshaping, sorting", "url": "https://pandas.pydata.org/docs/reference/series.html#reshaping-sorting", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.argsort.html#pandas.Series.argsort", "https://pandas.pydata.org/docs/reference/api/pandas.Series.argmax.html#pandas.Series.argmax", "https://pandas.pydata.org/docs/reference/api/pandas.Series.sort_values.html#pandas.Series.sort_values", "https://pandas.pydata.org/docs/reference/api/pandas.Series.swaplevel.html#pandas.Series.swaplevel", "https://pandas.pydata.org/docs/reference/api/pandas.Series.explode.html#pandas.Series.explode", "https://pandas.pydata.org/docs/reference/api/pandas.Series.ravel.html#pandas.Series.ravel", "https://pandas.pydata.org/docs/reference/api/pandas.Series.squeeze.html#pandas.Series.squeeze", "https://pandas.pydata.org/docs/reference/api/pandas.Series.argmin.html#pandas.Series.argmin", "https://pandas.pydata.org/docs/reference/api/pandas.Series.reorder_levels.html#pandas.Series.reorder_levels", "https://pandas.pydata.org/docs/reference/api/pandas.Series.sort_index.html#pandas.Series.sort_index", "https://pandas.pydata.org/docs/reference/api/pandas.Series.unstack.html#pandas.Series.unstack", "https://pandas.pydata.org/docs/reference/api/pandas.Series.searchsorted.html#pandas.Series.searchsorted", "https://pandas.pydata.org/docs/reference/api/pandas.Series.repeat.html#pandas.Series.repeat", "https://pandas.pydata.org/docs/reference/api/pandas.Series.view.html#pandas.Series.view"], "function_definitions": [{"function_name": "pandas.Series.argsort", "full_function": "Series.argsort(axis=0, kind='quicksort', order=None, stable=None)", "function_text": "Return the integer indices that would sort the Series values.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{0 or ‘index’}", "param_desc": "Unused. Parameter needed for compatibility with DataFrame.\n"}, {"param_name": "kind", "param_type": "{‘mergesort’, ‘quicksort’, ‘heapsort’, ‘stable’}, default ‘quicksort’", "param_desc": "Choice of sorting algorithm. See numpy.sort() for more\ninformation. ‘mergesort’ and ‘stable’ are the only stable algorithms.\n"}, {"param_name": "order", "param_type": "None", "param_desc": "Has no effect but is accepted for compatibility with numpy.\n"}, {"param_name": "stable", "param_type": "None", "param_desc": "Has no effect but is accepted for compatibility with numpy.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.argsort.html#pandas.Series.argsort"}, {"function_name": "pandas.Series.argmax", "full_function": "Series.argmax(axis=None, skipna=True, *args, **kwargs)", "function_text": "Return int position of the largest value in the Series.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{None}", "param_desc": "Unused. Parameter needed for compatibility with DataFrame.\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values when showing the result.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.argmax.html#pandas.Series.argmax"}, {"function_name": "pandas.Series.sort_values", "full_function": "Series.sort_values(*, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last', ignore_index=False, key=None)", "function_text": "Sort by the values.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{0 or ‘index’}", "param_desc": "Unused. Parameter needed for compatibility with DataFrame.\n"}, {"param_name": "ascending", "param_type": "bool or list of bools, default True", "param_desc": "If True, sort values in ascending order, otherwise descending.\n"}, {"param_name": "inplace", "param_type": "bool, default False", "param_desc": "If True, perform operation in-place.\n"}, {"param_name": "kind", "param_type": "{‘quicksort’, ‘mergesort’, ‘heapsort’, ‘stable’}, default ‘quicksort’", "param_desc": "Choice of sorting algorithm. See also numpy.sort() for more\ninformation. ‘mergesort’ and ‘stable’ are the only stable algorithms.\n"}, {"param_name": "na_position", "param_type": "{‘first’ or ‘last’}, default ‘last’", "param_desc": "Argument ‘first’ puts NaNs at the beginning, ‘last’ puts NaNs at\nthe end.\n"}, {"param_name": "ignore_index", "param_type": "bool, default False", "param_desc": "If True, the resulting axis will be labeled 0, 1, …, n - 1.\n"}, {"param_name": "key", "param_type": "callable, optional", "param_desc": "If not None, apply the key function to the series values\nbefore sorting. This is similar to the key argument in the\nbuiltin sorted() function, with the notable difference that\nthis key function should be vectorized. It should expect a\nSeries and return an array-like.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.sort_values.html#pandas.Series.sort_values"}, {"function_name": "pandas.Series.swaplevel", "full_function": "Series.swaplevel(i=-2, j=-1, copy=None)", "function_text": "Swap levels i and j in a MultiIndex.", "parameter_names_desc": [{"param_name": "i, j", "param_type": "int or str", "param_desc": "Levels of the indices to be swapped. Can pass level name as string.\n"}, {"param_name": "copy", "param_type": "bool, default True", "param_desc": "Whether to copy underlying data.\n\nNote\nThe copy keyword will change behavior in pandas 3.0.\nCopy-on-Write\nwill be enabled by default, which means that all methods with a\ncopy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas.\nYou can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.swaplevel.html#pandas.Series.swaplevel"}, {"function_name": "pandas.Series.explode", "full_function": "Series.explode(ignore_index=False)", "function_text": "Transform each element of a list-like to a row.", "parameter_names_desc": [{"param_name": "ignore_index", "param_type": "bool, default False", "param_desc": "If True, the resulting index will be labeled 0, 1, …, n - 1.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.explode.html#pandas.Series.explode"}, {"function_name": "pandas.Series.ravel", "full_function": "Series.ravel(order='C')", "function_text": "Return the flattened underlying data as an ndarray or ExtensionArray.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.ravel.html#pandas.Series.ravel"}, {"function_name": "pandas.Series.squeeze", "full_function": "Series.squeeze(axis=None)", "function_text": "Squeeze 1 dimensional axis objects into scalars.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’, None}, default None", "param_desc": "A specific axis to squeeze. By default, all length-1 axes are\nsqueezed. For Series this parameter is unused and defaults to None.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.squeeze.html#pandas.Series.squeeze"}, {"function_name": "pandas.Series.argmin", "full_function": "Series.argmin(axis=None, skipna=True, *args, **kwargs)", "function_text": "Return int position of the smallest value in the Series.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{None}", "param_desc": "Unused. Parameter needed for compatibility with DataFrame.\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values when showing the result.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.argmin.html#pandas.Series.argmin"}, {"function_name": "pandas.Series.reorder_levels", "full_function": "Series.reorder_levels(order)", "function_text": "Rearrange index levels using input order.", "parameter_names_desc": [{"param_name": "order", "param_type": "list of int representing new level order", "param_desc": "Reference level by number or key.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.reorder_levels.html#pandas.Series.reorder_levels"}, {"function_name": "pandas.Series.sort_index", "full_function": "Series.sort_index(*, axis=0, level=None, ascending=True, inplace=False, kind='quicksort', na_position='last', sort_remaining=True, ignore_index=False, key=None)", "function_text": "Sort Series by index labels.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{0 or ‘index’}", "param_desc": "Unused. Parameter needed for compatibility with DataFrame.\n"}, {"param_name": "level", "param_type": "int, optional", "param_desc": "If not None, sort on values in specified index level(s).\n"}, {"param_name": "ascending", "param_type": "bool or list-like of bools, default True", "param_desc": "Sort ascending vs. descending. When the index is a MultiIndex the\nsort direction can be controlled for each level individually.\n"}, {"param_name": "inplace", "param_type": "bool, default False", "param_desc": "If True, perform operation in-place.\n"}, {"param_name": "kind", "param_type": "{‘quicksort’, ‘mergesort’, ‘heapsort’, ‘stable’}, default ‘quicksort’", "param_desc": "Choice of sorting algorithm. See also numpy.sort() for more\ninformation. ‘mergesort’ and ‘stable’ are the only stable algorithms. For\nDataFrames, this option is only applied when sorting on a single\ncolumn or label.\n"}, {"param_name": "na_position", "param_type": "{‘first’, ‘last’}, default ‘last’", "param_desc": "If ‘first’ puts NaNs at the beginning, ‘last’ puts NaNs at the end.\nNot implemented for MultiIndex.\n"}, {"param_name": "sort_remaining", "param_type": "bool, default True", "param_desc": "If True and sorting by level and index is multilevel, sort by other\nlevels too (in order) after sorting by specified level.\n"}, {"param_name": "ignore_index", "param_type": "bool, default False", "param_desc": "If True, the resulting axis will be labeled 0, 1, …, n - 1.\n"}, {"param_name": "key", "param_type": "callable, optional", "param_desc": "If not None, apply the key function to the index values\nbefore sorting. This is similar to the key argument in the\nbuiltin sorted() function, with the notable difference that\nthis key function should be vectorized. It should expect an\nIndex and return an Index of the same shape.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.sort_index.html#pandas.Series.sort_index"}, {"function_name": "pandas.Series.unstack", "full_function": "Series.unstack(level=-1, fill_value=None, sort=True)", "function_text": "Unstack, also known as pivot, Series with MultiIndex to produce DataFrame.", "parameter_names_desc": [{"param_name": "level", "param_type": "int, str, or list of these, default last level", "param_desc": "Level(s) to unstack, can pass level name.\n"}, {"param_name": "fill_value", "param_type": "scalar value, default None", "param_desc": "Value to use when replacing NaN values.\n"}, {"param_name": "sort", "param_type": "bool, default True", "param_desc": "Sort the level(s) in the resulting MultiIndex columns.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.unstack.html#pandas.Series.unstack"}, {"function_name": "pandas.Series.searchsorted", "full_function": "Series.searchsorted(value, side='left', sorter=None)", "function_text": "Find indices where elements should be inserted to maintain order.", "parameter_names_desc": [{"param_name": "value", "param_type": "array-like or scalar", "param_desc": "Values to insert into self.\n"}, {"param_name": "side", "param_type": "{‘left’, ‘right’}, optional", "param_desc": "If ‘left’, the index of the first suitable location found is given.\nIf ‘right’, return the last such index. If there is no suitable\nindex, return either 0 or N (where N is the length of self).\n"}, {"param_name": "sorter", "param_type": "1-D array-like, optional", "param_desc": "Optional array of integer indices that sort self into ascending\norder. They are typically the result of np.argsort.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.searchsorted.html#pandas.Series.searchsorted"}, {"function_name": "pandas.Series.repeat", "full_function": "Series.repeat(repeats, axis=None)", "function_text": "Repeat elements of a Series.", "parameter_names_desc": [{"param_name": "repeats", "param_type": "int or array of ints", "param_desc": "The number of repetitions for each element. This should be a\nnon-negative integer. Repeating 0 times will return an empty\nSeries.\n"}, {"param_name": "axis", "param_type": "None", "param_desc": "Unused. Parameter needed for compatibility with DataFrame.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.repeat.html#pandas.Series.repeat"}, {"function_name": "pandas.Series.view", "full_function": "Series.view(dtype=None)", "function_text": "Create a new view of the Series.", "parameter_names_desc": [{"param_name": "dtype", "param_type": "data type", "param_desc": "Data type object or one of their string representations.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.view.html#pandas.Series.view"}]}, {"name": "Combining / comparing / joining / merging", "url": "https://pandas.pydata.org/docs/reference/series.html#combining-comparing-joining-merging", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.compare.html#pandas.Series.compare", "https://pandas.pydata.org/docs/reference/api/pandas.Series.update.html#pandas.Series.update"], "function_definitions": [{"function_name": "pandas.Series.compare", "full_function": "Series.compare(other, align_axis=1, keep_shape=False, keep_equal=False, result_names=('self', 'other'))", "function_text": "Compare to another Series and show the differences.", "parameter_names_desc": [{"param_name": "other", "param_type": "Series", "param_desc": "Object to compare with.\n"}, {"param_name": "align_axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 1", "param_desc": "Determine which axis to align the comparison on.\n\n\n0, or ‘index’Resulting differences are stacked verticallywith rows drawn alternately from self and other.\n\n\n\n\n1, or ‘columns’Resulting differences are aligned horizontallywith columns drawn alternately from self and other.\n\n\n\n\n"}, {"param_name": "keep_shape", "param_type": "bool, default False", "param_desc": "If true, all rows and columns are kept.\nOtherwise, only the ones with different values are kept.\n"}, {"param_name": "keep_equal", "param_type": "bool, default False", "param_desc": "If true, the result keeps values that are equal.\nOtherwise, equal values are shown as NaNs.\n"}, {"param_name": "result_names", "param_type": "tuple, default (‘self’, ‘other’)", "param_desc": "Set the dataframes names in the comparison.\n\nNew in version 1.5.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.compare.html#pandas.Series.compare"}, {"function_name": "pandas.Series.update", "full_function": "Series.update(other)", "function_text": "Modify Series in place using values from passed Series.", "parameter_names_desc": [{"param_name": "other", "param_type": "Series, or object coercible into Series", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.update.html#pandas.Series.update"}]}, {"name": "Time Series-related", "url": "https://pandas.pydata.org/docs/reference/series.html#time-series-related", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.asfreq.html#pandas.Series.asfreq", "https://pandas.pydata.org/docs/reference/api/pandas.Series.shift.html#pandas.Series.shift", "https://pandas.pydata.org/docs/reference/api/pandas.Series.last_valid_index.html#pandas.Series.last_valid_index", "https://pandas.pydata.org/docs/reference/api/pandas.Series.tz_convert.html#pandas.Series.tz_convert", "https://pandas.pydata.org/docs/reference/api/pandas.Series.at_time.html#pandas.Series.at_time", "https://pandas.pydata.org/docs/reference/api/pandas.Series.asof.html#pandas.Series.asof", "https://pandas.pydata.org/docs/reference/api/pandas.Series.first_valid_index.html#pandas.Series.first_valid_index", "https://pandas.pydata.org/docs/reference/api/pandas.Series.resample.html#pandas.Series.resample", "https://pandas.pydata.org/docs/reference/api/pandas.Series.tz_localize.html#pandas.Series.tz_localize", "https://pandas.pydata.org/docs/reference/api/pandas.Series.between_time.html#pandas.Series.between_time"], "function_definitions": [{"function_name": "pandas.Series.asfreq", "full_function": "Series.asfreq(freq, method=None, how=None, normalize=False, fill_value=None)", "function_text": "Convert time series to specified frequency.", "parameter_names_desc": [{"param_name": "freq", "param_type": "DateOffset or str", "param_desc": "Frequency DateOffset or string.\n"}, {"param_name": "method", "param_type": "{‘backfill’/’bfill’, ‘pad’/’ffill’}, default None", "param_desc": "Method to use for filling holes in reindexed Series (note this\ndoes not fill NaNs that already were present):\n\n‘pad’ / ‘ffill’: propagate last valid observation forward to next\nvalid\n‘backfill’ / ‘bfill’: use NEXT valid observation to fill.\n\n"}, {"param_name": "how", "param_type": "{‘start’, ‘end’}, default end", "param_desc": "For PeriodIndex only (see PeriodIndex.asfreq).\n"}, {"param_name": "normalize", "param_type": "bool, default False", "param_desc": "Whether to reset output index to midnight.\n"}, {"param_name": "fill_value", "param_type": "scalar, optional", "param_desc": "Value to use for missing values, applied during upsampling (note\nthis does not fill NaNs that already were present).\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.asfreq.html#pandas.Series.asfreq"}, {"function_name": "pandas.Series.shift", "full_function": "Series.shift(periods=1, freq=None, axis=0, fill_value=_NoDefault.no_default, suffix=None)", "function_text": "Shift index by desired number of periods with an optional time freq.", "parameter_names_desc": [{"param_name": "periods", "param_type": "int or Sequence", "param_desc": "Number of periods to shift. Can be positive or negative.\nIf an iterable of ints, the data will be shifted once by each int.\nThis is equivalent to shifting by one value at a time and\nconcatenating all resulting frames. The resulting columns will have\nthe shift suffixed to their column names. For multiple periods,\naxis must not be 1.\n"}, {"param_name": "freq", "param_type": "DateOffset, tseries.offsets, timedelta, or str, optional", "param_desc": "Offset to use from the tseries module or time rule (e.g. ‘EOM’).\nIf freq is specified then the index values are shifted but the\ndata is not realigned. That is, use freq if you would like to\nextend the index when shifting and preserve the original data.\nIf freq is specified as “infer” then it will be inferred from\nthe freq or inferred_freq attributes of the index. If neither of\nthose attributes exist, a ValueError is thrown.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’, None}, default None", "param_desc": "Shift direction. For Series this parameter is unused and defaults to 0.\n"}, {"param_name": "fill_value", "param_type": "object, optional", "param_desc": "The scalar value to use for newly introduced missing values.\nthe default depends on the dtype of self.\nFor numeric data, np.nan is used.\nFor datetime, timedelta, or period data, etc. NaT is used.\nFor extension dtypes, self.dtype.na_value is used.\n"}, {"param_name": "suffix", "param_type": "str, optional", "param_desc": "If str and periods is an iterable, this is added after the column\nname and before the shift value for each shifted column name.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.shift.html#pandas.Series.shift"}, {"function_name": "pandas.Series.last_valid_index", "full_function": "Series.last_valid_index()", "function_text": "Return index for last non-NA value or None, if no non-NA value is found.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.last_valid_index.html#pandas.Series.last_valid_index"}, {"function_name": "pandas.Series.tz_convert", "full_function": "Series.tz_convert(tz, axis=0, level=None, copy=None)", "function_text": "Convert tz-aware axis to target time zone.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.tz_convert.html#pandas.Series.tz_convert"}, {"function_name": "pandas.Series.at_time", "full_function": "Series.at_time(time, asof=False, axis=None)", "function_text": "Select values at particular time of day (e.g., 9:30AM).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.at_time.html#pandas.Series.at_time"}, {"function_name": "pandas.Series.asof", "full_function": "Series.asof(where, subset=None)", "function_text": "Return the last row(s) without any NaNs before where.", "parameter_names_desc": [{"param_name": "where", "param_type": "date or array-like of dates", "param_desc": "Date(s) before which the last row(s) are returned.\n"}, {"param_name": "subset", "param_type": "str or array-like of str, default None", "param_desc": "For DataFrame, if not None, only use these columns to\ncheck for NaNs.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.asof.html#pandas.Series.asof"}, {"function_name": "pandas.Series.first_valid_index", "full_function": "Series.first_valid_index()", "function_text": "Return index for first non-NA value or None, if no non-NA value is found.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.first_valid_index.html#pandas.Series.first_valid_index"}, {"function_name": "pandas.Series.resample", "full_function": "Series.resample(rule, axis=_NoDefault.no_default, closed=None, label=None, convention=_NoDefault.no_default, kind=_NoDefault.no_default, on=None, level=None, origin='start_day', offset=None, group_keys=False)", "function_text": "Resample time-series data.", "parameter_names_desc": [{"param_name": "rule", "param_type": "DateOffset, Timedelta or str", "param_desc": "The offset string or object representing target conversion.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "Which axis to use for up- or down-sampling. For Series this parameter\nis unused and defaults to 0. Must be\nDatetimeIndex, TimedeltaIndex or PeriodIndex.\n\nDeprecated since version 2.0.0: Use frame.T.resample(…) instead.\n\n"}, {"param_name": "closed", "param_type": "{‘right’, ‘left’}, default None", "param_desc": "Which side of bin interval is closed. The default is ‘left’\nfor all frequency offsets except for ‘ME’, ‘YE’, ‘QE’, ‘BME’,\n‘BA’, ‘BQE’, and ‘W’ which all have a default of ‘right’.\n"}, {"param_name": "label", "param_type": "{‘right’, ‘left’}, default None", "param_desc": "Which bin edge label to label bucket with. The default is ‘left’\nfor all frequency offsets except for ‘ME’, ‘YE’, ‘QE’, ‘BME’,\n‘BA’, ‘BQE’, and ‘W’ which all have a default of ‘right’.\n"}, {"param_name": "convention", "param_type": "{‘start’, ‘end’, ‘s’, ‘e’}, default ‘start’", "param_desc": "For PeriodIndex only, controls whether to use the start or\nend of rule.\n\nDeprecated since version 2.2.0: Convert PeriodIndex to DatetimeIndex before resampling instead.\n\n"}, {"param_name": "kind", "param_type": "{‘timestamp’, ‘period’}, optional, default None", "param_desc": "Pass ‘timestamp’ to convert the resulting index to a\nDateTimeIndex or ‘period’ to convert it to a PeriodIndex.\nBy default the input representation is retained.\n\nDeprecated since version 2.2.0: Convert index to desired type explicitly instead.\n\n"}, {"param_name": "on", "param_type": "str, optional", "param_desc": "For a DataFrame, column to use instead of index for resampling.\nColumn must be datetime-like.\n"}, {"param_name": "level", "param_type": "str or int, optional", "param_desc": "For a MultiIndex, level (name or number) to use for\nresampling. level must be datetime-like.\n"}, {"param_name": "origin", "param_type": "Timestamp or str, default ‘start_day’", "param_desc": "The timestamp on which to adjust the grouping. The timezone of origin\nmust match the timezone of the index.\nIf string, must be one of the following:\n\n‘epoch’: origin is 1970-01-01\n‘start’: origin is the first value of the timeseries\n‘start_day’: origin is the first day at midnight of the timeseries\n‘end’: origin is the last value of the timeseries\n‘end_day’: origin is the ceiling midnight of the last day\n\n\nNew in version 1.3.0.\n\n\nNote\nOnly takes effect for Tick-frequencies (i.e. fixed frequencies like\ndays, hours, and minutes, rather than months or quarters).\n\n"}, {"param_name": "offset", "param_type": "Timedelta or str, default is None", "param_desc": "An offset timedelta added to the origin.\n"}, {"param_name": "group_keys", "param_type": "bool, default False", "param_desc": "Whether to include the group keys in the result index when using\n.apply() on the resampled object.\n\nNew in version 1.5.0: Not specifying group_keys will retain values-dependent behavior\nfrom pandas 1.4 and earlier (see pandas 1.5.0 Release notes for examples).\n\n\nChanged in version 2.0.0: group_keys now defaults to False.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.resample.html#pandas.Series.resample"}, {"function_name": "pandas.Series.tz_localize", "full_function": "Series.tz_localize(tz, axis=0, level=None, copy=None, ambiguous='raise', nonexistent='raise')", "function_text": "Localize tz-naive index of a Series or DataFrame to target time zone.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.tz_localize.html#pandas.Series.tz_localize"}, {"function_name": "pandas.Series.between_time", "full_function": "Series.between_time(start_time, end_time, inclusive='both', axis=None)", "function_text": "Select values between particular times of the day (e.g., 9:00-9:30 AM).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.between_time.html#pandas.Series.between_time"}]}, {"name": "Accessors", "url": "https://pandas.pydata.org/docs/reference/series.html#accessors", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.html#pandas.Series.str", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.html#pandas.Series.dt", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sparse.html#pandas.DataFrame.sparse", "https://pandas.pydata.org/docs/reference/#api-series-str", "https://pandas.pydata.org/docs/reference/#api-series-sparse", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.date.html#pandas.Series.dt.date", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.timetz.html#pandas.Series.dt.timetz", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.month.html#pandas.Series.dt.month", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.hour.html#pandas.Series.dt.hour", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.second.html#pandas.Series.dt.second", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.nanosecond.html#pandas.Series.dt.nanosecond", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.day_of_week.html#pandas.Series.dt.day_of_week", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.dayofyear.html#pandas.Series.dt.dayofyear", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.days_in_month.html#pandas.Series.dt.days_in_month", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_month_start.html#pandas.Series.dt.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_quarter_start.html#pandas.Series.dt.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_year_start.html#pandas.Series.dt.is_year_start", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_leap_year.html#pandas.Series.dt.is_leap_year", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.days_in_month.html#pandas.Series.dt.days_in_month", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.freq.html#pandas.Series.dt.freq", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.isocalendar.html#pandas.Series.dt.isocalendar", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.to_pydatetime.html#pandas.Series.dt.to_pydatetime", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.tz_convert.html#pandas.Series.dt.tz_convert", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.strftime.html#pandas.Series.dt.strftime", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.floor.html#pandas.Series.dt.floor", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.month_name.html#pandas.Series.dt.month_name", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.as_unit.html#pandas.Series.dt.as_unit", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.qyear.html#pandas.Series.dt.qyear", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.end_time.html#pandas.Series.dt.end_time", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.days.html#pandas.Series.dt.days", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.microseconds.html#pandas.Series.dt.microseconds", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.components.html#pandas.Series.dt.components", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.to_pytimedelta.html#pandas.Series.dt.to_pytimedelta", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.as_unit.html#pandas.Series.dt.as_unit", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.capitalize.html#pandas.Series.str.capitalize", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.cat.html#pandas.Series.str.cat", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.contains.html#pandas.Series.str.contains", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.decode.html#pandas.Series.str.decode", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.endswith.html#pandas.Series.str.endswith", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.extractall.html#pandas.Series.str.extractall", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.findall.html#pandas.Series.str.findall", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.get.html#pandas.Series.str.get", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.join.html#pandas.Series.str.join", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.ljust.html#pandas.Series.str.ljust", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.lstrip.html#pandas.Series.str.lstrip", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.normalize.html#pandas.Series.str.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.partition.html#pandas.Series.str.partition", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.removesuffix.html#pandas.Series.str.removesuffix", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.replace.html#pandas.Series.str.replace", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rindex.html#pandas.Series.str.rindex", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rpartition.html#pandas.Series.str.rpartition", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.slice.html#pandas.Series.str.slice", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html#pandas.Series.str.split", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.startswith.html#pandas.Series.str.startswith", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.swapcase.html#pandas.Series.str.swapcase", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.translate.html#pandas.Series.str.translate", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.wrap.html#pandas.Series.str.wrap", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalnum.html#pandas.Series.str.isalnum", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isdigit.html#pandas.Series.str.isdigit", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.islower.html#pandas.Series.str.islower", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.istitle.html#pandas.Series.str.istitle", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isdecimal.html#pandas.Series.str.isdecimal", "https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.categories.html#pandas.Series.cat.categories", "https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.codes.html#pandas.Series.cat.codes", "https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.rename_categories.html#pandas.Series.cat.rename_categories", "https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.add_categories.html#pandas.Series.cat.add_categories", "https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_unused_categories.html#pandas.Series.cat.remove_unused_categories", "https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.as_ordered.html#pandas.Series.cat.as_ordered", "https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.npoints.html#pandas.Series.sparse.npoints", "https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.fill_value.html#pandas.Series.sparse.fill_value", "https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.from_coo.html#pandas.Series.sparse.from_coo", "https://pandas.pydata.org/docs/reference/api/pandas.Series.list.flatten.html#pandas.Series.list.flatten", "https://pandas.pydata.org/docs/reference/api/pandas.Series.list.__getitem__.html#pandas.Series.list.__getitem__", "https://pandas.pydata.org/docs/reference/api/pandas.Series.struct.dtypes.html#pandas.Series.struct.dtypes", "https://pandas.pydata.org/docs/reference/api/pandas.Series.struct.field.html#pandas.Series.struct.field", "https://pandas.pydata.org/docs/reference/api/pandas.Flags.html#pandas.Flags", "https://pandas.pydata.org/docs/reference/api/pandas.Series.attrs.html#pandas.Series.attrs", "https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.html#pandas.Series.cat", "https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.html#pandas.Series.sparse", "https://pandas.pydata.org/docs/reference/api/pandas.Index.str.html#pandas.Index.str", "https://pandas.pydata.org/docs/reference/#api-series-dt", "https://pandas.pydata.org/docs/reference/#api-series-cat", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.time.html#pandas.Series.dt.time", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.year.html#pandas.Series.dt.year", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.day.html#pandas.Series.dt.day", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.minute.html#pandas.Series.dt.minute", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.microsecond.html#pandas.Series.dt.microsecond", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.dayofweek.html#pandas.Series.dt.dayofweek", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.weekday.html#pandas.Series.dt.weekday", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.day_of_year.html#pandas.Series.dt.day_of_year", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.quarter.html#pandas.Series.dt.quarter", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_month_end.html#pandas.Series.dt.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_quarter_end.html#pandas.Series.dt.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_year_end.html#pandas.Series.dt.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.daysinmonth.html#pandas.Series.dt.daysinmonth", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.tz.html#pandas.Series.dt.tz", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.unit.html#pandas.Series.dt.unit", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.to_period.html#pandas.Series.dt.to_period", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.tz_localize.html#pandas.Series.dt.tz_localize", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.normalize.html#pandas.Series.dt.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.round.html#pandas.Series.dt.round", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.ceil.html#pandas.Series.dt.ceil", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.day_name.html#pandas.Series.dt.day_name", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.start_time.html#pandas.Series.dt.start_time", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.seconds.html#pandas.Series.dt.seconds", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.nanoseconds.html#pandas.Series.dt.nanoseconds", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.unit.html#pandas.Series.dt.unit", "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.total_seconds.html#pandas.Series.dt.total_seconds", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.casefold.html#pandas.Series.str.casefold", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.center.html#pandas.Series.str.center", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.count.html#pandas.Series.str.count", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.encode.html#pandas.Series.str.encode", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.extract.html#pandas.Series.str.extract", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.find.html#pandas.Series.str.find", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.fullmatch.html#pandas.Series.str.fullmatch", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.index.html#pandas.Series.str.index", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.len.html#pandas.Series.str.len", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.lower.html#pandas.Series.str.lower", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.match.html#pandas.Series.str.match", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.pad.html#pandas.Series.str.pad", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.removeprefix.html#pandas.Series.str.removeprefix", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.repeat.html#pandas.Series.str.repeat", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rfind.html#pandas.Series.str.rfind", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rjust.html#pandas.Series.str.rjust", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rstrip.html#pandas.Series.str.rstrip", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.slice_replace.html#pandas.Series.str.slice_replace", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rsplit.html#pandas.Series.str.rsplit", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.strip.html#pandas.Series.str.strip", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.title.html#pandas.Series.str.title", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.upper.html#pandas.Series.str.upper", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.zfill.html#pandas.Series.str.zfill", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalpha.html#pandas.Series.str.isalpha", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isspace.html#pandas.Series.str.isspace", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isupper.html#pandas.Series.str.isupper", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isnumeric.html#pandas.Series.str.isnumeric", "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.get_dummies.html#pandas.Series.str.get_dummies", "https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.ordered.html#pandas.Series.cat.ordered", "https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.reorder_categories.html#pandas.Series.cat.reorder_categories", "https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_categories.html#pandas.Series.cat.remove_categories", "https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.set_categories.html#pandas.Series.cat.set_categories", "https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.as_unordered.html#pandas.Series.cat.as_unordered", "https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.density.html#pandas.Series.sparse.density", "https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.sp_values.html#pandas.Series.sparse.sp_values", "https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.to_coo.html#pandas.Series.sparse.to_coo", "https://pandas.pydata.org/docs/reference/api/pandas.Series.list.len.html#pandas.Series.list.len", "https://pandas.pydata.org/docs/reference/api/pandas.Series.struct.explode.html#pandas.Series.struct.explode"], "function_definitions": [{"function_name": "pandas.Series.str", "full_function": "Series.str()", "function_text": "Vectorized string functions for Series and Index.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.html#pandas.Series.str"}, {"function_name": "pandas.Series.dt", "full_function": "Series.dt()", "function_text": "Accessor object for datetimelike properties of the Series values.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.html#pandas.Series.dt"}, {"function_name": "pandas.DataFrame.sparse", "full_function": "DataFrame.sparse()", "function_text": "DataFrame accessor for sparse data.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sparse.html#pandas.DataFrame.sparse"}, {"function_name": "pandas.DataFrame.sparse", "full_function": "DataFrame.sparse()", "function_text": "DataFrame accessor for sparse data.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sparse.html#pandas.DataFrame.sparse"}, {"function_name": "pandas.DataFrame.sparse", "full_function": "DataFrame.sparse()", "function_text": "DataFrame accessor for sparse data.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sparse.html#pandas.DataFrame.sparse"}, {"function_name": "pandas.Series.dt.date", "full_function": "Series.dt.date", "function_text": "Returns numpy array of python datetime.date objects.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.date.html#pandas.Series.dt.date"}, {"function_name": "pandas.Series.dt.timetz", "full_function": "Series.dt.timetz", "function_text": "Returns numpy array of datetime.time objects with timezones.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.timetz.html#pandas.Series.dt.timetz"}, {"function_name": "pandas.Series.dt.month", "full_function": "Series.dt.month", "function_text": "The month as January=1, December=12.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.month.html#pandas.Series.dt.month"}, {"function_name": "pandas.Series.dt.hour", "full_function": "Series.dt.hour", "function_text": "The hours of the datetime.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.hour.html#pandas.Series.dt.hour"}, {"function_name": "pandas.Series.dt.second", "full_function": "Series.dt.second", "function_text": "The seconds of the datetime.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.second.html#pandas.Series.dt.second"}, {"function_name": "pandas.Series.dt.nanosecond", "full_function": "Series.dt.nanosecond", "function_text": "The nanoseconds of the datetime.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.nanosecond.html#pandas.Series.dt.nanosecond"}, {"function_name": "pandas.Series.dt.day_of_week", "full_function": "Series.dt.day_of_week", "function_text": "The day of the week with Monday=0, Sunday=6.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.day_of_week.html#pandas.Series.dt.day_of_week"}, {"function_name": "pandas.Series.dt.dayofyear", "full_function": "Series.dt.dayofyear", "function_text": "The ordinal day of the year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.dayofyear.html#pandas.Series.dt.dayofyear"}, {"function_name": "pandas.Series.dt.days_in_month", "full_function": "Series.dt.days_in_month", "function_text": "The number of days in the month.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.days_in_month.html#pandas.Series.dt.days_in_month"}, {"function_name": "pandas.Series.dt.is_month_start", "full_function": "Series.dt.is_month_start", "function_text": "Indicates whether the date is the first day of the month.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_month_start.html#pandas.Series.dt.is_month_start"}, {"function_name": "pandas.Series.dt.is_quarter_start", "full_function": "Series.dt.is_quarter_start", "function_text": "Indicator for whether the date is the first day of a quarter.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_quarter_start.html#pandas.Series.dt.is_quarter_start"}, {"function_name": "pandas.Series.dt.is_year_start", "full_function": "Series.dt.is_year_start", "function_text": "Indicate whether the date is the first day of a year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_year_start.html#pandas.Series.dt.is_year_start"}, {"function_name": "pandas.Series.dt.is_leap_year", "full_function": "Series.dt.is_leap_year", "function_text": "Boolean indicator if the date belongs to a leap year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_leap_year.html#pandas.Series.dt.is_leap_year"}, {"function_name": "pandas.Series.dt.days_in_month", "full_function": "Series.dt.days_in_month", "function_text": "The number of days in the month.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.days_in_month.html#pandas.Series.dt.days_in_month"}, {"function_name": "pandas.Series.dt.days_in_month", "full_function": "Series.dt.days_in_month", "function_text": "The number of days in the month.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.days_in_month.html#pandas.Series.dt.days_in_month"}, {"function_name": "pandas.Series.dt.isocalendar", "full_function": "Series.dt.isocalendar()", "function_text": "Calculate year, week, and day according to the ISO 8601 standard.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.isocalendar.html#pandas.Series.dt.isocalendar"}, {"function_name": "pandas.Series.dt.to_pydatetime", "full_function": "Series.dt.to_pydatetime()", "function_text": "Return the data as an array of datetime.datetime objects.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.to_pydatetime.html#pandas.Series.dt.to_pydatetime"}, {"function_name": "pandas.Series.dt.tz_convert", "full_function": "Series.dt.tz_convert(*args, **kwargs)", "function_text": "Convert tz-aware Datetime Array/Index from one time zone to another.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.tz_convert.html#pandas.Series.dt.tz_convert"}, {"function_name": "pandas.Series.dt.strftime", "full_function": "Series.dt.strftime(*args, **kwargs)", "function_text": "Convert to Index using specified date_format.", "parameter_names_desc": [{"param_name": "date_format", "param_type": "str", "param_desc": "Date format string (e.g. “%Y-%m-%d”).\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.strftime.html#pandas.Series.dt.strftime"}, {"function_name": "pandas.Series.dt.floor", "full_function": "Series.dt.floor(*args, **kwargs)", "function_text": "Perform floor operation on the data to the specified freq.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.floor.html#pandas.Series.dt.floor"}, {"function_name": "pandas.Series.dt.month_name", "full_function": "Series.dt.month_name(*args, **kwargs)", "function_text": "Return the month names with specified locale.", "parameter_names_desc": [{"param_name": "locale", "param_type": "str, optional", "param_desc": "Locale determining the language in which to return the month name.\nDefault is English locale ('en_US.utf8'). Use the command\nlocale -a on your terminal on Unix systems to find your locale\nlanguage code.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.month_name.html#pandas.Series.dt.month_name"}, {"function_name": "pandas.Series.dt.month_name", "full_function": "Series.dt.month_name(*args, **kwargs)", "function_text": "Return the month names with specified locale.", "parameter_names_desc": [{"param_name": "locale", "param_type": "str, optional", "param_desc": "Locale determining the language in which to return the month name.\nDefault is English locale ('en_US.utf8'). Use the command\nlocale -a on your terminal on Unix systems to find your locale\nlanguage code.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.month_name.html#pandas.Series.dt.month_name"}, {"function_name": "pandas.Series.dt.month_name", "full_function": "Series.dt.month_name(*args, **kwargs)", "function_text": "Return the month names with specified locale.", "parameter_names_desc": [{"param_name": "locale", "param_type": "str, optional", "param_desc": "Locale determining the language in which to return the month name.\nDefault is English locale ('en_US.utf8'). Use the command\nlocale -a on your terminal on Unix systems to find your locale\nlanguage code.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.month_name.html#pandas.Series.dt.month_name"}, {"function_name": "pandas.Series.dt.end_time", "full_function": "Series.dt.end_time", "function_text": "Get the Timestamp for the end of the period.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.end_time.html#pandas.Series.dt.end_time"}, {"function_name": "pandas.Series.dt.days", "full_function": "Series.dt.days", "function_text": "Number of days for each element.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.days.html#pandas.Series.dt.days"}, {"function_name": "pandas.Series.dt.microseconds", "full_function": "Series.dt.microseconds", "function_text": "Number of microseconds (>= 0 and less than 1 second) for each element.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.microseconds.html#pandas.Series.dt.microseconds"}, {"function_name": "pandas.Series.dt.components", "full_function": "Series.dt.components", "function_text": "Return a Dataframe of the components of the Timedeltas.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.components.html#pandas.Series.dt.components"}, {"function_name": "pandas.Series.dt.to_pytimedelta", "full_function": "Series.dt.to_pytimedelta()", "function_text": "Return an array of native datetime.timedelta objects.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.to_pytimedelta.html#pandas.Series.dt.to_pytimedelta"}, {"function_name": "pandas.Series.dt.to_pytimedelta", "full_function": "Series.dt.to_pytimedelta()", "function_text": "Return an array of native datetime.timedelta objects.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.to_pytimedelta.html#pandas.Series.dt.to_pytimedelta"}, {"function_name": "pandas.Series.str.capitalize", "full_function": "Series.str.capitalize()", "function_text": "Convert strings in the Series/Index to be capitalized.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.capitalize.html#pandas.Series.str.capitalize"}, {"function_name": "pandas.Series.str.cat", "full_function": "Series.str.cat(others=None, sep=None, na_rep=None, join='left')", "function_text": "Concatenate strings in the Series/Index with given separator.", "parameter_names_desc": [{"param_name": "others", "param_type": "Series, Index, DataFrame, np.ndarray or list-like", "param_desc": "Series, Index, DataFrame, np.ndarray (one- or two-dimensional) and\nother list-likes of strings must have the same length as the\ncalling Series/Index, with the exception of indexed objects (i.e.\nSeries/Index/DataFrame) if join is not None.\nIf others is a list-like that contains a combination of Series,\nIndex or np.ndarray (1-dim), then all elements will be unpacked and\nmust satisfy the above criteria individually.\nIf others is None, the method returns the concatenation of all\nstrings in the calling Series/Index.\n"}, {"param_name": "sep", "param_type": "str, default ‘’", "param_desc": "The separator between the different elements/columns. By default\nthe empty string ‘’ is used.\n"}, {"param_name": "na_rep", "param_type": "str or None, default None", "param_desc": "Representation that is inserted for all missing values:\n\nIf na_rep is None, and others is None, missing values in the\nSeries/Index are omitted from the result.\nIf na_rep is None, and others is not None, a row containing a\nmissing value in any of the columns (before concatenation) will\nhave a missing value in the result.\n\n"}, {"param_name": "join", "param_type": "{‘left’, ‘right’, ‘outer’, ‘inner’}, default ‘left’", "param_desc": "Determines the join-style between the calling Series/Index and any\nSeries/Index/DataFrame in others (objects without an index need\nto match the length of the calling Series/Index). To disable\nalignment, use .values on any Series/Index/DataFrame in others.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.cat.html#pandas.Series.str.cat"}, {"function_name": "pandas.Series.str.contains", "full_function": "Series.str.contains(pat, case=True, flags=0, na=None, regex=True)", "function_text": "Test if pattern or regex is contained within a string of a Series or Index.", "parameter_names_desc": [{"param_name": "pat", "param_type": "str", "param_desc": "Character sequence or regular expression.\n"}, {"param_name": "case", "param_type": "bool, default True", "param_desc": "If True, case sensitive.\n"}, {"param_name": "flags", "param_type": "int, default 0 (no flags)", "param_desc": "Flags to pass through to the re module, e.g. re.IGNORECASE.\n"}, {"param_name": "na", "param_type": "scalar, optional", "param_desc": "Fill value for missing values. The default depends on dtype of the\narray. For object-dtype, numpy.nan is used. For StringDtype,\npandas.NA is used.\n"}, {"param_name": "regex", "param_type": "bool, default True", "param_desc": "If True, assumes the pat is a regular expression.\nIf False, treats the pat as a literal string.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.contains.html#pandas.Series.str.contains"}, {"function_name": "pandas.Series.str.decode", "full_function": "Series.str.decode(encoding, errors='strict')", "function_text": "Decode character string in the Series/Index using indicated encoding.", "parameter_names_desc": [{"param_name": "encoding", "param_type": "str", "param_desc": ""}, {"param_name": "errors", "param_type": "str, optional", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.decode.html#pandas.Series.str.decode"}, {"function_name": "pandas.Series.str.endswith", "full_function": "Series.str.endswith(pat, na=None)", "function_text": "Test if the end of each string element matches a pattern.", "parameter_names_desc": [{"param_name": "pat", "param_type": "str or tuple[str, …]", "param_desc": "Character sequence or tuple of strings. Regular expressions are not\naccepted.\n"}, {"param_name": "na", "param_type": "object, default NaN", "param_desc": "Object shown if element tested is not a string. The default depends\non dtype of the array. For object-dtype, numpy.nan is used.\nFor StringDtype, pandas.NA is used.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.endswith.html#pandas.Series.str.endswith"}, {"function_name": "pandas.Series.str.extractall", "full_function": "Series.str.extractall(pat, flags=0)", "function_text": "Extract capture groups in the regex pat as columns in DataFrame.", "parameter_names_desc": [{"param_name": "pat", "param_type": "str", "param_desc": "Regular expression pattern with capturing groups.\n"}, {"param_name": "flags", "param_type": "int, default 0 (no flags)", "param_desc": "A re module flag, for example re.IGNORECASE. These allow\nto modify regular expression matching for things like case, spaces,\netc. Multiple flags can be combined with the bitwise OR operator,\nfor example re.IGNORECASE | re.MULTILINE.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.extractall.html#pandas.Series.str.extractall"}, {"function_name": "pandas.Series.str.findall", "full_function": "Series.str.findall(pat, flags=0)", "function_text": "Find all occurrences of pattern or regular expression in the Series/Index.", "parameter_names_desc": [{"param_name": "pat", "param_type": "str", "param_desc": "Pattern or regular expression.\n"}, {"param_name": "flags", "param_type": "int, default 0", "param_desc": "Flags from re module, e.g. re.IGNORECASE (default is 0, which\nmeans no flags).\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.findall.html#pandas.Series.str.findall"}, {"function_name": "pandas.Series.str.get", "full_function": "Series.str.get(i)", "function_text": "Extract element from each component at specified position or with specified key.", "parameter_names_desc": [{"param_name": "i", "param_type": "int or hashable dict label", "param_desc": "Position or key of element to extract.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.get.html#pandas.Series.str.get"}, {"function_name": "pandas.Series.str.join", "full_function": "Series.str.join(sep)", "function_text": "Join lists contained as elements in the Series/Index with passed delimiter.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.join.html#pandas.Series.str.join"}, {"function_name": "pandas.Series.str.ljust", "full_function": "Series.str.ljust(width, fillchar=' ')", "function_text": "Pad right side of strings in the Series/Index.", "parameter_names_desc": [{"param_name": "width", "param_type": "int", "param_desc": "Minimum width of resulting string; additional characters will be filled\nwith fillchar.\n"}, {"param_name": "fillchar", "param_type": "str", "param_desc": "Additional character for filling, default is whitespace.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.ljust.html#pandas.Series.str.ljust"}, {"function_name": "pandas.Series.str.lstrip", "full_function": "Series.str.lstrip(to_strip=None)", "function_text": "Remove leading characters.", "parameter_names_desc": [{"param_name": "to_strip", "param_type": "str or None, default None", "param_desc": "Specifying the set of characters to be removed.\nAll combinations of this set of characters will be stripped.\nIf None then whitespaces are removed.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.lstrip.html#pandas.Series.str.lstrip"}, {"function_name": "pandas.Series.str.normalize", "full_function": "Series.str.normalize(form)", "function_text": "Return the Unicode normal form for the strings in the Series/Index.", "parameter_names_desc": [{"param_name": "form", "param_type": "{‘NFC’, ‘NFKC’, ‘NFD’, ‘NFKD’}", "param_desc": "Unicode form.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.normalize.html#pandas.Series.str.normalize"}, {"function_name": "pandas.Series.str.partition", "full_function": "Series.str.partition(sep=' ', expand=True)", "function_text": "Split the string at the first occurrence of sep.", "parameter_names_desc": [{"param_name": "sep", "param_type": "str, default whitespace", "param_desc": "String to split on.\n"}, {"param_name": "expand", "param_type": "bool, default True", "param_desc": "If True, return DataFrame/MultiIndex expanding dimensionality.\nIf False, return Series/Index.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.partition.html#pandas.Series.str.partition"}, {"function_name": "pandas.Series.str.removesuffix", "full_function": "Series.str.removesuffix(suffix)", "function_text": "Remove a suffix from an object series.", "parameter_names_desc": [{"param_name": "suffix", "param_type": "str", "param_desc": "Remove the suffix of the string.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.removesuffix.html#pandas.Series.str.removesuffix"}, {"function_name": "pandas.Series.str.replace", "full_function": "Series.str.replace(pat, repl, n=-1, case=None, flags=0, regex=False)", "function_text": "Replace each occurrence of pattern/regex in the Series/Index.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.replace.html#pandas.Series.str.replace"}, {"function_name": "pandas.Series.str.rindex", "full_function": "Series.str.rindex(sub, start=0, end=None)", "function_text": "Return highest indexes in each string in Series/Index.", "parameter_names_desc": [{"param_name": "sub", "param_type": "str", "param_desc": "Substring being searched.\n"}, {"param_name": "start", "param_type": "int", "param_desc": "Left edge index.\n"}, {"param_name": "end", "param_type": "int", "param_desc": "Right edge index.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rindex.html#pandas.Series.str.rindex"}, {"function_name": "pandas.Series.str.rpartition", "full_function": "Series.str.rpartition(sep=' ', expand=True)", "function_text": "Split the string at the last occurrence of sep.", "parameter_names_desc": [{"param_name": "sep", "param_type": "str, default whitespace", "param_desc": "String to split on.\n"}, {"param_name": "expand", "param_type": "bool, default True", "param_desc": "If True, return DataFrame/MultiIndex expanding dimensionality.\nIf False, return Series/Index.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rpartition.html#pandas.Series.str.rpartition"}, {"function_name": "pandas.Series.str.slice", "full_function": "Series.str.slice(start=None, stop=None, step=None)", "function_text": "Slice substrings from each element in the Series or Index.", "parameter_names_desc": [{"param_name": "start", "param_type": "int, optional", "param_desc": "Start position for slice operation.\n"}, {"param_name": "stop", "param_type": "int, optional", "param_desc": "Stop position for slice operation.\n"}, {"param_name": "step", "param_type": "int, optional", "param_desc": "Step size for slice operation.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.slice.html#pandas.Series.str.slice"}, {"function_name": "pandas.Series.str.split", "full_function": "Series.str.split(pat=None, *, n=-1, expand=False, regex=None)", "function_text": "Split strings around given separator/delimiter.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html#pandas.Series.str.split"}, {"function_name": "pandas.Series.str.startswith", "full_function": "Series.str.startswith(pat, na=None)", "function_text": "Test if the start of each string element matches a pattern.", "parameter_names_desc": [{"param_name": "pat", "param_type": "str or tuple[str, …]", "param_desc": "Character sequence or tuple of strings. Regular expressions are not\naccepted.\n"}, {"param_name": "na", "param_type": "object, default NaN", "param_desc": "Object shown if element tested is not a string. The default depends\non dtype of the array. For object-dtype, numpy.nan is used.\nFor StringDtype, pandas.NA is used.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.startswith.html#pandas.Series.str.startswith"}, {"function_name": "pandas.Series.str.swapcase", "full_function": "Series.str.swapcase()", "function_text": "Convert strings in the Series/Index to be swapcased.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.swapcase.html#pandas.Series.str.swapcase"}, {"function_name": "pandas.Series.str.translate", "full_function": "Series.str.translate(table)", "function_text": "Map all characters in the string through the given mapping table.", "parameter_names_desc": [{"param_name": "table", "param_type": "dict", "param_desc": "Table is a mapping of Unicode ordinals to Unicode ordinals, strings, or\nNone. Unmapped characters are left untouched.\nCharacters mapped to None are deleted. str.maketrans() is a\nhelper function for making translation tables.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.translate.html#pandas.Series.str.translate"}, {"function_name": "pandas.Series.str.wrap", "full_function": "Series.str.wrap(width, **kwargs)", "function_text": "Wrap strings in Series/Index at specified line width.", "parameter_names_desc": [{"param_name": "width", "param_type": "int", "param_desc": "Maximum line width.\n"}, {"param_name": "expand_tabs", "param_type": "bool, optional", "param_desc": "If True, tab characters will be expanded to spaces (default: True).\n"}, {"param_name": "replace_whitespace", "param_type": "bool, optional", "param_desc": "If True, each whitespace character (as defined by string.whitespace)\nremaining after tab expansion will be replaced by a single space\n(default: True).\n"}, {"param_name": "drop_whitespace", "param_type": "bool, optional", "param_desc": "If True, whitespace that, after wrapping, happens to end up at the\nbeginning or end of a line is dropped (default: True).\n"}, {"param_name": "break_long_words", "param_type": "bool, optional", "param_desc": "If True, then words longer than width will be broken in order to ensure\nthat no lines are longer than width. If it is false, long words will\nnot be broken, and some lines may be longer than width (default: True).\n"}, {"param_name": "break_on_hyphens", "param_type": "bool, optional", "param_desc": "If True, wrapping will occur preferably on whitespace and right after\nhyphens in compound words, as it is customary in English. If false,\nonly whitespaces will be considered as potentially good places for line\nbreaks, but you need to set break_long_words to false if you want truly\ninsecable words (default: True).\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.wrap.html#pandas.Series.str.wrap"}, {"function_name": "pandas.Series.str.isalnum", "full_function": "Series.str.isalnum()", "function_text": "Check whether all characters in each string are alphanumeric.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalnum.html#pandas.Series.str.isalnum"}, {"function_name": "pandas.Series.str.isdigit", "full_function": "Series.str.isdigit()", "function_text": "Check whether all characters in each string are digits.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isdigit.html#pandas.Series.str.isdigit"}, {"function_name": "pandas.Series.str.islower", "full_function": "Series.str.islower()", "function_text": "Check whether all characters in each string are lowercase.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.islower.html#pandas.Series.str.islower"}, {"function_name": "pandas.Series.str.istitle", "full_function": "Series.str.istitle()", "function_text": "Check whether all characters in each string are titlecase.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.istitle.html#pandas.Series.str.istitle"}, {"function_name": "pandas.Series.str.isdecimal", "full_function": "Series.str.isdecimal()", "function_text": "Check whether all characters in each string are decimal.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isdecimal.html#pandas.Series.str.isdecimal"}, {"function_name": "pandas.Series.cat.categories", "full_function": "Series.cat.categories", "function_text": "The categories of this categorical.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.categories.html#pandas.Series.cat.categories"}, {"function_name": "pandas.Series.cat.codes", "full_function": "Series.cat.codes", "function_text": "Return Series of codes as well as the index.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.codes.html#pandas.Series.cat.codes"}, {"function_name": "pandas.Series.cat.rename_categories", "full_function": "Series.cat.rename_categories(*args, **kwargs)", "function_text": "Rename categories.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.rename_categories.html#pandas.Series.cat.rename_categories"}, {"function_name": "pandas.Series.cat.add_categories", "full_function": "Series.cat.add_categories(*args, **kwargs)", "function_text": "Add new categories.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.add_categories.html#pandas.Series.cat.add_categories"}, {"function_name": "pandas.Series.cat.remove_unused_categories", "full_function": "Series.cat.remove_unused_categories(*args, **kwargs)", "function_text": "Remove categories which are not used.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_unused_categories.html#pandas.Series.cat.remove_unused_categories"}, {"function_name": "pandas.Series.cat.as_ordered", "full_function": "Series.cat.as_ordered(*args, **kwargs)", "function_text": "Set the Categorical to be ordered.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.as_ordered.html#pandas.Series.cat.as_ordered"}, {"function_name": "pandas.Series.sparse.npoints", "full_function": "Series.sparse.npoints", "function_text": "The number of non- fill_value points.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.npoints.html#pandas.Series.sparse.npoints"}, {"function_name": "pandas.Series.sparse.fill_value", "full_function": "Series.sparse.fill_value", "function_text": "Elements in data that are fill_value are not stored.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.fill_value.html#pandas.Series.sparse.fill_value"}, {"function_name": "pandas.Series.sparse.from_coo", "full_function": "classmethod Series.sparse.from_coo(A, dense_index=False)", "function_text": "Create a Series with sparse values from a scipy.sparse.coo_matrix.", "parameter_names_desc": [{"param_name": "A", "param_type": "scipy.sparse.coo_matrix", "param_desc": ""}, {"param_name": "dense_index", "param_type": "bool, default False", "param_desc": "If False (default), the index consists of only the\ncoords of the non-null entries of the original coo_matrix.\nIf True, the index consists of the full sorted\n(row, col) coordinates of the coo_matrix.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.from_coo.html#pandas.Series.sparse.from_coo"}, {"function_name": "pandas.Series.list.flatten", "full_function": "Series.list.flatten()", "function_text": "Flatten list values.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.list.flatten.html#pandas.Series.list.flatten"}, {"function_name": "pandas.Series.list.__getitem__", "full_function": "Series.list.__getitem__(key)", "function_text": "Index or slice lists in the Series.", "parameter_names_desc": [{"param_name": "key", "param_type": "int | slice", "param_desc": "Index or slice of indices to access from each list.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.list.__getitem__.html#pandas.Series.list.__getitem__"}, {"function_name": "pandas.Series.struct.dtypes", "full_function": "Series.struct.dtypes", "function_text": "Return the dtype object of each child field of the struct.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.struct.dtypes.html#pandas.Series.struct.dtypes"}, {"function_name": "pandas.Series.struct.field", "full_function": "Series.struct.field(name_or_index)", "function_text": "Extract a child field of a struct as a Series.", "parameter_names_desc": [{"param_name": "name_or_index", "param_type": "str | bytes | int | expression | list", "param_desc": "Name or index of the child field to extract.\nFor list-like inputs, this will index into a nested\nstruct.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.struct.field.html#pandas.Series.struct.field"}, {"function_name": "pandas.Flags", "full_function": "class pandas.Flags(obj, *, allows_duplicate_labels)", "function_text": "Flags that apply to pandas objects.", "parameter_names_desc": [{"param_name": "obj", "param_type": "Series or DataFrame", "param_desc": "The object these flags are associated with.\n"}, {"param_name": "allows_duplicate_labels", "param_type": "bool, default True", "param_desc": "Whether to allow duplicate labels in this object. By default,\nduplicate labels are permitted. Setting this to False will\ncause an errors.DuplicateLabelError to be raised when\nindex (or columns for DataFrame) is not unique, or any\nsubsequent operation on introduces duplicates.\nSee Disallowing Duplicate Labels for more.\n\nWarning\nThis is an experimental feature. Currently, many methods fail to\npropagate the allows_duplicate_labels value. In future versions\nit is expected that every method taking or returning one or more\nDataFrame or Series objects will propagate allows_duplicate_labels.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Flags.html#pandas.Flags"}, {"function_name": "pandas.Series.attrs", "full_function": "property Series.attrs", "function_text": "Dictionary of global attributes of this dataset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.attrs.html#pandas.Series.attrs"}, {"function_name": "pandas.Series.cat", "full_function": "Series.cat()", "function_text": "Accessor object for categorical properties of the Series values.", "parameter_names_desc": [{"param_name": "data", "param_type": "Series or CategoricalIndex", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.html#pandas.Series.cat"}, {"function_name": "pandas.Series.sparse", "full_function": "Series.sparse()", "function_text": "Accessor for SparseSparse from other sparse matrix data types.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.html#pandas.Series.sparse"}, {"function_name": "pandas.Index.str", "full_function": "Index.str()", "function_text": "Vectorized string functions for Series and Index.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.str.html#pandas.Index.str"}, {"function_name": "pandas.Index.str", "full_function": "Index.str()", "function_text": "Vectorized string functions for Series and Index.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.str.html#pandas.Index.str"}, {"function_name": "pandas.Index.str", "full_function": "Index.str()", "function_text": "Vectorized string functions for Series and Index.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.str.html#pandas.Index.str"}, {"function_name": "pandas.Series.dt.time", "full_function": "Series.dt.time", "function_text": "Returns numpy array of datetime.time objects.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.time.html#pandas.Series.dt.time"}, {"function_name": "pandas.Series.dt.year", "full_function": "Series.dt.year", "function_text": "The year of the datetime.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.year.html#pandas.Series.dt.year"}, {"function_name": "pandas.Series.dt.day", "full_function": "Series.dt.day", "function_text": "The day of the datetime.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.day.html#pandas.Series.dt.day"}, {"function_name": "pandas.Series.dt.minute", "full_function": "Series.dt.minute", "function_text": "The minutes of the datetime.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.minute.html#pandas.Series.dt.minute"}, {"function_name": "pandas.Series.dt.microsecond", "full_function": "Series.dt.microsecond", "function_text": "The microseconds of the datetime.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.microsecond.html#pandas.Series.dt.microsecond"}, {"function_name": "pandas.Series.dt.dayofweek", "full_function": "Series.dt.dayofweek", "function_text": "The day of the week with Monday=0, Sunday=6.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.dayofweek.html#pandas.Series.dt.dayofweek"}, {"function_name": "pandas.Series.dt.weekday", "full_function": "Series.dt.weekday", "function_text": "The day of the week with Monday=0, Sunday=6.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.weekday.html#pandas.Series.dt.weekday"}, {"function_name": "pandas.Series.dt.day_of_year", "full_function": "Series.dt.day_of_year", "function_text": "The ordinal day of the year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.day_of_year.html#pandas.Series.dt.day_of_year"}, {"function_name": "pandas.Series.dt.quarter", "full_function": "Series.dt.quarter", "function_text": "The quarter of the date.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.quarter.html#pandas.Series.dt.quarter"}, {"function_name": "pandas.Series.dt.is_month_end", "full_function": "Series.dt.is_month_end", "function_text": "Indicates whether the date is the last day of the month.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_month_end.html#pandas.Series.dt.is_month_end"}, {"function_name": "pandas.Series.dt.is_quarter_end", "full_function": "Series.dt.is_quarter_end", "function_text": "Indicator for whether the date is the last day of a quarter.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_quarter_end.html#pandas.Series.dt.is_quarter_end"}, {"function_name": "pandas.Series.dt.is_year_end", "full_function": "Series.dt.is_year_end", "function_text": "Indicate whether the date is the last day of the year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_year_end.html#pandas.Series.dt.is_year_end"}, {"function_name": "pandas.Series.dt.daysinmonth", "full_function": "Series.dt.daysinmonth", "function_text": "The number of days in the month.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.daysinmonth.html#pandas.Series.dt.daysinmonth"}, {"function_name": "pandas.Series.dt.tz", "full_function": "Series.dt.tz", "function_text": "Return the timezone.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.tz.html#pandas.Series.dt.tz"}, {"function_name": "pandas.Series.dt.tz", "full_function": "Series.dt.tz", "function_text": "Return the timezone.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.tz.html#pandas.Series.dt.tz"}, {"function_name": "pandas.Series.dt.to_period", "full_function": "Series.dt.to_period(*args, **kwargs)", "function_text": "Cast to PeriodArray/PeriodIndex at a particular frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.to_period.html#pandas.Series.dt.to_period"}, {"function_name": "pandas.Series.dt.tz_localize", "full_function": "Series.dt.tz_localize(*args, **kwargs)", "function_text": "Localize tz-naive Datetime Array/Index to tz-aware Datetime Array/Index.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.tz_localize.html#pandas.Series.dt.tz_localize"}, {"function_name": "pandas.Series.dt.normalize", "full_function": "Series.dt.normalize(*args, **kwargs)", "function_text": "Convert times to midnight.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.normalize.html#pandas.Series.dt.normalize"}, {"function_name": "pandas.Series.dt.round", "full_function": "Series.dt.round(*args, **kwargs)", "function_text": "Perform round operation on the data to the specified freq.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.round.html#pandas.Series.dt.round"}, {"function_name": "pandas.Series.dt.ceil", "full_function": "Series.dt.ceil(*args, **kwargs)", "function_text": "Perform ceil operation on the data to the specified freq.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.ceil.html#pandas.Series.dt.ceil"}, {"function_name": "pandas.Series.dt.day_name", "full_function": "Series.dt.day_name(*args, **kwargs)", "function_text": "Return the day names with specified locale.", "parameter_names_desc": [{"param_name": "locale", "param_type": "str, optional", "param_desc": "Locale determining the language in which to return the day name.\nDefault is English locale ('en_US.utf8'). Use the command\nlocale -a on your terminal on Unix systems to find your locale\nlanguage code.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.day_name.html#pandas.Series.dt.day_name"}, {"function_name": "pandas.Series.dt.start_time", "full_function": "Series.dt.start_time", "function_text": "Get the Timestamp for the start of the period.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.start_time.html#pandas.Series.dt.start_time"}, {"function_name": "pandas.Series.dt.seconds", "full_function": "Series.dt.seconds", "function_text": "Number of seconds (>= 0 and less than 1 day) for each element.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.seconds.html#pandas.Series.dt.seconds"}, {"function_name": "pandas.Series.dt.nanoseconds", "full_function": "Series.dt.nanoseconds", "function_text": "Number of nanoseconds (>= 0 and less than 1 microsecond) for each element.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.nanoseconds.html#pandas.Series.dt.nanoseconds"}, {"function_name": "pandas.Series.dt.nanoseconds", "full_function": "Series.dt.nanoseconds", "function_text": "Number of nanoseconds (>= 0 and less than 1 microsecond) for each element.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.nanoseconds.html#pandas.Series.dt.nanoseconds"}, {"function_name": "pandas.Series.dt.total_seconds", "full_function": "Series.dt.total_seconds(*args, **kwargs)", "function_text": "Return total duration of each element expressed in seconds.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.total_seconds.html#pandas.Series.dt.total_seconds"}, {"function_name": "pandas.Series.str.casefold", "full_function": "Series.str.casefold()", "function_text": "Convert strings in the Series/Index to be casefolded.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.casefold.html#pandas.Series.str.casefold"}, {"function_name": "pandas.Series.str.center", "full_function": "Series.str.center(width, fillchar=' ')", "function_text": "Pad left and right side of strings in the Series/Index.", "parameter_names_desc": [{"param_name": "width", "param_type": "int", "param_desc": "Minimum width of resulting string; additional characters will be filled\nwith fillchar.\n"}, {"param_name": "fillchar", "param_type": "str", "param_desc": "Additional character for filling, default is whitespace.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.center.html#pandas.Series.str.center"}, {"function_name": "pandas.Series.str.count", "full_function": "Series.str.count(pat, flags=0)", "function_text": "Count occurrences of pattern in each string of the Series/Index.", "parameter_names_desc": [{"param_name": "pat", "param_type": "str", "param_desc": "Valid regular expression.\n"}, {"param_name": "flags", "param_type": "int, default 0, meaning no flags", "param_desc": "Flags for the re module. For a complete list, see here.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.count.html#pandas.Series.str.count"}, {"function_name": "pandas.Series.str.encode", "full_function": "Series.str.encode(encoding, errors='strict')", "function_text": "Encode character string in the Series/Index using indicated encoding.", "parameter_names_desc": [{"param_name": "encoding", "param_type": "str", "param_desc": ""}, {"param_name": "errors", "param_type": "str, optional", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.encode.html#pandas.Series.str.encode"}, {"function_name": "pandas.Series.str.extract", "full_function": "Series.str.extract(pat, flags=0, expand=True)", "function_text": "Extract capture groups in the regex pat as columns in a DataFrame.", "parameter_names_desc": [{"param_name": "pat", "param_type": "str", "param_desc": "Regular expression pattern with capturing groups.\n"}, {"param_name": "flags", "param_type": "int, default 0 (no flags)", "param_desc": "Flags from the re module, e.g. re.IGNORECASE, that\nmodify regular expression matching for things like case,\nspaces, etc. For more details, see re.\n"}, {"param_name": "expand", "param_type": "bool, default True", "param_desc": "If True, return DataFrame with one column per capture group.\nIf False, return a Series/Index if there is one capture group\nor DataFrame if there are multiple capture groups.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.extract.html#pandas.Series.str.extract"}, {"function_name": "pandas.Series.str.find", "full_function": "Series.str.find(sub, start=0, end=None)", "function_text": "Return lowest indexes in each strings in the Series/Index.", "parameter_names_desc": [{"param_name": "sub", "param_type": "str", "param_desc": "Substring being searched.\n"}, {"param_name": "start", "param_type": "int", "param_desc": "Left edge index.\n"}, {"param_name": "end", "param_type": "int", "param_desc": "Right edge index.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.find.html#pandas.Series.str.find"}, {"function_name": "pandas.Series.str.fullmatch", "full_function": "Series.str.fullmatch(pat, case=True, flags=0, na=None)", "function_text": "Determine if each string entirely matches a regular expression.", "parameter_names_desc": [{"param_name": "pat", "param_type": "str", "param_desc": "Character sequence or regular expression.\n"}, {"param_name": "case", "param_type": "bool, default True", "param_desc": "If True, case sensitive.\n"}, {"param_name": "flags", "param_type": "int, default 0 (no flags)", "param_desc": "Regex module flags, e.g. re.IGNORECASE.\n"}, {"param_name": "na", "param_type": "scalar, optional", "param_desc": "Fill value for missing values. The default depends on dtype of the\narray. For object-dtype, numpy.nan is used. For StringDtype,\npandas.NA is used.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.fullmatch.html#pandas.Series.str.fullmatch"}, {"function_name": "pandas.Series.str.index", "full_function": "Series.str.index(sub, start=0, end=None)", "function_text": "Return lowest indexes in each string in Series/Index.", "parameter_names_desc": [{"param_name": "sub", "param_type": "str", "param_desc": "Substring being searched.\n"}, {"param_name": "start", "param_type": "int", "param_desc": "Left edge index.\n"}, {"param_name": "end", "param_type": "int", "param_desc": "Right edge index.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.index.html#pandas.Series.str.index"}, {"function_name": "pandas.Series.str.len", "full_function": "Series.str.len()", "function_text": "Compute the length of each element in the Series/Index.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.len.html#pandas.Series.str.len"}, {"function_name": "pandas.Series.str.lower", "full_function": "Series.str.lower()", "function_text": "Convert strings in the Series/Index to lowercase.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.lower.html#pandas.Series.str.lower"}, {"function_name": "pandas.Series.str.match", "full_function": "Series.str.match(pat, case=True, flags=0, na=None)", "function_text": "Determine if each string starts with a match of a regular expression.", "parameter_names_desc": [{"param_name": "pat", "param_type": "str", "param_desc": "Character sequence.\n"}, {"param_name": "case", "param_type": "bool, default True", "param_desc": "If True, case sensitive.\n"}, {"param_name": "flags", "param_type": "int, default 0 (no flags)", "param_desc": "Regex module flags, e.g. re.IGNORECASE.\n"}, {"param_name": "na", "param_type": "scalar, optional", "param_desc": "Fill value for missing values. The default depends on dtype of the\narray. For object-dtype, numpy.nan is used. For StringDtype,\npandas.NA is used.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.match.html#pandas.Series.str.match"}, {"function_name": "pandas.Series.str.pad", "full_function": "Series.str.pad(width, side='left', fillchar=' ')", "function_text": "Pad strings in the Series/Index up to width.", "parameter_names_desc": [{"param_name": "width", "param_type": "int", "param_desc": "Minimum width of resulting string; additional characters will be filled\nwith character defined in fillchar.\n"}, {"param_name": "side", "param_type": "{‘left’, ‘right’, ‘both’}, default ‘left’", "param_desc": "Side from which to fill resulting string.\n"}, {"param_name": "fillchar", "param_type": "str, default ‘ ‘", "param_desc": "Additional character for filling, default is whitespace.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.pad.html#pandas.Series.str.pad"}, {"function_name": "pandas.Series.str.removeprefix", "full_function": "Series.str.removeprefix(prefix)", "function_text": "Remove a prefix from an object series.", "parameter_names_desc": [{"param_name": "prefix", "param_type": "str", "param_desc": "Remove the prefix of the string.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.removeprefix.html#pandas.Series.str.removeprefix"}, {"function_name": "pandas.Series.str.repeat", "full_function": "Series.str.repeat(repeats)", "function_text": "Duplicate each string in the Series or Index.", "parameter_names_desc": [{"param_name": "repeats", "param_type": "int or sequence of int", "param_desc": "Same value for all (int) or different value per (sequence).\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.repeat.html#pandas.Series.str.repeat"}, {"function_name": "pandas.Series.str.rfind", "full_function": "Series.str.rfind(sub, start=0, end=None)", "function_text": "Return highest indexes in each strings in the Series/Index.", "parameter_names_desc": [{"param_name": "sub", "param_type": "str", "param_desc": "Substring being searched.\n"}, {"param_name": "start", "param_type": "int", "param_desc": "Left edge index.\n"}, {"param_name": "end", "param_type": "int", "param_desc": "Right edge index.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rfind.html#pandas.Series.str.rfind"}, {"function_name": "pandas.Series.str.rjust", "full_function": "Series.str.rjust(width, fillchar=' ')", "function_text": "Pad left side of strings in the Series/Index.", "parameter_names_desc": [{"param_name": "width", "param_type": "int", "param_desc": "Minimum width of resulting string; additional characters will be filled\nwith fillchar.\n"}, {"param_name": "fillchar", "param_type": "str", "param_desc": "Additional character for filling, default is whitespace.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rjust.html#pandas.Series.str.rjust"}, {"function_name": "pandas.Series.str.rstrip", "full_function": "Series.str.rstrip(to_strip=None)", "function_text": "Remove trailing characters.", "parameter_names_desc": [{"param_name": "to_strip", "param_type": "str or None, default None", "param_desc": "Specifying the set of characters to be removed.\nAll combinations of this set of characters will be stripped.\nIf None then whitespaces are removed.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rstrip.html#pandas.Series.str.rstrip"}, {"function_name": "pandas.Series.str.slice_replace", "full_function": "Series.str.slice_replace(start=None, stop=None, repl=None)", "function_text": "Replace a positional slice of a string with another value.", "parameter_names_desc": [{"param_name": "start", "param_type": "int, optional", "param_desc": "Left index position to use for the slice. If not specified (None),\nthe slice is unbounded on the left, i.e. slice from the start\nof the string.\n"}, {"param_name": "stop", "param_type": "int, optional", "param_desc": "Right index position to use for the slice. If not specified (None),\nthe slice is unbounded on the right, i.e. slice until the\nend of the string.\n"}, {"param_name": "repl", "param_type": "str, optional", "param_desc": "String for replacement. If not specified (None), the sliced region\nis replaced with an empty string.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.slice_replace.html#pandas.Series.str.slice_replace"}, {"function_name": "pandas.Series.str.rsplit", "full_function": "Series.str.rsplit(pat=None, *, n=-1, expand=False)", "function_text": "Split strings around given separator/delimiter.", "parameter_names_desc": [{"param_name": "pat", "param_type": "str, optional", "param_desc": "String to split on.\nIf not specified, split on whitespace.\n"}, {"param_name": "n", "param_type": "int, default -1 (all)", "param_desc": "Limit number of splits in output.\nNone, 0 and -1 will be interpreted as return all splits.\n"}, {"param_name": "expand", "param_type": "bool, default False", "param_desc": "Expand the split strings into separate columns.\n\nIf True, return DataFrame/MultiIndex expanding dimensionality.\nIf False, return Series/Index, containing lists of strings.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rsplit.html#pandas.Series.str.rsplit"}, {"function_name": "pandas.Series.str.strip", "full_function": "Series.str.strip(to_strip=None)", "function_text": "Remove leading and trailing characters.", "parameter_names_desc": [{"param_name": "to_strip", "param_type": "str or None, default None", "param_desc": "Specifying the set of characters to be removed.\nAll combinations of this set of characters will be stripped.\nIf None then whitespaces are removed.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.strip.html#pandas.Series.str.strip"}, {"function_name": "pandas.Series.str.title", "full_function": "Series.str.title()", "function_text": "Convert strings in the Series/Index to titlecase.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.title.html#pandas.Series.str.title"}, {"function_name": "pandas.Series.str.upper", "full_function": "Series.str.upper()", "function_text": "Convert strings in the Series/Index to uppercase.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.upper.html#pandas.Series.str.upper"}, {"function_name": "pandas.Series.str.zfill", "full_function": "Series.str.zfill(width)", "function_text": "Pad strings in the Series/Index by prepending ‘0’ characters.", "parameter_names_desc": [{"param_name": "width", "param_type": "int", "param_desc": "Minimum length of resulting string; strings with length less\nthan width be prepended with ‘0’ characters.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.zfill.html#pandas.Series.str.zfill"}, {"function_name": "pandas.Series.str.isalpha", "full_function": "Series.str.isalpha()", "function_text": "Check whether all characters in each string are alphabetic.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalpha.html#pandas.Series.str.isalpha"}, {"function_name": "pandas.Series.str.isspace", "full_function": "Series.str.isspace()", "function_text": "Check whether all characters in each string are whitespace.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isspace.html#pandas.Series.str.isspace"}, {"function_name": "pandas.Series.str.isupper", "full_function": "Series.str.isupper()", "function_text": "Check whether all characters in each string are uppercase.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isupper.html#pandas.Series.str.isupper"}, {"function_name": "pandas.Series.str.isnumeric", "full_function": "Series.str.isnumeric()", "function_text": "Check whether all characters in each string are numeric.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isnumeric.html#pandas.Series.str.isnumeric"}, {"function_name": "pandas.Series.str.get_dummies", "full_function": "Series.str.get_dummies(sep='|')", "function_text": "Return DataFrame of dummy/indicator variables for Series.", "parameter_names_desc": [{"param_name": "sep", "param_type": "str, default “|”", "param_desc": "String to split on.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.str.get_dummies.html#pandas.Series.str.get_dummies"}, {"function_name": "pandas.Series.cat.ordered", "full_function": "Series.cat.ordered", "function_text": "Whether the categories have an ordered relationship.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.ordered.html#pandas.Series.cat.ordered"}, {"function_name": "pandas.Series.cat.reorder_categories", "full_function": "Series.cat.reorder_categories(*args, **kwargs)", "function_text": "Reorder categories as specified in new_categories.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.reorder_categories.html#pandas.Series.cat.reorder_categories"}, {"function_name": "pandas.Series.cat.remove_categories", "full_function": "Series.cat.remove_categories(*args, **kwargs)", "function_text": "Remove the specified categories.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_categories.html#pandas.Series.cat.remove_categories"}, {"function_name": "pandas.Series.cat.set_categories", "full_function": "Series.cat.set_categories(*args, **kwargs)", "function_text": "Set the categories to the specified new categories.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.set_categories.html#pandas.Series.cat.set_categories"}, {"function_name": "pandas.Series.cat.as_unordered", "full_function": "Series.cat.as_unordered(*args, **kwargs)", "function_text": "Set the Categorical to be unordered.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.as_unordered.html#pandas.Series.cat.as_unordered"}, {"function_name": "pandas.Series.sparse.density", "full_function": "Series.sparse.density", "function_text": "The percent of non- fill_value points, as decimal.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.density.html#pandas.Series.sparse.density"}, {"function_name": "pandas.Series.sparse.sp_values", "full_function": "Series.sparse.sp_values", "function_text": "An ndarray containing the non- fill_value values.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.sp_values.html#pandas.Series.sparse.sp_values"}, {"function_name": "pandas.Series.sparse.to_coo", "full_function": "Series.sparse.to_coo(row_levels=(0,), column_levels=(1,), sort_labels=False)", "function_text": "Create a scipy.sparse.coo_matrix from a Series with MultiIndex.", "parameter_names_desc": [{"param_name": "row_levels", "param_type": "tuple/list", "param_desc": ""}, {"param_name": "column_levels", "param_type": "tuple/list", "param_desc": ""}, {"param_name": "sort_labels", "param_type": "bool, default False", "param_desc": "Sort the row and column labels before forming the sparse matrix.\nWhen row_levels and/or column_levels refer to a single level,\nset to True for a faster execution.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.to_coo.html#pandas.Series.sparse.to_coo"}, {"function_name": "pandas.Series.list.len", "full_function": "Series.list.len()", "function_text": "Return the length of each list in the Series.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.list.len.html#pandas.Series.list.len"}, {"function_name": "pandas.Series.struct.explode", "full_function": "Series.struct.explode()", "function_text": "Extract all child fields of a struct as a DataFrame.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.struct.explode.html#pandas.Series.struct.explode"}]}, {"name": "Plotting", "url": "https://pandas.pydata.org/docs/reference/series.html#plotting", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.html#pandas.Series.plot", "https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.area.html#pandas.Series.plot.area", "https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.barh.html#pandas.Series.plot.barh", "https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.density.html#pandas.Series.plot.density", "https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.kde.html#pandas.Series.plot.kde", "https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.pie.html#pandas.Series.plot.pie", "https://pandas.pydata.org/docs/reference/api/pandas.Series.hist.html#pandas.Series.hist", "https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.bar.html#pandas.Series.plot.bar", "https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.box.html#pandas.Series.plot.box", "https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.hist.html#pandas.Series.plot.hist", "https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.line.html#pandas.Series.plot.line"], "function_definitions": [{"function_name": "pandas.Series.plot", "full_function": "Series.plot(*args, **kwargs)", "function_text": "Make plots of Series or DataFrame.", "parameter_names_desc": [{"param_name": "data", "param_type": "Series or DataFrame", "param_desc": "The object for which the method is called.\n"}, {"param_name": "x", "param_type": "label or position, default None", "param_desc": "Only used if data is a DataFrame.\n"}, {"param_name": "y", "param_type": "label, position or list of label, positions, default None", "param_desc": "Allows plotting of one column versus another. Only used if data is a\nDataFrame.\n"}, {"param_name": "kind", "param_type": "str", "param_desc": "The kind of plot to produce:\n\n‘line’ : line plot (default)\n‘bar’ : vertical bar plot\n‘barh’ : horizontal bar plot\n‘hist’ : histogram\n‘box’ : boxplot\n‘kde’ : Kernel Density Estimation plot\n‘density’ : same as ‘kde’\n‘area’ : area plot\n‘pie’ : pie plot\n‘scatter’ : scatter plot (DataFrame only)\n‘hexbin’ : hexbin plot (DataFrame only)\n\n"}, {"param_name": "ax", "param_type": "matplotlib axes object, default None", "param_desc": "An axes of the current figure.\n"}, {"param_name": "subplots", "param_type": "bool or sequence of iterables, default False", "param_desc": "Whether to group columns into subplots:\n\nFalse : No subplots will be used\nTrue : Make separate subplots for each column.\nsequence of iterables of column labels: Create a subplot for each\ngroup of columns. For example [(‘a’, ‘c’), (‘b’, ‘d’)] will\ncreate 2 subplots: one with columns ‘a’ and ‘c’, and one\nwith columns ‘b’ and ‘d’. Remaining columns that aren’t specified\nwill be plotted in additional subplots (one per column).\n\nNew in version 1.5.0.\n\n\n\n"}, {"param_name": "sharex", "param_type": "bool, default True if ax is None else False", "param_desc": "In case subplots=True, share x axis and set some x axis labels\nto invisible; defaults to True if ax is None otherwise False if\nan ax is passed in; Be aware, that passing in both an ax and\nsharex=True will alter all x axis labels for all axis in a figure.\n"}, {"param_name": "sharey", "param_type": "bool, default False", "param_desc": "In case subplots=True, share y axis and set some y axis labels to invisible.\n"}, {"param_name": "layout", "param_type": "tuple, optional", "param_desc": "(rows, columns) for the layout of subplots.\n"}, {"param_name": "figsize", "param_type": "a tuple (width, height) in inches", "param_desc": "Size of a figure object.\n"}, {"param_name": "use_index", "param_type": "bool, default True", "param_desc": "Use index as ticks for x axis.\n"}, {"param_name": "title", "param_type": "str or list", "param_desc": "Title to use for the plot. If a string is passed, print the string\nat the top of the figure. If a list is passed and subplots is\nTrue, print each item in the list above the corresponding subplot.\n"}, {"param_name": "grid", "param_type": "bool, default None (matlab style default)", "param_desc": "Axis grid lines.\n"}, {"param_name": "legend", "param_type": "bool or {‘reverse’}", "param_desc": "Place legend on axis subplots.\n"}, {"param_name": "style", "param_type": "list or dict", "param_desc": "The matplotlib line style per column.\n"}, {"param_name": "logx", "param_type": "bool or ‘sym’, default False", "param_desc": "Use log scaling or symlog scaling on x axis.\n"}, {"param_name": "logy", "param_type": "bool or ‘sym’ default False", "param_desc": "Use log scaling or symlog scaling on y axis.\n"}, {"param_name": "loglog", "param_type": "bool or ‘sym’, default False", "param_desc": "Use log scaling or symlog scaling on both x and y axes.\n"}, {"param_name": "xticks", "param_type": "sequence", "param_desc": "Values to use for the xticks.\n"}, {"param_name": "yticks", "param_type": "sequence", "param_desc": "Values to use for the yticks.\n"}, {"param_name": "xlim", "param_type": "2-tuple/list", "param_desc": "Set the x limits of the current axes.\n"}, {"param_name": "ylim", "param_type": "2-tuple/list", "param_desc": "Set the y limits of the current axes.\n"}, {"param_name": "xlabel", "param_type": "label, optional", "param_desc": "Name to use for the xlabel on x-axis. Default uses index name as xlabel, or the\nx-column name for planar plots.\n\nChanged in version 2.0.0: Now applicable to histograms.\n\n"}, {"param_name": "ylabel", "param_type": "label, optional", "param_desc": "Name to use for the ylabel on y-axis. Default will show no ylabel, or the\ny-column name for planar plots.\n\nChanged in version 2.0.0: Now applicable to histograms.\n\n"}, {"param_name": "rot", "param_type": "float, default None", "param_desc": "Rotation for ticks (xticks for vertical, yticks for horizontal\nplots).\n"}, {"param_name": "fontsize", "param_type": "float, default None", "param_desc": "Font size for xticks and yticks.\n"}, {"param_name": "colormap", "param_type": "str or matplotlib colormap object, default None", "param_desc": "Colormap to select colors from. If string, load colormap with that\nname from matplotlib.\n"}, {"param_name": "colorbar", "param_type": "bool, optional", "param_desc": "If True, plot colorbar (only relevant for ‘scatter’ and ‘hexbin’\nplots).\n"}, {"param_name": "position", "param_type": "float", "param_desc": "Specify relative alignments for bar plot layout.\nFrom 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\n(center).\n"}, {"param_name": "table", "param_type": "bool, Series or DataFrame, default False", "param_desc": "If True, draw a table using the data in the DataFrame and the data\nwill be transposed to meet matplotlib’s default layout.\nIf a Series or DataFrame is passed, use passed data to draw a\ntable.\n"}, {"param_name": "yerr", "param_type": "DataFrame, Series, array-like, dict and str", "param_desc": "See Plotting with Error Bars for\ndetail.\n"}, {"param_name": "xerr", "param_type": "DataFrame, Series, array-like, dict and str", "param_desc": "Equivalent to yerr.\n"}, {"param_name": "stacked", "param_type": "bool, default False in line and bar plots, and True in area plot", "param_desc": "If True, create stacked plot.\n"}, {"param_name": "secondary_y", "param_type": "bool or sequence, default False", "param_desc": "Whether to plot on the secondary y-axis if a list/tuple, which\ncolumns to plot on secondary y-axis.\n"}, {"param_name": "mark_right", "param_type": "bool, default True", "param_desc": "When using a secondary_y axis, automatically mark the column\nlabels with “(right)” in the legend.\n"}, {"param_name": "include_bool", "param_type": "bool, default is False", "param_desc": "If True, boolean values can be plotted.\n"}, {"param_name": "backend", "param_type": "str, default None", "param_desc": "Backend to use instead of the backend specified in the option\nplotting.backend. For instance, ‘matplotlib’. Alternatively, to\nspecify the plotting.backend for the whole session, set\npd.options.plotting.backend.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.html#pandas.Series.plot"}, {"function_name": "pandas.Series.plot.area", "full_function": "Series.plot.area(x=None, y=None, stacked=True, **kwargs)", "function_text": "Draw a stacked area plot.", "parameter_names_desc": [{"param_name": "x", "param_type": "label or position, optional", "param_desc": "Coordinates for the X axis. By default uses the index.\n"}, {"param_name": "y", "param_type": "label or position, optional", "param_desc": "Column to plot. By default uses all columns.\n"}, {"param_name": "stacked", "param_type": "bool, default True", "param_desc": "Area plots are stacked by default. Set to False to create a\nunstacked plot.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.area.html#pandas.Series.plot.area"}, {"function_name": "pandas.Series.plot.barh", "full_function": "Series.plot.barh(x=None, y=None, **kwargs)", "function_text": "Make a horizontal bar plot.", "parameter_names_desc": [{"param_name": "x", "param_type": "label or position, optional", "param_desc": "Allows plotting of one column versus another. If not specified,\nthe index of the DataFrame is used.\n"}, {"param_name": "y", "param_type": "label or position, optional", "param_desc": "Allows plotting of one column versus another. If not specified,\nall numerical columns are used.\n"}, {"param_name": "color", "param_type": "str, array-like, or dict, optional", "param_desc": "The color for each of the DataFrame’s columns. Possible values are:\n\n\nA single color string referred to by name, RGB or RGBA code,for instance ‘red’ or ‘#a98d19’.\n\n\n\n\nA sequence of color strings referred to by name, RGB or RGBAcode, which will be used for each column recursively. For\ninstance [‘green’,’yellow’] each column’s bar will be filled in\ngreen or yellow, alternatively. If there is only a single column to\nbe plotted, then only the first color from the color list will be\nused.\n\n\n\n\nA dict of the form {column namecolor}, so that each column will becolored accordingly. For example, if your columns are called a and\nb, then passing {‘a’: ‘green’, ‘b’: ‘red’} will color bars for\ncolumn a in green and bars for column b in red.\n\n\n\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.barh.html#pandas.Series.plot.barh"}, {"function_name": "pandas.Series.plot.density", "full_function": "Series.plot.density(bw_method=None, ind=None, **kwargs)", "function_text": "Generate Kernel Density Estimate plot using Gaussian kernels.", "parameter_names_desc": [{"param_name": "bw_method", "param_type": "str, scalar or callable, optional", "param_desc": "The method used to calculate the estimator bandwidth. This can be\n‘scott’, ‘silverman’, a scalar constant or a callable.\nIf None (default), ‘scott’ is used.\nSee scipy.stats.gaussian_kde for more information.\n"}, {"param_name": "ind", "param_type": "NumPy array or int, optional", "param_desc": "Evaluation points for the estimated PDF. If None (default),\n1000 equally spaced points are used. If ind is a NumPy array, the\nKDE is evaluated at the points passed. If ind is an integer,\nind number of equally spaced points are used.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.density.html#pandas.Series.plot.density"}, {"function_name": "pandas.Series.plot.kde", "full_function": "Series.plot.kde(bw_method=None, ind=None, **kwargs)", "function_text": "Generate Kernel Density Estimate plot using Gaussian kernels.", "parameter_names_desc": [{"param_name": "bw_method", "param_type": "str, scalar or callable, optional", "param_desc": "The method used to calculate the estimator bandwidth. This can be\n‘scott’, ‘silverman’, a scalar constant or a callable.\nIf None (default), ‘scott’ is used.\nSee scipy.stats.gaussian_kde for more information.\n"}, {"param_name": "ind", "param_type": "NumPy array or int, optional", "param_desc": "Evaluation points for the estimated PDF. If None (default),\n1000 equally spaced points are used. If ind is a NumPy array, the\nKDE is evaluated at the points passed. If ind is an integer,\nind number of equally spaced points are used.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.kde.html#pandas.Series.plot.kde"}, {"function_name": "pandas.Series.plot.pie", "full_function": "Series.plot.pie(**kwargs)", "function_text": "Generate a pie plot.", "parameter_names_desc": [{"param_name": "y", "param_type": "int or label, optional", "param_desc": "Label or position of the column to plot.\nIf not provided, subplots=True argument must be passed.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.pie.html#pandas.Series.plot.pie"}, {"function_name": "pandas.Series.hist", "full_function": "Series.hist(by=None, ax=None, grid=True, xlabelsize=None, xrot=None, ylabelsize=None, yrot=None, figsize=None, bins=10, backend=None, legend=False, **kwargs)", "function_text": "Draw histogram of the input series using matplotlib.", "parameter_names_desc": [{"param_name": "by", "param_type": "object, optional", "param_desc": "If passed, then used to form histograms for separate groups.\n"}, {"param_name": "ax", "param_type": "matplotlib axis object", "param_desc": "If not passed, uses gca().\n"}, {"param_name": "grid", "param_type": "bool, default True", "param_desc": "Whether to show axis grid lines.\n"}, {"param_name": "xlabelsize", "param_type": "int, default None", "param_desc": "If specified changes the x-axis label size.\n"}, {"param_name": "xrot", "param_type": "float, default None", "param_desc": "Rotation of x axis labels.\n"}, {"param_name": "ylabelsize", "param_type": "int, default None", "param_desc": "If specified changes the y-axis label size.\n"}, {"param_name": "yrot", "param_type": "float, default None", "param_desc": "Rotation of y axis labels.\n"}, {"param_name": "figsize", "param_type": "tuple, default None", "param_desc": "Figure size in inches by default.\n"}, {"param_name": "bins", "param_type": "int or sequence, default 10", "param_desc": "Number of histogram bins to be used. If an integer is given, bins + 1\nbin edges are calculated and returned. If bins is a sequence, gives\nbin edges, including left edge of first bin and right edge of last\nbin. In this case, bins is returned unmodified.\n"}, {"param_name": "backend", "param_type": "str, default None", "param_desc": "Backend to use instead of the backend specified in the option\nplotting.backend. For instance, ‘matplotlib’. Alternatively, to\nspecify the plotting.backend for the whole session, set\npd.options.plotting.backend.\n"}, {"param_name": "legend", "param_type": "bool, default False", "param_desc": "Whether to show the legend.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.hist.html#pandas.Series.hist"}, {"function_name": "pandas.Series.plot.bar", "full_function": "Series.plot.bar(x=None, y=None, **kwargs)", "function_text": "Vertical bar plot.", "parameter_names_desc": [{"param_name": "x", "param_type": "label or position, optional", "param_desc": "Allows plotting of one column versus another. If not specified,\nthe index of the DataFrame is used.\n"}, {"param_name": "y", "param_type": "label or position, optional", "param_desc": "Allows plotting of one column versus another. If not specified,\nall numerical columns are used.\n"}, {"param_name": "color", "param_type": "str, array-like, or dict, optional", "param_desc": "The color for each of the DataFrame’s columns. Possible values are:\n\n\nA single color string referred to by name, RGB or RGBA code,for instance ‘red’ or ‘#a98d19’.\n\n\n\n\nA sequence of color strings referred to by name, RGB or RGBAcode, which will be used for each column recursively. For\ninstance [‘green’,’yellow’] each column’s bar will be filled in\ngreen or yellow, alternatively. If there is only a single column to\nbe plotted, then only the first color from the color list will be\nused.\n\n\n\n\nA dict of the form {column namecolor}, so that each column will becolored accordingly. For example, if your columns are called a and\nb, then passing {‘a’: ‘green’, ‘b’: ‘red’} will color bars for\ncolumn a in green and bars for column b in red.\n\n\n\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.bar.html#pandas.Series.plot.bar"}, {"function_name": "pandas.Series.plot.box", "full_function": "Series.plot.box(by=None, **kwargs)", "function_text": "Make a box plot of the DataFrame columns.", "parameter_names_desc": [{"param_name": "by", "param_type": "str or sequence", "param_desc": "Column in the DataFrame to group by.\n\nChanged in version 1.4.0: Previously, by is silently ignore and makes no groupings\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.box.html#pandas.Series.plot.box"}, {"function_name": "pandas.Series.plot.hist", "full_function": "Series.plot.hist(by=None, bins=10, **kwargs)", "function_text": "Draw one histogram of the DataFrame’s columns.", "parameter_names_desc": [{"param_name": "by", "param_type": "str or sequence, optional", "param_desc": "Column in the DataFrame to group by.\n\nChanged in version 1.4.0: Previously, by is silently ignore and makes no groupings\n\n"}, {"param_name": "bins", "param_type": "int, default 10", "param_desc": "Number of histogram bins to be used.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.hist.html#pandas.Series.plot.hist"}, {"function_name": "pandas.Series.plot.line", "full_function": "Series.plot.line(x=None, y=None, **kwargs)", "function_text": "Plot Series or DataFrame as lines.", "parameter_names_desc": [{"param_name": "x", "param_type": "label or position, optional", "param_desc": "Allows plotting of one column versus another. If not specified,\nthe index of the DataFrame is used.\n"}, {"param_name": "y", "param_type": "label or position, optional", "param_desc": "Allows plotting of one column versus another. If not specified,\nall numerical columns are used.\n"}, {"param_name": "color", "param_type": "str, array-like, or dict, optional", "param_desc": "The color for each of the DataFrame’s columns. Possible values are:\n\n\nA single color string referred to by name, RGB or RGBA code,for instance ‘red’ or ‘#a98d19’.\n\n\n\n\nA sequence of color strings referred to by name, RGB or RGBAcode, which will be used for each column recursively. For\ninstance [‘green’,’yellow’] each column’s line will be filled in\ngreen or yellow, alternatively. If there is only a single column to\nbe plotted, then only the first color from the color list will be\nused.\n\n\n\n\nA dict of the form {column namecolor}, so that each column will becolored accordingly. For example, if your columns are called a and\nb, then passing {‘a’: ‘green’, ‘b’: ‘red’} will color lines for\ncolumn a in green and lines for column b in red.\n\n\n\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.line.html#pandas.Series.plot.line"}]}, {"name": "Serialization / IO / conversion", "url": "https://pandas.pydata.org/docs/reference/series.html#serialization-io-conversion", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.to_pickle.html#pandas.Series.to_pickle", "https://pandas.pydata.org/docs/reference/api/pandas.Series.to_dict.html#pandas.Series.to_dict", "https://pandas.pydata.org/docs/reference/api/pandas.Series.to_frame.html#pandas.Series.to_frame", "https://pandas.pydata.org/docs/reference/api/pandas.Series.to_hdf.html#pandas.Series.to_hdf", "https://pandas.pydata.org/docs/reference/api/pandas.Series.to_json.html#pandas.Series.to_json", "https://pandas.pydata.org/docs/reference/api/pandas.Series.to_clipboard.html#pandas.Series.to_clipboard", "https://pandas.pydata.org/docs/reference/api/pandas.Series.to_markdown.html#pandas.Series.to_markdown", "https://pandas.pydata.org/docs/reference/api/pandas.Series.to_csv.html#pandas.Series.to_csv", "https://pandas.pydata.org/docs/reference/api/pandas.Series.to_excel.html#pandas.Series.to_excel", "https://pandas.pydata.org/docs/reference/api/pandas.Series.to_xarray.html#pandas.Series.to_xarray", "https://pandas.pydata.org/docs/reference/api/pandas.Series.to_sql.html#pandas.Series.to_sql", "https://pandas.pydata.org/docs/reference/api/pandas.Series.to_string.html#pandas.Series.to_string", "https://pandas.pydata.org/docs/reference/api/pandas.Series.to_latex.html#pandas.Series.to_latex"], "function_definitions": [{"function_name": "pandas.Series.to_pickle", "full_function": "Series.to_pickle(path, *, compression='infer', protocol=5, storage_options=None)", "function_text": "Pickle (serialize) object to file.", "parameter_names_desc": [{"param_name": "path", "param_type": "str, path object, or file-like object", "param_desc": "String, path object (implementing os.PathLike[str]), or file-like\nobject implementing a binary write() function. File path where\nthe pickled object will be stored.\n"}, {"param_name": "compression", "param_type": "str or dict, default ‘infer’", "param_desc": "For on-the-fly compression of the output data. If ‘infer’ and ‘path’ is\npath-like, then detect compression from the following extensions: ‘.gz’,\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\n(otherwise no compression).\nSet to None for no compression.\nCan also be a dict with key 'method' set\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\nother key-value pairs are forwarded to\nzipfile.ZipFile, gzip.GzipFile,\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\ntarfile.TarFile, respectively.\nAs an example, the following could be passed for faster compression and to create\na reproducible gzip archive:\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\n\nNew in version 1.5.0: Added support for .tar files.\n\n"}, {"param_name": "protocol", "param_type": "int", "param_desc": "Int which indicates which protocol should be used by the pickler,\ndefault HIGHEST_PROTOCOL (see [1] paragraph 12.1.2). The possible\nvalues are 0, 1, 2, 3, 4, 5. A negative value for the protocol\nparameter is equivalent to setting its value to HIGHEST_PROTOCOL.\n\n\n[1]\nhttps://docs.python.org/3/library/pickle.html.\n\n\n"}, {"param_name": "storage_options", "param_type": "dict, optional", "param_desc": "Extra options that make sense for a particular storage connection, e.g.\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\nare forwarded to urllib.request.Request as header options. For other\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\nforwarded to fsspec.open. Please see fsspec and urllib for more\ndetails, and for more examples on storage options refer here.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.to_pickle.html#pandas.Series.to_pickle"}, {"function_name": "pandas.Series.to_dict", "full_function": "Series.to_dict(*, into=<class 'dict'>)", "function_text": "Convert Series to {label -> value} dict or dict-like object.", "parameter_names_desc": [{"param_name": "into", "param_type": "class, default dict", "param_desc": "The collections.abc.MutableMapping subclass to use as the return\nobject. Can be the actual class or an empty instance of the mapping\ntype you want. If you want a collections.defaultdict, you must\npass it initialized.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.to_dict.html#pandas.Series.to_dict"}, {"function_name": "pandas.Series.to_frame", "full_function": "Series.to_frame(name=_NoDefault.no_default)", "function_text": "Convert Series to DataFrame.", "parameter_names_desc": [{"param_name": "name", "param_type": "object, optional", "param_desc": "The passed name should substitute for the series name (if it has\none).\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.to_frame.html#pandas.Series.to_frame"}, {"function_name": "pandas.Series.to_hdf", "full_function": "Series.to_hdf(path_or_buf, *, key, mode='a', complevel=None, complib=None, append=False, format=None, index=True, min_itemsize=None, nan_rep=None, dropna=None, data_columns=None, errors='strict', encoding='UTF-8')", "function_text": "Write the contained data to an HDF5 file using HDFStore.", "parameter_names_desc": [{"param_name": "path_or_buf", "param_type": "str or pandas.HDFStore", "param_desc": "File path or HDFStore object.\n"}, {"param_name": "key", "param_type": "str", "param_desc": "Identifier for the group in the store.\n"}, {"param_name": "mode", "param_type": "{‘a’, ‘w’, ‘r+’}, default ‘a’", "param_desc": "Mode to open file:\n\n‘w’: write, a new file is created (an existing file with\nthe same name would be deleted).\n‘a’: append, an existing file is opened for reading and\nwriting, and if the file does not exist it is created.\n‘r+’: similar to ‘a’, but the file must already exist.\n\n"}, {"param_name": "complevel", "param_type": "{0-9}, default None", "param_desc": "Specifies a compression level for data.\nA value of 0 or None disables compression.\n"}, {"param_name": "complib", "param_type": "{‘zlib’, ‘lzo’, ‘bzip2’, ‘blosc’}, default ‘zlib’", "param_desc": "Specifies the compression library to be used.\nThese additional compressors for Blosc are supported\n(default if no compressor specified: ‘blosc:blosclz’):\n{‘blosc:blosclz’, ‘blosc:lz4’, ‘blosc:lz4hc’, ‘blosc:snappy’,\n‘blosc:zlib’, ‘blosc:zstd’}.\nSpecifying a compression library which is not available issues\na ValueError.\n"}, {"param_name": "append", "param_type": "bool, default False", "param_desc": "For Table formats, append the input data to the existing.\n"}, {"param_name": "format", "param_type": "{‘fixed’, ‘table’, None}, default ‘fixed’", "param_desc": "Possible values:\n\n‘fixed’: Fixed format. Fast writing/reading. Not-appendable,\nnor searchable.\n‘table’: Table format. Write as a PyTables Table structure\nwhich may perform worse but allow more flexible operations\nlike searching / selecting subsets of the data.\nIf None, pd.get_option(‘io.hdf.default_format’) is checked,\nfollowed by fallback to “fixed”.\n\n"}, {"param_name": "index", "param_type": "bool, default True", "param_desc": "Write DataFrame index as a column.\n"}, {"param_name": "min_itemsize", "param_type": "dict or int, optional", "param_desc": "Map column names to minimum string sizes for columns.\n"}, {"param_name": "nan_rep", "param_type": "Any, optional", "param_desc": "How to represent null values as str.\nNot allowed with append=True.\n"}, {"param_name": "dropna", "param_type": "bool, default False, optional", "param_desc": "Remove missing values.\n"}, {"param_name": "data_columns", "param_type": "list of columns or True, optional", "param_desc": "List of columns to create as indexed data columns for on-disk\nqueries, or True to use all columns. By default only the axes\nof the object are indexed. See\nQuery via data columns. for\nmore information.\nApplicable only to format=’table’.\n"}, {"param_name": "errors", "param_type": "str, default ‘strict’", "param_desc": "Specifies how encoding and decoding errors are to be handled.\nSee the errors argument for open() for a full list\nof options.\n"}, {"param_name": "encoding", "param_type": "str, default “UTF-8”", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.to_hdf.html#pandas.Series.to_hdf"}, {"function_name": "pandas.Series.to_json", "full_function": "Series.to_json(path_or_buf=None, *, orient=None, date_format=None, double_precision=10, force_ascii=True, date_unit='ms', default_handler=None, lines=False, compression='infer', index=None, indent=None, storage_options=None, mode='w')", "function_text": "Convert the object to a JSON string.", "parameter_names_desc": [{"param_name": "path_or_buf", "param_type": "str, path object, file-like object, or None, default None", "param_desc": "String, path object (implementing os.PathLike[str]), or file-like\nobject implementing a write() function. If None, the result is\nreturned as a string.\n"}, {"param_name": "orient", "param_type": "str", "param_desc": "Indication of expected JSON string format.\n\nSeries:\n\n\ndefault is ‘index’\nallowed values are: {‘split’, ‘records’, ‘index’, ‘table’}.\n\n\n\nDataFrame:\n\n\ndefault is ‘columns’\nallowed values are: {‘split’, ‘records’, ‘index’, ‘columns’,\n‘values’, ‘table’}.\n\n\n\nThe format of the JSON string:\n\n\n‘split’ : dict like {‘index’ -> [index], ‘columns’ -> [columns],\n‘data’ -> [values]}\n‘records’ : list like [{column -> value}, … , {column -> value}]\n‘index’ : dict like {index -> {column -> value}}\n‘columns’ : dict like {column -> {index -> value}}\n‘values’ : just the values array\n‘table’ : dict like {‘schema’: {schema}, ‘data’: {data}}\n\nDescribing the data, where data component is like orient='records'.\n\n\n\n"}, {"param_name": "date_format", "param_type": "{None, ‘epoch’, ‘iso’}", "param_desc": "Type of date conversion. ‘epoch’ = epoch milliseconds,\n‘iso’ = ISO8601. The default depends on the orient. For\norient='table', the default is ‘iso’. For all other orients,\nthe default is ‘epoch’.\n"}, {"param_name": "double_precision", "param_type": "int, default 10", "param_desc": "The number of decimal places to use when encoding\nfloating point values. The possible maximal value is 15.\nPassing double_precision greater than 15 will raise a ValueError.\n"}, {"param_name": "force_ascii", "param_type": "bool, default True", "param_desc": "Force encoded string to be ASCII.\n"}, {"param_name": "date_unit", "param_type": "str, default ‘ms’ (milliseconds)", "param_desc": "The time unit to encode to, governs timestamp and ISO8601\nprecision. One of ‘s’, ‘ms’, ‘us’, ‘ns’ for second, millisecond,\nmicrosecond, and nanosecond respectively.\n"}, {"param_name": "default_handler", "param_type": "callable, default None", "param_desc": "Handler to call if object cannot otherwise be converted to a\nsuitable format for JSON. Should receive a single argument which is\nthe object to convert and return a serialisable object.\n"}, {"param_name": "lines", "param_type": "bool, default False", "param_desc": "If ‘orient’ is ‘records’ write out line-delimited json format. Will\nthrow ValueError if incorrect ‘orient’ since others are not\nlist-like.\n"}, {"param_name": "compression", "param_type": "str or dict, default ‘infer’", "param_desc": "For on-the-fly compression of the output data. If ‘infer’ and ‘path_or_buf’ is\npath-like, then detect compression from the following extensions: ‘.gz’,\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\n(otherwise no compression).\nSet to None for no compression.\nCan also be a dict with key 'method' set\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\nother key-value pairs are forwarded to\nzipfile.ZipFile, gzip.GzipFile,\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\ntarfile.TarFile, respectively.\nAs an example, the following could be passed for faster compression and to create\na reproducible gzip archive:\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\n\nNew in version 1.5.0: Added support for .tar files.\n\n\nChanged in version 1.4.0: Zstandard support.\n\n"}, {"param_name": "index", "param_type": "bool or None, default None", "param_desc": "The index is only used when ‘orient’ is ‘split’, ‘index’, ‘column’,\nor ‘table’. Of these, ‘index’ and ‘column’ do not support\nindex=False.\n"}, {"param_name": "indent", "param_type": "int, optional", "param_desc": "Length of whitespace used to indent each record.\n"}, {"param_name": "storage_options", "param_type": "dict, optional", "param_desc": "Extra options that make sense for a particular storage connection, e.g.\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\nare forwarded to urllib.request.Request as header options. For other\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\nforwarded to fsspec.open. Please see fsspec and urllib for more\ndetails, and for more examples on storage options refer here.\n"}, {"param_name": "mode", "param_type": "str, default ‘w’ (writing)", "param_desc": "Specify the IO mode for output when supplying a path_or_buf.\nAccepted args are ‘w’ (writing) and ‘a’ (append) only.\nmode=’a’ is only supported when lines is True and orient is ‘records’.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.to_json.html#pandas.Series.to_json"}, {"function_name": "pandas.Series.to_clipboard", "full_function": "Series.to_clipboard(*, excel=True, sep=None, **kwargs)", "function_text": "Copy object to the system clipboard.", "parameter_names_desc": [{"param_name": "excel", "param_type": "bool, default True", "param_desc": "Produce output in a csv format for easy pasting into excel.\n\nTrue, use the provided separator for csv pasting.\nFalse, write a string representation of the object to the clipboard.\n\n"}, {"param_name": "sep", "param_type": "str, default '\\t'", "param_desc": "Field delimiter.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.to_clipboard.html#pandas.Series.to_clipboard"}, {"function_name": "pandas.Series.to_markdown", "full_function": "Series.to_markdown(buf=None, mode='wt', index=True, storage_options=None, **kwargs)", "function_text": "Print Series in Markdown-friendly format.", "parameter_names_desc": [{"param_name": "buf", "param_type": "str, Path or StringIO-like, optional, default None", "param_desc": "Buffer to write to. If None, the output is returned as a string.\n"}, {"param_name": "mode", "param_type": "str, optional", "param_desc": "Mode in which file is opened, “wt” by default.\n"}, {"param_name": "index", "param_type": "bool, optional, default True", "param_desc": "Add index (row) labels.\n"}, {"param_name": "storage_options", "param_type": "dict, optional", "param_desc": "Extra options that make sense for a particular storage connection, e.g.\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\nare forwarded to urllib.request.Request as header options. For other\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\nforwarded to fsspec.open. Please see fsspec and urllib for more\ndetails, and for more examples on storage options refer here.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.to_markdown.html#pandas.Series.to_markdown"}, {"function_name": "pandas.Series.to_csv", "full_function": "Series.to_csv(path_or_buf=None, *, sep=',', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, mode='w', encoding=None, compression='infer', quoting=None, quotechar='\"', lineterminator=None, chunksize=None, date_format=None, doublequote=True, escapechar=None, decimal='.', errors='strict', storage_options=None)", "function_text": "Write object to a comma-separated values (csv) file.", "parameter_names_desc": [{"param_name": "path_or_buf", "param_type": "str, path object, file-like object, or None, default None", "param_desc": "String, path object (implementing os.PathLike[str]), or file-like\nobject implementing a write() function. If None, the result is\nreturned as a string. If a non-binary file object is passed, it should\nbe opened with newline=’’, disabling universal newlines. If a binary\nfile object is passed, mode might need to contain a ‘b’.\n"}, {"param_name": "sep", "param_type": "str, default ‘,’", "param_desc": "String of length 1. Field delimiter for the output file.\n"}, {"param_name": "na_rep", "param_type": "str, default ‘’", "param_desc": "Missing data representation.\n"}, {"param_name": "float_format", "param_type": "str, Callable, default None", "param_desc": "Format string for floating point numbers. If a Callable is given, it takes\nprecedence over other numeric formatting parameters, like decimal.\n"}, {"param_name": "columns", "param_type": "sequence, optional", "param_desc": "Columns to write.\n"}, {"param_name": "header", "param_type": "bool or list of str, default True", "param_desc": "Write out the column names. If a list of strings is given it is\nassumed to be aliases for the column names.\n"}, {"param_name": "index", "param_type": "bool, default True", "param_desc": "Write row names (index).\n"}, {"param_name": "index_label", "param_type": "str or sequence, or False, default None", "param_desc": "Column label for index column(s) if desired. If None is given, and\nheader and index are True, then the index names are used. A\nsequence should be given if the object uses MultiIndex. If\nFalse do not print fields for index names. Use index_label=False\nfor easier importing in R.\n"}, {"param_name": "mode", "param_type": "{‘w’, ‘x’, ‘a’}, default ‘w’", "param_desc": "Forwarded to either open(mode=) or fsspec.open(mode=) to control\nthe file opening. Typical values include:\n\n‘w’, truncate the file first.\n‘x’, exclusive creation, failing if the file already exists.\n‘a’, append to the end of file if it exists.\n\n"}, {"param_name": "encoding", "param_type": "str, optional", "param_desc": "A string representing the encoding to use in the output file,\ndefaults to ‘utf-8’. encoding is not supported if path_or_buf\nis a non-binary file object.\n"}, {"param_name": "compression", "param_type": "str or dict, default ‘infer’", "param_desc": "For on-the-fly compression of the output data. If ‘infer’ and ‘path_or_buf’ is\npath-like, then detect compression from the following extensions: ‘.gz’,\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\n(otherwise no compression).\nSet to None for no compression.\nCan also be a dict with key 'method' set\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\nother key-value pairs are forwarded to\nzipfile.ZipFile, gzip.GzipFile,\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\ntarfile.TarFile, respectively.\nAs an example, the following could be passed for faster compression and to create\na reproducible gzip archive:\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\n\nNew in version 1.5.0: Added support for .tar files.\nMay be a dict with key ‘method’ as compression mode\nand other entries as additional compression options if\ncompression mode is ‘zip’.\nPassing compression options as keys in dict is\nsupported for compression modes ‘gzip’, ‘bz2’, ‘zstd’, and ‘zip’.\n\n"}, {"param_name": "quoting", "param_type": "optional constant from csv module", "param_desc": "Defaults to csv.QUOTE_MINIMAL. If you have set a float_format\nthen floats are converted to strings and thus csv.QUOTE_NONNUMERIC\nwill treat them as non-numeric.\n"}, {"param_name": "quotechar", "param_type": "str, default ‘\"’", "param_desc": "String of length 1. Character used to quote fields.\n"}, {"param_name": "lineterminator", "param_type": "str, optional", "param_desc": "The newline character or character sequence to use in the output\nfile. Defaults to os.linesep, which depends on the OS in which\nthis method is called (’\\n’ for linux, ‘\\r\\n’ for Windows, i.e.).\n\nChanged in version 1.5.0: Previously was line_terminator, changed for consistency with\nread_csv and the standard library ‘csv’ module.\n\n"}, {"param_name": "chunksize", "param_type": "int or None", "param_desc": "Rows to write at a time.\n"}, {"param_name": "date_format", "param_type": "str, default None", "param_desc": "Format string for datetime objects.\n"}, {"param_name": "doublequote", "param_type": "bool, default True", "param_desc": "Control quoting of quotechar inside a field.\n"}, {"param_name": "escapechar", "param_type": "str, default None", "param_desc": "String of length 1. Character used to escape sep and quotechar\nwhen appropriate.\n"}, {"param_name": "decimal", "param_type": "str, default ‘.’", "param_desc": "Character recognized as decimal separator. E.g. use ‘,’ for\nEuropean data.\n"}, {"param_name": "errors", "param_type": "str, default ‘strict’", "param_desc": "Specifies how encoding and decoding errors are to be handled.\nSee the errors argument for open() for a full list\nof options.\n"}, {"param_name": "storage_options", "param_type": "dict, optional", "param_desc": "Extra options that make sense for a particular storage connection, e.g.\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\nare forwarded to urllib.request.Request as header options. For other\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\nforwarded to fsspec.open. Please see fsspec and urllib for more\ndetails, and for more examples on storage options refer here.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.to_csv.html#pandas.Series.to_csv"}, {"function_name": "pandas.Series.to_excel", "full_function": "Series.to_excel(excel_writer, *, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, inf_rep='inf', freeze_panes=None, storage_options=None, engine_kwargs=None)", "function_text": "Write object to an Excel sheet.", "parameter_names_desc": [{"param_name": "excel_writer", "param_type": "path-like, file-like, or ExcelWriter object", "param_desc": "File path or existing ExcelWriter.\n"}, {"param_name": "sheet_name", "param_type": "str, default ‘Sheet1’", "param_desc": "Name of sheet which will contain DataFrame.\n"}, {"param_name": "na_rep", "param_type": "str, default ‘’", "param_desc": "Missing data representation.\n"}, {"param_name": "float_format", "param_type": "str, optional", "param_desc": "Format string for floating point numbers. For example\nfloat_format=\"%.2f\" will format 0.1234 to 0.12.\n"}, {"param_name": "columns", "param_type": "sequence or list of str, optional", "param_desc": "Columns to write.\n"}, {"param_name": "header", "param_type": "bool or list of str, default True", "param_desc": "Write out the column names. If a list of string is given it is\nassumed to be aliases for the column names.\n"}, {"param_name": "index", "param_type": "bool, default True", "param_desc": "Write row names (index).\n"}, {"param_name": "index_label", "param_type": "str or sequence, optional", "param_desc": "Column label for index column(s) if desired. If not specified, and\nheader and index are True, then the index names are used. A\nsequence should be given if the DataFrame uses MultiIndex.\n"}, {"param_name": "startrow", "param_type": "int, default 0", "param_desc": "Upper left cell row to dump data frame.\n"}, {"param_name": "startcol", "param_type": "int, default 0", "param_desc": "Upper left cell column to dump data frame.\n"}, {"param_name": "engine", "param_type": "str, optional", "param_desc": "Write engine to use, ‘openpyxl’ or ‘xlsxwriter’. You can also set this\nvia the options io.excel.xlsx.writer or\nio.excel.xlsm.writer.\n"}, {"param_name": "merge_cells", "param_type": "bool, default True", "param_desc": "Write MultiIndex and Hierarchical Rows as merged cells.\n"}, {"param_name": "inf_rep", "param_type": "str, default ‘inf’", "param_desc": "Representation for infinity (there is no native representation for\ninfinity in Excel).\n"}, {"param_name": "freeze_panes", "param_type": "tuple of int (length 2), optional", "param_desc": "Specifies the one-based bottommost row and rightmost column that\nis to be frozen.\n"}, {"param_name": "storage_options", "param_type": "dict, optional", "param_desc": "Extra options that make sense for a particular storage connection, e.g.\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\nare forwarded to urllib.request.Request as header options. For other\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\nforwarded to fsspec.open. Please see fsspec and urllib for more\ndetails, and for more examples on storage options refer here.\n\nNew in version 1.2.0.\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, optional", "param_desc": "Arbitrary keyword arguments passed to excel engine.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.to_excel.html#pandas.Series.to_excel"}, {"function_name": "pandas.Series.to_xarray", "full_function": "Series.to_xarray()", "function_text": "Return an xarray object from the pandas object.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.to_xarray.html#pandas.Series.to_xarray"}, {"function_name": "pandas.Series.to_sql", "full_function": "Series.to_sql(name, con, *, schema=None, if_exists='fail', index=True, index_label=None, chunksize=None, dtype=None, method=None)", "function_text": "Write records stored in a DataFrame to a SQL database.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.to_sql.html#pandas.Series.to_sql"}, {"function_name": "pandas.Series.to_string", "full_function": "Series.to_string(buf=None, na_rep='NaN', float_format=None, header=True, index=True, length=False, dtype=False, name=False, max_rows=None, min_rows=None)", "function_text": "Render a string representation of the Series.", "parameter_names_desc": [{"param_name": "buf", "param_type": "StringIO-like, optional", "param_desc": "Buffer to write to.\n"}, {"param_name": "na_rep", "param_type": "str, optional", "param_desc": "String representation of NaN to use, default ‘NaN’.\n"}, {"param_name": "float_format", "param_type": "one-parameter function, optional", "param_desc": "Formatter function to apply to columns’ elements if they are\nfloats, default None.\n"}, {"param_name": "header", "param_type": "bool, default True", "param_desc": "Add the Series header (index name).\n"}, {"param_name": "index", "param_type": "bool, optional", "param_desc": "Add index (row) labels, default True.\n"}, {"param_name": "length", "param_type": "bool, default False", "param_desc": "Add the Series length.\n"}, {"param_name": "dtype", "param_type": "bool, default False", "param_desc": "Add the Series dtype.\n"}, {"param_name": "name", "param_type": "bool, default False", "param_desc": "Add the Series name if not None.\n"}, {"param_name": "max_rows", "param_type": "int, optional", "param_desc": "Maximum number of rows to show before truncating. If None, show\nall.\n"}, {"param_name": "min_rows", "param_type": "int, optional", "param_desc": "The number of rows to display in a truncated repr (when number\nof rows is above max_rows).\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.to_string.html#pandas.Series.to_string"}, {"function_name": "pandas.Series.to_latex", "full_function": "Series.to_latex(buf=None, *, columns=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, bold_rows=False, column_format=None, longtable=None, escape=None, encoding=None, decimal='.', multicolumn=None, multicolumn_format=None, multirow=None, caption=None, label=None, position=None)", "function_text": "Render object to a LaTeX tabular, longtable, or nested table.", "parameter_names_desc": [{"param_name": "buf", "param_type": "str, Path or StringIO-like, optional, default None", "param_desc": "Buffer to write to. If None, the output is returned as a string.\n"}, {"param_name": "columns", "param_type": "list of label, optional", "param_desc": "The subset of columns to write. Writes all columns by default.\n"}, {"param_name": "header", "param_type": "bool or list of str, default True", "param_desc": "Write out the column names. If a list of strings is given,\nit is assumed to be aliases for the column names.\n"}, {"param_name": "index", "param_type": "bool, default True", "param_desc": "Write row names (index).\n"}, {"param_name": "na_rep", "param_type": "str, default ‘NaN’", "param_desc": "Missing data representation.\n"}, {"param_name": "formatters", "param_type": "list of functions or dict of {{str: function}}, optional", "param_desc": "Formatter functions to apply to columns’ elements by position or\nname. The result of each function must be a unicode string.\nList must be of length equal to the number of columns.\n"}, {"param_name": "float_format", "param_type": "one-parameter function or str, optional, default None", "param_desc": "Formatter for floating point numbers. For example\nfloat_format=\"%.2f\" and float_format=\"{{:0.2f}}\".format will\nboth result in 0.1234 being formatted as 0.12.\n"}, {"param_name": "sparsify", "param_type": "bool, optional", "param_desc": "Set to False for a DataFrame with a hierarchical index to print\nevery multiindex key at each row. By default, the value will be\nread from the config module.\n"}, {"param_name": "index_names", "param_type": "bool, default True", "param_desc": "Prints the names of the indexes.\n"}, {"param_name": "bold_rows", "param_type": "bool, default False", "param_desc": "Make the row labels bold in the output.\n"}, {"param_name": "column_format", "param_type": "str, optional", "param_desc": "The columns format as specified in LaTeX table format e.g. ‘rcl’ for 3\ncolumns. By default, ‘l’ will be used for all columns except\ncolumns of numbers, which default to ‘r’.\n"}, {"param_name": "longtable", "param_type": "bool, optional", "param_desc": "Use a longtable environment instead of tabular. Requires\nadding a usepackage{{longtable}} to your LaTeX preamble.\nBy default, the value will be read from the pandas config\nmodule, and set to True if the option styler.latex.environment is\n“longtable”.\n\nChanged in version 2.0.0: The pandas option affecting this argument has changed.\n\n"}, {"param_name": "escape", "param_type": "bool, optional", "param_desc": "By default, the value will be read from the pandas config\nmodule and set to True if the option styler.format.escape is\n“latex”. When set to False prevents from escaping latex special\ncharacters in column names.\n\nChanged in version 2.0.0: The pandas option affecting this argument has changed, as has the\ndefault value to False.\n\n"}, {"param_name": "encoding", "param_type": "str, optional", "param_desc": "A string representing the encoding to use in the output file,\ndefaults to ‘utf-8’.\n"}, {"param_name": "decimal", "param_type": "str, default ‘.’", "param_desc": "Character recognized as decimal separator, e.g. ‘,’ in Europe.\n"}, {"param_name": "multicolumn", "param_type": "bool, default True", "param_desc": "Use multicolumn to enhance MultiIndex columns.\nThe default will be read from the config module, and is set\nas the option styler.sparse.columns.\n\nChanged in version 2.0.0: The pandas option affecting this argument has changed.\n\n"}, {"param_name": "multicolumn_format", "param_type": "str, default ‘r’", "param_desc": "The alignment for multicolumns, similar to column_format\nThe default will be read from the config module, and is set as the option\nstyler.latex.multicol_align.\n\nChanged in version 2.0.0: The pandas option affecting this argument has changed, as has the\ndefault value to “r”.\n\n"}, {"param_name": "multirow", "param_type": "bool, default True", "param_desc": "Use multirow to enhance MultiIndex rows. Requires adding a\nusepackage{{multirow}} to your LaTeX preamble. Will print\ncentered labels (instead of top-aligned) across the contained\nrows, separating groups via clines. The default will be read\nfrom the pandas config module, and is set as the option\nstyler.sparse.index.\n\nChanged in version 2.0.0: The pandas option affecting this argument has changed, as has the\ndefault value to True.\n\n"}, {"param_name": "caption", "param_type": "str or tuple, optional", "param_desc": "Tuple (full_caption, short_caption),\nwhich results in \\caption[short_caption]{{full_caption}};\nif a single string is passed, no short caption will be set.\n"}, {"param_name": "label", "param_type": "str, optional", "param_desc": "The LaTeX label to be placed inside \\label{{}} in the output.\nThis is used with \\ref{{}} in the main .tex file.\n"}, {"param_name": "position", "param_type": "str, optional", "param_desc": "The LaTeX positional argument for tables, to be placed after\n\\begin{{}} in the output.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Series.to_latex.html#pandas.Series.to_latex"}]}], "name": "Series", "url": "https://pandas.pydata.org/docs/reference/series.html"}, "frame.html": {"functions": [{"name": "Constructor", "url": "https://pandas.pydata.org/docs/reference/frame.html#constructor", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html#pandas.DataFrame"], "function_definitions": [{"function_name": "pandas.DataFrame", "full_function": "class pandas.DataFrame(data=None, index=None, columns=None, dtype=None, copy=None)", "function_text": "Two-dimensional, size-mutable, potentially heterogeneous tabular data.", "parameter_names_desc": [{"param_name": "data", "param_type": "ndarray (structured or homogeneous), Iterable, dict, or DataFrame", "param_desc": "Dict can contain Series, arrays, constants, dataclass or list-like objects. If\ndata is a dict, column order follows insertion-order. If a dict contains Series\nwhich have an index defined, it is aligned by its index. This alignment also\noccurs if data is a Series or a DataFrame itself. Alignment is done on\nSeries/DataFrame inputs.\nIf data is a list of dicts, column order follows insertion-order.\n"}, {"param_name": "index", "param_type": "Index or array-like", "param_desc": "Index to use for resulting frame. Will default to RangeIndex if\nno indexing information part of input data and no index provided.\n"}, {"param_name": "columns", "param_type": "Index or array-like", "param_desc": "Column labels to use for resulting frame when data does not have them,\ndefaulting to RangeIndex(0, 1, 2, …, n). If data contains column labels,\nwill perform column selection instead.\n"}, {"param_name": "dtype", "param_type": "dtype, default None", "param_desc": "Data type to force. Only a single dtype is allowed. If None, infer.\n"}, {"param_name": "copy", "param_type": "bool or None, default None", "param_desc": "Copy data from inputs.\nFor dict data, the default of None behaves like copy=True. For DataFrame\nor 2d ndarray input, the default of None behaves like copy=False.\nIf data is a dict containing one or more Series (possibly of different dtypes),\ncopy=False will ensure that these inputs are not copied.\n\nChanged in version 1.3.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html#pandas.DataFrame"}]}, {"name": "Attributes and underlying data", "url": "https://pandas.pydata.org/docs/reference/frame.html#attributes-and-underlying-data", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.index.html#pandas.DataFrame.index", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dtypes.html#pandas.DataFrame.dtypes", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.select_dtypes.html#pandas.DataFrame.select_dtypes", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.axes.html#pandas.DataFrame.axes", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.size.html#pandas.DataFrame.size", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.memory_usage.html#pandas.DataFrame.memory_usage", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_flags.html#pandas.DataFrame.set_flags", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.columns.html#pandas.DataFrame.columns", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html#pandas.DataFrame.info", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.values.html#pandas.DataFrame.values", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ndim.html#pandas.DataFrame.ndim", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shape.html#pandas.DataFrame.shape", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.empty.html#pandas.DataFrame.empty"], "function_definitions": [{"function_name": "pandas.DataFrame.index", "full_function": "DataFrame.index#", "function_text": "The index (row labels) of the DataFrame.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.index.html#pandas.DataFrame.index"}, {"function_name": "pandas.DataFrame.dtypes", "full_function": "property DataFrame.dtypes", "function_text": "Return the dtypes in the DataFrame.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dtypes.html#pandas.DataFrame.dtypes"}, {"function_name": "pandas.DataFrame.select_dtypes", "full_function": "DataFrame.select_dtypes(include=None, exclude=None)", "function_text": "Return a subset of the DataFrame’s columns based on the column dtypes.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.select_dtypes.html#pandas.DataFrame.select_dtypes"}, {"function_name": "pandas.DataFrame.axes", "full_function": "property DataFrame.axes", "function_text": "Return a list representing the axes of the DataFrame.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.axes.html#pandas.DataFrame.axes"}, {"function_name": "pandas.DataFrame.size", "full_function": "property DataFrame.size", "function_text": "Return an int representing the number of elements in this object.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.size.html#pandas.DataFrame.size"}, {"function_name": "pandas.DataFrame.memory_usage", "full_function": "DataFrame.memory_usage(index=True, deep=False)", "function_text": "Return the memory usage of each column in bytes.", "parameter_names_desc": [{"param_name": "index", "param_type": "bool, default True", "param_desc": "Specifies whether to include the memory usage of the DataFrame’s\nindex in returned Series. If index=True, the memory usage of\nthe index is the first item in the output.\n"}, {"param_name": "deep", "param_type": "bool, default False", "param_desc": "If True, introspect the data deeply by interrogating\nobject dtypes for system-level memory consumption, and include\nit in the returned values.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.memory_usage.html#pandas.DataFrame.memory_usage"}, {"function_name": "pandas.DataFrame.set_flags", "full_function": "DataFrame.set_flags(*, copy=False, allows_duplicate_labels=None)", "function_text": "Return a new object with updated flags.", "parameter_names_desc": [{"param_name": "copy", "param_type": "bool, default False", "param_desc": "Specify if a copy of the object should be made.\n\nNote\nThe copy keyword will change behavior in pandas 3.0.\nCopy-on-Write\nwill be enabled by default, which means that all methods with a\ncopy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas.\nYou can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True\n\n"}, {"param_name": "allows_duplicate_labels", "param_type": "bool, optional", "param_desc": "Whether the returned object allows duplicate labels.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_flags.html#pandas.DataFrame.set_flags"}, {"function_name": "pandas.DataFrame.columns", "full_function": "DataFrame.columns#", "function_text": "The column labels of the DataFrame.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.columns.html#pandas.DataFrame.columns"}, {"function_name": "pandas.DataFrame.info", "full_function": "DataFrame.info(verbose=None, buf=None, max_cols=None, memory_usage=None, show_counts=None)", "function_text": "Print a concise summary of a DataFrame.", "parameter_names_desc": [{"param_name": "verbose", "param_type": "bool, optional", "param_desc": "Whether to print the full summary. By default, the setting in\npandas.options.display.max_info_columns is followed.\n"}, {"param_name": "buf", "param_type": "writable buffer, defaults to sys.stdout", "param_desc": "Where to send the output. By default, the output is printed to\nsys.stdout. Pass a writable buffer if you need to further process\nthe output.\n"}, {"param_name": "max_cols", "param_type": "int, optional", "param_desc": "When to switch from the verbose to the truncated output. If the\nDataFrame has more than max_cols columns, the truncated output\nis used. By default, the setting in\npandas.options.display.max_info_columns is used.\n"}, {"param_name": "memory_usage", "param_type": "bool, str, optional", "param_desc": "Specifies whether total memory usage of the DataFrame\nelements (including the index) should be displayed. By default,\nthis follows the pandas.options.display.memory_usage setting.\nTrue always show memory usage. False never shows memory usage.\nA value of ‘deep’ is equivalent to “True with deep introspection”.\nMemory usage is shown in human-readable units (base-2\nrepresentation). Without deep introspection a memory estimation is\nmade based in column dtype and number of rows assuming values\nconsume the same memory amount for corresponding dtypes. With deep\nmemory introspection, a real memory usage calculation is performed\nat the cost of computational resources. See the\nFrequently Asked Questions for more\ndetails.\n"}, {"param_name": "show_counts", "param_type": "bool, optional", "param_desc": "Whether to show the non-null counts. By default, this is shown\nonly if the DataFrame is smaller than\npandas.options.display.max_info_rows and\npandas.options.display.max_info_columns. A value of True always\nshows the counts, and False never shows the counts.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html#pandas.DataFrame.info"}, {"function_name": "pandas.DataFrame.values", "full_function": "property DataFrame.values", "function_text": "Return a Numpy representation of the DataFrame.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.values.html#pandas.DataFrame.values"}, {"function_name": "pandas.DataFrame.ndim", "full_function": "property DataFrame.ndim", "function_text": "Return an int representing the number of axes / array dimensions.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ndim.html#pandas.DataFrame.ndim"}, {"function_name": "pandas.DataFrame.shape", "full_function": "property DataFrame.shape", "function_text": "Return a tuple representing the dimensionality of the DataFrame.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shape.html#pandas.DataFrame.shape"}, {"function_name": "pandas.DataFrame.empty", "full_function": "property DataFrame.empty", "function_text": "Indicator whether Series/DataFrame is empty.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.empty.html#pandas.DataFrame.empty"}]}, {"name": "Conversion", "url": "https://pandas.pydata.org/docs/reference/frame.html#conversion", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html#pandas.DataFrame.astype", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.infer_objects.html#pandas.DataFrame.infer_objects", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.bool.html#pandas.DataFrame.bool", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.convert_dtypes.html#pandas.DataFrame.convert_dtypes", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.copy.html#pandas.DataFrame.copy", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_numpy.html#pandas.DataFrame.to_numpy"], "function_definitions": [{"function_name": "pandas.DataFrame.astype", "full_function": "DataFrame.astype(dtype, copy=None, errors='raise')", "function_text": "Cast a pandas object to a specified dtype dtype.", "parameter_names_desc": [{"param_name": "dtype", "param_type": "str, data type, Series or Mapping of column name -> data type", "param_desc": "Use a str, numpy.dtype, pandas.ExtensionDtype or Python type to\ncast entire pandas object to the same type. Alternatively, use a\nmapping, e.g. {col: dtype, …}, where col is a column label and dtype is\na numpy.dtype or Python type to cast one or more of the DataFrame’s\ncolumns to column-specific types.\n"}, {"param_name": "copy", "param_type": "bool, default True", "param_desc": "Return a copy when copy=True (be very careful setting\ncopy=False as changes to values then may propagate to other\npandas objects).\n\nNote\nThe copy keyword will change behavior in pandas 3.0.\nCopy-on-Write\nwill be enabled by default, which means that all methods with a\ncopy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas.\nYou can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True\n\n"}, {"param_name": "errors", "param_type": "{‘raise’, ‘ignore’}, default ‘raise’", "param_desc": "Control raising of exceptions on invalid data for provided dtype.\n\nraise : allow exceptions to be raised\nignore : suppress exceptions. On error return original object.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html#pandas.DataFrame.astype"}, {"function_name": "pandas.DataFrame.infer_objects", "full_function": "DataFrame.infer_objects(copy=None)", "function_text": "Attempt to infer better dtypes for object columns.", "parameter_names_desc": [{"param_name": "copy", "param_type": "bool, default True", "param_desc": "Whether to make a copy for non-object or non-inferable columns\nor Series.\n\nNote\nThe copy keyword will change behavior in pandas 3.0.\nCopy-on-Write\nwill be enabled by default, which means that all methods with a\ncopy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas.\nYou can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.infer_objects.html#pandas.DataFrame.infer_objects"}, {"function_name": "pandas.DataFrame.bool", "full_function": "DataFrame.bool()", "function_text": "Return the bool of a single element Series or DataFrame.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.bool.html#pandas.DataFrame.bool"}, {"function_name": "pandas.DataFrame.convert_dtypes", "full_function": "DataFrame.convert_dtypes(infer_objects=True, convert_string=True, convert_integer=True, convert_boolean=True, convert_floating=True, dtype_backend='numpy_nullable')", "function_text": "Convert columns to the best possible dtypes using dtypes supporting pd.NA.", "parameter_names_desc": [{"param_name": "infer_objects", "param_type": "bool, default True", "param_desc": "Whether object dtypes should be converted to the best possible types.\n"}, {"param_name": "convert_string", "param_type": "bool, default True", "param_desc": "Whether object dtypes should be converted to StringDtype().\n"}, {"param_name": "convert_integer", "param_type": "bool, default True", "param_desc": "Whether, if possible, conversion can be done to integer extension types.\n"}, {"param_name": "convert_boolean", "param_type": "bool, defaults True", "param_desc": "Whether object dtypes should be converted to BooleanDtypes().\n"}, {"param_name": "convert_floating", "param_type": "bool, defaults True", "param_desc": "Whether, if possible, conversion can be done to floating extension types.\nIf convert_integer is also True, preference will be give to integer\ndtypes if the floats can be faithfully casted to integers.\n"}, {"param_name": "dtype_backend", "param_type": "{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’", "param_desc": "Back-end data type applied to the resultant DataFrame\n(still experimental). Behaviour is as follows:\n\n\"numpy_nullable\": returns nullable-dtype-backed DataFrame\n(default).\n\"pyarrow\": returns pyarrow-backed nullable ArrowDtype\nDataFrame.\n\n\nNew in version 2.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.convert_dtypes.html#pandas.DataFrame.convert_dtypes"}, {"function_name": "pandas.DataFrame.copy", "full_function": "DataFrame.copy(deep=True)", "function_text": "Make a copy of this object’s indices and data.", "parameter_names_desc": [{"param_name": "deep", "param_type": "bool, default True", "param_desc": "Make a deep copy, including a copy of the data and the indices.\nWith deep=False neither the indices nor the data are copied.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.copy.html#pandas.DataFrame.copy"}, {"function_name": "pandas.DataFrame.to_numpy", "full_function": "DataFrame.to_numpy(dtype=None, copy=False, na_value=_NoDefault.no_default)", "function_text": "Convert the DataFrame to a NumPy array.", "parameter_names_desc": [{"param_name": "dtype", "param_type": "str or numpy.dtype, optional", "param_desc": "The dtype to pass to numpy.asarray().\n"}, {"param_name": "copy", "param_type": "bool, default False", "param_desc": "Whether to ensure that the returned value is not a view on\nanother array. Note that copy=False does not ensure that\nto_numpy() is no-copy. Rather, copy=True ensure that\na copy is made, even if not strictly necessary.\n"}, {"param_name": "na_value", "param_type": "Any, optional", "param_desc": "The value to use for missing values. The default value depends\non dtype and the dtypes of the DataFrame columns.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_numpy.html#pandas.DataFrame.to_numpy"}]}, {"name": "Indexing, iteration", "url": "https://pandas.pydata.org/docs/reference/frame.html#indexing-iteration", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html#pandas.DataFrame.head", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iat.html#pandas.DataFrame.iat", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html#pandas.DataFrame.iloc", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.__iter__.html#pandas.DataFrame.__iter__", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.keys.html#pandas.DataFrame.keys", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.itertuples.html#pandas.DataFrame.itertuples", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tail.html#pandas.DataFrame.tail", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.get.html#pandas.DataFrame.get", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.where.html#pandas.DataFrame.where", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html#pandas.DataFrame.query", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.at.html#pandas.DataFrame.at", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.insert.html#pandas.DataFrame.insert", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.items.html#pandas.DataFrame.items", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iterrows.html#pandas.DataFrame.iterrows", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pop.html#pandas.DataFrame.pop", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.xs.html#pandas.DataFrame.xs", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isin.html#pandas.DataFrame.isin", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mask.html#pandas.DataFrame.mask"], "function_definitions": [{"function_name": "pandas.DataFrame.head", "full_function": "DataFrame.head(n=5)", "function_text": "Return the first n rows.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 5", "param_desc": "Number of rows to select.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html#pandas.DataFrame.head"}, {"function_name": "pandas.DataFrame.iat", "full_function": "property DataFrame.iat", "function_text": "Access a single value for a row/column pair by integer position.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iat.html#pandas.DataFrame.iat"}, {"function_name": "pandas.DataFrame.iloc", "full_function": "property DataFrame.iloc", "function_text": "Purely integer-location based indexing for selection by position.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html#pandas.DataFrame.iloc"}, {"function_name": "pandas.DataFrame.__iter__", "full_function": "DataFrame.__iter__()", "function_text": "Iterate over info axis.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.__iter__.html#pandas.DataFrame.__iter__"}, {"function_name": "pandas.DataFrame.keys", "full_function": "DataFrame.keys()", "function_text": "Get the ‘info axis’ (see Indexing for more).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.keys.html#pandas.DataFrame.keys"}, {"function_name": "pandas.DataFrame.itertuples", "full_function": "DataFrame.itertuples(index=True, name='Pandas')", "function_text": "Iterate over DataFrame rows as namedtuples.", "parameter_names_desc": [{"param_name": "index", "param_type": "bool, default True", "param_desc": "If True, return the index as the first element of the tuple.\n"}, {"param_name": "name", "param_type": "str or None, default “Pandas”", "param_desc": "The name of the returned namedtuples or None to return regular\ntuples.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.itertuples.html#pandas.DataFrame.itertuples"}, {"function_name": "pandas.DataFrame.tail", "full_function": "DataFrame.tail(n=5)", "function_text": "Return the last n rows.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 5", "param_desc": "Number of rows to select.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tail.html#pandas.DataFrame.tail"}, {"function_name": "pandas.DataFrame.get", "full_function": "DataFrame.get(key, default=None)", "function_text": "Get item from object for given key (ex: DataFrame column).", "parameter_names_desc": [{"param_name": "key", "param_type": "object", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.get.html#pandas.DataFrame.get"}, {"function_name": "pandas.DataFrame.where", "full_function": "DataFrame.where(cond, other=nan, *, inplace=False, axis=None, level=None)", "function_text": "Replace values where the condition is False.", "parameter_names_desc": [{"param_name": "cond", "param_type": "bool Series/DataFrame, array-like, or callable", "param_desc": "Where cond is True, keep the original value. Where\nFalse, replace with corresponding value from other.\nIf cond is callable, it is computed on the Series/DataFrame and\nshould return boolean Series/DataFrame or array. The callable must\nnot change input Series/DataFrame (though pandas doesn’t check it).\n"}, {"param_name": "other", "param_type": "scalar, Series/DataFrame, or callable", "param_desc": "Entries where cond is False are replaced with\ncorresponding value from other.\nIf other is callable, it is computed on the Series/DataFrame and\nshould return scalar or Series/DataFrame. The callable must not\nchange input Series/DataFrame (though pandas doesn’t check it).\nIf not specified, entries will be filled with the corresponding\nNULL value (np.nan for numpy dtypes, pd.NA for extension\ndtypes).\n"}, {"param_name": "inplace", "param_type": "bool, default False", "param_desc": "Whether to perform the operation in place on the data.\n"}, {"param_name": "axis", "param_type": "int, default None", "param_desc": "Alignment axis if needed. For Series this parameter is\nunused and defaults to 0.\n"}, {"param_name": "level", "param_type": "int, default None", "param_desc": "Alignment level if needed.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.where.html#pandas.DataFrame.where"}, {"function_name": "pandas.DataFrame.query", "full_function": "DataFrame.query(expr, *, inplace=False, **kwargs)", "function_text": "Query the columns of a DataFrame with a boolean expression.", "parameter_names_desc": [{"param_name": "expr", "param_type": "str", "param_desc": "The query string to evaluate.\nYou can refer to variables\nin the environment by prefixing them with an ‘@’ character like\n@a + b.\nYou can refer to column names that are not valid Python variable names\nby surrounding them in backticks. Thus, column names containing spaces\nor punctuations (besides underscores) or starting with digits must be\nsurrounded by backticks. (For example, a column named “Area (cm^2)” would\nbe referenced as `Area (cm^2)`). Column names which are Python keywords\n(like “list”, “for”, “import”, etc) cannot be used.\nFor example, if one of your columns is called a a and you want\nto sum it with b, your query should be `a a` + b.\n"}, {"param_name": "inplace", "param_type": "bool", "param_desc": "Whether to modify the DataFrame rather than creating a new one.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html#pandas.DataFrame.query"}, {"function_name": "pandas.DataFrame.at", "full_function": "property DataFrame.at", "function_text": "Access a single value for a row/column label pair.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.at.html#pandas.DataFrame.at"}, {"function_name": "pandas.DataFrame.loc", "full_function": "property DataFrame.loc", "function_text": "Access a group of rows and columns by label(s) or a boolean array.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc"}, {"function_name": "pandas.DataFrame.insert", "full_function": "DataFrame.insert(loc, column, value, allow_duplicates=_NoDefault.no_default)", "function_text": "Insert column into DataFrame at specified location.", "parameter_names_desc": [{"param_name": "loc", "param_type": "int", "param_desc": "Insertion index. Must verify 0 <= loc <= len(columns).\n"}, {"param_name": "column", "param_type": "str, number, or hashable object", "param_desc": "Label of the inserted column.\n"}, {"param_name": "value", "param_type": "Scalar, Series, or array-like", "param_desc": "Content of the inserted column.\n"}, {"param_name": "allow_duplicates", "param_type": "bool, optional, default lib.no_default", "param_desc": "Allow duplicate column labels to be created.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.insert.html#pandas.DataFrame.insert"}, {"function_name": "pandas.DataFrame.items", "full_function": "DataFrame.items()", "function_text": "Iterate over (column name, Series) pairs.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.items.html#pandas.DataFrame.items"}, {"function_name": "pandas.DataFrame.iterrows", "full_function": "DataFrame.iterrows()", "function_text": "Iterate over DataFrame rows as (index, Series) pairs.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iterrows.html#pandas.DataFrame.iterrows"}, {"function_name": "pandas.DataFrame.pop", "full_function": "DataFrame.pop(item)", "function_text": "Return item and drop from frame. Raise KeyError if not found.", "parameter_names_desc": [{"param_name": "item", "param_type": "label", "param_desc": "Label of column to be popped.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pop.html#pandas.DataFrame.pop"}, {"function_name": "pandas.DataFrame.xs", "full_function": "DataFrame.xs(key, axis=0, level=None, drop_level=True)", "function_text": "Return cross-section from the Series/DataFrame.", "parameter_names_desc": [{"param_name": "key", "param_type": "label or tuple of label", "param_desc": "Label contained in the index, or partially in a MultiIndex.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "Axis to retrieve cross-section on.\n"}, {"param_name": "level", "param_type": "object, defaults to first n levels (n=1 or len(key))", "param_desc": "In case of a key partially contained in a MultiIndex, indicate\nwhich levels are used. Levels can be referred by label or position.\n"}, {"param_name": "drop_level", "param_type": "bool, default True", "param_desc": "If False, returns object with same levels as self.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.xs.html#pandas.DataFrame.xs"}, {"function_name": "pandas.DataFrame.isin", "full_function": "DataFrame.isin(values)", "function_text": "Whether each element in the DataFrame is contained in values.", "parameter_names_desc": [{"param_name": "values", "param_type": "iterable, Series, DataFrame or dict", "param_desc": "The result will only be true at a location if all the\nlabels match. If values is a Series, that’s the index. If\nvalues is a dict, the keys must be the column names,\nwhich must match. If values is a DataFrame,\nthen both the index and column labels must match.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isin.html#pandas.DataFrame.isin"}, {"function_name": "pandas.DataFrame.mask", "full_function": "DataFrame.mask(cond, other=_NoDefault.no_default, *, inplace=False, axis=None, level=None)", "function_text": "Replace values where the condition is True.", "parameter_names_desc": [{"param_name": "cond", "param_type": "bool Series/DataFrame, array-like, or callable", "param_desc": "Where cond is False, keep the original value. Where\nTrue, replace with corresponding value from other.\nIf cond is callable, it is computed on the Series/DataFrame and\nshould return boolean Series/DataFrame or array. The callable must\nnot change input Series/DataFrame (though pandas doesn’t check it).\n"}, {"param_name": "other", "param_type": "scalar, Series/DataFrame, or callable", "param_desc": "Entries where cond is True are replaced with\ncorresponding value from other.\nIf other is callable, it is computed on the Series/DataFrame and\nshould return scalar or Series/DataFrame. The callable must not\nchange input Series/DataFrame (though pandas doesn’t check it).\nIf not specified, entries will be filled with the corresponding\nNULL value (np.nan for numpy dtypes, pd.NA for extension\ndtypes).\n"}, {"param_name": "inplace", "param_type": "bool, default False", "param_desc": "Whether to perform the operation in place on the data.\n"}, {"param_name": "axis", "param_type": "int, default None", "param_desc": "Alignment axis if needed. For Series this parameter is\nunused and defaults to 0.\n"}, {"param_name": "level", "param_type": "int, default None", "param_desc": "Alignment level if needed.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mask.html#pandas.DataFrame.mask"}]}, {"name": "Binary operator functions", "url": "https://pandas.pydata.org/docs/reference/frame.html#binary-operator-functions", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.__add__.html#pandas.DataFrame.__add__", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sub.html#pandas.DataFrame.sub", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.div.html#pandas.DataFrame.div", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.floordiv.html#pandas.DataFrame.floordiv", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pow.html#pandas.DataFrame.pow", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.radd.html#pandas.DataFrame.radd", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rmul.html#pandas.DataFrame.rmul", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rtruediv.html#pandas.DataFrame.rtruediv", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rmod.html#pandas.DataFrame.rmod", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.lt.html#pandas.DataFrame.lt", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.le.html#pandas.DataFrame.le", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ne.html#pandas.DataFrame.ne", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.combine.html#pandas.DataFrame.combine", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add.html#pandas.DataFrame.add", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mul.html#pandas.DataFrame.mul", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.truediv.html#pandas.DataFrame.truediv", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mod.html#pandas.DataFrame.mod", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dot.html#pandas.DataFrame.dot", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rsub.html#pandas.DataFrame.rsub", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rdiv.html#pandas.DataFrame.rdiv", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rfloordiv.html#pandas.DataFrame.rfloordiv", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rpow.html#pandas.DataFrame.rpow", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.gt.html#pandas.DataFrame.gt", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ge.html#pandas.DataFrame.ge", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.eq.html#pandas.DataFrame.eq", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.combine_first.html#pandas.DataFrame.combine_first"], "function_definitions": [{"function_name": "pandas.DataFrame.__add__", "full_function": "DataFrame.__add__(other)", "function_text": "Get Addition of DataFrame and other, column-wise.", "parameter_names_desc": [{"param_name": "other", "param_type": "scalar, sequence, Series, dict or DataFrame", "param_desc": "Object to be added to the DataFrame.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.__add__.html#pandas.DataFrame.__add__"}, {"function_name": "pandas.DataFrame.sub", "full_function": "DataFrame.sub(other, axis='columns', level=None, fill_value=None)", "function_text": "Get Subtraction of dataframe and other, element-wise (binary operator sub).", "parameter_names_desc": [{"param_name": "other", "param_type": "scalar, sequence, Series, dict or DataFrame", "param_desc": "Any single or multiple element data structure, or list-like object.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}", "param_desc": "Whether to compare by the index (0 or ‘index’) or columns.\n(1 or ‘columns’). For Series input, axis to match Series index on.\n"}, {"param_name": "level", "param_type": "int or label", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "float or None, default None", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful DataFrame alignment, with this value before computation.\nIf data in both corresponding DataFrame locations is missing\nthe result will be missing.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sub.html#pandas.DataFrame.sub"}, {"function_name": "pandas.DataFrame.div", "full_function": "DataFrame.div(other, axis='columns', level=None, fill_value=None)", "function_text": "Get Floating division of dataframe and other, element-wise (binary operator truediv).", "parameter_names_desc": [{"param_name": "other", "param_type": "scalar, sequence, Series, dict or DataFrame", "param_desc": "Any single or multiple element data structure, or list-like object.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}", "param_desc": "Whether to compare by the index (0 or ‘index’) or columns.\n(1 or ‘columns’). For Series input, axis to match Series index on.\n"}, {"param_name": "level", "param_type": "int or label", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "float or None, default None", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful DataFrame alignment, with this value before computation.\nIf data in both corresponding DataFrame locations is missing\nthe result will be missing.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.div.html#pandas.DataFrame.div"}, {"function_name": "pandas.DataFrame.floordiv", "full_function": "DataFrame.floordiv(other, axis='columns', level=None, fill_value=None)", "function_text": "Get Integer division of dataframe and other, element-wise (binary operator floordiv).", "parameter_names_desc": [{"param_name": "other", "param_type": "scalar, sequence, Series, dict or DataFrame", "param_desc": "Any single or multiple element data structure, or list-like object.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}", "param_desc": "Whether to compare by the index (0 or ‘index’) or columns.\n(1 or ‘columns’). For Series input, axis to match Series index on.\n"}, {"param_name": "level", "param_type": "int or label", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "float or None, default None", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful DataFrame alignment, with this value before computation.\nIf data in both corresponding DataFrame locations is missing\nthe result will be missing.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.floordiv.html#pandas.DataFrame.floordiv"}, {"function_name": "pandas.DataFrame.pow", "full_function": "DataFrame.pow(other, axis='columns', level=None, fill_value=None)", "function_text": "Get Exponential power of dataframe and other, element-wise (binary operator pow).", "parameter_names_desc": [{"param_name": "other", "param_type": "scalar, sequence, Series, dict or DataFrame", "param_desc": "Any single or multiple element data structure, or list-like object.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}", "param_desc": "Whether to compare by the index (0 or ‘index’) or columns.\n(1 or ‘columns’). For Series input, axis to match Series index on.\n"}, {"param_name": "level", "param_type": "int or label", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "float or None, default None", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful DataFrame alignment, with this value before computation.\nIf data in both corresponding DataFrame locations is missing\nthe result will be missing.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pow.html#pandas.DataFrame.pow"}, {"function_name": "pandas.DataFrame.radd", "full_function": "DataFrame.radd(other, axis='columns', level=None, fill_value=None)", "function_text": "Get Addition of dataframe and other, element-wise (binary operator radd).", "parameter_names_desc": [{"param_name": "other", "param_type": "scalar, sequence, Series, dict or DataFrame", "param_desc": "Any single or multiple element data structure, or list-like object.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}", "param_desc": "Whether to compare by the index (0 or ‘index’) or columns.\n(1 or ‘columns’). For Series input, axis to match Series index on.\n"}, {"param_name": "level", "param_type": "int or label", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "float or None, default None", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful DataFrame alignment, with this value before computation.\nIf data in both corresponding DataFrame locations is missing\nthe result will be missing.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.radd.html#pandas.DataFrame.radd"}, {"function_name": "pandas.DataFrame.rmul", "full_function": "DataFrame.rmul(other, axis='columns', level=None, fill_value=None)", "function_text": "Get Multiplication of dataframe and other, element-wise (binary operator rmul).", "parameter_names_desc": [{"param_name": "other", "param_type": "scalar, sequence, Series, dict or DataFrame", "param_desc": "Any single or multiple element data structure, or list-like object.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}", "param_desc": "Whether to compare by the index (0 or ‘index’) or columns.\n(1 or ‘columns’). For Series input, axis to match Series index on.\n"}, {"param_name": "level", "param_type": "int or label", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "float or None, default None", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful DataFrame alignment, with this value before computation.\nIf data in both corresponding DataFrame locations is missing\nthe result will be missing.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rmul.html#pandas.DataFrame.rmul"}, {"function_name": "pandas.DataFrame.rtruediv", "full_function": "DataFrame.rtruediv(other, axis='columns', level=None, fill_value=None)", "function_text": "Get Floating division of dataframe and other, element-wise (binary operator rtruediv).", "parameter_names_desc": [{"param_name": "other", "param_type": "scalar, sequence, Series, dict or DataFrame", "param_desc": "Any single or multiple element data structure, or list-like object.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}", "param_desc": "Whether to compare by the index (0 or ‘index’) or columns.\n(1 or ‘columns’). For Series input, axis to match Series index on.\n"}, {"param_name": "level", "param_type": "int or label", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "float or None, default None", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful DataFrame alignment, with this value before computation.\nIf data in both corresponding DataFrame locations is missing\nthe result will be missing.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rtruediv.html#pandas.DataFrame.rtruediv"}, {"function_name": "pandas.DataFrame.rmod", "full_function": "DataFrame.rmod(other, axis='columns', level=None, fill_value=None)", "function_text": "Get Modulo of dataframe and other, element-wise (binary operator rmod).", "parameter_names_desc": [{"param_name": "other", "param_type": "scalar, sequence, Series, dict or DataFrame", "param_desc": "Any single or multiple element data structure, or list-like object.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}", "param_desc": "Whether to compare by the index (0 or ‘index’) or columns.\n(1 or ‘columns’). For Series input, axis to match Series index on.\n"}, {"param_name": "level", "param_type": "int or label", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "float or None, default None", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful DataFrame alignment, with this value before computation.\nIf data in both corresponding DataFrame locations is missing\nthe result will be missing.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rmod.html#pandas.DataFrame.rmod"}, {"function_name": "pandas.DataFrame.lt", "full_function": "DataFrame.lt(other, axis='columns', level=None)", "function_text": "Get Less than of dataframe and other, element-wise (binary operator lt).", "parameter_names_desc": [{"param_name": "other", "param_type": "scalar, sequence, Series, or DataFrame", "param_desc": "Any single or multiple element data structure, or list-like object.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default ‘columns’", "param_desc": "Whether to compare by the index (0 or ‘index’) or columns\n(1 or ‘columns’).\n"}, {"param_name": "level", "param_type": "int or label", "param_desc": "Broadcast across a level, matching Index values on the passed\nMultiIndex level.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.lt.html#pandas.DataFrame.lt"}, {"function_name": "pandas.DataFrame.le", "full_function": "DataFrame.le(other, axis='columns', level=None)", "function_text": "Get Less than or equal to of dataframe and other, element-wise (binary operator le).", "parameter_names_desc": [{"param_name": "other", "param_type": "scalar, sequence, Series, or DataFrame", "param_desc": "Any single or multiple element data structure, or list-like object.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default ‘columns’", "param_desc": "Whether to compare by the index (0 or ‘index’) or columns\n(1 or ‘columns’).\n"}, {"param_name": "level", "param_type": "int or label", "param_desc": "Broadcast across a level, matching Index values on the passed\nMultiIndex level.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.le.html#pandas.DataFrame.le"}, {"function_name": "pandas.DataFrame.ne", "full_function": "DataFrame.ne(other, axis='columns', level=None)", "function_text": "Get Not equal to of dataframe and other, element-wise (binary operator ne).", "parameter_names_desc": [{"param_name": "other", "param_type": "scalar, sequence, Series, or DataFrame", "param_desc": "Any single or multiple element data structure, or list-like object.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default ‘columns’", "param_desc": "Whether to compare by the index (0 or ‘index’) or columns\n(1 or ‘columns’).\n"}, {"param_name": "level", "param_type": "int or label", "param_desc": "Broadcast across a level, matching Index values on the passed\nMultiIndex level.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ne.html#pandas.DataFrame.ne"}, {"function_name": "pandas.DataFrame.combine", "full_function": "DataFrame.combine(other, func, fill_value=None, overwrite=True)", "function_text": "Perform column-wise combine with another DataFrame.", "parameter_names_desc": [{"param_name": "other", "param_type": "DataFrame", "param_desc": "The DataFrame to merge column-wise.\n"}, {"param_name": "func", "param_type": "function", "param_desc": "Function that takes two series as inputs and return a Series or a\nscalar. Used to merge the two dataframes column by columns.\n"}, {"param_name": "fill_value", "param_type": "scalar value, default None", "param_desc": "The value to fill NaNs with prior to passing any column to the\nmerge func.\n"}, {"param_name": "overwrite", "param_type": "bool, default True", "param_desc": "If True, columns in self that do not exist in other will be\noverwritten with NaNs.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.combine.html#pandas.DataFrame.combine"}, {"function_name": "pandas.DataFrame.add", "full_function": "DataFrame.add(other, axis='columns', level=None, fill_value=None)", "function_text": "Get Addition of dataframe and other, element-wise (binary operator add).", "parameter_names_desc": [{"param_name": "other", "param_type": "scalar, sequence, Series, dict or DataFrame", "param_desc": "Any single or multiple element data structure, or list-like object.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}", "param_desc": "Whether to compare by the index (0 or ‘index’) or columns.\n(1 or ‘columns’). For Series input, axis to match Series index on.\n"}, {"param_name": "level", "param_type": "int or label", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "float or None, default None", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful DataFrame alignment, with this value before computation.\nIf data in both corresponding DataFrame locations is missing\nthe result will be missing.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add.html#pandas.DataFrame.add"}, {"function_name": "pandas.DataFrame.mul", "full_function": "DataFrame.mul(other, axis='columns', level=None, fill_value=None)", "function_text": "Get Multiplication of dataframe and other, element-wise (binary operator mul).", "parameter_names_desc": [{"param_name": "other", "param_type": "scalar, sequence, Series, dict or DataFrame", "param_desc": "Any single or multiple element data structure, or list-like object.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}", "param_desc": "Whether to compare by the index (0 or ‘index’) or columns.\n(1 or ‘columns’). For Series input, axis to match Series index on.\n"}, {"param_name": "level", "param_type": "int or label", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "float or None, default None", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful DataFrame alignment, with this value before computation.\nIf data in both corresponding DataFrame locations is missing\nthe result will be missing.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mul.html#pandas.DataFrame.mul"}, {"function_name": "pandas.DataFrame.truediv", "full_function": "DataFrame.truediv(other, axis='columns', level=None, fill_value=None)", "function_text": "Get Floating division of dataframe and other, element-wise (binary operator truediv).", "parameter_names_desc": [{"param_name": "other", "param_type": "scalar, sequence, Series, dict or DataFrame", "param_desc": "Any single or multiple element data structure, or list-like object.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}", "param_desc": "Whether to compare by the index (0 or ‘index’) or columns.\n(1 or ‘columns’). For Series input, axis to match Series index on.\n"}, {"param_name": "level", "param_type": "int or label", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "float or None, default None", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful DataFrame alignment, with this value before computation.\nIf data in both corresponding DataFrame locations is missing\nthe result will be missing.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.truediv.html#pandas.DataFrame.truediv"}, {"function_name": "pandas.DataFrame.mod", "full_function": "DataFrame.mod(other, axis='columns', level=None, fill_value=None)", "function_text": "Get Modulo of dataframe and other, element-wise (binary operator mod).", "parameter_names_desc": [{"param_name": "other", "param_type": "scalar, sequence, Series, dict or DataFrame", "param_desc": "Any single or multiple element data structure, or list-like object.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}", "param_desc": "Whether to compare by the index (0 or ‘index’) or columns.\n(1 or ‘columns’). For Series input, axis to match Series index on.\n"}, {"param_name": "level", "param_type": "int or label", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "float or None, default None", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful DataFrame alignment, with this value before computation.\nIf data in both corresponding DataFrame locations is missing\nthe result will be missing.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mod.html#pandas.DataFrame.mod"}, {"function_name": "pandas.DataFrame.dot", "full_function": "DataFrame.dot(other)", "function_text": "Compute the matrix multiplication between the DataFrame and other.", "parameter_names_desc": [{"param_name": "other", "param_type": "Series, DataFrame or array-like", "param_desc": "The other object to compute the matrix product with.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dot.html#pandas.DataFrame.dot"}, {"function_name": "pandas.DataFrame.rsub", "full_function": "DataFrame.rsub(other, axis='columns', level=None, fill_value=None)", "function_text": "Get Subtraction of dataframe and other, element-wise (binary operator rsub).", "parameter_names_desc": [{"param_name": "other", "param_type": "scalar, sequence, Series, dict or DataFrame", "param_desc": "Any single or multiple element data structure, or list-like object.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}", "param_desc": "Whether to compare by the index (0 or ‘index’) or columns.\n(1 or ‘columns’). For Series input, axis to match Series index on.\n"}, {"param_name": "level", "param_type": "int or label", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "float or None, default None", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful DataFrame alignment, with this value before computation.\nIf data in both corresponding DataFrame locations is missing\nthe result will be missing.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rsub.html#pandas.DataFrame.rsub"}, {"function_name": "pandas.DataFrame.rdiv", "full_function": "DataFrame.rdiv(other, axis='columns', level=None, fill_value=None)", "function_text": "Get Floating division of dataframe and other, element-wise (binary operator rtruediv).", "parameter_names_desc": [{"param_name": "other", "param_type": "scalar, sequence, Series, dict or DataFrame", "param_desc": "Any single or multiple element data structure, or list-like object.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}", "param_desc": "Whether to compare by the index (0 or ‘index’) or columns.\n(1 or ‘columns’). For Series input, axis to match Series index on.\n"}, {"param_name": "level", "param_type": "int or label", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "float or None, default None", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful DataFrame alignment, with this value before computation.\nIf data in both corresponding DataFrame locations is missing\nthe result will be missing.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rdiv.html#pandas.DataFrame.rdiv"}, {"function_name": "pandas.DataFrame.rfloordiv", "full_function": "DataFrame.rfloordiv(other, axis='columns', level=None, fill_value=None)", "function_text": "Get Integer division of dataframe and other, element-wise (binary operator rfloordiv).", "parameter_names_desc": [{"param_name": "other", "param_type": "scalar, sequence, Series, dict or DataFrame", "param_desc": "Any single or multiple element data structure, or list-like object.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}", "param_desc": "Whether to compare by the index (0 or ‘index’) or columns.\n(1 or ‘columns’). For Series input, axis to match Series index on.\n"}, {"param_name": "level", "param_type": "int or label", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "float or None, default None", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful DataFrame alignment, with this value before computation.\nIf data in both corresponding DataFrame locations is missing\nthe result will be missing.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rfloordiv.html#pandas.DataFrame.rfloordiv"}, {"function_name": "pandas.DataFrame.rpow", "full_function": "DataFrame.rpow(other, axis='columns', level=None, fill_value=None)", "function_text": "Get Exponential power of dataframe and other, element-wise (binary operator rpow).", "parameter_names_desc": [{"param_name": "other", "param_type": "scalar, sequence, Series, dict or DataFrame", "param_desc": "Any single or multiple element data structure, or list-like object.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}", "param_desc": "Whether to compare by the index (0 or ‘index’) or columns.\n(1 or ‘columns’). For Series input, axis to match Series index on.\n"}, {"param_name": "level", "param_type": "int or label", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "float or None, default None", "param_desc": "Fill existing missing (NaN) values, and any new element needed for\nsuccessful DataFrame alignment, with this value before computation.\nIf data in both corresponding DataFrame locations is missing\nthe result will be missing.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rpow.html#pandas.DataFrame.rpow"}, {"function_name": "pandas.DataFrame.gt", "full_function": "DataFrame.gt(other, axis='columns', level=None)", "function_text": "Get Greater than of dataframe and other, element-wise (binary operator gt).", "parameter_names_desc": [{"param_name": "other", "param_type": "scalar, sequence, Series, or DataFrame", "param_desc": "Any single or multiple element data structure, or list-like object.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default ‘columns’", "param_desc": "Whether to compare by the index (0 or ‘index’) or columns\n(1 or ‘columns’).\n"}, {"param_name": "level", "param_type": "int or label", "param_desc": "Broadcast across a level, matching Index values on the passed\nMultiIndex level.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.gt.html#pandas.DataFrame.gt"}, {"function_name": "pandas.DataFrame.ge", "full_function": "DataFrame.ge(other, axis='columns', level=None)", "function_text": "Get Greater than or equal to of dataframe and other, element-wise (binary operator ge).", "parameter_names_desc": [{"param_name": "other", "param_type": "scalar, sequence, Series, or DataFrame", "param_desc": "Any single or multiple element data structure, or list-like object.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default ‘columns’", "param_desc": "Whether to compare by the index (0 or ‘index’) or columns\n(1 or ‘columns’).\n"}, {"param_name": "level", "param_type": "int or label", "param_desc": "Broadcast across a level, matching Index values on the passed\nMultiIndex level.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ge.html#pandas.DataFrame.ge"}, {"function_name": "pandas.DataFrame.eq", "full_function": "DataFrame.eq(other, axis='columns', level=None)", "function_text": "Get Equal to of dataframe and other, element-wise (binary operator eq).", "parameter_names_desc": [{"param_name": "other", "param_type": "scalar, sequence, Series, or DataFrame", "param_desc": "Any single or multiple element data structure, or list-like object.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default ‘columns’", "param_desc": "Whether to compare by the index (0 or ‘index’) or columns\n(1 or ‘columns’).\n"}, {"param_name": "level", "param_type": "int or label", "param_desc": "Broadcast across a level, matching Index values on the passed\nMultiIndex level.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.eq.html#pandas.DataFrame.eq"}, {"function_name": "pandas.DataFrame.combine_first", "full_function": "DataFrame.combine_first(other)", "function_text": "Update null elements with value in the same location in other.", "parameter_names_desc": [{"param_name": "other", "param_type": "DataFrame", "param_desc": "Provided DataFrame to use to fill null values.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.combine_first.html#pandas.DataFrame.combine_first"}]}, {"name": "Function application, GroupBy & window", "url": "https://pandas.pydata.org/docs/reference/frame.html#function-application-groupby-window", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html#pandas.DataFrame.apply", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.applymap.html#pandas.DataFrame.applymap", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.agg.html#pandas.DataFrame.agg", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.transform.html#pandas.DataFrame.transform", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html#pandas.DataFrame.rolling", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ewm.html#pandas.DataFrame.ewm", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.map.html#pandas.DataFrame.map", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pipe.html#pandas.DataFrame.pipe", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.aggregate.html#pandas.DataFrame.aggregate", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html#pandas.DataFrame.groupby", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.expanding.html#pandas.DataFrame.expanding"], "function_definitions": [{"function_name": "pandas.DataFrame.apply", "full_function": "DataFrame.apply(func, axis=0, raw=False, result_type=None, args=(), by_row='compat', engine='python', engine_kwargs=None, **kwargs)", "function_text": "Apply a function along an axis of the DataFrame.", "parameter_names_desc": [{"param_name": "func", "param_type": "function", "param_desc": "Function to apply to each column or row.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "Axis along which the function is applied:\n\n0 or ‘index’: apply function to each column.\n1 or ‘columns’: apply function to each row.\n\n"}, {"param_name": "raw", "param_type": "bool, default False", "param_desc": "Determines if row or column is passed as a Series or ndarray object:\n\nFalse : passes each row or column as a Series to the\nfunction.\nTrue : the passed function will receive ndarray objects\ninstead.\nIf you are just applying a NumPy reduction function this will\nachieve much better performance.\n\n"}, {"param_name": "result_type", "param_type": "{‘expand’, ‘reduce’, ‘broadcast’, None}, default None", "param_desc": "These only act when axis=1 (columns):\n\n‘expand’ : list-like results will be turned into columns.\n‘reduce’ : returns a Series if possible rather than expanding\nlist-like results. This is the opposite of ‘expand’.\n‘broadcast’ : results will be broadcast to the original shape\nof the DataFrame, the original index and columns will be\nretained.\n\nThe default behaviour (None) depends on the return value of the\napplied function: list-like results will be returned as a Series\nof those. However if the apply function returns a Series these\nare expanded to columns.\n"}, {"param_name": "args", "param_type": "tuple", "param_desc": "Positional arguments to pass to func in addition to the\narray/series.\n"}, {"param_name": "by_row", "param_type": "False or “compat”, default “compat”", "param_desc": "Only has an effect when func is a listlike or dictlike of funcs\nand the func isn’t a string.\nIf “compat”, will if possible first translate the func into pandas\nmethods (e.g. Series().apply(np.sum) will be translated to\nSeries().sum()). If that doesn’t work, will try call to apply again with\nby_row=True and if that fails, will call apply again with\nby_row=False (backward compatible).\nIf False, the funcs will be passed the whole Series at once.\n\nNew in version 2.1.0.\n\n"}, {"param_name": "engine", "param_type": "{‘python’, ‘numba’}, default ‘python’", "param_desc": "Choose between the python (default) engine or the numba engine in apply.\nThe numba engine will attempt to JIT compile the passed function,\nwhich may result in speedups for large DataFrames.\nIt also supports the following engine_kwargs :\n\nnopython (compile the function in nopython mode)\nnogil (release the GIL inside the JIT compiled function)\nparallel (try to apply the function in parallel over the DataFrame)\nNote: Due to limitations within numba/how pandas interfaces with numba,\nyou should only use this if raw=True\n\n\nNote: The numba compiler only supports a subset of\nvalid Python/numpy operations.\nPlease read more about the supported python features\nand supported numpy features\nin numba to learn what you can or cannot use in the passed function.\n\nNew in version 2.2.0.\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict", "param_desc": "Pass keyword arguments to the engine.\nThis is currently only used by the numba engine,\nsee the documentation for the engine argument for more information.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html#pandas.DataFrame.apply"}, {"function_name": "pandas.DataFrame.applymap", "full_function": "DataFrame.applymap(func, na_action=None, **kwargs)", "function_text": "Apply a function to a Dataframe elementwise.", "parameter_names_desc": [{"param_name": "func", "param_type": "callable", "param_desc": "Python function, returns a single value from a single value.\n"}, {"param_name": "na_action", "param_type": "{None, ‘ignore’}, default None", "param_desc": "If ‘ignore’, propagate NaN values, without passing them to func.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.applymap.html#pandas.DataFrame.applymap"}, {"function_name": "pandas.DataFrame.agg", "full_function": "DataFrame.agg(func=None, axis=0, *args, **kwargs)", "function_text": "Aggregate using one or more operations over the specified axis.", "parameter_names_desc": [{"param_name": "func", "param_type": "function, str, list or dict", "param_desc": "Function to use for aggregating the data. If a function, must either\nwork when passed a DataFrame or when passed to DataFrame.apply.\nAccepted combinations are:\n\nfunction\nstring function name\nlist of functions and/or function names, e.g. [np.sum, 'mean']\ndict of axis labels -> functions, function names or list of such.\n\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "If 0 or ‘index’: apply function to each column.\nIf 1 or ‘columns’: apply function to each row.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.agg.html#pandas.DataFrame.agg"}, {"function_name": "pandas.DataFrame.transform", "full_function": "DataFrame.transform(func, axis=0, *args, **kwargs)", "function_text": "Call func on self producing a DataFrame with the same axis shape as self.", "parameter_names_desc": [{"param_name": "ValueError", "param_type": "If the returned DataFrame has a different length than self.", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.transform.html#pandas.DataFrame.transform"}, {"function_name": "pandas.DataFrame.rolling", "full_function": "DataFrame.rolling(window, min_periods=None, center=False, win_type=None, on=None, axis=_NoDefault.no_default, closed=None, step=None, method='single')", "function_text": "Provide rolling window calculations.", "parameter_names_desc": [{"param_name": "window", "param_type": "int, timedelta, str, offset, or BaseIndexer subclass", "param_desc": "Size of the moving window.\nIf an integer, the fixed number of observations used for\neach window.\nIf a timedelta, str, or offset, the time period of each window. Each\nwindow will be a variable sized based on the observations included in\nthe time-period. This is only valid for datetimelike indexes.\nTo learn more about the offsets & frequency strings, please see this link.\nIf a BaseIndexer subclass, the window boundaries\nbased on the defined get_window_bounds method. Additional rolling\nkeyword arguments, namely min_periods, center, closed and\nstep will be passed to get_window_bounds.\n"}, {"param_name": "min_periods", "param_type": "int, default None", "param_desc": "Minimum number of observations in window required to have a value;\notherwise, result is np.nan.\nFor a window that is specified by an offset, min_periods will default to 1.\nFor a window that is specified by an integer, min_periods will default\nto the size of the window.\n"}, {"param_name": "center", "param_type": "bool, default False", "param_desc": "If False, set the window labels as the right edge of the window index.\nIf True, set the window labels as the center of the window index.\n"}, {"param_name": "win_type", "param_type": "str, default None", "param_desc": "If None, all points are evenly weighted.\nIf a string, it must be a valid scipy.signal window function.\nCertain Scipy window types require additional parameters to be passed\nin the aggregation function. The additional parameters must match\nthe keywords specified in the Scipy window type method signature.\n"}, {"param_name": "on", "param_type": "str, optional", "param_desc": "For a DataFrame, a column label or Index level on which\nto calculate the rolling window, rather than the DataFrame’s index.\nProvided integer column is ignored and excluded from result since\nan integer index is not used to calculate the rolling window.\n"}, {"param_name": "axis", "param_type": "int or str, default 0", "param_desc": "If 0 or 'index', roll across the rows.\nIf 1 or 'columns', roll across the columns.\nFor Series this parameter is unused and defaults to 0.\n\nDeprecated since version 2.1.0: The axis keyword is deprecated. For axis=1,\ntranspose the DataFrame first instead.\n\n"}, {"param_name": "closed", "param_type": "str, default None", "param_desc": "If 'right', the first point in the window is excluded from calculations.\nIf 'left', the last point in the window is excluded from calculations.\nIf 'both', the no points in the window are excluded from calculations.\nIf 'neither', the first and last points in the window are excluded\nfrom calculations.\nDefault None ('right').\n"}, {"param_name": "step", "param_type": "int, default None", "param_desc": "\nNew in version 1.5.0.\n\nEvaluate the window at every step result, equivalent to slicing as\n[::step]. window must be an integer. Using a step argument other\nthan None or 1 will produce a result with a different shape than the input.\n"}, {"param_name": "method", "param_type": "str {‘single’, ‘table’}, default ‘single’", "param_desc": "\nNew in version 1.3.0.\n\nExecute the rolling operation per single column or row ('single')\nor over the entire object ('table').\nThis argument is only implemented when specifying engine='numba'\nin the method call.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html#pandas.DataFrame.rolling"}, {"function_name": "pandas.DataFrame.ewm", "full_function": "DataFrame.ewm(com=None, span=None, halflife=None, alpha=None, min_periods=0, adjust=True, ignore_na=False, axis=_NoDefault.no_default, times=None, method='single')", "function_text": "Provide exponentially weighted (EW) calculations.", "parameter_names_desc": [{"param_name": "com", "param_type": "float, optional", "param_desc": "Specify decay in terms of center of mass\n\\(\\alpha = 1 / (1 + com)\\), for \\(com \\geq 0\\).\n"}, {"param_name": "span", "param_type": "float, optional", "param_desc": "Specify decay in terms of span\n\\(\\alpha = 2 / (span + 1)\\), for \\(span \\geq 1\\).\n"}, {"param_name": "halflife", "param_type": "float, str, timedelta, optional", "param_desc": "Specify decay in terms of half-life\n\\(\\alpha = 1 - \\exp\\left(-\\ln(2) / halflife\\right)\\), for\n\\(halflife > 0\\).\nIf times is specified, a timedelta convertible unit over which an\nobservation decays to half its value. Only applicable to mean(),\nand halflife value will not apply to the other functions.\n"}, {"param_name": "alpha", "param_type": "float, optional", "param_desc": "Specify smoothing factor \\(\\alpha\\) directly\n\\(0 < \\alpha \\leq 1\\).\n"}, {"param_name": "min_periods", "param_type": "int, default 0", "param_desc": "Minimum number of observations in window required to have a value;\notherwise, result is np.nan.\n"}, {"param_name": "adjust", "param_type": "bool, default True", "param_desc": "Divide by decaying adjustment factor in beginning periods to account\nfor imbalance in relative weightings (viewing EWMA as a moving average).\n\nWhen adjust=True (default), the EW function is calculated using weights\n\\(w_i = (1 - \\alpha)^i\\). For example, the EW moving average of the series\n[\\(x_0, x_1, ..., x_t\\)] would be:\n\n\n\\[y_t = \\frac{x_t + (1 - \\alpha)x_{t-1} + (1 - \\alpha)^2 x_{t-2} + ... + (1 -\n\\alpha)^t x_0}{1 + (1 - \\alpha) + (1 - \\alpha)^2 + ... + (1 - \\alpha)^t}\\]\n\nWhen adjust=False, the exponentially weighted function is calculated\nrecursively:\n\n\n\\[\\begin{split}\\begin{split}\ny_0 &= x_0\\\\\ny_t &= (1 - \\alpha) y_{t-1} + \\alpha x_t,\n\\end{split}\\end{split}\\]\n"}, {"param_name": "ignore_na", "param_type": "bool, default False", "param_desc": "Ignore missing values when calculating weights.\n\nWhen ignore_na=False (default), weights are based on absolute positions.\nFor example, the weights of \\(x_0\\) and \\(x_2\\) used in calculating\nthe final weighted average of [\\(x_0\\), None, \\(x_2\\)] are\n\\((1-\\alpha)^2\\) and \\(1\\) if adjust=True, and\n\\((1-\\alpha)^2\\) and \\(\\alpha\\) if adjust=False.\nWhen ignore_na=True, weights are based\non relative positions. For example, the weights of \\(x_0\\) and \\(x_2\\)\nused in calculating the final weighted average of\n[\\(x_0\\), None, \\(x_2\\)] are \\(1-\\alpha\\) and \\(1\\) if\nadjust=True, and \\(1-\\alpha\\) and \\(\\alpha\\) if adjust=False.\n\n"}, {"param_name": "axis", "param_type": "{0, 1}, default 0", "param_desc": "If 0 or 'index', calculate across the rows.\nIf 1 or 'columns', calculate across the columns.\nFor Series this parameter is unused and defaults to 0.\n"}, {"param_name": "times", "param_type": "np.ndarray, Series, default None", "param_desc": "Only applicable to mean().\nTimes corresponding to the observations. Must be monotonically increasing and\ndatetime64[ns] dtype.\nIf 1-D array like, a sequence with the same shape as the observations.\n"}, {"param_name": "method", "param_type": "str {‘single’, ‘table’}, default ‘single’", "param_desc": "\nNew in version 1.4.0.\n\nExecute the rolling operation per single column or row ('single')\nor over the entire object ('table').\nThis argument is only implemented when specifying engine='numba'\nin the method call.\nOnly applicable to mean()\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ewm.html#pandas.DataFrame.ewm"}, {"function_name": "pandas.DataFrame.map", "full_function": "DataFrame.map(func, na_action=None, **kwargs)", "function_text": "Apply a function to a Dataframe elementwise.", "parameter_names_desc": [{"param_name": "func", "param_type": "callable", "param_desc": "Python function, returns a single value from a single value.\n"}, {"param_name": "na_action", "param_type": "{None, ‘ignore’}, default None", "param_desc": "If ‘ignore’, propagate NaN values, without passing them to func.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.map.html#pandas.DataFrame.map"}, {"function_name": "pandas.DataFrame.pipe", "full_function": "DataFrame.pipe(func, *args, **kwargs)", "function_text": "Apply chainable functions that expect Series or DataFrames.", "parameter_names_desc": [{"param_name": "func", "param_type": "function", "param_desc": "Function to apply to the Series/DataFrame.\nargs, and kwargs are passed into func.\nAlternatively a (callable, data_keyword) tuple where\ndata_keyword is a string indicating the keyword of\ncallable that expects the Series/DataFrame.\n"}, {"param_name": "*args", "param_type": "iterable, optional", "param_desc": "Positional arguments passed into func.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pipe.html#pandas.DataFrame.pipe"}, {"function_name": "pandas.DataFrame.aggregate", "full_function": "DataFrame.aggregate(func=None, axis=0, *args, **kwargs)", "function_text": "Aggregate using one or more operations over the specified axis.", "parameter_names_desc": [{"param_name": "func", "param_type": "function, str, list or dict", "param_desc": "Function to use for aggregating the data. If a function, must either\nwork when passed a DataFrame or when passed to DataFrame.apply.\nAccepted combinations are:\n\nfunction\nstring function name\nlist of functions and/or function names, e.g. [np.sum, 'mean']\ndict of axis labels -> functions, function names or list of such.\n\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "If 0 or ‘index’: apply function to each column.\nIf 1 or ‘columns’: apply function to each row.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.aggregate.html#pandas.DataFrame.aggregate"}, {"function_name": "pandas.DataFrame.groupby", "full_function": "DataFrame.groupby(by=None, axis=_NoDefault.no_default, level=None, as_index=True, sort=True, group_keys=True, observed=_NoDefault.no_default, dropna=True)", "function_text": "Group DataFrame using a mapper or by a Series of columns.", "parameter_names_desc": [{"param_name": "by", "param_type": "mapping, function, label, pd.Grouper or list of such", "param_desc": "Used to determine the groups for the groupby.\nIf by is a function, it’s called on each value of the object’s\nindex. If a dict or Series is passed, the Series or dict VALUES\nwill be used to determine the groups (the Series’ values are first\naligned; see .align() method). If a list or ndarray of length\nequal to the selected axis is passed (see the groupby user guide),\nthe values are used as-is to determine the groups. A label or list\nof labels may be passed to group by the columns in self.\nNotice that a tuple is interpreted as a (single) key.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "Split along rows (0) or columns (1). For Series this parameter\nis unused and defaults to 0.\n\nDeprecated since version 2.1.0: Will be removed and behave like axis=0 in a future version.\nFor axis=1, do frame.T.groupby(...) instead.\n\n"}, {"param_name": "level", "param_type": "int, level name, or sequence of such, default None", "param_desc": "If the axis is a MultiIndex (hierarchical), group by a particular\nlevel or levels. Do not specify both by and level.\n"}, {"param_name": "as_index", "param_type": "bool, default True", "param_desc": "Return object with group labels as the\nindex. Only relevant for DataFrame input. as_index=False is\neffectively “SQL-style” grouped output. This argument has no effect\non filtrations (see the filtrations in the user guide),\nsuch as head(), tail(), nth() and in transformations\n(see the transformations in the user guide).\n"}, {"param_name": "sort", "param_type": "bool, default True", "param_desc": "Sort group keys. Get better performance by turning this off.\nNote this does not influence the order of observations within each\ngroup. Groupby preserves the order of rows within each group. If False,\nthe groups will appear in the same order as they did in the original DataFrame.\nThis argument has no effect on filtrations (see the filtrations in the user guide),\nsuch as head(), tail(), nth() and in transformations\n(see the transformations in the user guide).\n\nChanged in version 2.0.0: Specifying sort=False with an ordered categorical grouper will no\nlonger sort the values.\n\n"}, {"param_name": "group_keys", "param_type": "bool, default True", "param_desc": "When calling apply and the by argument produces a like-indexed\n(i.e. a transform) result, add group keys to\nindex to identify pieces. By default group keys are not included\nwhen the result’s index (and column) labels match the inputs, and\nare included otherwise.\n\nChanged in version 1.5.0: Warns that group_keys will no longer be ignored when the\nresult from apply is a like-indexed Series or DataFrame.\nSpecify group_keys explicitly to include the group keys or\nnot.\n\n\nChanged in version 2.0.0: group_keys now defaults to True.\n\n"}, {"param_name": "observed", "param_type": "bool, default False", "param_desc": "This only applies if any of the groupers are Categoricals.\nIf True: only show observed values for categorical groupers.\nIf False: show all values for categorical groupers.\n\nDeprecated since version 2.1.0: The default value will change to True in a future version of pandas.\n\n"}, {"param_name": "dropna", "param_type": "bool, default True", "param_desc": "If True, and if group keys contain NA values, NA values together\nwith row/column will be dropped.\nIf False, NA values will also be treated as the key in groups.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html#pandas.DataFrame.groupby"}, {"function_name": "pandas.DataFrame.expanding", "full_function": "DataFrame.expanding(min_periods=1, axis=_NoDefault.no_default, method='single')", "function_text": "Provide expanding window calculations.", "parameter_names_desc": [{"param_name": "min_periods", "param_type": "int, default 1", "param_desc": "Minimum number of observations in window required to have a value;\notherwise, result is np.nan.\n"}, {"param_name": "axis", "param_type": "int or str, default 0", "param_desc": "If 0 or 'index', roll across the rows.\nIf 1 or 'columns', roll across the columns.\nFor Series this parameter is unused and defaults to 0.\n"}, {"param_name": "method", "param_type": "str {‘single’, ‘table’}, default ‘single’", "param_desc": "Execute the rolling operation per single column or row ('single')\nor over the entire object ('table').\nThis argument is only implemented when specifying engine='numba'\nin the method call.\n\nNew in version 1.3.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.expanding.html#pandas.DataFrame.expanding"}]}, {"name": "Computations / descriptive stats", "url": "https://pandas.pydata.org/docs/reference/frame.html#computations-descriptive-stats", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.abs.html#pandas.DataFrame.abs", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.any.html#pandas.DataFrame.any", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html#pandas.DataFrame.corr", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.count.html#pandas.DataFrame.count", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cummax.html#pandas.DataFrame.cummax", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cumprod.html#pandas.DataFrame.cumprod", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html#pandas.DataFrame.describe", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.eval.html#pandas.DataFrame.eval", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.kurtosis.html#pandas.DataFrame.kurtosis", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mean.html#pandas.DataFrame.mean", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.min.html#pandas.DataFrame.min", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pct_change.html#pandas.DataFrame.pct_change", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.product.html#pandas.DataFrame.product", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rank.html#pandas.DataFrame.rank", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sem.html#pandas.DataFrame.sem", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sum.html#pandas.DataFrame.sum", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.var.html#pandas.DataFrame.var", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html#pandas.DataFrame.value_counts", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.all.html#pandas.DataFrame.all", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.clip.html#pandas.DataFrame.clip", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corrwith.html#pandas.DataFrame.corrwith", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cov.html#pandas.DataFrame.cov", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cummin.html#pandas.DataFrame.cummin", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cumsum.html#pandas.DataFrame.cumsum", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.diff.html#pandas.DataFrame.diff", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.kurt.html#pandas.DataFrame.kurt", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.max.html#pandas.DataFrame.max", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.median.html#pandas.DataFrame.median", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mode.html#pandas.DataFrame.mode", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.prod.html#pandas.DataFrame.prod", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.quantile.html#pandas.DataFrame.quantile", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.round.html#pandas.DataFrame.round", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.skew.html#pandas.DataFrame.skew", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.std.html#pandas.DataFrame.std", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nunique.html#pandas.DataFrame.nunique"], "function_definitions": [{"function_name": "pandas.DataFrame.abs", "full_function": "DataFrame.abs()", "function_text": "Return a Series/DataFrame with absolute numeric value of each element.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.abs.html#pandas.DataFrame.abs"}, {"function_name": "pandas.DataFrame.any", "full_function": "DataFrame.any(*, axis=0, bool_only=False, skipna=True, **kwargs)", "function_text": "Return whether any element is True, potentially over an axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’, None}, default 0", "param_desc": "Indicate which axis or axes should be reduced. For Series this parameter\nis unused and defaults to 0.\n\n0 / ‘index’ : reduce the index, return a Series whose index is the\noriginal column labels.\n1 / ‘columns’ : reduce the columns, return a Series whose index is the\noriginal index.\nNone : reduce all axes, return a scalar.\n\n"}, {"param_name": "bool_only", "param_type": "bool, default False", "param_desc": "Include only boolean columns. Not implemented for Series.\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values. If the entire row/column is NA and skipna is\nTrue, then the result will be False, as for an empty row/column.\nIf skipna is False, then NA are treated as True, because these are not\nequal to zero.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.any.html#pandas.DataFrame.any"}, {"function_name": "pandas.DataFrame.corr", "full_function": "DataFrame.corr(method='pearson', min_periods=1, numeric_only=False)", "function_text": "Compute pairwise correlation of columns, excluding NA/null values.", "parameter_names_desc": [{"param_name": "method", "param_type": "{‘pearson’, ‘kendall’, ‘spearman’} or callable", "param_desc": "Method of correlation:\n\npearson : standard correlation coefficient\nkendall : Kendall Tau correlation coefficient\nspearman : Spearman rank correlation\n\ncallable: callable with input two 1d ndarraysand returning a float. Note that the returned matrix from corr\nwill have 1 along the diagonals and will be symmetric\nregardless of the callable’s behavior.\n\n\n\n\n"}, {"param_name": "min_periods", "param_type": "int, optional", "param_desc": "Minimum number of observations required per pair of columns\nto have a valid result. Currently only available for Pearson\nand Spearman correlation.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int or boolean data.\n\nNew in version 1.5.0.\n\n\nChanged in version 2.0.0: The default value of numeric_only is now False.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html#pandas.DataFrame.corr"}, {"function_name": "pandas.DataFrame.count", "full_function": "DataFrame.count(axis=0, numeric_only=False)", "function_text": "Count non-NA cells for each column or row.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "If 0 or ‘index’ counts are generated for each column.\nIf 1 or ‘columns’ counts are generated for each row.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int or boolean data.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.count.html#pandas.DataFrame.count"}, {"function_name": "pandas.DataFrame.cummax", "full_function": "DataFrame.cummax(axis=None, skipna=True, *args, **kwargs)", "function_text": "Return cumulative maximum over a DataFrame or Series axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "The index or the name of the axis. 0 is equivalent to None or ‘index’.\nFor Series this parameter is unused and defaults to 0.\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cummax.html#pandas.DataFrame.cummax"}, {"function_name": "pandas.DataFrame.cumprod", "full_function": "DataFrame.cumprod(axis=None, skipna=True, *args, **kwargs)", "function_text": "Return cumulative product over a DataFrame or Series axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "The index or the name of the axis. 0 is equivalent to None or ‘index’.\nFor Series this parameter is unused and defaults to 0.\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cumprod.html#pandas.DataFrame.cumprod"}, {"function_name": "pandas.DataFrame.describe", "full_function": "DataFrame.describe(percentiles=None, include=None, exclude=None)", "function_text": "Generate descriptive statistics.", "parameter_names_desc": [{"param_name": "percentiles", "param_type": "list-like of numbers, optional", "param_desc": "The percentiles to include in the output. All should\nfall between 0 and 1. The default is\n[.25, .5, .75], which returns the 25th, 50th, and\n75th percentiles.\n"}, {"param_name": "include", "param_type": "‘all’, list-like of dtypes or None (default), optional", "param_desc": "A white list of data types to include in the result. Ignored\nfor Series. Here are the options:\n\n‘all’ : All columns of the input will be included in the output.\nA list-like of dtypes : Limits the results to the\nprovided data types.\nTo limit the result to numeric types submit\nnumpy.number. To limit it instead to object columns submit\nthe numpy.object data type. Strings\ncan also be used in the style of\nselect_dtypes (e.g. df.describe(include=['O'])). To\nselect pandas categorical columns, use 'category'\nNone (default) : The result will include all numeric columns.\n\n"}, {"param_name": "exclude", "param_type": "list-like of dtypes or None (default), optional,", "param_desc": "A black list of data types to omit from the result. Ignored\nfor Series. Here are the options:\n\nA list-like of dtypes : Excludes the provided data types\nfrom the result. To exclude numeric types submit\nnumpy.number. To exclude object columns submit the data\ntype numpy.object. Strings can also be used in the style of\nselect_dtypes (e.g. df.describe(exclude=['O'])). To\nexclude pandas categorical columns, use 'category'\nNone (default) : The result will exclude nothing.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html#pandas.DataFrame.describe"}, {"function_name": "pandas.DataFrame.eval", "full_function": "DataFrame.eval(expr, *, inplace=False, **kwargs)", "function_text": "Evaluate a string describing operations on DataFrame columns.", "parameter_names_desc": [{"param_name": "expr", "param_type": "str", "param_desc": "The expression string to evaluate.\n"}, {"param_name": "inplace", "param_type": "bool, default False", "param_desc": "If the expression contains an assignment, whether to perform the\noperation inplace and mutate the existing DataFrame. Otherwise,\na new DataFrame is returned.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.eval.html#pandas.DataFrame.eval"}, {"function_name": "pandas.DataFrame.kurtosis", "full_function": "DataFrame.kurtosis(axis=0, skipna=True, numeric_only=False, **kwargs)", "function_text": "Return unbiased kurtosis over requested axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{index (0), columns (1)}", "param_desc": "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0.\nFor DataFrames, specifying axis=None will apply the aggregation\nacross both axes.\n\nNew in version 2.0.0.\n\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values when computing the result.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns. Not implemented for Series.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.kurtosis.html#pandas.DataFrame.kurtosis"}, {"function_name": "pandas.DataFrame.mean", "full_function": "DataFrame.mean(axis=0, skipna=True, numeric_only=False, **kwargs)", "function_text": "Return the mean of the values over the requested axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{index (0), columns (1)}", "param_desc": "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0.\nFor DataFrames, specifying axis=None will apply the aggregation\nacross both axes.\n\nNew in version 2.0.0.\n\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values when computing the result.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns. Not implemented for Series.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mean.html#pandas.DataFrame.mean"}, {"function_name": "pandas.DataFrame.min", "full_function": "DataFrame.min(axis=0, skipna=True, numeric_only=False, **kwargs)", "function_text": "Return the minimum of the values over the requested axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{index (0), columns (1)}", "param_desc": "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0.\nFor DataFrames, specifying axis=None will apply the aggregation\nacross both axes.\n\nNew in version 2.0.0.\n\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values when computing the result.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns. Not implemented for Series.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.min.html#pandas.DataFrame.min"}, {"function_name": "pandas.DataFrame.pct_change", "full_function": "DataFrame.pct_change(periods=1, fill_method=_NoDefault.no_default, limit=_NoDefault.no_default, freq=None, **kwargs)", "function_text": "Fractional change between the current and a prior element.", "parameter_names_desc": [{"param_name": "periods", "param_type": "int, default 1", "param_desc": "Periods to shift for forming percent change.\n"}, {"param_name": "fill_method", "param_type": "{‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}, default ‘pad’", "param_desc": "How to handle NAs before computing percent changes.\n\nDeprecated since version 2.1: All options of fill_method are deprecated except fill_method=None.\n\n"}, {"param_name": "limit", "param_type": "int, default None", "param_desc": "The number of consecutive NAs to fill before stopping.\n\nDeprecated since version 2.1.\n\n"}, {"param_name": "freq", "param_type": "DateOffset, timedelta, or str, optional", "param_desc": "Increment to use from time series API (e.g. ‘ME’ or BDay()).\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pct_change.html#pandas.DataFrame.pct_change"}, {"function_name": "pandas.DataFrame.product", "full_function": "DataFrame.product(axis=0, skipna=True, numeric_only=False, min_count=0, **kwargs)", "function_text": "Return the product of the values over the requested axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{index (0), columns (1)}", "param_desc": "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0.\n\nWarning\nThe behavior of DataFrame.prod with axis=None is deprecated,\nin a future version this will reduce over both axes and return a scalar\nTo retain the old behavior, pass axis=0 (or do not pass axis).\n\n\nNew in version 2.0.0.\n\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values when computing the result.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns. Not implemented for Series.\n"}, {"param_name": "min_count", "param_type": "int, default 0", "param_desc": "The required number of valid values to perform the operation. If fewer than\nmin_count non-NA values are present the result will be NA.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.product.html#pandas.DataFrame.product"}, {"function_name": "pandas.DataFrame.rank", "full_function": "DataFrame.rank(axis=0, method='average', numeric_only=False, na_option='keep', ascending=True, pct=False)", "function_text": "Compute numerical data ranks (1 through n) along axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "Index to direct ranking.\nFor Series this parameter is unused and defaults to 0.\n"}, {"param_name": "method", "param_type": "{‘average’, ‘min’, ‘max’, ‘first’, ‘dense’}, default ‘average’", "param_desc": "How to rank the group of records that have the same value (i.e. ties):\n\naverage: average rank of the group\nmin: lowest rank in the group\nmax: highest rank in the group\nfirst: ranks assigned in order they appear in the array\ndense: like ‘min’, but rank always increases by 1 between groups.\n\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "For DataFrame objects, rank only numeric columns if set to True.\n\nChanged in version 2.0.0: The default value of numeric_only is now False.\n\n"}, {"param_name": "na_option", "param_type": "{‘keep’, ‘top’, ‘bottom’}, default ‘keep’", "param_desc": "How to rank NaN values:\n\nkeep: assign NaN rank to NaN values\ntop: assign lowest rank to NaN values\nbottom: assign highest rank to NaN values\n\n"}, {"param_name": "ascending", "param_type": "bool, default True", "param_desc": "Whether or not the elements should be ranked in ascending order.\n"}, {"param_name": "pct", "param_type": "bool, default False", "param_desc": "Whether or not to display the returned rankings in percentile\nform.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rank.html#pandas.DataFrame.rank"}, {"function_name": "pandas.DataFrame.sem", "full_function": "DataFrame.sem(axis=0, skipna=True, ddof=1, numeric_only=False, **kwargs)", "function_text": "Return unbiased standard error of the mean over requested axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{index (0), columns (1)}", "param_desc": "For Series this parameter is unused and defaults to 0.\n\nWarning\nThe behavior of DataFrame.sem with axis=None is deprecated,\nin a future version this will reduce over both axes and return a scalar\nTo retain the old behavior, pass axis=0 (or do not pass axis).\n\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA.\n"}, {"param_name": "ddof", "param_type": "int, default 1", "param_desc": "Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\nwhere N represents the number of elements.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns. Not implemented for Series.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sem.html#pandas.DataFrame.sem"}, {"function_name": "pandas.DataFrame.sum", "full_function": "DataFrame.sum(axis=0, skipna=True, numeric_only=False, min_count=0, **kwargs)", "function_text": "Return the sum of the values over the requested axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{index (0), columns (1)}", "param_desc": "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0.\n\nWarning\nThe behavior of DataFrame.sum with axis=None is deprecated,\nin a future version this will reduce over both axes and return a scalar\nTo retain the old behavior, pass axis=0 (or do not pass axis).\n\n\nNew in version 2.0.0.\n\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values when computing the result.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns. Not implemented for Series.\n"}, {"param_name": "min_count", "param_type": "int, default 0", "param_desc": "The required number of valid values to perform the operation. If fewer than\nmin_count non-NA values are present the result will be NA.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sum.html#pandas.DataFrame.sum"}, {"function_name": "pandas.DataFrame.var", "full_function": "DataFrame.var(axis=0, skipna=True, ddof=1, numeric_only=False, **kwargs)", "function_text": "Return unbiased variance over requested axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{index (0), columns (1)}", "param_desc": "For Series this parameter is unused and defaults to 0.\n\nWarning\nThe behavior of DataFrame.var with axis=None is deprecated,\nin a future version this will reduce over both axes and return a scalar\nTo retain the old behavior, pass axis=0 (or do not pass axis).\n\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA.\n"}, {"param_name": "ddof", "param_type": "int, default 1", "param_desc": "Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\nwhere N represents the number of elements.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns. Not implemented for Series.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.var.html#pandas.DataFrame.var"}, {"function_name": "pandas.DataFrame.value_counts", "full_function": "DataFrame.value_counts(subset=None, normalize=False, sort=True, ascending=False, dropna=True)", "function_text": "Return a Series containing the frequency of each distinct row in the Dataframe.", "parameter_names_desc": [{"param_name": "subset", "param_type": "label or list of labels, optional", "param_desc": "Columns to use when counting unique combinations.\n"}, {"param_name": "normalize", "param_type": "bool, default False", "param_desc": "Return proportions rather than frequencies.\n"}, {"param_name": "sort", "param_type": "bool, default True", "param_desc": "Sort by frequencies when True. Sort by DataFrame column values when False.\n"}, {"param_name": "ascending", "param_type": "bool, default False", "param_desc": "Sort in ascending order.\n"}, {"param_name": "dropna", "param_type": "bool, default True", "param_desc": "Don’t include counts of rows that contain NA values.\n\nNew in version 1.3.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html#pandas.DataFrame.value_counts"}, {"function_name": "pandas.DataFrame.all", "full_function": "DataFrame.all(axis=0, bool_only=False, skipna=True, **kwargs)", "function_text": "Return whether all elements are True, potentially over an axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’, None}, default 0", "param_desc": "Indicate which axis or axes should be reduced. For Series this parameter\nis unused and defaults to 0.\n\n0 / ‘index’ : reduce the index, return a Series whose index is the\noriginal column labels.\n1 / ‘columns’ : reduce the columns, return a Series whose index is the\noriginal index.\nNone : reduce all axes, return a scalar.\n\n"}, {"param_name": "bool_only", "param_type": "bool, default False", "param_desc": "Include only boolean columns. Not implemented for Series.\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values. If the entire row/column is NA and skipna is\nTrue, then the result will be True, as for an empty row/column.\nIf skipna is False, then NA are treated as True, because these are not\nequal to zero.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.all.html#pandas.DataFrame.all"}, {"function_name": "pandas.DataFrame.clip", "full_function": "DataFrame.clip(lower=None, upper=None, *, axis=None, inplace=False, **kwargs)", "function_text": "Trim values at input threshold(s).", "parameter_names_desc": [{"param_name": "lower", "param_type": "float or array-like, default None", "param_desc": "Minimum threshold value. All values below this\nthreshold will be set to it. A missing\nthreshold (e.g NA) will not clip the value.\n"}, {"param_name": "upper", "param_type": "float or array-like, default None", "param_desc": "Maximum threshold value. All values above this\nthreshold will be set to it. A missing\nthreshold (e.g NA) will not clip the value.\n"}, {"param_name": "axis", "param_type": "{{0 or ‘index’, 1 or ‘columns’, None}}, default None", "param_desc": "Align object with lower and upper along the given axis.\nFor Series this parameter is unused and defaults to None.\n"}, {"param_name": "inplace", "param_type": "bool, default False", "param_desc": "Whether to perform the operation in place on the data.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.clip.html#pandas.DataFrame.clip"}, {"function_name": "pandas.DataFrame.corrwith", "full_function": "DataFrame.corrwith(other, axis=0, drop=False, method='pearson', numeric_only=False)", "function_text": "Compute pairwise correlation.", "parameter_names_desc": [{"param_name": "other", "param_type": "DataFrame, Series", "param_desc": "Object with which to compute correlations.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "The axis to use. 0 or ‘index’ to compute row-wise, 1 or ‘columns’ for\ncolumn-wise.\n"}, {"param_name": "drop", "param_type": "bool, default False", "param_desc": "Drop missing indices from result.\n"}, {"param_name": "method", "param_type": "{‘pearson’, ‘kendall’, ‘spearman’} or callable", "param_desc": "Method of correlation:\n\npearson : standard correlation coefficient\nkendall : Kendall Tau correlation coefficient\nspearman : Spearman rank correlation\n\ncallable: callable with input two 1d ndarraysand returning a float.\n\n\n\n\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int or boolean data.\n\nNew in version 1.5.0.\n\n\nChanged in version 2.0.0: The default value of numeric_only is now False.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corrwith.html#pandas.DataFrame.corrwith"}, {"function_name": "pandas.DataFrame.cov", "full_function": "DataFrame.cov(min_periods=None, ddof=1, numeric_only=False)", "function_text": "Compute pairwise covariance of columns, excluding NA/null values.", "parameter_names_desc": [{"param_name": "min_periods", "param_type": "int, optional", "param_desc": "Minimum number of observations required per pair of columns\nto have a valid result.\n"}, {"param_name": "ddof", "param_type": "int, default 1", "param_desc": "Delta degrees of freedom. The divisor used in calculations\nis N - ddof, where N represents the number of elements.\nThis argument is applicable only when no nan is in the dataframe.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int or boolean data.\n\nNew in version 1.5.0.\n\n\nChanged in version 2.0.0: The default value of numeric_only is now False.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cov.html#pandas.DataFrame.cov"}, {"function_name": "pandas.DataFrame.cummin", "full_function": "DataFrame.cummin(axis=None, skipna=True, *args, **kwargs)", "function_text": "Return cumulative minimum over a DataFrame or Series axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "The index or the name of the axis. 0 is equivalent to None or ‘index’.\nFor Series this parameter is unused and defaults to 0.\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cummin.html#pandas.DataFrame.cummin"}, {"function_name": "pandas.DataFrame.cumsum", "full_function": "DataFrame.cumsum(axis=None, skipna=True, *args, **kwargs)", "function_text": "Return cumulative sum over a DataFrame or Series axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "The index or the name of the axis. 0 is equivalent to None or ‘index’.\nFor Series this parameter is unused and defaults to 0.\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cumsum.html#pandas.DataFrame.cumsum"}, {"function_name": "pandas.DataFrame.diff", "full_function": "DataFrame.diff(periods=1, axis=0)", "function_text": "First discrete difference of element.", "parameter_names_desc": [{"param_name": "periods", "param_type": "int, default 1", "param_desc": "Periods to shift for calculating difference, accepts negative\nvalues.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "Take difference over rows (0) or columns (1).\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.diff.html#pandas.DataFrame.diff"}, {"function_name": "pandas.DataFrame.kurt", "full_function": "DataFrame.kurt(axis=0, skipna=True, numeric_only=False, **kwargs)", "function_text": "Return unbiased kurtosis over requested axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{index (0), columns (1)}", "param_desc": "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0.\nFor DataFrames, specifying axis=None will apply the aggregation\nacross both axes.\n\nNew in version 2.0.0.\n\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values when computing the result.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns. Not implemented for Series.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.kurt.html#pandas.DataFrame.kurt"}, {"function_name": "pandas.DataFrame.max", "full_function": "DataFrame.max(axis=0, skipna=True, numeric_only=False, **kwargs)", "function_text": "Return the maximum of the values over the requested axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{index (0), columns (1)}", "param_desc": "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0.\nFor DataFrames, specifying axis=None will apply the aggregation\nacross both axes.\n\nNew in version 2.0.0.\n\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values when computing the result.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns. Not implemented for Series.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.max.html#pandas.DataFrame.max"}, {"function_name": "pandas.DataFrame.median", "full_function": "DataFrame.median(axis=0, skipna=True, numeric_only=False, **kwargs)", "function_text": "Return the median of the values over the requested axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{index (0), columns (1)}", "param_desc": "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0.\nFor DataFrames, specifying axis=None will apply the aggregation\nacross both axes.\n\nNew in version 2.0.0.\n\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values when computing the result.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns. Not implemented for Series.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.median.html#pandas.DataFrame.median"}, {"function_name": "pandas.DataFrame.mode", "full_function": "DataFrame.mode(axis=0, numeric_only=False, dropna=True)", "function_text": "Get the mode(s) of each element along the selected axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "The axis to iterate over while searching for the mode:\n\n0 or ‘index’ : get mode of each column\n1 or ‘columns’ : get mode of each row.\n\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "If True, only apply to numeric columns.\n"}, {"param_name": "dropna", "param_type": "bool, default True", "param_desc": "Don’t consider counts of NaN/NaT.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mode.html#pandas.DataFrame.mode"}, {"function_name": "pandas.DataFrame.prod", "full_function": "DataFrame.prod(axis=0, skipna=True, numeric_only=False, min_count=0, **kwargs)", "function_text": "Return the product of the values over the requested axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{index (0), columns (1)}", "param_desc": "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0.\n\nWarning\nThe behavior of DataFrame.prod with axis=None is deprecated,\nin a future version this will reduce over both axes and return a scalar\nTo retain the old behavior, pass axis=0 (or do not pass axis).\n\n\nNew in version 2.0.0.\n\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values when computing the result.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns. Not implemented for Series.\n"}, {"param_name": "min_count", "param_type": "int, default 0", "param_desc": "The required number of valid values to perform the operation. If fewer than\nmin_count non-NA values are present the result will be NA.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.prod.html#pandas.DataFrame.prod"}, {"function_name": "pandas.DataFrame.quantile", "full_function": "DataFrame.quantile(q=0.5, axis=0, numeric_only=False, interpolation='linear', method='single')", "function_text": "Return values at the given quantile over requested axis.", "parameter_names_desc": [{"param_name": "q", "param_type": "float or array-like, default 0.5 (50% quantile)", "param_desc": "Value between 0 <= q <= 1, the quantile(s) to compute.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "Equals 0 or ‘index’ for row-wise, 1 or ‘columns’ for column-wise.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int or boolean data.\n\nChanged in version 2.0.0: The default value of numeric_only is now False.\n\n"}, {"param_name": "interpolation", "param_type": "{‘linear’, ‘lower’, ‘higher’, ‘midpoint’, ‘nearest’}", "param_desc": "This optional parameter specifies the interpolation method to use,\nwhen the desired quantile lies between two data points i and j:\n\nlinear: i + (j - i) * fraction, where fraction is the\nfractional part of the index surrounded by i and j.\nlower: i.\nhigher: j.\nnearest: i or j whichever is nearest.\nmidpoint: (i + j) / 2.\n\n"}, {"param_name": "method", "param_type": "{‘single’, ‘table’}, default ‘single’", "param_desc": "Whether to compute quantiles per-column (‘single’) or over all columns\n(‘table’). When ‘table’, the only allowed interpolation methods are\n‘nearest’, ‘lower’, and ‘higher’.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.quantile.html#pandas.DataFrame.quantile"}, {"function_name": "pandas.DataFrame.round", "full_function": "DataFrame.round(decimals=0, *args, **kwargs)", "function_text": "Round a DataFrame to a variable number of decimal places.", "parameter_names_desc": [{"param_name": "decimals", "param_type": "int, dict, Series", "param_desc": "Number of decimal places to round each column to. If an int is\ngiven, round each column to the same number of places.\nOtherwise dict and Series round to variable numbers of places.\nColumn names should be in the keys if decimals is a\ndict-like, or in the index if decimals is a Series. Any\ncolumns not included in decimals will be left as is. Elements\nof decimals which are not columns of the input will be\nignored.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.round.html#pandas.DataFrame.round"}, {"function_name": "pandas.DataFrame.skew", "full_function": "DataFrame.skew(axis=0, skipna=True, numeric_only=False, **kwargs)", "function_text": "Return unbiased skew over requested axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{index (0), columns (1)}", "param_desc": "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0.\nFor DataFrames, specifying axis=None will apply the aggregation\nacross both axes.\n\nNew in version 2.0.0.\n\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values when computing the result.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns. Not implemented for Series.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.skew.html#pandas.DataFrame.skew"}, {"function_name": "pandas.DataFrame.std", "full_function": "DataFrame.std(axis=0, skipna=True, ddof=1, numeric_only=False, **kwargs)", "function_text": "Return sample standard deviation over requested axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{index (0), columns (1)}", "param_desc": "For Series this parameter is unused and defaults to 0.\n\nWarning\nThe behavior of DataFrame.std with axis=None is deprecated,\nin a future version this will reduce over both axes and return a scalar\nTo retain the old behavior, pass axis=0 (or do not pass axis).\n\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA.\n"}, {"param_name": "ddof", "param_type": "int, default 1", "param_desc": "Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\nwhere N represents the number of elements.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns. Not implemented for Series.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.std.html#pandas.DataFrame.std"}, {"function_name": "pandas.DataFrame.nunique", "full_function": "DataFrame.nunique(axis=0, dropna=True)", "function_text": "Count number of distinct elements in specified axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "The axis to use. 0 or ‘index’ for row-wise, 1 or ‘columns’ for\ncolumn-wise.\n"}, {"param_name": "dropna", "param_type": "bool, default True", "param_desc": "Don’t include NaN in the counts.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nunique.html#pandas.DataFrame.nunique"}]}, {"name": "Reindexing / selection / label manipulation", "url": "https://pandas.pydata.org/docs/reference/frame.html#reindexing-selection-label-manipulation", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add_prefix.html#pandas.DataFrame.add_prefix", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.align.html#pandas.DataFrame.align", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.between_time.html#pandas.DataFrame.between_time", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html#pandas.DataFrame.drop_duplicates", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.equals.html#pandas.DataFrame.equals", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.first.html#pandas.DataFrame.first", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.idxmax.html#pandas.DataFrame.idxmax", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.last.html#pandas.DataFrame.last", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reindex_like.html#pandas.DataFrame.reindex_like", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename_axis.html#pandas.DataFrame.rename_axis", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html#pandas.DataFrame.sample", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_index.html#pandas.DataFrame.set_index", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.take.html#pandas.DataFrame.take", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add_suffix.html#pandas.DataFrame.add_suffix", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.at_time.html#pandas.DataFrame.at_time", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html#pandas.DataFrame.drop", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html#pandas.DataFrame.duplicated", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.filter.html#pandas.DataFrame.filter", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html#pandas.DataFrame.head", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.idxmin.html#pandas.DataFrame.idxmin", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reindex.html#pandas.DataFrame.reindex", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html#pandas.DataFrame.rename", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html#pandas.DataFrame.reset_index", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_axis.html#pandas.DataFrame.set_axis", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tail.html#pandas.DataFrame.tail", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.truncate.html#pandas.DataFrame.truncate"], "function_definitions": [{"function_name": "pandas.DataFrame.add_prefix", "full_function": "DataFrame.add_prefix(prefix, axis=None)", "function_text": "Prefix labels with string prefix.", "parameter_names_desc": [{"param_name": "prefix", "param_type": "str", "param_desc": "The string to add before each label.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’, None}, default None", "param_desc": "Axis to add prefix on\n\nNew in version 2.0.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add_prefix.html#pandas.DataFrame.add_prefix"}, {"function_name": "pandas.DataFrame.align", "full_function": "DataFrame.align(other, join='outer', axis=None, level=None, copy=None, fill_value=None, method=_NoDefault.no_default, limit=_NoDefault.no_default, fill_axis=_NoDefault.no_default, broadcast_axis=_NoDefault.no_default)", "function_text": "Align two objects on their axes with the specified join method.", "parameter_names_desc": [{"param_name": "other", "param_type": "DataFrame or Series", "param_desc": ""}, {"param_name": "join", "param_type": "{‘outer’, ‘inner’, ‘left’, ‘right’}, default ‘outer’", "param_desc": "Type of alignment to be performed.\n\nleft: use only keys from left frame, preserve key order.\nright: use only keys from right frame, preserve key order.\nouter: use union of keys from both frames, sort keys lexicographically.\ninner: use intersection of keys from both frames,\npreserve the order of the left keys.\n\n"}, {"param_name": "axis", "param_type": "allowed axis of the other object, default None", "param_desc": "Align on index (0), columns (1), or both (None).\n"}, {"param_name": "level", "param_type": "int or level name, default None", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "copy", "param_type": "bool, default True", "param_desc": "Always returns new objects. If copy=False and no reindexing is\nrequired then original objects are returned.\n\nNote\nThe copy keyword will change behavior in pandas 3.0.\nCopy-on-Write\nwill be enabled by default, which means that all methods with a\ncopy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas.\nYou can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True\n\n"}, {"param_name": "fill_value", "param_type": "scalar, default np.nan", "param_desc": "Value to use for missing values. Defaults to NaN, but can be any\n“compatible” value.\n"}, {"param_name": "method", "param_type": "{‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}, default None", "param_desc": "Method to use for filling holes in reindexed Series:\n\npad / ffill: propagate last valid observation forward to next valid.\nbackfill / bfill: use NEXT valid observation to fill gap.\n\n\nDeprecated since version 2.1.\n\n"}, {"param_name": "limit", "param_type": "int, default None", "param_desc": "If method is specified, this is the maximum number of consecutive\nNaN values to forward/backward fill. In other words, if there is\na gap with more than this number of consecutive NaNs, it will only\nbe partially filled. If method is not specified, this is the\nmaximum number of entries along the entire axis where NaNs will be\nfilled. Must be greater than 0 if not None.\n\nDeprecated since version 2.1.\n\n"}, {"param_name": "fill_axis", "param_type": "{0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame, default 0", "param_desc": "Filling axis, method and limit.\n\nDeprecated since version 2.1.\n\n"}, {"param_name": "broadcast_axis", "param_type": "{0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame, default None", "param_desc": "Broadcast values along this axis, if aligning two objects of\ndifferent dimensions.\n\nDeprecated since version 2.1.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.align.html#pandas.DataFrame.align"}, {"function_name": "pandas.DataFrame.between_time", "full_function": "DataFrame.between_time(start_time, end_time, inclusive='both', axis=None)", "function_text": "Select values between particular times of the day (e.g., 9:00-9:30 AM).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.between_time.html#pandas.DataFrame.between_time"}, {"function_name": "pandas.DataFrame.drop_duplicates", "full_function": "DataFrame.drop_duplicates(subset=None, *, keep='first', inplace=False, ignore_index=False)", "function_text": "Return DataFrame with duplicate rows removed.", "parameter_names_desc": [{"param_name": "subset", "param_type": "column label or sequence of labels, optional", "param_desc": "Only consider certain columns for identifying duplicates, by\ndefault use all of the columns.\n"}, {"param_name": "keep", "param_type": "{‘first’, ‘last’, False}, default ‘first’", "param_desc": "Determines which duplicates (if any) to keep.\n\n‘first’ : Drop duplicates except for the first occurrence.\n‘last’ : Drop duplicates except for the last occurrence.\nFalse : Drop all duplicates.\n\n"}, {"param_name": "inplace", "param_type": "bool, default False", "param_desc": "Whether to modify the DataFrame rather than creating a new one.\n"}, {"param_name": "ignore_index", "param_type": "bool, default False", "param_desc": "If True, the resulting axis will be labeled 0, 1, …, n - 1.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html#pandas.DataFrame.drop_duplicates"}, {"function_name": "pandas.DataFrame.equals", "full_function": "DataFrame.equals(other)", "function_text": "Test whether two objects contain the same elements.", "parameter_names_desc": [{"param_name": "other", "param_type": "Series or DataFrame", "param_desc": "The other Series or DataFrame to be compared with the first.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.equals.html#pandas.DataFrame.equals"}, {"function_name": "pandas.DataFrame.first", "full_function": "DataFrame.first(offset)", "function_text": "Select initial periods of time series data based on a date offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.first.html#pandas.DataFrame.first"}, {"function_name": "pandas.DataFrame.idxmax", "full_function": "DataFrame.idxmax(axis=0, skipna=True, numeric_only=False)", "function_text": "Return index of first occurrence of maximum over requested axis.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.idxmax.html#pandas.DataFrame.idxmax"}, {"function_name": "pandas.DataFrame.last", "full_function": "DataFrame.last(offset)", "function_text": "Select final periods of time series data based on a date offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.last.html#pandas.DataFrame.last"}, {"function_name": "pandas.DataFrame.reindex_like", "full_function": "DataFrame.reindex_like(other, method=None, copy=None, limit=None, tolerance=None)", "function_text": "Return an object with matching indices as other object.", "parameter_names_desc": [{"param_name": "other", "param_type": "Object of the same data type", "param_desc": "Its row and column indices are used to define the new indices\nof this object.\n"}, {"param_name": "method", "param_type": "{None, ‘backfill’/’bfill’, ‘pad’/’ffill’, ‘nearest’}", "param_desc": "Method to use for filling holes in reindexed DataFrame.\nPlease note: this is only applicable to DataFrames/Series with a\nmonotonically increasing/decreasing index.\n\nNone (default): don’t fill gaps\npad / ffill: propagate last valid observation forward to next\nvalid\nbackfill / bfill: use next valid observation to fill gap\nnearest: use nearest valid observations to fill gap.\n\n"}, {"param_name": "copy", "param_type": "bool, default True", "param_desc": "Return a new object, even if the passed indexes are the same.\n\nNote\nThe copy keyword will change behavior in pandas 3.0.\nCopy-on-Write\nwill be enabled by default, which means that all methods with a\ncopy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas.\nYou can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True\n\n"}, {"param_name": "limit", "param_type": "int, default None", "param_desc": "Maximum number of consecutive labels to fill for inexact matches.\n"}, {"param_name": "tolerance", "param_type": "optional", "param_desc": "Maximum distance between original and new labels for inexact\nmatches. The values of the index at the matching locations must\nsatisfy the equation abs(index[indexer] - target) <= tolerance.\nTolerance may be a scalar value, which applies the same tolerance\nto all values, or list-like, which applies variable tolerance per\nelement. List-like includes list, tuple, array, Series, and must be\nthe same size as the index and its dtype must exactly match the\nindex’s type.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reindex_like.html#pandas.DataFrame.reindex_like"}, {"function_name": "pandas.DataFrame.rename_axis", "full_function": "DataFrame.rename_axis(mapper=_NoDefault.no_default, *, index=_NoDefault.no_default, columns=_NoDefault.no_default, axis=0, copy=None, inplace=False)", "function_text": "Set the name of the axis for the index or columns.", "parameter_names_desc": [{"param_name": "mapper", "param_type": "scalar, list-like, optional", "param_desc": "Value to set the axis name attribute.\n"}, {"param_name": "index, columns", "param_type": "scalar, list-like, dict-like or function, optional", "param_desc": "A scalar, list-like, dict-like or functions transformations to\napply to that axis’ values.\nNote that the columns parameter is not allowed if the\nobject is a Series. This parameter only apply for DataFrame\ntype objects.\nUse either mapper and axis to\nspecify the axis to target with mapper, or index\nand/or columns.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "The axis to rename. For Series this parameter is unused and defaults to 0.\n"}, {"param_name": "copy", "param_type": "bool, default None", "param_desc": "Also copy underlying data.\n\nNote\nThe copy keyword will change behavior in pandas 3.0.\nCopy-on-Write\nwill be enabled by default, which means that all methods with a\ncopy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas.\nYou can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True\n\n"}, {"param_name": "inplace", "param_type": "bool, default False", "param_desc": "Modifies the object directly, instead of creating a new Series\nor DataFrame.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename_axis.html#pandas.DataFrame.rename_axis"}, {"function_name": "pandas.DataFrame.sample", "full_function": "DataFrame.sample(n=None, frac=None, replace=False, weights=None, random_state=None, axis=None, ignore_index=False)", "function_text": "Return a random sample of items from an axis of object.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, optional", "param_desc": "Number of items from axis to return. Cannot be used with frac.\nDefault = 1 if frac = None.\n"}, {"param_name": "frac", "param_type": "float, optional", "param_desc": "Fraction of axis items to return. Cannot be used with n.\n"}, {"param_name": "replace", "param_type": "bool, default False", "param_desc": "Allow or disallow sampling of the same row more than once.\n"}, {"param_name": "weights", "param_type": "str or ndarray-like, optional", "param_desc": "Default ‘None’ results in equal probability weighting.\nIf passed a Series, will align with target object on index. Index\nvalues in weights not found in sampled object will be ignored and\nindex values in sampled object not in weights will be assigned\nweights of zero.\nIf called on a DataFrame, will accept the name of a column\nwhen axis = 0.\nUnless weights are a Series, weights must be same length as axis\nbeing sampled.\nIf weights do not sum to 1, they will be normalized to sum to 1.\nMissing values in the weights column will be treated as zero.\nInfinite values not allowed.\n"}, {"param_name": "random_state", "param_type": "int, array-like, BitGenerator, np.random.RandomState, np.random.Generator, optional", "param_desc": "If int, array-like, or BitGenerator, seed for random number generator.\nIf np.random.RandomState or np.random.Generator, use as given.\n\nChanged in version 1.4.0: np.random.Generator objects now accepted\n\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’, None}, default None", "param_desc": "Axis to sample. Accepts axis number or name. Default is stat axis\nfor given data type. For Series this parameter is unused and defaults to None.\n"}, {"param_name": "ignore_index", "param_type": "bool, default False", "param_desc": "If True, the resulting index will be labeled 0, 1, …, n - 1.\n\nNew in version 1.3.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html#pandas.DataFrame.sample"}, {"function_name": "pandas.DataFrame.set_index", "full_function": "DataFrame.set_index(keys, *, drop=True, append=False, inplace=False, verify_integrity=False)", "function_text": "Set the DataFrame index using existing columns.", "parameter_names_desc": [{"param_name": "keys", "param_type": "label or array-like or list of labels/arrays", "param_desc": "This parameter can be either a single column key, a single array of\nthe same length as the calling DataFrame, or a list containing an\narbitrary combination of column keys and arrays. Here, “array”\nencompasses Series, Index, np.ndarray, and\ninstances of Iterator.\n"}, {"param_name": "drop", "param_type": "bool, default True", "param_desc": "Delete columns to be used as the new index.\n"}, {"param_name": "append", "param_type": "bool, default False", "param_desc": "Whether to append columns to existing index.\n"}, {"param_name": "inplace", "param_type": "bool, default False", "param_desc": "Whether to modify the DataFrame rather than creating a new one.\n"}, {"param_name": "verify_integrity", "param_type": "bool, default False", "param_desc": "Check the new index for duplicates. Otherwise defer the check until\nnecessary. Setting to False will improve the performance of this\nmethod.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_index.html#pandas.DataFrame.set_index"}, {"function_name": "pandas.DataFrame.take", "full_function": "DataFrame.take(indices, axis=0, **kwargs)", "function_text": "Return the elements in the given positional indices along an axis.", "parameter_names_desc": [{"param_name": "indices", "param_type": "array-like", "param_desc": "An array of ints indicating which positions to take.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’, None}, default 0", "param_desc": "The axis on which to select elements. 0 means that we are\nselecting rows, 1 means that we are selecting columns.\nFor Series this parameter is unused and defaults to 0.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.take.html#pandas.DataFrame.take"}, {"function_name": "pandas.DataFrame.add_suffix", "full_function": "DataFrame.add_suffix(suffix, axis=None)", "function_text": "Suffix labels with string suffix.", "parameter_names_desc": [{"param_name": "suffix", "param_type": "str", "param_desc": "The string to add after each label.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’, None}, default None", "param_desc": "Axis to add suffix on\n\nNew in version 2.0.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add_suffix.html#pandas.DataFrame.add_suffix"}, {"function_name": "pandas.DataFrame.at_time", "full_function": "DataFrame.at_time(time, asof=False, axis=None)", "function_text": "Select values at particular time of day (e.g., 9:30AM).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.at_time.html#pandas.DataFrame.at_time"}, {"function_name": "pandas.DataFrame.drop", "full_function": "DataFrame.drop(labels=None, *, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')", "function_text": "Drop specified labels from rows or columns.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html#pandas.DataFrame.drop"}, {"function_name": "pandas.DataFrame.duplicated", "full_function": "DataFrame.duplicated(subset=None, keep='first')", "function_text": "Return boolean Series denoting duplicate rows.", "parameter_names_desc": [{"param_name": "subset", "param_type": "column label or sequence of labels, optional", "param_desc": "Only consider certain columns for identifying duplicates, by\ndefault use all of the columns.\n"}, {"param_name": "keep", "param_type": "{‘first’, ‘last’, False}, default ‘first’", "param_desc": "Determines which duplicates (if any) to mark.\n\nfirst : Mark duplicates as True except for the first occurrence.\nlast : Mark duplicates as True except for the last occurrence.\nFalse : Mark all duplicates as True.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html#pandas.DataFrame.duplicated"}, {"function_name": "pandas.DataFrame.filter", "full_function": "DataFrame.filter(items=None, like=None, regex=None, axis=None)", "function_text": "Subset the dataframe rows or columns according to the specified index labels.", "parameter_names_desc": [{"param_name": "items", "param_type": "list-like", "param_desc": "Keep labels from axis which are in items.\n"}, {"param_name": "like", "param_type": "str", "param_desc": "Keep labels from axis for which “like in label == True”.\n"}, {"param_name": "regex", "param_type": "str (regular expression)", "param_desc": "Keep labels from axis for which re.search(regex, label) == True.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’, None}, default None", "param_desc": "The axis to filter on, expressed either as an index (int)\nor axis name (str). By default this is the info axis, ‘columns’ for\nDataFrame. For Series this parameter is unused and defaults to None.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.filter.html#pandas.DataFrame.filter"}, {"function_name": "pandas.DataFrame.head", "full_function": "DataFrame.head(n=5)", "function_text": "Return the first n rows.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 5", "param_desc": "Number of rows to select.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html#pandas.DataFrame.head"}, {"function_name": "pandas.DataFrame.idxmin", "full_function": "DataFrame.idxmin(axis=0, skipna=True, numeric_only=False)", "function_text": "Return index of first occurrence of minimum over requested axis.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.idxmin.html#pandas.DataFrame.idxmin"}, {"function_name": "pandas.DataFrame.reindex", "full_function": "DataFrame.reindex(labels=None, *, index=None, columns=None, axis=None, method=None, copy=None, level=None, fill_value=nan, limit=None, tolerance=None)", "function_text": "Conform DataFrame to new index with optional filling logic.", "parameter_names_desc": [{"param_name": "labels", "param_type": "array-like, optional", "param_desc": "New labels / index to conform the axis specified by ‘axis’ to.\n"}, {"param_name": "index", "param_type": "array-like, optional", "param_desc": "New labels for the index. Preferably an Index object to avoid\nduplicating data.\n"}, {"param_name": "columns", "param_type": "array-like, optional", "param_desc": "New labels for the columns. Preferably an Index object to avoid\nduplicating data.\n"}, {"param_name": "axis", "param_type": "int or str, optional", "param_desc": "Axis to target. Can be either the axis name (‘index’, ‘columns’)\nor number (0, 1).\n"}, {"param_name": "method", "param_type": "{None, ‘backfill’/’bfill’, ‘pad’/’ffill’, ‘nearest’}", "param_desc": "Method to use for filling holes in reindexed DataFrame.\nPlease note: this is only applicable to DataFrames/Series with a\nmonotonically increasing/decreasing index.\n\nNone (default): don’t fill gaps\npad / ffill: Propagate last valid observation forward to next\nvalid.\nbackfill / bfill: Use next valid observation to fill gap.\nnearest: Use nearest valid observations to fill gap.\n\n"}, {"param_name": "copy", "param_type": "bool, default True", "param_desc": "Return a new object, even if the passed indexes are the same.\n\nNote\nThe copy keyword will change behavior in pandas 3.0.\nCopy-on-Write\nwill be enabled by default, which means that all methods with a\ncopy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas.\nYou can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True\n\n"}, {"param_name": "level", "param_type": "int or name", "param_desc": "Broadcast across a level, matching Index values on the\npassed MultiIndex level.\n"}, {"param_name": "fill_value", "param_type": "scalar, default np.nan", "param_desc": "Value to use for missing values. Defaults to NaN, but can be any\n“compatible” value.\n"}, {"param_name": "limit", "param_type": "int, default None", "param_desc": "Maximum number of consecutive elements to forward or backward fill.\n"}, {"param_name": "tolerance", "param_type": "optional", "param_desc": "Maximum distance between original and new labels for inexact\nmatches. The values of the index at the matching locations most\nsatisfy the equation abs(index[indexer] - target) <= tolerance.\nTolerance may be a scalar value, which applies the same tolerance\nto all values, or list-like, which applies variable tolerance per\nelement. List-like includes list, tuple, array, Series, and must be\nthe same size as the index and its dtype must exactly match the\nindex’s type.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reindex.html#pandas.DataFrame.reindex"}, {"function_name": "pandas.DataFrame.rename", "full_function": "DataFrame.rename(mapper=None, *, index=None, columns=None, axis=None, copy=None, inplace=False, level=None, errors='ignore')", "function_text": "Rename columns or index labels.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html#pandas.DataFrame.rename"}, {"function_name": "pandas.DataFrame.reset_index", "full_function": "DataFrame.reset_index(level=None, *, drop=False, inplace=False, col_level=0, col_fill='', allow_duplicates=_NoDefault.no_default, names=None)", "function_text": "Reset the index, or a level of it.", "parameter_names_desc": [{"param_name": "level", "param_type": "int, str, tuple, or list, default None", "param_desc": "Only remove the given levels from the index. Removes all levels by\ndefault.\n"}, {"param_name": "drop", "param_type": "bool, default False", "param_desc": "Do not try to insert index into dataframe columns. This resets\nthe index to the default integer index.\n"}, {"param_name": "inplace", "param_type": "bool, default False", "param_desc": "Whether to modify the DataFrame rather than creating a new one.\n"}, {"param_name": "col_level", "param_type": "int or str, default 0", "param_desc": "If the columns have multiple levels, determines which level the\nlabels are inserted into. By default it is inserted into the first\nlevel.\n"}, {"param_name": "col_fill", "param_type": "object, default ‘’", "param_desc": "If the columns have multiple levels, determines how the other\nlevels are named. If None then the index name is repeated.\n"}, {"param_name": "allow_duplicates", "param_type": "bool, optional, default lib.no_default", "param_desc": "Allow duplicate column labels to be created.\n\nNew in version 1.5.0.\n\n"}, {"param_name": "names", "param_type": "int, str or 1-dimensional list, default None", "param_desc": "Using the given string, rename the DataFrame column which contains the\nindex data. If the DataFrame has a MultiIndex, this has to be a list or\ntuple with length equal to the number of levels.\n\nNew in version 1.5.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html#pandas.DataFrame.reset_index"}, {"function_name": "pandas.DataFrame.set_axis", "full_function": "DataFrame.set_axis(labels, *, axis=0, copy=None)", "function_text": "Assign desired index to given axis.", "parameter_names_desc": [{"param_name": "labels", "param_type": "list-like, Index", "param_desc": "The values for the new index.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "The axis to update. The value 0 identifies the rows. For Series\nthis parameter is unused and defaults to 0.\n"}, {"param_name": "copy", "param_type": "bool, default True", "param_desc": "Whether to make a copy of the underlying data.\n\nNote\nThe copy keyword will change behavior in pandas 3.0.\nCopy-on-Write\nwill be enabled by default, which means that all methods with a\ncopy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas.\nYou can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_axis.html#pandas.DataFrame.set_axis"}, {"function_name": "pandas.DataFrame.tail", "full_function": "DataFrame.tail(n=5)", "function_text": "Return the last n rows.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 5", "param_desc": "Number of rows to select.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tail.html#pandas.DataFrame.tail"}, {"function_name": "pandas.DataFrame.truncate", "full_function": "DataFrame.truncate(before=None, after=None, axis=None, copy=None)", "function_text": "Truncate a Series or DataFrame before and after some index value.", "parameter_names_desc": [{"param_name": "before", "param_type": "date, str, int", "param_desc": "Truncate all rows before this index value.\n"}, {"param_name": "after", "param_type": "date, str, int", "param_desc": "Truncate all rows after this index value.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, optional", "param_desc": "Axis to truncate. Truncates the index (rows) by default.\nFor Series this parameter is unused and defaults to 0.\n"}, {"param_name": "copy", "param_type": "bool, default is True,", "param_desc": "Return a copy of the truncated section.\n\nNote\nThe copy keyword will change behavior in pandas 3.0.\nCopy-on-Write\nwill be enabled by default, which means that all methods with a\ncopy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas.\nYou can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.truncate.html#pandas.DataFrame.truncate"}]}, {"name": "Missing data handling", "url": "https://pandas.pydata.org/docs/reference/frame.html#missing-data-handling", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.backfill.html#pandas.DataFrame.backfill", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html#pandas.DataFrame.dropna", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html#pandas.DataFrame.isna", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.notna.html#pandas.DataFrame.notna", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pad.html#pandas.DataFrame.pad", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.bfill.html#pandas.DataFrame.bfill", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ffill.html#pandas.DataFrame.ffill", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.interpolate.html#pandas.DataFrame.interpolate", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isnull.html#pandas.DataFrame.isnull", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.notnull.html#pandas.DataFrame.notnull", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html#pandas.DataFrame.replace"], "function_definitions": [{"function_name": "pandas.DataFrame.backfill", "full_function": "DataFrame.backfill(*, axis=None, inplace=False, limit=None, downcast=_NoDefault.no_default)", "function_text": "Fill NA/NaN values by using the next valid observation to fill the gap.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.backfill.html#pandas.DataFrame.backfill"}, {"function_name": "pandas.DataFrame.dropna", "full_function": "DataFrame.dropna(*, axis=0, how=_NoDefault.no_default, thresh=_NoDefault.no_default, subset=None, inplace=False, ignore_index=False)", "function_text": "Remove missing values.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "Determine if rows or columns which contain missing values are\nremoved.\n\n0, or ‘index’ : Drop rows which contain missing values.\n1, or ‘columns’ : Drop columns which contain missing value.\n\nOnly a single axis is allowed.\n"}, {"param_name": "how", "param_type": "{‘any’, ‘all’}, default ‘any’", "param_desc": "Determine if row or column is removed from DataFrame, when we have\nat least one NA or all NA.\n\n‘any’ : If any NA values are present, drop that row or column.\n‘all’ : If all values are NA, drop that row or column.\n\n"}, {"param_name": "thresh", "param_type": "int, optional", "param_desc": "Require that many non-NA values. Cannot be combined with how.\n"}, {"param_name": "subset", "param_type": "column label or sequence of labels, optional", "param_desc": "Labels along other axis to consider, e.g. if you are dropping rows\nthese would be a list of columns to include.\n"}, {"param_name": "inplace", "param_type": "bool, default False", "param_desc": "Whether to modify the DataFrame rather than creating a new one.\n"}, {"param_name": "ignore_index", "param_type": "bool, default False", "param_desc": "If True, the resulting axis will be labeled 0, 1, …, n - 1.\n\nNew in version 2.0.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html#pandas.DataFrame.dropna"}, {"function_name": "pandas.DataFrame.fillna", "full_function": "DataFrame.fillna(value=None, *, method=None, axis=None, inplace=False, limit=None, downcast=_NoDefault.no_default)", "function_text": "Fill NA/NaN values using the specified method.", "parameter_names_desc": [{"param_name": "value", "param_type": "scalar, dict, Series, or DataFrame", "param_desc": "Value to use to fill holes (e.g. 0), alternately a\ndict/Series/DataFrame of values specifying which value to use for\neach index (for a Series) or column (for a DataFrame). Values not\nin the dict/Series/DataFrame will not be filled. This value cannot\nbe a list.\n"}, {"param_name": "method", "param_type": "{‘backfill’, ‘bfill’, ‘ffill’, None}, default None", "param_desc": "Method to use for filling holes in reindexed Series:\n\nffill: propagate last valid observation forward to next valid.\nbackfill / bfill: use next valid observation to fill gap.\n\n\nDeprecated since version 2.1.0: Use ffill or bfill instead.\n\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame", "param_desc": "Axis along which to fill missing values. For Series\nthis parameter is unused and defaults to 0.\n"}, {"param_name": "inplace", "param_type": "bool, default False", "param_desc": "If True, fill in-place. Note: this will modify any\nother views on this object (e.g., a no-copy slice for a column in a\nDataFrame).\n"}, {"param_name": "limit", "param_type": "int, default None", "param_desc": "If method is specified, this is the maximum number of consecutive\nNaN values to forward/backward fill. In other words, if there is\na gap with more than this number of consecutive NaNs, it will only\nbe partially filled. If method is not specified, this is the\nmaximum number of entries along the entire axis where NaNs will be\nfilled. Must be greater than 0 if not None.\n"}, {"param_name": "downcast", "param_type": "dict, default is None", "param_desc": "A dict of item->dtype of what to downcast if possible,\nor the string ‘infer’ which will try to downcast to an appropriate\nequal type (e.g. float64 to int64 if possible).\n\nDeprecated since version 2.2.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna"}, {"function_name": "pandas.DataFrame.isna", "full_function": "DataFrame.isna()", "function_text": "Detect missing values.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html#pandas.DataFrame.isna"}, {"function_name": "pandas.DataFrame.notna", "full_function": "DataFrame.notna()", "function_text": "Detect existing (non-missing) values.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.notna.html#pandas.DataFrame.notna"}, {"function_name": "pandas.DataFrame.pad", "full_function": "DataFrame.pad(*, axis=None, inplace=False, limit=None, downcast=_NoDefault.no_default)", "function_text": "Fill NA/NaN values by propagating the last valid observation to next valid.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pad.html#pandas.DataFrame.pad"}, {"function_name": "pandas.DataFrame.bfill", "full_function": "DataFrame.bfill(*, axis=None, inplace=False, limit=None, limit_area=None, downcast=_NoDefault.no_default)", "function_text": "Fill NA/NaN values by using the next valid observation to fill the gap.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame", "param_desc": "Axis along which to fill missing values. For Series\nthis parameter is unused and defaults to 0.\n"}, {"param_name": "inplace", "param_type": "bool, default False", "param_desc": "If True, fill in-place. Note: this will modify any\nother views on this object (e.g., a no-copy slice for a column in a\nDataFrame).\n"}, {"param_name": "limit", "param_type": "int, default None", "param_desc": "If method is specified, this is the maximum number of consecutive\nNaN values to forward/backward fill. In other words, if there is\na gap with more than this number of consecutive NaNs, it will only\nbe partially filled. If method is not specified, this is the\nmaximum number of entries along the entire axis where NaNs will be\nfilled. Must be greater than 0 if not None.\n"}, {"param_name": "limit_area", "param_type": "{None, ‘inside’, ‘outside’}, default None", "param_desc": "If limit is specified, consecutive NaNs will be filled with this\nrestriction.\n\nNone: No fill restriction.\n‘inside’: Only fill NaNs surrounded by valid values\n(interpolate).\n‘outside’: Only fill NaNs outside valid values (extrapolate).\n\n\nNew in version 2.2.0.\n\n"}, {"param_name": "downcast", "param_type": "dict, default is None", "param_desc": "A dict of item->dtype of what to downcast if possible,\nor the string ‘infer’ which will try to downcast to an appropriate\nequal type (e.g. float64 to int64 if possible).\n\nDeprecated since version 2.2.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.bfill.html#pandas.DataFrame.bfill"}, {"function_name": "pandas.DataFrame.ffill", "full_function": "DataFrame.ffill(*, axis=None, inplace=False, limit=None, limit_area=None, downcast=_NoDefault.no_default)", "function_text": "Fill NA/NaN values by propagating the last valid observation to next valid.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame", "param_desc": "Axis along which to fill missing values. For Series\nthis parameter is unused and defaults to 0.\n"}, {"param_name": "inplace", "param_type": "bool, default False", "param_desc": "If True, fill in-place. Note: this will modify any\nother views on this object (e.g., a no-copy slice for a column in a\nDataFrame).\n"}, {"param_name": "limit", "param_type": "int, default None", "param_desc": "If method is specified, this is the maximum number of consecutive\nNaN values to forward/backward fill. In other words, if there is\na gap with more than this number of consecutive NaNs, it will only\nbe partially filled. If method is not specified, this is the\nmaximum number of entries along the entire axis where NaNs will be\nfilled. Must be greater than 0 if not None.\n"}, {"param_name": "limit_area", "param_type": "{None, ‘inside’, ‘outside’}, default None", "param_desc": "If limit is specified, consecutive NaNs will be filled with this\nrestriction.\n\nNone: No fill restriction.\n‘inside’: Only fill NaNs surrounded by valid values\n(interpolate).\n‘outside’: Only fill NaNs outside valid values (extrapolate).\n\n\nNew in version 2.2.0.\n\n"}, {"param_name": "downcast", "param_type": "dict, default is None", "param_desc": "A dict of item->dtype of what to downcast if possible,\nor the string ‘infer’ which will try to downcast to an appropriate\nequal type (e.g. float64 to int64 if possible).\n\nDeprecated since version 2.2.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ffill.html#pandas.DataFrame.ffill"}, {"function_name": "pandas.DataFrame.interpolate", "full_function": "DataFrame.interpolate(method='linear', *, axis=0, limit=None, inplace=False, limit_direction=None, limit_area=None, downcast=_NoDefault.no_default, **kwargs)", "function_text": "Fill NaN values using an interpolation method.", "parameter_names_desc": [{"param_name": "method", "param_type": "str, default ‘linear’", "param_desc": "Interpolation technique to use. One of:\n\n‘linear’: Ignore the index and treat the values as equally\nspaced. This is the only method supported on MultiIndexes.\n‘time’: Works on daily and higher resolution data to interpolate\ngiven length of interval.\n‘index’, ‘values’: use the actual numerical values of the index.\n‘pad’: Fill in NaNs using existing values.\n‘nearest’, ‘zero’, ‘slinear’, ‘quadratic’, ‘cubic’,\n‘barycentric’, ‘polynomial’: Passed to\nscipy.interpolate.interp1d, whereas ‘spline’ is passed to\nscipy.interpolate.UnivariateSpline. These methods use the numerical\nvalues of the index. Both ‘polynomial’ and ‘spline’ require that\nyou also specify an order (int), e.g.\ndf.interpolate(method='polynomial', order=5). Note that,\nslinear method in Pandas refers to the Scipy first order spline\ninstead of Pandas first order spline.\n‘krogh’, ‘piecewise_polynomial’, ‘spline’, ‘pchip’, ‘akima’,\n‘cubicspline’: Wrappers around the SciPy interpolation methods of\nsimilar names. See Notes.\n‘from_derivatives’: Refers to\nscipy.interpolate.BPoly.from_derivatives.\n\n"}, {"param_name": "axis", "param_type": "{{0 or ‘index’, 1 or ‘columns’, None}}, default None", "param_desc": "Axis to interpolate along. For Series this parameter is unused\nand defaults to 0.\n"}, {"param_name": "limit", "param_type": "int, optional", "param_desc": "Maximum number of consecutive NaNs to fill. Must be greater than\n0.\n"}, {"param_name": "inplace", "param_type": "bool, default False", "param_desc": "Update the data in place if possible.\n"}, {"param_name": "limit_direction", "param_type": "{{‘forward’, ‘backward’, ‘both’}}, Optional", "param_desc": "Consecutive NaNs will be filled in this direction.\n\nIf limit is specified:\nIf ‘method’ is ‘pad’ or ‘ffill’, ‘limit_direction’ must be ‘forward’.\nIf ‘method’ is ‘backfill’ or ‘bfill’, ‘limit_direction’ must be\n‘backwards’.\n\n\nIf ‘limit’ is not specified:\nIf ‘method’ is ‘backfill’ or ‘bfill’, the default is ‘backward’\nelse the default is ‘forward’\n\n\nraises ValueError if limit_direction is ‘forward’ or ‘both’ andmethod is ‘backfill’ or ‘bfill’.\n\nraises ValueError if limit_direction is ‘backward’ or ‘both’ andmethod is ‘pad’ or ‘ffill’.\n\n\n"}, {"param_name": "limit_area", "param_type": "{{None, ‘inside’, ‘outside’}}, default None", "param_desc": "If limit is specified, consecutive NaNs will be filled with this\nrestriction.\n\nNone: No fill restriction.\n‘inside’: Only fill NaNs surrounded by valid values\n(interpolate).\n‘outside’: Only fill NaNs outside valid values (extrapolate).\n\n"}, {"param_name": "downcast", "param_type": "optional, ‘infer’ or None, defaults to None", "param_desc": "Downcast dtypes if possible.\n\nDeprecated since version 2.1.0.\n\n"}, {"param_name": "``**kwargs``", "param_type": "optional", "param_desc": "Keyword arguments to pass on to the interpolating function.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.interpolate.html#pandas.DataFrame.interpolate"}, {"function_name": "pandas.DataFrame.isnull", "full_function": "DataFrame.isnull()", "function_text": "DataFrame.isnull is an alias for DataFrame.isna.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isnull.html#pandas.DataFrame.isnull"}, {"function_name": "pandas.DataFrame.notnull", "full_function": "DataFrame.notnull()", "function_text": "DataFrame.notnull is an alias for DataFrame.notna.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.notnull.html#pandas.DataFrame.notnull"}, {"function_name": "pandas.DataFrame.replace", "full_function": "DataFrame.replace(to_replace=None, value=_NoDefault.no_default, *, inplace=False, limit=None, regex=False, method=_NoDefault.no_default)", "function_text": "Replace values given in to_replace with value.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html#pandas.DataFrame.replace"}]}, {"name": "Reshaping, sorting, transposing", "url": "https://pandas.pydata.org/docs/reference/frame.html#reshaping-sorting-transposing", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.droplevel.html#pandas.DataFrame.droplevel", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot_table.html#pandas.DataFrame.pivot_table", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html#pandas.DataFrame.sort_values", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nlargest.html#pandas.DataFrame.nlargest", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.swaplevel.html#pandas.DataFrame.swaplevel", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.unstack.html#pandas.DataFrame.unstack", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.melt.html#pandas.DataFrame.melt", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.squeeze.html#pandas.DataFrame.squeeze", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.T.html#pandas.DataFrame.T", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot.html#pandas.DataFrame.pivot", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reorder_levels.html#pandas.DataFrame.reorder_levels", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_index.html#pandas.DataFrame.sort_index", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nsmallest.html#pandas.DataFrame.nsmallest", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.stack.html#pandas.DataFrame.stack", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.swapaxes.html#pandas.DataFrame.swapaxes", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.explode.html#pandas.DataFrame.explode", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_xarray.html#pandas.DataFrame.to_xarray", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.transpose.html#pandas.DataFrame.transpose"], "function_definitions": [{"function_name": "pandas.DataFrame.droplevel", "full_function": "DataFrame.droplevel(level, axis=0)", "function_text": "Return Series/DataFrame with requested index / column level(s) removed.", "parameter_names_desc": [{"param_name": "level", "param_type": "int, str, or list-like", "param_desc": "If a string is given, must be the name of a level\nIf list-like, elements must be names or positional indexes\nof levels.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "Axis along which the level(s) is removed:\n\n0 or ‘index’: remove level(s) in column.\n1 or ‘columns’: remove level(s) in row.\n\nFor Series this parameter is unused and defaults to 0.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.droplevel.html#pandas.DataFrame.droplevel"}, {"function_name": "pandas.DataFrame.pivot_table", "full_function": "DataFrame.pivot_table(values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All', observed=_NoDefault.no_default, sort=True)", "function_text": "Create a spreadsheet-style pivot table as a DataFrame.", "parameter_names_desc": [{"param_name": "values", "param_type": "list-like or scalar, optional", "param_desc": "Column or columns to aggregate.\n"}, {"param_name": "index", "param_type": "column, Grouper, array, or list of the previous", "param_desc": "Keys to group by on the pivot table index. If a list is passed,\nit can contain any of the other types (except list). If an array is\npassed, it must be the same length as the data and will be used in\nthe same manner as column values.\n"}, {"param_name": "columns", "param_type": "column, Grouper, array, or list of the previous", "param_desc": "Keys to group by on the pivot table column. If a list is passed,\nit can contain any of the other types (except list). If an array is\npassed, it must be the same length as the data and will be used in\nthe same manner as column values.\n"}, {"param_name": "aggfunc", "param_type": "function, list of functions, dict, default “mean”", "param_desc": "If a list of functions is passed, the resulting pivot table will have\nhierarchical columns whose top level are the function names\n(inferred from the function objects themselves).\nIf a dict is passed, the key is column to aggregate and the value is\nfunction or list of functions. If margin=True, aggfunc will be\nused to calculate the partial aggregates.\n"}, {"param_name": "fill_value", "param_type": "scalar, default None", "param_desc": "Value to replace missing values with (in the resulting pivot table,\nafter aggregation).\n"}, {"param_name": "margins", "param_type": "bool, default False", "param_desc": "If margins=True, special All columns and rows\nwill be added with partial group aggregates across the categories\non the rows and columns.\n"}, {"param_name": "dropna", "param_type": "bool, default True", "param_desc": "Do not include columns whose entries are all NaN. If True,\nrows with a NaN value in any column will be omitted before\ncomputing margins.\n"}, {"param_name": "margins_name", "param_type": "str, default ‘All’", "param_desc": "Name of the row / column that will contain the totals\nwhen margins is True.\n"}, {"param_name": "observed", "param_type": "bool, default False", "param_desc": "This only applies if any of the groupers are Categoricals.\nIf True: only show observed values for categorical groupers.\nIf False: show all values for categorical groupers.\n\nDeprecated since version 2.2.0: The default value of False is deprecated and will change to\nTrue in a future version of pandas.\n\n"}, {"param_name": "sort", "param_type": "bool, default True", "param_desc": "Specifies if the result should be sorted.\n\nNew in version 1.3.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot_table.html#pandas.DataFrame.pivot_table"}, {"function_name": "pandas.DataFrame.sort_values", "full_function": "DataFrame.sort_values(by, *, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last', ignore_index=False, key=None)", "function_text": "Sort by the values along either axis.", "parameter_names_desc": [{"param_name": "by", "param_type": "str or list of str", "param_desc": "Name or list of names to sort by.\n\nif axis is 0 or ‘index’ then by may contain index\nlevels and/or column labels.\nif axis is 1 or ‘columns’ then by may contain column\nlevels and/or index labels.\n\n"}, {"param_name": "axis", "param_type": "“{0 or ‘index’, 1 or ‘columns’}”, default 0", "param_desc": "Axis to be sorted.\n"}, {"param_name": "ascending", "param_type": "bool or list of bool, default True", "param_desc": "Sort ascending vs. descending. Specify list for multiple sort\norders. If this is a list of bools, must match the length of\nthe by.\n"}, {"param_name": "inplace", "param_type": "bool, default False", "param_desc": "If True, perform operation in-place.\n"}, {"param_name": "kind", "param_type": "{‘quicksort’, ‘mergesort’, ‘heapsort’, ‘stable’}, default ‘quicksort’", "param_desc": "Choice of sorting algorithm. See also numpy.sort() for more\ninformation. mergesort and stable are the only stable algorithms. For\nDataFrames, this option is only applied when sorting on a single\ncolumn or label.\n"}, {"param_name": "na_position", "param_type": "{‘first’, ‘last’}, default ‘last’", "param_desc": "Puts NaNs at the beginning if first; last puts NaNs at the\nend.\n"}, {"param_name": "ignore_index", "param_type": "bool, default False", "param_desc": "If True, the resulting axis will be labeled 0, 1, …, n - 1.\n"}, {"param_name": "key", "param_type": "callable, optional", "param_desc": "Apply the key function to the values\nbefore sorting. This is similar to the key argument in the\nbuiltin sorted() function, with the notable difference that\nthis key function should be vectorized. It should expect a\nSeries and return a Series with the same shape as the input.\nIt will be applied to each column in by independently.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html#pandas.DataFrame.sort_values"}, {"function_name": "pandas.DataFrame.nlargest", "full_function": "DataFrame.nlargest(n, columns, keep='first')", "function_text": "Return the first n rows ordered by columns in descending order.", "parameter_names_desc": [{"param_name": "n", "param_type": "int", "param_desc": "Number of rows to return.\n"}, {"param_name": "columns", "param_type": "label or list of labels", "param_desc": "Column label(s) to order by.\n"}, {"param_name": "keep", "param_type": "{‘first’, ‘last’, ‘all’}, default ‘first’", "param_desc": "Where there are duplicate values:\n\nfirst : prioritize the first occurrence(s)\nlast : prioritize the last occurrence(s)\nall : keep all the ties of the smallest item even if it means\nselecting more than n items.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nlargest.html#pandas.DataFrame.nlargest"}, {"function_name": "pandas.DataFrame.swaplevel", "full_function": "DataFrame.swaplevel(i=-2, j=-1, axis=0)", "function_text": "Swap levels i and j in a MultiIndex.", "parameter_names_desc": [{"param_name": "i, j", "param_type": "int or str", "param_desc": "Levels of the indices to be swapped. Can pass level name as string.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "The axis to swap levels on. 0 or ‘index’ for row-wise, 1 or\n‘columns’ for column-wise.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.swaplevel.html#pandas.DataFrame.swaplevel"}, {"function_name": "pandas.DataFrame.unstack", "full_function": "DataFrame.unstack(level=-1, fill_value=None, sort=True)", "function_text": "Pivot a level of the (necessarily hierarchical) index labels.", "parameter_names_desc": [{"param_name": "level", "param_type": "int, str, or list of these, default -1 (last level)", "param_desc": "Level(s) of index to unstack, can pass level name.\n"}, {"param_name": "fill_value", "param_type": "int, str or dict", "param_desc": "Replace NaN with this value if the unstack produces missing values.\n"}, {"param_name": "sort", "param_type": "bool, default True", "param_desc": "Sort the level(s) in the resulting MultiIndex columns.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.unstack.html#pandas.DataFrame.unstack"}, {"function_name": "pandas.DataFrame.melt", "full_function": "DataFrame.melt(id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None, ignore_index=True)", "function_text": "Unpivot a DataFrame from wide to long format, optionally leaving identifiers set.", "parameter_names_desc": [{"param_name": "id_vars", "param_type": "scalar, tuple, list, or ndarray, optional", "param_desc": "Column(s) to use as identifier variables.\n"}, {"param_name": "value_vars", "param_type": "scalar, tuple, list, or ndarray, optional", "param_desc": "Column(s) to unpivot. If not specified, uses all columns that\nare not set as id_vars.\n"}, {"param_name": "var_name", "param_type": "scalar, default None", "param_desc": "Name to use for the ‘variable’ column. If None it uses\nframe.columns.name or ‘variable’.\n"}, {"param_name": "value_name", "param_type": "scalar, default ‘value’", "param_desc": "Name to use for the ‘value’ column, can’t be an existing column label.\n"}, {"param_name": "col_level", "param_type": "scalar, optional", "param_desc": "If columns are a MultiIndex then use this level to melt.\n"}, {"param_name": "ignore_index", "param_type": "bool, default True", "param_desc": "If True, original index is ignored. If False, the original index is retained.\nIndex labels will be repeated as necessary.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.melt.html#pandas.DataFrame.melt"}, {"function_name": "pandas.DataFrame.squeeze", "full_function": "DataFrame.squeeze(axis=None)", "function_text": "Squeeze 1 dimensional axis objects into scalars.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’, None}, default None", "param_desc": "A specific axis to squeeze. By default, all length-1 axes are\nsqueezed. For Series this parameter is unused and defaults to None.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.squeeze.html#pandas.DataFrame.squeeze"}, {"function_name": "pandas.DataFrame.T", "full_function": "property DataFrame.T", "function_text": "The transpose of the DataFrame.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.T.html#pandas.DataFrame.T"}, {"function_name": "pandas.DataFrame.pivot", "full_function": "DataFrame.pivot(*, columns, index=_NoDefault.no_default, values=_NoDefault.no_default)", "function_text": "Return reshaped DataFrame organized by given index / column values.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot.html#pandas.DataFrame.pivot"}, {"function_name": "pandas.DataFrame.reorder_levels", "full_function": "DataFrame.reorder_levels(order, axis=0)", "function_text": "Rearrange index levels using input order. May not drop or duplicate levels.", "parameter_names_desc": [{"param_name": "order", "param_type": "list of int or list of str", "param_desc": "List representing new level order. Reference level by number\n(position) or by key (label).\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "Where to reorder levels.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reorder_levels.html#pandas.DataFrame.reorder_levels"}, {"function_name": "pandas.DataFrame.sort_index", "full_function": "DataFrame.sort_index(*, axis=0, level=None, ascending=True, inplace=False, kind='quicksort', na_position='last', sort_remaining=True, ignore_index=False, key=None)", "function_text": "Sort object by labels (along an axis).", "parameter_names_desc": [{"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "The axis along which to sort. The value 0 identifies the rows,\nand 1 identifies the columns.\n"}, {"param_name": "level", "param_type": "int or level name or list of ints or list of level names", "param_desc": "If not None, sort on values in specified index level(s).\n"}, {"param_name": "ascending", "param_type": "bool or list-like of bools, default True", "param_desc": "Sort ascending vs. descending. When the index is a MultiIndex the\nsort direction can be controlled for each level individually.\n"}, {"param_name": "inplace", "param_type": "bool, default False", "param_desc": "Whether to modify the DataFrame rather than creating a new one.\n"}, {"param_name": "kind", "param_type": "{‘quicksort’, ‘mergesort’, ‘heapsort’, ‘stable’}, default ‘quicksort’", "param_desc": "Choice of sorting algorithm. See also numpy.sort() for more\ninformation. mergesort and stable are the only stable algorithms. For\nDataFrames, this option is only applied when sorting on a single\ncolumn or label.\n"}, {"param_name": "na_position", "param_type": "{‘first’, ‘last’}, default ‘last’", "param_desc": "Puts NaNs at the beginning if first; last puts NaNs at the end.\nNot implemented for MultiIndex.\n"}, {"param_name": "sort_remaining", "param_type": "bool, default True", "param_desc": "If True and sorting by level and index is multilevel, sort by other\nlevels too (in order) after sorting by specified level.\n"}, {"param_name": "ignore_index", "param_type": "bool, default False", "param_desc": "If True, the resulting axis will be labeled 0, 1, …, n - 1.\n"}, {"param_name": "key", "param_type": "callable, optional", "param_desc": "If not None, apply the key function to the index values\nbefore sorting. This is similar to the key argument in the\nbuiltin sorted() function, with the notable difference that\nthis key function should be vectorized. It should expect an\nIndex and return an Index of the same shape. For MultiIndex\ninputs, the key is applied per level.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_index.html#pandas.DataFrame.sort_index"}, {"function_name": "pandas.DataFrame.nsmallest", "full_function": "DataFrame.nsmallest(n, columns, keep='first')", "function_text": "Return the first n rows ordered by columns in ascending order.", "parameter_names_desc": [{"param_name": "n", "param_type": "int", "param_desc": "Number of items to retrieve.\n"}, {"param_name": "columns", "param_type": "list or str", "param_desc": "Column name or names to order by.\n"}, {"param_name": "keep", "param_type": "{‘first’, ‘last’, ‘all’}, default ‘first’", "param_desc": "Where there are duplicate values:\n\nfirst : take the first occurrence.\nlast : take the last occurrence.\nall : keep all the ties of the largest item even if it means\nselecting more than n items.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nsmallest.html#pandas.DataFrame.nsmallest"}, {"function_name": "pandas.DataFrame.stack", "full_function": "DataFrame.stack(level=-1, dropna=_NoDefault.no_default, sort=_NoDefault.no_default, future_stack=False)", "function_text": "Stack the prescribed level(s) from columns to index.", "parameter_names_desc": [{"param_name": "level", "param_type": "int, str, list, default -1", "param_desc": "Level(s) to stack from the column axis onto the index\naxis, defined as one index or label, or a list of indices\nor labels.\n"}, {"param_name": "dropna", "param_type": "bool, default True", "param_desc": "Whether to drop rows in the resulting Frame/Series with\nmissing values. Stacking a column level onto the index\naxis can create combinations of index and column values\nthat are missing from the original dataframe. See Examples\nsection.\n"}, {"param_name": "sort", "param_type": "bool, default True", "param_desc": "Whether to sort the levels of the resulting MultiIndex.\n"}, {"param_name": "future_stack", "param_type": "bool, default False", "param_desc": "Whether to use the new implementation that will replace the current\nimplementation in pandas 3.0. When True, dropna and sort have no impact\non the result and must remain unspecified. See pandas 2.1.0 Release\nnotes for more details.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.stack.html#pandas.DataFrame.stack"}, {"function_name": "pandas.DataFrame.swapaxes", "full_function": "DataFrame.swapaxes(axis1, axis2, copy=None)", "function_text": "Interchange axes and swap values axes appropriately.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.swapaxes.html#pandas.DataFrame.swapaxes"}, {"function_name": "pandas.DataFrame.explode", "full_function": "DataFrame.explode(column, ignore_index=False)", "function_text": "Transform each element of a list-like to a row, replicating index values.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.explode.html#pandas.DataFrame.explode"}, {"function_name": "pandas.DataFrame.to_xarray", "full_function": "DataFrame.to_xarray()", "function_text": "Return an xarray object from the pandas object.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_xarray.html#pandas.DataFrame.to_xarray"}, {"function_name": "pandas.DataFrame.transpose", "full_function": "DataFrame.transpose(*args, copy=False)", "function_text": "Transpose index and columns.", "parameter_names_desc": [{"param_name": "*args", "param_type": "tuple, optional", "param_desc": "Accepted for compatibility with NumPy.\n"}, {"param_name": "copy", "param_type": "bool, default False", "param_desc": "Whether to copy the data after transposing, even for DataFrames\nwith a single dtype.\nNote that a copy is always required for mixed dtype DataFrames,\nor for DataFrames with any extension types.\n\nNote\nThe copy keyword will change behavior in pandas 3.0.\nCopy-on-Write\nwill be enabled by default, which means that all methods with a\ncopy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas.\nYou can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.transpose.html#pandas.DataFrame.transpose"}]}, {"name": "Combining / comparing / joining / merging", "url": "https://pandas.pydata.org/docs/reference/frame.html#combining-comparing-joining-merging", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.assign.html#pandas.DataFrame.assign", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.join.html#pandas.DataFrame.join", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.update.html#pandas.DataFrame.update", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.compare.html#pandas.DataFrame.compare", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html#pandas.DataFrame.merge"], "function_definitions": [{"function_name": "pandas.DataFrame.assign", "full_function": "DataFrame.assign(**kwargs)", "function_text": "Assign new columns to a DataFrame.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.assign.html#pandas.DataFrame.assign"}, {"function_name": "pandas.DataFrame.join", "full_function": "DataFrame.join(other, on=None, how='left', lsuffix='', rsuffix='', sort=False, validate=None)", "function_text": "Join columns of another DataFrame.", "parameter_names_desc": [{"param_name": "other", "param_type": "DataFrame, Series, or a list containing any combination of them", "param_desc": "Index should be similar to one of the columns in this one. If a\nSeries is passed, its name attribute must be set, and that will be\nused as the column name in the resulting joined DataFrame.\n"}, {"param_name": "on", "param_type": "str, list of str, or array-like, optional", "param_desc": "Column or index level name(s) in the caller to join on the index\nin other, otherwise joins index-on-index. If multiple\nvalues given, the other DataFrame must have a MultiIndex. Can\npass an array as the join key if it is not already contained in\nthe calling DataFrame. Like an Excel VLOOKUP operation.\n"}, {"param_name": "how", "param_type": "{‘left’, ‘right’, ‘outer’, ‘inner’, ‘cross’}, default ‘left’", "param_desc": "How to handle the operation of the two objects.\n\nleft: use calling frame’s index (or column if on is specified)\nright: use other’s index.\nouter: form union of calling frame’s index (or column if on is\nspecified) with other’s index, and sort it lexicographically.\ninner: form intersection of calling frame’s index (or column if\non is specified) with other’s index, preserving the order\nof the calling’s one.\ncross: creates the cartesian product from both frames, preserves the order\nof the left keys.\n\n"}, {"param_name": "lsuffix", "param_type": "str, default ‘’", "param_desc": "Suffix to use from left frame’s overlapping columns.\n"}, {"param_name": "rsuffix", "param_type": "str, default ‘’", "param_desc": "Suffix to use from right frame’s overlapping columns.\n"}, {"param_name": "sort", "param_type": "bool, default False", "param_desc": "Order result DataFrame lexicographically by the join key. If False,\nthe order of the join key depends on the join type (how keyword).\n"}, {"param_name": "validate", "param_type": "str, optional", "param_desc": "If specified, checks if join is of specified type.\n\n“one_to_one” or “1:1”: check if join keys are unique in both left\nand right datasets.\n“one_to_many” or “1:m”: check if join keys are unique in left dataset.\n“many_to_one” or “m:1”: check if join keys are unique in right dataset.\n“many_to_many” or “m:m”: allowed, but does not result in checks.\n\n\nNew in version 1.5.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.join.html#pandas.DataFrame.join"}, {"function_name": "pandas.DataFrame.update", "full_function": "DataFrame.update(other, join='left', overwrite=True, filter_func=None, errors='ignore')", "function_text": "Modify in place using non-NA values from another DataFrame.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.update.html#pandas.DataFrame.update"}, {"function_name": "pandas.DataFrame.compare", "full_function": "DataFrame.compare(other, align_axis=1, keep_shape=False, keep_equal=False, result_names=('self', 'other'))", "function_text": "Compare to another DataFrame and show the differences.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.compare.html#pandas.DataFrame.compare"}, {"function_name": "pandas.DataFrame.merge", "full_function": "DataFrame.merge(right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=None, indicator=False, validate=None)", "function_text": "Merge DataFrame or named Series objects with a database-style join.", "parameter_names_desc": [{"param_name": "right", "param_type": "DataFrame or named Series", "param_desc": "Object to merge with.\n"}, {"param_name": "how", "param_type": "{‘left’, ‘right’, ‘outer’, ‘inner’, ‘cross’}, default ‘inner’", "param_desc": "Type of merge to be performed.\n\nleft: use only keys from left frame, similar to a SQL left outer join;\npreserve key order.\nright: use only keys from right frame, similar to a SQL right outer join;\npreserve key order.\nouter: use union of keys from both frames, similar to a SQL full outer\njoin; sort keys lexicographically.\ninner: use intersection of keys from both frames, similar to a SQL inner\njoin; preserve the order of the left keys.\ncross: creates the cartesian product from both frames, preserves the order\nof the left keys.\n\n"}, {"param_name": "on", "param_type": "label or list", "param_desc": "Column or index level names to join on. These must be found in both\nDataFrames. If on is None and not merging on indexes then this defaults\nto the intersection of the columns in both DataFrames.\n"}, {"param_name": "left_on", "param_type": "label or list, or array-like", "param_desc": "Column or index level names to join on in the left DataFrame. Can also\nbe an array or list of arrays of the length of the left DataFrame.\nThese arrays are treated as if they are columns.\n"}, {"param_name": "right_on", "param_type": "label or list, or array-like", "param_desc": "Column or index level names to join on in the right DataFrame. Can also\nbe an array or list of arrays of the length of the right DataFrame.\nThese arrays are treated as if they are columns.\n"}, {"param_name": "left_index", "param_type": "bool, default False", "param_desc": "Use the index from the left DataFrame as the join key(s). If it is a\nMultiIndex, the number of keys in the other DataFrame (either the index\nor a number of columns) must match the number of levels.\n"}, {"param_name": "right_index", "param_type": "bool, default False", "param_desc": "Use the index from the right DataFrame as the join key. Same caveats as\nleft_index.\n"}, {"param_name": "sort", "param_type": "bool, default False", "param_desc": "Sort the join keys lexicographically in the result DataFrame. If False,\nthe order of the join keys depends on the join type (how keyword).\n"}, {"param_name": "suffixes", "param_type": "list-like, default is (“_x”, “_y”)", "param_desc": "A length-2 sequence where each element is optionally a string\nindicating the suffix to add to overlapping column names in\nleft and right respectively. Pass a value of None instead\nof a string to indicate that the column name from left or\nright should be left as-is, with no suffix. At least one of the\nvalues must not be None.\n"}, {"param_name": "copy", "param_type": "bool, default True", "param_desc": "If False, avoid copy if possible.\n\nNote\nThe copy keyword will change behavior in pandas 3.0.\nCopy-on-Write\nwill be enabled by default, which means that all methods with a\ncopy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas.\nYou can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True\n\n"}, {"param_name": "indicator", "param_type": "bool or str, default False", "param_desc": "If True, adds a column to the output DataFrame called “_merge” with\ninformation on the source of each row. The column can be given a different\nname by providing a string argument. The column will have a Categorical\ntype with the value of “left_only” for observations whose merge key only\nappears in the left DataFrame, “right_only” for observations\nwhose merge key only appears in the right DataFrame, and “both”\nif the observation’s merge key is found in both DataFrames.\n"}, {"param_name": "validate", "param_type": "str, optional", "param_desc": "If specified, checks if merge is of specified type.\n\n“one_to_one” or “1:1”: check if merge keys are unique in both\nleft and right datasets.\n“one_to_many” or “1:m”: check if merge keys are unique in left\ndataset.\n“many_to_one” or “m:1”: check if merge keys are unique in right\ndataset.\n“many_to_many” or “m:m”: allowed, but does not result in checks.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html#pandas.DataFrame.merge"}]}, {"name": "Time Series-related", "url": "https://pandas.pydata.org/docs/reference/frame.html#time-series-related", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.asfreq.html#pandas.DataFrame.asfreq", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shift.html#pandas.DataFrame.shift", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.last_valid_index.html#pandas.DataFrame.last_valid_index", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_period.html#pandas.DataFrame.to_period", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tz_convert.html#pandas.DataFrame.tz_convert", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.asof.html#pandas.DataFrame.asof", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.first_valid_index.html#pandas.DataFrame.first_valid_index", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html#pandas.DataFrame.resample", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_timestamp.html#pandas.DataFrame.to_timestamp", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tz_localize.html#pandas.DataFrame.tz_localize"], "function_definitions": [{"function_name": "pandas.DataFrame.asfreq", "full_function": "DataFrame.asfreq(freq, method=None, how=None, normalize=False, fill_value=None)", "function_text": "Convert time series to specified frequency.", "parameter_names_desc": [{"param_name": "freq", "param_type": "DateOffset or str", "param_desc": "Frequency DateOffset or string.\n"}, {"param_name": "method", "param_type": "{‘backfill’/’bfill’, ‘pad’/’ffill’}, default None", "param_desc": "Method to use for filling holes in reindexed Series (note this\ndoes not fill NaNs that already were present):\n\n‘pad’ / ‘ffill’: propagate last valid observation forward to next\nvalid\n‘backfill’ / ‘bfill’: use NEXT valid observation to fill.\n\n"}, {"param_name": "how", "param_type": "{‘start’, ‘end’}, default end", "param_desc": "For PeriodIndex only (see PeriodIndex.asfreq).\n"}, {"param_name": "normalize", "param_type": "bool, default False", "param_desc": "Whether to reset output index to midnight.\n"}, {"param_name": "fill_value", "param_type": "scalar, optional", "param_desc": "Value to use for missing values, applied during upsampling (note\nthis does not fill NaNs that already were present).\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.asfreq.html#pandas.DataFrame.asfreq"}, {"function_name": "pandas.DataFrame.shift", "full_function": "DataFrame.shift(periods=1, freq=None, axis=0, fill_value=_NoDefault.no_default, suffix=None)", "function_text": "Shift index by desired number of periods with an optional time freq.", "parameter_names_desc": [{"param_name": "periods", "param_type": "int or Sequence", "param_desc": "Number of periods to shift. Can be positive or negative.\nIf an iterable of ints, the data will be shifted once by each int.\nThis is equivalent to shifting by one value at a time and\nconcatenating all resulting frames. The resulting columns will have\nthe shift suffixed to their column names. For multiple periods,\naxis must not be 1.\n"}, {"param_name": "freq", "param_type": "DateOffset, tseries.offsets, timedelta, or str, optional", "param_desc": "Offset to use from the tseries module or time rule (e.g. ‘EOM’).\nIf freq is specified then the index values are shifted but the\ndata is not realigned. That is, use freq if you would like to\nextend the index when shifting and preserve the original data.\nIf freq is specified as “infer” then it will be inferred from\nthe freq or inferred_freq attributes of the index. If neither of\nthose attributes exist, a ValueError is thrown.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’, None}, default None", "param_desc": "Shift direction. For Series this parameter is unused and defaults to 0.\n"}, {"param_name": "fill_value", "param_type": "object, optional", "param_desc": "The scalar value to use for newly introduced missing values.\nthe default depends on the dtype of self.\nFor numeric data, np.nan is used.\nFor datetime, timedelta, or period data, etc. NaT is used.\nFor extension dtypes, self.dtype.na_value is used.\n"}, {"param_name": "suffix", "param_type": "str, optional", "param_desc": "If str and periods is an iterable, this is added after the column\nname and before the shift value for each shifted column name.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shift.html#pandas.DataFrame.shift"}, {"function_name": "pandas.DataFrame.last_valid_index", "full_function": "DataFrame.last_valid_index()", "function_text": "Return index for last non-NA value or None, if no non-NA value is found.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.last_valid_index.html#pandas.DataFrame.last_valid_index"}, {"function_name": "pandas.DataFrame.to_period", "full_function": "DataFrame.to_period(freq=None, axis=0, copy=None)", "function_text": "Convert DataFrame from DatetimeIndex to PeriodIndex.", "parameter_names_desc": [{"param_name": "freq", "param_type": "str, default", "param_desc": "Frequency of the PeriodIndex.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "The axis to convert (the index by default).\n"}, {"param_name": "copy", "param_type": "bool, default True", "param_desc": "If False then underlying input data is not copied.\n\nNote\nThe copy keyword will change behavior in pandas 3.0.\nCopy-on-Write\nwill be enabled by default, which means that all methods with a\ncopy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas.\nYou can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_period.html#pandas.DataFrame.to_period"}, {"function_name": "pandas.DataFrame.tz_convert", "full_function": "DataFrame.tz_convert(tz, axis=0, level=None, copy=None)", "function_text": "Convert tz-aware axis to target time zone.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tz_convert.html#pandas.DataFrame.tz_convert"}, {"function_name": "pandas.DataFrame.asof", "full_function": "DataFrame.asof(where, subset=None)", "function_text": "Return the last row(s) without any NaNs before where.", "parameter_names_desc": [{"param_name": "where", "param_type": "date or array-like of dates", "param_desc": "Date(s) before which the last row(s) are returned.\n"}, {"param_name": "subset", "param_type": "str or array-like of str, default None", "param_desc": "For DataFrame, if not None, only use these columns to\ncheck for NaNs.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.asof.html#pandas.DataFrame.asof"}, {"function_name": "pandas.DataFrame.first_valid_index", "full_function": "DataFrame.first_valid_index()", "function_text": "Return index for first non-NA value or None, if no non-NA value is found.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.first_valid_index.html#pandas.DataFrame.first_valid_index"}, {"function_name": "pandas.DataFrame.resample", "full_function": "DataFrame.resample(rule, axis=_NoDefault.no_default, closed=None, label=None, convention=_NoDefault.no_default, kind=_NoDefault.no_default, on=None, level=None, origin='start_day', offset=None, group_keys=False)", "function_text": "Resample time-series data.", "parameter_names_desc": [{"param_name": "rule", "param_type": "DateOffset, Timedelta or str", "param_desc": "The offset string or object representing target conversion.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "Which axis to use for up- or down-sampling. For Series this parameter\nis unused and defaults to 0. Must be\nDatetimeIndex, TimedeltaIndex or PeriodIndex.\n\nDeprecated since version 2.0.0: Use frame.T.resample(…) instead.\n\n"}, {"param_name": "closed", "param_type": "{‘right’, ‘left’}, default None", "param_desc": "Which side of bin interval is closed. The default is ‘left’\nfor all frequency offsets except for ‘ME’, ‘YE’, ‘QE’, ‘BME’,\n‘BA’, ‘BQE’, and ‘W’ which all have a default of ‘right’.\n"}, {"param_name": "label", "param_type": "{‘right’, ‘left’}, default None", "param_desc": "Which bin edge label to label bucket with. The default is ‘left’\nfor all frequency offsets except for ‘ME’, ‘YE’, ‘QE’, ‘BME’,\n‘BA’, ‘BQE’, and ‘W’ which all have a default of ‘right’.\n"}, {"param_name": "convention", "param_type": "{‘start’, ‘end’, ‘s’, ‘e’}, default ‘start’", "param_desc": "For PeriodIndex only, controls whether to use the start or\nend of rule.\n\nDeprecated since version 2.2.0: Convert PeriodIndex to DatetimeIndex before resampling instead.\n\n"}, {"param_name": "kind", "param_type": "{‘timestamp’, ‘period’}, optional, default None", "param_desc": "Pass ‘timestamp’ to convert the resulting index to a\nDateTimeIndex or ‘period’ to convert it to a PeriodIndex.\nBy default the input representation is retained.\n\nDeprecated since version 2.2.0: Convert index to desired type explicitly instead.\n\n"}, {"param_name": "on", "param_type": "str, optional", "param_desc": "For a DataFrame, column to use instead of index for resampling.\nColumn must be datetime-like.\n"}, {"param_name": "level", "param_type": "str or int, optional", "param_desc": "For a MultiIndex, level (name or number) to use for\nresampling. level must be datetime-like.\n"}, {"param_name": "origin", "param_type": "Timestamp or str, default ‘start_day’", "param_desc": "The timestamp on which to adjust the grouping. The timezone of origin\nmust match the timezone of the index.\nIf string, must be one of the following:\n\n‘epoch’: origin is 1970-01-01\n‘start’: origin is the first value of the timeseries\n‘start_day’: origin is the first day at midnight of the timeseries\n‘end’: origin is the last value of the timeseries\n‘end_day’: origin is the ceiling midnight of the last day\n\n\nNew in version 1.3.0.\n\n\nNote\nOnly takes effect for Tick-frequencies (i.e. fixed frequencies like\ndays, hours, and minutes, rather than months or quarters).\n\n"}, {"param_name": "offset", "param_type": "Timedelta or str, default is None", "param_desc": "An offset timedelta added to the origin.\n"}, {"param_name": "group_keys", "param_type": "bool, default False", "param_desc": "Whether to include the group keys in the result index when using\n.apply() on the resampled object.\n\nNew in version 1.5.0: Not specifying group_keys will retain values-dependent behavior\nfrom pandas 1.4 and earlier (see pandas 1.5.0 Release notes for examples).\n\n\nChanged in version 2.0.0: group_keys now defaults to False.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html#pandas.DataFrame.resample"}, {"function_name": "pandas.DataFrame.to_timestamp", "full_function": "DataFrame.to_timestamp(freq=None, how='start', axis=0, copy=None)", "function_text": "Cast to DatetimeIndex of timestamps, at beginning of period.", "parameter_names_desc": [{"param_name": "freq", "param_type": "str, default frequency of PeriodIndex", "param_desc": "Desired frequency.\n"}, {"param_name": "how", "param_type": "{‘s’, ‘e’, ‘start’, ‘end’}", "param_desc": "Convention for converting period to timestamp; start of period\nvs. end.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "The axis to convert (the index by default).\n"}, {"param_name": "copy", "param_type": "bool, default True", "param_desc": "If False then underlying input data is not copied.\n\nNote\nThe copy keyword will change behavior in pandas 3.0.\nCopy-on-Write\nwill be enabled by default, which means that all methods with a\ncopy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas.\nYou can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_timestamp.html#pandas.DataFrame.to_timestamp"}, {"function_name": "pandas.DataFrame.tz_localize", "full_function": "DataFrame.tz_localize(tz, axis=0, level=None, copy=None, ambiguous='raise', nonexistent='raise')", "function_text": "Localize tz-naive index of a Series or DataFrame to target time zone.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tz_localize.html#pandas.DataFrame.tz_localize"}]}, {"name": "Flags", "url": "https://pandas.pydata.org/docs/reference/frame.html#flags", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.Flags.html#pandas.Flags"], "function_definitions": [{"function_name": "pandas.Flags", "full_function": "class pandas.Flags(obj, *, allows_duplicate_labels)", "function_text": "Flags that apply to pandas objects.", "parameter_names_desc": [{"param_name": "obj", "param_type": "Series or DataFrame", "param_desc": "The object these flags are associated with.\n"}, {"param_name": "allows_duplicate_labels", "param_type": "bool, default True", "param_desc": "Whether to allow duplicate labels in this object. By default,\nduplicate labels are permitted. Setting this to False will\ncause an errors.DuplicateLabelError to be raised when\nindex (or columns for DataFrame) is not unique, or any\nsubsequent operation on introduces duplicates.\nSee Disallowing Duplicate Labels for more.\n\nWarning\nThis is an experimental feature. Currently, many methods fail to\npropagate the allows_duplicate_labels value. In future versions\nit is expected that every method taking or returning one or more\nDataFrame or Series objects will propagate allows_duplicate_labels.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Flags.html#pandas.Flags"}]}, {"name": "Metadata", "url": "https://pandas.pydata.org/docs/reference/frame.html#metadata", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.attrs.html#pandas.DataFrame.attrs"], "function_definitions": [{"function_name": "pandas.DataFrame.attrs", "full_function": "property DataFrame.attrs", "function_text": "Dictionary of global attributes of this dataset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.attrs.html#pandas.DataFrame.attrs"}]}, {"name": "Plotting", "url": "https://pandas.pydata.org/docs/reference/frame.html#plotting", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html#pandas.DataFrame.plot", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.area.html#pandas.DataFrame.plot.area", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.barh.html#pandas.DataFrame.plot.barh", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.density.html#pandas.DataFrame.plot.density", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.hist.html#pandas.DataFrame.plot.hist", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.line.html#pandas.DataFrame.plot.line", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.scatter.html#pandas.DataFrame.plot.scatter", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.boxplot.html#pandas.DataFrame.boxplot", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.bar.html#pandas.DataFrame.plot.bar", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.box.html#pandas.DataFrame.plot.box", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.hexbin.html#pandas.DataFrame.plot.hexbin", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.kde.html#pandas.DataFrame.plot.kde", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.pie.html#pandas.DataFrame.plot.pie", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.hist.html#pandas.DataFrame.hist"], "function_definitions": [{"function_name": "pandas.DataFrame.plot", "full_function": "DataFrame.plot(*args, **kwargs)", "function_text": "Make plots of Series or DataFrame.", "parameter_names_desc": [{"param_name": "data", "param_type": "Series or DataFrame", "param_desc": "The object for which the method is called.\n"}, {"param_name": "x", "param_type": "label or position, default None", "param_desc": "Only used if data is a DataFrame.\n"}, {"param_name": "y", "param_type": "label, position or list of label, positions, default None", "param_desc": "Allows plotting of one column versus another. Only used if data is a\nDataFrame.\n"}, {"param_name": "kind", "param_type": "str", "param_desc": "The kind of plot to produce:\n\n‘line’ : line plot (default)\n‘bar’ : vertical bar plot\n‘barh’ : horizontal bar plot\n‘hist’ : histogram\n‘box’ : boxplot\n‘kde’ : Kernel Density Estimation plot\n‘density’ : same as ‘kde’\n‘area’ : area plot\n‘pie’ : pie plot\n‘scatter’ : scatter plot (DataFrame only)\n‘hexbin’ : hexbin plot (DataFrame only)\n\n"}, {"param_name": "ax", "param_type": "matplotlib axes object, default None", "param_desc": "An axes of the current figure.\n"}, {"param_name": "subplots", "param_type": "bool or sequence of iterables, default False", "param_desc": "Whether to group columns into subplots:\n\nFalse : No subplots will be used\nTrue : Make separate subplots for each column.\nsequence of iterables of column labels: Create a subplot for each\ngroup of columns. For example [(‘a’, ‘c’), (‘b’, ‘d’)] will\ncreate 2 subplots: one with columns ‘a’ and ‘c’, and one\nwith columns ‘b’ and ‘d’. Remaining columns that aren’t specified\nwill be plotted in additional subplots (one per column).\n\nNew in version 1.5.0.\n\n\n\n"}, {"param_name": "sharex", "param_type": "bool, default True if ax is None else False", "param_desc": "In case subplots=True, share x axis and set some x axis labels\nto invisible; defaults to True if ax is None otherwise False if\nan ax is passed in; Be aware, that passing in both an ax and\nsharex=True will alter all x axis labels for all axis in a figure.\n"}, {"param_name": "sharey", "param_type": "bool, default False", "param_desc": "In case subplots=True, share y axis and set some y axis labels to invisible.\n"}, {"param_name": "layout", "param_type": "tuple, optional", "param_desc": "(rows, columns) for the layout of subplots.\n"}, {"param_name": "figsize", "param_type": "a tuple (width, height) in inches", "param_desc": "Size of a figure object.\n"}, {"param_name": "use_index", "param_type": "bool, default True", "param_desc": "Use index as ticks for x axis.\n"}, {"param_name": "title", "param_type": "str or list", "param_desc": "Title to use for the plot. If a string is passed, print the string\nat the top of the figure. If a list is passed and subplots is\nTrue, print each item in the list above the corresponding subplot.\n"}, {"param_name": "grid", "param_type": "bool, default None (matlab style default)", "param_desc": "Axis grid lines.\n"}, {"param_name": "legend", "param_type": "bool or {‘reverse’}", "param_desc": "Place legend on axis subplots.\n"}, {"param_name": "style", "param_type": "list or dict", "param_desc": "The matplotlib line style per column.\n"}, {"param_name": "logx", "param_type": "bool or ‘sym’, default False", "param_desc": "Use log scaling or symlog scaling on x axis.\n"}, {"param_name": "logy", "param_type": "bool or ‘sym’ default False", "param_desc": "Use log scaling or symlog scaling on y axis.\n"}, {"param_name": "loglog", "param_type": "bool or ‘sym’, default False", "param_desc": "Use log scaling or symlog scaling on both x and y axes.\n"}, {"param_name": "xticks", "param_type": "sequence", "param_desc": "Values to use for the xticks.\n"}, {"param_name": "yticks", "param_type": "sequence", "param_desc": "Values to use for the yticks.\n"}, {"param_name": "xlim", "param_type": "2-tuple/list", "param_desc": "Set the x limits of the current axes.\n"}, {"param_name": "ylim", "param_type": "2-tuple/list", "param_desc": "Set the y limits of the current axes.\n"}, {"param_name": "xlabel", "param_type": "label, optional", "param_desc": "Name to use for the xlabel on x-axis. Default uses index name as xlabel, or the\nx-column name for planar plots.\n\nChanged in version 2.0.0: Now applicable to histograms.\n\n"}, {"param_name": "ylabel", "param_type": "label, optional", "param_desc": "Name to use for the ylabel on y-axis. Default will show no ylabel, or the\ny-column name for planar plots.\n\nChanged in version 2.0.0: Now applicable to histograms.\n\n"}, {"param_name": "rot", "param_type": "float, default None", "param_desc": "Rotation for ticks (xticks for vertical, yticks for horizontal\nplots).\n"}, {"param_name": "fontsize", "param_type": "float, default None", "param_desc": "Font size for xticks and yticks.\n"}, {"param_name": "colormap", "param_type": "str or matplotlib colormap object, default None", "param_desc": "Colormap to select colors from. If string, load colormap with that\nname from matplotlib.\n"}, {"param_name": "colorbar", "param_type": "bool, optional", "param_desc": "If True, plot colorbar (only relevant for ‘scatter’ and ‘hexbin’\nplots).\n"}, {"param_name": "position", "param_type": "float", "param_desc": "Specify relative alignments for bar plot layout.\nFrom 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\n(center).\n"}, {"param_name": "table", "param_type": "bool, Series or DataFrame, default False", "param_desc": "If True, draw a table using the data in the DataFrame and the data\nwill be transposed to meet matplotlib’s default layout.\nIf a Series or DataFrame is passed, use passed data to draw a\ntable.\n"}, {"param_name": "yerr", "param_type": "DataFrame, Series, array-like, dict and str", "param_desc": "See Plotting with Error Bars for\ndetail.\n"}, {"param_name": "xerr", "param_type": "DataFrame, Series, array-like, dict and str", "param_desc": "Equivalent to yerr.\n"}, {"param_name": "stacked", "param_type": "bool, default False in line and bar plots, and True in area plot", "param_desc": "If True, create stacked plot.\n"}, {"param_name": "secondary_y", "param_type": "bool or sequence, default False", "param_desc": "Whether to plot on the secondary y-axis if a list/tuple, which\ncolumns to plot on secondary y-axis.\n"}, {"param_name": "mark_right", "param_type": "bool, default True", "param_desc": "When using a secondary_y axis, automatically mark the column\nlabels with “(right)” in the legend.\n"}, {"param_name": "include_bool", "param_type": "bool, default is False", "param_desc": "If True, boolean values can be plotted.\n"}, {"param_name": "backend", "param_type": "str, default None", "param_desc": "Backend to use instead of the backend specified in the option\nplotting.backend. For instance, ‘matplotlib’. Alternatively, to\nspecify the plotting.backend for the whole session, set\npd.options.plotting.backend.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html#pandas.DataFrame.plot"}, {"function_name": "pandas.DataFrame.plot.area", "full_function": "DataFrame.plot.area(x=None, y=None, stacked=True, **kwargs)", "function_text": "Draw a stacked area plot.", "parameter_names_desc": [{"param_name": "x", "param_type": "label or position, optional", "param_desc": "Coordinates for the X axis. By default uses the index.\n"}, {"param_name": "y", "param_type": "label or position, optional", "param_desc": "Column to plot. By default uses all columns.\n"}, {"param_name": "stacked", "param_type": "bool, default True", "param_desc": "Area plots are stacked by default. Set to False to create a\nunstacked plot.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.area.html#pandas.DataFrame.plot.area"}, {"function_name": "pandas.DataFrame.plot.barh", "full_function": "DataFrame.plot.barh(x=None, y=None, **kwargs)", "function_text": "Make a horizontal bar plot.", "parameter_names_desc": [{"param_name": "x", "param_type": "label or position, optional", "param_desc": "Allows plotting of one column versus another. If not specified,\nthe index of the DataFrame is used.\n"}, {"param_name": "y", "param_type": "label or position, optional", "param_desc": "Allows plotting of one column versus another. If not specified,\nall numerical columns are used.\n"}, {"param_name": "color", "param_type": "str, array-like, or dict, optional", "param_desc": "The color for each of the DataFrame’s columns. Possible values are:\n\n\nA single color string referred to by name, RGB or RGBA code,for instance ‘red’ or ‘#a98d19’.\n\n\n\n\nA sequence of color strings referred to by name, RGB or RGBAcode, which will be used for each column recursively. For\ninstance [‘green’,’yellow’] each column’s bar will be filled in\ngreen or yellow, alternatively. If there is only a single column to\nbe plotted, then only the first color from the color list will be\nused.\n\n\n\n\nA dict of the form {column namecolor}, so that each column will becolored accordingly. For example, if your columns are called a and\nb, then passing {‘a’: ‘green’, ‘b’: ‘red’} will color bars for\ncolumn a in green and bars for column b in red.\n\n\n\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.barh.html#pandas.DataFrame.plot.barh"}, {"function_name": "pandas.DataFrame.plot.density", "full_function": "DataFrame.plot.density(bw_method=None, ind=None, **kwargs)", "function_text": "Generate Kernel Density Estimate plot using Gaussian kernels.", "parameter_names_desc": [{"param_name": "bw_method", "param_type": "str, scalar or callable, optional", "param_desc": "The method used to calculate the estimator bandwidth. This can be\n‘scott’, ‘silverman’, a scalar constant or a callable.\nIf None (default), ‘scott’ is used.\nSee scipy.stats.gaussian_kde for more information.\n"}, {"param_name": "ind", "param_type": "NumPy array or int, optional", "param_desc": "Evaluation points for the estimated PDF. If None (default),\n1000 equally spaced points are used. If ind is a NumPy array, the\nKDE is evaluated at the points passed. If ind is an integer,\nind number of equally spaced points are used.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.density.html#pandas.DataFrame.plot.density"}, {"function_name": "pandas.DataFrame.plot.hist", "full_function": "DataFrame.plot.hist(by=None, bins=10, **kwargs)", "function_text": "Draw one histogram of the DataFrame’s columns.", "parameter_names_desc": [{"param_name": "by", "param_type": "str or sequence, optional", "param_desc": "Column in the DataFrame to group by.\n\nChanged in version 1.4.0: Previously, by is silently ignore and makes no groupings\n\n"}, {"param_name": "bins", "param_type": "int, default 10", "param_desc": "Number of histogram bins to be used.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.hist.html#pandas.DataFrame.plot.hist"}, {"function_name": "pandas.DataFrame.plot.line", "full_function": "DataFrame.plot.line(x=None, y=None, **kwargs)", "function_text": "Plot Series or DataFrame as lines.", "parameter_names_desc": [{"param_name": "x", "param_type": "label or position, optional", "param_desc": "Allows plotting of one column versus another. If not specified,\nthe index of the DataFrame is used.\n"}, {"param_name": "y", "param_type": "label or position, optional", "param_desc": "Allows plotting of one column versus another. If not specified,\nall numerical columns are used.\n"}, {"param_name": "color", "param_type": "str, array-like, or dict, optional", "param_desc": "The color for each of the DataFrame’s columns. Possible values are:\n\n\nA single color string referred to by name, RGB or RGBA code,for instance ‘red’ or ‘#a98d19’.\n\n\n\n\nA sequence of color strings referred to by name, RGB or RGBAcode, which will be used for each column recursively. For\ninstance [‘green’,’yellow’] each column’s line will be filled in\ngreen or yellow, alternatively. If there is only a single column to\nbe plotted, then only the first color from the color list will be\nused.\n\n\n\n\nA dict of the form {column namecolor}, so that each column will becolored accordingly. For example, if your columns are called a and\nb, then passing {‘a’: ‘green’, ‘b’: ‘red’} will color lines for\ncolumn a in green and lines for column b in red.\n\n\n\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.line.html#pandas.DataFrame.plot.line"}, {"function_name": "pandas.DataFrame.plot.scatter", "full_function": "DataFrame.plot.scatter(x, y, s=None, c=None, **kwargs)", "function_text": "Create a scatter plot with varying marker point size and color.", "parameter_names_desc": [{"param_name": "x", "param_type": "int or str", "param_desc": "The column name or column position to be used as horizontal\ncoordinates for each point.\n"}, {"param_name": "y", "param_type": "int or str", "param_desc": "The column name or column position to be used as vertical\ncoordinates for each point.\n"}, {"param_name": "s", "param_type": "str, scalar or array-like, optional", "param_desc": "The size of each point. Possible values are:\n\nA string with the name of the column to be used for marker’s size.\nA single scalar so all points have the same size.\nA sequence of scalars, which will be used for each point’s size\nrecursively. For instance, when passing [2,14] all points size\nwill be either 2 or 14, alternatively.\n\n"}, {"param_name": "c", "param_type": "str, int or array-like, optional", "param_desc": "The color of each point. Possible values are:\n\nA single color string referred to by name, RGB or RGBA code,\nfor instance ‘red’ or ‘#a98d19’.\nA sequence of color strings referred to by name, RGB or RGBA\ncode, which will be used for each point’s color recursively. For\ninstance [‘green’,’yellow’] all points will be filled in green or\nyellow, alternatively.\nA column name or position whose values will be used to color the\nmarker points according to a colormap.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.scatter.html#pandas.DataFrame.plot.scatter"}, {"function_name": "pandas.DataFrame.boxplot", "full_function": "DataFrame.boxplot(column=None, by=None, ax=None, fontsize=None, rot=0, grid=True, figsize=None, layout=None, return_type=None, backend=None, **kwargs)", "function_text": "Make a box plot from DataFrame columns.", "parameter_names_desc": [{"param_name": "column", "param_type": "str or list of str, optional", "param_desc": "Column name or list of names, or vector.\nCan be any valid input to pandas.DataFrame.groupby().\n"}, {"param_name": "by", "param_type": "str or array-like, optional", "param_desc": "Column in the DataFrame to pandas.DataFrame.groupby().\nOne box-plot will be done per value of columns in by.\n"}, {"param_name": "ax", "param_type": "object of class matplotlib.axes.Axes, optional", "param_desc": "The matplotlib axes to be used by boxplot.\n"}, {"param_name": "fontsize", "param_type": "float or str", "param_desc": "Tick label font size in points or as a string (e.g., large).\n"}, {"param_name": "rot", "param_type": "float, default 0", "param_desc": "The rotation angle of labels (in degrees)\nwith respect to the screen coordinate system.\n"}, {"param_name": "grid", "param_type": "bool, default True", "param_desc": "Setting this to True will show the grid.\n"}, {"param_name": "figsize", "param_type": "A tuple (width, height) in inches", "param_desc": "The size of the figure to create in matplotlib.\n"}, {"param_name": "layout", "param_type": "tuple (rows, columns), optional", "param_desc": "For example, (3, 5) will display the subplots\nusing 3 rows and 5 columns, starting from the top-left.\n"}, {"param_name": "return_type", "param_type": "{‘axes’, ‘dict’, ‘both’} or None, default ‘axes’", "param_desc": "The kind of object to return. The default is axes.\n\n‘axes’ returns the matplotlib axes the boxplot is drawn on.\n‘dict’ returns a dictionary whose values are the matplotlib\nLines of the boxplot.\n‘both’ returns a namedtuple with the axes and dict.\nwhen grouping with by, a Series mapping columns to\nreturn_type is returned.\nIf return_type is None, a NumPy array\nof axes with the same shape as layout is returned.\n\n\n"}, {"param_name": "backend", "param_type": "str, default None", "param_desc": "Backend to use instead of the backend specified in the option\nplotting.backend. For instance, ‘matplotlib’. Alternatively, to\nspecify the plotting.backend for the whole session, set\npd.options.plotting.backend.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.boxplot.html#pandas.DataFrame.boxplot"}, {"function_name": "pandas.DataFrame.plot.bar", "full_function": "DataFrame.plot.bar(x=None, y=None, **kwargs)", "function_text": "Vertical bar plot.", "parameter_names_desc": [{"param_name": "x", "param_type": "label or position, optional", "param_desc": "Allows plotting of one column versus another. If not specified,\nthe index of the DataFrame is used.\n"}, {"param_name": "y", "param_type": "label or position, optional", "param_desc": "Allows plotting of one column versus another. If not specified,\nall numerical columns are used.\n"}, {"param_name": "color", "param_type": "str, array-like, or dict, optional", "param_desc": "The color for each of the DataFrame’s columns. Possible values are:\n\n\nA single color string referred to by name, RGB or RGBA code,for instance ‘red’ or ‘#a98d19’.\n\n\n\n\nA sequence of color strings referred to by name, RGB or RGBAcode, which will be used for each column recursively. For\ninstance [‘green’,’yellow’] each column’s bar will be filled in\ngreen or yellow, alternatively. If there is only a single column to\nbe plotted, then only the first color from the color list will be\nused.\n\n\n\n\nA dict of the form {column namecolor}, so that each column will becolored accordingly. For example, if your columns are called a and\nb, then passing {‘a’: ‘green’, ‘b’: ‘red’} will color bars for\ncolumn a in green and bars for column b in red.\n\n\n\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.bar.html#pandas.DataFrame.plot.bar"}, {"function_name": "pandas.DataFrame.plot.box", "full_function": "DataFrame.plot.box(by=None, **kwargs)", "function_text": "Make a box plot of the DataFrame columns.", "parameter_names_desc": [{"param_name": "by", "param_type": "str or sequence", "param_desc": "Column in the DataFrame to group by.\n\nChanged in version 1.4.0: Previously, by is silently ignore and makes no groupings\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.box.html#pandas.DataFrame.plot.box"}, {"function_name": "pandas.DataFrame.plot.hexbin", "full_function": "DataFrame.plot.hexbin(x, y, C=None, reduce_C_function=None, gridsize=None, **kwargs)", "function_text": "Generate a hexagonal binning plot.", "parameter_names_desc": [{"param_name": "x", "param_type": "int or str", "param_desc": "The column label or position for x points.\n"}, {"param_name": "y", "param_type": "int or str", "param_desc": "The column label or position for y points.\n"}, {"param_name": "C", "param_type": "int or str, optional", "param_desc": "The column label or position for the value of (x, y) point.\n"}, {"param_name": "reduce_C_function", "param_type": "callable, default np.mean", "param_desc": "Function of one argument that reduces all the values in a bin to\na single number (e.g. np.mean, np.max, np.sum, np.std).\n"}, {"param_name": "gridsize", "param_type": "int or tuple of (int, int), default 100", "param_desc": "The number of hexagons in the x-direction.\nThe corresponding number of hexagons in the y-direction is\nchosen in a way that the hexagons are approximately regular.\nAlternatively, gridsize can be a tuple with two elements\nspecifying the number of hexagons in the x-direction and the\ny-direction.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.hexbin.html#pandas.DataFrame.plot.hexbin"}, {"function_name": "pandas.DataFrame.plot.kde", "full_function": "DataFrame.plot.kde(bw_method=None, ind=None, **kwargs)", "function_text": "Generate Kernel Density Estimate plot using Gaussian kernels.", "parameter_names_desc": [{"param_name": "bw_method", "param_type": "str, scalar or callable, optional", "param_desc": "The method used to calculate the estimator bandwidth. This can be\n‘scott’, ‘silverman’, a scalar constant or a callable.\nIf None (default), ‘scott’ is used.\nSee scipy.stats.gaussian_kde for more information.\n"}, {"param_name": "ind", "param_type": "NumPy array or int, optional", "param_desc": "Evaluation points for the estimated PDF. If None (default),\n1000 equally spaced points are used. If ind is a NumPy array, the\nKDE is evaluated at the points passed. If ind is an integer,\nind number of equally spaced points are used.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.kde.html#pandas.DataFrame.plot.kde"}, {"function_name": "pandas.DataFrame.plot.pie", "full_function": "DataFrame.plot.pie(**kwargs)", "function_text": "Generate a pie plot.", "parameter_names_desc": [{"param_name": "y", "param_type": "int or label, optional", "param_desc": "Label or position of the column to plot.\nIf not provided, subplots=True argument must be passed.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.pie.html#pandas.DataFrame.plot.pie"}, {"function_name": "pandas.DataFrame.hist", "full_function": "DataFrame.hist(column=None, by=None, grid=True, xlabelsize=None, xrot=None, ylabelsize=None, yrot=None, ax=None, sharex=False, sharey=False, figsize=None, layout=None, bins=10, backend=None, legend=False, **kwargs)", "function_text": "Make a histogram of the DataFrame’s columns.", "parameter_names_desc": [{"param_name": "data", "param_type": "DataFrame", "param_desc": "The pandas object holding the data.\n"}, {"param_name": "column", "param_type": "str or sequence, optional", "param_desc": "If passed, will be used to limit data to a subset of columns.\n"}, {"param_name": "by", "param_type": "object, optional", "param_desc": "If passed, then used to form histograms for separate groups.\n"}, {"param_name": "grid", "param_type": "bool, default True", "param_desc": "Whether to show axis grid lines.\n"}, {"param_name": "xlabelsize", "param_type": "int, default None", "param_desc": "If specified changes the x-axis label size.\n"}, {"param_name": "xrot", "param_type": "float, default None", "param_desc": "Rotation of x axis labels. For example, a value of 90 displays the\nx labels rotated 90 degrees clockwise.\n"}, {"param_name": "ylabelsize", "param_type": "int, default None", "param_desc": "If specified changes the y-axis label size.\n"}, {"param_name": "yrot", "param_type": "float, default None", "param_desc": "Rotation of y axis labels. For example, a value of 90 displays the\ny labels rotated 90 degrees clockwise.\n"}, {"param_name": "ax", "param_type": "Matplotlib axes object, default None", "param_desc": "The axes to plot the histogram on.\n"}, {"param_name": "sharex", "param_type": "bool, default True if ax is None else False", "param_desc": "In case subplots=True, share x axis and set some x axis labels to\ninvisible; defaults to True if ax is None otherwise False if an ax\nis passed in.\nNote that passing in both an ax and sharex=True will alter all x axis\nlabels for all subplots in a figure.\n"}, {"param_name": "sharey", "param_type": "bool, default False", "param_desc": "In case subplots=True, share y axis and set some y axis labels to\ninvisible.\n"}, {"param_name": "figsize", "param_type": "tuple, optional", "param_desc": "The size in inches of the figure to create. Uses the value in\nmatplotlib.rcParams by default.\n"}, {"param_name": "layout", "param_type": "tuple, optional", "param_desc": "Tuple of (rows, columns) for the layout of the histograms.\n"}, {"param_name": "bins", "param_type": "int or sequence, default 10", "param_desc": "Number of histogram bins to be used. If an integer is given, bins + 1\nbin edges are calculated and returned. If bins is a sequence, gives\nbin edges, including left edge of first bin and right edge of last\nbin. In this case, bins is returned unmodified.\n"}, {"param_name": "backend", "param_type": "str, default None", "param_desc": "Backend to use instead of the backend specified in the option\nplotting.backend. For instance, ‘matplotlib’. Alternatively, to\nspecify the plotting.backend for the whole session, set\npd.options.plotting.backend.\n"}, {"param_name": "legend", "param_type": "bool, default False", "param_desc": "Whether to show the legend.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.hist.html#pandas.DataFrame.hist"}]}, {"name": "Sparse accessor", "url": "https://pandas.pydata.org/docs/reference/frame.html#sparse-accessor", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sparse.density.html#pandas.DataFrame.sparse.density", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sparse.from_spmatrix.html#pandas.DataFrame.sparse.from_spmatrix", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sparse.to_dense.html#pandas.DataFrame.sparse.to_dense", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sparse.to_coo.html#pandas.DataFrame.sparse.to_coo"], "function_definitions": [{"function_name": "pandas.DataFrame.sparse.density", "full_function": "DataFrame.sparse.density", "function_text": "Ratio of non-sparse points to total (dense) data points.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sparse.density.html#pandas.DataFrame.sparse.density"}, {"function_name": "pandas.DataFrame.sparse.from_spmatrix", "full_function": "classmethod DataFrame.sparse.from_spmatrix(data, index=None, columns=None)", "function_text": "Create a new DataFrame from a scipy sparse matrix.", "parameter_names_desc": [{"param_name": "data", "param_type": "scipy.sparse.spmatrix", "param_desc": "Must be convertible to csc format.\n"}, {"param_name": "index, columns", "param_type": "Index, optional", "param_desc": "Row and column labels to use for the resulting DataFrame.\nDefaults to a RangeIndex.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sparse.from_spmatrix.html#pandas.DataFrame.sparse.from_spmatrix"}, {"function_name": "pandas.DataFrame.sparse.to_dense", "full_function": "DataFrame.sparse.to_dense()", "function_text": "Convert a DataFrame with sparse values to dense.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sparse.to_dense.html#pandas.DataFrame.sparse.to_dense"}, {"function_name": "pandas.DataFrame.sparse.to_coo", "full_function": "DataFrame.sparse.to_coo()", "function_text": "Return the contents of the frame as a sparse SciPy COO matrix.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sparse.to_coo.html#pandas.DataFrame.sparse.to_coo"}]}, {"name": "Serialization / IO / conversion", "url": "https://pandas.pydata.org/docs/reference/frame.html#serialization-io-conversion", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.from_dict.html#pandas.DataFrame.from_dict", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_orc.html#pandas.DataFrame.to_orc", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_pickle.html#pandas.DataFrame.to_pickle", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_hdf.html#pandas.DataFrame.to_hdf", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_dict.html#pandas.DataFrame.to_dict", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_json.html#pandas.DataFrame.to_json", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_feather.html#pandas.DataFrame.to_feather", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_stata.html#pandas.DataFrame.to_stata", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_records.html#pandas.DataFrame.to_records", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_clipboard.html#pandas.DataFrame.to_clipboard", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.style.html#pandas.DataFrame.style", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.from_records.html#pandas.DataFrame.from_records", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_parquet.html#pandas.DataFrame.to_parquet", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html#pandas.DataFrame.to_csv", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_sql.html#pandas.DataFrame.to_sql", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_excel.html#pandas.DataFrame.to_excel", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_html.html#pandas.DataFrame.to_html", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_latex.html#pandas.DataFrame.to_latex", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_gbq.html#pandas.DataFrame.to_gbq", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_string.html#pandas.DataFrame.to_string", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_markdown.html#pandas.DataFrame.to_markdown", "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.__dataframe__.html#pandas.DataFrame.__dataframe__"], "function_definitions": [{"function_name": "pandas.DataFrame.from_dict", "full_function": "classmethod DataFrame.from_dict(data, orient='columns', dtype=None, columns=None)", "function_text": "Construct DataFrame from dict of array-like or dicts.", "parameter_names_desc": [{"param_name": "data", "param_type": "dict", "param_desc": "Of the form {field : array-like} or {field : dict}.\n"}, {"param_name": "orient", "param_type": "{‘columns’, ‘index’, ‘tight’}, default ‘columns’", "param_desc": "The “orientation” of the data. If the keys of the passed dict\nshould be the columns of the resulting DataFrame, pass ‘columns’\n(default). Otherwise if the keys should be rows, pass ‘index’.\nIf ‘tight’, assume a dict with keys [‘index’, ‘columns’, ‘data’,\n‘index_names’, ‘column_names’].\n\nNew in version 1.4.0: ‘tight’ as an allowed value for the orient argument\n\n"}, {"param_name": "dtype", "param_type": "dtype, default None", "param_desc": "Data type to force after DataFrame construction, otherwise infer.\n"}, {"param_name": "columns", "param_type": "list, default None", "param_desc": "Column labels to use when orient='index'. Raises a ValueError\nif used with orient='columns' or orient='tight'.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.from_dict.html#pandas.DataFrame.from_dict"}, {"function_name": "pandas.DataFrame.to_orc", "full_function": "DataFrame.to_orc(path=None, *, engine='pyarrow', index=None, engine_kwargs=None)", "function_text": "Write a DataFrame to the ORC format.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_orc.html#pandas.DataFrame.to_orc"}, {"function_name": "pandas.DataFrame.to_pickle", "full_function": "DataFrame.to_pickle(path, *, compression='infer', protocol=5, storage_options=None)", "function_text": "Pickle (serialize) object to file.", "parameter_names_desc": [{"param_name": "path", "param_type": "str, path object, or file-like object", "param_desc": "String, path object (implementing os.PathLike[str]), or file-like\nobject implementing a binary write() function. File path where\nthe pickled object will be stored.\n"}, {"param_name": "compression", "param_type": "str or dict, default ‘infer’", "param_desc": "For on-the-fly compression of the output data. If ‘infer’ and ‘path’ is\npath-like, then detect compression from the following extensions: ‘.gz’,\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\n(otherwise no compression).\nSet to None for no compression.\nCan also be a dict with key 'method' set\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\nother key-value pairs are forwarded to\nzipfile.ZipFile, gzip.GzipFile,\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\ntarfile.TarFile, respectively.\nAs an example, the following could be passed for faster compression and to create\na reproducible gzip archive:\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\n\nNew in version 1.5.0: Added support for .tar files.\n\n"}, {"param_name": "protocol", "param_type": "int", "param_desc": "Int which indicates which protocol should be used by the pickler,\ndefault HIGHEST_PROTOCOL (see [1] paragraph 12.1.2). The possible\nvalues are 0, 1, 2, 3, 4, 5. A negative value for the protocol\nparameter is equivalent to setting its value to HIGHEST_PROTOCOL.\n\n\n[1]\nhttps://docs.python.org/3/library/pickle.html.\n\n\n"}, {"param_name": "storage_options", "param_type": "dict, optional", "param_desc": "Extra options that make sense for a particular storage connection, e.g.\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\nare forwarded to urllib.request.Request as header options. For other\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\nforwarded to fsspec.open. Please see fsspec and urllib for more\ndetails, and for more examples on storage options refer here.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_pickle.html#pandas.DataFrame.to_pickle"}, {"function_name": "pandas.DataFrame.to_hdf", "full_function": "DataFrame.to_hdf(path_or_buf, *, key, mode='a', complevel=None, complib=None, append=False, format=None, index=True, min_itemsize=None, nan_rep=None, dropna=None, data_columns=None, errors='strict', encoding='UTF-8')", "function_text": "Write the contained data to an HDF5 file using HDFStore.", "parameter_names_desc": [{"param_name": "path_or_buf", "param_type": "str or pandas.HDFStore", "param_desc": "File path or HDFStore object.\n"}, {"param_name": "key", "param_type": "str", "param_desc": "Identifier for the group in the store.\n"}, {"param_name": "mode", "param_type": "{‘a’, ‘w’, ‘r+’}, default ‘a’", "param_desc": "Mode to open file:\n\n‘w’: write, a new file is created (an existing file with\nthe same name would be deleted).\n‘a’: append, an existing file is opened for reading and\nwriting, and if the file does not exist it is created.\n‘r+’: similar to ‘a’, but the file must already exist.\n\n"}, {"param_name": "complevel", "param_type": "{0-9}, default None", "param_desc": "Specifies a compression level for data.\nA value of 0 or None disables compression.\n"}, {"param_name": "complib", "param_type": "{‘zlib’, ‘lzo’, ‘bzip2’, ‘blosc’}, default ‘zlib’", "param_desc": "Specifies the compression library to be used.\nThese additional compressors for Blosc are supported\n(default if no compressor specified: ‘blosc:blosclz’):\n{‘blosc:blosclz’, ‘blosc:lz4’, ‘blosc:lz4hc’, ‘blosc:snappy’,\n‘blosc:zlib’, ‘blosc:zstd’}.\nSpecifying a compression library which is not available issues\na ValueError.\n"}, {"param_name": "append", "param_type": "bool, default False", "param_desc": "For Table formats, append the input data to the existing.\n"}, {"param_name": "format", "param_type": "{‘fixed’, ‘table’, None}, default ‘fixed’", "param_desc": "Possible values:\n\n‘fixed’: Fixed format. Fast writing/reading. Not-appendable,\nnor searchable.\n‘table’: Table format. Write as a PyTables Table structure\nwhich may perform worse but allow more flexible operations\nlike searching / selecting subsets of the data.\nIf None, pd.get_option(‘io.hdf.default_format’) is checked,\nfollowed by fallback to “fixed”.\n\n"}, {"param_name": "index", "param_type": "bool, default True", "param_desc": "Write DataFrame index as a column.\n"}, {"param_name": "min_itemsize", "param_type": "dict or int, optional", "param_desc": "Map column names to minimum string sizes for columns.\n"}, {"param_name": "nan_rep", "param_type": "Any, optional", "param_desc": "How to represent null values as str.\nNot allowed with append=True.\n"}, {"param_name": "dropna", "param_type": "bool, default False, optional", "param_desc": "Remove missing values.\n"}, {"param_name": "data_columns", "param_type": "list of columns or True, optional", "param_desc": "List of columns to create as indexed data columns for on-disk\nqueries, or True to use all columns. By default only the axes\nof the object are indexed. See\nQuery via data columns. for\nmore information.\nApplicable only to format=’table’.\n"}, {"param_name": "errors", "param_type": "str, default ‘strict’", "param_desc": "Specifies how encoding and decoding errors are to be handled.\nSee the errors argument for open() for a full list\nof options.\n"}, {"param_name": "encoding", "param_type": "str, default “UTF-8”", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_hdf.html#pandas.DataFrame.to_hdf"}, {"function_name": "pandas.DataFrame.to_dict", "full_function": "DataFrame.to_dict(orient='dict', *, into=<class 'dict'>, index=True)", "function_text": "Convert the DataFrame to a dictionary.", "parameter_names_desc": [{"param_name": "orient", "param_type": "str {‘dict’, ‘list’, ‘series’, ‘split’, ‘tight’, ‘records’, ‘index’}", "param_desc": "Determines the type of the values of the dictionary.\n\n‘dict’ (default) : dict like {column -> {index -> value}}\n‘list’ : dict like {column -> [values]}\n‘series’ : dict like {column -> Series(values)}\n‘split’ : dict like\n{‘index’ -> [index], ‘columns’ -> [columns], ‘data’ -> [values]}\n‘tight’ : dict like\n{‘index’ -> [index], ‘columns’ -> [columns], ‘data’ -> [values],\n‘index_names’ -> [index.names], ‘column_names’ -> [column.names]}\n‘records’ : list like\n[{column -> value}, … , {column -> value}]\n‘index’ : dict like {index -> {column -> value}}\n\n\nNew in version 1.4.0: ‘tight’ as an allowed value for the orient argument\n\n"}, {"param_name": "into", "param_type": "class, default dict", "param_desc": "The collections.abc.MutableMapping subclass used for all Mappings\nin the return value. Can be the actual class or an empty\ninstance of the mapping type you want. If you want a\ncollections.defaultdict, you must pass it initialized.\n"}, {"param_name": "index", "param_type": "bool, default True", "param_desc": "Whether to include the index item (and index_names item if orient\nis ‘tight’) in the returned dictionary. Can only be False\nwhen orient is ‘split’ or ‘tight’.\n\nNew in version 2.0.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_dict.html#pandas.DataFrame.to_dict"}, {"function_name": "pandas.DataFrame.to_json", "full_function": "DataFrame.to_json(path_or_buf=None, *, orient=None, date_format=None, double_precision=10, force_ascii=True, date_unit='ms', default_handler=None, lines=False, compression='infer', index=None, indent=None, storage_options=None, mode='w')", "function_text": "Convert the object to a JSON string.", "parameter_names_desc": [{"param_name": "path_or_buf", "param_type": "str, path object, file-like object, or None, default None", "param_desc": "String, path object (implementing os.PathLike[str]), or file-like\nobject implementing a write() function. If None, the result is\nreturned as a string.\n"}, {"param_name": "orient", "param_type": "str", "param_desc": "Indication of expected JSON string format.\n\nSeries:\n\n\ndefault is ‘index’\nallowed values are: {‘split’, ‘records’, ‘index’, ‘table’}.\n\n\n\nDataFrame:\n\n\ndefault is ‘columns’\nallowed values are: {‘split’, ‘records’, ‘index’, ‘columns’,\n‘values’, ‘table’}.\n\n\n\nThe format of the JSON string:\n\n\n‘split’ : dict like {‘index’ -> [index], ‘columns’ -> [columns],\n‘data’ -> [values]}\n‘records’ : list like [{column -> value}, … , {column -> value}]\n‘index’ : dict like {index -> {column -> value}}\n‘columns’ : dict like {column -> {index -> value}}\n‘values’ : just the values array\n‘table’ : dict like {‘schema’: {schema}, ‘data’: {data}}\n\nDescribing the data, where data component is like orient='records'.\n\n\n\n"}, {"param_name": "date_format", "param_type": "{None, ‘epoch’, ‘iso’}", "param_desc": "Type of date conversion. ‘epoch’ = epoch milliseconds,\n‘iso’ = ISO8601. The default depends on the orient. For\norient='table', the default is ‘iso’. For all other orients,\nthe default is ‘epoch’.\n"}, {"param_name": "double_precision", "param_type": "int, default 10", "param_desc": "The number of decimal places to use when encoding\nfloating point values. The possible maximal value is 15.\nPassing double_precision greater than 15 will raise a ValueError.\n"}, {"param_name": "force_ascii", "param_type": "bool, default True", "param_desc": "Force encoded string to be ASCII.\n"}, {"param_name": "date_unit", "param_type": "str, default ‘ms’ (milliseconds)", "param_desc": "The time unit to encode to, governs timestamp and ISO8601\nprecision. One of ‘s’, ‘ms’, ‘us’, ‘ns’ for second, millisecond,\nmicrosecond, and nanosecond respectively.\n"}, {"param_name": "default_handler", "param_type": "callable, default None", "param_desc": "Handler to call if object cannot otherwise be converted to a\nsuitable format for JSON. Should receive a single argument which is\nthe object to convert and return a serialisable object.\n"}, {"param_name": "lines", "param_type": "bool, default False", "param_desc": "If ‘orient’ is ‘records’ write out line-delimited json format. Will\nthrow ValueError if incorrect ‘orient’ since others are not\nlist-like.\n"}, {"param_name": "compression", "param_type": "str or dict, default ‘infer’", "param_desc": "For on-the-fly compression of the output data. If ‘infer’ and ‘path_or_buf’ is\npath-like, then detect compression from the following extensions: ‘.gz’,\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\n(otherwise no compression).\nSet to None for no compression.\nCan also be a dict with key 'method' set\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\nother key-value pairs are forwarded to\nzipfile.ZipFile, gzip.GzipFile,\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\ntarfile.TarFile, respectively.\nAs an example, the following could be passed for faster compression and to create\na reproducible gzip archive:\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\n\nNew in version 1.5.0: Added support for .tar files.\n\n\nChanged in version 1.4.0: Zstandard support.\n\n"}, {"param_name": "index", "param_type": "bool or None, default None", "param_desc": "The index is only used when ‘orient’ is ‘split’, ‘index’, ‘column’,\nor ‘table’. Of these, ‘index’ and ‘column’ do not support\nindex=False.\n"}, {"param_name": "indent", "param_type": "int, optional", "param_desc": "Length of whitespace used to indent each record.\n"}, {"param_name": "storage_options", "param_type": "dict, optional", "param_desc": "Extra options that make sense for a particular storage connection, e.g.\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\nare forwarded to urllib.request.Request as header options. For other\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\nforwarded to fsspec.open. Please see fsspec and urllib for more\ndetails, and for more examples on storage options refer here.\n"}, {"param_name": "mode", "param_type": "str, default ‘w’ (writing)", "param_desc": "Specify the IO mode for output when supplying a path_or_buf.\nAccepted args are ‘w’ (writing) and ‘a’ (append) only.\nmode=’a’ is only supported when lines is True and orient is ‘records’.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_json.html#pandas.DataFrame.to_json"}, {"function_name": "pandas.DataFrame.to_feather", "full_function": "DataFrame.to_feather(path, **kwargs)", "function_text": "Write a DataFrame to the binary Feather format.", "parameter_names_desc": [{"param_name": "path", "param_type": "str, path object, file-like object", "param_desc": "String, path object (implementing os.PathLike[str]), or file-like\nobject implementing a binary write() function. If a string or a path,\nit will be used as Root Directory path when writing a partitioned dataset.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_feather.html#pandas.DataFrame.to_feather"}, {"function_name": "pandas.DataFrame.to_stata", "full_function": "DataFrame.to_stata(path, *, convert_dates=None, write_index=True, byteorder=None, time_stamp=None, data_label=None, variable_labels=None, version=114, convert_strl=None, compression='infer', storage_options=None, value_labels=None)", "function_text": "Export DataFrame object to Stata dta format.", "parameter_names_desc": [{"param_name": "path", "param_type": "str, path object, or buffer", "param_desc": "String, path object (implementing os.PathLike[str]), or file-like\nobject implementing a binary write() function.\n"}, {"param_name": "convert_dates", "param_type": "dict", "param_desc": "Dictionary mapping columns containing datetime types to stata\ninternal format to use when writing the dates. Options are ‘tc’,\n‘td’, ‘tm’, ‘tw’, ‘th’, ‘tq’, ‘ty’. Column can be either an integer\nor a name. Datetime columns that do not have a conversion type\nspecified will be converted to ‘tc’. Raises NotImplementedError if\na datetime column has timezone information.\n"}, {"param_name": "write_index", "param_type": "bool", "param_desc": "Write the index to Stata dataset.\n"}, {"param_name": "byteorder", "param_type": "str", "param_desc": "Can be “>”, “<”, “little”, or “big”. default is sys.byteorder.\n"}, {"param_name": "time_stamp", "param_type": "datetime", "param_desc": "A datetime to use as file creation date. Default is the current\ntime.\n"}, {"param_name": "data_label", "param_type": "str, optional", "param_desc": "A label for the data set. Must be 80 characters or smaller.\n"}, {"param_name": "variable_labels", "param_type": "dict", "param_desc": "Dictionary containing columns as keys and variable labels as\nvalues. Each label must be 80 characters or smaller.\n"}, {"param_name": "version", "param_type": "{114, 117, 118, 119, None}, default 114", "param_desc": "Version to use in the output dta file. Set to None to let pandas\ndecide between 118 or 119 formats depending on the number of\ncolumns in the frame. Version 114 can be read by Stata 10 and\nlater. Version 117 can be read by Stata 13 or later. Version 118\nis supported in Stata 14 and later. Version 119 is supported in\nStata 15 and later. Version 114 limits string variables to 244\ncharacters or fewer while versions 117 and later allow strings\nwith lengths up to 2,000,000 characters. Versions 118 and 119\nsupport Unicode characters, and version 119 supports more than\n32,767 variables.\nVersion 119 should usually only be used when the number of\nvariables exceeds the capacity of dta format 118. Exporting\nsmaller datasets in format 119 may have unintended consequences,\nand, as of November 2020, Stata SE cannot read version 119 files.\n"}, {"param_name": "convert_strl", "param_type": "list, optional", "param_desc": "List of column names to convert to string columns to Stata StrL\nformat. Only available if version is 117. Storing strings in the\nStrL format can produce smaller dta files if strings have more than\n8 characters and values are repeated.\n"}, {"param_name": "compression", "param_type": "str or dict, default ‘infer’", "param_desc": "For on-the-fly compression of the output data. If ‘infer’ and ‘path’ is\npath-like, then detect compression from the following extensions: ‘.gz’,\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\n(otherwise no compression).\nSet to None for no compression.\nCan also be a dict with key 'method' set\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\nother key-value pairs are forwarded to\nzipfile.ZipFile, gzip.GzipFile,\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\ntarfile.TarFile, respectively.\nAs an example, the following could be passed for faster compression and to create\na reproducible gzip archive:\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\n\nNew in version 1.5.0: Added support for .tar files.\n\n\nChanged in version 1.4.0: Zstandard support.\n\n"}, {"param_name": "storage_options", "param_type": "dict, optional", "param_desc": "Extra options that make sense for a particular storage connection, e.g.\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\nare forwarded to urllib.request.Request as header options. For other\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\nforwarded to fsspec.open. Please see fsspec and urllib for more\ndetails, and for more examples on storage options refer here.\n"}, {"param_name": "value_labels", "param_type": "dict of dicts", "param_desc": "Dictionary containing columns as keys and dictionaries of column value\nto labels as values. Labels for a single variable must be 32,000\ncharacters or smaller.\n\nNew in version 1.4.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_stata.html#pandas.DataFrame.to_stata"}, {"function_name": "pandas.DataFrame.to_records", "full_function": "DataFrame.to_records(index=True, column_dtypes=None, index_dtypes=None)", "function_text": "Convert DataFrame to a NumPy record array.", "parameter_names_desc": [{"param_name": "index", "param_type": "bool, default True", "param_desc": "Include index in resulting record array, stored in ‘index’\nfield or using the index label, if set.\n"}, {"param_name": "column_dtypes", "param_type": "str, type, dict, default None", "param_desc": "If a string or type, the data type to store all columns. If\na dictionary, a mapping of column names and indices (zero-indexed)\nto specific data types.\n"}, {"param_name": "index_dtypes", "param_type": "str, type, dict, default None", "param_desc": "If a string or type, the data type to store all index levels. If\na dictionary, a mapping of index level names and indices\n(zero-indexed) to specific data types.\nThis mapping is applied only if index=True.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_records.html#pandas.DataFrame.to_records"}, {"function_name": "pandas.DataFrame.to_clipboard", "full_function": "DataFrame.to_clipboard(*, excel=True, sep=None, **kwargs)", "function_text": "Copy object to the system clipboard.", "parameter_names_desc": [{"param_name": "excel", "param_type": "bool, default True", "param_desc": "Produce output in a csv format for easy pasting into excel.\n\nTrue, use the provided separator for csv pasting.\nFalse, write a string representation of the object to the clipboard.\n\n"}, {"param_name": "sep", "param_type": "str, default '\\t'", "param_desc": "Field delimiter.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_clipboard.html#pandas.DataFrame.to_clipboard"}, {"function_name": "pandas.DataFrame.style", "full_function": "property DataFrame.style", "function_text": "Returns a Styler object.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.style.html#pandas.DataFrame.style"}, {"function_name": "pandas.DataFrame.from_records", "full_function": "classmethod DataFrame.from_records(data, index=None, exclude=None, columns=None, coerce_float=False, nrows=None)", "function_text": "Convert structured or record ndarray to DataFrame.", "parameter_names_desc": [{"param_name": "data", "param_type": "structured ndarray, sequence of tuples or dicts, or DataFrame", "param_desc": "Structured input data.\n\nDeprecated since version 2.1.0: Passing a DataFrame is deprecated.\n\n"}, {"param_name": "index", "param_type": "str, list of fields, array-like", "param_desc": "Field of array to use as the index, alternately a specific set of\ninput labels to use.\n"}, {"param_name": "exclude", "param_type": "sequence, default None", "param_desc": "Columns or fields to exclude.\n"}, {"param_name": "columns", "param_type": "sequence, default None", "param_desc": "Column names to use. If the passed data do not have names\nassociated with them, this argument provides names for the\ncolumns. Otherwise this argument indicates the order of the columns\nin the result (any names not found in the data will become all-NA\ncolumns).\n"}, {"param_name": "coerce_float", "param_type": "bool, default False", "param_desc": "Attempt to convert values of non-string, non-numeric objects (like\ndecimal.Decimal) to floating point, useful for SQL result sets.\n"}, {"param_name": "nrows", "param_type": "int, default None", "param_desc": "Number of rows to read if data is an iterator.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.from_records.html#pandas.DataFrame.from_records"}, {"function_name": "pandas.DataFrame.to_parquet", "full_function": "DataFrame.to_parquet(path=None, *, engine='auto', compression='snappy', index=None, partition_cols=None, storage_options=None, **kwargs)", "function_text": "Write a DataFrame to the binary parquet format.", "parameter_names_desc": [{"param_name": "path", "param_type": "str, path object, file-like object, or None, default None", "param_desc": "String, path object (implementing os.PathLike[str]), or file-like\nobject implementing a binary write() function. If None, the result is\nreturned as bytes. If a string or path, it will be used as Root Directory\npath when writing a partitioned dataset.\n"}, {"param_name": "engine", "param_type": "{‘auto’, ‘pyarrow’, ‘fastparquet’}, default ‘auto’", "param_desc": "Parquet library to use. If ‘auto’, then the option\nio.parquet.engine is used. The default io.parquet.engine\nbehavior is to try ‘pyarrow’, falling back to ‘fastparquet’ if\n‘pyarrow’ is unavailable.\n"}, {"param_name": "compression", "param_type": "str or None, default ‘snappy’", "param_desc": "Name of the compression to use. Use None for no compression.\nSupported options: ‘snappy’, ‘gzip’, ‘brotli’, ‘lz4’, ‘zstd’.\n"}, {"param_name": "index", "param_type": "bool, default None", "param_desc": "If True, include the dataframe’s index(es) in the file output.\nIf False, they will not be written to the file.\nIf None, similar to True the dataframe’s index(es)\nwill be saved. However, instead of being saved as values,\nthe RangeIndex will be stored as a range in the metadata so it\ndoesn’t require much space and is faster. Other indexes will\nbe included as columns in the file output.\n"}, {"param_name": "partition_cols", "param_type": "list, optional, default None", "param_desc": "Column names by which to partition the dataset.\nColumns are partitioned in the order they are given.\nMust be None if path is not a string.\n"}, {"param_name": "storage_options", "param_type": "dict, optional", "param_desc": "Extra options that make sense for a particular storage connection, e.g.\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\nare forwarded to urllib.request.Request as header options. For other\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\nforwarded to fsspec.open. Please see fsspec and urllib for more\ndetails, and for more examples on storage options refer here.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_parquet.html#pandas.DataFrame.to_parquet"}, {"function_name": "pandas.DataFrame.to_csv", "full_function": "DataFrame.to_csv(path_or_buf=None, *, sep=',', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, mode='w', encoding=None, compression='infer', quoting=None, quotechar='\"', lineterminator=None, chunksize=None, date_format=None, doublequote=True, escapechar=None, decimal='.', errors='strict', storage_options=None)", "function_text": "Write object to a comma-separated values (csv) file.", "parameter_names_desc": [{"param_name": "path_or_buf", "param_type": "str, path object, file-like object, or None, default None", "param_desc": "String, path object (implementing os.PathLike[str]), or file-like\nobject implementing a write() function. If None, the result is\nreturned as a string. If a non-binary file object is passed, it should\nbe opened with newline=’’, disabling universal newlines. If a binary\nfile object is passed, mode might need to contain a ‘b’.\n"}, {"param_name": "sep", "param_type": "str, default ‘,’", "param_desc": "String of length 1. Field delimiter for the output file.\n"}, {"param_name": "na_rep", "param_type": "str, default ‘’", "param_desc": "Missing data representation.\n"}, {"param_name": "float_format", "param_type": "str, Callable, default None", "param_desc": "Format string for floating point numbers. If a Callable is given, it takes\nprecedence over other numeric formatting parameters, like decimal.\n"}, {"param_name": "columns", "param_type": "sequence, optional", "param_desc": "Columns to write.\n"}, {"param_name": "header", "param_type": "bool or list of str, default True", "param_desc": "Write out the column names. If a list of strings is given it is\nassumed to be aliases for the column names.\n"}, {"param_name": "index", "param_type": "bool, default True", "param_desc": "Write row names (index).\n"}, {"param_name": "index_label", "param_type": "str or sequence, or False, default None", "param_desc": "Column label for index column(s) if desired. If None is given, and\nheader and index are True, then the index names are used. A\nsequence should be given if the object uses MultiIndex. If\nFalse do not print fields for index names. Use index_label=False\nfor easier importing in R.\n"}, {"param_name": "mode", "param_type": "{‘w’, ‘x’, ‘a’}, default ‘w’", "param_desc": "Forwarded to either open(mode=) or fsspec.open(mode=) to control\nthe file opening. Typical values include:\n\n‘w’, truncate the file first.\n‘x’, exclusive creation, failing if the file already exists.\n‘a’, append to the end of file if it exists.\n\n"}, {"param_name": "encoding", "param_type": "str, optional", "param_desc": "A string representing the encoding to use in the output file,\ndefaults to ‘utf-8’. encoding is not supported if path_or_buf\nis a non-binary file object.\n"}, {"param_name": "compression", "param_type": "str or dict, default ‘infer’", "param_desc": "For on-the-fly compression of the output data. If ‘infer’ and ‘path_or_buf’ is\npath-like, then detect compression from the following extensions: ‘.gz’,\n‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’\n(otherwise no compression).\nSet to None for no compression.\nCan also be a dict with key 'method' set\nto one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and\nother key-value pairs are forwarded to\nzipfile.ZipFile, gzip.GzipFile,\nbz2.BZ2File, zstandard.ZstdCompressor, lzma.LZMAFile or\ntarfile.TarFile, respectively.\nAs an example, the following could be passed for faster compression and to create\na reproducible gzip archive:\ncompression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}.\n\nNew in version 1.5.0: Added support for .tar files.\nMay be a dict with key ‘method’ as compression mode\nand other entries as additional compression options if\ncompression mode is ‘zip’.\nPassing compression options as keys in dict is\nsupported for compression modes ‘gzip’, ‘bz2’, ‘zstd’, and ‘zip’.\n\n"}, {"param_name": "quoting", "param_type": "optional constant from csv module", "param_desc": "Defaults to csv.QUOTE_MINIMAL. If you have set a float_format\nthen floats are converted to strings and thus csv.QUOTE_NONNUMERIC\nwill treat them as non-numeric.\n"}, {"param_name": "quotechar", "param_type": "str, default ‘\"’", "param_desc": "String of length 1. Character used to quote fields.\n"}, {"param_name": "lineterminator", "param_type": "str, optional", "param_desc": "The newline character or character sequence to use in the output\nfile. Defaults to os.linesep, which depends on the OS in which\nthis method is called (’\\n’ for linux, ‘\\r\\n’ for Windows, i.e.).\n\nChanged in version 1.5.0: Previously was line_terminator, changed for consistency with\nread_csv and the standard library ‘csv’ module.\n\n"}, {"param_name": "chunksize", "param_type": "int or None", "param_desc": "Rows to write at a time.\n"}, {"param_name": "date_format", "param_type": "str, default None", "param_desc": "Format string for datetime objects.\n"}, {"param_name": "doublequote", "param_type": "bool, default True", "param_desc": "Control quoting of quotechar inside a field.\n"}, {"param_name": "escapechar", "param_type": "str, default None", "param_desc": "String of length 1. Character used to escape sep and quotechar\nwhen appropriate.\n"}, {"param_name": "decimal", "param_type": "str, default ‘.’", "param_desc": "Character recognized as decimal separator. E.g. use ‘,’ for\nEuropean data.\n"}, {"param_name": "errors", "param_type": "str, default ‘strict’", "param_desc": "Specifies how encoding and decoding errors are to be handled.\nSee the errors argument for open() for a full list\nof options.\n"}, {"param_name": "storage_options", "param_type": "dict, optional", "param_desc": "Extra options that make sense for a particular storage connection, e.g.\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\nare forwarded to urllib.request.Request as header options. For other\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\nforwarded to fsspec.open. Please see fsspec and urllib for more\ndetails, and for more examples on storage options refer here.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html#pandas.DataFrame.to_csv"}, {"function_name": "pandas.DataFrame.to_sql", "full_function": "DataFrame.to_sql(name, con, *, schema=None, if_exists='fail', index=True, index_label=None, chunksize=None, dtype=None, method=None)", "function_text": "Write records stored in a DataFrame to a SQL database.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_sql.html#pandas.DataFrame.to_sql"}, {"function_name": "pandas.DataFrame.to_excel", "full_function": "DataFrame.to_excel(excel_writer, *, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, inf_rep='inf', freeze_panes=None, storage_options=None, engine_kwargs=None)", "function_text": "Write object to an Excel sheet.", "parameter_names_desc": [{"param_name": "excel_writer", "param_type": "path-like, file-like, or ExcelWriter object", "param_desc": "File path or existing ExcelWriter.\n"}, {"param_name": "sheet_name", "param_type": "str, default ‘Sheet1’", "param_desc": "Name of sheet which will contain DataFrame.\n"}, {"param_name": "na_rep", "param_type": "str, default ‘’", "param_desc": "Missing data representation.\n"}, {"param_name": "float_format", "param_type": "str, optional", "param_desc": "Format string for floating point numbers. For example\nfloat_format=\"%.2f\" will format 0.1234 to 0.12.\n"}, {"param_name": "columns", "param_type": "sequence or list of str, optional", "param_desc": "Columns to write.\n"}, {"param_name": "header", "param_type": "bool or list of str, default True", "param_desc": "Write out the column names. If a list of string is given it is\nassumed to be aliases for the column names.\n"}, {"param_name": "index", "param_type": "bool, default True", "param_desc": "Write row names (index).\n"}, {"param_name": "index_label", "param_type": "str or sequence, optional", "param_desc": "Column label for index column(s) if desired. If not specified, and\nheader and index are True, then the index names are used. A\nsequence should be given if the DataFrame uses MultiIndex.\n"}, {"param_name": "startrow", "param_type": "int, default 0", "param_desc": "Upper left cell row to dump data frame.\n"}, {"param_name": "startcol", "param_type": "int, default 0", "param_desc": "Upper left cell column to dump data frame.\n"}, {"param_name": "engine", "param_type": "str, optional", "param_desc": "Write engine to use, ‘openpyxl’ or ‘xlsxwriter’. You can also set this\nvia the options io.excel.xlsx.writer or\nio.excel.xlsm.writer.\n"}, {"param_name": "merge_cells", "param_type": "bool, default True", "param_desc": "Write MultiIndex and Hierarchical Rows as merged cells.\n"}, {"param_name": "inf_rep", "param_type": "str, default ‘inf’", "param_desc": "Representation for infinity (there is no native representation for\ninfinity in Excel).\n"}, {"param_name": "freeze_panes", "param_type": "tuple of int (length 2), optional", "param_desc": "Specifies the one-based bottommost row and rightmost column that\nis to be frozen.\n"}, {"param_name": "storage_options", "param_type": "dict, optional", "param_desc": "Extra options that make sense for a particular storage connection, e.g.\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\nare forwarded to urllib.request.Request as header options. For other\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\nforwarded to fsspec.open. Please see fsspec and urllib for more\ndetails, and for more examples on storage options refer here.\n\nNew in version 1.2.0.\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, optional", "param_desc": "Arbitrary keyword arguments passed to excel engine.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_excel.html#pandas.DataFrame.to_excel"}, {"function_name": "pandas.DataFrame.to_html", "full_function": "DataFrame.to_html(buf=None, *, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, justify=None, max_rows=None, max_cols=None, show_dimensions=False, decimal='.', bold_rows=True, classes=None, escape=True, notebook=False, border=None, table_id=None, render_links=False, encoding=None)", "function_text": "Render a DataFrame as an HTML table.", "parameter_names_desc": [{"param_name": "buf", "param_type": "str, Path or StringIO-like, optional, default None", "param_desc": "Buffer to write to. If None, the output is returned as a string.\n"}, {"param_name": "columns", "param_type": "array-like, optional, default None", "param_desc": "The subset of columns to write. Writes all columns by default.\n"}, {"param_name": "col_space", "param_type": "str or int, list or dict of int or str, optional", "param_desc": "The minimum width of each column in CSS length units. An int is assumed to be px units..\n"}, {"param_name": "header", "param_type": "bool, optional", "param_desc": "Whether to print column labels, default True.\n"}, {"param_name": "index", "param_type": "bool, optional, default True", "param_desc": "Whether to print index (row) labels.\n"}, {"param_name": "na_rep", "param_type": "str, optional, default ‘NaN’", "param_desc": "String representation of NaN to use.\n"}, {"param_name": "formatters", "param_type": "list, tuple or dict of one-param. functions, optional", "param_desc": "Formatter functions to apply to columns’ elements by position or\nname.\nThe result of each function must be a unicode string.\nList/tuple must be of length equal to the number of columns.\n"}, {"param_name": "float_format", "param_type": "one-parameter function, optional, default None", "param_desc": "Formatter function to apply to columns’ elements if they are\nfloats. This function must return a unicode string and will be\napplied only to the non-NaN elements, with NaN being\nhandled by na_rep.\n"}, {"param_name": "sparsify", "param_type": "bool, optional, default True", "param_desc": "Set to False for a DataFrame with a hierarchical index to print\nevery multiindex key at each row.\n"}, {"param_name": "index_names", "param_type": "bool, optional, default True", "param_desc": "Prints the names of the indexes.\n"}, {"param_name": "justify", "param_type": "str, default None", "param_desc": "How to justify the column labels. If None uses the option from\nthe print configuration (controlled by set_option), ‘right’ out\nof the box. Valid values are\n\nleft\nright\ncenter\njustify\njustify-all\nstart\nend\ninherit\nmatch-parent\ninitial\nunset.\n\n"}, {"param_name": "max_rows", "param_type": "int, optional", "param_desc": "Maximum number of rows to display in the console.\n"}, {"param_name": "max_cols", "param_type": "int, optional", "param_desc": "Maximum number of columns to display in the console.\n"}, {"param_name": "show_dimensions", "param_type": "bool, default False", "param_desc": "Display DataFrame dimensions (number of rows by number of columns).\n"}, {"param_name": "decimal", "param_type": "str, default ‘.’", "param_desc": "Character recognized as decimal separator, e.g. ‘,’ in Europe.\n"}, {"param_name": "bold_rows", "param_type": "bool, default True", "param_desc": "Make the row labels bold in the output.\n"}, {"param_name": "classes", "param_type": "str or list or tuple, default None", "param_desc": "CSS class(es) to apply to the resulting html table.\n"}, {"param_name": "escape", "param_type": "bool, default True", "param_desc": "Convert the characters <, >, and & to HTML-safe sequences.\n"}, {"param_name": "notebook", "param_type": "{True, False}, default False", "param_desc": "Whether the generated HTML is for IPython Notebook.\n"}, {"param_name": "border", "param_type": "int", "param_desc": "A border=border attribute is included in the opening\n<table> tag. Default pd.options.display.html.border.\n"}, {"param_name": "table_id", "param_type": "str, optional", "param_desc": "A css id is included in the opening <table> tag if specified.\n"}, {"param_name": "render_links", "param_type": "bool, default False", "param_desc": "Convert URLs to HTML links.\n"}, {"param_name": "encoding", "param_type": "str, default “utf-8”", "param_desc": "Set character encoding.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_html.html#pandas.DataFrame.to_html"}, {"function_name": "pandas.DataFrame.to_latex", "full_function": "DataFrame.to_latex(buf=None, *, columns=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, bold_rows=False, column_format=None, longtable=None, escape=None, encoding=None, decimal='.', multicolumn=None, multicolumn_format=None, multirow=None, caption=None, label=None, position=None)", "function_text": "Render object to a LaTeX tabular, longtable, or nested table.", "parameter_names_desc": [{"param_name": "buf", "param_type": "str, Path or StringIO-like, optional, default None", "param_desc": "Buffer to write to. If None, the output is returned as a string.\n"}, {"param_name": "columns", "param_type": "list of label, optional", "param_desc": "The subset of columns to write. Writes all columns by default.\n"}, {"param_name": "header", "param_type": "bool or list of str, default True", "param_desc": "Write out the column names. If a list of strings is given,\nit is assumed to be aliases for the column names.\n"}, {"param_name": "index", "param_type": "bool, default True", "param_desc": "Write row names (index).\n"}, {"param_name": "na_rep", "param_type": "str, default ‘NaN’", "param_desc": "Missing data representation.\n"}, {"param_name": "formatters", "param_type": "list of functions or dict of {{str: function}}, optional", "param_desc": "Formatter functions to apply to columns’ elements by position or\nname. The result of each function must be a unicode string.\nList must be of length equal to the number of columns.\n"}, {"param_name": "float_format", "param_type": "one-parameter function or str, optional, default None", "param_desc": "Formatter for floating point numbers. For example\nfloat_format=\"%.2f\" and float_format=\"{{:0.2f}}\".format will\nboth result in 0.1234 being formatted as 0.12.\n"}, {"param_name": "sparsify", "param_type": "bool, optional", "param_desc": "Set to False for a DataFrame with a hierarchical index to print\nevery multiindex key at each row. By default, the value will be\nread from the config module.\n"}, {"param_name": "index_names", "param_type": "bool, default True", "param_desc": "Prints the names of the indexes.\n"}, {"param_name": "bold_rows", "param_type": "bool, default False", "param_desc": "Make the row labels bold in the output.\n"}, {"param_name": "column_format", "param_type": "str, optional", "param_desc": "The columns format as specified in LaTeX table format e.g. ‘rcl’ for 3\ncolumns. By default, ‘l’ will be used for all columns except\ncolumns of numbers, which default to ‘r’.\n"}, {"param_name": "longtable", "param_type": "bool, optional", "param_desc": "Use a longtable environment instead of tabular. Requires\nadding a usepackage{{longtable}} to your LaTeX preamble.\nBy default, the value will be read from the pandas config\nmodule, and set to True if the option styler.latex.environment is\n“longtable”.\n\nChanged in version 2.0.0: The pandas option affecting this argument has changed.\n\n"}, {"param_name": "escape", "param_type": "bool, optional", "param_desc": "By default, the value will be read from the pandas config\nmodule and set to True if the option styler.format.escape is\n“latex”. When set to False prevents from escaping latex special\ncharacters in column names.\n\nChanged in version 2.0.0: The pandas option affecting this argument has changed, as has the\ndefault value to False.\n\n"}, {"param_name": "encoding", "param_type": "str, optional", "param_desc": "A string representing the encoding to use in the output file,\ndefaults to ‘utf-8’.\n"}, {"param_name": "decimal", "param_type": "str, default ‘.’", "param_desc": "Character recognized as decimal separator, e.g. ‘,’ in Europe.\n"}, {"param_name": "multicolumn", "param_type": "bool, default True", "param_desc": "Use multicolumn to enhance MultiIndex columns.\nThe default will be read from the config module, and is set\nas the option styler.sparse.columns.\n\nChanged in version 2.0.0: The pandas option affecting this argument has changed.\n\n"}, {"param_name": "multicolumn_format", "param_type": "str, default ‘r’", "param_desc": "The alignment for multicolumns, similar to column_format\nThe default will be read from the config module, and is set as the option\nstyler.latex.multicol_align.\n\nChanged in version 2.0.0: The pandas option affecting this argument has changed, as has the\ndefault value to “r”.\n\n"}, {"param_name": "multirow", "param_type": "bool, default True", "param_desc": "Use multirow to enhance MultiIndex rows. Requires adding a\nusepackage{{multirow}} to your LaTeX preamble. Will print\ncentered labels (instead of top-aligned) across the contained\nrows, separating groups via clines. The default will be read\nfrom the pandas config module, and is set as the option\nstyler.sparse.index.\n\nChanged in version 2.0.0: The pandas option affecting this argument has changed, as has the\ndefault value to True.\n\n"}, {"param_name": "caption", "param_type": "str or tuple, optional", "param_desc": "Tuple (full_caption, short_caption),\nwhich results in \\caption[short_caption]{{full_caption}};\nif a single string is passed, no short caption will be set.\n"}, {"param_name": "label", "param_type": "str, optional", "param_desc": "The LaTeX label to be placed inside \\label{{}} in the output.\nThis is used with \\ref{{}} in the main .tex file.\n"}, {"param_name": "position", "param_type": "str, optional", "param_desc": "The LaTeX positional argument for tables, to be placed after\n\\begin{{}} in the output.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_latex.html#pandas.DataFrame.to_latex"}, {"function_name": "pandas.DataFrame.to_gbq", "full_function": "DataFrame.to_gbq(destination_table, *, project_id=None, chunksize=None, reauth=False, if_exists='fail', auth_local_webserver=True, table_schema=None, location=None, progress_bar=True, credentials=None)", "function_text": "Write a DataFrame to a Google BigQuery table.", "parameter_names_desc": [{"param_name": "destination_table", "param_type": "str", "param_desc": "Name of table to be written, in the form dataset.tablename.\n"}, {"param_name": "project_id", "param_type": "str, optional", "param_desc": "Google BigQuery Account project ID. Optional when available from\nthe environment.\n"}, {"param_name": "chunksize", "param_type": "int, optional", "param_desc": "Number of rows to be inserted in each chunk from the dataframe.\nSet to None to load the whole dataframe at once.\n"}, {"param_name": "reauth", "param_type": "bool, default False", "param_desc": "Force Google BigQuery to re-authenticate the user. This is useful\nif multiple accounts are used.\n"}, {"param_name": "if_exists", "param_type": "str, default ‘fail’", "param_desc": "Behavior when the destination table exists. Value can be one of:\n\n'fail'If table exists raise pandas_gbq.gbq.TableCreationError.\n\n'replace'If table exists, drop it, recreate it, and insert data.\n\n'append'If table exists, insert data. Create if does not exist.\n\n\n"}, {"param_name": "auth_local_webserver", "param_type": "bool, default True", "param_desc": "Use the local webserver flow instead of the console flow\nwhen getting user credentials.\nNew in version 0.2.0 of pandas-gbq.\n\nChanged in version 1.5.0: Default value is changed to True. Google has deprecated the\nauth_local_webserver = False “out of band” (copy-paste)\nflow.\n\n"}, {"param_name": "table_schema", "param_type": "list of dicts, optional", "param_desc": "List of BigQuery table fields to which according DataFrame\ncolumns conform to, e.g. [{'name': 'col1', 'type':\n'STRING'},...]. If schema is not provided, it will be\ngenerated according to dtypes of DataFrame columns. See\nBigQuery API documentation on available names of a field.\nNew in version 0.3.1 of pandas-gbq.\n"}, {"param_name": "location", "param_type": "str, optional", "param_desc": "Location where the load job should run. See the BigQuery locations\ndocumentation for a\nlist of available locations. The location must match that of the\ntarget dataset.\nNew in version 0.5.0 of pandas-gbq.\n"}, {"param_name": "progress_bar", "param_type": "bool, default True", "param_desc": "Use the library tqdm to show the progress bar for the upload,\nchunk by chunk.\nNew in version 0.5.0 of pandas-gbq.\n"}, {"param_name": "credentials", "param_type": "google.auth.credentials.Credentials, optional", "param_desc": "Credentials for accessing Google APIs. Use this parameter to\noverride default credentials, such as to use Compute Engine\ngoogle.auth.compute_engine.Credentials or Service\nAccount google.oauth2.service_account.Credentials\ndirectly.\nNew in version 0.8.0 of pandas-gbq.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_gbq.html#pandas.DataFrame.to_gbq"}, {"function_name": "pandas.DataFrame.to_string", "full_function": "DataFrame.to_string(buf=None, *, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, justify=None, max_rows=None, max_cols=None, show_dimensions=False, decimal='.', line_width=None, min_rows=None, max_colwidth=None, encoding=None)", "function_text": "Render a DataFrame to a console-friendly tabular output.", "parameter_names_desc": [{"param_name": "buf", "param_type": "str, Path or StringIO-like, optional, default None", "param_desc": "Buffer to write to. If None, the output is returned as a string.\n"}, {"param_name": "columns", "param_type": "array-like, optional, default None", "param_desc": "The subset of columns to write. Writes all columns by default.\n"}, {"param_name": "col_space", "param_type": "int, list or dict of int, optional", "param_desc": "The minimum width of each column. If a list of ints is given every integers corresponds with one column. If a dict is given, the key references the column, while the value defines the space to use..\n"}, {"param_name": "header", "param_type": "bool or list of str, optional", "param_desc": "Write out the column names. If a list of columns is given, it is assumed to be aliases for the column names.\n"}, {"param_name": "index", "param_type": "bool, optional, default True", "param_desc": "Whether to print index (row) labels.\n"}, {"param_name": "na_rep", "param_type": "str, optional, default ‘NaN’", "param_desc": "String representation of NaN to use.\n"}, {"param_name": "formatters", "param_type": "list, tuple or dict of one-param. functions, optional", "param_desc": "Formatter functions to apply to columns’ elements by position or\nname.\nThe result of each function must be a unicode string.\nList/tuple must be of length equal to the number of columns.\n"}, {"param_name": "float_format", "param_type": "one-parameter function, optional, default None", "param_desc": "Formatter function to apply to columns’ elements if they are\nfloats. This function must return a unicode string and will be\napplied only to the non-NaN elements, with NaN being\nhandled by na_rep.\n"}, {"param_name": "sparsify", "param_type": "bool, optional, default True", "param_desc": "Set to False for a DataFrame with a hierarchical index to print\nevery multiindex key at each row.\n"}, {"param_name": "index_names", "param_type": "bool, optional, default True", "param_desc": "Prints the names of the indexes.\n"}, {"param_name": "justify", "param_type": "str, default None", "param_desc": "How to justify the column labels. If None uses the option from\nthe print configuration (controlled by set_option), ‘right’ out\nof the box. Valid values are\n\nleft\nright\ncenter\njustify\njustify-all\nstart\nend\ninherit\nmatch-parent\ninitial\nunset.\n\n"}, {"param_name": "max_rows", "param_type": "int, optional", "param_desc": "Maximum number of rows to display in the console.\n"}, {"param_name": "max_cols", "param_type": "int, optional", "param_desc": "Maximum number of columns to display in the console.\n"}, {"param_name": "show_dimensions", "param_type": "bool, default False", "param_desc": "Display DataFrame dimensions (number of rows by number of columns).\n"}, {"param_name": "decimal", "param_type": "str, default ‘.’", "param_desc": "Character recognized as decimal separator, e.g. ‘,’ in Europe.\n"}, {"param_name": "line_width", "param_type": "int, optional", "param_desc": "Width to wrap a line in characters.\n"}, {"param_name": "min_rows", "param_type": "int, optional", "param_desc": "The number of rows to display in the console in a truncated repr\n(when number of rows is above max_rows).\n"}, {"param_name": "max_colwidth", "param_type": "int, optional", "param_desc": "Max width to truncate each column in characters. By default, no limit.\n"}, {"param_name": "encoding", "param_type": "str, default “utf-8”", "param_desc": "Set character encoding.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_string.html#pandas.DataFrame.to_string"}, {"function_name": "pandas.DataFrame.to_markdown", "full_function": "DataFrame.to_markdown(buf=None, *, mode='wt', index=True, storage_options=None, **kwargs)", "function_text": "Print DataFrame in Markdown-friendly format.", "parameter_names_desc": [{"param_name": "buf", "param_type": "str, Path or StringIO-like, optional, default None", "param_desc": "Buffer to write to. If None, the output is returned as a string.\n"}, {"param_name": "mode", "param_type": "str, optional", "param_desc": "Mode in which file is opened, “wt” by default.\n"}, {"param_name": "index", "param_type": "bool, optional, default True", "param_desc": "Add index (row) labels.\n"}, {"param_name": "storage_options", "param_type": "dict, optional", "param_desc": "Extra options that make sense for a particular storage connection, e.g.\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\nare forwarded to urllib.request.Request as header options. For other\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\nforwarded to fsspec.open. Please see fsspec and urllib for more\ndetails, and for more examples on storage options refer here.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_markdown.html#pandas.DataFrame.to_markdown"}, {"function_name": "pandas.DataFrame.__dataframe__", "full_function": "DataFrame.__dataframe__(nan_as_null=False, allow_copy=True)", "function_text": "Return the dataframe interchange object implementing the interchange protocol.", "parameter_names_desc": [{"param_name": "nan_as_null", "param_type": "bool, default False", "param_desc": "nan_as_null is DEPRECATED and has no effect. Please avoid using\nit; it will be removed in a future release.\n"}, {"param_name": "allow_copy", "param_type": "bool, default True", "param_desc": "Whether to allow memory copying when exporting. If set to False\nit would cause non-zero-copy exports to fail.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.__dataframe__.html#pandas.DataFrame.__dataframe__"}]}], "name": "DataFrame", "url": "https://pandas.pydata.org/docs/reference/frame.html"}, "arrays.html": {"functions": [{"name": "Objects", "url": "https://pandas.pydata.org/docs/reference/arrays.html#objects", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.html#pandas.Timedelta", "https://pandas.pydata.org/docs/reference/api/pandas.IntervalDtype.html#pandas.IntervalDtype", "https://pandas.pydata.org/docs/reference/api/pandas.Float64Dtype.html#pandas.Float64Dtype", "https://pandas.pydata.org/docs/reference/api/pandas.SparseDtype.html#pandas.SparseDtype", "https://pandas.pydata.org/docs/reference/api/pandas.BooleanDtype.html#pandas.BooleanDtype", "https://pandas.pydata.org/docs/reference/api/pandas.array.html#pandas.array", "https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.int8.html#pyarrow.int8", "https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.int32.html#pyarrow.int32", "https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.uint8.html#pyarrow.uint8", "https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.uint32.html#pyarrow.uint32", "https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.float32.html#pyarrow.float32", "https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.time32.html#pyarrow.time32", "https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.timestamp.html#pyarrow.timestamp", "https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.date64.html#pyarrow.date64", "https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.binary.html#pyarrow.binary", "https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.decimal128.html#pyarrow.decimal128", "https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.map_.html#pyarrow.map_", "https://pandas.pydata.org/docs/reference/api/pandas.arrays.ArrowExtensionArray.html#pandas.arrays.ArrowExtensionArray", "https://pandas.pydata.org/docs/reference/api/pandas.ArrowDtype.html#pandas.ArrowDtype", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.html#pandas.Timestamp", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.asm8.html#pandas.Timestamp.asm8", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.dayofweek.html#pandas.Timestamp.dayofweek", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.dayofyear.html#pandas.Timestamp.dayofyear", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.days_in_month.html#pandas.Timestamp.days_in_month", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.fold.html#pandas.Timestamp.fold", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.is_leap_year.html#pandas.Timestamp.is_leap_year", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.is_month_start.html#pandas.Timestamp.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.is_quarter_start.html#pandas.Timestamp.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.is_year_start.html#pandas.Timestamp.is_year_start", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.microsecond.html#pandas.Timestamp.microsecond", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.minute.html#pandas.Timestamp.minute", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.nanosecond.html#pandas.Timestamp.nanosecond", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.resolution.html#pandas.Timestamp.resolution", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.tz.html#pandas.Timestamp.tz", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.unit.html#pandas.Timestamp.unit", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.week.html#pandas.Timestamp.week", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.year.html#pandas.Timestamp.year", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.as_unit.html#pandas.Timestamp.as_unit", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.ceil.html#pandas.Timestamp.ceil", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.ctime.html#pandas.Timestamp.ctime", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.day_name.html#pandas.Timestamp.day_name", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.floor.html#pandas.Timestamp.floor", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.fromtimestamp.html#pandas.Timestamp.fromtimestamp", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.isoformat.html#pandas.Timestamp.isoformat", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.month_name.html#pandas.Timestamp.month_name", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.now.html#pandas.Timestamp.now", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.round.html#pandas.Timestamp.round", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.strptime.html#pandas.Timestamp.strptime", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.timestamp.html#pandas.Timestamp.timestamp", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.timetz.html#pandas.Timestamp.timetz", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.to_numpy.html#pandas.Timestamp.to_numpy", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.to_period.html#pandas.Timestamp.to_period", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.today.html#pandas.Timestamp.today", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.tz_convert.html#pandas.Timestamp.tz_convert", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.tzname.html#pandas.Timestamp.tzname", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.utcnow.html#pandas.Timestamp.utcnow", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.utctimetuple.html#pandas.Timestamp.utctimetuple", "https://pandas.pydata.org/docs/reference/api/pandas.arrays.DatetimeArray.html#pandas.arrays.DatetimeArray", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeTZDtype.html#pandas.DatetimeTZDtype", "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.html#pandas.Timedelta", "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.asm8.html#pandas.Timedelta.asm8", "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.days.html#pandas.Timedelta.days", "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.microseconds.html#pandas.Timedelta.microseconds", "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.nanoseconds.html#pandas.Timedelta.nanoseconds", "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.seconds.html#pandas.Timedelta.seconds", "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.value.html#pandas.Timedelta.value", "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.as_unit.html#pandas.Timedelta.as_unit", "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.floor.html#pandas.Timedelta.floor", "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.round.html#pandas.Timedelta.round", "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.to_timedelta64.html#pandas.Timedelta.to_timedelta64", "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.total_seconds.html#pandas.Timedelta.total_seconds", "https://pandas.pydata.org/docs/reference/api/pandas.arrays.TimedeltaArray.html#pandas.arrays.TimedeltaArray", "https://pandas.pydata.org/docs/reference/api/pandas.Period.html#pandas.Period", "https://pandas.pydata.org/docs/reference/api/pandas.Period.day.html#pandas.Period.day", "https://pandas.pydata.org/docs/reference/api/pandas.Period.day_of_week.html#pandas.Period.day_of_week", "https://pandas.pydata.org/docs/reference/api/pandas.Period.day_of_year.html#pandas.Period.day_of_year", "https://pandas.pydata.org/docs/reference/api/pandas.Period.daysinmonth.html#pandas.Period.daysinmonth", "https://pandas.pydata.org/docs/reference/api/pandas.Period.freq.html#pandas.Period.freq", "https://pandas.pydata.org/docs/reference/api/pandas.Period.hour.html#pandas.Period.hour", "https://pandas.pydata.org/docs/reference/api/pandas.Period.minute.html#pandas.Period.minute", "https://pandas.pydata.org/docs/reference/api/pandas.Period.ordinal.html#pandas.Period.ordinal", "https://pandas.pydata.org/docs/reference/api/pandas.Period.qyear.html#pandas.Period.qyear", "https://pandas.pydata.org/docs/reference/api/pandas.Period.start_time.html#pandas.Period.start_time", "https://pandas.pydata.org/docs/reference/api/pandas.Period.weekday.html#pandas.Period.weekday", "https://pandas.pydata.org/docs/reference/api/pandas.Period.year.html#pandas.Period.year", "https://pandas.pydata.org/docs/reference/api/pandas.Period.asfreq.html#pandas.Period.asfreq", "https://pandas.pydata.org/docs/reference/api/pandas.Period.strftime.html#pandas.Period.strftime", "https://pandas.pydata.org/docs/reference/api/pandas.arrays.PeriodArray.html#pandas.arrays.PeriodArray", "https://pandas.pydata.org/docs/reference/api/pandas.PeriodDtype.html#pandas.PeriodDtype", "https://pandas.pydata.org/docs/reference/api/pandas.Interval.html#pandas.Interval", "https://pandas.pydata.org/docs/reference/api/pandas.Interval.closed.html#pandas.Interval.closed", "https://pandas.pydata.org/docs/reference/api/pandas.Interval.closed_right.html#pandas.Interval.closed_right", "https://pandas.pydata.org/docs/reference/api/pandas.Interval.left.html#pandas.Interval.left", "https://pandas.pydata.org/docs/reference/api/pandas.Interval.mid.html#pandas.Interval.mid", "https://pandas.pydata.org/docs/reference/api/pandas.Interval.open_right.html#pandas.Interval.open_right", "https://pandas.pydata.org/docs/reference/api/pandas.Interval.right.html#pandas.Interval.right", "https://pandas.pydata.org/docs/reference/api/pandas.arrays.IntervalArray.html#pandas.arrays.IntervalArray", "https://pandas.pydata.org/docs/reference/api/pandas.IntervalDtype.html#pandas.IntervalDtype", "https://pandas.pydata.org/docs/reference/api/pandas.arrays.IntegerArray.html#pandas.arrays.IntegerArray", "https://pandas.pydata.org/docs/reference/api/pandas.Int8Dtype.html#pandas.Int8Dtype", "https://pandas.pydata.org/docs/reference/api/pandas.Int32Dtype.html#pandas.Int32Dtype", "https://pandas.pydata.org/docs/reference/api/pandas.UInt8Dtype.html#pandas.UInt8Dtype", "https://pandas.pydata.org/docs/reference/api/pandas.UInt32Dtype.html#pandas.UInt32Dtype", "https://pandas.pydata.org/docs/reference/api/pandas.arrays.FloatingArray.html#pandas.arrays.FloatingArray", "https://pandas.pydata.org/docs/reference/api/pandas.Float32Dtype.html#pandas.Float32Dtype", "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalDtype.html#pandas.CategoricalDtype", "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalDtype.categories.html#pandas.CategoricalDtype.categories", "https://pandas.pydata.org/docs/reference/api/pandas.Categorical.html#pandas.Categorical", "https://pandas.pydata.org/docs/reference/api/pandas.Categorical.from_codes.html#pandas.Categorical.from_codes", "https://pandas.pydata.org/docs/reference/api/pandas.Categorical.dtype.html#pandas.Categorical.dtype", "https://pandas.pydata.org/docs/reference/api/pandas.Categorical.ordered.html#pandas.Categorical.ordered", "https://pandas.pydata.org/docs/reference/api/pandas.Categorical.__array__.html#pandas.Categorical.__array__", "https://pandas.pydata.org/docs/reference/api/pandas.arrays.SparseArray.html#pandas.arrays.SparseArray", "https://pandas.pydata.org/docs/reference/api/pandas.SparseDtype.html#pandas.SparseDtype", "https://pandas.pydata.org/docs/reference/api/pandas.arrays.StringArray.html#pandas.arrays.StringArray", "https://pandas.pydata.org/docs/reference/api/pandas.StringDtype.html#pandas.StringDtype", "https://pandas.pydata.org/docs/reference/api/pandas.arrays.BooleanArray.html#pandas.arrays.BooleanArray", "https://pandas.pydata.org/docs/reference/api/pandas.BooleanDtype.html#pandas.BooleanDtype", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeTZDtype.html#pandas.DatetimeTZDtype", "https://pandas.pydata.org/docs/reference/api/pandas.PeriodDtype.html#pandas.PeriodDtype", "https://pandas.pydata.org/docs/reference/api/pandas.Int64Dtype.html#pandas.Int64Dtype", "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalDtype.html#pandas.CategoricalDtype", "https://pandas.pydata.org/docs/reference/api/pandas.StringDtype.html#pandas.StringDtype", "https://pandas.pydata.org/docs/reference/api/pandas.ArrowDtype.html#pandas.ArrowDtype", "https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.bool_.html#pyarrow.bool_", "https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.int16.html#pyarrow.int16", "https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.int64.html#pyarrow.int64", "https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.uint16.html#pyarrow.uint16", "https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.uint64.html#pyarrow.uint64", "https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.float64.html#pyarrow.float64", "https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.time64.html#pyarrow.time64", "https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.date32.html#pyarrow.date32", "https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.duration.html#pyarrow.duration", "https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.string.html#pyarrow.string", "https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.list_.html#pyarrow.list_", "https://pandas.pydata.org/docs/reference/https://arrow.apache.org/docs/python/generated/pyarrow.dictionary.html#pyarrow.dictionary", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.day.html#pandas.Timestamp.day", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.day_of_week.html#pandas.Timestamp.day_of_week", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.day_of_year.html#pandas.Timestamp.day_of_year", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.daysinmonth.html#pandas.Timestamp.daysinmonth", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.hour.html#pandas.Timestamp.hour", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.is_month_end.html#pandas.Timestamp.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.is_quarter_end.html#pandas.Timestamp.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.is_year_end.html#pandas.Timestamp.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.max.html#pandas.Timestamp.max", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.min.html#pandas.Timestamp.min", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.month.html#pandas.Timestamp.month", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.quarter.html#pandas.Timestamp.quarter", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.second.html#pandas.Timestamp.second", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.tzinfo.html#pandas.Timestamp.tzinfo", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.value.html#pandas.Timestamp.value", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.weekofyear.html#pandas.Timestamp.weekofyear", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.astimezone.html#pandas.Timestamp.astimezone", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.combine.html#pandas.Timestamp.combine", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.date.html#pandas.Timestamp.date", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.dst.html#pandas.Timestamp.dst", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.fromordinal.html#pandas.Timestamp.fromordinal", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.isocalendar.html#pandas.Timestamp.isocalendar", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.isoweekday.html#pandas.Timestamp.isoweekday", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.normalize.html#pandas.Timestamp.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.replace.html#pandas.Timestamp.replace", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.strftime.html#pandas.Timestamp.strftime", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.time.html#pandas.Timestamp.time", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.timetuple.html#pandas.Timestamp.timetuple", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.to_datetime64.html#pandas.Timestamp.to_datetime64", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.to_julian_date.html#pandas.Timestamp.to_julian_date", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.to_pydatetime.html#pandas.Timestamp.to_pydatetime", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.toordinal.html#pandas.Timestamp.toordinal", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.tz_localize.html#pandas.Timestamp.tz_localize", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.utcfromtimestamp.html#pandas.Timestamp.utcfromtimestamp", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.utcoffset.html#pandas.Timestamp.utcoffset", "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.weekday.html#pandas.Timestamp.weekday", "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.components.html#pandas.Timedelta.components", "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.max.html#pandas.Timedelta.max", "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.min.html#pandas.Timedelta.min", "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.resolution.html#pandas.Timedelta.resolution", "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.unit.html#pandas.Timedelta.unit", "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.view.html#pandas.Timedelta.view", "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.ceil.html#pandas.Timedelta.ceil", "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.isoformat.html#pandas.Timedelta.isoformat", "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.to_pytimedelta.html#pandas.Timedelta.to_pytimedelta", "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.to_numpy.html#pandas.Timedelta.to_numpy", "https://pandas.pydata.org/docs/reference/api/pandas.Period.dayofweek.html#pandas.Period.dayofweek", "https://pandas.pydata.org/docs/reference/api/pandas.Period.dayofyear.html#pandas.Period.dayofyear", "https://pandas.pydata.org/docs/reference/api/pandas.Period.days_in_month.html#pandas.Period.days_in_month", "https://pandas.pydata.org/docs/reference/api/pandas.Period.end_time.html#pandas.Period.end_time", "https://pandas.pydata.org/docs/reference/api/pandas.Period.freqstr.html#pandas.Period.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.Period.is_leap_year.html#pandas.Period.is_leap_year", "https://pandas.pydata.org/docs/reference/api/pandas.Period.month.html#pandas.Period.month", "https://pandas.pydata.org/docs/reference/api/pandas.Period.quarter.html#pandas.Period.quarter", "https://pandas.pydata.org/docs/reference/api/pandas.Period.second.html#pandas.Period.second", "https://pandas.pydata.org/docs/reference/api/pandas.Period.week.html#pandas.Period.week", "https://pandas.pydata.org/docs/reference/api/pandas.Period.weekofyear.html#pandas.Period.weekofyear", "https://pandas.pydata.org/docs/reference/api/pandas.Period.now.html#pandas.Period.now", "https://pandas.pydata.org/docs/reference/api/pandas.Period.to_timestamp.html#pandas.Period.to_timestamp", "https://pandas.pydata.org/docs/reference/api/pandas.Interval.closed_left.html#pandas.Interval.closed_left", "https://pandas.pydata.org/docs/reference/api/pandas.Interval.is_empty.html#pandas.Interval.is_empty", "https://pandas.pydata.org/docs/reference/api/pandas.Interval.length.html#pandas.Interval.length", "https://pandas.pydata.org/docs/reference/api/pandas.Interval.open_left.html#pandas.Interval.open_left", "https://pandas.pydata.org/docs/reference/api/pandas.Interval.overlaps.html#pandas.Interval.overlaps", "https://pandas.pydata.org/docs/reference/api/pandas.Int16Dtype.html#pandas.Int16Dtype", "https://pandas.pydata.org/docs/reference/api/pandas.Int64Dtype.html#pandas.Int64Dtype", "https://pandas.pydata.org/docs/reference/api/pandas.UInt16Dtype.html#pandas.UInt16Dtype", "https://pandas.pydata.org/docs/reference/api/pandas.UInt64Dtype.html#pandas.UInt64Dtype", "https://pandas.pydata.org/docs/reference/api/pandas.Float64Dtype.html#pandas.Float64Dtype", "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalDtype.ordered.html#pandas.CategoricalDtype.ordered", "https://pandas.pydata.org/docs/reference/api/pandas.Categorical.categories.html#pandas.Categorical.categories", "https://pandas.pydata.org/docs/reference/api/pandas.Categorical.codes.html#pandas.Categorical.codes", "https://pandas.pydata.org/docs/reference/api/pandas.arrays.ArrowStringArray.html#pandas.arrays.ArrowStringArray"], "function_definitions": [{"function_name": "pandas.Timedelta", "full_function": "class pandas.Timedelta(value=<object object>, unit=None, **kwargs)#", "function_text": "Represents a duration, the difference between two dates or times.", "parameter_names_desc": [{"param_name": "value", "param_type": "Timedelta, timedelta, np.timedelta64, str, or int", "param_desc": ""}, {"param_name": "unit", "param_type": "str, default ‘ns’", "param_desc": "Denote the unit of the input, if input is an integer.\nPossible values:\n\n‘W’, or ‘D’\n‘days’, or ‘day’\n‘hours’, ‘hour’, ‘hr’, or ‘h’\n‘minutes’, ‘minute’, ‘min’, or ‘m’\n‘seconds’, ‘second’, ‘sec’, or ‘s’\n‘milliseconds’, ‘millisecond’, ‘millis’, ‘milli’, or ‘ms’\n‘microseconds’, ‘microsecond’, ‘micros’, ‘micro’, or ‘us’\n‘nanoseconds’, ‘nanosecond’, ‘nanos’, ‘nano’, or ‘ns’.\n\n\nDeprecated since version 2.2.0: Values H, T, S, L, U, and N are deprecated in favour\nof the values h, min, s, ms, us, and ns.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.html#pandas.Timedelta"}, {"function_name": "pandas.IntervalDtype", "full_function": "class pandas.IntervalDtype(subtype=None, closed=None)", "function_text": "An ExtensionDtype for Interval data.", "parameter_names_desc": [{"param_name": "subtype", "param_type": "str, np.dtype", "param_desc": "The dtype of the Interval bounds.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.IntervalDtype.html#pandas.IntervalDtype"}, {"function_name": "pandas.Float64Dtype", "full_function": "class pandas.Float64Dtype", "function_text": "An ExtensionDtype for float64 data.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Float64Dtype.html#pandas.Float64Dtype"}, {"function_name": "pandas.SparseDtype", "full_function": "class pandas.SparseDtype(dtype=<class 'numpy.float64'>, fill_value=None)", "function_text": "Dtype for data stored in SparseArray.", "parameter_names_desc": [{"param_name": "dtype", "param_type": "str, ExtensionDtype, numpy.dtype, type, default numpy.float64", "param_desc": "The dtype of the underlying array storing the non-fill value values.\n"}, {"param_name": "fill_value", "param_type": "scalar, optional", "param_desc": "The scalar value not stored in the SparseArray. By default, this\ndepends on dtype.\n\n\ndtype\nna_value\n\n\n\nfloat\nnp.nan\n\nint\n0\n\nbool\nFalse\n\ndatetime64\npd.NaT\n\ntimedelta64\npd.NaT\n\n\n\nThe default value may be overridden by specifying a fill_value.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.SparseDtype.html#pandas.SparseDtype"}, {"function_name": "pandas.BooleanDtype", "full_function": "class pandas.BooleanDtype", "function_text": "Extension dtype for boolean data.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.BooleanDtype.html#pandas.BooleanDtype"}, {"function_name": "pandas.array", "full_function": "pandas.array(data, dtype=None, copy=True)", "function_text": "Create an array.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.array.html#pandas.array"}, {"function_name": "pandas.array", "full_function": "pandas.array(data, dtype=None, copy=True)", "function_text": "Create an array.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.array.html#pandas.array"}, {"function_name": "pandas.array", "full_function": "pandas.array(data, dtype=None, copy=True)", "function_text": "Create an array.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.array.html#pandas.array"}, {"function_name": "pandas.array", "full_function": "pandas.array(data, dtype=None, copy=True)", "function_text": "Create an array.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.array.html#pandas.array"}, {"function_name": "pandas.array", "full_function": "pandas.array(data, dtype=None, copy=True)", "function_text": "Create an array.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.array.html#pandas.array"}, {"function_name": "pandas.array", "full_function": "pandas.array(data, dtype=None, copy=True)", "function_text": "Create an array.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.array.html#pandas.array"}, {"function_name": "pandas.array", "full_function": "pandas.array(data, dtype=None, copy=True)", "function_text": "Create an array.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.array.html#pandas.array"}, {"function_name": "pandas.array", "full_function": "pandas.array(data, dtype=None, copy=True)", "function_text": "Create an array.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.array.html#pandas.array"}, {"function_name": "pandas.array", "full_function": "pandas.array(data, dtype=None, copy=True)", "function_text": "Create an array.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.array.html#pandas.array"}, {"function_name": "pandas.array", "full_function": "pandas.array(data, dtype=None, copy=True)", "function_text": "Create an array.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.array.html#pandas.array"}, {"function_name": "pandas.array", "full_function": "pandas.array(data, dtype=None, copy=True)", "function_text": "Create an array.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.array.html#pandas.array"}, {"function_name": "pandas.array", "full_function": "pandas.array(data, dtype=None, copy=True)", "function_text": "Create an array.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.array.html#pandas.array"}, {"function_name": "pandas.arrays.ArrowExtensionArray", "full_function": "class pandas.arrays.ArrowExtensionArray(values)", "function_text": "Pandas ExtensionArray backed by a PyArrow ChunkedArray.", "parameter_names_desc": [{"param_name": "values", "param_type": "pyarrow.Array or pyarrow.ChunkedArray", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.arrays.ArrowExtensionArray.html#pandas.arrays.ArrowExtensionArray"}, {"function_name": "pandas.ArrowDtype", "full_function": "class pandas.ArrowDtype(pyarrow_dtype)", "function_text": "An ExtensionDtype for PyArrow data types.", "parameter_names_desc": [{"param_name": "pyarrow_dtype", "param_type": "pa.DataType", "param_desc": "An instance of a pyarrow.DataType.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.ArrowDtype.html#pandas.ArrowDtype"}, {"function_name": "pandas.Timestamp", "full_function": "class pandas.Timestamp(ts_input=<object object>, year=None, month=None, day=None, hour=None, minute=None, second=None, microsecond=None, tzinfo=None, *, nanosecond=None, tz=None, unit=None, fold=None)#", "function_text": "Pandas replacement for python datetime.datetime object.", "parameter_names_desc": [{"param_name": "ts_input", "param_type": "datetime-like, str, int, float", "param_desc": "Value to be converted to Timestamp.\n"}, {"param_name": "year, month, day", "param_type": "int", "param_desc": ""}, {"param_name": "hour, minute, second, microsecond", "param_type": "int, optional, default 0", "param_desc": ""}, {"param_name": "tzinfo", "param_type": "datetime.tzinfo, optional, default None", "param_desc": ""}, {"param_name": "nanosecond", "param_type": "int, optional, default 0", "param_desc": ""}, {"param_name": "tz", "param_type": "str, pytz.timezone, dateutil.tz.tzfile or None", "param_desc": "Time zone for time which Timestamp will have.\n"}, {"param_name": "unit", "param_type": "str", "param_desc": "Unit used for conversion if ts_input is of type int or float. The\nvalid values are ‘D’, ‘h’, ‘m’, ‘s’, ‘ms’, ‘us’, and ‘ns’. For\nexample, ‘s’ means seconds and ‘ms’ means milliseconds.\nFor float inputs, the result will be stored in nanoseconds, and\nthe unit attribute will be set as 'ns'.\n"}, {"param_name": "fold", "param_type": "{0, 1}, default None, keyword-only", "param_desc": "Due to daylight saving time, one wall clock time can occur twice\nwhen shifting from summer to winter time; fold describes whether the\ndatetime-like corresponds to the first (0) or the second time (1)\nthe wall clock hits the ambiguous time.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.html#pandas.Timestamp"}, {"function_name": "pandas.Timestamp.asm8", "full_function": "Timestamp.asm8#", "function_text": "Return numpy datetime64 format in nanoseconds.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.asm8.html#pandas.Timestamp.asm8"}, {"function_name": "pandas.Timestamp.dayofweek", "full_function": "Timestamp.dayofweek#", "function_text": "Return day of the week.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.dayofweek.html#pandas.Timestamp.dayofweek"}, {"function_name": "pandas.Timestamp.dayofyear", "full_function": "Timestamp.dayofyear#", "function_text": "Return the day of the year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.dayofyear.html#pandas.Timestamp.dayofyear"}, {"function_name": "pandas.Timestamp.days_in_month", "full_function": "Timestamp.days_in_month#", "function_text": "Return the number of days in the month.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.days_in_month.html#pandas.Timestamp.days_in_month"}, {"function_name": "pandas.Timestamp.days_in_month", "full_function": "Timestamp.days_in_month#", "function_text": "Return the number of days in the month.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.days_in_month.html#pandas.Timestamp.days_in_month"}, {"function_name": "pandas.Timestamp.is_leap_year", "full_function": "Timestamp.is_leap_year#", "function_text": "Return True if year is a leap year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.is_leap_year.html#pandas.Timestamp.is_leap_year"}, {"function_name": "pandas.Timestamp.is_month_start", "full_function": "Timestamp.is_month_start#", "function_text": "Check if the date is the first day of the month.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.is_month_start.html#pandas.Timestamp.is_month_start"}, {"function_name": "pandas.Timestamp.is_quarter_start", "full_function": "Timestamp.is_quarter_start#", "function_text": "Check if the date is the first day of the quarter.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.is_quarter_start.html#pandas.Timestamp.is_quarter_start"}, {"function_name": "pandas.Timestamp.is_year_start", "full_function": "Timestamp.is_year_start#", "function_text": "Return True if date is first day of the year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.is_year_start.html#pandas.Timestamp.is_year_start"}, {"function_name": "pandas.Timestamp.is_year_start", "full_function": "Timestamp.is_year_start#", "function_text": "Return True if date is first day of the year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.is_year_start.html#pandas.Timestamp.is_year_start"}, {"function_name": "pandas.Timestamp.is_year_start", "full_function": "Timestamp.is_year_start#", "function_text": "Return True if date is first day of the year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.is_year_start.html#pandas.Timestamp.is_year_start"}, {"function_name": "pandas.Timestamp.is_year_start", "full_function": "Timestamp.is_year_start#", "function_text": "Return True if date is first day of the year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.is_year_start.html#pandas.Timestamp.is_year_start"}, {"function_name": "pandas.Timestamp.is_year_start", "full_function": "Timestamp.is_year_start#", "function_text": "Return True if date is first day of the year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.is_year_start.html#pandas.Timestamp.is_year_start"}, {"function_name": "pandas.Timestamp.tz", "full_function": "property Timestamp.tz#", "function_text": "Alias for tzinfo.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.tz.html#pandas.Timestamp.tz"}, {"function_name": "pandas.Timestamp.unit", "full_function": "Timestamp.unit#", "function_text": "The abbreviation associated with self._creso.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.unit.html#pandas.Timestamp.unit"}, {"function_name": "pandas.Timestamp.week", "full_function": "Timestamp.week#", "function_text": "Return the week number of the year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.week.html#pandas.Timestamp.week"}, {"function_name": "pandas.Timestamp.week", "full_function": "Timestamp.week#", "function_text": "Return the week number of the year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.week.html#pandas.Timestamp.week"}, {"function_name": "pandas.Timestamp.as_unit", "full_function": "Timestamp.as_unit(unit, round_ok=True)#", "function_text": "Convert the underlying int64 representaton to the given unit.", "parameter_names_desc": [{"param_name": "unit", "param_type": "{“ns”, “us”, “ms”, “s”}", "param_desc": ""}, {"param_name": "round_ok", "param_type": "bool, default True", "param_desc": "If False and the conversion requires rounding, raise.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.as_unit.html#pandas.Timestamp.as_unit"}, {"function_name": "pandas.Timestamp.ceil", "full_function": "Timestamp.ceil(freq, ambiguous='raise', nonexistent='raise')#", "function_text": "Return a new Timestamp ceiled to this resolution.", "parameter_names_desc": [{"param_name": "freq", "param_type": "str", "param_desc": "Frequency string indicating the ceiling resolution.\n"}, {"param_name": "ambiguous", "param_type": "bool or {‘raise’, ‘NaT’}, default ‘raise’", "param_desc": "The behavior is as follows:\n\nbool contains flags to determine if time is dst or not (note\nthat this flag is only applicable for ambiguous fall dst dates).\n‘NaT’ will return NaT for an ambiguous time.\n‘raise’ will raise an AmbiguousTimeError for an ambiguous time.\n\n"}, {"param_name": "nonexistent", "param_type": "{‘raise’, ‘shift_forward’, ‘shift_backward, ‘NaT’, timedelta}, default ‘raise’", "param_desc": "A nonexistent time does not exist in a particular timezone\nwhere clocks moved forward due to DST.\n\n‘shift_forward’ will shift the nonexistent time forward to the\nclosest existing time.\n‘shift_backward’ will shift the nonexistent time backward to the\nclosest existing time.\n‘NaT’ will return NaT where there are nonexistent times.\ntimedelta objects will shift nonexistent times by the timedelta.\n‘raise’ will raise an NonExistentTimeError if there are\nnonexistent times.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.ceil.html#pandas.Timestamp.ceil"}, {"function_name": "pandas.Timestamp.ctime", "full_function": "Timestamp.ctime()#", "function_text": "Return ctime() style string.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.ctime.html#pandas.Timestamp.ctime"}, {"function_name": "pandas.Timestamp.day_name", "full_function": "Timestamp.day_name(locale=None)#", "function_text": "Return the day name of the Timestamp with specified locale.", "parameter_names_desc": [{"param_name": "locale", "param_type": "str, default None (English locale)", "param_desc": "Locale determining the language in which to return the day name.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.day_name.html#pandas.Timestamp.day_name"}, {"function_name": "pandas.Timestamp.floor", "full_function": "Timestamp.floor(freq, ambiguous='raise', nonexistent='raise')#", "function_text": "Return a new Timestamp floored to this resolution.", "parameter_names_desc": [{"param_name": "freq", "param_type": "str", "param_desc": "Frequency string indicating the flooring resolution.\n"}, {"param_name": "ambiguous", "param_type": "bool or {‘raise’, ‘NaT’}, default ‘raise’", "param_desc": "The behavior is as follows:\n\nbool contains flags to determine if time is dst or not (note\nthat this flag is only applicable for ambiguous fall dst dates).\n‘NaT’ will return NaT for an ambiguous time.\n‘raise’ will raise an AmbiguousTimeError for an ambiguous time.\n\n"}, {"param_name": "nonexistent", "param_type": "{‘raise’, ‘shift_forward’, ‘shift_backward, ‘NaT’, timedelta}, default ‘raise’", "param_desc": "A nonexistent time does not exist in a particular timezone\nwhere clocks moved forward due to DST.\n\n‘shift_forward’ will shift the nonexistent time forward to the\nclosest existing time.\n‘shift_backward’ will shift the nonexistent time backward to the\nclosest existing time.\n‘NaT’ will return NaT where there are nonexistent times.\ntimedelta objects will shift nonexistent times by the timedelta.\n‘raise’ will raise an NonExistentTimeError if there are\nnonexistent times.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.floor.html#pandas.Timestamp.floor"}, {"function_name": "pandas.Timestamp.fromtimestamp", "full_function": "classmethod Timestamp.fromtimestamp(ts)#", "function_text": "Transform timestamp[, tz] to tz’s local time from POSIX timestamp.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.fromtimestamp.html#pandas.Timestamp.fromtimestamp"}, {"function_name": "pandas.Timestamp.isoformat", "full_function": "Timestamp.isoformat(sep='T', timespec='auto')#", "function_text": "Return the time formatted according to ISO 8601.", "parameter_names_desc": [{"param_name": "sep", "param_type": "str, default ‘T’", "param_desc": "String used as the separator between the date and time.\n"}, {"param_name": "timespec", "param_type": "str, default ‘auto’", "param_desc": "Specifies the number of additional terms of the time to include.\nThe valid values are ‘auto’, ‘hours’, ‘minutes’, ‘seconds’,\n‘milliseconds’, ‘microseconds’, and ‘nanoseconds’.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.isoformat.html#pandas.Timestamp.isoformat"}, {"function_name": "pandas.Timestamp.month_name", "full_function": "Timestamp.month_name(locale=None)#", "function_text": "Return the month name of the Timestamp with specified locale.", "parameter_names_desc": [{"param_name": "locale", "param_type": "str, default None (English locale)", "param_desc": "Locale determining the language in which to return the month name.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.month_name.html#pandas.Timestamp.month_name"}, {"function_name": "pandas.Timestamp.now", "full_function": "classmethod Timestamp.now(tz=None)#", "function_text": "Return new Timestamp object representing current time local to tz.", "parameter_names_desc": [{"param_name": "tz", "param_type": "str or timezone object, default None", "param_desc": "Timezone to localize to.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.now.html#pandas.Timestamp.now"}, {"function_name": "pandas.Timestamp.round", "full_function": "Timestamp.round(freq, ambiguous='raise', nonexistent='raise')#", "function_text": "Round the Timestamp to the specified resolution.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.round.html#pandas.Timestamp.round"}, {"function_name": "pandas.Timestamp.strptime", "full_function": "classmethod Timestamp.strptime(string, format)#", "function_text": "Function is not implemented. Use pd.to_datetime().", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.strptime.html#pandas.Timestamp.strptime"}, {"function_name": "pandas.Timestamp.timestamp", "full_function": "Timestamp.timestamp()#", "function_text": "Return POSIX timestamp as float.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.timestamp.html#pandas.Timestamp.timestamp"}, {"function_name": "pandas.Timestamp.timetz", "full_function": "Timestamp.timetz()#", "function_text": "Return time object with same time and tzinfo.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.timetz.html#pandas.Timestamp.timetz"}, {"function_name": "pandas.Timestamp.to_numpy", "full_function": "Timestamp.to_numpy(dtype=None, copy=False)#", "function_text": "Convert the Timestamp to a NumPy datetime64.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.to_numpy.html#pandas.Timestamp.to_numpy"}, {"function_name": "pandas.Timestamp.to_period", "full_function": "Timestamp.to_period(freq=None)#", "function_text": "Return an period of which this timestamp is an observation.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.to_period.html#pandas.Timestamp.to_period"}, {"function_name": "pandas.Timestamp.today", "full_function": "classmethod Timestamp.today(tz=None)#", "function_text": "Return the current time in the local timezone.", "parameter_names_desc": [{"param_name": "tz", "param_type": "str or timezone object, default None", "param_desc": "Timezone to localize to.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.today.html#pandas.Timestamp.today"}, {"function_name": "pandas.Timestamp.tz_convert", "full_function": "Timestamp.tz_convert(tz)#", "function_text": "Convert timezone-aware Timestamp to another time zone.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.tz_convert.html#pandas.Timestamp.tz_convert"}, {"function_name": "pandas.Timestamp.tzname", "full_function": "Timestamp.tzname()#", "function_text": "Return time zone name.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.tzname.html#pandas.Timestamp.tzname"}, {"function_name": "pandas.Timestamp.utcnow", "full_function": "classmethod Timestamp.utcnow()#", "function_text": "Return a new Timestamp representing UTC day and time.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.utcnow.html#pandas.Timestamp.utcnow"}, {"function_name": "pandas.Timestamp.utctimetuple", "full_function": "Timestamp.utctimetuple()#", "function_text": "Return UTC time tuple, compatible with time.localtime().", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.utctimetuple.html#pandas.Timestamp.utctimetuple"}, {"function_name": "pandas.arrays.DatetimeArray", "full_function": "class pandas.arrays.DatetimeArray(values, dtype=None, freq=_NoDefault.no_default, copy=False)", "function_text": "Pandas ExtensionArray for tz-naive or tz-aware datetime data.", "parameter_names_desc": [{"param_name": "values", "param_type": "Series, Index, DatetimeArray, ndarray", "param_desc": "The datetime data.\nFor DatetimeArray values (or a Series or Index boxing one),\ndtype and freq will be extracted from values.\n"}, {"param_name": "dtype", "param_type": "numpy.dtype or DatetimeTZDtype", "param_desc": "Note that the only NumPy dtype allowed is ‘datetime64[ns]’.\n"}, {"param_name": "freq", "param_type": "str or Offset, optional", "param_desc": "The frequency.\n"}, {"param_name": "copy", "param_type": "bool, default False", "param_desc": "Whether to copy the underlying array of values.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.arrays.DatetimeArray.html#pandas.arrays.DatetimeArray"}, {"function_name": "pandas.DatetimeTZDtype", "full_function": "class pandas.DatetimeTZDtype(unit='ns', tz=None)", "function_text": "An ExtensionDtype for timezone-aware datetime data.", "parameter_names_desc": [{"param_name": "unit", "param_type": "str, default “ns”", "param_desc": "The precision of the datetime data. Currently limited\nto \"ns\".\n"}, {"param_name": "tz", "param_type": "str, int, or datetime.tzinfo", "param_desc": "The timezone.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeTZDtype.html#pandas.DatetimeTZDtype"}, {"function_name": "pandas.Timedelta", "full_function": "class pandas.Timedelta(value=<object object>, unit=None, **kwargs)#", "function_text": "Represents a duration, the difference between two dates or times.", "parameter_names_desc": [{"param_name": "value", "param_type": "Timedelta, timedelta, np.timedelta64, str, or int", "param_desc": ""}, {"param_name": "unit", "param_type": "str, default ‘ns’", "param_desc": "Denote the unit of the input, if input is an integer.\nPossible values:\n\n‘W’, or ‘D’\n‘days’, or ‘day’\n‘hours’, ‘hour’, ‘hr’, or ‘h’\n‘minutes’, ‘minute’, ‘min’, or ‘m’\n‘seconds’, ‘second’, ‘sec’, or ‘s’\n‘milliseconds’, ‘millisecond’, ‘millis’, ‘milli’, or ‘ms’\n‘microseconds’, ‘microsecond’, ‘micros’, ‘micro’, or ‘us’\n‘nanoseconds’, ‘nanosecond’, ‘nanos’, ‘nano’, or ‘ns’.\n\n\nDeprecated since version 2.2.0: Values H, T, S, L, U, and N are deprecated in favour\nof the values h, min, s, ms, us, and ns.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.html#pandas.Timedelta"}, {"function_name": "pandas.Timedelta.asm8", "full_function": "Timedelta.asm8#", "function_text": "Return a numpy timedelta64 array scalar view.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.asm8.html#pandas.Timedelta.asm8"}, {"function_name": "pandas.Timedelta.days", "full_function": "Timedelta.days#", "function_text": "Returns the days of the timedelta.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.days.html#pandas.Timedelta.days"}, {"function_name": "pandas.Timedelta.days", "full_function": "Timedelta.days#", "function_text": "Returns the days of the timedelta.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.days.html#pandas.Timedelta.days"}, {"function_name": "pandas.Timedelta.nanoseconds", "full_function": "Timedelta.nanoseconds#", "function_text": "Return the number of nanoseconds (n), where 0 <= n < 1 microsecond.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.nanoseconds.html#pandas.Timedelta.nanoseconds"}, {"function_name": "pandas.Timedelta.seconds", "full_function": "Timedelta.seconds#", "function_text": "Return the total hours, minutes, and seconds of the timedelta as seconds.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.seconds.html#pandas.Timedelta.seconds"}, {"function_name": "pandas.Timedelta.seconds", "full_function": "Timedelta.seconds#", "function_text": "Return the total hours, minutes, and seconds of the timedelta as seconds.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.seconds.html#pandas.Timedelta.seconds"}, {"function_name": "pandas.Timedelta.as_unit", "full_function": "Timedelta.as_unit(unit, round_ok=True)#", "function_text": "Convert the underlying int64 representation to the given unit.", "parameter_names_desc": [{"param_name": "unit", "param_type": "{“ns”, “us”, “ms”, “s”}", "param_desc": ""}, {"param_name": "round_ok", "param_type": "bool, default True", "param_desc": "If False and the conversion requires rounding, raise.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.as_unit.html#pandas.Timedelta.as_unit"}, {"function_name": "pandas.Timedelta.floor", "full_function": "Timedelta.floor(freq)#", "function_text": "Return a new Timedelta floored to this resolution.", "parameter_names_desc": [{"param_name": "freq", "param_type": "str", "param_desc": "Frequency string indicating the flooring resolution.\nIt uses the same units as class constructor Timedelta.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.floor.html#pandas.Timedelta.floor"}, {"function_name": "pandas.Timedelta.round", "full_function": "Timedelta.round(freq)#", "function_text": "Round the Timedelta to the specified resolution.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.round.html#pandas.Timedelta.round"}, {"function_name": "pandas.Timedelta.to_timedelta64", "full_function": "Timedelta.to_timedelta64()#", "function_text": "Return a numpy.timedelta64 object with ‘ns’ precision.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.to_timedelta64.html#pandas.Timedelta.to_timedelta64"}, {"function_name": "pandas.Timedelta.total_seconds", "full_function": "Timedelta.total_seconds()#", "function_text": "Total seconds in the duration.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.total_seconds.html#pandas.Timedelta.total_seconds"}, {"function_name": "pandas.arrays.TimedeltaArray", "full_function": "class pandas.arrays.TimedeltaArray(values, dtype=None, freq=_NoDefault.no_default, copy=False)", "function_text": "Pandas ExtensionArray for timedelta data.", "parameter_names_desc": [{"param_name": "values", "param_type": "array-like", "param_desc": "The timedelta data.\n"}, {"param_name": "dtype", "param_type": "numpy.dtype", "param_desc": "Currently, only numpy.dtype(\"timedelta64[ns]\") is accepted.\n"}, {"param_name": "freq", "param_type": "Offset, optional", "param_desc": ""}, {"param_name": "copy", "param_type": "bool, default False", "param_desc": "Whether to copy the underlying array of data.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.arrays.TimedeltaArray.html#pandas.arrays.TimedeltaArray"}, {"function_name": "pandas.Period", "full_function": "class pandas.Period(value=None, freq=None, ordinal=None, year=None, month=None, quarter=None, day=None, hour=None, minute=None, second=None)#", "function_text": "Represents a period of time.", "parameter_names_desc": [{"param_name": "value", "param_type": "Period, str, datetime, date or pandas.Timestamp, default None", "param_desc": "The time period represented (e.g., ‘4Q2005’). This represents neither\nthe start or the end of the period, but rather the entire period itself.\n"}, {"param_name": "freq", "param_type": "str, default None", "param_desc": "One of pandas period strings or corresponding objects. Accepted\nstrings are listed in the\nperiod alias section in the user docs.\nIf value is datetime, freq is required.\n"}, {"param_name": "ordinal", "param_type": "int, default None", "param_desc": "The period offset from the proleptic Gregorian epoch.\n"}, {"param_name": "year", "param_type": "int, default None", "param_desc": "Year value of the period.\n"}, {"param_name": "month", "param_type": "int, default 1", "param_desc": "Month value of the period.\n"}, {"param_name": "quarter", "param_type": "int, default None", "param_desc": "Quarter value of the period.\n"}, {"param_name": "day", "param_type": "int, default 1", "param_desc": "Day value of the period.\n"}, {"param_name": "hour", "param_type": "int, default 0", "param_desc": "Hour value of the period.\n"}, {"param_name": "minute", "param_type": "int, default 0", "param_desc": "Minute value of the period.\n"}, {"param_name": "second", "param_type": "int, default 0", "param_desc": "Second value of the period.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Period.html#pandas.Period"}, {"function_name": "pandas.Period.day", "full_function": "Period.day#", "function_text": "Get day of the month that a Period falls on.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Period.day.html#pandas.Period.day"}, {"function_name": "pandas.Period.day_of_week", "full_function": "Period.day_of_week#", "function_text": "Day of the week the period lies in, with Monday=0 and Sunday=6.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Period.day_of_week.html#pandas.Period.day_of_week"}, {"function_name": "pandas.Period.day_of_year", "full_function": "Period.day_of_year#", "function_text": "Return the day of the year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Period.day_of_year.html#pandas.Period.day_of_year"}, {"function_name": "pandas.Period.daysinmonth", "full_function": "Period.daysinmonth#", "function_text": "Get the total number of days of the month that this period falls on.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Period.daysinmonth.html#pandas.Period.daysinmonth"}, {"function_name": "pandas.Period.daysinmonth", "full_function": "Period.daysinmonth#", "function_text": "Get the total number of days of the month that this period falls on.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Period.daysinmonth.html#pandas.Period.daysinmonth"}, {"function_name": "pandas.Period.hour", "full_function": "Period.hour#", "function_text": "Get the hour of the day component of the Period.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Period.hour.html#pandas.Period.hour"}, {"function_name": "pandas.Period.minute", "full_function": "Period.minute#", "function_text": "Get minute of the hour component of the Period.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Period.minute.html#pandas.Period.minute"}, {"function_name": "pandas.Period.minute", "full_function": "Period.minute#", "function_text": "Get minute of the hour component of the Period.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Period.minute.html#pandas.Period.minute"}, {"function_name": "pandas.Period.qyear", "full_function": "Period.qyear#", "function_text": "Fiscal year the Period lies in according to its starting-quarter.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Period.qyear.html#pandas.Period.qyear"}, {"function_name": "pandas.Period.start_time", "full_function": "Period.start_time#", "function_text": "Get the Timestamp for the start of the period.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Period.start_time.html#pandas.Period.start_time"}, {"function_name": "pandas.Period.weekday", "full_function": "Period.weekday#", "function_text": "Day of the week the period lies in, with Monday=0 and Sunday=6.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Period.weekday.html#pandas.Period.weekday"}, {"function_name": "pandas.Period.year", "full_function": "Period.year#", "function_text": "Return the year this Period falls on.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Period.year.html#pandas.Period.year"}, {"function_name": "pandas.Period.asfreq", "full_function": "Period.asfreq(freq, how='E')#", "function_text": "Convert Period to desired frequency, at the start or end of the interval.", "parameter_names_desc": [{"param_name": "freq", "param_type": "str, BaseOffset", "param_desc": "The desired frequency. If passing a str, it needs to be a\nvalid period alias.\n"}, {"param_name": "how", "param_type": "{‘E’, ‘S’, ‘end’, ‘start’}, default ‘end’", "param_desc": "Start or end of the timespan.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Period.asfreq.html#pandas.Period.asfreq"}, {"function_name": "pandas.Period.strftime", "full_function": "Period.strftime(fmt)#", "function_text": "Returns a formatted string representation of the Period.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Period.strftime.html#pandas.Period.strftime"}, {"function_name": "pandas.arrays.PeriodArray", "full_function": "class pandas.arrays.PeriodArray(values, dtype=None, freq=None, copy=False)", "function_text": "Pandas ExtensionArray for storing Period data.", "parameter_names_desc": [{"param_name": "values", "param_type": "Union[PeriodArray, Series[period], ndarray[int], PeriodIndex]", "param_desc": "The data to store. These should be arrays that can be directly\nconverted to ordinals without inference or copy (PeriodArray,\nndarray[int64]), or a box around such an array (Series[period],\nPeriodIndex).\n"}, {"param_name": "dtype", "param_type": "PeriodDtype, optional", "param_desc": "A PeriodDtype instance from which to extract a freq. If both\nfreq and dtype are specified, then the frequencies must match.\n"}, {"param_name": "freq", "param_type": "str or DateOffset", "param_desc": "The freq to use for the array. Mostly applicable when values\nis an ndarray of integers, when freq is required. When values\nis a PeriodArray (or box around), it’s checked that values.freq\nmatches freq.\n"}, {"param_name": "copy", "param_type": "bool, default False", "param_desc": "Whether to copy the ordinals before storing.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.arrays.PeriodArray.html#pandas.arrays.PeriodArray"}, {"function_name": "pandas.PeriodDtype", "full_function": "class pandas.PeriodDtype(freq)", "function_text": "An ExtensionDtype for Period data.", "parameter_names_desc": [{"param_name": "freq", "param_type": "str or DateOffset", "param_desc": "The frequency of this PeriodDtype.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.PeriodDtype.html#pandas.PeriodDtype"}, {"function_name": "pandas.Interval", "full_function": "class pandas.Interval#", "function_text": "Immutable object implementing an Interval, a bounded slice-like interval.", "parameter_names_desc": [{"param_name": "left", "param_type": "orderable scalar", "param_desc": "Left bound for the interval.\n"}, {"param_name": "right", "param_type": "orderable scalar", "param_desc": "Right bound for the interval.\n"}, {"param_name": "closed", "param_type": "{‘right’, ‘left’, ‘both’, ‘neither’}, default ‘right’", "param_desc": "Whether the interval is closed on the left-side, right-side, both or\nneither. See the Notes for more detailed explanation.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Interval.html#pandas.Interval"}, {"function_name": "pandas.Interval.closed", "full_function": "Interval.closed#", "function_text": "String describing the inclusive side the intervals.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Interval.closed.html#pandas.Interval.closed"}, {"function_name": "pandas.Interval.closed_right", "full_function": "Interval.closed_right#", "function_text": "Check if the interval is closed on the right side.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Interval.closed_right.html#pandas.Interval.closed_right"}, {"function_name": "pandas.Interval.left", "full_function": "Interval.left#", "function_text": "Left bound for the interval.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Interval.left.html#pandas.Interval.left"}, {"function_name": "pandas.Interval.mid", "full_function": "Interval.mid#", "function_text": "Return the midpoint of the Interval.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Interval.mid.html#pandas.Interval.mid"}, {"function_name": "pandas.Interval.open_right", "full_function": "Interval.open_right#", "function_text": "Check if the interval is open on the right side.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Interval.open_right.html#pandas.Interval.open_right"}, {"function_name": "pandas.Interval.right", "full_function": "Interval.right#", "function_text": "Right bound for the interval.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Interval.right.html#pandas.Interval.right"}, {"function_name": "pandas.arrays.IntervalArray", "full_function": "class pandas.arrays.IntervalArray(data, closed=None, dtype=None, copy=False, verify_integrity=True)", "function_text": "Pandas array for interval data that are closed on the same side.", "parameter_names_desc": [{"param_name": "data", "param_type": "array-like (1-dimensional)", "param_desc": "Array-like (ndarray, DateTimeArray, TimeDeltaArray) containing\nInterval objects from which to build the IntervalArray.\n"}, {"param_name": "closed", "param_type": "{‘left’, ‘right’, ‘both’, ‘neither’}, default ‘right’", "param_desc": "Whether the intervals are closed on the left-side, right-side, both or\nneither.\n"}, {"param_name": "dtype", "param_type": "dtype or None, default None", "param_desc": "If None, dtype will be inferred.\n"}, {"param_name": "copy", "param_type": "bool, default False", "param_desc": "Copy the input data.\n"}, {"param_name": "verify_integrity", "param_type": "bool, default True", "param_desc": "Verify that the IntervalArray is valid.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.arrays.IntervalArray.html#pandas.arrays.IntervalArray"}, {"function_name": "pandas.IntervalDtype", "full_function": "class pandas.IntervalDtype(subtype=None, closed=None)", "function_text": "An ExtensionDtype for Interval data.", "parameter_names_desc": [{"param_name": "subtype", "param_type": "str, np.dtype", "param_desc": "The dtype of the Interval bounds.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.IntervalDtype.html#pandas.IntervalDtype"}, {"function_name": "pandas.arrays.IntegerArray", "full_function": "class pandas.arrays.IntegerArray(values, mask, copy=False)", "function_text": "Array of integer (optional missing) values.", "parameter_names_desc": [{"param_name": "values", "param_type": "numpy.ndarray", "param_desc": "A 1-d integer-dtype array.\n"}, {"param_name": "mask", "param_type": "numpy.ndarray", "param_desc": "A 1-d boolean-dtype array indicating missing values.\n"}, {"param_name": "copy", "param_type": "bool, default False", "param_desc": "Whether to copy the values and mask.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.arrays.IntegerArray.html#pandas.arrays.IntegerArray"}, {"function_name": "pandas.Int8Dtype", "full_function": "class pandas.Int8Dtype", "function_text": "An ExtensionDtype for int8 integer data.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Int8Dtype.html#pandas.Int8Dtype"}, {"function_name": "pandas.Int32Dtype", "full_function": "class pandas.Int32Dtype", "function_text": "An ExtensionDtype for int32 integer data.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Int32Dtype.html#pandas.Int32Dtype"}, {"function_name": "pandas.UInt8Dtype", "full_function": "class pandas.UInt8Dtype", "function_text": "An ExtensionDtype for uint8 integer data.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.UInt8Dtype.html#pandas.UInt8Dtype"}, {"function_name": "pandas.UInt32Dtype", "full_function": "class pandas.UInt32Dtype", "function_text": "An ExtensionDtype for uint32 integer data.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.UInt32Dtype.html#pandas.UInt32Dtype"}, {"function_name": "pandas.arrays.FloatingArray", "full_function": "class pandas.arrays.FloatingArray(values, mask, copy=False)", "function_text": "Array of floating (optional missing) values.", "parameter_names_desc": [{"param_name": "values", "param_type": "numpy.ndarray", "param_desc": "A 1-d float-dtype array.\n"}, {"param_name": "mask", "param_type": "numpy.ndarray", "param_desc": "A 1-d boolean-dtype array indicating missing values.\n"}, {"param_name": "copy", "param_type": "bool, default False", "param_desc": "Whether to copy the values and mask.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.arrays.FloatingArray.html#pandas.arrays.FloatingArray"}, {"function_name": "pandas.Float32Dtype", "full_function": "class pandas.Float32Dtype", "function_text": "An ExtensionDtype for float32 data.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Float32Dtype.html#pandas.Float32Dtype"}, {"function_name": "pandas.CategoricalDtype", "full_function": "class pandas.CategoricalDtype(categories=None, ordered=False)", "function_text": "Type for categorical data with the categories and orderedness.", "parameter_names_desc": [{"param_name": "categories", "param_type": "sequence, optional", "param_desc": "Must be unique, and must not contain any nulls.\nThe categories are stored in an Index,\nand if an index is provided the dtype of that index will be used.\n"}, {"param_name": "ordered", "param_type": "bool or None, default False", "param_desc": "Whether or not this categorical is treated as a ordered categorical.\nNone can be used to maintain the ordered value of existing categoricals when\nused in operations that combine categoricals, e.g. astype, and will resolve to\nFalse if there is no existing ordered to maintain.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalDtype.html#pandas.CategoricalDtype"}, {"function_name": "pandas.CategoricalDtype.categories", "full_function": "property CategoricalDtype.categories", "function_text": "An Index containing the unique categories allowed.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalDtype.categories.html#pandas.CategoricalDtype.categories"}, {"function_name": "pandas.Categorical", "full_function": "class pandas.Categorical(values, categories=None, ordered=None, dtype=None, fastpath=_NoDefault.no_default, copy=True)", "function_text": "Represent a categorical variable in classic R / S-plus fashion.", "parameter_names_desc": [{"param_name": "values", "param_type": "list-like", "param_desc": "The values of the categorical. If categories are given, values not in\ncategories will be replaced with NaN.\n"}, {"param_name": "categories", "param_type": "Index-like (unique), optional", "param_desc": "The unique categories for this categorical. If not given, the\ncategories are assumed to be the unique values of values (sorted, if\npossible, otherwise in the order in which they appear).\n"}, {"param_name": "ordered", "param_type": "bool, default False", "param_desc": "Whether or not this categorical is treated as a ordered categorical.\nIf True, the resulting categorical will be ordered.\nAn ordered categorical respects, when sorted, the order of its\ncategories attribute (which in turn is the categories argument, if\nprovided).\n"}, {"param_name": "dtype", "param_type": "CategoricalDtype", "param_desc": "An instance of CategoricalDtype to use for this categorical.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Categorical.html#pandas.Categorical"}, {"function_name": "pandas.Categorical.from_codes", "full_function": "classmethod Categorical.from_codes(codes, categories=None, ordered=None, dtype=None, validate=True)", "function_text": "Make a Categorical type from codes and categories or dtype.", "parameter_names_desc": [{"param_name": "codes", "param_type": "array-like of int", "param_desc": "An integer array, where each integer points to a category in\ncategories or dtype.categories, or else is -1 for NaN.\n"}, {"param_name": "categories", "param_type": "index-like, optional", "param_desc": "The categories for the categorical. Items need to be unique.\nIf the categories are not given here, then they must be provided\nin dtype.\n"}, {"param_name": "ordered", "param_type": "bool, optional", "param_desc": "Whether or not this categorical is treated as an ordered\ncategorical. If not given here or in dtype, the resulting\ncategorical will be unordered.\n"}, {"param_name": "dtype", "param_type": "CategoricalDtype or “category”, optional", "param_desc": "If CategoricalDtype, cannot be used together with\ncategories or ordered.\n"}, {"param_name": "validate", "param_type": "bool, default True", "param_desc": "If True, validate that the codes are valid for the dtype.\nIf False, don’t validate that the codes are valid. Be careful about skipping\nvalidation, as invalid codes can lead to severe problems, such as segfaults.\n\nNew in version 2.1.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Categorical.from_codes.html#pandas.Categorical.from_codes"}, {"function_name": "pandas.Categorical.dtype", "full_function": "property Categorical.dtype", "function_text": "The CategoricalDtype for this instance.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Categorical.dtype.html#pandas.Categorical.dtype"}, {"function_name": "pandas.Categorical.ordered", "full_function": "property Categorical.ordered", "function_text": "Whether the categories have an ordered relationship.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Categorical.ordered.html#pandas.Categorical.ordered"}, {"function_name": "pandas.Categorical.__array__", "full_function": "Categorical.__array__(dtype=None, copy=None)", "function_text": "The numpy array interface.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Categorical.__array__.html#pandas.Categorical.__array__"}, {"function_name": "pandas.arrays.SparseArray", "full_function": "class pandas.arrays.SparseArray(data, sparse_index=None, fill_value=None, kind='integer', dtype=None, copy=False)", "function_text": "An ExtensionArray for storing sparse data.", "parameter_names_desc": [{"param_name": "data", "param_type": "array-like or scalar", "param_desc": "A dense array of values to store in the SparseArray. This may contain\nfill_value.\n"}, {"param_name": "sparse_index", "param_type": "SparseIndex, optional", "param_desc": ""}, {"param_name": "fill_value", "param_type": "scalar, optional", "param_desc": "Elements in data that are fill_value are not stored in the\nSparseArray. For memory savings, this should be the most common value\nin data. By default, fill_value depends on the dtype of data:\n\n\ndata.dtype\nna_value\n\n\n\nfloat\nnp.nan\n\nint\n0\n\nbool\nFalse\n\ndatetime64\npd.NaT\n\ntimedelta64\npd.NaT\n\n\n\nThe fill value is potentially specified in three ways. In order of\nprecedence, these are\n\nThe fill_value argument\ndtype.fill_value if fill_value is None and dtype is\na SparseDtype\ndata.dtype.fill_value if fill_value is None and dtype\nis not a SparseDtype and data is a SparseArray.\n\n"}, {"param_name": "kind", "param_type": "str", "param_desc": "Can be ‘integer’ or ‘block’, default is ‘integer’.\nThe type of storage for sparse locations.\n\n‘block’: Stores a block and block_length for each\ncontiguous span of sparse values. This is best when\nsparse data tends to be clumped together, with large\nregions of fill-value values between sparse values.\n‘integer’: uses an integer to store the location of\neach sparse value.\n\n"}, {"param_name": "dtype", "param_type": "np.dtype or SparseDtype, optional", "param_desc": "The dtype to use for the SparseArray. For numpy dtypes, this\ndetermines the dtype of self.sp_values. For SparseDtype,\nthis determines self.sp_values and self.fill_value.\n"}, {"param_name": "copy", "param_type": "bool, default False", "param_desc": "Whether to explicitly copy the incoming data array.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.arrays.SparseArray.html#pandas.arrays.SparseArray"}, {"function_name": "pandas.SparseDtype", "full_function": "class pandas.SparseDtype(dtype=<class 'numpy.float64'>, fill_value=None)", "function_text": "Dtype for data stored in SparseArray.", "parameter_names_desc": [{"param_name": "dtype", "param_type": "str, ExtensionDtype, numpy.dtype, type, default numpy.float64", "param_desc": "The dtype of the underlying array storing the non-fill value values.\n"}, {"param_name": "fill_value", "param_type": "scalar, optional", "param_desc": "The scalar value not stored in the SparseArray. By default, this\ndepends on dtype.\n\n\ndtype\nna_value\n\n\n\nfloat\nnp.nan\n\nint\n0\n\nbool\nFalse\n\ndatetime64\npd.NaT\n\ntimedelta64\npd.NaT\n\n\n\nThe default value may be overridden by specifying a fill_value.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.SparseDtype.html#pandas.SparseDtype"}, {"function_name": "pandas.arrays.StringArray", "full_function": "class pandas.arrays.StringArray(values, copy=False)", "function_text": "Extension array for string data.", "parameter_names_desc": [{"param_name": "values", "param_type": "array-like", "param_desc": "The array of data.\n\nWarning\nCurrently, this expects an object-dtype ndarray\nwhere the elements are Python strings\nor nan-likes (None, np.nan, NA).\nThis may change without warning in the future. Use\npandas.array() with dtype=\"string\" for a stable way of\ncreating a StringArray from any sequence.\n\n\nChanged in version 1.5.0: StringArray now accepts array-likes containing\nnan-likes(None, np.nan) for the values parameter\nin addition to strings and pandas.NA\n\n"}, {"param_name": "copy", "param_type": "bool, default False", "param_desc": "Whether to copy the array of data.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.arrays.StringArray.html#pandas.arrays.StringArray"}, {"function_name": "pandas.StringDtype", "full_function": "class pandas.StringDtype(storage=None)", "function_text": "Extension dtype for string data.", "parameter_names_desc": [{"param_name": "storage", "param_type": "{“python”, “pyarrow”, “pyarrow_numpy”}, optional", "param_desc": "If not given, the value of pd.options.mode.string_storage.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.StringDtype.html#pandas.StringDtype"}, {"function_name": "pandas.arrays.BooleanArray", "full_function": "class pandas.arrays.BooleanArray(values, mask, copy=False)", "function_text": "Array of boolean (True/False) data with missing values.", "parameter_names_desc": [{"param_name": "values", "param_type": "numpy.ndarray", "param_desc": "A 1-d boolean-dtype array with the data.\n"}, {"param_name": "mask", "param_type": "numpy.ndarray", "param_desc": "A 1-d boolean-dtype array indicating missing values (True\nindicates missing).\n"}, {"param_name": "copy", "param_type": "bool, default False", "param_desc": "Whether to copy the values and mask arrays.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.arrays.BooleanArray.html#pandas.arrays.BooleanArray"}, {"function_name": "pandas.BooleanDtype", "full_function": "class pandas.BooleanDtype", "function_text": "Extension dtype for boolean data.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.BooleanDtype.html#pandas.BooleanDtype"}, {"function_name": "pandas.DatetimeTZDtype", "full_function": "class pandas.DatetimeTZDtype(unit='ns', tz=None)", "function_text": "An ExtensionDtype for timezone-aware datetime data.", "parameter_names_desc": [{"param_name": "unit", "param_type": "str, default “ns”", "param_desc": "The precision of the datetime data. Currently limited\nto \"ns\".\n"}, {"param_name": "tz", "param_type": "str, int, or datetime.tzinfo", "param_desc": "The timezone.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeTZDtype.html#pandas.DatetimeTZDtype"}, {"function_name": "pandas.PeriodDtype", "full_function": "class pandas.PeriodDtype(freq)", "function_text": "An ExtensionDtype for Period data.", "parameter_names_desc": [{"param_name": "freq", "param_type": "str or DateOffset", "param_desc": "The frequency of this PeriodDtype.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.PeriodDtype.html#pandas.PeriodDtype"}, {"function_name": "pandas.Int64Dtype", "full_function": "class pandas.Int64Dtype", "function_text": "An ExtensionDtype for int64 integer data.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Int64Dtype.html#pandas.Int64Dtype"}, {"function_name": "pandas.CategoricalDtype", "full_function": "class pandas.CategoricalDtype(categories=None, ordered=False)", "function_text": "Type for categorical data with the categories and orderedness.", "parameter_names_desc": [{"param_name": "categories", "param_type": "sequence, optional", "param_desc": "Must be unique, and must not contain any nulls.\nThe categories are stored in an Index,\nand if an index is provided the dtype of that index will be used.\n"}, {"param_name": "ordered", "param_type": "bool or None, default False", "param_desc": "Whether or not this categorical is treated as a ordered categorical.\nNone can be used to maintain the ordered value of existing categoricals when\nused in operations that combine categoricals, e.g. astype, and will resolve to\nFalse if there is no existing ordered to maintain.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalDtype.html#pandas.CategoricalDtype"}, {"function_name": "pandas.StringDtype", "full_function": "class pandas.StringDtype(storage=None)", "function_text": "Extension dtype for string data.", "parameter_names_desc": [{"param_name": "storage", "param_type": "{“python”, “pyarrow”, “pyarrow_numpy”}, optional", "param_desc": "If not given, the value of pd.options.mode.string_storage.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.StringDtype.html#pandas.StringDtype"}, {"function_name": "pandas.ArrowDtype", "full_function": "class pandas.ArrowDtype(pyarrow_dtype)", "function_text": "An ExtensionDtype for PyArrow data types.", "parameter_names_desc": [{"param_name": "pyarrow_dtype", "param_type": "pa.DataType", "param_desc": "An instance of a pyarrow.DataType.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.ArrowDtype.html#pandas.ArrowDtype"}, {"function_name": "pandas.ArrowDtype", "full_function": "class pandas.ArrowDtype(pyarrow_dtype)", "function_text": "An ExtensionDtype for PyArrow data types.", "parameter_names_desc": [{"param_name": "pyarrow_dtype", "param_type": "pa.DataType", "param_desc": "An instance of a pyarrow.DataType.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.ArrowDtype.html#pandas.ArrowDtype"}, {"function_name": "pandas.ArrowDtype", "full_function": "class pandas.ArrowDtype(pyarrow_dtype)", "function_text": "An ExtensionDtype for PyArrow data types.", "parameter_names_desc": [{"param_name": "pyarrow_dtype", "param_type": "pa.DataType", "param_desc": "An instance of a pyarrow.DataType.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.ArrowDtype.html#pandas.ArrowDtype"}, {"function_name": "pandas.ArrowDtype", "full_function": "class pandas.ArrowDtype(pyarrow_dtype)", "function_text": "An ExtensionDtype for PyArrow data types.", "parameter_names_desc": [{"param_name": "pyarrow_dtype", "param_type": "pa.DataType", "param_desc": "An instance of a pyarrow.DataType.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.ArrowDtype.html#pandas.ArrowDtype"}, {"function_name": "pandas.ArrowDtype", "full_function": "class pandas.ArrowDtype(pyarrow_dtype)", "function_text": "An ExtensionDtype for PyArrow data types.", "parameter_names_desc": [{"param_name": "pyarrow_dtype", "param_type": "pa.DataType", "param_desc": "An instance of a pyarrow.DataType.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.ArrowDtype.html#pandas.ArrowDtype"}, {"function_name": "pandas.ArrowDtype", "full_function": "class pandas.ArrowDtype(pyarrow_dtype)", "function_text": "An ExtensionDtype for PyArrow data types.", "parameter_names_desc": [{"param_name": "pyarrow_dtype", "param_type": "pa.DataType", "param_desc": "An instance of a pyarrow.DataType.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.ArrowDtype.html#pandas.ArrowDtype"}, {"function_name": "pandas.ArrowDtype", "full_function": "class pandas.ArrowDtype(pyarrow_dtype)", "function_text": "An ExtensionDtype for PyArrow data types.", "parameter_names_desc": [{"param_name": "pyarrow_dtype", "param_type": "pa.DataType", "param_desc": "An instance of a pyarrow.DataType.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.ArrowDtype.html#pandas.ArrowDtype"}, {"function_name": "pandas.ArrowDtype", "full_function": "class pandas.ArrowDtype(pyarrow_dtype)", "function_text": "An ExtensionDtype for PyArrow data types.", "parameter_names_desc": [{"param_name": "pyarrow_dtype", "param_type": "pa.DataType", "param_desc": "An instance of a pyarrow.DataType.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.ArrowDtype.html#pandas.ArrowDtype"}, {"function_name": "pandas.ArrowDtype", "full_function": "class pandas.ArrowDtype(pyarrow_dtype)", "function_text": "An ExtensionDtype for PyArrow data types.", "parameter_names_desc": [{"param_name": "pyarrow_dtype", "param_type": "pa.DataType", "param_desc": "An instance of a pyarrow.DataType.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.ArrowDtype.html#pandas.ArrowDtype"}, {"function_name": "pandas.ArrowDtype", "full_function": "class pandas.ArrowDtype(pyarrow_dtype)", "function_text": "An ExtensionDtype for PyArrow data types.", "parameter_names_desc": [{"param_name": "pyarrow_dtype", "param_type": "pa.DataType", "param_desc": "An instance of a pyarrow.DataType.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.ArrowDtype.html#pandas.ArrowDtype"}, {"function_name": "pandas.ArrowDtype", "full_function": "class pandas.ArrowDtype(pyarrow_dtype)", "function_text": "An ExtensionDtype for PyArrow data types.", "parameter_names_desc": [{"param_name": "pyarrow_dtype", "param_type": "pa.DataType", "param_desc": "An instance of a pyarrow.DataType.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.ArrowDtype.html#pandas.ArrowDtype"}, {"function_name": "pandas.ArrowDtype", "full_function": "class pandas.ArrowDtype(pyarrow_dtype)", "function_text": "An ExtensionDtype for PyArrow data types.", "parameter_names_desc": [{"param_name": "pyarrow_dtype", "param_type": "pa.DataType", "param_desc": "An instance of a pyarrow.DataType.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.ArrowDtype.html#pandas.ArrowDtype"}, {"function_name": "pandas.ArrowDtype", "full_function": "class pandas.ArrowDtype(pyarrow_dtype)", "function_text": "An ExtensionDtype for PyArrow data types.", "parameter_names_desc": [{"param_name": "pyarrow_dtype", "param_type": "pa.DataType", "param_desc": "An instance of a pyarrow.DataType.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.ArrowDtype.html#pandas.ArrowDtype"}, {"function_name": "pandas.ArrowDtype", "full_function": "class pandas.ArrowDtype(pyarrow_dtype)", "function_text": "An ExtensionDtype for PyArrow data types.", "parameter_names_desc": [{"param_name": "pyarrow_dtype", "param_type": "pa.DataType", "param_desc": "An instance of a pyarrow.DataType.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.ArrowDtype.html#pandas.ArrowDtype"}, {"function_name": "pandas.Timestamp.day_of_week", "full_function": "Timestamp.day_of_week#", "function_text": "Return day of the week.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.day_of_week.html#pandas.Timestamp.day_of_week"}, {"function_name": "pandas.Timestamp.day_of_year", "full_function": "Timestamp.day_of_year#", "function_text": "Return the day of the year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.day_of_year.html#pandas.Timestamp.day_of_year"}, {"function_name": "pandas.Timestamp.daysinmonth", "full_function": "Timestamp.daysinmonth#", "function_text": "Return the number of days in the month.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.daysinmonth.html#pandas.Timestamp.daysinmonth"}, {"function_name": "pandas.Timestamp.daysinmonth", "full_function": "Timestamp.daysinmonth#", "function_text": "Return the number of days in the month.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.daysinmonth.html#pandas.Timestamp.daysinmonth"}, {"function_name": "pandas.Timestamp.is_month_end", "full_function": "Timestamp.is_month_end#", "function_text": "Check if the date is the last day of the month.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.is_month_end.html#pandas.Timestamp.is_month_end"}, {"function_name": "pandas.Timestamp.is_quarter_end", "full_function": "Timestamp.is_quarter_end#", "function_text": "Check if date is last day of the quarter.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.is_quarter_end.html#pandas.Timestamp.is_quarter_end"}, {"function_name": "pandas.Timestamp.is_year_end", "full_function": "Timestamp.is_year_end#", "function_text": "Return True if date is last day of the year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.is_year_end.html#pandas.Timestamp.is_year_end"}, {"function_name": "pandas.Timestamp.is_year_end", "full_function": "Timestamp.is_year_end#", "function_text": "Return True if date is last day of the year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.is_year_end.html#pandas.Timestamp.is_year_end"}, {"function_name": "pandas.Timestamp.is_year_end", "full_function": "Timestamp.is_year_end#", "function_text": "Return True if date is last day of the year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.is_year_end.html#pandas.Timestamp.is_year_end"}, {"function_name": "pandas.Timestamp.is_year_end", "full_function": "Timestamp.is_year_end#", "function_text": "Return True if date is last day of the year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.is_year_end.html#pandas.Timestamp.is_year_end"}, {"function_name": "pandas.Timestamp.quarter", "full_function": "Timestamp.quarter#", "function_text": "Return the quarter of the year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.quarter.html#pandas.Timestamp.quarter"}, {"function_name": "pandas.Timestamp.quarter", "full_function": "Timestamp.quarter#", "function_text": "Return the quarter of the year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.quarter.html#pandas.Timestamp.quarter"}, {"function_name": "pandas.Timestamp.quarter", "full_function": "Timestamp.quarter#", "function_text": "Return the quarter of the year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.quarter.html#pandas.Timestamp.quarter"}, {"function_name": "pandas.Timestamp.quarter", "full_function": "Timestamp.quarter#", "function_text": "Return the quarter of the year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.quarter.html#pandas.Timestamp.quarter"}, {"function_name": "pandas.Timestamp.weekofyear", "full_function": "Timestamp.weekofyear#", "function_text": "Return the week number of the year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.weekofyear.html#pandas.Timestamp.weekofyear"}, {"function_name": "pandas.Timestamp.astimezone", "full_function": "Timestamp.astimezone(tz)#", "function_text": "Convert timezone-aware Timestamp to another time zone.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.astimezone.html#pandas.Timestamp.astimezone"}, {"function_name": "pandas.Timestamp.combine", "full_function": "classmethod Timestamp.combine(date, time)#", "function_text": "Combine date, time into datetime with same date and time fields.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.combine.html#pandas.Timestamp.combine"}, {"function_name": "pandas.Timestamp.date", "full_function": "Timestamp.date()#", "function_text": "Return date object with same year, month and day.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.date.html#pandas.Timestamp.date"}, {"function_name": "pandas.Timestamp.dst", "full_function": "Timestamp.dst()#", "function_text": "Return the daylight saving time (DST) adjustment.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.dst.html#pandas.Timestamp.dst"}, {"function_name": "pandas.Timestamp.fromordinal", "full_function": "classmethod Timestamp.fromordinal(ordinal, tz=None)#", "function_text": "Construct a timestamp from a a proleptic Gregorian ordinal.", "parameter_names_desc": [{"param_name": "ordinal", "param_type": "int", "param_desc": "Date corresponding to a proleptic Gregorian ordinal.\n"}, {"param_name": "tz", "param_type": "str, pytz.timezone, dateutil.tz.tzfile or None", "param_desc": "Time zone for the Timestamp.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.fromordinal.html#pandas.Timestamp.fromordinal"}, {"function_name": "pandas.Timestamp.isocalendar", "full_function": "Timestamp.isocalendar()#", "function_text": "Return a named tuple containing ISO year, week number, and weekday.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.isocalendar.html#pandas.Timestamp.isocalendar"}, {"function_name": "pandas.Timestamp.isoweekday", "full_function": "Timestamp.isoweekday()#", "function_text": "Return the day of the week represented by the date.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.isoweekday.html#pandas.Timestamp.isoweekday"}, {"function_name": "pandas.Timestamp.normalize", "full_function": "Timestamp.normalize()#", "function_text": "Normalize Timestamp to midnight, preserving tz information.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.normalize.html#pandas.Timestamp.normalize"}, {"function_name": "pandas.Timestamp.replace", "full_function": "Timestamp.replace(year=None, month=None, day=None, hour=None, minute=None, second=None, microsecond=None, nanosecond=None, tzinfo=<class 'object'>, fold=None)#", "function_text": "Implements datetime.replace, handles nanoseconds.", "parameter_names_desc": [{"param_name": "year", "param_type": "int, optional", "param_desc": ""}, {"param_name": "month", "param_type": "int, optional", "param_desc": ""}, {"param_name": "day", "param_type": "int, optional", "param_desc": ""}, {"param_name": "hour", "param_type": "int, optional", "param_desc": ""}, {"param_name": "minute", "param_type": "int, optional", "param_desc": ""}, {"param_name": "second", "param_type": "int, optional", "param_desc": ""}, {"param_name": "microsecond", "param_type": "int, optional", "param_desc": ""}, {"param_name": "nanosecond", "param_type": "int, optional", "param_desc": ""}, {"param_name": "tzinfo", "param_type": "tz-convertible, optional", "param_desc": ""}, {"param_name": "fold", "param_type": "int, optional", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.replace.html#pandas.Timestamp.replace"}, {"function_name": "pandas.Timestamp.strftime", "full_function": "Timestamp.strftime(format)#", "function_text": "Return a formatted string of the Timestamp.", "parameter_names_desc": [{"param_name": "format", "param_type": "str", "param_desc": "Format string to convert Timestamp to string.\nSee strftime documentation for more information on the format string:\nhttps://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.strftime.html#pandas.Timestamp.strftime"}, {"function_name": "pandas.Timestamp.time", "full_function": "Timestamp.time()#", "function_text": "Return time object with same time but with tzinfo=None.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.time.html#pandas.Timestamp.time"}, {"function_name": "pandas.Timestamp.timetuple", "full_function": "Timestamp.timetuple()#", "function_text": "Return time tuple, compatible with time.localtime().", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.timetuple.html#pandas.Timestamp.timetuple"}, {"function_name": "pandas.Timestamp.to_datetime64", "full_function": "Timestamp.to_datetime64()#", "function_text": "Return a numpy.datetime64 object with same precision.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.to_datetime64.html#pandas.Timestamp.to_datetime64"}, {"function_name": "pandas.Timestamp.to_julian_date", "full_function": "Timestamp.to_julian_date()#", "function_text": "Convert TimeStamp to a Julian Date.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.to_julian_date.html#pandas.Timestamp.to_julian_date"}, {"function_name": "pandas.Timestamp.to_pydatetime", "full_function": "Timestamp.to_pydatetime(warn=True)#", "function_text": "Convert a Timestamp object to a native Python datetime object.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.to_pydatetime.html#pandas.Timestamp.to_pydatetime"}, {"function_name": "pandas.Timestamp.toordinal", "full_function": "Timestamp.toordinal()#", "function_text": "Return proleptic Gregorian ordinal. January 1 of year 1 is day 1.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.toordinal.html#pandas.Timestamp.toordinal"}, {"function_name": "pandas.Timestamp.tz_localize", "full_function": "Timestamp.tz_localize(tz, ambiguous='raise', nonexistent='raise')#", "function_text": "Localize the Timestamp to a timezone.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.tz_localize.html#pandas.Timestamp.tz_localize"}, {"function_name": "pandas.Timestamp.utcfromtimestamp", "full_function": "classmethod Timestamp.utcfromtimestamp(ts)#", "function_text": "Construct a timezone-aware UTC datetime from a POSIX timestamp.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.utcfromtimestamp.html#pandas.Timestamp.utcfromtimestamp"}, {"function_name": "pandas.Timestamp.utcoffset", "full_function": "Timestamp.utcoffset()#", "function_text": "Return utc offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.utcoffset.html#pandas.Timestamp.utcoffset"}, {"function_name": "pandas.Timestamp.weekday", "full_function": "Timestamp.weekday()#", "function_text": "Return the day of the week represented by the date.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.weekday.html#pandas.Timestamp.weekday"}, {"function_name": "pandas.Timedelta.components", "full_function": "Timedelta.components#", "function_text": "Return a components namedtuple-like.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.components.html#pandas.Timedelta.components"}, {"function_name": "pandas.Timedelta.components", "full_function": "Timedelta.components#", "function_text": "Return a components namedtuple-like.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.components.html#pandas.Timedelta.components"}, {"function_name": "pandas.Timedelta.components", "full_function": "Timedelta.components#", "function_text": "Return a components namedtuple-like.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.components.html#pandas.Timedelta.components"}, {"function_name": "pandas.Timedelta.components", "full_function": "Timedelta.components#", "function_text": "Return a components namedtuple-like.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.components.html#pandas.Timedelta.components"}, {"function_name": "pandas.Timedelta.components", "full_function": "Timedelta.components#", "function_text": "Return a components namedtuple-like.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.components.html#pandas.Timedelta.components"}, {"function_name": "pandas.Timedelta.view", "full_function": "Timedelta.view(dtype)#", "function_text": "Array view compatibility.", "parameter_names_desc": [{"param_name": "dtype", "param_type": "str or dtype", "param_desc": "The dtype to view the underlying data as.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.view.html#pandas.Timedelta.view"}, {"function_name": "pandas.Timedelta.ceil", "full_function": "Timedelta.ceil(freq)#", "function_text": "Return a new Timedelta ceiled to this resolution.", "parameter_names_desc": [{"param_name": "freq", "param_type": "str", "param_desc": "Frequency string indicating the ceiling resolution.\nIt uses the same units as class constructor Timedelta.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.ceil.html#pandas.Timedelta.ceil"}, {"function_name": "pandas.Timedelta.isoformat", "full_function": "Timedelta.isoformat()#", "function_text": "Format the Timedelta as ISO 8601 Duration.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.isoformat.html#pandas.Timedelta.isoformat"}, {"function_name": "pandas.Timedelta.to_pytimedelta", "full_function": "Timedelta.to_pytimedelta()#", "function_text": "Convert a pandas Timedelta object into a python datetime.timedelta object.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.to_pytimedelta.html#pandas.Timedelta.to_pytimedelta"}, {"function_name": "pandas.Timedelta.to_numpy", "full_function": "Timedelta.to_numpy(dtype=None, copy=False)#", "function_text": "Convert the Timedelta to a NumPy timedelta64.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.to_numpy.html#pandas.Timedelta.to_numpy"}, {"function_name": "pandas.Period.dayofweek", "full_function": "Period.dayofweek#", "function_text": "Day of the week the period lies in, with Monday=0 and Sunday=6.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Period.dayofweek.html#pandas.Period.dayofweek"}, {"function_name": "pandas.Period.dayofyear", "full_function": "Period.dayofyear#", "function_text": "Return the day of the year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Period.dayofyear.html#pandas.Period.dayofyear"}, {"function_name": "pandas.Period.days_in_month", "full_function": "Period.days_in_month#", "function_text": "Get the total number of days in the month that this period falls on.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Period.days_in_month.html#pandas.Period.days_in_month"}, {"function_name": "pandas.Period.end_time", "full_function": "Period.end_time#", "function_text": "Get the Timestamp for the end of the period.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Period.end_time.html#pandas.Period.end_time"}, {"function_name": "pandas.Period.freqstr", "full_function": "Period.freqstr#", "function_text": "Return a string representation of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Period.freqstr.html#pandas.Period.freqstr"}, {"function_name": "pandas.Period.is_leap_year", "full_function": "Period.is_leap_year#", "function_text": "Return True if the period’s year is in a leap year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Period.is_leap_year.html#pandas.Period.is_leap_year"}, {"function_name": "pandas.Period.month", "full_function": "Period.month#", "function_text": "Return the month this Period falls on.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Period.month.html#pandas.Period.month"}, {"function_name": "pandas.Period.quarter", "full_function": "Period.quarter#", "function_text": "Return the quarter this Period falls on.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Period.quarter.html#pandas.Period.quarter"}, {"function_name": "pandas.Period.second", "full_function": "Period.second#", "function_text": "Get the second component of the Period.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Period.second.html#pandas.Period.second"}, {"function_name": "pandas.Period.week", "full_function": "Period.week#", "function_text": "Get the week of the year on the given Period.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Period.week.html#pandas.Period.week"}, {"function_name": "pandas.Period.weekofyear", "full_function": "Period.weekofyear#", "function_text": "Get the week of the year on the given Period.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Period.weekofyear.html#pandas.Period.weekofyear"}, {"function_name": "pandas.Period.now", "full_function": "classmethod Period.now(freq)#", "function_text": "Return the period of now’s date.", "parameter_names_desc": [{"param_name": "freq", "param_type": "str, BaseOffset", "param_desc": "Frequency to use for the returned period.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Period.now.html#pandas.Period.now"}, {"function_name": "pandas.Period.to_timestamp", "full_function": "Period.to_timestamp(freq=None, how='start')#", "function_text": "Return the Timestamp representation of the Period.", "parameter_names_desc": [{"param_name": "freq", "param_type": "str or DateOffset", "param_desc": "Target frequency. Default is ‘D’ if self.freq is week or\nlonger and ‘S’ otherwise.\n"}, {"param_name": "how", "param_type": "str, default ‘S’ (start)", "param_desc": "One of ‘S’, ‘E’. Can be aliased as case insensitive\n‘Start’, ‘Finish’, ‘Begin’, ‘End’.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Period.to_timestamp.html#pandas.Period.to_timestamp"}, {"function_name": "pandas.Interval.closed_left", "full_function": "Interval.closed_left#", "function_text": "Check if the interval is closed on the left side.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Interval.closed_left.html#pandas.Interval.closed_left"}, {"function_name": "pandas.Interval.is_empty", "full_function": "Interval.is_empty#", "function_text": "Indicates if an interval is empty, meaning it contains no points.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Interval.is_empty.html#pandas.Interval.is_empty"}, {"function_name": "pandas.Interval.length", "full_function": "Interval.length#", "function_text": "Return the length of the Interval.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Interval.length.html#pandas.Interval.length"}, {"function_name": "pandas.Interval.open_left", "full_function": "Interval.open_left#", "function_text": "Check if the interval is open on the left side.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Interval.open_left.html#pandas.Interval.open_left"}, {"function_name": "pandas.Interval.overlaps", "full_function": "Interval.overlaps(other)#", "function_text": "Check whether two Interval objects overlap.", "parameter_names_desc": [{"param_name": "other", "param_type": "Interval", "param_desc": "Interval to check against for an overlap.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Interval.overlaps.html#pandas.Interval.overlaps"}, {"function_name": "pandas.Int16Dtype", "full_function": "class pandas.Int16Dtype", "function_text": "An ExtensionDtype for int16 integer data.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Int16Dtype.html#pandas.Int16Dtype"}, {"function_name": "pandas.Int64Dtype", "full_function": "class pandas.Int64Dtype", "function_text": "An ExtensionDtype for int64 integer data.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Int64Dtype.html#pandas.Int64Dtype"}, {"function_name": "pandas.UInt16Dtype", "full_function": "class pandas.UInt16Dtype", "function_text": "An ExtensionDtype for uint16 integer data.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.UInt16Dtype.html#pandas.UInt16Dtype"}, {"function_name": "pandas.UInt64Dtype", "full_function": "class pandas.UInt64Dtype", "function_text": "An ExtensionDtype for uint64 integer data.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.UInt64Dtype.html#pandas.UInt64Dtype"}, {"function_name": "pandas.Float64Dtype", "full_function": "class pandas.Float64Dtype", "function_text": "An ExtensionDtype for float64 data.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Float64Dtype.html#pandas.Float64Dtype"}, {"function_name": "pandas.CategoricalDtype.ordered", "full_function": "property CategoricalDtype.ordered", "function_text": "Whether the categories have an ordered relationship.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalDtype.ordered.html#pandas.CategoricalDtype.ordered"}, {"function_name": "pandas.Categorical.categories", "full_function": "property Categorical.categories", "function_text": "The categories of this categorical.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Categorical.categories.html#pandas.Categorical.categories"}, {"function_name": "pandas.Categorical.codes", "full_function": "property Categorical.codes", "function_text": "The category codes of this categorical index.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Categorical.codes.html#pandas.Categorical.codes"}, {"function_name": "pandas.arrays.ArrowStringArray", "full_function": "class pandas.arrays.ArrowStringArray(values)", "function_text": "Extension array for string data in a pyarrow.ChunkedArray.", "parameter_names_desc": [{"param_name": "values", "param_type": "pyarrow.Array or pyarrow.ChunkedArray", "param_desc": "The array of data.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.arrays.ArrowStringArray.html#pandas.arrays.ArrowStringArray"}]}, {"name": "Utilities", "url": "https://pandas.pydata.org/docs/reference/arrays.html#utilities", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.union_categoricals.html#pandas.api.types.union_categoricals", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.pandas_dtype.html#pandas.api.types.pandas_dtype", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_any_real_numeric_dtype.html#pandas.api.types.is_any_real_numeric_dtype", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_categorical_dtype.html#pandas.api.types.is_categorical_dtype", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_datetime64_any_dtype.html#pandas.api.types.is_datetime64_any_dtype", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_datetime64_ns_dtype.html#pandas.api.types.is_datetime64_ns_dtype", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_extension_array_dtype.html#pandas.api.types.is_extension_array_dtype", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_int64_dtype.html#pandas.api.types.is_int64_dtype", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_interval_dtype.html#pandas.api.types.is_interval_dtype", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_object_dtype.html#pandas.api.types.is_object_dtype", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_signed_integer_dtype.html#pandas.api.types.is_signed_integer_dtype", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_timedelta64_dtype.html#pandas.api.types.is_timedelta64_dtype", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_unsigned_integer_dtype.html#pandas.api.types.is_unsigned_integer_dtype", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_dict_like.html#pandas.api.types.is_dict_like", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_list_like.html#pandas.api.types.is_list_like", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_iterator.html#pandas.api.types.is_iterator", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_bool.html#pandas.api.types.is_bool", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_float.html#pandas.api.types.is_float", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_integer.html#pandas.api.types.is_integer", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_number.html#pandas.api.types.is_number", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_re_compilable.html#pandas.api.types.is_re_compilable", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.infer_dtype.html#pandas.api.types.infer_dtype", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_bool_dtype.html#pandas.api.types.is_bool_dtype", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_complex_dtype.html#pandas.api.types.is_complex_dtype", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_datetime64_dtype.html#pandas.api.types.is_datetime64_dtype", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_datetime64tz_dtype.html#pandas.api.types.is_datetime64tz_dtype", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_float_dtype.html#pandas.api.types.is_float_dtype", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_integer_dtype.html#pandas.api.types.is_integer_dtype", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_numeric_dtype.html#pandas.api.types.is_numeric_dtype", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_period_dtype.html#pandas.api.types.is_period_dtype", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_string_dtype.html#pandas.api.types.is_string_dtype", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_timedelta64_ns_dtype.html#pandas.api.types.is_timedelta64_ns_dtype", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_sparse.html#pandas.api.types.is_sparse", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_file_like.html#pandas.api.types.is_file_like", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_named_tuple.html#pandas.api.types.is_named_tuple", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_complex.html#pandas.api.types.is_complex", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_hashable.html#pandas.api.types.is_hashable", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_interval.html#pandas.api.types.is_interval", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_re.html#pandas.api.types.is_re", "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_scalar.html#pandas.api.types.is_scalar"], "function_definitions": [{"function_name": "pandas.api.types.union_categoricals", "full_function": "pandas.api.types.union_categoricals(to_union, sort_categories=False, ignore_order=False)", "function_text": "Combine list-like of Categorical-like, unioning categories.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.union_categoricals.html#pandas.api.types.union_categoricals"}, {"function_name": "pandas.api.types.pandas_dtype", "full_function": "pandas.api.types.pandas_dtype(dtype)", "function_text": "Convert input into a pandas only dtype object or a numpy dtype object.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.pandas_dtype.html#pandas.api.types.pandas_dtype"}, {"function_name": "pandas.api.types.is_any_real_numeric_dtype", "full_function": "pandas.api.types.is_any_real_numeric_dtype(arr_or_dtype)", "function_text": "Check whether the provided array or dtype is of a real number dtype.", "parameter_names_desc": [{"param_name": "arr_or_dtype", "param_type": "array-like or dtype", "param_desc": "The array or dtype to check.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_any_real_numeric_dtype.html#pandas.api.types.is_any_real_numeric_dtype"}, {"function_name": "pandas.api.types.is_categorical_dtype", "full_function": "pandas.api.types.is_categorical_dtype(arr_or_dtype)", "function_text": "Check whether an array-like or dtype is of the Categorical dtype.", "parameter_names_desc": [{"param_name": "arr_or_dtype", "param_type": "array-like or dtype", "param_desc": "The array-like or dtype to check.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_categorical_dtype.html#pandas.api.types.is_categorical_dtype"}, {"function_name": "pandas.api.types.is_datetime64_any_dtype", "full_function": "pandas.api.types.is_datetime64_any_dtype(arr_or_dtype)", "function_text": "Check whether the provided array or dtype is of the datetime64 dtype.", "parameter_names_desc": [{"param_name": "arr_or_dtype", "param_type": "array-like or dtype", "param_desc": "The array or dtype to check.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_datetime64_any_dtype.html#pandas.api.types.is_datetime64_any_dtype"}, {"function_name": "pandas.api.types.is_datetime64_ns_dtype", "full_function": "pandas.api.types.is_datetime64_ns_dtype(arr_or_dtype)", "function_text": "Check whether the provided array or dtype is of the datetime64[ns] dtype.", "parameter_names_desc": [{"param_name": "arr_or_dtype", "param_type": "array-like or dtype", "param_desc": "The array or dtype to check.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_datetime64_ns_dtype.html#pandas.api.types.is_datetime64_ns_dtype"}, {"function_name": "pandas.api.types.is_extension_array_dtype", "full_function": "pandas.api.types.is_extension_array_dtype(arr_or_dtype)", "function_text": "Check if an object is a pandas extension array type.", "parameter_names_desc": [{"param_name": "arr_or_dtype", "param_type": "object", "param_desc": "For array-like input, the .dtype attribute will\nbe extracted.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_extension_array_dtype.html#pandas.api.types.is_extension_array_dtype"}, {"function_name": "pandas.api.types.is_int64_dtype", "full_function": "pandas.api.types.is_int64_dtype(arr_or_dtype)", "function_text": "Check whether the provided array or dtype is of the int64 dtype.", "parameter_names_desc": [{"param_name": "arr_or_dtype", "param_type": "array-like or dtype", "param_desc": "The array or dtype to check.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_int64_dtype.html#pandas.api.types.is_int64_dtype"}, {"function_name": "pandas.api.types.is_interval_dtype", "full_function": "pandas.api.types.is_interval_dtype(arr_or_dtype)", "function_text": "Check whether an array-like or dtype is of the Interval dtype.", "parameter_names_desc": [{"param_name": "arr_or_dtype", "param_type": "array-like or dtype", "param_desc": "The array-like or dtype to check.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_interval_dtype.html#pandas.api.types.is_interval_dtype"}, {"function_name": "pandas.api.types.is_object_dtype", "full_function": "pandas.api.types.is_object_dtype(arr_or_dtype)", "function_text": "Check whether an array-like or dtype is of the object dtype.", "parameter_names_desc": [{"param_name": "arr_or_dtype", "param_type": "array-like or dtype", "param_desc": "The array-like or dtype to check.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_object_dtype.html#pandas.api.types.is_object_dtype"}, {"function_name": "pandas.api.types.is_signed_integer_dtype", "full_function": "pandas.api.types.is_signed_integer_dtype(arr_or_dtype)", "function_text": "Check whether the provided array or dtype is of a signed integer dtype.", "parameter_names_desc": [{"param_name": "arr_or_dtype", "param_type": "array-like or dtype", "param_desc": "The array or dtype to check.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_signed_integer_dtype.html#pandas.api.types.is_signed_integer_dtype"}, {"function_name": "pandas.api.types.is_timedelta64_dtype", "full_function": "pandas.api.types.is_timedelta64_dtype(arr_or_dtype)", "function_text": "Check whether an array-like or dtype is of the timedelta64 dtype.", "parameter_names_desc": [{"param_name": "arr_or_dtype", "param_type": "array-like or dtype", "param_desc": "The array-like or dtype to check.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_timedelta64_dtype.html#pandas.api.types.is_timedelta64_dtype"}, {"function_name": "pandas.api.types.is_unsigned_integer_dtype", "full_function": "pandas.api.types.is_unsigned_integer_dtype(arr_or_dtype)", "function_text": "Check whether the provided array or dtype is of an unsigned integer dtype.", "parameter_names_desc": [{"param_name": "arr_or_dtype", "param_type": "array-like or dtype", "param_desc": "The array or dtype to check.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_unsigned_integer_dtype.html#pandas.api.types.is_unsigned_integer_dtype"}, {"function_name": "pandas.api.types.is_dict_like", "full_function": "pandas.api.types.is_dict_like(obj)", "function_text": "Check if the object is dict-like.", "parameter_names_desc": [{"param_name": "obj", "param_type": "The object to check", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_dict_like.html#pandas.api.types.is_dict_like"}, {"function_name": "pandas.api.types.is_list_like", "full_function": "pandas.api.types.is_list_like(obj, allow_sets=True)#", "function_text": "Check if the object is list-like.", "parameter_names_desc": [{"param_name": "obj", "param_type": "object", "param_desc": "Object to check.\n"}, {"param_name": "allow_sets", "param_type": "bool, default True", "param_desc": "If this parameter is False, sets will not be considered list-like.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_list_like.html#pandas.api.types.is_list_like"}, {"function_name": "pandas.api.types.is_iterator", "full_function": "pandas.api.types.is_iterator(obj)#", "function_text": "Check if the object is an iterator.", "parameter_names_desc": [{"param_name": "obj", "param_type": "The object to check", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_iterator.html#pandas.api.types.is_iterator"}, {"function_name": "pandas.api.types.is_bool", "full_function": "pandas.api.types.is_bool(obj)#", "function_text": "Return True if given object is boolean.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_bool.html#pandas.api.types.is_bool"}, {"function_name": "pandas.api.types.is_float", "full_function": "pandas.api.types.is_float(obj)#", "function_text": "Return True if given object is float.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_float.html#pandas.api.types.is_float"}, {"function_name": "pandas.api.types.is_integer", "full_function": "pandas.api.types.is_integer(obj)#", "function_text": "Return True if given object is integer.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_integer.html#pandas.api.types.is_integer"}, {"function_name": "pandas.api.types.is_number", "full_function": "pandas.api.types.is_number(obj)", "function_text": "Check if the object is a number.", "parameter_names_desc": [{"param_name": "obj", "param_type": "any type", "param_desc": "The object to check if is a number.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_number.html#pandas.api.types.is_number"}, {"function_name": "pandas.api.types.is_re_compilable", "full_function": "pandas.api.types.is_re_compilable(obj)", "function_text": "Check if the object can be compiled into a regex pattern instance.", "parameter_names_desc": [{"param_name": "obj", "param_type": "The object to check", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_re_compilable.html#pandas.api.types.is_re_compilable"}, {"function_name": "pandas.api.types.infer_dtype", "full_function": "pandas.api.types.infer_dtype(value, skipna=True)#", "function_text": "Return a string label of the type of a scalar or list-like of values.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.infer_dtype.html#pandas.api.types.infer_dtype"}, {"function_name": "pandas.api.types.is_bool_dtype", "full_function": "pandas.api.types.is_bool_dtype(arr_or_dtype)", "function_text": "Check whether the provided array or dtype is of a boolean dtype.", "parameter_names_desc": [{"param_name": "arr_or_dtype", "param_type": "array-like or dtype", "param_desc": "The array or dtype to check.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_bool_dtype.html#pandas.api.types.is_bool_dtype"}, {"function_name": "pandas.api.types.is_complex_dtype", "full_function": "pandas.api.types.is_complex_dtype(arr_or_dtype)", "function_text": "Check whether the provided array or dtype is of a complex dtype.", "parameter_names_desc": [{"param_name": "arr_or_dtype", "param_type": "array-like or dtype", "param_desc": "The array or dtype to check.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_complex_dtype.html#pandas.api.types.is_complex_dtype"}, {"function_name": "pandas.api.types.is_datetime64_dtype", "full_function": "pandas.api.types.is_datetime64_dtype(arr_or_dtype)", "function_text": "Check whether an array-like or dtype is of the datetime64 dtype.", "parameter_names_desc": [{"param_name": "arr_or_dtype", "param_type": "array-like or dtype", "param_desc": "The array-like or dtype to check.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_datetime64_dtype.html#pandas.api.types.is_datetime64_dtype"}, {"function_name": "pandas.api.types.is_datetime64tz_dtype", "full_function": "pandas.api.types.is_datetime64tz_dtype(arr_or_dtype)", "function_text": "Check whether an array-like or dtype is of a DatetimeTZDtype dtype.", "parameter_names_desc": [{"param_name": "arr_or_dtype", "param_type": "array-like or dtype", "param_desc": "The array-like or dtype to check.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_datetime64tz_dtype.html#pandas.api.types.is_datetime64tz_dtype"}, {"function_name": "pandas.api.types.is_float_dtype", "full_function": "pandas.api.types.is_float_dtype(arr_or_dtype)", "function_text": "Check whether the provided array or dtype is of a float dtype.", "parameter_names_desc": [{"param_name": "arr_or_dtype", "param_type": "array-like or dtype", "param_desc": "The array or dtype to check.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_float_dtype.html#pandas.api.types.is_float_dtype"}, {"function_name": "pandas.api.types.is_integer_dtype", "full_function": "pandas.api.types.is_integer_dtype(arr_or_dtype)", "function_text": "Check whether the provided array or dtype is of an integer dtype.", "parameter_names_desc": [{"param_name": "arr_or_dtype", "param_type": "array-like or dtype", "param_desc": "The array or dtype to check.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_integer_dtype.html#pandas.api.types.is_integer_dtype"}, {"function_name": "pandas.api.types.is_numeric_dtype", "full_function": "pandas.api.types.is_numeric_dtype(arr_or_dtype)", "function_text": "Check whether the provided array or dtype is of a numeric dtype.", "parameter_names_desc": [{"param_name": "arr_or_dtype", "param_type": "array-like or dtype", "param_desc": "The array or dtype to check.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_numeric_dtype.html#pandas.api.types.is_numeric_dtype"}, {"function_name": "pandas.api.types.is_period_dtype", "full_function": "pandas.api.types.is_period_dtype(arr_or_dtype)", "function_text": "Check whether an array-like or dtype is of the Period dtype.", "parameter_names_desc": [{"param_name": "arr_or_dtype", "param_type": "array-like or dtype", "param_desc": "The array-like or dtype to check.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_period_dtype.html#pandas.api.types.is_period_dtype"}, {"function_name": "pandas.api.types.is_string_dtype", "full_function": "pandas.api.types.is_string_dtype(arr_or_dtype)", "function_text": "Check whether the provided array or dtype is of the string dtype.", "parameter_names_desc": [{"param_name": "arr_or_dtype", "param_type": "array-like or dtype", "param_desc": "The array or dtype to check.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_string_dtype.html#pandas.api.types.is_string_dtype"}, {"function_name": "pandas.api.types.is_timedelta64_ns_dtype", "full_function": "pandas.api.types.is_timedelta64_ns_dtype(arr_or_dtype)", "function_text": "Check whether the provided array or dtype is of the timedelta64[ns] dtype.", "parameter_names_desc": [{"param_name": "arr_or_dtype", "param_type": "array-like or dtype", "param_desc": "The array or dtype to check.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_timedelta64_ns_dtype.html#pandas.api.types.is_timedelta64_ns_dtype"}, {"function_name": "pandas.api.types.is_sparse", "full_function": "pandas.api.types.is_sparse(arr)", "function_text": "Check whether an array-like is a 1-D pandas sparse array.", "parameter_names_desc": [{"param_name": "arr", "param_type": "array-like", "param_desc": "Array-like to check.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_sparse.html#pandas.api.types.is_sparse"}, {"function_name": "pandas.api.types.is_file_like", "full_function": "pandas.api.types.is_file_like(obj)", "function_text": "Check if the object is a file-like object.", "parameter_names_desc": [{"param_name": "obj", "param_type": "The object to check", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_file_like.html#pandas.api.types.is_file_like"}, {"function_name": "pandas.api.types.is_named_tuple", "full_function": "pandas.api.types.is_named_tuple(obj)", "function_text": "Check if the object is a named tuple.", "parameter_names_desc": [{"param_name": "obj", "param_type": "The object to check", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_named_tuple.html#pandas.api.types.is_named_tuple"}, {"function_name": "pandas.api.types.is_complex", "full_function": "pandas.api.types.is_complex(obj)#", "function_text": "Return True if given object is complex.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_complex.html#pandas.api.types.is_complex"}, {"function_name": "pandas.api.types.is_hashable", "full_function": "pandas.api.types.is_hashable(obj)", "function_text": "Return True if hash(obj) will succeed, False otherwise.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_hashable.html#pandas.api.types.is_hashable"}, {"function_name": "pandas.api.types.is_hashable", "full_function": "pandas.api.types.is_hashable(obj)", "function_text": "Return True if hash(obj) will succeed, False otherwise.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_hashable.html#pandas.api.types.is_hashable"}, {"function_name": "pandas.api.types.is_re", "full_function": "pandas.api.types.is_re(obj)", "function_text": "Check if the object is a regex pattern instance.", "parameter_names_desc": [{"param_name": "obj", "param_type": "The object to check", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_re.html#pandas.api.types.is_re"}, {"function_name": "pandas.api.types.is_scalar", "full_function": "pandas.api.types.is_scalar(val)#", "function_text": "Return True if given object is scalar.", "parameter_names_desc": [{"param_name": "val", "param_type": "object", "param_desc": "This includes:\n\nnumpy array scalar (e.g. np.int64)\nPython builtin numerics\nPython builtin byte arrays and strings\nNone\ndatetime.datetime\ndatetime.timedelta\nPeriod\ndecimal.Decimal\nInterval\nDateOffset\nFraction\nNumber.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_scalar.html#pandas.api.types.is_scalar"}]}], "name": "pandas arrays, scalars, and data types", "url": "https://pandas.pydata.org/docs/reference/arrays.html"}, "indexing.html": {"functions": [{"name": "Index", "url": "https://pandas.pydata.org/docs/reference/indexing.html#index", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.Index.html#pandas.Index", "https://pandas.pydata.org/docs/reference/api/pandas.Index.values.html#pandas.Index.values", "https://pandas.pydata.org/docs/reference/api/pandas.Index.is_monotonic_decreasing.html#pandas.Index.is_monotonic_decreasing", "https://pandas.pydata.org/docs/reference/api/pandas.Index.has_duplicates.html#pandas.Index.has_duplicates", "https://pandas.pydata.org/docs/reference/api/pandas.Index.dtype.html#pandas.Index.dtype", "https://pandas.pydata.org/docs/reference/api/pandas.Index.shape.html#pandas.Index.shape", "https://pandas.pydata.org/docs/reference/api/pandas.Index.names.html#pandas.Index.names", "https://pandas.pydata.org/docs/reference/api/pandas.Index.ndim.html#pandas.Index.ndim", "https://pandas.pydata.org/docs/reference/api/pandas.Index.empty.html#pandas.Index.empty", "https://pandas.pydata.org/docs/reference/api/pandas.Index.memory_usage.html#pandas.Index.memory_usage", "https://pandas.pydata.org/docs/reference/api/pandas.Index.all.html#pandas.Index.all", "https://pandas.pydata.org/docs/reference/api/pandas.Index.argmin.html#pandas.Index.argmin", "https://pandas.pydata.org/docs/reference/api/pandas.Index.copy.html#pandas.Index.copy", "https://pandas.pydata.org/docs/reference/api/pandas.Index.drop.html#pandas.Index.drop", "https://pandas.pydata.org/docs/reference/api/pandas.Index.duplicated.html#pandas.Index.duplicated", "https://pandas.pydata.org/docs/reference/api/pandas.Index.factorize.html#pandas.Index.factorize", "https://pandas.pydata.org/docs/reference/api/pandas.Index.insert.html#pandas.Index.insert", "https://pandas.pydata.org/docs/reference/api/pandas.Index.is_boolean.html#pandas.Index.is_boolean", "https://pandas.pydata.org/docs/reference/api/pandas.Index.is_floating.html#pandas.Index.is_floating", "https://pandas.pydata.org/docs/reference/api/pandas.Index.is_interval.html#pandas.Index.is_interval", "https://pandas.pydata.org/docs/reference/api/pandas.Index.is_object.html#pandas.Index.is_object", "https://pandas.pydata.org/docs/reference/api/pandas.Index.max.html#pandas.Index.max", "https://pandas.pydata.org/docs/reference/api/pandas.Index.rename.html#pandas.Index.rename", "https://pandas.pydata.org/docs/reference/api/pandas.Index.where.html#pandas.Index.where", "https://pandas.pydata.org/docs/reference/api/pandas.Index.putmask.html#pandas.Index.putmask", "https://pandas.pydata.org/docs/reference/api/pandas.Index.nunique.html#pandas.Index.nunique", "https://pandas.pydata.org/docs/reference/api/pandas.Index.set_names.html#pandas.Index.set_names", "https://pandas.pydata.org/docs/reference/api/pandas.Index.fillna.html#pandas.Index.fillna", "https://pandas.pydata.org/docs/reference/api/pandas.Index.isna.html#pandas.Index.isna", "https://pandas.pydata.org/docs/reference/api/pandas.Index.astype.html#pandas.Index.astype", "https://pandas.pydata.org/docs/reference/api/pandas.Index.map.html#pandas.Index.map", "https://pandas.pydata.org/docs/reference/api/pandas.Index.to_list.html#pandas.Index.to_list", "https://pandas.pydata.org/docs/reference/api/pandas.Index.to_frame.html#pandas.Index.to_frame", "https://pandas.pydata.org/docs/reference/api/pandas.Index.argsort.html#pandas.Index.argsort", "https://pandas.pydata.org/docs/reference/api/pandas.Index.sort_values.html#pandas.Index.sort_values", "https://pandas.pydata.org/docs/reference/api/pandas.Index.shift.html#pandas.Index.shift", "https://pandas.pydata.org/docs/reference/api/pandas.Index.append.html#pandas.Index.append", "https://pandas.pydata.org/docs/reference/api/pandas.Index.intersection.html#pandas.Index.intersection", "https://pandas.pydata.org/docs/reference/api/pandas.Index.difference.html#pandas.Index.difference", "https://pandas.pydata.org/docs/reference/api/pandas.Index.asof.html#pandas.Index.asof", "https://pandas.pydata.org/docs/reference/api/pandas.Index.get_indexer.html#pandas.Index.get_indexer", "https://pandas.pydata.org/docs/reference/api/pandas.Index.get_indexer_non_unique.html#pandas.Index.get_indexer_non_unique", "https://pandas.pydata.org/docs/reference/api/pandas.Index.get_loc.html#pandas.Index.get_loc", "https://pandas.pydata.org/docs/reference/api/pandas.Index.isin.html#pandas.Index.isin", "https://pandas.pydata.org/docs/reference/api/pandas.Index.slice_locs.html#pandas.Index.slice_locs", "https://pandas.pydata.org/docs/reference/api/pandas.Index.is_monotonic_increasing.html#pandas.Index.is_monotonic_increasing", "https://pandas.pydata.org/docs/reference/api/pandas.Index.is_unique.html#pandas.Index.is_unique", "https://pandas.pydata.org/docs/reference/api/pandas.Index.hasnans.html#pandas.Index.hasnans", "https://pandas.pydata.org/docs/reference/api/pandas.Index.inferred_type.html#pandas.Index.inferred_type", "https://pandas.pydata.org/docs/reference/api/pandas.Index.name.html#pandas.Index.name", "https://pandas.pydata.org/docs/reference/api/pandas.Index.nbytes.html#pandas.Index.nbytes", "https://pandas.pydata.org/docs/reference/api/pandas.Index.size.html#pandas.Index.size", "https://pandas.pydata.org/docs/reference/api/pandas.Index.T.html#pandas.Index.T", "https://pandas.pydata.org/docs/reference/api/pandas.Index.any.html#pandas.Index.any", "https://pandas.pydata.org/docs/reference/api/pandas.Index.argmax.html#pandas.Index.argmax", "https://pandas.pydata.org/docs/reference/api/pandas.Index.delete.html#pandas.Index.delete", "https://pandas.pydata.org/docs/reference/api/pandas.Index.drop_duplicates.html#pandas.Index.drop_duplicates", "https://pandas.pydata.org/docs/reference/api/pandas.Index.equals.html#pandas.Index.equals", "https://pandas.pydata.org/docs/reference/api/pandas.Index.identical.html#pandas.Index.identical", "https://pandas.pydata.org/docs/reference/api/pandas.Index.is_.html#pandas.Index.is_", "https://pandas.pydata.org/docs/reference/api/pandas.Index.is_categorical.html#pandas.Index.is_categorical", "https://pandas.pydata.org/docs/reference/api/pandas.Index.is_integer.html#pandas.Index.is_integer", "https://pandas.pydata.org/docs/reference/api/pandas.Index.is_numeric.html#pandas.Index.is_numeric", "https://pandas.pydata.org/docs/reference/api/pandas.Index.min.html#pandas.Index.min", "https://pandas.pydata.org/docs/reference/api/pandas.Index.reindex.html#pandas.Index.reindex", "https://pandas.pydata.org/docs/reference/api/pandas.Index.repeat.html#pandas.Index.repeat", "https://pandas.pydata.org/docs/reference/api/pandas.Index.take.html#pandas.Index.take", "https://pandas.pydata.org/docs/reference/api/pandas.Index.unique.html#pandas.Index.unique", "https://pandas.pydata.org/docs/reference/api/pandas.Index.value_counts.html#pandas.Index.value_counts", "https://pandas.pydata.org/docs/reference/api/pandas.Index.droplevel.html#pandas.Index.droplevel", "https://pandas.pydata.org/docs/reference/api/pandas.Index.dropna.html#pandas.Index.dropna", "https://pandas.pydata.org/docs/reference/api/pandas.Index.notna.html#pandas.Index.notna", "https://pandas.pydata.org/docs/reference/api/pandas.Index.item.html#pandas.Index.item", "https://pandas.pydata.org/docs/reference/api/pandas.Index.ravel.html#pandas.Index.ravel", "https://pandas.pydata.org/docs/reference/api/pandas.Index.to_series.html#pandas.Index.to_series", "https://pandas.pydata.org/docs/reference/api/pandas.Index.view.html#pandas.Index.view", "https://pandas.pydata.org/docs/reference/api/pandas.Index.searchsorted.html#pandas.Index.searchsorted", "https://pandas.pydata.org/docs/reference/api/pandas.Index.join.html#pandas.Index.join", "https://pandas.pydata.org/docs/reference/api/pandas.Index.union.html#pandas.Index.union", "https://pandas.pydata.org/docs/reference/api/pandas.Index.symmetric_difference.html#pandas.Index.symmetric_difference", "https://pandas.pydata.org/docs/reference/api/pandas.Index.asof_locs.html#pandas.Index.asof_locs", "https://pandas.pydata.org/docs/reference/api/pandas.Index.get_indexer_for.html#pandas.Index.get_indexer_for", "https://pandas.pydata.org/docs/reference/api/pandas.Index.get_level_values.html#pandas.Index.get_level_values", "https://pandas.pydata.org/docs/reference/api/pandas.Index.get_slice_bound.html#pandas.Index.get_slice_bound", "https://pandas.pydata.org/docs/reference/api/pandas.Index.slice_indexer.html#pandas.Index.slice_indexer"], "function_definitions": [{"function_name": "pandas.Index", "full_function": "class pandas.Index(data=None, dtype=None, copy=False, name=None, tupleize_cols=True)", "function_text": "Immutable sequence used for indexing and alignment.", "parameter_names_desc": [{"param_name": "data", "param_type": "array-like (1-dimensional)", "param_desc": ""}, {"param_name": "dtype", "param_type": "str, numpy.dtype, or ExtensionDtype, optional", "param_desc": "Data type for the output Index. If not specified, this will be\ninferred from data.\nSee the user guide for more usages.\n"}, {"param_name": "copy", "param_type": "bool, default False", "param_desc": "Copy input data.\n"}, {"param_name": "name", "param_type": "object", "param_desc": "Name to be stored in the index.\n"}, {"param_name": "tupleize_cols", "param_type": "bool (default: True)", "param_desc": "When True, attempt to create a MultiIndex if possible.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.html#pandas.Index"}, {"function_name": "pandas.Index.values", "full_function": "property Index.values", "function_text": "Return an array representing the data in the Index.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.values.html#pandas.Index.values"}, {"function_name": "pandas.Index.is_monotonic_decreasing", "full_function": "property Index.is_monotonic_decreasing", "function_text": "Return a boolean if the values are equal or decreasing.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.is_monotonic_decreasing.html#pandas.Index.is_monotonic_decreasing"}, {"function_name": "pandas.Index.has_duplicates", "full_function": "property Index.has_duplicates", "function_text": "Check if the Index has duplicate values.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.has_duplicates.html#pandas.Index.has_duplicates"}, {"function_name": "pandas.Index.dtype", "full_function": "Index.dtype", "function_text": "Return the dtype object of the underlying data.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.dtype.html#pandas.Index.dtype"}, {"function_name": "pandas.Index.shape", "full_function": "property Index.shape", "function_text": "Return a tuple of the shape of the underlying data.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.shape.html#pandas.Index.shape"}, {"function_name": "pandas.Index.shape", "full_function": "property Index.shape", "function_text": "Return a tuple of the shape of the underlying data.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.shape.html#pandas.Index.shape"}, {"function_name": "pandas.Index.ndim", "full_function": "property Index.ndim", "function_text": "Number of dimensions of the underlying data, by definition 1.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.ndim.html#pandas.Index.ndim"}, {"function_name": "pandas.Index.ndim", "full_function": "property Index.ndim", "function_text": "Number of dimensions of the underlying data, by definition 1.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.ndim.html#pandas.Index.ndim"}, {"function_name": "pandas.Index.memory_usage", "full_function": "Index.memory_usage(deep=False)", "function_text": "Memory usage of the values.", "parameter_names_desc": [{"param_name": "deep", "param_type": "bool, default False", "param_desc": "Introspect the data deeply, interrogate\nobject dtypes for system-level memory consumption.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.memory_usage.html#pandas.Index.memory_usage"}, {"function_name": "pandas.Index.all", "full_function": "Index.all(*args, **kwargs)", "function_text": "Return whether all elements are Truthy.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.all.html#pandas.Index.all"}, {"function_name": "pandas.Index.argmin", "full_function": "Index.argmin(axis=None, skipna=True, *args, **kwargs)", "function_text": "Return int position of the smallest value in the Series.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{None}", "param_desc": "Unused. Parameter needed for compatibility with DataFrame.\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values when showing the result.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.argmin.html#pandas.Index.argmin"}, {"function_name": "pandas.Index.copy", "full_function": "Index.copy(name=None, deep=False)", "function_text": "Make a copy of this object.", "parameter_names_desc": [{"param_name": "name", "param_type": "Label, optional", "param_desc": "Set name for new object.\n"}, {"param_name": "deep", "param_type": "bool, default False", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.copy.html#pandas.Index.copy"}, {"function_name": "pandas.Index.drop", "full_function": "Index.drop(labels, errors='raise')", "function_text": "Make new Index with passed list of labels deleted.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.drop.html#pandas.Index.drop"}, {"function_name": "pandas.Index.duplicated", "full_function": "Index.duplicated(keep='first')", "function_text": "Indicate duplicate index values.", "parameter_names_desc": [{"param_name": "keep", "param_type": "{‘first’, ‘last’, False}, default ‘first’", "param_desc": "The value or values in a set of duplicates to mark as missing.\n\n‘first’ : Mark duplicates as True except for the first\noccurrence.\n‘last’ : Mark duplicates as True except for the last\noccurrence.\nFalse : Mark all duplicates as True.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.duplicated.html#pandas.Index.duplicated"}, {"function_name": "pandas.Index.factorize", "full_function": "Index.factorize(sort=False, use_na_sentinel=True)", "function_text": "Encode the object as an enumerated type or categorical variable.", "parameter_names_desc": [{"param_name": "sort", "param_type": "bool, default False", "param_desc": "Sort uniques and shuffle codes to maintain the\nrelationship.\n"}, {"param_name": "use_na_sentinel", "param_type": "bool, default True", "param_desc": "If True, the sentinel -1 will be used for NaN values. If False,\nNaN values will be encoded as non-negative integers and will not drop the\nNaN from the uniques of the values.\n\nNew in version 1.5.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.factorize.html#pandas.Index.factorize"}, {"function_name": "pandas.Index.insert", "full_function": "Index.insert(loc, item)", "function_text": "Make new Index inserting new item at location.", "parameter_names_desc": [{"param_name": "loc", "param_type": "int", "param_desc": ""}, {"param_name": "item", "param_type": "object", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.insert.html#pandas.Index.insert"}, {"function_name": "pandas.Index.is_boolean", "full_function": "final Index.is_boolean()", "function_text": "Check if the Index only consists of booleans.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.is_boolean.html#pandas.Index.is_boolean"}, {"function_name": "pandas.Index.is_floating", "full_function": "final Index.is_floating()", "function_text": "Check if the Index is a floating type.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.is_floating.html#pandas.Index.is_floating"}, {"function_name": "pandas.Index.is_interval", "full_function": "final Index.is_interval()", "function_text": "Check if the Index holds Interval objects.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.is_interval.html#pandas.Index.is_interval"}, {"function_name": "pandas.Index.is_object", "full_function": "final Index.is_object()", "function_text": "Check if the Index is of the object dtype.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.is_object.html#pandas.Index.is_object"}, {"function_name": "pandas.Index.max", "full_function": "Index.max(axis=None, skipna=True, *args, **kwargs)", "function_text": "Return the maximum value of the Index.", "parameter_names_desc": [{"param_name": "axis", "param_type": "int, optional", "param_desc": "For compatibility with NumPy. Only 0 or None are allowed.\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values when showing the result.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.max.html#pandas.Index.max"}, {"function_name": "pandas.Index.rename", "full_function": "Index.rename(name, *, inplace=False)", "function_text": "Alter Index or MultiIndex name.", "parameter_names_desc": [{"param_name": "name", "param_type": "label or list of labels", "param_desc": "Name(s) to set.\n"}, {"param_name": "inplace", "param_type": "bool, default False", "param_desc": "Modifies the object directly, instead of creating a new Index or\nMultiIndex.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.rename.html#pandas.Index.rename"}, {"function_name": "pandas.Index.where", "full_function": "final Index.where(cond, other=None)", "function_text": "Replace values where the condition is False.", "parameter_names_desc": [{"param_name": "cond", "param_type": "bool array-like with the same length as self", "param_desc": "Condition to select the values on.\n"}, {"param_name": "other", "param_type": "scalar, or array-like, default None", "param_desc": "Replacement if the condition is False.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.where.html#pandas.Index.where"}, {"function_name": "pandas.Index.putmask", "full_function": "Index.putmask(mask, value)", "function_text": "Return a new Index of the values set with the mask.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.putmask.html#pandas.Index.putmask"}, {"function_name": "pandas.Index.nunique", "full_function": "Index.nunique(dropna=True)", "function_text": "Return number of unique elements in the object.", "parameter_names_desc": [{"param_name": "dropna", "param_type": "bool, default True", "param_desc": "Don’t include NaN in the count.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.nunique.html#pandas.Index.nunique"}, {"function_name": "pandas.Index.set_names", "full_function": "Index.set_names(names, *, level=None, inplace=False)", "function_text": "Set Index or MultiIndex name.", "parameter_names_desc": [{"param_name": "names", "param_type": "label or list of label or dict-like for MultiIndex", "param_desc": "Name(s) to set.\n\nChanged in version 1.3.0.\n\n"}, {"param_name": "level", "param_type": "int, label or list of int or label, optional", "param_desc": "If the index is a MultiIndex and names is not dict-like, level(s) to set\n(None for all levels). Otherwise level must be None.\n\nChanged in version 1.3.0.\n\n"}, {"param_name": "inplace", "param_type": "bool, default False", "param_desc": "Modifies the object directly, instead of creating a new Index or\nMultiIndex.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.set_names.html#pandas.Index.set_names"}, {"function_name": "pandas.Index.fillna", "full_function": "Index.fillna(value=None, downcast=_NoDefault.no_default)", "function_text": "Fill NA/NaN values with the specified value.", "parameter_names_desc": [{"param_name": "value", "param_type": "scalar", "param_desc": "Scalar value to use to fill holes (e.g. 0).\nThis value cannot be a list-likes.\n"}, {"param_name": "downcast", "param_type": "dict, default is None", "param_desc": "A dict of item->dtype of what to downcast if possible,\nor the string ‘infer’ which will try to downcast to an appropriate\nequal type (e.g. float64 to int64 if possible).\n\nDeprecated since version 2.1.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.fillna.html#pandas.Index.fillna"}, {"function_name": "pandas.Index.isna", "full_function": "final Index.isna()", "function_text": "Detect missing values.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.isna.html#pandas.Index.isna"}, {"function_name": "pandas.Index.astype", "full_function": "Index.astype(dtype, copy=True)", "function_text": "Create an Index with values cast to dtypes.", "parameter_names_desc": [{"param_name": "dtype", "param_type": "numpy dtype or pandas type", "param_desc": "Note that any signed integer dtype is treated as 'int64',\nand any unsigned integer dtype is treated as 'uint64',\nregardless of the size.\n"}, {"param_name": "copy", "param_type": "bool, default True", "param_desc": "By default, astype always returns a newly allocated object.\nIf copy is set to False and internal requirements on dtype are\nsatisfied, the original data is used to create a new Index\nor the original Index is returned.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.astype.html#pandas.Index.astype"}, {"function_name": "pandas.Index.map", "full_function": "Index.map(mapper, na_action=None)", "function_text": "Map values using an input mapping or function.", "parameter_names_desc": [{"param_name": "mapper", "param_type": "function, dict, or Series", "param_desc": "Mapping correspondence.\n"}, {"param_name": "na_action", "param_type": "{None, ‘ignore’}", "param_desc": "If ‘ignore’, propagate NA values, without passing them to the\nmapping correspondence.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.map.html#pandas.Index.map"}, {"function_name": "pandas.Index.to_list", "full_function": "Index.to_list()", "function_text": "Return a list of the values.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.to_list.html#pandas.Index.to_list"}, {"function_name": "pandas.Index.to_frame", "full_function": "Index.to_frame(index=True, name=_NoDefault.no_default)", "function_text": "Create a DataFrame with a column containing the Index.", "parameter_names_desc": [{"param_name": "index", "param_type": "bool, default True", "param_desc": "Set the index of the returned DataFrame as the original Index.\n"}, {"param_name": "name", "param_type": "object, defaults to index.name", "param_desc": "The passed name should substitute for the index name (if it has\none).\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.to_frame.html#pandas.Index.to_frame"}, {"function_name": "pandas.Index.argsort", "full_function": "Index.argsort(*args, **kwargs)", "function_text": "Return the integer indices that would sort the index.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.argsort.html#pandas.Index.argsort"}, {"function_name": "pandas.Index.sort_values", "full_function": "Index.sort_values(*, return_indexer=False, ascending=True, na_position='last', key=None)", "function_text": "Return a sorted copy of the index.", "parameter_names_desc": [{"param_name": "return_indexer", "param_type": "bool, default False", "param_desc": "Should the indices that would sort the index be returned.\n"}, {"param_name": "ascending", "param_type": "bool, default True", "param_desc": "Should the index values be sorted in an ascending order.\n"}, {"param_name": "na_position", "param_type": "{‘first’ or ‘last’}, default ‘last’", "param_desc": "Argument ‘first’ puts NaNs at the beginning, ‘last’ puts NaNs at\nthe end.\n"}, {"param_name": "key", "param_type": "callable, optional", "param_desc": "If not None, apply the key function to the index values\nbefore sorting. This is similar to the key argument in the\nbuiltin sorted() function, with the notable difference that\nthis key function should be vectorized. It should expect an\nIndex and return an Index of the same shape.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.sort_values.html#pandas.Index.sort_values"}, {"function_name": "pandas.Index.shift", "full_function": "Index.shift(periods=1, freq=None)", "function_text": "Shift index by desired number of time frequency increments.", "parameter_names_desc": [{"param_name": "periods", "param_type": "int, default 1", "param_desc": "Number of periods (or increments) to shift by,\ncan be positive or negative.\n"}, {"param_name": "freq", "param_type": "pandas.DateOffset, pandas.Timedelta or str, optional", "param_desc": "Frequency increment to shift by.\nIf None, the index is shifted by its own freq attribute.\nOffset aliases are valid strings, e.g., ‘D’, ‘W’, ‘M’ etc.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.shift.html#pandas.Index.shift"}, {"function_name": "pandas.Index.append", "full_function": "Index.append(other)", "function_text": "Append a collection of Index options together.", "parameter_names_desc": [{"param_name": "other", "param_type": "Index or list/tuple of indices", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.append.html#pandas.Index.append"}, {"function_name": "pandas.Index.intersection", "full_function": "final Index.intersection(other, sort=False)", "function_text": "Form the intersection of two Index objects.", "parameter_names_desc": [{"param_name": "other", "param_type": "Index or array-like", "param_desc": ""}, {"param_name": "sort", "param_type": "True, False or None, default False", "param_desc": "Whether to sort the resulting index.\n\nNone : sort the result, except when self and other are equal\nor when the values cannot be compared.\nFalse : do not sort the result.\nTrue : Sort the result (which may raise TypeError).\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.intersection.html#pandas.Index.intersection"}, {"function_name": "pandas.Index.difference", "full_function": "final Index.difference(other, sort=None)", "function_text": "Return a new Index with elements of index not in other.", "parameter_names_desc": [{"param_name": "other", "param_type": "Index or array-like", "param_desc": ""}, {"param_name": "sort", "param_type": "bool or None, default None", "param_desc": "Whether to sort the resulting index. By default, the\nvalues are attempted to be sorted, but any TypeError from\nincomparable elements is caught by pandas.\n\nNone : Attempt to sort the result, but catch any TypeErrors\nfrom comparing incomparable elements.\nFalse : Do not sort the result.\nTrue : Sort the result (which may raise TypeError).\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.difference.html#pandas.Index.difference"}, {"function_name": "pandas.Index.asof", "full_function": "final Index.asof(label)", "function_text": "Return the label from the index, or, if not present, the previous one.", "parameter_names_desc": [{"param_name": "label", "param_type": "object", "param_desc": "The label up to which the method returns the latest index label.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.asof.html#pandas.Index.asof"}, {"function_name": "pandas.Index.get_indexer", "full_function": "final Index.get_indexer(target, method=None, limit=None, tolerance=None)", "function_text": "Compute indexer and mask for new index given the current index.", "parameter_names_desc": [{"param_name": "target", "param_type": "Index", "param_desc": ""}, {"param_name": "method", "param_type": "{None, ‘pad’/’ffill’, ‘backfill’/’bfill’, ‘nearest’}, optional", "param_desc": "\ndefault: exact matches only.\npad / ffill: find the PREVIOUS index value if no exact match.\nbackfill / bfill: use NEXT index value if no exact match\nnearest: use the NEAREST index value if no exact match. Tied\ndistances are broken by preferring the larger index value.\n\n"}, {"param_name": "limit", "param_type": "int, optional", "param_desc": "Maximum number of consecutive labels in target to match for\ninexact matches.\n"}, {"param_name": "tolerance", "param_type": "optional", "param_desc": "Maximum distance between original and new labels for inexact\nmatches. The values of the index at the matching locations must\nsatisfy the equation abs(index[indexer] - target) <= tolerance.\nTolerance may be a scalar value, which applies the same tolerance\nto all values, or list-like, which applies variable tolerance per\nelement. List-like includes list, tuple, array, Series, and must be\nthe same size as the index and its dtype must exactly match the\nindex’s type.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.get_indexer.html#pandas.Index.get_indexer"}, {"function_name": "pandas.Index.get_indexer_non_unique", "full_function": "Index.get_indexer_non_unique(target)", "function_text": "Compute indexer and mask for new index given the current index.", "parameter_names_desc": [{"param_name": "target", "param_type": "Index", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.get_indexer_non_unique.html#pandas.Index.get_indexer_non_unique"}, {"function_name": "pandas.Index.get_loc", "full_function": "Index.get_loc(key)", "function_text": "Get integer location, slice or boolean mask for requested label.", "parameter_names_desc": [{"param_name": "key", "param_type": "label", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.get_loc.html#pandas.Index.get_loc"}, {"function_name": "pandas.Index.isin", "full_function": "Index.isin(values, level=None)", "function_text": "Return a boolean array where the index values are in values.", "parameter_names_desc": [{"param_name": "values", "param_type": "set or list-like", "param_desc": "Sought values.\n"}, {"param_name": "level", "param_type": "str or int, optional", "param_desc": "Name or position of the index level to use (if the index is a\nMultiIndex).\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.isin.html#pandas.Index.isin"}, {"function_name": "pandas.Index.slice_locs", "full_function": "Index.slice_locs(start=None, end=None, step=None)", "function_text": "Compute slice locations for input labels.", "parameter_names_desc": [{"param_name": "start", "param_type": "label, default None", "param_desc": "If None, defaults to the beginning.\n"}, {"param_name": "end", "param_type": "label, default None", "param_desc": "If None, defaults to the end.\n"}, {"param_name": "step", "param_type": "int, defaults None", "param_desc": "If None, defaults to 1.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.slice_locs.html#pandas.Index.slice_locs"}, {"function_name": "pandas.Index.is_monotonic_increasing", "full_function": "property Index.is_monotonic_increasing", "function_text": "Return a boolean if the values are equal or increasing.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.is_monotonic_increasing.html#pandas.Index.is_monotonic_increasing"}, {"function_name": "pandas.Index.is_unique", "full_function": "Index.is_unique", "function_text": "Return if the index has unique values.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.is_unique.html#pandas.Index.is_unique"}, {"function_name": "pandas.Index.hasnans", "full_function": "Index.hasnans", "function_text": "Return True if there are any NaNs.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.hasnans.html#pandas.Index.hasnans"}, {"function_name": "pandas.Index.inferred_type", "full_function": "Index.inferred_type", "function_text": "Return a string of the type inferred from the values.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.inferred_type.html#pandas.Index.inferred_type"}, {"function_name": "pandas.Index.name", "full_function": "property Index.name", "function_text": "Return Index or MultiIndex name.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.name.html#pandas.Index.name"}, {"function_name": "pandas.Index.nbytes", "full_function": "property Index.nbytes", "function_text": "Return the number of bytes in the underlying data.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.nbytes.html#pandas.Index.nbytes"}, {"function_name": "pandas.Index.size", "full_function": "property Index.size", "function_text": "Return the number of elements in the underlying data.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.size.html#pandas.Index.size"}, {"function_name": "pandas.Index.T", "full_function": "property Index.T", "function_text": "Return the transpose, which is by definition self.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.T.html#pandas.Index.T"}, {"function_name": "pandas.Index.any", "full_function": "Index.any(*args, **kwargs)", "function_text": "Return whether any element is Truthy.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.any.html#pandas.Index.any"}, {"function_name": "pandas.Index.argmax", "full_function": "Index.argmax(axis=None, skipna=True, *args, **kwargs)", "function_text": "Return int position of the largest value in the Series.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{None}", "param_desc": "Unused. Parameter needed for compatibility with DataFrame.\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values when showing the result.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.argmax.html#pandas.Index.argmax"}, {"function_name": "pandas.Index.delete", "full_function": "Index.delete(loc)", "function_text": "Make new Index with passed location(-s) deleted.", "parameter_names_desc": [{"param_name": "loc", "param_type": "int or list of int", "param_desc": "Location of item(-s) which will be deleted.\nUse a list of locations to delete more than one value at the same time.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.delete.html#pandas.Index.delete"}, {"function_name": "pandas.Index.drop_duplicates", "full_function": "Index.drop_duplicates(*, keep='first')", "function_text": "Return Index with duplicate values removed.", "parameter_names_desc": [{"param_name": "keep", "param_type": "{‘first’, ‘last’, False}, default ‘first’", "param_desc": "\n‘first’ : Drop duplicates except for the first occurrence.\n‘last’ : Drop duplicates except for the last occurrence.\nFalse : Drop all duplicates.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.drop_duplicates.html#pandas.Index.drop_duplicates"}, {"function_name": "pandas.Index.equals", "full_function": "Index.equals(other)", "function_text": "Determine if two Index object are equal.", "parameter_names_desc": [{"param_name": "other", "param_type": "Any", "param_desc": "The other object to compare against.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.equals.html#pandas.Index.equals"}, {"function_name": "pandas.Index.identical", "full_function": "final Index.identical(other)", "function_text": "Similar to equals, but checks that object attributes and types are also equal.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.identical.html#pandas.Index.identical"}, {"function_name": "pandas.Index.is_", "full_function": "final Index.is_(other)", "function_text": "More flexible, faster check like is but that works through views.", "parameter_names_desc": [{"param_name": "other", "param_type": "object", "param_desc": "Other object to compare against.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.is_.html#pandas.Index.is_"}, {"function_name": "pandas.Index.is_categorical", "full_function": "final Index.is_categorical()", "function_text": "Check if the Index holds categorical data.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.is_categorical.html#pandas.Index.is_categorical"}, {"function_name": "pandas.Index.is_integer", "full_function": "final Index.is_integer()", "function_text": "Check if the Index only consists of integers.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.is_integer.html#pandas.Index.is_integer"}, {"function_name": "pandas.Index.is_numeric", "full_function": "final Index.is_numeric()", "function_text": "Check if the Index only consists of numeric data.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.is_numeric.html#pandas.Index.is_numeric"}, {"function_name": "pandas.Index.min", "full_function": "Index.min(axis=None, skipna=True, *args, **kwargs)", "function_text": "Return the minimum value of the Index.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{None}", "param_desc": "Dummy argument for consistency with Series.\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values when showing the result.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.min.html#pandas.Index.min"}, {"function_name": "pandas.Index.reindex", "full_function": "Index.reindex(target, method=None, level=None, limit=None, tolerance=None)", "function_text": "Create index with target’s values.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.reindex.html#pandas.Index.reindex"}, {"function_name": "pandas.Index.repeat", "full_function": "Index.repeat(repeats, axis=None)", "function_text": "Repeat elements of a Index.", "parameter_names_desc": [{"param_name": "repeats", "param_type": "int or array of ints", "param_desc": "The number of repetitions for each element. This should be a\nnon-negative integer. Repeating 0 times will return an empty\nIndex.\n"}, {"param_name": "axis", "param_type": "None", "param_desc": "Must be None. Has no effect but is accepted for compatibility\nwith numpy.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.repeat.html#pandas.Index.repeat"}, {"function_name": "pandas.Index.take", "full_function": "Index.take(indices, axis=0, allow_fill=True, fill_value=None, **kwargs)", "function_text": "Return a new Index of the values selected by the indices.", "parameter_names_desc": [{"param_name": "indices", "param_type": "array-like", "param_desc": "Indices to be taken.\n"}, {"param_name": "axis", "param_type": "int, optional", "param_desc": "The axis over which to select values, always 0.\n"}, {"param_name": "allow_fill", "param_type": "bool, default True", "param_desc": ""}, {"param_name": "fill_value", "param_type": "scalar, default None", "param_desc": "If allow_fill=True and fill_value is not None, indices specified by\n-1 are regarded as NA. If Index doesn’t hold NA, raise ValueError.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.take.html#pandas.Index.take"}, {"function_name": "pandas.Index.unique", "full_function": "Index.unique(level=None)", "function_text": "Return unique values in the index.", "parameter_names_desc": [{"param_name": "level", "param_type": "int or hashable, optional", "param_desc": "Only return values from specified level (for MultiIndex).\nIf int, gets the level by integer position, else by level name.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.unique.html#pandas.Index.unique"}, {"function_name": "pandas.Index.value_counts", "full_function": "Index.value_counts(normalize=False, sort=True, ascending=False, bins=None, dropna=True)", "function_text": "Return a Series containing counts of unique values.", "parameter_names_desc": [{"param_name": "normalize", "param_type": "bool, default False", "param_desc": "If True then the object returned will contain the relative\nfrequencies of the unique values.\n"}, {"param_name": "sort", "param_type": "bool, default True", "param_desc": "Sort by frequencies when True. Preserve the order of the data when False.\n"}, {"param_name": "ascending", "param_type": "bool, default False", "param_desc": "Sort in ascending order.\n"}, {"param_name": "bins", "param_type": "int, optional", "param_desc": "Rather than count values, group them into half-open bins,\na convenience for pd.cut, only works with numeric data.\n"}, {"param_name": "dropna", "param_type": "bool, default True", "param_desc": "Don’t include counts of NaN.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.value_counts.html#pandas.Index.value_counts"}, {"function_name": "pandas.Index.droplevel", "full_function": "final Index.droplevel(level=0)", "function_text": "Return index with requested level(s) removed.", "parameter_names_desc": [{"param_name": "level", "param_type": "int, str, or list-like, default 0", "param_desc": "If a string is given, must be the name of a level\nIf list-like, elements must be names or indexes of levels.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.droplevel.html#pandas.Index.droplevel"}, {"function_name": "pandas.Index.dropna", "full_function": "Index.dropna(how='any')", "function_text": "Return Index without NA/NaN values.", "parameter_names_desc": [{"param_name": "how", "param_type": "{‘any’, ‘all’}, default ‘any’", "param_desc": "If the Index is a MultiIndex, drop the value when any or all levels\nare NaN.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.dropna.html#pandas.Index.dropna"}, {"function_name": "pandas.Index.notna", "full_function": "final Index.notna()", "function_text": "Detect existing (non-missing) values.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.notna.html#pandas.Index.notna"}, {"function_name": "pandas.Index.item", "full_function": "Index.item()", "function_text": "Return the first element of the underlying data as a Python scalar.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.item.html#pandas.Index.item"}, {"function_name": "pandas.Index.ravel", "full_function": "final Index.ravel(order='C')", "function_text": "Return a view on self.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.ravel.html#pandas.Index.ravel"}, {"function_name": "pandas.Index.to_series", "full_function": "final Index.to_series(index=None, name=None)", "function_text": "Create a Series with both index and values equal to the index keys.", "parameter_names_desc": [{"param_name": "index", "param_type": "Index, optional", "param_desc": "Index of resulting Series. If None, defaults to original index.\n"}, {"param_name": "name", "param_type": "str, optional", "param_desc": "Name of resulting Series. If None, defaults to name of original\nindex.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.to_series.html#pandas.Index.to_series"}, {"function_name": "pandas.Index.to_series", "full_function": "final Index.to_series(index=None, name=None)", "function_text": "Create a Series with both index and values equal to the index keys.", "parameter_names_desc": [{"param_name": "index", "param_type": "Index, optional", "param_desc": "Index of resulting Series. If None, defaults to original index.\n"}, {"param_name": "name", "param_type": "str, optional", "param_desc": "Name of resulting Series. If None, defaults to name of original\nindex.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.to_series.html#pandas.Index.to_series"}, {"function_name": "pandas.Index.searchsorted", "full_function": "Index.searchsorted(value, side='left', sorter=None)", "function_text": "Find indices where elements should be inserted to maintain order.", "parameter_names_desc": [{"param_name": "value", "param_type": "array-like or scalar", "param_desc": "Values to insert into self.\n"}, {"param_name": "side", "param_type": "{‘left’, ‘right’}, optional", "param_desc": "If ‘left’, the index of the first suitable location found is given.\nIf ‘right’, return the last such index. If there is no suitable\nindex, return either 0 or N (where N is the length of self).\n"}, {"param_name": "sorter", "param_type": "1-D array-like, optional", "param_desc": "Optional array of integer indices that sort self into ascending\norder. They are typically the result of np.argsort.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.searchsorted.html#pandas.Index.searchsorted"}, {"function_name": "pandas.Index.join", "full_function": "final Index.join(other, *, how='left', level=None, return_indexers=False, sort=False)", "function_text": "Compute join_index and indexers to conform data structures to the new index.", "parameter_names_desc": [{"param_name": "other", "param_type": "Index", "param_desc": ""}, {"param_name": "how", "param_type": "{‘left’, ‘right’, ‘inner’, ‘outer’}", "param_desc": ""}, {"param_name": "level", "param_type": "int or level name, default None", "param_desc": ""}, {"param_name": "return_indexers", "param_type": "bool, default False", "param_desc": ""}, {"param_name": "sort", "param_type": "bool, default False", "param_desc": "Sort the join keys lexicographically in the result Index. If False,\nthe order of the join keys depends on the join type (how keyword).\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.join.html#pandas.Index.join"}, {"function_name": "pandas.Index.union", "full_function": "final Index.union(other, sort=None)", "function_text": "Form the union of two Index objects.", "parameter_names_desc": [{"param_name": "other", "param_type": "Index or array-like", "param_desc": ""}, {"param_name": "sort", "param_type": "bool or None, default None", "param_desc": "Whether to sort the resulting Index.\n\nNone : Sort the result, except when\n\nself and other are equal.\nself or other has length 0.\nSome values in self or other cannot be compared.\nA RuntimeWarning is issued in this case.\n\n\nFalse : do not sort the result.\nTrue : Sort the result (which may raise TypeError).\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.union.html#pandas.Index.union"}, {"function_name": "pandas.Index.symmetric_difference", "full_function": "Index.symmetric_difference(other, result_name=None, sort=None)", "function_text": "Compute the symmetric difference of two Index objects.", "parameter_names_desc": [{"param_name": "other", "param_type": "Index or array-like", "param_desc": ""}, {"param_name": "result_name", "param_type": "str", "param_desc": ""}, {"param_name": "sort", "param_type": "bool or None, default None", "param_desc": "Whether to sort the resulting index. By default, the\nvalues are attempted to be sorted, but any TypeError from\nincomparable elements is caught by pandas.\n\nNone : Attempt to sort the result, but catch any TypeErrors\nfrom comparing incomparable elements.\nFalse : Do not sort the result.\nTrue : Sort the result (which may raise TypeError).\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.symmetric_difference.html#pandas.Index.symmetric_difference"}, {"function_name": "pandas.Index.asof_locs", "full_function": "Index.asof_locs(where, mask)", "function_text": "Return the locations (indices) of labels in the index.", "parameter_names_desc": [{"param_name": "where", "param_type": "Index", "param_desc": "An Index consisting of an array of timestamps.\n"}, {"param_name": "mask", "param_type": "np.ndarray[bool]", "param_desc": "Array of booleans denoting where values in the original\ndata are not NA.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.asof_locs.html#pandas.Index.asof_locs"}, {"function_name": "pandas.Index.get_indexer_for", "full_function": "final Index.get_indexer_for(target)", "function_text": "Guaranteed return of an indexer even when non-unique.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.get_indexer_for.html#pandas.Index.get_indexer_for"}, {"function_name": "pandas.Index.get_level_values", "full_function": "Index.get_level_values(level)", "function_text": "Return an Index of values for requested level.", "parameter_names_desc": [{"param_name": "level", "param_type": "int or str", "param_desc": "It is either the integer position or the name of the level.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.get_level_values.html#pandas.Index.get_level_values"}, {"function_name": "pandas.Index.get_slice_bound", "full_function": "Index.get_slice_bound(label, side)", "function_text": "Calculate slice bound that corresponds to given label.", "parameter_names_desc": [{"param_name": "label", "param_type": "object", "param_desc": ""}, {"param_name": "side", "param_type": "{‘left’, ‘right’}", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.get_slice_bound.html#pandas.Index.get_slice_bound"}, {"function_name": "pandas.Index.slice_indexer", "full_function": "Index.slice_indexer(start=None, end=None, step=None)", "function_text": "Compute the slice indexer for input labels and step.", "parameter_names_desc": [{"param_name": "KeyError", "param_type": "If key does not exist, or key is not unique and index is", "param_desc": "not ordered.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Index.slice_indexer.html#pandas.Index.slice_indexer"}]}, {"name": "Numeric Index", "url": "https://pandas.pydata.org/docs/reference/indexing.html#numeric-index", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.RangeIndex.html#pandas.RangeIndex", "https://pandas.pydata.org/docs/reference/api/pandas.RangeIndex.start.html#pandas.RangeIndex.start", "https://pandas.pydata.org/docs/reference/api/pandas.RangeIndex.step.html#pandas.RangeIndex.step", "https://pandas.pydata.org/docs/reference/api/pandas.RangeIndex.stop.html#pandas.RangeIndex.stop", "https://pandas.pydata.org/docs/reference/api/pandas.RangeIndex.from_range.html#pandas.RangeIndex.from_range"], "function_definitions": [{"function_name": "pandas.RangeIndex", "full_function": "class pandas.RangeIndex(start=None, stop=None, step=None, dtype=None, copy=False, name=None)", "function_text": "Immutable Index implementing a monotonic integer range.", "parameter_names_desc": [{"param_name": "start", "param_type": "int (default: 0), range, or other RangeIndex instance", "param_desc": "If int and “stop” is not given, interpreted as “stop” instead.\n"}, {"param_name": "stop", "param_type": "int (default: 0)", "param_desc": ""}, {"param_name": "step", "param_type": "int (default: 1)", "param_desc": ""}, {"param_name": "dtype", "param_type": "np.int64", "param_desc": "Unused, accepted for homogeneity with other index types.\n"}, {"param_name": "copy", "param_type": "bool, default False", "param_desc": "Unused, accepted for homogeneity with other index types.\n"}, {"param_name": "name", "param_type": "object, optional", "param_desc": "Name to be stored in the index.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.RangeIndex.html#pandas.RangeIndex"}, {"function_name": "pandas.RangeIndex.start", "full_function": "property RangeIndex.start", "function_text": "The value of the start parameter (0 if this was not supplied).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.RangeIndex.start.html#pandas.RangeIndex.start"}, {"function_name": "pandas.RangeIndex.step", "full_function": "property RangeIndex.step", "function_text": "The value of the step parameter (1 if this was not supplied).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.RangeIndex.step.html#pandas.RangeIndex.step"}, {"function_name": "pandas.RangeIndex.stop", "full_function": "property RangeIndex.stop", "function_text": "The value of the stop parameter.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.RangeIndex.stop.html#pandas.RangeIndex.stop"}, {"function_name": "pandas.RangeIndex.from_range", "full_function": "classmethod RangeIndex.from_range(data, name=None, dtype=None)", "function_text": "Create pandas.RangeIndex from a range object.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.RangeIndex.from_range.html#pandas.RangeIndex.from_range"}]}, {"name": "CategoricalIndex", "url": "https://pandas.pydata.org/docs/reference/indexing.html#categoricalindex", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.html#pandas.CategoricalIndex", "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.codes.html#pandas.CategoricalIndex.codes", "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.ordered.html#pandas.CategoricalIndex.ordered", "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.reorder_categories.html#pandas.CategoricalIndex.reorder_categories", "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.remove_categories.html#pandas.CategoricalIndex.remove_categories", "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.set_categories.html#pandas.CategoricalIndex.set_categories", "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.as_unordered.html#pandas.CategoricalIndex.as_unordered", "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.map.html#pandas.CategoricalIndex.map", "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.categories.html#pandas.CategoricalIndex.categories", "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.rename_categories.html#pandas.CategoricalIndex.rename_categories", "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.add_categories.html#pandas.CategoricalIndex.add_categories", "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.remove_unused_categories.html#pandas.CategoricalIndex.remove_unused_categories", "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.as_ordered.html#pandas.CategoricalIndex.as_ordered", "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.equals.html#pandas.CategoricalIndex.equals"], "function_definitions": [{"function_name": "pandas.CategoricalIndex", "full_function": "class pandas.CategoricalIndex(data=None, categories=None, ordered=None, dtype=None, copy=False, name=None)", "function_text": "Index based on an underlying Categorical.", "parameter_names_desc": [{"param_name": "data", "param_type": "array-like (1-dimensional)", "param_desc": "The values of the categorical. If categories are given, values not in\ncategories will be replaced with NaN.\n"}, {"param_name": "categories", "param_type": "index-like, optional", "param_desc": "The categories for the categorical. Items need to be unique.\nIf the categories are not given here (and also not in dtype), they\nwill be inferred from the data.\n"}, {"param_name": "ordered", "param_type": "bool, optional", "param_desc": "Whether or not this categorical is treated as an ordered\ncategorical. If not given here or in dtype, the resulting\ncategorical will be unordered.\n"}, {"param_name": "dtype", "param_type": "CategoricalDtype or “category”, optional", "param_desc": "If CategoricalDtype, cannot be used together with\ncategories or ordered.\n"}, {"param_name": "copy", "param_type": "bool, default False", "param_desc": "Make a copy of input ndarray.\n"}, {"param_name": "name", "param_type": "object, optional", "param_desc": "Name to be stored in the index.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.html#pandas.CategoricalIndex"}, {"function_name": "pandas.CategoricalIndex.codes", "full_function": "property CategoricalIndex.codes", "function_text": "The category codes of this categorical index.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.codes.html#pandas.CategoricalIndex.codes"}, {"function_name": "pandas.CategoricalIndex.ordered", "full_function": "property CategoricalIndex.ordered", "function_text": "Whether the categories have an ordered relationship.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.ordered.html#pandas.CategoricalIndex.ordered"}, {"function_name": "pandas.CategoricalIndex.reorder_categories", "full_function": "CategoricalIndex.reorder_categories(*args, **kwargs)", "function_text": "Reorder categories as specified in new_categories.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.reorder_categories.html#pandas.CategoricalIndex.reorder_categories"}, {"function_name": "pandas.CategoricalIndex.remove_categories", "full_function": "CategoricalIndex.remove_categories(*args, **kwargs)", "function_text": "Remove the specified categories.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.remove_categories.html#pandas.CategoricalIndex.remove_categories"}, {"function_name": "pandas.CategoricalIndex.set_categories", "full_function": "CategoricalIndex.set_categories(*args, **kwargs)", "function_text": "Set the categories to the specified new categories.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.set_categories.html#pandas.CategoricalIndex.set_categories"}, {"function_name": "pandas.CategoricalIndex.as_unordered", "full_function": "CategoricalIndex.as_unordered(*args, **kwargs)", "function_text": "Set the Categorical to be unordered.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.as_unordered.html#pandas.CategoricalIndex.as_unordered"}, {"function_name": "pandas.CategoricalIndex.map", "full_function": "CategoricalIndex.map(mapper, na_action=None)", "function_text": "Map values using input an input mapping or function.", "parameter_names_desc": [{"param_name": "mapper", "param_type": "function, dict, or Series", "param_desc": "Mapping correspondence.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.map.html#pandas.CategoricalIndex.map"}, {"function_name": "pandas.CategoricalIndex.categories", "full_function": "property CategoricalIndex.categories", "function_text": "The categories of this categorical.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.categories.html#pandas.CategoricalIndex.categories"}, {"function_name": "pandas.CategoricalIndex.rename_categories", "full_function": "CategoricalIndex.rename_categories(*args, **kwargs)", "function_text": "Rename categories.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.rename_categories.html#pandas.CategoricalIndex.rename_categories"}, {"function_name": "pandas.CategoricalIndex.add_categories", "full_function": "CategoricalIndex.add_categories(*args, **kwargs)", "function_text": "Add new categories.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.add_categories.html#pandas.CategoricalIndex.add_categories"}, {"function_name": "pandas.CategoricalIndex.remove_unused_categories", "full_function": "CategoricalIndex.remove_unused_categories(*args, **kwargs)", "function_text": "Remove categories which are not used.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.remove_unused_categories.html#pandas.CategoricalIndex.remove_unused_categories"}, {"function_name": "pandas.CategoricalIndex.as_ordered", "full_function": "CategoricalIndex.as_ordered(*args, **kwargs)", "function_text": "Set the Categorical to be ordered.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.as_ordered.html#pandas.CategoricalIndex.as_ordered"}, {"function_name": "pandas.CategoricalIndex.equals", "full_function": "CategoricalIndex.equals(other)", "function_text": "Determine if two CategoricalIndex objects contain the same elements.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.CategoricalIndex.equals.html#pandas.CategoricalIndex.equals"}]}, {"name": "IntervalIndex", "url": "https://pandas.pydata.org/docs/reference/indexing.html#intervalindex", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.html#pandas.IntervalIndex", "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.from_arrays.html#pandas.IntervalIndex.from_arrays", "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.from_breaks.html#pandas.IntervalIndex.from_breaks", "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.right.html#pandas.IntervalIndex.right", "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.closed.html#pandas.IntervalIndex.closed", "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.values.html#pandas.IntervalIndex.values", "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.is_non_overlapping_monotonic.html#pandas.IntervalIndex.is_non_overlapping_monotonic", "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.get_loc.html#pandas.IntervalIndex.get_loc", "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.set_closed.html#pandas.IntervalIndex.set_closed", "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.overlaps.html#pandas.IntervalIndex.overlaps", "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.from_tuples.html#pandas.IntervalIndex.from_tuples", "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.left.html#pandas.IntervalIndex.left", "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.mid.html#pandas.IntervalIndex.mid", "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.length.html#pandas.IntervalIndex.length", "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.is_empty.html#pandas.IntervalIndex.is_empty", "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.is_overlapping.html#pandas.IntervalIndex.is_overlapping", "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.get_indexer.html#pandas.IntervalIndex.get_indexer", "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.contains.html#pandas.IntervalIndex.contains", "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.to_tuples.html#pandas.IntervalIndex.to_tuples"], "function_definitions": [{"function_name": "pandas.IntervalIndex", "full_function": "class pandas.IntervalIndex(data, closed=None, dtype=None, copy=False, name=None, verify_integrity=True)", "function_text": "Immutable index of intervals that are closed on the same side.", "parameter_names_desc": [{"param_name": "data", "param_type": "array-like (1-dimensional)", "param_desc": "Array-like (ndarray, DateTimeArray, TimeDeltaArray) containing\nInterval objects from which to build the IntervalIndex.\n"}, {"param_name": "closed", "param_type": "{‘left’, ‘right’, ‘both’, ‘neither’}, default ‘right’", "param_desc": "Whether the intervals are closed on the left-side, right-side, both or\nneither.\n"}, {"param_name": "dtype", "param_type": "dtype or None, default None", "param_desc": "If None, dtype will be inferred.\n"}, {"param_name": "copy", "param_type": "bool, default False", "param_desc": "Copy the input data.\n"}, {"param_name": "name", "param_type": "object, optional", "param_desc": "Name to be stored in the index.\n"}, {"param_name": "verify_integrity", "param_type": "bool, default True", "param_desc": "Verify that the IntervalIndex is valid.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.html#pandas.IntervalIndex"}, {"function_name": "pandas.IntervalIndex.from_arrays", "full_function": "classmethod IntervalIndex.from_arrays(left, right, closed='right', name=None, copy=False, dtype=None)", "function_text": "Construct from two arrays defining the left and right bounds.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.from_arrays.html#pandas.IntervalIndex.from_arrays"}, {"function_name": "pandas.IntervalIndex.from_breaks", "full_function": "classmethod IntervalIndex.from_breaks(breaks, closed='right', name=None, copy=False, dtype=None)", "function_text": "Construct an IntervalIndex from an array of splits.", "parameter_names_desc": [{"param_name": "breaks", "param_type": "array-like (1-dimensional)", "param_desc": "Left and right bounds for each interval.\n"}, {"param_name": "closed", "param_type": "{‘left’, ‘right’, ‘both’, ‘neither’}, default ‘right’", "param_desc": "Whether the intervals are closed on the left-side, right-side, both\nor neither.\n"}, {"param_name": "name", "param_type": "str, optional", "param_desc": "Name of the resulting IntervalIndex.\n"}, {"param_name": "copy", "param_type": "bool, default False", "param_desc": "Copy the data.\n"}, {"param_name": "dtype", "param_type": "dtype or None, default None", "param_desc": "If None, dtype will be inferred.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.from_breaks.html#pandas.IntervalIndex.from_breaks"}, {"function_name": "pandas.IntervalIndex.from_breaks", "full_function": "classmethod IntervalIndex.from_breaks(breaks, closed='right', name=None, copy=False, dtype=None)", "function_text": "Construct an IntervalIndex from an array of splits.", "parameter_names_desc": [{"param_name": "breaks", "param_type": "array-like (1-dimensional)", "param_desc": "Left and right bounds for each interval.\n"}, {"param_name": "closed", "param_type": "{‘left’, ‘right’, ‘both’, ‘neither’}, default ‘right’", "param_desc": "Whether the intervals are closed on the left-side, right-side, both\nor neither.\n"}, {"param_name": "name", "param_type": "str, optional", "param_desc": "Name of the resulting IntervalIndex.\n"}, {"param_name": "copy", "param_type": "bool, default False", "param_desc": "Copy the data.\n"}, {"param_name": "dtype", "param_type": "dtype or None, default None", "param_desc": "If None, dtype will be inferred.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.from_breaks.html#pandas.IntervalIndex.from_breaks"}, {"function_name": "pandas.IntervalIndex.closed", "full_function": "IntervalIndex.closed", "function_text": "String describing the inclusive side the intervals.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.closed.html#pandas.IntervalIndex.closed"}, {"function_name": "pandas.IntervalIndex.values", "full_function": "property IntervalIndex.values", "function_text": "Return an array representing the data in the Index.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.values.html#pandas.IntervalIndex.values"}, {"function_name": "pandas.IntervalIndex.is_non_overlapping_monotonic", "full_function": "IntervalIndex.is_non_overlapping_monotonic", "function_text": "Return a boolean whether the IntervalArray is non-overlapping and monotonic.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.is_non_overlapping_monotonic.html#pandas.IntervalIndex.is_non_overlapping_monotonic"}, {"function_name": "pandas.IntervalIndex.get_loc", "full_function": "IntervalIndex.get_loc(key)", "function_text": "Get integer location, slice or boolean mask for requested label.", "parameter_names_desc": [{"param_name": "key", "param_type": "label", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.get_loc.html#pandas.IntervalIndex.get_loc"}, {"function_name": "pandas.IntervalIndex.set_closed", "full_function": "IntervalIndex.set_closed(*args, **kwargs)", "function_text": "Return an identical IntervalArray closed on the specified side.", "parameter_names_desc": [{"param_name": "closed", "param_type": "{‘left’, ‘right’, ‘both’, ‘neither’}", "param_desc": "Whether the intervals are closed on the left-side, right-side, both\nor neither.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.set_closed.html#pandas.IntervalIndex.set_closed"}, {"function_name": "pandas.IntervalIndex.overlaps", "full_function": "IntervalIndex.overlaps(*args, **kwargs)", "function_text": "Check elementwise if an Interval overlaps the values in the IntervalArray.", "parameter_names_desc": [{"param_name": "other", "param_type": "IntervalArray", "param_desc": "Interval to check against for an overlap.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.overlaps.html#pandas.IntervalIndex.overlaps"}, {"function_name": "pandas.IntervalIndex.from_tuples", "full_function": "classmethod IntervalIndex.from_tuples(data, closed='right', name=None, copy=False, dtype=None)", "function_text": "Construct an IntervalIndex from an array-like of tuples.", "parameter_names_desc": [{"param_name": "data", "param_type": "array-like (1-dimensional)", "param_desc": "Array of tuples.\n"}, {"param_name": "closed", "param_type": "{‘left’, ‘right’, ‘both’, ‘neither’}, default ‘right’", "param_desc": "Whether the intervals are closed on the left-side, right-side, both\nor neither.\n"}, {"param_name": "name", "param_type": "str, optional", "param_desc": "Name of the resulting IntervalIndex.\n"}, {"param_name": "copy", "param_type": "bool, default False", "param_desc": "By-default copy the data, this is compat only and ignored.\n"}, {"param_name": "dtype", "param_type": "dtype or None, default None", "param_desc": "If None, dtype will be inferred.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.from_tuples.html#pandas.IntervalIndex.from_tuples"}, {"function_name": "pandas.IntervalIndex.from_tuples", "full_function": "classmethod IntervalIndex.from_tuples(data, closed='right', name=None, copy=False, dtype=None)", "function_text": "Construct an IntervalIndex from an array-like of tuples.", "parameter_names_desc": [{"param_name": "data", "param_type": "array-like (1-dimensional)", "param_desc": "Array of tuples.\n"}, {"param_name": "closed", "param_type": "{‘left’, ‘right’, ‘both’, ‘neither’}, default ‘right’", "param_desc": "Whether the intervals are closed on the left-side, right-side, both\nor neither.\n"}, {"param_name": "name", "param_type": "str, optional", "param_desc": "Name of the resulting IntervalIndex.\n"}, {"param_name": "copy", "param_type": "bool, default False", "param_desc": "By-default copy the data, this is compat only and ignored.\n"}, {"param_name": "dtype", "param_type": "dtype or None, default None", "param_desc": "If None, dtype will be inferred.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.from_tuples.html#pandas.IntervalIndex.from_tuples"}, {"function_name": "pandas.IntervalIndex.from_tuples", "full_function": "classmethod IntervalIndex.from_tuples(data, closed='right', name=None, copy=False, dtype=None)", "function_text": "Construct an IntervalIndex from an array-like of tuples.", "parameter_names_desc": [{"param_name": "data", "param_type": "array-like (1-dimensional)", "param_desc": "Array of tuples.\n"}, {"param_name": "closed", "param_type": "{‘left’, ‘right’, ‘both’, ‘neither’}, default ‘right’", "param_desc": "Whether the intervals are closed on the left-side, right-side, both\nor neither.\n"}, {"param_name": "name", "param_type": "str, optional", "param_desc": "Name of the resulting IntervalIndex.\n"}, {"param_name": "copy", "param_type": "bool, default False", "param_desc": "By-default copy the data, this is compat only and ignored.\n"}, {"param_name": "dtype", "param_type": "dtype or None, default None", "param_desc": "If None, dtype will be inferred.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.from_tuples.html#pandas.IntervalIndex.from_tuples"}, {"function_name": "pandas.IntervalIndex.from_tuples", "full_function": "classmethod IntervalIndex.from_tuples(data, closed='right', name=None, copy=False, dtype=None)", "function_text": "Construct an IntervalIndex from an array-like of tuples.", "parameter_names_desc": [{"param_name": "data", "param_type": "array-like (1-dimensional)", "param_desc": "Array of tuples.\n"}, {"param_name": "closed", "param_type": "{‘left’, ‘right’, ‘both’, ‘neither’}, default ‘right’", "param_desc": "Whether the intervals are closed on the left-side, right-side, both\nor neither.\n"}, {"param_name": "name", "param_type": "str, optional", "param_desc": "Name of the resulting IntervalIndex.\n"}, {"param_name": "copy", "param_type": "bool, default False", "param_desc": "By-default copy the data, this is compat only and ignored.\n"}, {"param_name": "dtype", "param_type": "dtype or None, default None", "param_desc": "If None, dtype will be inferred.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.from_tuples.html#pandas.IntervalIndex.from_tuples"}, {"function_name": "pandas.IntervalIndex.is_empty", "full_function": "property IntervalIndex.is_empty", "function_text": "Indicates if an interval is empty, meaning it contains no points.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.is_empty.html#pandas.IntervalIndex.is_empty"}, {"function_name": "pandas.IntervalIndex.is_overlapping", "full_function": "property IntervalIndex.is_overlapping", "function_text": "Return True if the IntervalIndex has overlapping intervals, else False.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.is_overlapping.html#pandas.IntervalIndex.is_overlapping"}, {"function_name": "pandas.IntervalIndex.get_indexer", "full_function": "IntervalIndex.get_indexer(target, method=None, limit=None, tolerance=None)", "function_text": "Compute indexer and mask for new index given the current index.", "parameter_names_desc": [{"param_name": "target", "param_type": "Index", "param_desc": ""}, {"param_name": "method", "param_type": "{None, ‘pad’/’ffill’, ‘backfill’/’bfill’, ‘nearest’}, optional", "param_desc": "\ndefault: exact matches only.\npad / ffill: find the PREVIOUS index value if no exact match.\nbackfill / bfill: use NEXT index value if no exact match\nnearest: use the NEAREST index value if no exact match. Tied\ndistances are broken by preferring the larger index value.\n\n"}, {"param_name": "limit", "param_type": "int, optional", "param_desc": "Maximum number of consecutive labels in target to match for\ninexact matches.\n"}, {"param_name": "tolerance", "param_type": "optional", "param_desc": "Maximum distance between original and new labels for inexact\nmatches. The values of the index at the matching locations must\nsatisfy the equation abs(index[indexer] - target) <= tolerance.\nTolerance may be a scalar value, which applies the same tolerance\nto all values, or list-like, which applies variable tolerance per\nelement. List-like includes list, tuple, array, Series, and must be\nthe same size as the index and its dtype must exactly match the\nindex’s type.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.get_indexer.html#pandas.IntervalIndex.get_indexer"}, {"function_name": "pandas.IntervalIndex.contains", "full_function": "IntervalIndex.contains(*args, **kwargs)", "function_text": "Check elementwise if the Intervals contain the value.", "parameter_names_desc": [{"param_name": "other", "param_type": "scalar", "param_desc": "The value to check whether it is contained in the Intervals.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.contains.html#pandas.IntervalIndex.contains"}, {"function_name": "pandas.IntervalIndex.to_tuples", "full_function": "IntervalIndex.to_tuples(*args, **kwargs)", "function_text": "Return an ndarray (if self is IntervalArray) or Index (if self is IntervalIndex) of tuples of the form (left, right).", "parameter_names_desc": [{"param_name": "na_tuple", "param_type": "bool, default True", "param_desc": "If True, return NA as a tuple (nan, nan). If False,\njust return NA as nan.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.IntervalIndex.to_tuples.html#pandas.IntervalIndex.to_tuples"}]}, {"name": "MultiIndex", "url": "https://pandas.pydata.org/docs/reference/indexing.html#multiindex", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.html#pandas.MultiIndex", "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.from_arrays.html#pandas.MultiIndex.from_arrays", "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.from_product.html#pandas.MultiIndex.from_product", "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.names.html#pandas.MultiIndex.names", "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.codes.html#pandas.MultiIndex.codes", "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.levshape.html#pandas.MultiIndex.levshape", "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.set_levels.html#pandas.MultiIndex.set_levels", "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.to_flat_index.html#pandas.MultiIndex.to_flat_index", "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.sortlevel.html#pandas.MultiIndex.sortlevel", "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.swaplevel.html#pandas.MultiIndex.swaplevel", "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.remove_unused_levels.html#pandas.MultiIndex.remove_unused_levels", "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.copy.html#pandas.MultiIndex.copy", "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.truncate.html#pandas.MultiIndex.truncate", "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.get_loc.html#pandas.MultiIndex.get_loc", "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.get_loc_level.html#pandas.MultiIndex.get_loc_level", "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.get_level_values.html#pandas.MultiIndex.get_level_values", "https://pandas.pydata.org/docs/reference/api/pandas.IndexSlice.html#pandas.IndexSlice", "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.from_tuples.html#pandas.MultiIndex.from_tuples", "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.from_frame.html#pandas.MultiIndex.from_frame", "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.levels.html#pandas.MultiIndex.levels", "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.nlevels.html#pandas.MultiIndex.nlevels", "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.dtypes.html#pandas.MultiIndex.dtypes", "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.set_codes.html#pandas.MultiIndex.set_codes", "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.to_frame.html#pandas.MultiIndex.to_frame", "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.droplevel.html#pandas.MultiIndex.droplevel", "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.reorder_levels.html#pandas.MultiIndex.reorder_levels", "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.drop.html#pandas.MultiIndex.drop", "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.append.html#pandas.MultiIndex.append", "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.get_locs.html#pandas.MultiIndex.get_locs", "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.get_indexer.html#pandas.MultiIndex.get_indexer"], "function_definitions": [{"function_name": "pandas.MultiIndex", "full_function": "class pandas.MultiIndex(levels=None, codes=None, sortorder=None, names=None, dtype=None, copy=False, name=None, verify_integrity=True)", "function_text": "A multi-level, or hierarchical, index object for pandas objects.", "parameter_names_desc": [{"param_name": "levels", "param_type": "sequence of arrays", "param_desc": "The unique labels for each level.\n"}, {"param_name": "codes", "param_type": "sequence of arrays", "param_desc": "Integers for each level designating which label at each location.\n"}, {"param_name": "sortorder", "param_type": "optional int", "param_desc": "Level of sortedness (must be lexicographically sorted by that\nlevel).\n"}, {"param_name": "names", "param_type": "optional sequence of objects", "param_desc": "Names for each of the index levels. (name is accepted for compat).\n"}, {"param_name": "copy", "param_type": "bool, default False", "param_desc": "Copy the meta-data.\n"}, {"param_name": "verify_integrity", "param_type": "bool, default True", "param_desc": "Check that the levels/codes are consistent and valid.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.html#pandas.MultiIndex"}, {"function_name": "pandas.MultiIndex.from_arrays", "full_function": "classmethod MultiIndex.from_arrays(arrays, sortorder=None, names=_NoDefault.no_default)", "function_text": "Convert arrays to MultiIndex.", "parameter_names_desc": [{"param_name": "arrays", "param_type": "list / sequence of array-likes", "param_desc": "Each array-like gives one level’s value for each data point.\nlen(arrays) is the number of levels.\n"}, {"param_name": "sortorder", "param_type": "int or None", "param_desc": "Level of sortedness (must be lexicographically sorted by that\nlevel).\n"}, {"param_name": "names", "param_type": "list / sequence of str, optional", "param_desc": "Names for the levels in the index.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.from_arrays.html#pandas.MultiIndex.from_arrays"}, {"function_name": "pandas.MultiIndex.from_product", "full_function": "classmethod MultiIndex.from_product(iterables, sortorder=None, names=_NoDefault.no_default)", "function_text": "Make a MultiIndex from the cartesian product of multiple iterables.", "parameter_names_desc": [{"param_name": "iterables", "param_type": "list / sequence of iterables", "param_desc": "Each iterable has unique labels for each level of the index.\n"}, {"param_name": "sortorder", "param_type": "int or None", "param_desc": "Level of sortedness (must be lexicographically sorted by that\nlevel).\n"}, {"param_name": "names", "param_type": "list / sequence of str, optional", "param_desc": "Names for the levels in the index.\nIf not explicitly provided, names will be inferred from the\nelements of iterables if an element has a name attribute.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.from_product.html#pandas.MultiIndex.from_product"}, {"function_name": "pandas.MultiIndex.names", "full_function": "property MultiIndex.names", "function_text": "Names of levels in MultiIndex.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.names.html#pandas.MultiIndex.names"}, {"function_name": "pandas.MultiIndex.names", "full_function": "property MultiIndex.names", "function_text": "Names of levels in MultiIndex.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.names.html#pandas.MultiIndex.names"}, {"function_name": "pandas.MultiIndex.levshape", "full_function": "property MultiIndex.levshape", "function_text": "A tuple with the length of each level.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.levshape.html#pandas.MultiIndex.levshape"}, {"function_name": "pandas.MultiIndex.set_levels", "full_function": "MultiIndex.set_levels(levels, *, level=None, verify_integrity=True)", "function_text": "Set new levels on MultiIndex. Defaults to returning new index.", "parameter_names_desc": [{"param_name": "levels", "param_type": "sequence or list of sequence", "param_desc": "New level(s) to apply.\n"}, {"param_name": "level", "param_type": "int, level name, or sequence of int/level names (default None)", "param_desc": "Level(s) to set (None for all levels).\n"}, {"param_name": "verify_integrity", "param_type": "bool, default True", "param_desc": "If True, checks that levels and codes are compatible.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.set_levels.html#pandas.MultiIndex.set_levels"}, {"function_name": "pandas.MultiIndex.to_flat_index", "full_function": "MultiIndex.to_flat_index()", "function_text": "Convert a MultiIndex to an Index of Tuples containing the level values.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.to_flat_index.html#pandas.MultiIndex.to_flat_index"}, {"function_name": "pandas.MultiIndex.sortlevel", "full_function": "MultiIndex.sortlevel(level=0, ascending=True, sort_remaining=True, na_position='first')", "function_text": "Sort MultiIndex at the requested level.", "parameter_names_desc": [{"param_name": "level", "param_type": "list-like, int or str, default 0", "param_desc": "If a string is given, must be a name of the level.\nIf list-like must be names or ints of levels.\n"}, {"param_name": "ascending", "param_type": "bool, default True", "param_desc": "False to sort in descending order.\nCan also be a list to specify a directed ordering.\n"}, {"param_name": "sort_remaining", "param_type": "sort by the remaining levels after level", "param_desc": ""}, {"param_name": "na_position", "param_type": "{‘first’ or ‘last’}, default ‘first’", "param_desc": "Argument ‘first’ puts NaNs at the beginning, ‘last’ puts NaNs at\nthe end.\n\nNew in version 2.1.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.sortlevel.html#pandas.MultiIndex.sortlevel"}, {"function_name": "pandas.MultiIndex.swaplevel", "full_function": "MultiIndex.swaplevel(i=-2, j=-1)", "function_text": "Swap level i with level j.", "parameter_names_desc": [{"param_name": "i", "param_type": "int, str, default -2", "param_desc": "First level of index to be swapped. Can pass level name as string.\nType of parameters can be mixed.\n"}, {"param_name": "j", "param_type": "int, str, default -1", "param_desc": "Second level of index to be swapped. Can pass level name as string.\nType of parameters can be mixed.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.swaplevel.html#pandas.MultiIndex.swaplevel"}, {"function_name": "pandas.MultiIndex.remove_unused_levels", "full_function": "MultiIndex.remove_unused_levels()", "function_text": "Create new MultiIndex from current that removes unused levels.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.remove_unused_levels.html#pandas.MultiIndex.remove_unused_levels"}, {"function_name": "pandas.MultiIndex.copy", "full_function": "MultiIndex.copy(names=None, deep=False, name=None)", "function_text": "Make a copy of this object.", "parameter_names_desc": [{"param_name": "names", "param_type": "sequence, optional", "param_desc": ""}, {"param_name": "deep", "param_type": "bool, default False", "param_desc": ""}, {"param_name": "name", "param_type": "Label", "param_desc": "Kept for compatibility with 1-dimensional Index. Should not be used.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.copy.html#pandas.MultiIndex.copy"}, {"function_name": "pandas.MultiIndex.truncate", "full_function": "MultiIndex.truncate(before=None, after=None)", "function_text": "Slice index between two labels / tuples, return new MultiIndex.", "parameter_names_desc": [{"param_name": "before", "param_type": "label or tuple, can be partial. Default None", "param_desc": "None defaults to start.\n"}, {"param_name": "after", "param_type": "label or tuple, can be partial. Default None", "param_desc": "None defaults to end.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.truncate.html#pandas.MultiIndex.truncate"}, {"function_name": "pandas.MultiIndex.get_loc", "full_function": "MultiIndex.get_loc(key)", "function_text": "Get location for a label or a tuple of labels.", "parameter_names_desc": [{"param_name": "key", "param_type": "label or tuple of labels (one for each level)", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.get_loc.html#pandas.MultiIndex.get_loc"}, {"function_name": "pandas.MultiIndex.get_loc_level", "full_function": "MultiIndex.get_loc_level(key, level=0, drop_level=True)", "function_text": "Get location and sliced index for requested label(s)/level(s).", "parameter_names_desc": [{"param_name": "key", "param_type": "label or sequence of labels", "param_desc": ""}, {"param_name": "level", "param_type": "int/level name or list thereof, optional", "param_desc": ""}, {"param_name": "drop_level", "param_type": "bool, default True", "param_desc": "If False, the resulting index will not drop any level.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.get_loc_level.html#pandas.MultiIndex.get_loc_level"}, {"function_name": "pandas.MultiIndex.get_level_values", "full_function": "MultiIndex.get_level_values(level)", "function_text": "Return vector of label values for requested level.", "parameter_names_desc": [{"param_name": "level", "param_type": "int or str", "param_desc": "level is either the integer position of the level in the\nMultiIndex, or the name of the level.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.get_level_values.html#pandas.MultiIndex.get_level_values"}, {"function_name": "pandas.IndexSlice", "full_function": "pandas.IndexSlice = <pandas.core.indexing._IndexSlice object>#", "function_text": "Create an object to more easily perform multi-index slicing.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.IndexSlice.html#pandas.IndexSlice"}, {"function_name": "pandas.MultiIndex.from_tuples", "full_function": "classmethod MultiIndex.from_tuples(tuples, sortorder=None, names=None)", "function_text": "Convert list of tuples to MultiIndex.", "parameter_names_desc": [{"param_name": "tuples", "param_type": "list / sequence of tuple-likes", "param_desc": "Each tuple is the index of one row/column.\n"}, {"param_name": "sortorder", "param_type": "int or None", "param_desc": "Level of sortedness (must be lexicographically sorted by that\nlevel).\n"}, {"param_name": "names", "param_type": "list / sequence of str, optional", "param_desc": "Names for the levels in the index.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.from_tuples.html#pandas.MultiIndex.from_tuples"}, {"function_name": "pandas.MultiIndex.from_frame", "full_function": "classmethod MultiIndex.from_frame(df, sortorder=None, names=None)", "function_text": "Make a MultiIndex from a DataFrame.", "parameter_names_desc": [{"param_name": "df", "param_type": "DataFrame", "param_desc": "DataFrame to be converted to MultiIndex.\n"}, {"param_name": "sortorder", "param_type": "int, optional", "param_desc": "Level of sortedness (must be lexicographically sorted by that\nlevel).\n"}, {"param_name": "names", "param_type": "list-like, optional", "param_desc": "If no names are provided, use the column names, or tuple of column\nnames if the columns is a MultiIndex. If a sequence, overwrite\nnames with the given sequence.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.from_frame.html#pandas.MultiIndex.from_frame"}, {"function_name": "pandas.MultiIndex.levels", "full_function": "MultiIndex.levels", "function_text": "Levels of the MultiIndex.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.levels.html#pandas.MultiIndex.levels"}, {"function_name": "pandas.MultiIndex.nlevels", "full_function": "property MultiIndex.nlevels", "function_text": "Integer number of levels in this MultiIndex.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.nlevels.html#pandas.MultiIndex.nlevels"}, {"function_name": "pandas.MultiIndex.dtypes", "full_function": "MultiIndex.dtypes", "function_text": "Return the dtypes as a Series for the underlying MultiIndex.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.dtypes.html#pandas.MultiIndex.dtypes"}, {"function_name": "pandas.MultiIndex.set_codes", "full_function": "MultiIndex.set_codes(codes, *, level=None, verify_integrity=True)", "function_text": "Set new codes on MultiIndex. Defaults to returning new index.", "parameter_names_desc": [{"param_name": "codes", "param_type": "sequence or list of sequence", "param_desc": "New codes to apply.\n"}, {"param_name": "level", "param_type": "int, level name, or sequence of int/level names (default None)", "param_desc": "Level(s) to set (None for all levels).\n"}, {"param_name": "verify_integrity", "param_type": "bool, default True", "param_desc": "If True, checks that levels and codes are compatible.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.set_codes.html#pandas.MultiIndex.set_codes"}, {"function_name": "pandas.MultiIndex.to_frame", "full_function": "MultiIndex.to_frame(index=True, name=_NoDefault.no_default, allow_duplicates=False)", "function_text": "Create a DataFrame with the levels of the MultiIndex as columns.", "parameter_names_desc": [{"param_name": "index", "param_type": "bool, default True", "param_desc": "Set the index of the returned DataFrame as the original MultiIndex.\n"}, {"param_name": "name", "param_type": "list / sequence of str, optional", "param_desc": "The passed names should substitute index level names.\n"}, {"param_name": "allow_duplicates", "param_type": "bool, optional default False", "param_desc": "Allow duplicate column labels to be created.\n\nNew in version 1.5.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.to_frame.html#pandas.MultiIndex.to_frame"}, {"function_name": "pandas.MultiIndex.droplevel", "full_function": "MultiIndex.droplevel(level=0)", "function_text": "Return index with requested level(s) removed.", "parameter_names_desc": [{"param_name": "level", "param_type": "int, str, or list-like, default 0", "param_desc": "If a string is given, must be the name of a level\nIf list-like, elements must be names or indexes of levels.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.droplevel.html#pandas.MultiIndex.droplevel"}, {"function_name": "pandas.MultiIndex.reorder_levels", "full_function": "MultiIndex.reorder_levels(order)", "function_text": "Rearrange levels using input order. May not drop or duplicate levels.", "parameter_names_desc": [{"param_name": "order", "param_type": "list of int or list of str", "param_desc": "List representing new level order. Reference level by number\n(position) or by key (label).\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.reorder_levels.html#pandas.MultiIndex.reorder_levels"}, {"function_name": "pandas.MultiIndex.drop", "full_function": "MultiIndex.drop(codes, level=None, errors='raise')", "function_text": "Make a new pandas.MultiIndex with the passed list of codes deleted.", "parameter_names_desc": [{"param_name": "codes", "param_type": "array-like", "param_desc": "Must be a list of tuples when level is not specified.\n"}, {"param_name": "level", "param_type": "int or level name, default None", "param_desc": ""}, {"param_name": "errors", "param_type": "str, default ‘raise’", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.drop.html#pandas.MultiIndex.drop"}, {"function_name": "pandas.MultiIndex.append", "full_function": "MultiIndex.append(other)", "function_text": "Append a collection of Index options together.", "parameter_names_desc": [{"param_name": "other", "param_type": "Index or list/tuple of indices", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.append.html#pandas.MultiIndex.append"}, {"function_name": "pandas.MultiIndex.get_locs", "full_function": "MultiIndex.get_locs(seq)", "function_text": "Get location for a sequence of labels.", "parameter_names_desc": [{"param_name": "seq", "param_type": "label, slice, list, mask or a sequence of such", "param_desc": "You should use one of the above for each level.\nIf a level should not be used, set it to slice(None).\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.get_locs.html#pandas.MultiIndex.get_locs"}, {"function_name": "pandas.MultiIndex.get_indexer", "full_function": "MultiIndex.get_indexer(target, method=None, limit=None, tolerance=None)", "function_text": "Compute indexer and mask for new index given the current index.", "parameter_names_desc": [{"param_name": "target", "param_type": "Index", "param_desc": ""}, {"param_name": "method", "param_type": "{None, ‘pad’/’ffill’, ‘backfill’/’bfill’, ‘nearest’}, optional", "param_desc": "\ndefault: exact matches only.\npad / ffill: find the PREVIOUS index value if no exact match.\nbackfill / bfill: use NEXT index value if no exact match\nnearest: use the NEAREST index value if no exact match. Tied\ndistances are broken by preferring the larger index value.\n\n"}, {"param_name": "limit", "param_type": "int, optional", "param_desc": "Maximum number of consecutive labels in target to match for\ninexact matches.\n"}, {"param_name": "tolerance", "param_type": "optional", "param_desc": "Maximum distance between original and new labels for inexact\nmatches. The values of the index at the matching locations must\nsatisfy the equation abs(index[indexer] - target) <= tolerance.\nTolerance may be a scalar value, which applies the same tolerance\nto all values, or list-like, which applies variable tolerance per\nelement. List-like includes list, tuple, array, Series, and must be\nthe same size as the index and its dtype must exactly match the\nindex’s type.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.get_indexer.html#pandas.MultiIndex.get_indexer"}]}, {"name": "DatetimeIndex", "url": "https://pandas.pydata.org/docs/reference/indexing.html#datetimeindex", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.html#pandas.DatetimeIndex", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.year.html#pandas.DatetimeIndex.year", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.day.html#pandas.DatetimeIndex.day", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.minute.html#pandas.DatetimeIndex.minute", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.microsecond.html#pandas.DatetimeIndex.microsecond", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.date.html#pandas.DatetimeIndex.date", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.timetz.html#pandas.DatetimeIndex.timetz", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.day_of_year.html#pandas.DatetimeIndex.day_of_year", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.day_of_week.html#pandas.DatetimeIndex.day_of_week", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.quarter.html#pandas.DatetimeIndex.quarter", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.freq.html#pandas.DatetimeIndex.freq", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_month_start.html#pandas.DatetimeIndex.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_quarter_start.html#pandas.DatetimeIndex.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_year_start.html#pandas.DatetimeIndex.is_year_start", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_leap_year.html#pandas.DatetimeIndex.is_leap_year", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.indexer_at_time.html#pandas.DatetimeIndex.indexer_at_time", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.normalize.html#pandas.DatetimeIndex.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.snap.html#pandas.DatetimeIndex.snap", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.tz_localize.html#pandas.DatetimeIndex.tz_localize", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.floor.html#pandas.DatetimeIndex.floor", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.month_name.html#pandas.DatetimeIndex.month_name", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.as_unit.html#pandas.DatetimeIndex.as_unit", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.to_pydatetime.html#pandas.DatetimeIndex.to_pydatetime", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.to_frame.html#pandas.DatetimeIndex.to_frame", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.mean.html#pandas.DatetimeIndex.mean", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.month.html#pandas.DatetimeIndex.month", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.hour.html#pandas.DatetimeIndex.hour", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.second.html#pandas.DatetimeIndex.second", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.nanosecond.html#pandas.DatetimeIndex.nanosecond", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.time.html#pandas.DatetimeIndex.time", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.dayofyear.html#pandas.DatetimeIndex.dayofyear", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.dayofweek.html#pandas.DatetimeIndex.dayofweek", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.weekday.html#pandas.DatetimeIndex.weekday", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.tz.html#pandas.DatetimeIndex.tz", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.freqstr.html#pandas.DatetimeIndex.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_month_end.html#pandas.DatetimeIndex.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_quarter_end.html#pandas.DatetimeIndex.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_year_end.html#pandas.DatetimeIndex.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.inferred_freq.html#pandas.DatetimeIndex.inferred_freq", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.indexer_between_time.html#pandas.DatetimeIndex.indexer_between_time", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.strftime.html#pandas.DatetimeIndex.strftime", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.tz_convert.html#pandas.DatetimeIndex.tz_convert", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.round.html#pandas.DatetimeIndex.round", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.ceil.html#pandas.DatetimeIndex.ceil", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.day_name.html#pandas.DatetimeIndex.day_name", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.to_period.html#pandas.DatetimeIndex.to_period", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.to_series.html#pandas.DatetimeIndex.to_series", "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.std.html#pandas.DatetimeIndex.std"], "function_definitions": [{"function_name": "pandas.DatetimeIndex", "full_function": "class pandas.DatetimeIndex(data=None, freq=_NoDefault.no_default, tz=_NoDefault.no_default, normalize=_NoDefault.no_default, closed=_NoDefault.no_default, ambiguous='raise', dayfirst=False, yearfirst=False, dtype=None, copy=False, name=None)", "function_text": "Immutable ndarray-like of datetime64 data.", "parameter_names_desc": [{"param_name": "data", "param_type": "array-like (1-dimensional)", "param_desc": "Datetime-like data to construct index with.\n"}, {"param_name": "freq", "param_type": "str or pandas offset object, optional", "param_desc": "One of pandas date offset strings or corresponding objects. The string\n‘infer’ can be passed in order to set the frequency of the index as the\ninferred frequency upon creation.\n"}, {"param_name": "tz", "param_type": "pytz.timezone or dateutil.tz.tzfile or datetime.tzinfo or str", "param_desc": "Set the Timezone of the data.\n"}, {"param_name": "normalize", "param_type": "bool, default False", "param_desc": "Normalize start/end dates to midnight before generating date range.\n\nDeprecated since version 2.1.0.\n\n"}, {"param_name": "closed", "param_type": "{‘left’, ‘right’}, optional", "param_desc": "Set whether to include start and end that are on the\nboundary. The default includes boundary points on either end.\n\nDeprecated since version 2.1.0.\n\n"}, {"param_name": "ambiguous", "param_type": "‘infer’, bool-ndarray, ‘NaT’, default ‘raise’", "param_desc": "When clocks moved backward due to DST, ambiguous times may arise.\nFor example in Central European Time (UTC+01), when going from 03:00\nDST to 02:00 non-DST, 02:30:00 local time occurs both at 00:30:00 UTC\nand at 01:30:00 UTC. In such a situation, the ambiguous parameter\ndictates how ambiguous times should be handled.\n\n‘infer’ will attempt to infer fall dst-transition hours based on\norder\nbool-ndarray where True signifies a DST time, False signifies a\nnon-DST time (note that this flag is only applicable for ambiguous\ntimes)\n‘NaT’ will return NaT where there are ambiguous times\n‘raise’ will raise an AmbiguousTimeError if there are ambiguous times.\n\n"}, {"param_name": "dayfirst", "param_type": "bool, default False", "param_desc": "If True, parse dates in data with the day first order.\n"}, {"param_name": "yearfirst", "param_type": "bool, default False", "param_desc": "If True parse dates in data with the year first order.\n"}, {"param_name": "dtype", "param_type": "numpy.dtype or DatetimeTZDtype or str, default None", "param_desc": "Note that the only NumPy dtype allowed is datetime64[ns].\n"}, {"param_name": "copy", "param_type": "bool, default False", "param_desc": "Make a copy of input ndarray.\n"}, {"param_name": "name", "param_type": "label, default None", "param_desc": "Name to be stored in the index.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.html#pandas.DatetimeIndex"}, {"function_name": "pandas.DatetimeIndex.year", "full_function": "property DatetimeIndex.year", "function_text": "The year of the datetime.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.year.html#pandas.DatetimeIndex.year"}, {"function_name": "pandas.DatetimeIndex.day", "full_function": "property DatetimeIndex.day", "function_text": "The day of the datetime.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.day.html#pandas.DatetimeIndex.day"}, {"function_name": "pandas.DatetimeIndex.minute", "full_function": "property DatetimeIndex.minute", "function_text": "The minutes of the datetime.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.minute.html#pandas.DatetimeIndex.minute"}, {"function_name": "pandas.DatetimeIndex.microsecond", "full_function": "property DatetimeIndex.microsecond", "function_text": "The microseconds of the datetime.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.microsecond.html#pandas.DatetimeIndex.microsecond"}, {"function_name": "pandas.DatetimeIndex.date", "full_function": "property DatetimeIndex.date", "function_text": "Returns numpy array of python datetime.date objects.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.date.html#pandas.DatetimeIndex.date"}, {"function_name": "pandas.DatetimeIndex.timetz", "full_function": "property DatetimeIndex.timetz", "function_text": "Returns numpy array of datetime.time objects with timezones.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.timetz.html#pandas.DatetimeIndex.timetz"}, {"function_name": "pandas.DatetimeIndex.day_of_year", "full_function": "property DatetimeIndex.day_of_year", "function_text": "The ordinal day of the year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.day_of_year.html#pandas.DatetimeIndex.day_of_year"}, {"function_name": "pandas.DatetimeIndex.day_of_week", "full_function": "property DatetimeIndex.day_of_week", "function_text": "The day of the week with Monday=0, Sunday=6.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.day_of_week.html#pandas.DatetimeIndex.day_of_week"}, {"function_name": "pandas.DatetimeIndex.quarter", "full_function": "property DatetimeIndex.quarter", "function_text": "The quarter of the date.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.quarter.html#pandas.DatetimeIndex.quarter"}, {"function_name": "pandas.DatetimeIndex.quarter", "full_function": "property DatetimeIndex.quarter", "function_text": "The quarter of the date.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.quarter.html#pandas.DatetimeIndex.quarter"}, {"function_name": "pandas.DatetimeIndex.is_month_start", "full_function": "property DatetimeIndex.is_month_start", "function_text": "Indicates whether the date is the first day of the month.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_month_start.html#pandas.DatetimeIndex.is_month_start"}, {"function_name": "pandas.DatetimeIndex.is_quarter_start", "full_function": "property DatetimeIndex.is_quarter_start", "function_text": "Indicator for whether the date is the first day of a quarter.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_quarter_start.html#pandas.DatetimeIndex.is_quarter_start"}, {"function_name": "pandas.DatetimeIndex.is_year_start", "full_function": "property DatetimeIndex.is_year_start", "function_text": "Indicate whether the date is the first day of a year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_year_start.html#pandas.DatetimeIndex.is_year_start"}, {"function_name": "pandas.DatetimeIndex.is_leap_year", "full_function": "property DatetimeIndex.is_leap_year", "function_text": "Boolean indicator if the date belongs to a leap year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_leap_year.html#pandas.DatetimeIndex.is_leap_year"}, {"function_name": "pandas.DatetimeIndex.indexer_at_time", "full_function": "DatetimeIndex.indexer_at_time(time, asof=False)", "function_text": "Return index locations of values at particular time of day.", "parameter_names_desc": [{"param_name": "time", "param_type": "datetime.time or str", "param_desc": "Time passed in either as object (datetime.time) or as string in\nappropriate format (“%H:%M”, “%H%M”, “%I:%M%p”, “%I%M%p”,\n“%H:%M:%S”, “%H%M%S”, “%I:%M:%S%p”, “%I%M%S%p”).\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.indexer_at_time.html#pandas.DatetimeIndex.indexer_at_time"}, {"function_name": "pandas.DatetimeIndex.normalize", "full_function": "DatetimeIndex.normalize(*args, **kwargs)", "function_text": "Convert times to midnight.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.normalize.html#pandas.DatetimeIndex.normalize"}, {"function_name": "pandas.DatetimeIndex.snap", "full_function": "DatetimeIndex.snap(freq='S')", "function_text": "Snap time stamps to nearest occurring frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.snap.html#pandas.DatetimeIndex.snap"}, {"function_name": "pandas.DatetimeIndex.tz_localize", "full_function": "DatetimeIndex.tz_localize(tz, ambiguous='raise', nonexistent='raise')", "function_text": "Localize tz-naive Datetime Array/Index to tz-aware Datetime Array/Index.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.tz_localize.html#pandas.DatetimeIndex.tz_localize"}, {"function_name": "pandas.DatetimeIndex.floor", "full_function": "DatetimeIndex.floor(*args, **kwargs)", "function_text": "Perform floor operation on the data to the specified freq.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.floor.html#pandas.DatetimeIndex.floor"}, {"function_name": "pandas.DatetimeIndex.month_name", "full_function": "DatetimeIndex.month_name(*args, **kwargs)", "function_text": "Return the month names with specified locale.", "parameter_names_desc": [{"param_name": "locale", "param_type": "str, optional", "param_desc": "Locale determining the language in which to return the month name.\nDefault is English locale ('en_US.utf8'). Use the command\nlocale -a on your terminal on Unix systems to find your locale\nlanguage code.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.month_name.html#pandas.DatetimeIndex.month_name"}, {"function_name": "pandas.DatetimeIndex.as_unit", "full_function": "DatetimeIndex.as_unit(*args, **kwargs)", "function_text": "Convert to a dtype with the given unit resolution.", "parameter_names_desc": [{"param_name": "unit", "param_type": "{‘s’, ‘ms’, ‘us’, ‘ns’}", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.as_unit.html#pandas.DatetimeIndex.as_unit"}, {"function_name": "pandas.DatetimeIndex.to_pydatetime", "full_function": "DatetimeIndex.to_pydatetime(*args, **kwargs)", "function_text": "Return an ndarray of datetime.datetime objects.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.to_pydatetime.html#pandas.DatetimeIndex.to_pydatetime"}, {"function_name": "pandas.DatetimeIndex.to_frame", "full_function": "DatetimeIndex.to_frame(index=True, name=_NoDefault.no_default)", "function_text": "Create a DataFrame with a column containing the Index.", "parameter_names_desc": [{"param_name": "index", "param_type": "bool, default True", "param_desc": "Set the index of the returned DataFrame as the original Index.\n"}, {"param_name": "name", "param_type": "object, defaults to index.name", "param_desc": "The passed name should substitute for the index name (if it has\none).\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.to_frame.html#pandas.DatetimeIndex.to_frame"}, {"function_name": "pandas.DatetimeIndex.mean", "full_function": "DatetimeIndex.mean(*, skipna=True, axis=0)", "function_text": "Return the mean value of the Array.", "parameter_names_desc": [{"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Whether to ignore any NaT elements.\n"}, {"param_name": "axis", "param_type": "int, optional, default 0", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.mean.html#pandas.DatetimeIndex.mean"}, {"function_name": "pandas.DatetimeIndex.month", "full_function": "property DatetimeIndex.month", "function_text": "The month as January=1, December=12.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.month.html#pandas.DatetimeIndex.month"}, {"function_name": "pandas.DatetimeIndex.hour", "full_function": "property DatetimeIndex.hour", "function_text": "The hours of the datetime.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.hour.html#pandas.DatetimeIndex.hour"}, {"function_name": "pandas.DatetimeIndex.second", "full_function": "property DatetimeIndex.second", "function_text": "The seconds of the datetime.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.second.html#pandas.DatetimeIndex.second"}, {"function_name": "pandas.DatetimeIndex.nanosecond", "full_function": "property DatetimeIndex.nanosecond", "function_text": "The nanoseconds of the datetime.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.nanosecond.html#pandas.DatetimeIndex.nanosecond"}, {"function_name": "pandas.DatetimeIndex.time", "full_function": "property DatetimeIndex.time", "function_text": "Returns numpy array of datetime.time objects.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.time.html#pandas.DatetimeIndex.time"}, {"function_name": "pandas.DatetimeIndex.dayofyear", "full_function": "property DatetimeIndex.dayofyear", "function_text": "The ordinal day of the year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.dayofyear.html#pandas.DatetimeIndex.dayofyear"}, {"function_name": "pandas.DatetimeIndex.dayofweek", "full_function": "property DatetimeIndex.dayofweek", "function_text": "The day of the week with Monday=0, Sunday=6.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.dayofweek.html#pandas.DatetimeIndex.dayofweek"}, {"function_name": "pandas.DatetimeIndex.weekday", "full_function": "property DatetimeIndex.weekday", "function_text": "The day of the week with Monday=0, Sunday=6.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.weekday.html#pandas.DatetimeIndex.weekday"}, {"function_name": "pandas.DatetimeIndex.tz", "full_function": "property DatetimeIndex.tz", "function_text": "Return the timezone.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.tz.html#pandas.DatetimeIndex.tz"}, {"function_name": "pandas.DatetimeIndex.freqstr", "full_function": "property DatetimeIndex.freqstr", "function_text": "Return the frequency object as a string if it’s set, otherwise None.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.freqstr.html#pandas.DatetimeIndex.freqstr"}, {"function_name": "pandas.DatetimeIndex.is_month_end", "full_function": "property DatetimeIndex.is_month_end", "function_text": "Indicates whether the date is the last day of the month.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_month_end.html#pandas.DatetimeIndex.is_month_end"}, {"function_name": "pandas.DatetimeIndex.is_quarter_end", "full_function": "property DatetimeIndex.is_quarter_end", "function_text": "Indicator for whether the date is the last day of a quarter.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_quarter_end.html#pandas.DatetimeIndex.is_quarter_end"}, {"function_name": "pandas.DatetimeIndex.is_year_end", "full_function": "property DatetimeIndex.is_year_end", "function_text": "Indicate whether the date is the last day of the year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.is_year_end.html#pandas.DatetimeIndex.is_year_end"}, {"function_name": "pandas.DatetimeIndex.inferred_freq", "full_function": "DatetimeIndex.inferred_freq", "function_text": "Tries to return a string representing a frequency generated by infer_freq.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.inferred_freq.html#pandas.DatetimeIndex.inferred_freq"}, {"function_name": "pandas.DatetimeIndex.indexer_between_time", "full_function": "DatetimeIndex.indexer_between_time(start_time, end_time, include_start=True, include_end=True)", "function_text": "Return index locations of values between particular times of day.", "parameter_names_desc": [{"param_name": "start_time, end_time", "param_type": "datetime.time, str", "param_desc": "Time passed either as object (datetime.time) or as string in\nappropriate format (“%H:%M”, “%H%M”, “%I:%M%p”, “%I%M%p”,\n“%H:%M:%S”, “%H%M%S”, “%I:%M:%S%p”,”%I%M%S%p”).\n"}, {"param_name": "include_start", "param_type": "bool, default True", "param_desc": ""}, {"param_name": "include_end", "param_type": "bool, default True", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.indexer_between_time.html#pandas.DatetimeIndex.indexer_between_time"}, {"function_name": "pandas.DatetimeIndex.strftime", "full_function": "DatetimeIndex.strftime(date_format)", "function_text": "Convert to Index using specified date_format.", "parameter_names_desc": [{"param_name": "date_format", "param_type": "str", "param_desc": "Date format string (e.g. “%Y-%m-%d”).\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.strftime.html#pandas.DatetimeIndex.strftime"}, {"function_name": "pandas.DatetimeIndex.tz_convert", "full_function": "DatetimeIndex.tz_convert(tz)", "function_text": "Convert tz-aware Datetime Array/Index from one time zone to another.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.tz_convert.html#pandas.DatetimeIndex.tz_convert"}, {"function_name": "pandas.DatetimeIndex.round", "full_function": "DatetimeIndex.round(*args, **kwargs)", "function_text": "Perform round operation on the data to the specified freq.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.round.html#pandas.DatetimeIndex.round"}, {"function_name": "pandas.DatetimeIndex.ceil", "full_function": "DatetimeIndex.ceil(*args, **kwargs)", "function_text": "Perform ceil operation on the data to the specified freq.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.ceil.html#pandas.DatetimeIndex.ceil"}, {"function_name": "pandas.DatetimeIndex.day_name", "full_function": "DatetimeIndex.day_name(*args, **kwargs)", "function_text": "Return the day names with specified locale.", "parameter_names_desc": [{"param_name": "locale", "param_type": "str, optional", "param_desc": "Locale determining the language in which to return the day name.\nDefault is English locale ('en_US.utf8'). Use the command\nlocale -a on your terminal on Unix systems to find your locale\nlanguage code.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.day_name.html#pandas.DatetimeIndex.day_name"}, {"function_name": "pandas.DatetimeIndex.to_period", "full_function": "DatetimeIndex.to_period(*args, **kwargs)", "function_text": "Cast to PeriodArray/PeriodIndex at a particular frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.to_period.html#pandas.DatetimeIndex.to_period"}, {"function_name": "pandas.DatetimeIndex.to_series", "full_function": "DatetimeIndex.to_series(index=None, name=None)", "function_text": "Create a Series with both index and values equal to the index keys.", "parameter_names_desc": [{"param_name": "index", "param_type": "Index, optional", "param_desc": "Index of resulting Series. If None, defaults to original index.\n"}, {"param_name": "name", "param_type": "str, optional", "param_desc": "Name of resulting Series. If None, defaults to name of original\nindex.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.to_series.html#pandas.DatetimeIndex.to_series"}, {"function_name": "pandas.DatetimeIndex.std", "full_function": "DatetimeIndex.std(*args, **kwargs)", "function_text": "Return sample standard deviation over requested axis.", "parameter_names_desc": [{"param_name": "axis", "param_type": "int, optional", "param_desc": "Axis for the function to be applied on. For pandas.Series\nthis parameter is unused and defaults to None.\n"}, {"param_name": "ddof", "param_type": "int, default 1", "param_desc": "Degrees of Freedom. The divisor used in calculations is N - ddof,\nwhere N represents the number of elements.\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.std.html#pandas.DatetimeIndex.std"}]}, {"name": "TimedeltaIndex", "url": "https://pandas.pydata.org/docs/reference/indexing.html#timedeltaindex", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.html#pandas.TimedeltaIndex", "https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.days.html#pandas.TimedeltaIndex.days", "https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.microseconds.html#pandas.TimedeltaIndex.microseconds", "https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.components.html#pandas.TimedeltaIndex.components", "https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.as_unit.html#pandas.TimedeltaIndex.as_unit", "https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.to_series.html#pandas.TimedeltaIndex.to_series", "https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.floor.html#pandas.TimedeltaIndex.floor", "https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.to_frame.html#pandas.TimedeltaIndex.to_frame", "https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.mean.html#pandas.TimedeltaIndex.mean", "https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.seconds.html#pandas.TimedeltaIndex.seconds", "https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.nanoseconds.html#pandas.TimedeltaIndex.nanoseconds", "https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.inferred_freq.html#pandas.TimedeltaIndex.inferred_freq", "https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.to_pytimedelta.html#pandas.TimedeltaIndex.to_pytimedelta", "https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.round.html#pandas.TimedeltaIndex.round", "https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.ceil.html#pandas.TimedeltaIndex.ceil"], "function_definitions": [{"function_name": "pandas.TimedeltaIndex", "full_function": "class pandas.TimedeltaIndex(data=None, unit=_NoDefault.no_default, freq=_NoDefault.no_default, closed=_NoDefault.no_default, dtype=None, copy=False, name=None)", "function_text": "Immutable Index of timedelta64 data.", "parameter_names_desc": [{"param_name": "data", "param_type": "array-like (1-dimensional), optional", "param_desc": "Optional timedelta-like data to construct index with.\n"}, {"param_name": "unit", "param_type": "{‘D’, ‘h’, ‘m’, ‘s’, ‘ms’, ‘us’, ‘ns’}, optional", "param_desc": "The unit of data.\n\nDeprecated since version 2.2.0: Use pd.to_timedelta instead.\n\n"}, {"param_name": "freq", "param_type": "str or pandas offset object, optional", "param_desc": "One of pandas date offset strings or corresponding objects. The string\n'infer' can be passed in order to set the frequency of the index as\nthe inferred frequency upon creation.\n"}, {"param_name": "dtype", "param_type": "numpy.dtype or str, default None", "param_desc": "Valid numpy dtypes are timedelta64[ns], timedelta64[us],\ntimedelta64[ms], and timedelta64[s].\n"}, {"param_name": "copy", "param_type": "bool", "param_desc": "Make a copy of input array.\n"}, {"param_name": "name", "param_type": "object", "param_desc": "Name to be stored in the index.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.html#pandas.TimedeltaIndex"}, {"function_name": "pandas.TimedeltaIndex.days", "full_function": "property TimedeltaIndex.days", "function_text": "Number of days for each element.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.days.html#pandas.TimedeltaIndex.days"}, {"function_name": "pandas.TimedeltaIndex.microseconds", "full_function": "property TimedeltaIndex.microseconds", "function_text": "Number of microseconds (>= 0 and less than 1 second) for each element.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.microseconds.html#pandas.TimedeltaIndex.microseconds"}, {"function_name": "pandas.TimedeltaIndex.components", "full_function": "property TimedeltaIndex.components", "function_text": "Return a DataFrame of the individual resolution components of the Timedeltas.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.components.html#pandas.TimedeltaIndex.components"}, {"function_name": "pandas.TimedeltaIndex.as_unit", "full_function": "TimedeltaIndex.as_unit(unit)", "function_text": "Convert to a dtype with the given unit resolution.", "parameter_names_desc": [{"param_name": "unit", "param_type": "{‘s’, ‘ms’, ‘us’, ‘ns’}", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.as_unit.html#pandas.TimedeltaIndex.as_unit"}, {"function_name": "pandas.TimedeltaIndex.to_series", "full_function": "TimedeltaIndex.to_series(index=None, name=None)", "function_text": "Create a Series with both index and values equal to the index keys.", "parameter_names_desc": [{"param_name": "index", "param_type": "Index, optional", "param_desc": "Index of resulting Series. If None, defaults to original index.\n"}, {"param_name": "name", "param_type": "str, optional", "param_desc": "Name of resulting Series. If None, defaults to name of original\nindex.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.to_series.html#pandas.TimedeltaIndex.to_series"}, {"function_name": "pandas.TimedeltaIndex.floor", "full_function": "TimedeltaIndex.floor(*args, **kwargs)", "function_text": "Perform floor operation on the data to the specified freq.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.floor.html#pandas.TimedeltaIndex.floor"}, {"function_name": "pandas.TimedeltaIndex.to_frame", "full_function": "TimedeltaIndex.to_frame(index=True, name=_NoDefault.no_default)", "function_text": "Create a DataFrame with a column containing the Index.", "parameter_names_desc": [{"param_name": "index", "param_type": "bool, default True", "param_desc": "Set the index of the returned DataFrame as the original Index.\n"}, {"param_name": "name", "param_type": "object, defaults to index.name", "param_desc": "The passed name should substitute for the index name (if it has\none).\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.to_frame.html#pandas.TimedeltaIndex.to_frame"}, {"function_name": "pandas.TimedeltaIndex.mean", "full_function": "TimedeltaIndex.mean(*, skipna=True, axis=0)", "function_text": "Return the mean value of the Array.", "parameter_names_desc": [{"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Whether to ignore any NaT elements.\n"}, {"param_name": "axis", "param_type": "int, optional, default 0", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.mean.html#pandas.TimedeltaIndex.mean"}, {"function_name": "pandas.TimedeltaIndex.seconds", "full_function": "property TimedeltaIndex.seconds", "function_text": "Number of seconds (>= 0 and less than 1 day) for each element.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.seconds.html#pandas.TimedeltaIndex.seconds"}, {"function_name": "pandas.TimedeltaIndex.nanoseconds", "full_function": "property TimedeltaIndex.nanoseconds", "function_text": "Number of nanoseconds (>= 0 and less than 1 microsecond) for each element.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.nanoseconds.html#pandas.TimedeltaIndex.nanoseconds"}, {"function_name": "pandas.TimedeltaIndex.inferred_freq", "full_function": "TimedeltaIndex.inferred_freq", "function_text": "Tries to return a string representing a frequency generated by infer_freq.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.inferred_freq.html#pandas.TimedeltaIndex.inferred_freq"}, {"function_name": "pandas.TimedeltaIndex.to_pytimedelta", "full_function": "TimedeltaIndex.to_pytimedelta(*args, **kwargs)", "function_text": "Return an ndarray of datetime.timedelta objects.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.to_pytimedelta.html#pandas.TimedeltaIndex.to_pytimedelta"}, {"function_name": "pandas.TimedeltaIndex.round", "full_function": "TimedeltaIndex.round(*args, **kwargs)", "function_text": "Perform round operation on the data to the specified freq.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.round.html#pandas.TimedeltaIndex.round"}, {"function_name": "pandas.TimedeltaIndex.ceil", "full_function": "TimedeltaIndex.ceil(*args, **kwargs)", "function_text": "Perform ceil operation on the data to the specified freq.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.TimedeltaIndex.ceil.html#pandas.TimedeltaIndex.ceil"}]}, {"name": "PeriodIndex", "url": "https://pandas.pydata.org/docs/reference/indexing.html#periodindex", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.html#pandas.PeriodIndex", "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.day.html#pandas.PeriodIndex.day", "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.day_of_week.html#pandas.PeriodIndex.day_of_week", "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.day_of_year.html#pandas.PeriodIndex.day_of_year", "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.daysinmonth.html#pandas.PeriodIndex.daysinmonth", "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.freq.html#pandas.PeriodIndex.freq", "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.hour.html#pandas.PeriodIndex.hour", "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.minute.html#pandas.PeriodIndex.minute", "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.quarter.html#pandas.PeriodIndex.quarter", "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.second.html#pandas.PeriodIndex.second", "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.week.html#pandas.PeriodIndex.week", "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.weekofyear.html#pandas.PeriodIndex.weekofyear", "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.asfreq.html#pandas.PeriodIndex.asfreq", "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.to_timestamp.html#pandas.PeriodIndex.to_timestamp", "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.from_ordinals.html#pandas.PeriodIndex.from_ordinals", "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.dayofweek.html#pandas.PeriodIndex.dayofweek", "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.dayofyear.html#pandas.PeriodIndex.dayofyear", "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.days_in_month.html#pandas.PeriodIndex.days_in_month", "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.end_time.html#pandas.PeriodIndex.end_time", "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.freqstr.html#pandas.PeriodIndex.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.is_leap_year.html#pandas.PeriodIndex.is_leap_year", "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.month.html#pandas.PeriodIndex.month", "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.qyear.html#pandas.PeriodIndex.qyear", "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.start_time.html#pandas.PeriodIndex.start_time", "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.weekday.html#pandas.PeriodIndex.weekday", "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.year.html#pandas.PeriodIndex.year", "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.strftime.html#pandas.PeriodIndex.strftime", "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.from_fields.html#pandas.PeriodIndex.from_fields"], "function_definitions": [{"function_name": "pandas.PeriodIndex", "full_function": "class pandas.PeriodIndex(data=None, ordinal=None, freq=None, dtype=None, copy=False, name=None, **fields)", "function_text": "Immutable ndarray holding ordinal values indicating regular periods in time.", "parameter_names_desc": [{"param_name": "data", "param_type": "array-like (1d int np.ndarray or PeriodArray), optional", "param_desc": "Optional period-like data to construct index with.\n"}, {"param_name": "copy", "param_type": "bool", "param_desc": "Make a copy of input ndarray.\n"}, {"param_name": "freq", "param_type": "str or period object, optional", "param_desc": "One of pandas period strings or corresponding objects.\n"}, {"param_name": "year", "param_type": "int, array, or Series, default None", "param_desc": "\nDeprecated since version 2.2.0: Use PeriodIndex.from_fields instead.\n\n"}, {"param_name": "month", "param_type": "int, array, or Series, default None", "param_desc": "\nDeprecated since version 2.2.0: Use PeriodIndex.from_fields instead.\n\n"}, {"param_name": "quarter", "param_type": "int, array, or Series, default None", "param_desc": "\nDeprecated since version 2.2.0: Use PeriodIndex.from_fields instead.\n\n"}, {"param_name": "day", "param_type": "int, array, or Series, default None", "param_desc": "\nDeprecated since version 2.2.0: Use PeriodIndex.from_fields instead.\n\n"}, {"param_name": "hour", "param_type": "int, array, or Series, default None", "param_desc": "\nDeprecated since version 2.2.0: Use PeriodIndex.from_fields instead.\n\n"}, {"param_name": "minute", "param_type": "int, array, or Series, default None", "param_desc": "\nDeprecated since version 2.2.0: Use PeriodIndex.from_fields instead.\n\n"}, {"param_name": "second", "param_type": "int, array, or Series, default None", "param_desc": "\nDeprecated since version 2.2.0: Use PeriodIndex.from_fields instead.\n\n"}, {"param_name": "dtype", "param_type": "str or PeriodDtype, default None", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.html#pandas.PeriodIndex"}, {"function_name": "pandas.PeriodIndex.day", "full_function": "property PeriodIndex.day", "function_text": "The days of the period.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.day.html#pandas.PeriodIndex.day"}, {"function_name": "pandas.PeriodIndex.day_of_week", "full_function": "property PeriodIndex.day_of_week", "function_text": "The day of the week with Monday=0, Sunday=6.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.day_of_week.html#pandas.PeriodIndex.day_of_week"}, {"function_name": "pandas.PeriodIndex.day_of_year", "full_function": "property PeriodIndex.day_of_year", "function_text": "The ordinal day of the year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.day_of_year.html#pandas.PeriodIndex.day_of_year"}, {"function_name": "pandas.PeriodIndex.daysinmonth", "full_function": "property PeriodIndex.daysinmonth", "function_text": "The number of days in the month.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.daysinmonth.html#pandas.PeriodIndex.daysinmonth"}, {"function_name": "pandas.PeriodIndex.daysinmonth", "full_function": "property PeriodIndex.daysinmonth", "function_text": "The number of days in the month.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.daysinmonth.html#pandas.PeriodIndex.daysinmonth"}, {"function_name": "pandas.PeriodIndex.hour", "full_function": "property PeriodIndex.hour", "function_text": "The hour of the period.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.hour.html#pandas.PeriodIndex.hour"}, {"function_name": "pandas.PeriodIndex.minute", "full_function": "property PeriodIndex.minute", "function_text": "The minute of the period.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.minute.html#pandas.PeriodIndex.minute"}, {"function_name": "pandas.PeriodIndex.quarter", "full_function": "property PeriodIndex.quarter", "function_text": "The quarter of the date.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.quarter.html#pandas.PeriodIndex.quarter"}, {"function_name": "pandas.PeriodIndex.second", "full_function": "property PeriodIndex.second", "function_text": "The second of the period.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.second.html#pandas.PeriodIndex.second"}, {"function_name": "pandas.PeriodIndex.week", "full_function": "property PeriodIndex.week", "function_text": "The week ordinal of the year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.week.html#pandas.PeriodIndex.week"}, {"function_name": "pandas.PeriodIndex.weekofyear", "full_function": "property PeriodIndex.weekofyear", "function_text": "The week ordinal of the year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.weekofyear.html#pandas.PeriodIndex.weekofyear"}, {"function_name": "pandas.PeriodIndex.asfreq", "full_function": "PeriodIndex.asfreq(freq=None, how='E')", "function_text": "Convert the PeriodArray to the specified frequency freq.", "parameter_names_desc": [{"param_name": "freq", "param_type": "str", "param_desc": "A frequency.\n"}, {"param_name": "how", "param_type": "str {‘E’, ‘S’}, default ‘E’", "param_desc": "Whether the elements should be aligned to the end\nor start within pa period.\n\n‘E’, ‘END’, or ‘FINISH’ for end,\n‘S’, ‘START’, or ‘BEGIN’ for start.\n\nJanuary 31st (‘END’) vs. January 1st (‘START’) for example.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.asfreq.html#pandas.PeriodIndex.asfreq"}, {"function_name": "pandas.PeriodIndex.to_timestamp", "full_function": "PeriodIndex.to_timestamp(freq=None, how='start')", "function_text": "Cast to DatetimeArray/Index.", "parameter_names_desc": [{"param_name": "freq", "param_type": "str or DateOffset, optional", "param_desc": "Target frequency. The default is ‘D’ for week or longer,\n‘s’ otherwise.\n"}, {"param_name": "how", "param_type": "{‘s’, ‘e’, ‘start’, ‘end’}", "param_desc": "Whether to use the start or end of the time period being converted.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.to_timestamp.html#pandas.PeriodIndex.to_timestamp"}, {"function_name": "pandas.PeriodIndex.to_timestamp", "full_function": "PeriodIndex.to_timestamp(freq=None, how='start')", "function_text": "Cast to DatetimeArray/Index.", "parameter_names_desc": [{"param_name": "freq", "param_type": "str or DateOffset, optional", "param_desc": "Target frequency. The default is ‘D’ for week or longer,\n‘s’ otherwise.\n"}, {"param_name": "how", "param_type": "{‘s’, ‘e’, ‘start’, ‘end’}", "param_desc": "Whether to use the start or end of the time period being converted.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.to_timestamp.html#pandas.PeriodIndex.to_timestamp"}, {"function_name": "pandas.PeriodIndex.dayofweek", "full_function": "property PeriodIndex.dayofweek", "function_text": "The day of the week with Monday=0, Sunday=6.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.dayofweek.html#pandas.PeriodIndex.dayofweek"}, {"function_name": "pandas.PeriodIndex.dayofyear", "full_function": "property PeriodIndex.dayofyear", "function_text": "The ordinal day of the year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.dayofyear.html#pandas.PeriodIndex.dayofyear"}, {"function_name": "pandas.PeriodIndex.days_in_month", "full_function": "property PeriodIndex.days_in_month", "function_text": "The number of days in the month.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.days_in_month.html#pandas.PeriodIndex.days_in_month"}, {"function_name": "pandas.PeriodIndex.end_time", "full_function": "property PeriodIndex.end_time", "function_text": "Get the Timestamp for the end of the period.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.end_time.html#pandas.PeriodIndex.end_time"}, {"function_name": "pandas.PeriodIndex.freqstr", "full_function": "property PeriodIndex.freqstr", "function_text": "Return the frequency object as a string if it’s set, otherwise None.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.freqstr.html#pandas.PeriodIndex.freqstr"}, {"function_name": "pandas.PeriodIndex.is_leap_year", "full_function": "property PeriodIndex.is_leap_year", "function_text": "Logical indicating if the date belongs to a leap year.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.is_leap_year.html#pandas.PeriodIndex.is_leap_year"}, {"function_name": "pandas.PeriodIndex.month", "full_function": "property PeriodIndex.month", "function_text": "The month as January=1, December=12.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.month.html#pandas.PeriodIndex.month"}, {"function_name": "pandas.PeriodIndex.month", "full_function": "property PeriodIndex.month", "function_text": "The month as January=1, December=12.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.month.html#pandas.PeriodIndex.month"}, {"function_name": "pandas.PeriodIndex.start_time", "full_function": "property PeriodIndex.start_time", "function_text": "Get the Timestamp for the start of the period.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.start_time.html#pandas.PeriodIndex.start_time"}, {"function_name": "pandas.PeriodIndex.weekday", "full_function": "property PeriodIndex.weekday", "function_text": "The day of the week with Monday=0, Sunday=6.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.weekday.html#pandas.PeriodIndex.weekday"}, {"function_name": "pandas.PeriodIndex.year", "full_function": "property PeriodIndex.year", "function_text": "The year of the period.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.year.html#pandas.PeriodIndex.year"}, {"function_name": "pandas.PeriodIndex.strftime", "full_function": "PeriodIndex.strftime(*args, **kwargs)", "function_text": "Convert to Index using specified date_format.", "parameter_names_desc": [{"param_name": "date_format", "param_type": "str", "param_desc": "Date format string (e.g. “%Y-%m-%d”).\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.strftime.html#pandas.PeriodIndex.strftime"}, {"function_name": "pandas.PeriodIndex.strftime", "full_function": "PeriodIndex.strftime(*args, **kwargs)", "function_text": "Convert to Index using specified date_format.", "parameter_names_desc": [{"param_name": "date_format", "param_type": "str", "param_desc": "Date format string (e.g. “%Y-%m-%d”).\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.PeriodIndex.strftime.html#pandas.PeriodIndex.strftime"}]}], "name": "Index objects", "url": "https://pandas.pydata.org/docs/reference/indexing.html"}, "offset_frequency.html": {"functions": [{"name": "DateOffset", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#dateoffset", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.html#pandas.tseries.offsets.DateOffset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.freqstr.html#pandas.tseries.offsets.DateOffset.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.name.html#pandas.tseries.offsets.DateOffset.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.normalize.html#pandas.tseries.offsets.DateOffset.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.n.html#pandas.tseries.offsets.DateOffset.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.is_month_end.html#pandas.tseries.offsets.DateOffset.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.copy.html#pandas.tseries.offsets.DateOffset.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.is_on_offset.html#pandas.tseries.offsets.DateOffset.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.is_month_end.html#pandas.tseries.offsets.DateOffset.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.is_quarter_end.html#pandas.tseries.offsets.DateOffset.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.is_year_end.html#pandas.tseries.offsets.DateOffset.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.kwds.html#pandas.tseries.offsets.DateOffset.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.nanos.html#pandas.tseries.offsets.DateOffset.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.rule_code.html#pandas.tseries.offsets.DateOffset.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.is_month_start.html#pandas.tseries.offsets.DateOffset.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.is_anchored.html#pandas.tseries.offsets.DateOffset.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.is_month_start.html#pandas.tseries.offsets.DateOffset.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.is_quarter_start.html#pandas.tseries.offsets.DateOffset.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.is_year_start.html#pandas.tseries.offsets.DateOffset.is_year_start"], "function_definitions": [{"function_name": "pandas.tseries.offsets.DateOffset", "full_function": "class pandas.tseries.offsets.DateOffset#", "function_text": "Standard kind of date increment used for a date range.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of time periods the offset represents.\nIf specified without a temporal pattern, defaults to n days.\n"}, {"param_name": "normalize", "param_type": "bool, default False", "param_desc": "Whether to round the result of a DateOffset addition down to the\nprevious midnight.\n"}, {"param_name": "weekday", "param_type": "int {0, 1, …, 6}, default 0", "param_desc": "A specific integer for the day of the week.\n\n0 is Monday\n1 is Tuesday\n2 is Wednesday\n3 is Thursday\n4 is Friday\n5 is Saturday\n6 is Sunday\n\nInstead Weekday type from dateutil.relativedelta can be used.\n\nMO is Monday\nTU is Tuesday\nWE is Wednesday\nTH is Thursday\nFR is Friday\nSA is Saturday\nSU is Sunday.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.html#pandas.tseries.offsets.DateOffset"}, {"function_name": "pandas.tseries.offsets.DateOffset.freqstr", "full_function": "DateOffset.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.freqstr.html#pandas.tseries.offsets.DateOffset.freqstr"}, {"function_name": "pandas.tseries.offsets.DateOffset.name", "full_function": "DateOffset.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.name.html#pandas.tseries.offsets.DateOffset.name"}, {"function_name": "pandas.tseries.offsets.DateOffset.name", "full_function": "DateOffset.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.name.html#pandas.tseries.offsets.DateOffset.name"}, {"function_name": "pandas.tseries.offsets.DateOffset.name", "full_function": "DateOffset.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.name.html#pandas.tseries.offsets.DateOffset.name"}, {"function_name": "pandas.tseries.offsets.DateOffset.is_month_end", "full_function": "DateOffset.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.is_month_end.html#pandas.tseries.offsets.DateOffset.is_month_end"}, {"function_name": "pandas.tseries.offsets.DateOffset.copy", "full_function": "DateOffset.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.copy.html#pandas.tseries.offsets.DateOffset.copy"}, {"function_name": "pandas.tseries.offsets.DateOffset.is_on_offset", "full_function": "DateOffset.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.is_on_offset.html#pandas.tseries.offsets.DateOffset.is_on_offset"}, {"function_name": "pandas.tseries.offsets.DateOffset.is_month_end", "full_function": "DateOffset.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.is_month_end.html#pandas.tseries.offsets.DateOffset.is_month_end"}, {"function_name": "pandas.tseries.offsets.DateOffset.is_quarter_end", "full_function": "DateOffset.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.is_quarter_end.html#pandas.tseries.offsets.DateOffset.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.DateOffset.is_year_end", "full_function": "DateOffset.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.is_year_end.html#pandas.tseries.offsets.DateOffset.is_year_end"}, {"function_name": "pandas.tseries.offsets.DateOffset.kwds", "full_function": "DateOffset.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.kwds.html#pandas.tseries.offsets.DateOffset.kwds"}, {"function_name": "pandas.tseries.offsets.DateOffset.kwds", "full_function": "DateOffset.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.kwds.html#pandas.tseries.offsets.DateOffset.kwds"}, {"function_name": "pandas.tseries.offsets.DateOffset.kwds", "full_function": "DateOffset.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.kwds.html#pandas.tseries.offsets.DateOffset.kwds"}, {"function_name": "pandas.tseries.offsets.DateOffset.is_month_start", "full_function": "DateOffset.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.is_month_start.html#pandas.tseries.offsets.DateOffset.is_month_start"}, {"function_name": "pandas.tseries.offsets.DateOffset.is_anchored", "full_function": "DateOffset.is_anchored()#", "function_text": "Return boolean whether the frequency is a unit frequency (n=1).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.is_anchored.html#pandas.tseries.offsets.DateOffset.is_anchored"}, {"function_name": "pandas.tseries.offsets.DateOffset.is_month_start", "full_function": "DateOffset.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.is_month_start.html#pandas.tseries.offsets.DateOffset.is_month_start"}, {"function_name": "pandas.tseries.offsets.DateOffset.is_quarter_start", "full_function": "DateOffset.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.is_quarter_start.html#pandas.tseries.offsets.DateOffset.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.DateOffset.is_year_start", "full_function": "DateOffset.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.is_year_start.html#pandas.tseries.offsets.DateOffset.is_year_start"}]}, {"name": "BusinessDay", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#businessday", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.html#pandas.tseries.offsets.BusinessDay", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BDay.html#pandas.tseries.offsets.BDay", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.freqstr.html#pandas.tseries.offsets.BusinessDay.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.name.html#pandas.tseries.offsets.BusinessDay.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.normalize.html#pandas.tseries.offsets.BusinessDay.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.n.html#pandas.tseries.offsets.BusinessDay.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.holidays.html#pandas.tseries.offsets.BusinessDay.holidays", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.copy.html#pandas.tseries.offsets.BusinessDay.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.is_on_offset.html#pandas.tseries.offsets.BusinessDay.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.is_month_end.html#pandas.tseries.offsets.BusinessDay.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.is_quarter_end.html#pandas.tseries.offsets.BusinessDay.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.is_year_end.html#pandas.tseries.offsets.BusinessDay.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.kwds.html#pandas.tseries.offsets.BusinessDay.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.nanos.html#pandas.tseries.offsets.BusinessDay.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.rule_code.html#pandas.tseries.offsets.BusinessDay.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.weekmask.html#pandas.tseries.offsets.BusinessDay.weekmask", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.calendar.html#pandas.tseries.offsets.BusinessDay.calendar", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.is_anchored.html#pandas.tseries.offsets.BusinessDay.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.is_month_start.html#pandas.tseries.offsets.BusinessDay.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.is_quarter_start.html#pandas.tseries.offsets.BusinessDay.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.is_year_start.html#pandas.tseries.offsets.BusinessDay.is_year_start"], "function_definitions": [{"function_name": "pandas.tseries.offsets.BusinessDay", "full_function": "class pandas.tseries.offsets.BusinessDay#", "function_text": "DateOffset subclass representing possibly n business days.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of days represented.\n"}, {"param_name": "normalize", "param_type": "bool, default False", "param_desc": "Normalize start/end dates to midnight.\n"}, {"param_name": "offset", "param_type": "timedelta, default timedelta(0)", "param_desc": "Time offset to apply.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.html#pandas.tseries.offsets.BusinessDay"}, {"function_name": "pandas.tseries.offsets.BDay", "full_function": "pandas.tseries.offsets.BDay#", "function_text": "alias of BusinessDay", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BDay.html#pandas.tseries.offsets.BDay"}, {"function_name": "pandas.tseries.offsets.BusinessDay.freqstr", "full_function": "BusinessDay.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.freqstr.html#pandas.tseries.offsets.BusinessDay.freqstr"}, {"function_name": "pandas.tseries.offsets.BusinessDay.name", "full_function": "BusinessDay.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.name.html#pandas.tseries.offsets.BusinessDay.name"}, {"function_name": "pandas.tseries.offsets.BusinessDay.name", "full_function": "BusinessDay.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.name.html#pandas.tseries.offsets.BusinessDay.name"}, {"function_name": "pandas.tseries.offsets.BusinessDay.name", "full_function": "BusinessDay.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.name.html#pandas.tseries.offsets.BusinessDay.name"}, {"function_name": "pandas.tseries.offsets.BusinessDay.name", "full_function": "BusinessDay.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.name.html#pandas.tseries.offsets.BusinessDay.name"}, {"function_name": "pandas.tseries.offsets.BusinessDay.copy", "full_function": "BusinessDay.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.copy.html#pandas.tseries.offsets.BusinessDay.copy"}, {"function_name": "pandas.tseries.offsets.BusinessDay.is_on_offset", "full_function": "BusinessDay.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.is_on_offset.html#pandas.tseries.offsets.BusinessDay.is_on_offset"}, {"function_name": "pandas.tseries.offsets.BusinessDay.is_month_end", "full_function": "BusinessDay.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.is_month_end.html#pandas.tseries.offsets.BusinessDay.is_month_end"}, {"function_name": "pandas.tseries.offsets.BusinessDay.is_quarter_end", "full_function": "BusinessDay.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.is_quarter_end.html#pandas.tseries.offsets.BusinessDay.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.BusinessDay.is_year_end", "full_function": "BusinessDay.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.is_year_end.html#pandas.tseries.offsets.BusinessDay.is_year_end"}, {"function_name": "pandas.tseries.offsets.BusinessDay.kwds", "full_function": "BusinessDay.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.kwds.html#pandas.tseries.offsets.BusinessDay.kwds"}, {"function_name": "pandas.tseries.offsets.BusinessDay.kwds", "full_function": "BusinessDay.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.kwds.html#pandas.tseries.offsets.BusinessDay.kwds"}, {"function_name": "pandas.tseries.offsets.BusinessDay.kwds", "full_function": "BusinessDay.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.kwds.html#pandas.tseries.offsets.BusinessDay.kwds"}, {"function_name": "pandas.tseries.offsets.BusinessDay.kwds", "full_function": "BusinessDay.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.kwds.html#pandas.tseries.offsets.BusinessDay.kwds"}, {"function_name": "pandas.tseries.offsets.BusinessDay.kwds", "full_function": "BusinessDay.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.kwds.html#pandas.tseries.offsets.BusinessDay.kwds"}, {"function_name": "pandas.tseries.offsets.BusinessDay.is_anchored", "full_function": "BusinessDay.is_anchored()#", "function_text": "Return boolean whether the frequency is a unit frequency (n=1).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.is_anchored.html#pandas.tseries.offsets.BusinessDay.is_anchored"}, {"function_name": "pandas.tseries.offsets.BusinessDay.is_month_start", "full_function": "BusinessDay.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.is_month_start.html#pandas.tseries.offsets.BusinessDay.is_month_start"}, {"function_name": "pandas.tseries.offsets.BusinessDay.is_quarter_start", "full_function": "BusinessDay.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.is_quarter_start.html#pandas.tseries.offsets.BusinessDay.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.BusinessDay.is_year_start", "full_function": "BusinessDay.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessDay.is_year_start.html#pandas.tseries.offsets.BusinessDay.is_year_start"}]}, {"name": "BusinessHour", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#businesshour", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.html#pandas.tseries.offsets.BusinessHour", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.freqstr.html#pandas.tseries.offsets.BusinessHour.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.name.html#pandas.tseries.offsets.BusinessHour.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.normalize.html#pandas.tseries.offsets.BusinessHour.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.n.html#pandas.tseries.offsets.BusinessHour.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.end.html#pandas.tseries.offsets.BusinessHour.end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.holidays.html#pandas.tseries.offsets.BusinessHour.holidays", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.copy.html#pandas.tseries.offsets.BusinessHour.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.is_on_offset.html#pandas.tseries.offsets.BusinessHour.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.is_month_end.html#pandas.tseries.offsets.BusinessHour.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.is_quarter_end.html#pandas.tseries.offsets.BusinessHour.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.is_year_end.html#pandas.tseries.offsets.BusinessHour.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.kwds.html#pandas.tseries.offsets.BusinessHour.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.nanos.html#pandas.tseries.offsets.BusinessHour.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.rule_code.html#pandas.tseries.offsets.BusinessHour.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.start.html#pandas.tseries.offsets.BusinessHour.start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.weekmask.html#pandas.tseries.offsets.BusinessHour.weekmask", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.calendar.html#pandas.tseries.offsets.BusinessHour.calendar", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.is_anchored.html#pandas.tseries.offsets.BusinessHour.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.is_month_start.html#pandas.tseries.offsets.BusinessHour.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.is_quarter_start.html#pandas.tseries.offsets.BusinessHour.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.is_year_start.html#pandas.tseries.offsets.BusinessHour.is_year_start"], "function_definitions": [{"function_name": "pandas.tseries.offsets.BusinessHour", "full_function": "class pandas.tseries.offsets.BusinessHour#", "function_text": "DateOffset subclass representing possibly n business hours.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of hours represented.\n"}, {"param_name": "normalize", "param_type": "bool, default False", "param_desc": "Normalize start/end dates to midnight before generating date range.\n"}, {"param_name": "start", "param_type": "str, time, or list of str/time, default “09:00”", "param_desc": "Start time of your custom business hour in 24h format.\n"}, {"param_name": "end", "param_type": "str, time, or list of str/time, default: “17:00”", "param_desc": "End time of your custom business hour in 24h format.\n"}, {"param_name": "offset", "param_type": "timedelta, default timedelta(0)", "param_desc": "Time offset to apply.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.html#pandas.tseries.offsets.BusinessHour"}, {"function_name": "pandas.tseries.offsets.BusinessHour.freqstr", "full_function": "BusinessHour.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.freqstr.html#pandas.tseries.offsets.BusinessHour.freqstr"}, {"function_name": "pandas.tseries.offsets.BusinessHour.name", "full_function": "BusinessHour.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.name.html#pandas.tseries.offsets.BusinessHour.name"}, {"function_name": "pandas.tseries.offsets.BusinessHour.name", "full_function": "BusinessHour.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.name.html#pandas.tseries.offsets.BusinessHour.name"}, {"function_name": "pandas.tseries.offsets.BusinessHour.name", "full_function": "BusinessHour.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.name.html#pandas.tseries.offsets.BusinessHour.name"}, {"function_name": "pandas.tseries.offsets.BusinessHour.name", "full_function": "BusinessHour.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.name.html#pandas.tseries.offsets.BusinessHour.name"}, {"function_name": "pandas.tseries.offsets.BusinessHour.name", "full_function": "BusinessHour.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.name.html#pandas.tseries.offsets.BusinessHour.name"}, {"function_name": "pandas.tseries.offsets.BusinessHour.copy", "full_function": "BusinessHour.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.copy.html#pandas.tseries.offsets.BusinessHour.copy"}, {"function_name": "pandas.tseries.offsets.BusinessHour.is_on_offset", "full_function": "BusinessHour.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.is_on_offset.html#pandas.tseries.offsets.BusinessHour.is_on_offset"}, {"function_name": "pandas.tseries.offsets.BusinessHour.is_month_end", "full_function": "BusinessHour.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.is_month_end.html#pandas.tseries.offsets.BusinessHour.is_month_end"}, {"function_name": "pandas.tseries.offsets.BusinessHour.is_quarter_end", "full_function": "BusinessHour.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.is_quarter_end.html#pandas.tseries.offsets.BusinessHour.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.BusinessHour.is_year_end", "full_function": "BusinessHour.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.is_year_end.html#pandas.tseries.offsets.BusinessHour.is_year_end"}, {"function_name": "pandas.tseries.offsets.BusinessHour.kwds", "full_function": "BusinessHour.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.kwds.html#pandas.tseries.offsets.BusinessHour.kwds"}, {"function_name": "pandas.tseries.offsets.BusinessHour.kwds", "full_function": "BusinessHour.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.kwds.html#pandas.tseries.offsets.BusinessHour.kwds"}, {"function_name": "pandas.tseries.offsets.BusinessHour.kwds", "full_function": "BusinessHour.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.kwds.html#pandas.tseries.offsets.BusinessHour.kwds"}, {"function_name": "pandas.tseries.offsets.BusinessHour.kwds", "full_function": "BusinessHour.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.kwds.html#pandas.tseries.offsets.BusinessHour.kwds"}, {"function_name": "pandas.tseries.offsets.BusinessHour.kwds", "full_function": "BusinessHour.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.kwds.html#pandas.tseries.offsets.BusinessHour.kwds"}, {"function_name": "pandas.tseries.offsets.BusinessHour.kwds", "full_function": "BusinessHour.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.kwds.html#pandas.tseries.offsets.BusinessHour.kwds"}, {"function_name": "pandas.tseries.offsets.BusinessHour.is_anchored", "full_function": "BusinessHour.is_anchored()#", "function_text": "Return boolean whether the frequency is a unit frequency (n=1).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.is_anchored.html#pandas.tseries.offsets.BusinessHour.is_anchored"}, {"function_name": "pandas.tseries.offsets.BusinessHour.is_month_start", "full_function": "BusinessHour.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.is_month_start.html#pandas.tseries.offsets.BusinessHour.is_month_start"}, {"function_name": "pandas.tseries.offsets.BusinessHour.is_quarter_start", "full_function": "BusinessHour.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.is_quarter_start.html#pandas.tseries.offsets.BusinessHour.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.BusinessHour.is_year_start", "full_function": "BusinessHour.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessHour.is_year_start.html#pandas.tseries.offsets.BusinessHour.is_year_start"}]}, {"name": "CustomBusinessDay", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#custombusinessday", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.html#pandas.tseries.offsets.CustomBusinessDay", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CDay.html#pandas.tseries.offsets.CDay", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.freqstr.html#pandas.tseries.offsets.CustomBusinessDay.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.name.html#pandas.tseries.offsets.CustomBusinessDay.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.normalize.html#pandas.tseries.offsets.CustomBusinessDay.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.n.html#pandas.tseries.offsets.CustomBusinessDay.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.calendar.html#pandas.tseries.offsets.CustomBusinessDay.calendar", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.copy.html#pandas.tseries.offsets.CustomBusinessDay.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.is_on_offset.html#pandas.tseries.offsets.CustomBusinessDay.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.is_month_end.html#pandas.tseries.offsets.CustomBusinessDay.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.is_quarter_end.html#pandas.tseries.offsets.CustomBusinessDay.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.is_year_end.html#pandas.tseries.offsets.CustomBusinessDay.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.kwds.html#pandas.tseries.offsets.CustomBusinessDay.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.nanos.html#pandas.tseries.offsets.CustomBusinessDay.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.rule_code.html#pandas.tseries.offsets.CustomBusinessDay.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.weekmask.html#pandas.tseries.offsets.CustomBusinessDay.weekmask", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.holidays.html#pandas.tseries.offsets.CustomBusinessDay.holidays", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.is_anchored.html#pandas.tseries.offsets.CustomBusinessDay.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.is_month_start.html#pandas.tseries.offsets.CustomBusinessDay.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.is_quarter_start.html#pandas.tseries.offsets.CustomBusinessDay.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.is_year_start.html#pandas.tseries.offsets.CustomBusinessDay.is_year_start"], "function_definitions": [{"function_name": "pandas.tseries.offsets.CustomBusinessDay", "full_function": "class pandas.tseries.offsets.CustomBusinessDay#", "function_text": "DateOffset subclass representing possibly n custom business days.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of days represented.\n"}, {"param_name": "normalize", "param_type": "bool, default False", "param_desc": "Normalize start/end dates to midnight before generating date range.\n"}, {"param_name": "weekmask", "param_type": "str, Default ‘Mon Tue Wed Thu Fri’", "param_desc": "Weekmask of valid business days, passed to numpy.busdaycalendar.\n"}, {"param_name": "holidays", "param_type": "list", "param_desc": "List/array of dates to exclude from the set of valid business days,\npassed to numpy.busdaycalendar.\n"}, {"param_name": "calendar", "param_type": "np.busdaycalendar", "param_desc": "Calendar to integrate.\n"}, {"param_name": "offset", "param_type": "timedelta, default timedelta(0)", "param_desc": "Time offset to apply.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.html#pandas.tseries.offsets.CustomBusinessDay"}, {"function_name": "pandas.tseries.offsets.CDay", "full_function": "pandas.tseries.offsets.CDay#", "function_text": "alias of CustomBusinessDay", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CDay.html#pandas.tseries.offsets.CDay"}, {"function_name": "pandas.tseries.offsets.CustomBusinessDay.freqstr", "full_function": "CustomBusinessDay.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.freqstr.html#pandas.tseries.offsets.CustomBusinessDay.freqstr"}, {"function_name": "pandas.tseries.offsets.CustomBusinessDay.name", "full_function": "CustomBusinessDay.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.name.html#pandas.tseries.offsets.CustomBusinessDay.name"}, {"function_name": "pandas.tseries.offsets.CustomBusinessDay.name", "full_function": "CustomBusinessDay.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.name.html#pandas.tseries.offsets.CustomBusinessDay.name"}, {"function_name": "pandas.tseries.offsets.CustomBusinessDay.name", "full_function": "CustomBusinessDay.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.name.html#pandas.tseries.offsets.CustomBusinessDay.name"}, {"function_name": "pandas.tseries.offsets.CustomBusinessDay.name", "full_function": "CustomBusinessDay.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.name.html#pandas.tseries.offsets.CustomBusinessDay.name"}, {"function_name": "pandas.tseries.offsets.CustomBusinessDay.copy", "full_function": "CustomBusinessDay.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.copy.html#pandas.tseries.offsets.CustomBusinessDay.copy"}, {"function_name": "pandas.tseries.offsets.CustomBusinessDay.is_on_offset", "full_function": "CustomBusinessDay.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.is_on_offset.html#pandas.tseries.offsets.CustomBusinessDay.is_on_offset"}, {"function_name": "pandas.tseries.offsets.CustomBusinessDay.is_month_end", "full_function": "CustomBusinessDay.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.is_month_end.html#pandas.tseries.offsets.CustomBusinessDay.is_month_end"}, {"function_name": "pandas.tseries.offsets.CustomBusinessDay.is_quarter_end", "full_function": "CustomBusinessDay.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.is_quarter_end.html#pandas.tseries.offsets.CustomBusinessDay.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.CustomBusinessDay.is_year_end", "full_function": "CustomBusinessDay.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.is_year_end.html#pandas.tseries.offsets.CustomBusinessDay.is_year_end"}, {"function_name": "pandas.tseries.offsets.CustomBusinessDay.kwds", "full_function": "CustomBusinessDay.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.kwds.html#pandas.tseries.offsets.CustomBusinessDay.kwds"}, {"function_name": "pandas.tseries.offsets.CustomBusinessDay.kwds", "full_function": "CustomBusinessDay.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.kwds.html#pandas.tseries.offsets.CustomBusinessDay.kwds"}, {"function_name": "pandas.tseries.offsets.CustomBusinessDay.kwds", "full_function": "CustomBusinessDay.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.kwds.html#pandas.tseries.offsets.CustomBusinessDay.kwds"}, {"function_name": "pandas.tseries.offsets.CustomBusinessDay.kwds", "full_function": "CustomBusinessDay.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.kwds.html#pandas.tseries.offsets.CustomBusinessDay.kwds"}, {"function_name": "pandas.tseries.offsets.CustomBusinessDay.kwds", "full_function": "CustomBusinessDay.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.kwds.html#pandas.tseries.offsets.CustomBusinessDay.kwds"}, {"function_name": "pandas.tseries.offsets.CustomBusinessDay.is_anchored", "full_function": "CustomBusinessDay.is_anchored()#", "function_text": "Return boolean whether the frequency is a unit frequency (n=1).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.is_anchored.html#pandas.tseries.offsets.CustomBusinessDay.is_anchored"}, {"function_name": "pandas.tseries.offsets.CustomBusinessDay.is_month_start", "full_function": "CustomBusinessDay.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.is_month_start.html#pandas.tseries.offsets.CustomBusinessDay.is_month_start"}, {"function_name": "pandas.tseries.offsets.CustomBusinessDay.is_quarter_start", "full_function": "CustomBusinessDay.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.is_quarter_start.html#pandas.tseries.offsets.CustomBusinessDay.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.CustomBusinessDay.is_year_start", "full_function": "CustomBusinessDay.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessDay.is_year_start.html#pandas.tseries.offsets.CustomBusinessDay.is_year_start"}]}, {"name": "CustomBusinessHour", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#custombusinesshour", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.html#pandas.tseries.offsets.CustomBusinessHour", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.freqstr.html#pandas.tseries.offsets.CustomBusinessHour.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.name.html#pandas.tseries.offsets.CustomBusinessHour.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.normalize.html#pandas.tseries.offsets.CustomBusinessHour.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.n.html#pandas.tseries.offsets.CustomBusinessHour.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.calendar.html#pandas.tseries.offsets.CustomBusinessHour.calendar", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.start.html#pandas.tseries.offsets.CustomBusinessHour.start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.copy.html#pandas.tseries.offsets.CustomBusinessHour.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.is_on_offset.html#pandas.tseries.offsets.CustomBusinessHour.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.is_month_end.html#pandas.tseries.offsets.CustomBusinessHour.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.is_quarter_end.html#pandas.tseries.offsets.CustomBusinessHour.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.is_year_end.html#pandas.tseries.offsets.CustomBusinessHour.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.kwds.html#pandas.tseries.offsets.CustomBusinessHour.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.nanos.html#pandas.tseries.offsets.CustomBusinessHour.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.rule_code.html#pandas.tseries.offsets.CustomBusinessHour.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.weekmask.html#pandas.tseries.offsets.CustomBusinessHour.weekmask", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.holidays.html#pandas.tseries.offsets.CustomBusinessHour.holidays", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.end.html#pandas.tseries.offsets.CustomBusinessHour.end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.is_anchored.html#pandas.tseries.offsets.CustomBusinessHour.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.is_month_start.html#pandas.tseries.offsets.CustomBusinessHour.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.is_quarter_start.html#pandas.tseries.offsets.CustomBusinessHour.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.is_year_start.html#pandas.tseries.offsets.CustomBusinessHour.is_year_start"], "function_definitions": [{"function_name": "pandas.tseries.offsets.CustomBusinessHour", "full_function": "class pandas.tseries.offsets.CustomBusinessHour#", "function_text": "DateOffset subclass representing possibly n custom business days.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of hours represented.\n"}, {"param_name": "normalize", "param_type": "bool, default False", "param_desc": "Normalize start/end dates to midnight before generating date range.\n"}, {"param_name": "weekmask", "param_type": "str, Default ‘Mon Tue Wed Thu Fri’", "param_desc": "Weekmask of valid business days, passed to numpy.busdaycalendar.\n"}, {"param_name": "holidays", "param_type": "list", "param_desc": "List/array of dates to exclude from the set of valid business days,\npassed to numpy.busdaycalendar.\n"}, {"param_name": "calendar", "param_type": "np.busdaycalendar", "param_desc": "Calendar to integrate.\n"}, {"param_name": "start", "param_type": "str, time, or list of str/time, default “09:00”", "param_desc": "Start time of your custom business hour in 24h format.\n"}, {"param_name": "end", "param_type": "str, time, or list of str/time, default: “17:00”", "param_desc": "End time of your custom business hour in 24h format.\n"}, {"param_name": "offset", "param_type": "timedelta, default timedelta(0)", "param_desc": "Time offset to apply.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.html#pandas.tseries.offsets.CustomBusinessHour"}, {"function_name": "pandas.tseries.offsets.CustomBusinessHour.freqstr", "full_function": "CustomBusinessHour.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.freqstr.html#pandas.tseries.offsets.CustomBusinessHour.freqstr"}, {"function_name": "pandas.tseries.offsets.CustomBusinessHour.name", "full_function": "CustomBusinessHour.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.name.html#pandas.tseries.offsets.CustomBusinessHour.name"}, {"function_name": "pandas.tseries.offsets.CustomBusinessHour.name", "full_function": "CustomBusinessHour.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.name.html#pandas.tseries.offsets.CustomBusinessHour.name"}, {"function_name": "pandas.tseries.offsets.CustomBusinessHour.name", "full_function": "CustomBusinessHour.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.name.html#pandas.tseries.offsets.CustomBusinessHour.name"}, {"function_name": "pandas.tseries.offsets.CustomBusinessHour.name", "full_function": "CustomBusinessHour.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.name.html#pandas.tseries.offsets.CustomBusinessHour.name"}, {"function_name": "pandas.tseries.offsets.CustomBusinessHour.name", "full_function": "CustomBusinessHour.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.name.html#pandas.tseries.offsets.CustomBusinessHour.name"}, {"function_name": "pandas.tseries.offsets.CustomBusinessHour.copy", "full_function": "CustomBusinessHour.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.copy.html#pandas.tseries.offsets.CustomBusinessHour.copy"}, {"function_name": "pandas.tseries.offsets.CustomBusinessHour.is_on_offset", "full_function": "CustomBusinessHour.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.is_on_offset.html#pandas.tseries.offsets.CustomBusinessHour.is_on_offset"}, {"function_name": "pandas.tseries.offsets.CustomBusinessHour.is_month_end", "full_function": "CustomBusinessHour.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.is_month_end.html#pandas.tseries.offsets.CustomBusinessHour.is_month_end"}, {"function_name": "pandas.tseries.offsets.CustomBusinessHour.is_quarter_end", "full_function": "CustomBusinessHour.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.is_quarter_end.html#pandas.tseries.offsets.CustomBusinessHour.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.CustomBusinessHour.is_year_end", "full_function": "CustomBusinessHour.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.is_year_end.html#pandas.tseries.offsets.CustomBusinessHour.is_year_end"}, {"function_name": "pandas.tseries.offsets.CustomBusinessHour.kwds", "full_function": "CustomBusinessHour.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.kwds.html#pandas.tseries.offsets.CustomBusinessHour.kwds"}, {"function_name": "pandas.tseries.offsets.CustomBusinessHour.kwds", "full_function": "CustomBusinessHour.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.kwds.html#pandas.tseries.offsets.CustomBusinessHour.kwds"}, {"function_name": "pandas.tseries.offsets.CustomBusinessHour.kwds", "full_function": "CustomBusinessHour.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.kwds.html#pandas.tseries.offsets.CustomBusinessHour.kwds"}, {"function_name": "pandas.tseries.offsets.CustomBusinessHour.kwds", "full_function": "CustomBusinessHour.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.kwds.html#pandas.tseries.offsets.CustomBusinessHour.kwds"}, {"function_name": "pandas.tseries.offsets.CustomBusinessHour.kwds", "full_function": "CustomBusinessHour.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.kwds.html#pandas.tseries.offsets.CustomBusinessHour.kwds"}, {"function_name": "pandas.tseries.offsets.CustomBusinessHour.kwds", "full_function": "CustomBusinessHour.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.kwds.html#pandas.tseries.offsets.CustomBusinessHour.kwds"}, {"function_name": "pandas.tseries.offsets.CustomBusinessHour.is_anchored", "full_function": "CustomBusinessHour.is_anchored()#", "function_text": "Return boolean whether the frequency is a unit frequency (n=1).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.is_anchored.html#pandas.tseries.offsets.CustomBusinessHour.is_anchored"}, {"function_name": "pandas.tseries.offsets.CustomBusinessHour.is_month_start", "full_function": "CustomBusinessHour.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.is_month_start.html#pandas.tseries.offsets.CustomBusinessHour.is_month_start"}, {"function_name": "pandas.tseries.offsets.CustomBusinessHour.is_quarter_start", "full_function": "CustomBusinessHour.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.is_quarter_start.html#pandas.tseries.offsets.CustomBusinessHour.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.CustomBusinessHour.is_year_start", "full_function": "CustomBusinessHour.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessHour.is_year_start.html#pandas.tseries.offsets.CustomBusinessHour.is_year_start"}]}, {"name": "MonthEnd", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#monthend", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.html#pandas.tseries.offsets.MonthEnd", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.freqstr.html#pandas.tseries.offsets.MonthEnd.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.name.html#pandas.tseries.offsets.MonthEnd.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.normalize.html#pandas.tseries.offsets.MonthEnd.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.n.html#pandas.tseries.offsets.MonthEnd.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.copy.html#pandas.tseries.offsets.MonthEnd.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.is_on_offset.html#pandas.tseries.offsets.MonthEnd.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.is_month_end.html#pandas.tseries.offsets.MonthEnd.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.is_quarter_end.html#pandas.tseries.offsets.MonthEnd.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.is_year_end.html#pandas.tseries.offsets.MonthEnd.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.kwds.html#pandas.tseries.offsets.MonthEnd.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.nanos.html#pandas.tseries.offsets.MonthEnd.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.rule_code.html#pandas.tseries.offsets.MonthEnd.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.is_anchored.html#pandas.tseries.offsets.MonthEnd.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.is_month_start.html#pandas.tseries.offsets.MonthEnd.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.is_quarter_start.html#pandas.tseries.offsets.MonthEnd.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.is_year_start.html#pandas.tseries.offsets.MonthEnd.is_year_start"], "function_definitions": [{"function_name": "pandas.tseries.offsets.MonthEnd", "full_function": "class pandas.tseries.offsets.MonthEnd#", "function_text": "DateOffset of one month end.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of months represented.\n"}, {"param_name": "normalize", "param_type": "bool, default False", "param_desc": "Normalize start/end dates to midnight before generating date range.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.html#pandas.tseries.offsets.MonthEnd"}, {"function_name": "pandas.tseries.offsets.MonthEnd.freqstr", "full_function": "MonthEnd.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.freqstr.html#pandas.tseries.offsets.MonthEnd.freqstr"}, {"function_name": "pandas.tseries.offsets.MonthEnd.name", "full_function": "MonthEnd.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.name.html#pandas.tseries.offsets.MonthEnd.name"}, {"function_name": "pandas.tseries.offsets.MonthEnd.name", "full_function": "MonthEnd.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.name.html#pandas.tseries.offsets.MonthEnd.name"}, {"function_name": "pandas.tseries.offsets.MonthEnd.name", "full_function": "MonthEnd.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.name.html#pandas.tseries.offsets.MonthEnd.name"}, {"function_name": "pandas.tseries.offsets.MonthEnd.copy", "full_function": "MonthEnd.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.copy.html#pandas.tseries.offsets.MonthEnd.copy"}, {"function_name": "pandas.tseries.offsets.MonthEnd.is_on_offset", "full_function": "MonthEnd.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.is_on_offset.html#pandas.tseries.offsets.MonthEnd.is_on_offset"}, {"function_name": "pandas.tseries.offsets.MonthEnd.is_month_end", "full_function": "MonthEnd.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.is_month_end.html#pandas.tseries.offsets.MonthEnd.is_month_end"}, {"function_name": "pandas.tseries.offsets.MonthEnd.is_quarter_end", "full_function": "MonthEnd.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.is_quarter_end.html#pandas.tseries.offsets.MonthEnd.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.MonthEnd.is_year_end", "full_function": "MonthEnd.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.is_year_end.html#pandas.tseries.offsets.MonthEnd.is_year_end"}, {"function_name": "pandas.tseries.offsets.MonthEnd.kwds", "full_function": "MonthEnd.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.kwds.html#pandas.tseries.offsets.MonthEnd.kwds"}, {"function_name": "pandas.tseries.offsets.MonthEnd.kwds", "full_function": "MonthEnd.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.kwds.html#pandas.tseries.offsets.MonthEnd.kwds"}, {"function_name": "pandas.tseries.offsets.MonthEnd.kwds", "full_function": "MonthEnd.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.kwds.html#pandas.tseries.offsets.MonthEnd.kwds"}, {"function_name": "pandas.tseries.offsets.MonthEnd.is_anchored", "full_function": "MonthEnd.is_anchored()#", "function_text": "Return boolean whether the frequency is a unit frequency (n=1).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.is_anchored.html#pandas.tseries.offsets.MonthEnd.is_anchored"}, {"function_name": "pandas.tseries.offsets.MonthEnd.is_month_start", "full_function": "MonthEnd.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.is_month_start.html#pandas.tseries.offsets.MonthEnd.is_month_start"}, {"function_name": "pandas.tseries.offsets.MonthEnd.is_quarter_start", "full_function": "MonthEnd.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.is_quarter_start.html#pandas.tseries.offsets.MonthEnd.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.MonthEnd.is_year_start", "full_function": "MonthEnd.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthEnd.is_year_start.html#pandas.tseries.offsets.MonthEnd.is_year_start"}]}, {"name": "MonthBegin", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#monthbegin", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.html#pandas.tseries.offsets.MonthBegin", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.freqstr.html#pandas.tseries.offsets.MonthBegin.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.name.html#pandas.tseries.offsets.MonthBegin.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.normalize.html#pandas.tseries.offsets.MonthBegin.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.n.html#pandas.tseries.offsets.MonthBegin.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.copy.html#pandas.tseries.offsets.MonthBegin.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.is_on_offset.html#pandas.tseries.offsets.MonthBegin.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.is_month_end.html#pandas.tseries.offsets.MonthBegin.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.is_quarter_end.html#pandas.tseries.offsets.MonthBegin.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.is_year_end.html#pandas.tseries.offsets.MonthBegin.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.kwds.html#pandas.tseries.offsets.MonthBegin.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.nanos.html#pandas.tseries.offsets.MonthBegin.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.rule_code.html#pandas.tseries.offsets.MonthBegin.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.is_anchored.html#pandas.tseries.offsets.MonthBegin.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.is_month_start.html#pandas.tseries.offsets.MonthBegin.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.is_quarter_start.html#pandas.tseries.offsets.MonthBegin.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.is_year_start.html#pandas.tseries.offsets.MonthBegin.is_year_start"], "function_definitions": [{"function_name": "pandas.tseries.offsets.MonthBegin", "full_function": "class pandas.tseries.offsets.MonthBegin#", "function_text": "DateOffset of one month at beginning.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of months represented.\n"}, {"param_name": "normalize", "param_type": "bool, default False", "param_desc": "Normalize start/end dates to midnight before generating date range.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.html#pandas.tseries.offsets.MonthBegin"}, {"function_name": "pandas.tseries.offsets.MonthBegin.freqstr", "full_function": "MonthBegin.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.freqstr.html#pandas.tseries.offsets.MonthBegin.freqstr"}, {"function_name": "pandas.tseries.offsets.MonthBegin.name", "full_function": "MonthBegin.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.name.html#pandas.tseries.offsets.MonthBegin.name"}, {"function_name": "pandas.tseries.offsets.MonthBegin.name", "full_function": "MonthBegin.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.name.html#pandas.tseries.offsets.MonthBegin.name"}, {"function_name": "pandas.tseries.offsets.MonthBegin.name", "full_function": "MonthBegin.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.name.html#pandas.tseries.offsets.MonthBegin.name"}, {"function_name": "pandas.tseries.offsets.MonthBegin.copy", "full_function": "MonthBegin.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.copy.html#pandas.tseries.offsets.MonthBegin.copy"}, {"function_name": "pandas.tseries.offsets.MonthBegin.is_on_offset", "full_function": "MonthBegin.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.is_on_offset.html#pandas.tseries.offsets.MonthBegin.is_on_offset"}, {"function_name": "pandas.tseries.offsets.MonthBegin.is_month_end", "full_function": "MonthBegin.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.is_month_end.html#pandas.tseries.offsets.MonthBegin.is_month_end"}, {"function_name": "pandas.tseries.offsets.MonthBegin.is_quarter_end", "full_function": "MonthBegin.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.is_quarter_end.html#pandas.tseries.offsets.MonthBegin.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.MonthBegin.is_year_end", "full_function": "MonthBegin.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.is_year_end.html#pandas.tseries.offsets.MonthBegin.is_year_end"}, {"function_name": "pandas.tseries.offsets.MonthBegin.kwds", "full_function": "MonthBegin.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.kwds.html#pandas.tseries.offsets.MonthBegin.kwds"}, {"function_name": "pandas.tseries.offsets.MonthBegin.kwds", "full_function": "MonthBegin.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.kwds.html#pandas.tseries.offsets.MonthBegin.kwds"}, {"function_name": "pandas.tseries.offsets.MonthBegin.kwds", "full_function": "MonthBegin.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.kwds.html#pandas.tseries.offsets.MonthBegin.kwds"}, {"function_name": "pandas.tseries.offsets.MonthBegin.is_anchored", "full_function": "MonthBegin.is_anchored()#", "function_text": "Return boolean whether the frequency is a unit frequency (n=1).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.is_anchored.html#pandas.tseries.offsets.MonthBegin.is_anchored"}, {"function_name": "pandas.tseries.offsets.MonthBegin.is_month_start", "full_function": "MonthBegin.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.is_month_start.html#pandas.tseries.offsets.MonthBegin.is_month_start"}, {"function_name": "pandas.tseries.offsets.MonthBegin.is_quarter_start", "full_function": "MonthBegin.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.is_quarter_start.html#pandas.tseries.offsets.MonthBegin.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.MonthBegin.is_year_start", "full_function": "MonthBegin.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.MonthBegin.is_year_start.html#pandas.tseries.offsets.MonthBegin.is_year_start"}]}, {"name": "BusinessMonthEnd", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#businessmonthend", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.html#pandas.tseries.offsets.BusinessMonthEnd", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BMonthEnd.html#pandas.tseries.offsets.BMonthEnd", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.freqstr.html#pandas.tseries.offsets.BusinessMonthEnd.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.name.html#pandas.tseries.offsets.BusinessMonthEnd.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.normalize.html#pandas.tseries.offsets.BusinessMonthEnd.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.n.html#pandas.tseries.offsets.BusinessMonthEnd.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.copy.html#pandas.tseries.offsets.BusinessMonthEnd.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.is_on_offset.html#pandas.tseries.offsets.BusinessMonthEnd.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.is_month_end.html#pandas.tseries.offsets.BusinessMonthEnd.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.is_quarter_end.html#pandas.tseries.offsets.BusinessMonthEnd.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.is_year_end.html#pandas.tseries.offsets.BusinessMonthEnd.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.kwds.html#pandas.tseries.offsets.BusinessMonthEnd.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.nanos.html#pandas.tseries.offsets.BusinessMonthEnd.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.rule_code.html#pandas.tseries.offsets.BusinessMonthEnd.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.is_anchored.html#pandas.tseries.offsets.BusinessMonthEnd.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.is_month_start.html#pandas.tseries.offsets.BusinessMonthEnd.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.is_quarter_start.html#pandas.tseries.offsets.BusinessMonthEnd.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.is_year_start.html#pandas.tseries.offsets.BusinessMonthEnd.is_year_start"], "function_definitions": [{"function_name": "pandas.tseries.offsets.BusinessMonthEnd", "full_function": "class pandas.tseries.offsets.BusinessMonthEnd#", "function_text": "DateOffset increments between the last business day of the month.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of months represented.\n"}, {"param_name": "normalize", "param_type": "bool, default False", "param_desc": "Normalize start/end dates to midnight before generating date range.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.html#pandas.tseries.offsets.BusinessMonthEnd"}, {"function_name": "pandas.tseries.offsets.BMonthEnd", "full_function": "pandas.tseries.offsets.BMonthEnd#", "function_text": "alias of BusinessMonthEnd", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BMonthEnd.html#pandas.tseries.offsets.BMonthEnd"}, {"function_name": "pandas.tseries.offsets.BusinessMonthEnd.freqstr", "full_function": "BusinessMonthEnd.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.freqstr.html#pandas.tseries.offsets.BusinessMonthEnd.freqstr"}, {"function_name": "pandas.tseries.offsets.BusinessMonthEnd.name", "full_function": "BusinessMonthEnd.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.name.html#pandas.tseries.offsets.BusinessMonthEnd.name"}, {"function_name": "pandas.tseries.offsets.BusinessMonthEnd.name", "full_function": "BusinessMonthEnd.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.name.html#pandas.tseries.offsets.BusinessMonthEnd.name"}, {"function_name": "pandas.tseries.offsets.BusinessMonthEnd.name", "full_function": "BusinessMonthEnd.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.name.html#pandas.tseries.offsets.BusinessMonthEnd.name"}, {"function_name": "pandas.tseries.offsets.BusinessMonthEnd.copy", "full_function": "BusinessMonthEnd.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.copy.html#pandas.tseries.offsets.BusinessMonthEnd.copy"}, {"function_name": "pandas.tseries.offsets.BusinessMonthEnd.is_on_offset", "full_function": "BusinessMonthEnd.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.is_on_offset.html#pandas.tseries.offsets.BusinessMonthEnd.is_on_offset"}, {"function_name": "pandas.tseries.offsets.BusinessMonthEnd.is_month_end", "full_function": "BusinessMonthEnd.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.is_month_end.html#pandas.tseries.offsets.BusinessMonthEnd.is_month_end"}, {"function_name": "pandas.tseries.offsets.BusinessMonthEnd.is_quarter_end", "full_function": "BusinessMonthEnd.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.is_quarter_end.html#pandas.tseries.offsets.BusinessMonthEnd.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.BusinessMonthEnd.is_year_end", "full_function": "BusinessMonthEnd.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.is_year_end.html#pandas.tseries.offsets.BusinessMonthEnd.is_year_end"}, {"function_name": "pandas.tseries.offsets.BusinessMonthEnd.kwds", "full_function": "BusinessMonthEnd.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.kwds.html#pandas.tseries.offsets.BusinessMonthEnd.kwds"}, {"function_name": "pandas.tseries.offsets.BusinessMonthEnd.kwds", "full_function": "BusinessMonthEnd.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.kwds.html#pandas.tseries.offsets.BusinessMonthEnd.kwds"}, {"function_name": "pandas.tseries.offsets.BusinessMonthEnd.kwds", "full_function": "BusinessMonthEnd.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.kwds.html#pandas.tseries.offsets.BusinessMonthEnd.kwds"}, {"function_name": "pandas.tseries.offsets.BusinessMonthEnd.is_anchored", "full_function": "BusinessMonthEnd.is_anchored()#", "function_text": "Return boolean whether the frequency is a unit frequency (n=1).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.is_anchored.html#pandas.tseries.offsets.BusinessMonthEnd.is_anchored"}, {"function_name": "pandas.tseries.offsets.BusinessMonthEnd.is_month_start", "full_function": "BusinessMonthEnd.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.is_month_start.html#pandas.tseries.offsets.BusinessMonthEnd.is_month_start"}, {"function_name": "pandas.tseries.offsets.BusinessMonthEnd.is_quarter_start", "full_function": "BusinessMonthEnd.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.is_quarter_start.html#pandas.tseries.offsets.BusinessMonthEnd.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.BusinessMonthEnd.is_year_start", "full_function": "BusinessMonthEnd.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthEnd.is_year_start.html#pandas.tseries.offsets.BusinessMonthEnd.is_year_start"}]}, {"name": "BusinessMonthBegin", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#businessmonthbegin", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.html#pandas.tseries.offsets.BusinessMonthBegin", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BMonthBegin.html#pandas.tseries.offsets.BMonthBegin", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.freqstr.html#pandas.tseries.offsets.BusinessMonthBegin.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.name.html#pandas.tseries.offsets.BusinessMonthBegin.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.normalize.html#pandas.tseries.offsets.BusinessMonthBegin.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.n.html#pandas.tseries.offsets.BusinessMonthBegin.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.copy.html#pandas.tseries.offsets.BusinessMonthBegin.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.is_on_offset.html#pandas.tseries.offsets.BusinessMonthBegin.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.is_month_end.html#pandas.tseries.offsets.BusinessMonthBegin.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.is_quarter_end.html#pandas.tseries.offsets.BusinessMonthBegin.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.is_year_end.html#pandas.tseries.offsets.BusinessMonthBegin.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.kwds.html#pandas.tseries.offsets.BusinessMonthBegin.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.nanos.html#pandas.tseries.offsets.BusinessMonthBegin.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.rule_code.html#pandas.tseries.offsets.BusinessMonthBegin.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.is_anchored.html#pandas.tseries.offsets.BusinessMonthBegin.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.is_month_start.html#pandas.tseries.offsets.BusinessMonthBegin.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.is_quarter_start.html#pandas.tseries.offsets.BusinessMonthBegin.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.is_year_start.html#pandas.tseries.offsets.BusinessMonthBegin.is_year_start"], "function_definitions": [{"function_name": "pandas.tseries.offsets.BusinessMonthBegin", "full_function": "class pandas.tseries.offsets.BusinessMonthBegin#", "function_text": "DateOffset of one month at the first business day.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of months represented.\n"}, {"param_name": "normalize", "param_type": "bool, default False", "param_desc": "Normalize start/end dates to midnight before generating date range.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.html#pandas.tseries.offsets.BusinessMonthBegin"}, {"function_name": "pandas.tseries.offsets.BMonthBegin", "full_function": "pandas.tseries.offsets.BMonthBegin#", "function_text": "alias of BusinessMonthBegin", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BMonthBegin.html#pandas.tseries.offsets.BMonthBegin"}, {"function_name": "pandas.tseries.offsets.BusinessMonthBegin.freqstr", "full_function": "BusinessMonthBegin.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.freqstr.html#pandas.tseries.offsets.BusinessMonthBegin.freqstr"}, {"function_name": "pandas.tseries.offsets.BusinessMonthBegin.name", "full_function": "BusinessMonthBegin.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.name.html#pandas.tseries.offsets.BusinessMonthBegin.name"}, {"function_name": "pandas.tseries.offsets.BusinessMonthBegin.name", "full_function": "BusinessMonthBegin.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.name.html#pandas.tseries.offsets.BusinessMonthBegin.name"}, {"function_name": "pandas.tseries.offsets.BusinessMonthBegin.name", "full_function": "BusinessMonthBegin.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.name.html#pandas.tseries.offsets.BusinessMonthBegin.name"}, {"function_name": "pandas.tseries.offsets.BusinessMonthBegin.copy", "full_function": "BusinessMonthBegin.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.copy.html#pandas.tseries.offsets.BusinessMonthBegin.copy"}, {"function_name": "pandas.tseries.offsets.BusinessMonthBegin.is_on_offset", "full_function": "BusinessMonthBegin.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.is_on_offset.html#pandas.tseries.offsets.BusinessMonthBegin.is_on_offset"}, {"function_name": "pandas.tseries.offsets.BusinessMonthBegin.is_month_end", "full_function": "BusinessMonthBegin.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.is_month_end.html#pandas.tseries.offsets.BusinessMonthBegin.is_month_end"}, {"function_name": "pandas.tseries.offsets.BusinessMonthBegin.is_quarter_end", "full_function": "BusinessMonthBegin.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.is_quarter_end.html#pandas.tseries.offsets.BusinessMonthBegin.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.BusinessMonthBegin.is_year_end", "full_function": "BusinessMonthBegin.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.is_year_end.html#pandas.tseries.offsets.BusinessMonthBegin.is_year_end"}, {"function_name": "pandas.tseries.offsets.BusinessMonthBegin.kwds", "full_function": "BusinessMonthBegin.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.kwds.html#pandas.tseries.offsets.BusinessMonthBegin.kwds"}, {"function_name": "pandas.tseries.offsets.BusinessMonthBegin.kwds", "full_function": "BusinessMonthBegin.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.kwds.html#pandas.tseries.offsets.BusinessMonthBegin.kwds"}, {"function_name": "pandas.tseries.offsets.BusinessMonthBegin.kwds", "full_function": "BusinessMonthBegin.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.kwds.html#pandas.tseries.offsets.BusinessMonthBegin.kwds"}, {"function_name": "pandas.tseries.offsets.BusinessMonthBegin.is_anchored", "full_function": "BusinessMonthBegin.is_anchored()#", "function_text": "Return boolean whether the frequency is a unit frequency (n=1).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.is_anchored.html#pandas.tseries.offsets.BusinessMonthBegin.is_anchored"}, {"function_name": "pandas.tseries.offsets.BusinessMonthBegin.is_month_start", "full_function": "BusinessMonthBegin.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.is_month_start.html#pandas.tseries.offsets.BusinessMonthBegin.is_month_start"}, {"function_name": "pandas.tseries.offsets.BusinessMonthBegin.is_quarter_start", "full_function": "BusinessMonthBegin.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.is_quarter_start.html#pandas.tseries.offsets.BusinessMonthBegin.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.BusinessMonthBegin.is_year_start", "full_function": "BusinessMonthBegin.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BusinessMonthBegin.is_year_start.html#pandas.tseries.offsets.BusinessMonthBegin.is_year_start"}]}, {"name": "CustomBusinessMonthEnd", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#custombusinessmonthend", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.html#pandas.tseries.offsets.CustomBusinessMonthEnd", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CBMonthEnd.html#pandas.tseries.offsets.CBMonthEnd", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.freqstr.html#pandas.tseries.offsets.CustomBusinessMonthEnd.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.m_offset.html#pandas.tseries.offsets.CustomBusinessMonthEnd.m_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.nanos.html#pandas.tseries.offsets.CustomBusinessMonthEnd.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.rule_code.html#pandas.tseries.offsets.CustomBusinessMonthEnd.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.weekmask.html#pandas.tseries.offsets.CustomBusinessMonthEnd.weekmask", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.holidays.html#pandas.tseries.offsets.CustomBusinessMonthEnd.holidays", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.copy.html#pandas.tseries.offsets.CustomBusinessMonthEnd.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.is_on_offset.html#pandas.tseries.offsets.CustomBusinessMonthEnd.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.is_month_end.html#pandas.tseries.offsets.CustomBusinessMonthEnd.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.is_quarter_end.html#pandas.tseries.offsets.CustomBusinessMonthEnd.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.is_year_end.html#pandas.tseries.offsets.CustomBusinessMonthEnd.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.kwds.html#pandas.tseries.offsets.CustomBusinessMonthEnd.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.name.html#pandas.tseries.offsets.CustomBusinessMonthEnd.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.normalize.html#pandas.tseries.offsets.CustomBusinessMonthEnd.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.n.html#pandas.tseries.offsets.CustomBusinessMonthEnd.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.calendar.html#pandas.tseries.offsets.CustomBusinessMonthEnd.calendar", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.is_anchored.html#pandas.tseries.offsets.CustomBusinessMonthEnd.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.is_month_start.html#pandas.tseries.offsets.CustomBusinessMonthEnd.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.is_quarter_start.html#pandas.tseries.offsets.CustomBusinessMonthEnd.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.is_year_start.html#pandas.tseries.offsets.CustomBusinessMonthEnd.is_year_start"], "function_definitions": [{"function_name": "pandas.tseries.offsets.CustomBusinessMonthEnd", "full_function": "class pandas.tseries.offsets.CustomBusinessMonthEnd#", "function_text": "DateOffset subclass representing custom business month(s).", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of months represented.\n"}, {"param_name": "normalize", "param_type": "bool, default False", "param_desc": "Normalize end dates to midnight before generating date range.\n"}, {"param_name": "weekmask", "param_type": "str, Default ‘Mon Tue Wed Thu Fri’", "param_desc": "Weekmask of valid business days, passed to numpy.busdaycalendar.\n"}, {"param_name": "holidays", "param_type": "list", "param_desc": "List/array of dates to exclude from the set of valid business days,\npassed to numpy.busdaycalendar.\n"}, {"param_name": "calendar", "param_type": "np.busdaycalendar", "param_desc": "Calendar to integrate.\n"}, {"param_name": "offset", "param_type": "timedelta, default timedelta(0)", "param_desc": "Time offset to apply.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.html#pandas.tseries.offsets.CustomBusinessMonthEnd"}, {"function_name": "pandas.tseries.offsets.CBMonthEnd", "full_function": "pandas.tseries.offsets.CBMonthEnd#", "function_text": "alias of CustomBusinessMonthEnd", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CBMonthEnd.html#pandas.tseries.offsets.CBMonthEnd"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthEnd.freqstr", "full_function": "CustomBusinessMonthEnd.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.freqstr.html#pandas.tseries.offsets.CustomBusinessMonthEnd.freqstr"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthEnd.freqstr", "full_function": "CustomBusinessMonthEnd.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.freqstr.html#pandas.tseries.offsets.CustomBusinessMonthEnd.freqstr"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthEnd.freqstr", "full_function": "CustomBusinessMonthEnd.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.freqstr.html#pandas.tseries.offsets.CustomBusinessMonthEnd.freqstr"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthEnd.freqstr", "full_function": "CustomBusinessMonthEnd.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.freqstr.html#pandas.tseries.offsets.CustomBusinessMonthEnd.freqstr"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthEnd.freqstr", "full_function": "CustomBusinessMonthEnd.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.freqstr.html#pandas.tseries.offsets.CustomBusinessMonthEnd.freqstr"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthEnd.freqstr", "full_function": "CustomBusinessMonthEnd.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.freqstr.html#pandas.tseries.offsets.CustomBusinessMonthEnd.freqstr"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthEnd.copy", "full_function": "CustomBusinessMonthEnd.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.copy.html#pandas.tseries.offsets.CustomBusinessMonthEnd.copy"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthEnd.is_on_offset", "full_function": "CustomBusinessMonthEnd.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.is_on_offset.html#pandas.tseries.offsets.CustomBusinessMonthEnd.is_on_offset"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthEnd.is_month_end", "full_function": "CustomBusinessMonthEnd.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.is_month_end.html#pandas.tseries.offsets.CustomBusinessMonthEnd.is_month_end"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthEnd.is_quarter_end", "full_function": "CustomBusinessMonthEnd.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.is_quarter_end.html#pandas.tseries.offsets.CustomBusinessMonthEnd.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthEnd.is_year_end", "full_function": "CustomBusinessMonthEnd.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.is_year_end.html#pandas.tseries.offsets.CustomBusinessMonthEnd.is_year_end"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthEnd.kwds", "full_function": "CustomBusinessMonthEnd.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.kwds.html#pandas.tseries.offsets.CustomBusinessMonthEnd.kwds"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthEnd.name", "full_function": "CustomBusinessMonthEnd.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.name.html#pandas.tseries.offsets.CustomBusinessMonthEnd.name"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthEnd.name", "full_function": "CustomBusinessMonthEnd.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.name.html#pandas.tseries.offsets.CustomBusinessMonthEnd.name"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthEnd.name", "full_function": "CustomBusinessMonthEnd.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.name.html#pandas.tseries.offsets.CustomBusinessMonthEnd.name"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthEnd.name", "full_function": "CustomBusinessMonthEnd.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.name.html#pandas.tseries.offsets.CustomBusinessMonthEnd.name"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthEnd.is_anchored", "full_function": "CustomBusinessMonthEnd.is_anchored()#", "function_text": "Return boolean whether the frequency is a unit frequency (n=1).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.is_anchored.html#pandas.tseries.offsets.CustomBusinessMonthEnd.is_anchored"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthEnd.is_month_start", "full_function": "CustomBusinessMonthEnd.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.is_month_start.html#pandas.tseries.offsets.CustomBusinessMonthEnd.is_month_start"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthEnd.is_quarter_start", "full_function": "CustomBusinessMonthEnd.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.is_quarter_start.html#pandas.tseries.offsets.CustomBusinessMonthEnd.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthEnd.is_year_start", "full_function": "CustomBusinessMonthEnd.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthEnd.is_year_start.html#pandas.tseries.offsets.CustomBusinessMonthEnd.is_year_start"}]}, {"name": "CustomBusinessMonthBegin", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#custombusinessmonthbegin", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.html#pandas.tseries.offsets.CustomBusinessMonthBegin", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CBMonthBegin.html#pandas.tseries.offsets.CBMonthBegin", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.freqstr.html#pandas.tseries.offsets.CustomBusinessMonthBegin.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.m_offset.html#pandas.tseries.offsets.CustomBusinessMonthBegin.m_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.nanos.html#pandas.tseries.offsets.CustomBusinessMonthBegin.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.rule_code.html#pandas.tseries.offsets.CustomBusinessMonthBegin.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.weekmask.html#pandas.tseries.offsets.CustomBusinessMonthBegin.weekmask", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.holidays.html#pandas.tseries.offsets.CustomBusinessMonthBegin.holidays", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.copy.html#pandas.tseries.offsets.CustomBusinessMonthBegin.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.is_on_offset.html#pandas.tseries.offsets.CustomBusinessMonthBegin.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.is_month_end.html#pandas.tseries.offsets.CustomBusinessMonthBegin.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.is_quarter_end.html#pandas.tseries.offsets.CustomBusinessMonthBegin.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.is_year_end.html#pandas.tseries.offsets.CustomBusinessMonthBegin.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.kwds.html#pandas.tseries.offsets.CustomBusinessMonthBegin.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.name.html#pandas.tseries.offsets.CustomBusinessMonthBegin.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.normalize.html#pandas.tseries.offsets.CustomBusinessMonthBegin.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.n.html#pandas.tseries.offsets.CustomBusinessMonthBegin.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.calendar.html#pandas.tseries.offsets.CustomBusinessMonthBegin.calendar", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.is_anchored.html#pandas.tseries.offsets.CustomBusinessMonthBegin.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.is_month_start.html#pandas.tseries.offsets.CustomBusinessMonthBegin.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.is_quarter_start.html#pandas.tseries.offsets.CustomBusinessMonthBegin.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.is_year_start.html#pandas.tseries.offsets.CustomBusinessMonthBegin.is_year_start"], "function_definitions": [{"function_name": "pandas.tseries.offsets.CustomBusinessMonthBegin", "full_function": "class pandas.tseries.offsets.CustomBusinessMonthBegin#", "function_text": "DateOffset subclass representing custom business month(s).", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of months represented.\n"}, {"param_name": "normalize", "param_type": "bool, default False", "param_desc": "Normalize start dates to midnight before generating date range.\n"}, {"param_name": "weekmask", "param_type": "str, Default ‘Mon Tue Wed Thu Fri’", "param_desc": "Weekmask of valid business days, passed to numpy.busdaycalendar.\n"}, {"param_name": "holidays", "param_type": "list", "param_desc": "List/array of dates to exclude from the set of valid business days,\npassed to numpy.busdaycalendar.\n"}, {"param_name": "calendar", "param_type": "np.busdaycalendar", "param_desc": "Calendar to integrate.\n"}, {"param_name": "offset", "param_type": "timedelta, default timedelta(0)", "param_desc": "Time offset to apply.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.html#pandas.tseries.offsets.CustomBusinessMonthBegin"}, {"function_name": "pandas.tseries.offsets.CBMonthBegin", "full_function": "pandas.tseries.offsets.CBMonthBegin#", "function_text": "alias of CustomBusinessMonthBegin", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CBMonthBegin.html#pandas.tseries.offsets.CBMonthBegin"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthBegin.freqstr", "full_function": "CustomBusinessMonthBegin.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.freqstr.html#pandas.tseries.offsets.CustomBusinessMonthBegin.freqstr"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthBegin.freqstr", "full_function": "CustomBusinessMonthBegin.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.freqstr.html#pandas.tseries.offsets.CustomBusinessMonthBegin.freqstr"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthBegin.freqstr", "full_function": "CustomBusinessMonthBegin.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.freqstr.html#pandas.tseries.offsets.CustomBusinessMonthBegin.freqstr"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthBegin.freqstr", "full_function": "CustomBusinessMonthBegin.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.freqstr.html#pandas.tseries.offsets.CustomBusinessMonthBegin.freqstr"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthBegin.freqstr", "full_function": "CustomBusinessMonthBegin.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.freqstr.html#pandas.tseries.offsets.CustomBusinessMonthBegin.freqstr"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthBegin.freqstr", "full_function": "CustomBusinessMonthBegin.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.freqstr.html#pandas.tseries.offsets.CustomBusinessMonthBegin.freqstr"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthBegin.copy", "full_function": "CustomBusinessMonthBegin.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.copy.html#pandas.tseries.offsets.CustomBusinessMonthBegin.copy"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthBegin.is_on_offset", "full_function": "CustomBusinessMonthBegin.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.is_on_offset.html#pandas.tseries.offsets.CustomBusinessMonthBegin.is_on_offset"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthBegin.is_month_end", "full_function": "CustomBusinessMonthBegin.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.is_month_end.html#pandas.tseries.offsets.CustomBusinessMonthBegin.is_month_end"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthBegin.is_quarter_end", "full_function": "CustomBusinessMonthBegin.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.is_quarter_end.html#pandas.tseries.offsets.CustomBusinessMonthBegin.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthBegin.is_year_end", "full_function": "CustomBusinessMonthBegin.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.is_year_end.html#pandas.tseries.offsets.CustomBusinessMonthBegin.is_year_end"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthBegin.kwds", "full_function": "CustomBusinessMonthBegin.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.kwds.html#pandas.tseries.offsets.CustomBusinessMonthBegin.kwds"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthBegin.name", "full_function": "CustomBusinessMonthBegin.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.name.html#pandas.tseries.offsets.CustomBusinessMonthBegin.name"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthBegin.name", "full_function": "CustomBusinessMonthBegin.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.name.html#pandas.tseries.offsets.CustomBusinessMonthBegin.name"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthBegin.name", "full_function": "CustomBusinessMonthBegin.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.name.html#pandas.tseries.offsets.CustomBusinessMonthBegin.name"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthBegin.name", "full_function": "CustomBusinessMonthBegin.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.name.html#pandas.tseries.offsets.CustomBusinessMonthBegin.name"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthBegin.is_anchored", "full_function": "CustomBusinessMonthBegin.is_anchored()#", "function_text": "Return boolean whether the frequency is a unit frequency (n=1).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.is_anchored.html#pandas.tseries.offsets.CustomBusinessMonthBegin.is_anchored"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthBegin.is_month_start", "full_function": "CustomBusinessMonthBegin.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.is_month_start.html#pandas.tseries.offsets.CustomBusinessMonthBegin.is_month_start"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthBegin.is_quarter_start", "full_function": "CustomBusinessMonthBegin.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.is_quarter_start.html#pandas.tseries.offsets.CustomBusinessMonthBegin.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.CustomBusinessMonthBegin.is_year_start", "full_function": "CustomBusinessMonthBegin.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.CustomBusinessMonthBegin.is_year_start.html#pandas.tseries.offsets.CustomBusinessMonthBegin.is_year_start"}]}, {"name": "SemiMonthEnd", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#semimonthend", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.html#pandas.tseries.offsets.SemiMonthEnd", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.freqstr.html#pandas.tseries.offsets.SemiMonthEnd.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.name.html#pandas.tseries.offsets.SemiMonthEnd.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.normalize.html#pandas.tseries.offsets.SemiMonthEnd.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.n.html#pandas.tseries.offsets.SemiMonthEnd.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.copy.html#pandas.tseries.offsets.SemiMonthEnd.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.is_on_offset.html#pandas.tseries.offsets.SemiMonthEnd.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.is_month_end.html#pandas.tseries.offsets.SemiMonthEnd.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.is_quarter_end.html#pandas.tseries.offsets.SemiMonthEnd.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.is_year_end.html#pandas.tseries.offsets.SemiMonthEnd.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.kwds.html#pandas.tseries.offsets.SemiMonthEnd.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.nanos.html#pandas.tseries.offsets.SemiMonthEnd.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.rule_code.html#pandas.tseries.offsets.SemiMonthEnd.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.day_of_month.html#pandas.tseries.offsets.SemiMonthEnd.day_of_month", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.is_anchored.html#pandas.tseries.offsets.SemiMonthEnd.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.is_month_start.html#pandas.tseries.offsets.SemiMonthEnd.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.is_quarter_start.html#pandas.tseries.offsets.SemiMonthEnd.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.is_year_start.html#pandas.tseries.offsets.SemiMonthEnd.is_year_start"], "function_definitions": [{"function_name": "pandas.tseries.offsets.SemiMonthEnd", "full_function": "class pandas.tseries.offsets.SemiMonthEnd#", "function_text": "Two DateOffset’s per month repeating on the last day of the month & day_of_month.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of months represented.\n"}, {"param_name": "normalize", "param_type": "bool, default False", "param_desc": "Normalize start/end dates to midnight before generating date range.\n"}, {"param_name": "day_of_month", "param_type": "int, {1, 3,…,27}, default 15", "param_desc": "A specific integer for the day of the month.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.html#pandas.tseries.offsets.SemiMonthEnd"}, {"function_name": "pandas.tseries.offsets.SemiMonthEnd.freqstr", "full_function": "SemiMonthEnd.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.freqstr.html#pandas.tseries.offsets.SemiMonthEnd.freqstr"}, {"function_name": "pandas.tseries.offsets.SemiMonthEnd.name", "full_function": "SemiMonthEnd.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.name.html#pandas.tseries.offsets.SemiMonthEnd.name"}, {"function_name": "pandas.tseries.offsets.SemiMonthEnd.name", "full_function": "SemiMonthEnd.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.name.html#pandas.tseries.offsets.SemiMonthEnd.name"}, {"function_name": "pandas.tseries.offsets.SemiMonthEnd.name", "full_function": "SemiMonthEnd.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.name.html#pandas.tseries.offsets.SemiMonthEnd.name"}, {"function_name": "pandas.tseries.offsets.SemiMonthEnd.copy", "full_function": "SemiMonthEnd.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.copy.html#pandas.tseries.offsets.SemiMonthEnd.copy"}, {"function_name": "pandas.tseries.offsets.SemiMonthEnd.is_on_offset", "full_function": "SemiMonthEnd.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.is_on_offset.html#pandas.tseries.offsets.SemiMonthEnd.is_on_offset"}, {"function_name": "pandas.tseries.offsets.SemiMonthEnd.is_month_end", "full_function": "SemiMonthEnd.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.is_month_end.html#pandas.tseries.offsets.SemiMonthEnd.is_month_end"}, {"function_name": "pandas.tseries.offsets.SemiMonthEnd.is_quarter_end", "full_function": "SemiMonthEnd.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.is_quarter_end.html#pandas.tseries.offsets.SemiMonthEnd.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.SemiMonthEnd.is_year_end", "full_function": "SemiMonthEnd.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.is_year_end.html#pandas.tseries.offsets.SemiMonthEnd.is_year_end"}, {"function_name": "pandas.tseries.offsets.SemiMonthEnd.kwds", "full_function": "SemiMonthEnd.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.kwds.html#pandas.tseries.offsets.SemiMonthEnd.kwds"}, {"function_name": "pandas.tseries.offsets.SemiMonthEnd.kwds", "full_function": "SemiMonthEnd.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.kwds.html#pandas.tseries.offsets.SemiMonthEnd.kwds"}, {"function_name": "pandas.tseries.offsets.SemiMonthEnd.kwds", "full_function": "SemiMonthEnd.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.kwds.html#pandas.tseries.offsets.SemiMonthEnd.kwds"}, {"function_name": "pandas.tseries.offsets.SemiMonthEnd.kwds", "full_function": "SemiMonthEnd.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.kwds.html#pandas.tseries.offsets.SemiMonthEnd.kwds"}, {"function_name": "pandas.tseries.offsets.SemiMonthEnd.is_anchored", "full_function": "SemiMonthEnd.is_anchored()#", "function_text": "Return boolean whether the frequency is a unit frequency (n=1).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.is_anchored.html#pandas.tseries.offsets.SemiMonthEnd.is_anchored"}, {"function_name": "pandas.tseries.offsets.SemiMonthEnd.is_month_start", "full_function": "SemiMonthEnd.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.is_month_start.html#pandas.tseries.offsets.SemiMonthEnd.is_month_start"}, {"function_name": "pandas.tseries.offsets.SemiMonthEnd.is_quarter_start", "full_function": "SemiMonthEnd.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.is_quarter_start.html#pandas.tseries.offsets.SemiMonthEnd.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.SemiMonthEnd.is_year_start", "full_function": "SemiMonthEnd.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthEnd.is_year_start.html#pandas.tseries.offsets.SemiMonthEnd.is_year_start"}]}, {"name": "SemiMonthBegin", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#semimonthbegin", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.html#pandas.tseries.offsets.SemiMonthBegin", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.freqstr.html#pandas.tseries.offsets.SemiMonthBegin.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.name.html#pandas.tseries.offsets.SemiMonthBegin.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.normalize.html#pandas.tseries.offsets.SemiMonthBegin.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.n.html#pandas.tseries.offsets.SemiMonthBegin.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.copy.html#pandas.tseries.offsets.SemiMonthBegin.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.is_on_offset.html#pandas.tseries.offsets.SemiMonthBegin.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.is_month_end.html#pandas.tseries.offsets.SemiMonthBegin.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.is_quarter_end.html#pandas.tseries.offsets.SemiMonthBegin.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.is_year_end.html#pandas.tseries.offsets.SemiMonthBegin.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.kwds.html#pandas.tseries.offsets.SemiMonthBegin.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.nanos.html#pandas.tseries.offsets.SemiMonthBegin.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.rule_code.html#pandas.tseries.offsets.SemiMonthBegin.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.day_of_month.html#pandas.tseries.offsets.SemiMonthBegin.day_of_month", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.is_anchored.html#pandas.tseries.offsets.SemiMonthBegin.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.is_month_start.html#pandas.tseries.offsets.SemiMonthBegin.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.is_quarter_start.html#pandas.tseries.offsets.SemiMonthBegin.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.is_year_start.html#pandas.tseries.offsets.SemiMonthBegin.is_year_start"], "function_definitions": [{"function_name": "pandas.tseries.offsets.SemiMonthBegin", "full_function": "class pandas.tseries.offsets.SemiMonthBegin#", "function_text": "Two DateOffset’s per month repeating on the first day of the month & day_of_month.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of months represented.\n"}, {"param_name": "normalize", "param_type": "bool, default False", "param_desc": "Normalize start/end dates to midnight before generating date range.\n"}, {"param_name": "day_of_month", "param_type": "int, {1, 3,…,27}, default 15", "param_desc": "A specific integer for the day of the month.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.html#pandas.tseries.offsets.SemiMonthBegin"}, {"function_name": "pandas.tseries.offsets.SemiMonthBegin.freqstr", "full_function": "SemiMonthBegin.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.freqstr.html#pandas.tseries.offsets.SemiMonthBegin.freqstr"}, {"function_name": "pandas.tseries.offsets.SemiMonthBegin.name", "full_function": "SemiMonthBegin.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.name.html#pandas.tseries.offsets.SemiMonthBegin.name"}, {"function_name": "pandas.tseries.offsets.SemiMonthBegin.name", "full_function": "SemiMonthBegin.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.name.html#pandas.tseries.offsets.SemiMonthBegin.name"}, {"function_name": "pandas.tseries.offsets.SemiMonthBegin.name", "full_function": "SemiMonthBegin.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.name.html#pandas.tseries.offsets.SemiMonthBegin.name"}, {"function_name": "pandas.tseries.offsets.SemiMonthBegin.copy", "full_function": "SemiMonthBegin.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.copy.html#pandas.tseries.offsets.SemiMonthBegin.copy"}, {"function_name": "pandas.tseries.offsets.SemiMonthBegin.is_on_offset", "full_function": "SemiMonthBegin.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.is_on_offset.html#pandas.tseries.offsets.SemiMonthBegin.is_on_offset"}, {"function_name": "pandas.tseries.offsets.SemiMonthBegin.is_month_end", "full_function": "SemiMonthBegin.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.is_month_end.html#pandas.tseries.offsets.SemiMonthBegin.is_month_end"}, {"function_name": "pandas.tseries.offsets.SemiMonthBegin.is_quarter_end", "full_function": "SemiMonthBegin.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.is_quarter_end.html#pandas.tseries.offsets.SemiMonthBegin.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.SemiMonthBegin.is_year_end", "full_function": "SemiMonthBegin.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.is_year_end.html#pandas.tseries.offsets.SemiMonthBegin.is_year_end"}, {"function_name": "pandas.tseries.offsets.SemiMonthBegin.kwds", "full_function": "SemiMonthBegin.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.kwds.html#pandas.tseries.offsets.SemiMonthBegin.kwds"}, {"function_name": "pandas.tseries.offsets.SemiMonthBegin.kwds", "full_function": "SemiMonthBegin.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.kwds.html#pandas.tseries.offsets.SemiMonthBegin.kwds"}, {"function_name": "pandas.tseries.offsets.SemiMonthBegin.kwds", "full_function": "SemiMonthBegin.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.kwds.html#pandas.tseries.offsets.SemiMonthBegin.kwds"}, {"function_name": "pandas.tseries.offsets.SemiMonthBegin.kwds", "full_function": "SemiMonthBegin.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.kwds.html#pandas.tseries.offsets.SemiMonthBegin.kwds"}, {"function_name": "pandas.tseries.offsets.SemiMonthBegin.is_anchored", "full_function": "SemiMonthBegin.is_anchored()#", "function_text": "Return boolean whether the frequency is a unit frequency (n=1).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.is_anchored.html#pandas.tseries.offsets.SemiMonthBegin.is_anchored"}, {"function_name": "pandas.tseries.offsets.SemiMonthBegin.is_month_start", "full_function": "SemiMonthBegin.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.is_month_start.html#pandas.tseries.offsets.SemiMonthBegin.is_month_start"}, {"function_name": "pandas.tseries.offsets.SemiMonthBegin.is_quarter_start", "full_function": "SemiMonthBegin.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.is_quarter_start.html#pandas.tseries.offsets.SemiMonthBegin.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.SemiMonthBegin.is_year_start", "full_function": "SemiMonthBegin.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.SemiMonthBegin.is_year_start.html#pandas.tseries.offsets.SemiMonthBegin.is_year_start"}]}, {"name": "Week", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#week", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.html#pandas.tseries.offsets.Week", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.freqstr.html#pandas.tseries.offsets.Week.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.name.html#pandas.tseries.offsets.Week.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.normalize.html#pandas.tseries.offsets.Week.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.n.html#pandas.tseries.offsets.Week.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.copy.html#pandas.tseries.offsets.Week.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.is_on_offset.html#pandas.tseries.offsets.Week.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.is_month_end.html#pandas.tseries.offsets.Week.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.is_quarter_end.html#pandas.tseries.offsets.Week.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.is_year_end.html#pandas.tseries.offsets.Week.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.kwds.html#pandas.tseries.offsets.Week.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.nanos.html#pandas.tseries.offsets.Week.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.rule_code.html#pandas.tseries.offsets.Week.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.weekday.html#pandas.tseries.offsets.Week.weekday", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.is_anchored.html#pandas.tseries.offsets.Week.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.is_month_start.html#pandas.tseries.offsets.Week.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.is_quarter_start.html#pandas.tseries.offsets.Week.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.is_year_start.html#pandas.tseries.offsets.Week.is_year_start"], "function_definitions": [{"function_name": "pandas.tseries.offsets.Week", "full_function": "class pandas.tseries.offsets.Week#", "function_text": "Weekly offset.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of weeks represented.\n"}, {"param_name": "normalize", "param_type": "bool, default False", "param_desc": "Normalize start/end dates to midnight before generating date range.\n"}, {"param_name": "weekday", "param_type": "int or None, default None", "param_desc": "Always generate specific day of week.\n0 for Monday and 6 for Sunday.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.html#pandas.tseries.offsets.Week"}, {"function_name": "pandas.tseries.offsets.Week.freqstr", "full_function": "Week.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.freqstr.html#pandas.tseries.offsets.Week.freqstr"}, {"function_name": "pandas.tseries.offsets.Week.name", "full_function": "Week.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.name.html#pandas.tseries.offsets.Week.name"}, {"function_name": "pandas.tseries.offsets.Week.name", "full_function": "Week.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.name.html#pandas.tseries.offsets.Week.name"}, {"function_name": "pandas.tseries.offsets.Week.name", "full_function": "Week.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.name.html#pandas.tseries.offsets.Week.name"}, {"function_name": "pandas.tseries.offsets.Week.copy", "full_function": "Week.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.copy.html#pandas.tseries.offsets.Week.copy"}, {"function_name": "pandas.tseries.offsets.Week.is_on_offset", "full_function": "Week.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.is_on_offset.html#pandas.tseries.offsets.Week.is_on_offset"}, {"function_name": "pandas.tseries.offsets.Week.is_month_end", "full_function": "Week.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.is_month_end.html#pandas.tseries.offsets.Week.is_month_end"}, {"function_name": "pandas.tseries.offsets.Week.is_quarter_end", "full_function": "Week.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.is_quarter_end.html#pandas.tseries.offsets.Week.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.Week.is_year_end", "full_function": "Week.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.is_year_end.html#pandas.tseries.offsets.Week.is_year_end"}, {"function_name": "pandas.tseries.offsets.Week.kwds", "full_function": "Week.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.kwds.html#pandas.tseries.offsets.Week.kwds"}, {"function_name": "pandas.tseries.offsets.Week.kwds", "full_function": "Week.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.kwds.html#pandas.tseries.offsets.Week.kwds"}, {"function_name": "pandas.tseries.offsets.Week.kwds", "full_function": "Week.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.kwds.html#pandas.tseries.offsets.Week.kwds"}, {"function_name": "pandas.tseries.offsets.Week.kwds", "full_function": "Week.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.kwds.html#pandas.tseries.offsets.Week.kwds"}, {"function_name": "pandas.tseries.offsets.Week.is_anchored", "full_function": "Week.is_anchored()#", "function_text": "Return boolean whether the frequency is a unit frequency (n=1).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.is_anchored.html#pandas.tseries.offsets.Week.is_anchored"}, {"function_name": "pandas.tseries.offsets.Week.is_month_start", "full_function": "Week.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.is_month_start.html#pandas.tseries.offsets.Week.is_month_start"}, {"function_name": "pandas.tseries.offsets.Week.is_quarter_start", "full_function": "Week.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.is_quarter_start.html#pandas.tseries.offsets.Week.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.Week.is_year_start", "full_function": "Week.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Week.is_year_start.html#pandas.tseries.offsets.Week.is_year_start"}]}, {"name": "WeekOfMonth", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#weekofmonth", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.html#pandas.tseries.offsets.WeekOfMonth", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.freqstr.html#pandas.tseries.offsets.WeekOfMonth.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.name.html#pandas.tseries.offsets.WeekOfMonth.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.normalize.html#pandas.tseries.offsets.WeekOfMonth.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.n.html#pandas.tseries.offsets.WeekOfMonth.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.copy.html#pandas.tseries.offsets.WeekOfMonth.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.is_on_offset.html#pandas.tseries.offsets.WeekOfMonth.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.is_month_start.html#pandas.tseries.offsets.WeekOfMonth.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.is_quarter_start.html#pandas.tseries.offsets.WeekOfMonth.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.is_year_start.html#pandas.tseries.offsets.WeekOfMonth.is_year_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.kwds.html#pandas.tseries.offsets.WeekOfMonth.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.nanos.html#pandas.tseries.offsets.WeekOfMonth.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.rule_code.html#pandas.tseries.offsets.WeekOfMonth.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.week.html#pandas.tseries.offsets.WeekOfMonth.week", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.is_anchored.html#pandas.tseries.offsets.WeekOfMonth.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.weekday.html#pandas.tseries.offsets.WeekOfMonth.weekday", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.is_month_end.html#pandas.tseries.offsets.WeekOfMonth.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.is_quarter_end.html#pandas.tseries.offsets.WeekOfMonth.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.is_year_end.html#pandas.tseries.offsets.WeekOfMonth.is_year_end"], "function_definitions": [{"function_name": "pandas.tseries.offsets.WeekOfMonth", "full_function": "class pandas.tseries.offsets.WeekOfMonth#", "function_text": "Describes monthly dates like “the Tuesday of the 2nd week of each month”.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of months represented.\n"}, {"param_name": "normalize", "param_type": "bool, default False", "param_desc": "Normalize start/end dates to midnight before generating date range.\n"}, {"param_name": "week", "param_type": "int {0, 1, 2, 3, …}, default 0", "param_desc": "A specific integer for the week of the month.\ne.g. 0 is 1st week of month, 1 is the 2nd week, etc.\n"}, {"param_name": "weekday", "param_type": "int {0, 1, …, 6}, default 0", "param_desc": "A specific integer for the day of the week.\n\n0 is Monday\n1 is Tuesday\n2 is Wednesday\n3 is Thursday\n4 is Friday\n5 is Saturday\n6 is Sunday.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.html#pandas.tseries.offsets.WeekOfMonth"}, {"function_name": "pandas.tseries.offsets.WeekOfMonth.freqstr", "full_function": "WeekOfMonth.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.freqstr.html#pandas.tseries.offsets.WeekOfMonth.freqstr"}, {"function_name": "pandas.tseries.offsets.WeekOfMonth.name", "full_function": "WeekOfMonth.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.name.html#pandas.tseries.offsets.WeekOfMonth.name"}, {"function_name": "pandas.tseries.offsets.WeekOfMonth.name", "full_function": "WeekOfMonth.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.name.html#pandas.tseries.offsets.WeekOfMonth.name"}, {"function_name": "pandas.tseries.offsets.WeekOfMonth.name", "full_function": "WeekOfMonth.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.name.html#pandas.tseries.offsets.WeekOfMonth.name"}, {"function_name": "pandas.tseries.offsets.WeekOfMonth.copy", "full_function": "WeekOfMonth.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.copy.html#pandas.tseries.offsets.WeekOfMonth.copy"}, {"function_name": "pandas.tseries.offsets.WeekOfMonth.is_on_offset", "full_function": "WeekOfMonth.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.is_on_offset.html#pandas.tseries.offsets.WeekOfMonth.is_on_offset"}, {"function_name": "pandas.tseries.offsets.WeekOfMonth.is_month_start", "full_function": "WeekOfMonth.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.is_month_start.html#pandas.tseries.offsets.WeekOfMonth.is_month_start"}, {"function_name": "pandas.tseries.offsets.WeekOfMonth.is_quarter_start", "full_function": "WeekOfMonth.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.is_quarter_start.html#pandas.tseries.offsets.WeekOfMonth.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.WeekOfMonth.is_year_start", "full_function": "WeekOfMonth.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.is_year_start.html#pandas.tseries.offsets.WeekOfMonth.is_year_start"}, {"function_name": "pandas.tseries.offsets.WeekOfMonth.kwds", "full_function": "WeekOfMonth.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.kwds.html#pandas.tseries.offsets.WeekOfMonth.kwds"}, {"function_name": "pandas.tseries.offsets.WeekOfMonth.kwds", "full_function": "WeekOfMonth.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.kwds.html#pandas.tseries.offsets.WeekOfMonth.kwds"}, {"function_name": "pandas.tseries.offsets.WeekOfMonth.kwds", "full_function": "WeekOfMonth.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.kwds.html#pandas.tseries.offsets.WeekOfMonth.kwds"}, {"function_name": "pandas.tseries.offsets.WeekOfMonth.kwds", "full_function": "WeekOfMonth.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.kwds.html#pandas.tseries.offsets.WeekOfMonth.kwds"}, {"function_name": "pandas.tseries.offsets.WeekOfMonth.is_anchored", "full_function": "WeekOfMonth.is_anchored()#", "function_text": "Return boolean whether the frequency is a unit frequency (n=1).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.is_anchored.html#pandas.tseries.offsets.WeekOfMonth.is_anchored"}, {"function_name": "pandas.tseries.offsets.WeekOfMonth.is_anchored", "full_function": "WeekOfMonth.is_anchored()#", "function_text": "Return boolean whether the frequency is a unit frequency (n=1).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.is_anchored.html#pandas.tseries.offsets.WeekOfMonth.is_anchored"}, {"function_name": "pandas.tseries.offsets.WeekOfMonth.is_month_end", "full_function": "WeekOfMonth.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.is_month_end.html#pandas.tseries.offsets.WeekOfMonth.is_month_end"}, {"function_name": "pandas.tseries.offsets.WeekOfMonth.is_quarter_end", "full_function": "WeekOfMonth.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.is_quarter_end.html#pandas.tseries.offsets.WeekOfMonth.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.WeekOfMonth.is_year_end", "full_function": "WeekOfMonth.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.WeekOfMonth.is_year_end.html#pandas.tseries.offsets.WeekOfMonth.is_year_end"}]}, {"name": "LastWeekOfMonth", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#lastweekofmonth", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.html#pandas.tseries.offsets.LastWeekOfMonth", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.freqstr.html#pandas.tseries.offsets.LastWeekOfMonth.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.name.html#pandas.tseries.offsets.LastWeekOfMonth.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.normalize.html#pandas.tseries.offsets.LastWeekOfMonth.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.n.html#pandas.tseries.offsets.LastWeekOfMonth.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.week.html#pandas.tseries.offsets.LastWeekOfMonth.week", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.copy.html#pandas.tseries.offsets.LastWeekOfMonth.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.is_on_offset.html#pandas.tseries.offsets.LastWeekOfMonth.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.is_month_end.html#pandas.tseries.offsets.LastWeekOfMonth.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.is_quarter_end.html#pandas.tseries.offsets.LastWeekOfMonth.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.is_year_end.html#pandas.tseries.offsets.LastWeekOfMonth.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.kwds.html#pandas.tseries.offsets.LastWeekOfMonth.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.nanos.html#pandas.tseries.offsets.LastWeekOfMonth.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.rule_code.html#pandas.tseries.offsets.LastWeekOfMonth.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.weekday.html#pandas.tseries.offsets.LastWeekOfMonth.weekday", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.is_anchored.html#pandas.tseries.offsets.LastWeekOfMonth.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.is_month_start.html#pandas.tseries.offsets.LastWeekOfMonth.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.is_quarter_start.html#pandas.tseries.offsets.LastWeekOfMonth.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.is_year_start.html#pandas.tseries.offsets.LastWeekOfMonth.is_year_start"], "function_definitions": [{"function_name": "pandas.tseries.offsets.LastWeekOfMonth", "full_function": "class pandas.tseries.offsets.LastWeekOfMonth#", "function_text": "Describes monthly dates in last week of month.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of months represented.\n"}, {"param_name": "normalize", "param_type": "bool, default False", "param_desc": "Normalize start/end dates to midnight before generating date range.\n"}, {"param_name": "weekday", "param_type": "int {0, 1, …, 6}, default 0", "param_desc": "A specific integer for the day of the week.\n\n0 is Monday\n1 is Tuesday\n2 is Wednesday\n3 is Thursday\n4 is Friday\n5 is Saturday\n6 is Sunday.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.html#pandas.tseries.offsets.LastWeekOfMonth"}, {"function_name": "pandas.tseries.offsets.LastWeekOfMonth.freqstr", "full_function": "LastWeekOfMonth.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.freqstr.html#pandas.tseries.offsets.LastWeekOfMonth.freqstr"}, {"function_name": "pandas.tseries.offsets.LastWeekOfMonth.name", "full_function": "LastWeekOfMonth.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.name.html#pandas.tseries.offsets.LastWeekOfMonth.name"}, {"function_name": "pandas.tseries.offsets.LastWeekOfMonth.name", "full_function": "LastWeekOfMonth.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.name.html#pandas.tseries.offsets.LastWeekOfMonth.name"}, {"function_name": "pandas.tseries.offsets.LastWeekOfMonth.name", "full_function": "LastWeekOfMonth.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.name.html#pandas.tseries.offsets.LastWeekOfMonth.name"}, {"function_name": "pandas.tseries.offsets.LastWeekOfMonth.name", "full_function": "LastWeekOfMonth.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.name.html#pandas.tseries.offsets.LastWeekOfMonth.name"}, {"function_name": "pandas.tseries.offsets.LastWeekOfMonth.copy", "full_function": "LastWeekOfMonth.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.copy.html#pandas.tseries.offsets.LastWeekOfMonth.copy"}, {"function_name": "pandas.tseries.offsets.LastWeekOfMonth.is_on_offset", "full_function": "LastWeekOfMonth.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.is_on_offset.html#pandas.tseries.offsets.LastWeekOfMonth.is_on_offset"}, {"function_name": "pandas.tseries.offsets.LastWeekOfMonth.is_month_end", "full_function": "LastWeekOfMonth.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.is_month_end.html#pandas.tseries.offsets.LastWeekOfMonth.is_month_end"}, {"function_name": "pandas.tseries.offsets.LastWeekOfMonth.is_quarter_end", "full_function": "LastWeekOfMonth.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.is_quarter_end.html#pandas.tseries.offsets.LastWeekOfMonth.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.LastWeekOfMonth.is_year_end", "full_function": "LastWeekOfMonth.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.is_year_end.html#pandas.tseries.offsets.LastWeekOfMonth.is_year_end"}, {"function_name": "pandas.tseries.offsets.LastWeekOfMonth.kwds", "full_function": "LastWeekOfMonth.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.kwds.html#pandas.tseries.offsets.LastWeekOfMonth.kwds"}, {"function_name": "pandas.tseries.offsets.LastWeekOfMonth.kwds", "full_function": "LastWeekOfMonth.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.kwds.html#pandas.tseries.offsets.LastWeekOfMonth.kwds"}, {"function_name": "pandas.tseries.offsets.LastWeekOfMonth.kwds", "full_function": "LastWeekOfMonth.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.kwds.html#pandas.tseries.offsets.LastWeekOfMonth.kwds"}, {"function_name": "pandas.tseries.offsets.LastWeekOfMonth.kwds", "full_function": "LastWeekOfMonth.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.kwds.html#pandas.tseries.offsets.LastWeekOfMonth.kwds"}, {"function_name": "pandas.tseries.offsets.LastWeekOfMonth.is_anchored", "full_function": "LastWeekOfMonth.is_anchored()#", "function_text": "Return boolean whether the frequency is a unit frequency (n=1).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.is_anchored.html#pandas.tseries.offsets.LastWeekOfMonth.is_anchored"}, {"function_name": "pandas.tseries.offsets.LastWeekOfMonth.is_month_start", "full_function": "LastWeekOfMonth.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.is_month_start.html#pandas.tseries.offsets.LastWeekOfMonth.is_month_start"}, {"function_name": "pandas.tseries.offsets.LastWeekOfMonth.is_quarter_start", "full_function": "LastWeekOfMonth.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.is_quarter_start.html#pandas.tseries.offsets.LastWeekOfMonth.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.LastWeekOfMonth.is_year_start", "full_function": "LastWeekOfMonth.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.LastWeekOfMonth.is_year_start.html#pandas.tseries.offsets.LastWeekOfMonth.is_year_start"}]}, {"name": "BQuarterEnd", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#bquarterend", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.html#pandas.tseries.offsets.BQuarterEnd", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.freqstr.html#pandas.tseries.offsets.BQuarterEnd.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.name.html#pandas.tseries.offsets.BQuarterEnd.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.normalize.html#pandas.tseries.offsets.BQuarterEnd.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.n.html#pandas.tseries.offsets.BQuarterEnd.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.copy.html#pandas.tseries.offsets.BQuarterEnd.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.is_on_offset.html#pandas.tseries.offsets.BQuarterEnd.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.is_month_end.html#pandas.tseries.offsets.BQuarterEnd.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.is_quarter_end.html#pandas.tseries.offsets.BQuarterEnd.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.is_year_end.html#pandas.tseries.offsets.BQuarterEnd.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.kwds.html#pandas.tseries.offsets.BQuarterEnd.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.nanos.html#pandas.tseries.offsets.BQuarterEnd.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.rule_code.html#pandas.tseries.offsets.BQuarterEnd.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.startingMonth.html#pandas.tseries.offsets.BQuarterEnd.startingMonth", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.is_anchored.html#pandas.tseries.offsets.BQuarterEnd.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.is_month_start.html#pandas.tseries.offsets.BQuarterEnd.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.is_quarter_start.html#pandas.tseries.offsets.BQuarterEnd.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.is_year_start.html#pandas.tseries.offsets.BQuarterEnd.is_year_start"], "function_definitions": [{"function_name": "pandas.tseries.offsets.BQuarterEnd", "full_function": "class pandas.tseries.offsets.BQuarterEnd#", "function_text": "DateOffset increments between the last business day of each Quarter.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of quarters represented.\n"}, {"param_name": "normalize", "param_type": "bool, default False", "param_desc": "Normalize start/end dates to midnight before generating date range.\n"}, {"param_name": "startingMonth", "param_type": "int, default 3", "param_desc": "A specific integer for the month of the year from which we start quarters.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.html#pandas.tseries.offsets.BQuarterEnd"}, {"function_name": "pandas.tseries.offsets.BQuarterEnd.freqstr", "full_function": "BQuarterEnd.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.freqstr.html#pandas.tseries.offsets.BQuarterEnd.freqstr"}, {"function_name": "pandas.tseries.offsets.BQuarterEnd.name", "full_function": "BQuarterEnd.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.name.html#pandas.tseries.offsets.BQuarterEnd.name"}, {"function_name": "pandas.tseries.offsets.BQuarterEnd.name", "full_function": "BQuarterEnd.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.name.html#pandas.tseries.offsets.BQuarterEnd.name"}, {"function_name": "pandas.tseries.offsets.BQuarterEnd.name", "full_function": "BQuarterEnd.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.name.html#pandas.tseries.offsets.BQuarterEnd.name"}, {"function_name": "pandas.tseries.offsets.BQuarterEnd.copy", "full_function": "BQuarterEnd.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.copy.html#pandas.tseries.offsets.BQuarterEnd.copy"}, {"function_name": "pandas.tseries.offsets.BQuarterEnd.is_on_offset", "full_function": "BQuarterEnd.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.is_on_offset.html#pandas.tseries.offsets.BQuarterEnd.is_on_offset"}, {"function_name": "pandas.tseries.offsets.BQuarterEnd.is_month_end", "full_function": "BQuarterEnd.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.is_month_end.html#pandas.tseries.offsets.BQuarterEnd.is_month_end"}, {"function_name": "pandas.tseries.offsets.BQuarterEnd.is_quarter_end", "full_function": "BQuarterEnd.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.is_quarter_end.html#pandas.tseries.offsets.BQuarterEnd.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.BQuarterEnd.is_year_end", "full_function": "BQuarterEnd.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.is_year_end.html#pandas.tseries.offsets.BQuarterEnd.is_year_end"}, {"function_name": "pandas.tseries.offsets.BQuarterEnd.kwds", "full_function": "BQuarterEnd.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.kwds.html#pandas.tseries.offsets.BQuarterEnd.kwds"}, {"function_name": "pandas.tseries.offsets.BQuarterEnd.kwds", "full_function": "BQuarterEnd.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.kwds.html#pandas.tseries.offsets.BQuarterEnd.kwds"}, {"function_name": "pandas.tseries.offsets.BQuarterEnd.kwds", "full_function": "BQuarterEnd.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.kwds.html#pandas.tseries.offsets.BQuarterEnd.kwds"}, {"function_name": "pandas.tseries.offsets.BQuarterEnd.kwds", "full_function": "BQuarterEnd.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.kwds.html#pandas.tseries.offsets.BQuarterEnd.kwds"}, {"function_name": "pandas.tseries.offsets.BQuarterEnd.is_anchored", "full_function": "BQuarterEnd.is_anchored()#", "function_text": "Return boolean whether the frequency is a unit frequency (n=1).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.is_anchored.html#pandas.tseries.offsets.BQuarterEnd.is_anchored"}, {"function_name": "pandas.tseries.offsets.BQuarterEnd.is_month_start", "full_function": "BQuarterEnd.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.is_month_start.html#pandas.tseries.offsets.BQuarterEnd.is_month_start"}, {"function_name": "pandas.tseries.offsets.BQuarterEnd.is_quarter_start", "full_function": "BQuarterEnd.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.is_quarter_start.html#pandas.tseries.offsets.BQuarterEnd.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.BQuarterEnd.is_year_start", "full_function": "BQuarterEnd.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterEnd.is_year_start.html#pandas.tseries.offsets.BQuarterEnd.is_year_start"}]}, {"name": "BQuarterBegin", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#bquarterbegin", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.html#pandas.tseries.offsets.BQuarterBegin", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.freqstr.html#pandas.tseries.offsets.BQuarterBegin.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.name.html#pandas.tseries.offsets.BQuarterBegin.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.normalize.html#pandas.tseries.offsets.BQuarterBegin.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.n.html#pandas.tseries.offsets.BQuarterBegin.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.copy.html#pandas.tseries.offsets.BQuarterBegin.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.is_on_offset.html#pandas.tseries.offsets.BQuarterBegin.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.is_month_end.html#pandas.tseries.offsets.BQuarterBegin.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.is_quarter_end.html#pandas.tseries.offsets.BQuarterBegin.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.is_year_end.html#pandas.tseries.offsets.BQuarterBegin.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.kwds.html#pandas.tseries.offsets.BQuarterBegin.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.nanos.html#pandas.tseries.offsets.BQuarterBegin.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.rule_code.html#pandas.tseries.offsets.BQuarterBegin.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.startingMonth.html#pandas.tseries.offsets.BQuarterBegin.startingMonth", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.is_anchored.html#pandas.tseries.offsets.BQuarterBegin.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.is_month_start.html#pandas.tseries.offsets.BQuarterBegin.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.is_quarter_start.html#pandas.tseries.offsets.BQuarterBegin.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.is_year_start.html#pandas.tseries.offsets.BQuarterBegin.is_year_start"], "function_definitions": [{"function_name": "pandas.tseries.offsets.BQuarterBegin", "full_function": "class pandas.tseries.offsets.BQuarterBegin#", "function_text": "DateOffset increments between the first business day of each Quarter.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of quarters represented.\n"}, {"param_name": "normalize", "param_type": "bool, default False", "param_desc": "Normalize start/end dates to midnight before generating date range.\n"}, {"param_name": "startingMonth", "param_type": "int, default 3", "param_desc": "A specific integer for the month of the year from which we start quarters.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.html#pandas.tseries.offsets.BQuarterBegin"}, {"function_name": "pandas.tseries.offsets.BQuarterBegin.freqstr", "full_function": "BQuarterBegin.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.freqstr.html#pandas.tseries.offsets.BQuarterBegin.freqstr"}, {"function_name": "pandas.tseries.offsets.BQuarterBegin.name", "full_function": "BQuarterBegin.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.name.html#pandas.tseries.offsets.BQuarterBegin.name"}, {"function_name": "pandas.tseries.offsets.BQuarterBegin.name", "full_function": "BQuarterBegin.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.name.html#pandas.tseries.offsets.BQuarterBegin.name"}, {"function_name": "pandas.tseries.offsets.BQuarterBegin.name", "full_function": "BQuarterBegin.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.name.html#pandas.tseries.offsets.BQuarterBegin.name"}, {"function_name": "pandas.tseries.offsets.BQuarterBegin.copy", "full_function": "BQuarterBegin.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.copy.html#pandas.tseries.offsets.BQuarterBegin.copy"}, {"function_name": "pandas.tseries.offsets.BQuarterBegin.is_on_offset", "full_function": "BQuarterBegin.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.is_on_offset.html#pandas.tseries.offsets.BQuarterBegin.is_on_offset"}, {"function_name": "pandas.tseries.offsets.BQuarterBegin.is_month_end", "full_function": "BQuarterBegin.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.is_month_end.html#pandas.tseries.offsets.BQuarterBegin.is_month_end"}, {"function_name": "pandas.tseries.offsets.BQuarterBegin.is_quarter_end", "full_function": "BQuarterBegin.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.is_quarter_end.html#pandas.tseries.offsets.BQuarterBegin.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.BQuarterBegin.is_year_end", "full_function": "BQuarterBegin.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.is_year_end.html#pandas.tseries.offsets.BQuarterBegin.is_year_end"}, {"function_name": "pandas.tseries.offsets.BQuarterBegin.kwds", "full_function": "BQuarterBegin.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.kwds.html#pandas.tseries.offsets.BQuarterBegin.kwds"}, {"function_name": "pandas.tseries.offsets.BQuarterBegin.kwds", "full_function": "BQuarterBegin.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.kwds.html#pandas.tseries.offsets.BQuarterBegin.kwds"}, {"function_name": "pandas.tseries.offsets.BQuarterBegin.kwds", "full_function": "BQuarterBegin.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.kwds.html#pandas.tseries.offsets.BQuarterBegin.kwds"}, {"function_name": "pandas.tseries.offsets.BQuarterBegin.kwds", "full_function": "BQuarterBegin.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.kwds.html#pandas.tseries.offsets.BQuarterBegin.kwds"}, {"function_name": "pandas.tseries.offsets.BQuarterBegin.is_anchored", "full_function": "BQuarterBegin.is_anchored()#", "function_text": "Return boolean whether the frequency is a unit frequency (n=1).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.is_anchored.html#pandas.tseries.offsets.BQuarterBegin.is_anchored"}, {"function_name": "pandas.tseries.offsets.BQuarterBegin.is_month_start", "full_function": "BQuarterBegin.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.is_month_start.html#pandas.tseries.offsets.BQuarterBegin.is_month_start"}, {"function_name": "pandas.tseries.offsets.BQuarterBegin.is_quarter_start", "full_function": "BQuarterBegin.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.is_quarter_start.html#pandas.tseries.offsets.BQuarterBegin.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.BQuarterBegin.is_year_start", "full_function": "BQuarterBegin.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BQuarterBegin.is_year_start.html#pandas.tseries.offsets.BQuarterBegin.is_year_start"}]}, {"name": "QuarterEnd", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#quarterend", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.html#pandas.tseries.offsets.QuarterEnd", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.freqstr.html#pandas.tseries.offsets.QuarterEnd.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.name.html#pandas.tseries.offsets.QuarterEnd.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.normalize.html#pandas.tseries.offsets.QuarterEnd.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.n.html#pandas.tseries.offsets.QuarterEnd.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.copy.html#pandas.tseries.offsets.QuarterEnd.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.is_on_offset.html#pandas.tseries.offsets.QuarterEnd.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.is_month_end.html#pandas.tseries.offsets.QuarterEnd.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.is_quarter_end.html#pandas.tseries.offsets.QuarterEnd.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.is_year_end.html#pandas.tseries.offsets.QuarterEnd.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.kwds.html#pandas.tseries.offsets.QuarterEnd.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.nanos.html#pandas.tseries.offsets.QuarterEnd.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.rule_code.html#pandas.tseries.offsets.QuarterEnd.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.startingMonth.html#pandas.tseries.offsets.QuarterEnd.startingMonth", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.is_anchored.html#pandas.tseries.offsets.QuarterEnd.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.is_month_start.html#pandas.tseries.offsets.QuarterEnd.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.is_quarter_start.html#pandas.tseries.offsets.QuarterEnd.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.is_year_start.html#pandas.tseries.offsets.QuarterEnd.is_year_start"], "function_definitions": [{"function_name": "pandas.tseries.offsets.QuarterEnd", "full_function": "class pandas.tseries.offsets.QuarterEnd#", "function_text": "DateOffset increments between Quarter end dates.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of quarters represented.\n"}, {"param_name": "normalize", "param_type": "bool, default False", "param_desc": "Normalize start/end dates to midnight before generating date range.\n"}, {"param_name": "startingMonth", "param_type": "int, default 3", "param_desc": "A specific integer for the month of the year from which we start quarters.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.html#pandas.tseries.offsets.QuarterEnd"}, {"function_name": "pandas.tseries.offsets.QuarterEnd.freqstr", "full_function": "QuarterEnd.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.freqstr.html#pandas.tseries.offsets.QuarterEnd.freqstr"}, {"function_name": "pandas.tseries.offsets.QuarterEnd.name", "full_function": "QuarterEnd.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.name.html#pandas.tseries.offsets.QuarterEnd.name"}, {"function_name": "pandas.tseries.offsets.QuarterEnd.name", "full_function": "QuarterEnd.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.name.html#pandas.tseries.offsets.QuarterEnd.name"}, {"function_name": "pandas.tseries.offsets.QuarterEnd.name", "full_function": "QuarterEnd.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.name.html#pandas.tseries.offsets.QuarterEnd.name"}, {"function_name": "pandas.tseries.offsets.QuarterEnd.copy", "full_function": "QuarterEnd.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.copy.html#pandas.tseries.offsets.QuarterEnd.copy"}, {"function_name": "pandas.tseries.offsets.QuarterEnd.is_on_offset", "full_function": "QuarterEnd.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.is_on_offset.html#pandas.tseries.offsets.QuarterEnd.is_on_offset"}, {"function_name": "pandas.tseries.offsets.QuarterEnd.is_month_end", "full_function": "QuarterEnd.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.is_month_end.html#pandas.tseries.offsets.QuarterEnd.is_month_end"}, {"function_name": "pandas.tseries.offsets.QuarterEnd.is_quarter_end", "full_function": "QuarterEnd.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.is_quarter_end.html#pandas.tseries.offsets.QuarterEnd.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.QuarterEnd.is_year_end", "full_function": "QuarterEnd.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.is_year_end.html#pandas.tseries.offsets.QuarterEnd.is_year_end"}, {"function_name": "pandas.tseries.offsets.QuarterEnd.kwds", "full_function": "QuarterEnd.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.kwds.html#pandas.tseries.offsets.QuarterEnd.kwds"}, {"function_name": "pandas.tseries.offsets.QuarterEnd.kwds", "full_function": "QuarterEnd.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.kwds.html#pandas.tseries.offsets.QuarterEnd.kwds"}, {"function_name": "pandas.tseries.offsets.QuarterEnd.kwds", "full_function": "QuarterEnd.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.kwds.html#pandas.tseries.offsets.QuarterEnd.kwds"}, {"function_name": "pandas.tseries.offsets.QuarterEnd.kwds", "full_function": "QuarterEnd.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.kwds.html#pandas.tseries.offsets.QuarterEnd.kwds"}, {"function_name": "pandas.tseries.offsets.QuarterEnd.is_anchored", "full_function": "QuarterEnd.is_anchored()#", "function_text": "Return boolean whether the frequency is a unit frequency (n=1).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.is_anchored.html#pandas.tseries.offsets.QuarterEnd.is_anchored"}, {"function_name": "pandas.tseries.offsets.QuarterEnd.is_month_start", "full_function": "QuarterEnd.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.is_month_start.html#pandas.tseries.offsets.QuarterEnd.is_month_start"}, {"function_name": "pandas.tseries.offsets.QuarterEnd.is_quarter_start", "full_function": "QuarterEnd.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.is_quarter_start.html#pandas.tseries.offsets.QuarterEnd.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.QuarterEnd.is_year_start", "full_function": "QuarterEnd.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterEnd.is_year_start.html#pandas.tseries.offsets.QuarterEnd.is_year_start"}]}, {"name": "QuarterBegin", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#quarterbegin", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.html#pandas.tseries.offsets.QuarterBegin", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.freqstr.html#pandas.tseries.offsets.QuarterBegin.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.name.html#pandas.tseries.offsets.QuarterBegin.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.normalize.html#pandas.tseries.offsets.QuarterBegin.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.n.html#pandas.tseries.offsets.QuarterBegin.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.copy.html#pandas.tseries.offsets.QuarterBegin.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.is_on_offset.html#pandas.tseries.offsets.QuarterBegin.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.is_month_end.html#pandas.tseries.offsets.QuarterBegin.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.is_quarter_end.html#pandas.tseries.offsets.QuarterBegin.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.is_year_end.html#pandas.tseries.offsets.QuarterBegin.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.kwds.html#pandas.tseries.offsets.QuarterBegin.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.nanos.html#pandas.tseries.offsets.QuarterBegin.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.rule_code.html#pandas.tseries.offsets.QuarterBegin.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.startingMonth.html#pandas.tseries.offsets.QuarterBegin.startingMonth", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.is_anchored.html#pandas.tseries.offsets.QuarterBegin.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.is_month_start.html#pandas.tseries.offsets.QuarterBegin.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.is_quarter_start.html#pandas.tseries.offsets.QuarterBegin.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.is_year_start.html#pandas.tseries.offsets.QuarterBegin.is_year_start"], "function_definitions": [{"function_name": "pandas.tseries.offsets.QuarterBegin", "full_function": "class pandas.tseries.offsets.QuarterBegin#", "function_text": "DateOffset increments between Quarter start dates.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of quarters represented.\n"}, {"param_name": "normalize", "param_type": "bool, default False", "param_desc": "Normalize start/end dates to midnight before generating date range.\n"}, {"param_name": "startingMonth", "param_type": "int, default 3", "param_desc": "A specific integer for the month of the year from which we start quarters.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.html#pandas.tseries.offsets.QuarterBegin"}, {"function_name": "pandas.tseries.offsets.QuarterBegin.freqstr", "full_function": "QuarterBegin.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.freqstr.html#pandas.tseries.offsets.QuarterBegin.freqstr"}, {"function_name": "pandas.tseries.offsets.QuarterBegin.name", "full_function": "QuarterBegin.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.name.html#pandas.tseries.offsets.QuarterBegin.name"}, {"function_name": "pandas.tseries.offsets.QuarterBegin.name", "full_function": "QuarterBegin.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.name.html#pandas.tseries.offsets.QuarterBegin.name"}, {"function_name": "pandas.tseries.offsets.QuarterBegin.name", "full_function": "QuarterBegin.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.name.html#pandas.tseries.offsets.QuarterBegin.name"}, {"function_name": "pandas.tseries.offsets.QuarterBegin.copy", "full_function": "QuarterBegin.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.copy.html#pandas.tseries.offsets.QuarterBegin.copy"}, {"function_name": "pandas.tseries.offsets.QuarterBegin.is_on_offset", "full_function": "QuarterBegin.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.is_on_offset.html#pandas.tseries.offsets.QuarterBegin.is_on_offset"}, {"function_name": "pandas.tseries.offsets.QuarterBegin.is_month_end", "full_function": "QuarterBegin.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.is_month_end.html#pandas.tseries.offsets.QuarterBegin.is_month_end"}, {"function_name": "pandas.tseries.offsets.QuarterBegin.is_quarter_end", "full_function": "QuarterBegin.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.is_quarter_end.html#pandas.tseries.offsets.QuarterBegin.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.QuarterBegin.is_year_end", "full_function": "QuarterBegin.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.is_year_end.html#pandas.tseries.offsets.QuarterBegin.is_year_end"}, {"function_name": "pandas.tseries.offsets.QuarterBegin.kwds", "full_function": "QuarterBegin.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.kwds.html#pandas.tseries.offsets.QuarterBegin.kwds"}, {"function_name": "pandas.tseries.offsets.QuarterBegin.kwds", "full_function": "QuarterBegin.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.kwds.html#pandas.tseries.offsets.QuarterBegin.kwds"}, {"function_name": "pandas.tseries.offsets.QuarterBegin.kwds", "full_function": "QuarterBegin.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.kwds.html#pandas.tseries.offsets.QuarterBegin.kwds"}, {"function_name": "pandas.tseries.offsets.QuarterBegin.kwds", "full_function": "QuarterBegin.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.kwds.html#pandas.tseries.offsets.QuarterBegin.kwds"}, {"function_name": "pandas.tseries.offsets.QuarterBegin.is_anchored", "full_function": "QuarterBegin.is_anchored()#", "function_text": "Return boolean whether the frequency is a unit frequency (n=1).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.is_anchored.html#pandas.tseries.offsets.QuarterBegin.is_anchored"}, {"function_name": "pandas.tseries.offsets.QuarterBegin.is_month_start", "full_function": "QuarterBegin.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.is_month_start.html#pandas.tseries.offsets.QuarterBegin.is_month_start"}, {"function_name": "pandas.tseries.offsets.QuarterBegin.is_quarter_start", "full_function": "QuarterBegin.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.is_quarter_start.html#pandas.tseries.offsets.QuarterBegin.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.QuarterBegin.is_year_start", "full_function": "QuarterBegin.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.QuarterBegin.is_year_start.html#pandas.tseries.offsets.QuarterBegin.is_year_start"}]}, {"name": "BYearEnd", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#byearend", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.html#pandas.tseries.offsets.BYearEnd", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.freqstr.html#pandas.tseries.offsets.BYearEnd.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.name.html#pandas.tseries.offsets.BYearEnd.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.normalize.html#pandas.tseries.offsets.BYearEnd.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.n.html#pandas.tseries.offsets.BYearEnd.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.copy.html#pandas.tseries.offsets.BYearEnd.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.is_on_offset.html#pandas.tseries.offsets.BYearEnd.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.is_month_end.html#pandas.tseries.offsets.BYearEnd.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.is_quarter_end.html#pandas.tseries.offsets.BYearEnd.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.is_year_end.html#pandas.tseries.offsets.BYearEnd.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.kwds.html#pandas.tseries.offsets.BYearEnd.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.nanos.html#pandas.tseries.offsets.BYearEnd.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.rule_code.html#pandas.tseries.offsets.BYearEnd.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.month.html#pandas.tseries.offsets.BYearEnd.month", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.is_anchored.html#pandas.tseries.offsets.BYearEnd.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.is_month_start.html#pandas.tseries.offsets.BYearEnd.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.is_quarter_start.html#pandas.tseries.offsets.BYearEnd.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.is_year_start.html#pandas.tseries.offsets.BYearEnd.is_year_start"], "function_definitions": [{"function_name": "pandas.tseries.offsets.BYearEnd", "full_function": "class pandas.tseries.offsets.BYearEnd#", "function_text": "DateOffset increments between the last business day of the year.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of years represented.\n"}, {"param_name": "normalize", "param_type": "bool, default False", "param_desc": "Normalize start/end dates to midnight before generating date range.\n"}, {"param_name": "month", "param_type": "int, default 12", "param_desc": "A specific integer for the month of the year.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.html#pandas.tseries.offsets.BYearEnd"}, {"function_name": "pandas.tseries.offsets.BYearEnd.freqstr", "full_function": "BYearEnd.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.freqstr.html#pandas.tseries.offsets.BYearEnd.freqstr"}, {"function_name": "pandas.tseries.offsets.BYearEnd.name", "full_function": "BYearEnd.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.name.html#pandas.tseries.offsets.BYearEnd.name"}, {"function_name": "pandas.tseries.offsets.BYearEnd.name", "full_function": "BYearEnd.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.name.html#pandas.tseries.offsets.BYearEnd.name"}, {"function_name": "pandas.tseries.offsets.BYearEnd.name", "full_function": "BYearEnd.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.name.html#pandas.tseries.offsets.BYearEnd.name"}, {"function_name": "pandas.tseries.offsets.BYearEnd.copy", "full_function": "BYearEnd.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.copy.html#pandas.tseries.offsets.BYearEnd.copy"}, {"function_name": "pandas.tseries.offsets.BYearEnd.is_on_offset", "full_function": "BYearEnd.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.is_on_offset.html#pandas.tseries.offsets.BYearEnd.is_on_offset"}, {"function_name": "pandas.tseries.offsets.BYearEnd.is_month_end", "full_function": "BYearEnd.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.is_month_end.html#pandas.tseries.offsets.BYearEnd.is_month_end"}, {"function_name": "pandas.tseries.offsets.BYearEnd.is_quarter_end", "full_function": "BYearEnd.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.is_quarter_end.html#pandas.tseries.offsets.BYearEnd.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.BYearEnd.is_year_end", "full_function": "BYearEnd.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.is_year_end.html#pandas.tseries.offsets.BYearEnd.is_year_end"}, {"function_name": "pandas.tseries.offsets.BYearEnd.kwds", "full_function": "BYearEnd.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.kwds.html#pandas.tseries.offsets.BYearEnd.kwds"}, {"function_name": "pandas.tseries.offsets.BYearEnd.kwds", "full_function": "BYearEnd.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.kwds.html#pandas.tseries.offsets.BYearEnd.kwds"}, {"function_name": "pandas.tseries.offsets.BYearEnd.kwds", "full_function": "BYearEnd.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.kwds.html#pandas.tseries.offsets.BYearEnd.kwds"}, {"function_name": "pandas.tseries.offsets.BYearEnd.kwds", "full_function": "BYearEnd.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.kwds.html#pandas.tseries.offsets.BYearEnd.kwds"}, {"function_name": "pandas.tseries.offsets.BYearEnd.is_anchored", "full_function": "BYearEnd.is_anchored()#", "function_text": "Return boolean whether the frequency is a unit frequency (n=1).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.is_anchored.html#pandas.tseries.offsets.BYearEnd.is_anchored"}, {"function_name": "pandas.tseries.offsets.BYearEnd.is_month_start", "full_function": "BYearEnd.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.is_month_start.html#pandas.tseries.offsets.BYearEnd.is_month_start"}, {"function_name": "pandas.tseries.offsets.BYearEnd.is_quarter_start", "full_function": "BYearEnd.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.is_quarter_start.html#pandas.tseries.offsets.BYearEnd.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.BYearEnd.is_year_start", "full_function": "BYearEnd.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearEnd.is_year_start.html#pandas.tseries.offsets.BYearEnd.is_year_start"}]}, {"name": "BYearBegin", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#byearbegin", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.html#pandas.tseries.offsets.BYearBegin", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.freqstr.html#pandas.tseries.offsets.BYearBegin.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.name.html#pandas.tseries.offsets.BYearBegin.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.normalize.html#pandas.tseries.offsets.BYearBegin.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.n.html#pandas.tseries.offsets.BYearBegin.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.copy.html#pandas.tseries.offsets.BYearBegin.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.is_on_offset.html#pandas.tseries.offsets.BYearBegin.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.is_month_end.html#pandas.tseries.offsets.BYearBegin.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.is_quarter_end.html#pandas.tseries.offsets.BYearBegin.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.is_year_end.html#pandas.tseries.offsets.BYearBegin.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.kwds.html#pandas.tseries.offsets.BYearBegin.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.nanos.html#pandas.tseries.offsets.BYearBegin.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.rule_code.html#pandas.tseries.offsets.BYearBegin.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.month.html#pandas.tseries.offsets.BYearBegin.month", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.is_anchored.html#pandas.tseries.offsets.BYearBegin.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.is_month_start.html#pandas.tseries.offsets.BYearBegin.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.is_quarter_start.html#pandas.tseries.offsets.BYearBegin.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.is_year_start.html#pandas.tseries.offsets.BYearBegin.is_year_start"], "function_definitions": [{"function_name": "pandas.tseries.offsets.BYearBegin", "full_function": "class pandas.tseries.offsets.BYearBegin#", "function_text": "DateOffset increments between the first business day of the year.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of years represented.\n"}, {"param_name": "normalize", "param_type": "bool, default False", "param_desc": "Normalize start/end dates to midnight before generating date range.\n"}, {"param_name": "month", "param_type": "int, default 1", "param_desc": "A specific integer for the month of the year.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.html#pandas.tseries.offsets.BYearBegin"}, {"function_name": "pandas.tseries.offsets.BYearBegin.freqstr", "full_function": "BYearBegin.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.freqstr.html#pandas.tseries.offsets.BYearBegin.freqstr"}, {"function_name": "pandas.tseries.offsets.BYearBegin.name", "full_function": "BYearBegin.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.name.html#pandas.tseries.offsets.BYearBegin.name"}, {"function_name": "pandas.tseries.offsets.BYearBegin.name", "full_function": "BYearBegin.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.name.html#pandas.tseries.offsets.BYearBegin.name"}, {"function_name": "pandas.tseries.offsets.BYearBegin.name", "full_function": "BYearBegin.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.name.html#pandas.tseries.offsets.BYearBegin.name"}, {"function_name": "pandas.tseries.offsets.BYearBegin.copy", "full_function": "BYearBegin.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.copy.html#pandas.tseries.offsets.BYearBegin.copy"}, {"function_name": "pandas.tseries.offsets.BYearBegin.is_on_offset", "full_function": "BYearBegin.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.is_on_offset.html#pandas.tseries.offsets.BYearBegin.is_on_offset"}, {"function_name": "pandas.tseries.offsets.BYearBegin.is_month_end", "full_function": "BYearBegin.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.is_month_end.html#pandas.tseries.offsets.BYearBegin.is_month_end"}, {"function_name": "pandas.tseries.offsets.BYearBegin.is_quarter_end", "full_function": "BYearBegin.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.is_quarter_end.html#pandas.tseries.offsets.BYearBegin.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.BYearBegin.is_year_end", "full_function": "BYearBegin.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.is_year_end.html#pandas.tseries.offsets.BYearBegin.is_year_end"}, {"function_name": "pandas.tseries.offsets.BYearBegin.kwds", "full_function": "BYearBegin.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.kwds.html#pandas.tseries.offsets.BYearBegin.kwds"}, {"function_name": "pandas.tseries.offsets.BYearBegin.kwds", "full_function": "BYearBegin.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.kwds.html#pandas.tseries.offsets.BYearBegin.kwds"}, {"function_name": "pandas.tseries.offsets.BYearBegin.kwds", "full_function": "BYearBegin.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.kwds.html#pandas.tseries.offsets.BYearBegin.kwds"}, {"function_name": "pandas.tseries.offsets.BYearBegin.kwds", "full_function": "BYearBegin.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.kwds.html#pandas.tseries.offsets.BYearBegin.kwds"}, {"function_name": "pandas.tseries.offsets.BYearBegin.is_anchored", "full_function": "BYearBegin.is_anchored()#", "function_text": "Return boolean whether the frequency is a unit frequency (n=1).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.is_anchored.html#pandas.tseries.offsets.BYearBegin.is_anchored"}, {"function_name": "pandas.tseries.offsets.BYearBegin.is_month_start", "full_function": "BYearBegin.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.is_month_start.html#pandas.tseries.offsets.BYearBegin.is_month_start"}, {"function_name": "pandas.tseries.offsets.BYearBegin.is_quarter_start", "full_function": "BYearBegin.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.is_quarter_start.html#pandas.tseries.offsets.BYearBegin.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.BYearBegin.is_year_start", "full_function": "BYearBegin.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.BYearBegin.is_year_start.html#pandas.tseries.offsets.BYearBegin.is_year_start"}]}, {"name": "YearEnd", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#yearend", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.html#pandas.tseries.offsets.YearEnd", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.freqstr.html#pandas.tseries.offsets.YearEnd.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.name.html#pandas.tseries.offsets.YearEnd.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.normalize.html#pandas.tseries.offsets.YearEnd.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.n.html#pandas.tseries.offsets.YearEnd.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.copy.html#pandas.tseries.offsets.YearEnd.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.is_on_offset.html#pandas.tseries.offsets.YearEnd.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.is_month_end.html#pandas.tseries.offsets.YearEnd.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.is_quarter_end.html#pandas.tseries.offsets.YearEnd.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.is_year_end.html#pandas.tseries.offsets.YearEnd.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.kwds.html#pandas.tseries.offsets.YearEnd.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.nanos.html#pandas.tseries.offsets.YearEnd.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.rule_code.html#pandas.tseries.offsets.YearEnd.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.month.html#pandas.tseries.offsets.YearEnd.month", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.is_anchored.html#pandas.tseries.offsets.YearEnd.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.is_month_start.html#pandas.tseries.offsets.YearEnd.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.is_quarter_start.html#pandas.tseries.offsets.YearEnd.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.is_year_start.html#pandas.tseries.offsets.YearEnd.is_year_start"], "function_definitions": [{"function_name": "pandas.tseries.offsets.YearEnd", "full_function": "class pandas.tseries.offsets.YearEnd#", "function_text": "DateOffset increments between calendar year end dates.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of years represented.\n"}, {"param_name": "normalize", "param_type": "bool, default False", "param_desc": "Normalize start/end dates to midnight before generating date range.\n"}, {"param_name": "month", "param_type": "int, default 12", "param_desc": "A specific integer for the month of the year.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.html#pandas.tseries.offsets.YearEnd"}, {"function_name": "pandas.tseries.offsets.YearEnd.freqstr", "full_function": "YearEnd.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.freqstr.html#pandas.tseries.offsets.YearEnd.freqstr"}, {"function_name": "pandas.tseries.offsets.YearEnd.name", "full_function": "YearEnd.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.name.html#pandas.tseries.offsets.YearEnd.name"}, {"function_name": "pandas.tseries.offsets.YearEnd.name", "full_function": "YearEnd.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.name.html#pandas.tseries.offsets.YearEnd.name"}, {"function_name": "pandas.tseries.offsets.YearEnd.name", "full_function": "YearEnd.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.name.html#pandas.tseries.offsets.YearEnd.name"}, {"function_name": "pandas.tseries.offsets.YearEnd.copy", "full_function": "YearEnd.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.copy.html#pandas.tseries.offsets.YearEnd.copy"}, {"function_name": "pandas.tseries.offsets.YearEnd.is_on_offset", "full_function": "YearEnd.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.is_on_offset.html#pandas.tseries.offsets.YearEnd.is_on_offset"}, {"function_name": "pandas.tseries.offsets.YearEnd.is_month_end", "full_function": "YearEnd.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.is_month_end.html#pandas.tseries.offsets.YearEnd.is_month_end"}, {"function_name": "pandas.tseries.offsets.YearEnd.is_quarter_end", "full_function": "YearEnd.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.is_quarter_end.html#pandas.tseries.offsets.YearEnd.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.YearEnd.is_year_end", "full_function": "YearEnd.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.is_year_end.html#pandas.tseries.offsets.YearEnd.is_year_end"}, {"function_name": "pandas.tseries.offsets.YearEnd.kwds", "full_function": "YearEnd.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.kwds.html#pandas.tseries.offsets.YearEnd.kwds"}, {"function_name": "pandas.tseries.offsets.YearEnd.kwds", "full_function": "YearEnd.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.kwds.html#pandas.tseries.offsets.YearEnd.kwds"}, {"function_name": "pandas.tseries.offsets.YearEnd.kwds", "full_function": "YearEnd.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.kwds.html#pandas.tseries.offsets.YearEnd.kwds"}, {"function_name": "pandas.tseries.offsets.YearEnd.kwds", "full_function": "YearEnd.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.kwds.html#pandas.tseries.offsets.YearEnd.kwds"}, {"function_name": "pandas.tseries.offsets.YearEnd.is_anchored", "full_function": "YearEnd.is_anchored()#", "function_text": "Return boolean whether the frequency is a unit frequency (n=1).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.is_anchored.html#pandas.tseries.offsets.YearEnd.is_anchored"}, {"function_name": "pandas.tseries.offsets.YearEnd.is_month_start", "full_function": "YearEnd.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.is_month_start.html#pandas.tseries.offsets.YearEnd.is_month_start"}, {"function_name": "pandas.tseries.offsets.YearEnd.is_quarter_start", "full_function": "YearEnd.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.is_quarter_start.html#pandas.tseries.offsets.YearEnd.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.YearEnd.is_year_start", "full_function": "YearEnd.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearEnd.is_year_start.html#pandas.tseries.offsets.YearEnd.is_year_start"}]}, {"name": "YearBegin", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#yearbegin", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.html#pandas.tseries.offsets.YearBegin", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.freqstr.html#pandas.tseries.offsets.YearBegin.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.name.html#pandas.tseries.offsets.YearBegin.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.normalize.html#pandas.tseries.offsets.YearBegin.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.n.html#pandas.tseries.offsets.YearBegin.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.copy.html#pandas.tseries.offsets.YearBegin.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.is_on_offset.html#pandas.tseries.offsets.YearBegin.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.is_month_end.html#pandas.tseries.offsets.YearBegin.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.is_quarter_end.html#pandas.tseries.offsets.YearBegin.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.is_year_end.html#pandas.tseries.offsets.YearBegin.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.kwds.html#pandas.tseries.offsets.YearBegin.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.nanos.html#pandas.tseries.offsets.YearBegin.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.rule_code.html#pandas.tseries.offsets.YearBegin.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.month.html#pandas.tseries.offsets.YearBegin.month", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.is_anchored.html#pandas.tseries.offsets.YearBegin.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.is_month_start.html#pandas.tseries.offsets.YearBegin.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.is_quarter_start.html#pandas.tseries.offsets.YearBegin.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.is_year_start.html#pandas.tseries.offsets.YearBegin.is_year_start"], "function_definitions": [{"function_name": "pandas.tseries.offsets.YearBegin", "full_function": "class pandas.tseries.offsets.YearBegin#", "function_text": "DateOffset increments between calendar year begin dates.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of years represented.\n"}, {"param_name": "normalize", "param_type": "bool, default False", "param_desc": "Normalize start/end dates to midnight before generating date range.\n"}, {"param_name": "month", "param_type": "int, default 1", "param_desc": "A specific integer for the month of the year.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.html#pandas.tseries.offsets.YearBegin"}, {"function_name": "pandas.tseries.offsets.YearBegin.freqstr", "full_function": "YearBegin.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.freqstr.html#pandas.tseries.offsets.YearBegin.freqstr"}, {"function_name": "pandas.tseries.offsets.YearBegin.name", "full_function": "YearBegin.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.name.html#pandas.tseries.offsets.YearBegin.name"}, {"function_name": "pandas.tseries.offsets.YearBegin.name", "full_function": "YearBegin.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.name.html#pandas.tseries.offsets.YearBegin.name"}, {"function_name": "pandas.tseries.offsets.YearBegin.name", "full_function": "YearBegin.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.name.html#pandas.tseries.offsets.YearBegin.name"}, {"function_name": "pandas.tseries.offsets.YearBegin.copy", "full_function": "YearBegin.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.copy.html#pandas.tseries.offsets.YearBegin.copy"}, {"function_name": "pandas.tseries.offsets.YearBegin.is_on_offset", "full_function": "YearBegin.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.is_on_offset.html#pandas.tseries.offsets.YearBegin.is_on_offset"}, {"function_name": "pandas.tseries.offsets.YearBegin.is_month_end", "full_function": "YearBegin.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.is_month_end.html#pandas.tseries.offsets.YearBegin.is_month_end"}, {"function_name": "pandas.tseries.offsets.YearBegin.is_quarter_end", "full_function": "YearBegin.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.is_quarter_end.html#pandas.tseries.offsets.YearBegin.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.YearBegin.is_year_end", "full_function": "YearBegin.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.is_year_end.html#pandas.tseries.offsets.YearBegin.is_year_end"}, {"function_name": "pandas.tseries.offsets.YearBegin.kwds", "full_function": "YearBegin.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.kwds.html#pandas.tseries.offsets.YearBegin.kwds"}, {"function_name": "pandas.tseries.offsets.YearBegin.kwds", "full_function": "YearBegin.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.kwds.html#pandas.tseries.offsets.YearBegin.kwds"}, {"function_name": "pandas.tseries.offsets.YearBegin.kwds", "full_function": "YearBegin.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.kwds.html#pandas.tseries.offsets.YearBegin.kwds"}, {"function_name": "pandas.tseries.offsets.YearBegin.kwds", "full_function": "YearBegin.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.kwds.html#pandas.tseries.offsets.YearBegin.kwds"}, {"function_name": "pandas.tseries.offsets.YearBegin.is_anchored", "full_function": "YearBegin.is_anchored()#", "function_text": "Return boolean whether the frequency is a unit frequency (n=1).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.is_anchored.html#pandas.tseries.offsets.YearBegin.is_anchored"}, {"function_name": "pandas.tseries.offsets.YearBegin.is_month_start", "full_function": "YearBegin.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.is_month_start.html#pandas.tseries.offsets.YearBegin.is_month_start"}, {"function_name": "pandas.tseries.offsets.YearBegin.is_quarter_start", "full_function": "YearBegin.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.is_quarter_start.html#pandas.tseries.offsets.YearBegin.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.YearBegin.is_year_start", "full_function": "YearBegin.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.YearBegin.is_year_start.html#pandas.tseries.offsets.YearBegin.is_year_start"}]}, {"name": "FY5253", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#fy5253", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.html#pandas.tseries.offsets.FY5253", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.freqstr.html#pandas.tseries.offsets.FY5253.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.name.html#pandas.tseries.offsets.FY5253.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.normalize.html#pandas.tseries.offsets.FY5253.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.n.html#pandas.tseries.offsets.FY5253.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.variation.html#pandas.tseries.offsets.FY5253.variation", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.copy.html#pandas.tseries.offsets.FY5253.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.get_year_end.html#pandas.tseries.offsets.FY5253.get_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.is_on_offset.html#pandas.tseries.offsets.FY5253.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.is_month_end.html#pandas.tseries.offsets.FY5253.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.is_quarter_end.html#pandas.tseries.offsets.FY5253.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.is_year_end.html#pandas.tseries.offsets.FY5253.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.kwds.html#pandas.tseries.offsets.FY5253.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.nanos.html#pandas.tseries.offsets.FY5253.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.rule_code.html#pandas.tseries.offsets.FY5253.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.startingMonth.html#pandas.tseries.offsets.FY5253.startingMonth", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.weekday.html#pandas.tseries.offsets.FY5253.weekday", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.get_rule_code_suffix.html#pandas.tseries.offsets.FY5253.get_rule_code_suffix", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.is_anchored.html#pandas.tseries.offsets.FY5253.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.is_month_start.html#pandas.tseries.offsets.FY5253.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.is_quarter_start.html#pandas.tseries.offsets.FY5253.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.is_year_start.html#pandas.tseries.offsets.FY5253.is_year_start"], "function_definitions": [{"function_name": "pandas.tseries.offsets.FY5253", "full_function": "class pandas.tseries.offsets.FY5253#", "function_text": "Describes 52-53 week fiscal year. This is also known as a 4-4-5 calendar.", "parameter_names_desc": [{"param_name": "n", "param_type": "int", "param_desc": "The number of fiscal years represented.\n"}, {"param_name": "normalize", "param_type": "bool, default False", "param_desc": "Normalize start/end dates to midnight before generating date range.\n"}, {"param_name": "weekday", "param_type": "int {0, 1, …, 6}, default 0", "param_desc": "A specific integer for the day of the week.\n\n0 is Monday\n1 is Tuesday\n2 is Wednesday\n3 is Thursday\n4 is Friday\n5 is Saturday\n6 is Sunday.\n\n"}, {"param_name": "startingMonth", "param_type": "int {1, 2, … 12}, default 1", "param_desc": "The month in which the fiscal year ends.\n"}, {"param_name": "variation", "param_type": "str, default “nearest”", "param_desc": "Method of employing 4-4-5 calendar.\nThere are two options:\n\n“nearest” means year end is weekday closest to last day of month in year.\n“last” means year end is final weekday of the final month in fiscal year.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.html#pandas.tseries.offsets.FY5253"}, {"function_name": "pandas.tseries.offsets.FY5253.freqstr", "full_function": "FY5253.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.freqstr.html#pandas.tseries.offsets.FY5253.freqstr"}, {"function_name": "pandas.tseries.offsets.FY5253.name", "full_function": "FY5253.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.name.html#pandas.tseries.offsets.FY5253.name"}, {"function_name": "pandas.tseries.offsets.FY5253.name", "full_function": "FY5253.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.name.html#pandas.tseries.offsets.FY5253.name"}, {"function_name": "pandas.tseries.offsets.FY5253.name", "full_function": "FY5253.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.name.html#pandas.tseries.offsets.FY5253.name"}, {"function_name": "pandas.tseries.offsets.FY5253.name", "full_function": "FY5253.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.name.html#pandas.tseries.offsets.FY5253.name"}, {"function_name": "pandas.tseries.offsets.FY5253.copy", "full_function": "FY5253.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.copy.html#pandas.tseries.offsets.FY5253.copy"}, {"function_name": "pandas.tseries.offsets.FY5253.copy", "full_function": "FY5253.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.copy.html#pandas.tseries.offsets.FY5253.copy"}, {"function_name": "pandas.tseries.offsets.FY5253.is_on_offset", "full_function": "FY5253.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.is_on_offset.html#pandas.tseries.offsets.FY5253.is_on_offset"}, {"function_name": "pandas.tseries.offsets.FY5253.is_month_end", "full_function": "FY5253.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.is_month_end.html#pandas.tseries.offsets.FY5253.is_month_end"}, {"function_name": "pandas.tseries.offsets.FY5253.is_quarter_end", "full_function": "FY5253.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.is_quarter_end.html#pandas.tseries.offsets.FY5253.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.FY5253.is_year_end", "full_function": "FY5253.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.is_year_end.html#pandas.tseries.offsets.FY5253.is_year_end"}, {"function_name": "pandas.tseries.offsets.FY5253.kwds", "full_function": "FY5253.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.kwds.html#pandas.tseries.offsets.FY5253.kwds"}, {"function_name": "pandas.tseries.offsets.FY5253.kwds", "full_function": "FY5253.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.kwds.html#pandas.tseries.offsets.FY5253.kwds"}, {"function_name": "pandas.tseries.offsets.FY5253.kwds", "full_function": "FY5253.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.kwds.html#pandas.tseries.offsets.FY5253.kwds"}, {"function_name": "pandas.tseries.offsets.FY5253.kwds", "full_function": "FY5253.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.kwds.html#pandas.tseries.offsets.FY5253.kwds"}, {"function_name": "pandas.tseries.offsets.FY5253.kwds", "full_function": "FY5253.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.kwds.html#pandas.tseries.offsets.FY5253.kwds"}, {"function_name": "pandas.tseries.offsets.FY5253.kwds", "full_function": "FY5253.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.kwds.html#pandas.tseries.offsets.FY5253.kwds"}, {"function_name": "pandas.tseries.offsets.FY5253.is_anchored", "full_function": "FY5253.is_anchored()#", "function_text": "Return boolean whether the frequency is a unit frequency (n=1).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.is_anchored.html#pandas.tseries.offsets.FY5253.is_anchored"}, {"function_name": "pandas.tseries.offsets.FY5253.is_month_start", "full_function": "FY5253.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.is_month_start.html#pandas.tseries.offsets.FY5253.is_month_start"}, {"function_name": "pandas.tseries.offsets.FY5253.is_quarter_start", "full_function": "FY5253.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.is_quarter_start.html#pandas.tseries.offsets.FY5253.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.FY5253.is_year_start", "full_function": "FY5253.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253.is_year_start.html#pandas.tseries.offsets.FY5253.is_year_start"}]}, {"name": "FY5253Quarter", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#fy5253quarter", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.html#pandas.tseries.offsets.FY5253Quarter", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.freqstr.html#pandas.tseries.offsets.FY5253Quarter.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.name.html#pandas.tseries.offsets.FY5253Quarter.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.normalize.html#pandas.tseries.offsets.FY5253Quarter.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.n.html#pandas.tseries.offsets.FY5253Quarter.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.startingMonth.html#pandas.tseries.offsets.FY5253Quarter.startingMonth", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.weekday.html#pandas.tseries.offsets.FY5253Quarter.weekday", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.copy.html#pandas.tseries.offsets.FY5253Quarter.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.get_weeks.html#pandas.tseries.offsets.FY5253Quarter.get_weeks", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.is_on_offset.html#pandas.tseries.offsets.FY5253Quarter.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.is_month_start.html#pandas.tseries.offsets.FY5253Quarter.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.is_quarter_start.html#pandas.tseries.offsets.FY5253Quarter.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.is_year_start.html#pandas.tseries.offsets.FY5253Quarter.is_year_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.kwds.html#pandas.tseries.offsets.FY5253Quarter.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.nanos.html#pandas.tseries.offsets.FY5253Quarter.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.rule_code.html#pandas.tseries.offsets.FY5253Quarter.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.qtr_with_extra_week.html#pandas.tseries.offsets.FY5253Quarter.qtr_with_extra_week", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.variation.html#pandas.tseries.offsets.FY5253Quarter.variation", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.get_rule_code_suffix.html#pandas.tseries.offsets.FY5253Quarter.get_rule_code_suffix", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.is_anchored.html#pandas.tseries.offsets.FY5253Quarter.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.year_has_extra_week.html#pandas.tseries.offsets.FY5253Quarter.year_has_extra_week", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.is_month_end.html#pandas.tseries.offsets.FY5253Quarter.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.is_quarter_end.html#pandas.tseries.offsets.FY5253Quarter.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.is_year_end.html#pandas.tseries.offsets.FY5253Quarter.is_year_end"], "function_definitions": [{"function_name": "pandas.tseries.offsets.FY5253Quarter", "full_function": "class pandas.tseries.offsets.FY5253Quarter#", "function_text": "DateOffset increments between business quarter dates for 52-53 week fiscal year.", "parameter_names_desc": [{"param_name": "n", "param_type": "int", "param_desc": "The number of business quarters represented.\n"}, {"param_name": "normalize", "param_type": "bool, default False", "param_desc": "Normalize start/end dates to midnight before generating date range.\n"}, {"param_name": "weekday", "param_type": "int {0, 1, …, 6}, default 0", "param_desc": "A specific integer for the day of the week.\n\n0 is Monday\n1 is Tuesday\n2 is Wednesday\n3 is Thursday\n4 is Friday\n5 is Saturday\n6 is Sunday.\n\n"}, {"param_name": "startingMonth", "param_type": "int {1, 2, …, 12}, default 1", "param_desc": "The month in which fiscal years end.\n"}, {"param_name": "qtr_with_extra_week", "param_type": "int {1, 2, 3, 4}, default 1", "param_desc": "The quarter number that has the leap or 14 week when needed.\n"}, {"param_name": "variation", "param_type": "str, default “nearest”", "param_desc": "Method of employing 4-4-5 calendar.\nThere are two options:\n\n“nearest” means year end is weekday closest to last day of month in year.\n“last” means year end is final weekday of the final month in fiscal year.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.html#pandas.tseries.offsets.FY5253Quarter"}, {"function_name": "pandas.tseries.offsets.FY5253Quarter.freqstr", "full_function": "FY5253Quarter.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.freqstr.html#pandas.tseries.offsets.FY5253Quarter.freqstr"}, {"function_name": "pandas.tseries.offsets.FY5253Quarter.name", "full_function": "FY5253Quarter.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.name.html#pandas.tseries.offsets.FY5253Quarter.name"}, {"function_name": "pandas.tseries.offsets.FY5253Quarter.name", "full_function": "FY5253Quarter.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.name.html#pandas.tseries.offsets.FY5253Quarter.name"}, {"function_name": "pandas.tseries.offsets.FY5253Quarter.name", "full_function": "FY5253Quarter.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.name.html#pandas.tseries.offsets.FY5253Quarter.name"}, {"function_name": "pandas.tseries.offsets.FY5253Quarter.name", "full_function": "FY5253Quarter.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.name.html#pandas.tseries.offsets.FY5253Quarter.name"}, {"function_name": "pandas.tseries.offsets.FY5253Quarter.name", "full_function": "FY5253Quarter.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.name.html#pandas.tseries.offsets.FY5253Quarter.name"}, {"function_name": "pandas.tseries.offsets.FY5253Quarter.copy", "full_function": "FY5253Quarter.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.copy.html#pandas.tseries.offsets.FY5253Quarter.copy"}, {"function_name": "pandas.tseries.offsets.FY5253Quarter.copy", "full_function": "FY5253Quarter.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.copy.html#pandas.tseries.offsets.FY5253Quarter.copy"}, {"function_name": "pandas.tseries.offsets.FY5253Quarter.is_on_offset", "full_function": "FY5253Quarter.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.is_on_offset.html#pandas.tseries.offsets.FY5253Quarter.is_on_offset"}, {"function_name": "pandas.tseries.offsets.FY5253Quarter.is_month_start", "full_function": "FY5253Quarter.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.is_month_start.html#pandas.tseries.offsets.FY5253Quarter.is_month_start"}, {"function_name": "pandas.tseries.offsets.FY5253Quarter.is_quarter_start", "full_function": "FY5253Quarter.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.is_quarter_start.html#pandas.tseries.offsets.FY5253Quarter.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.FY5253Quarter.is_year_start", "full_function": "FY5253Quarter.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.is_year_start.html#pandas.tseries.offsets.FY5253Quarter.is_year_start"}, {"function_name": "pandas.tseries.offsets.FY5253Quarter.kwds", "full_function": "FY5253Quarter.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.kwds.html#pandas.tseries.offsets.FY5253Quarter.kwds"}, {"function_name": "pandas.tseries.offsets.FY5253Quarter.kwds", "full_function": "FY5253Quarter.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.kwds.html#pandas.tseries.offsets.FY5253Quarter.kwds"}, {"function_name": "pandas.tseries.offsets.FY5253Quarter.kwds", "full_function": "FY5253Quarter.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.kwds.html#pandas.tseries.offsets.FY5253Quarter.kwds"}, {"function_name": "pandas.tseries.offsets.FY5253Quarter.kwds", "full_function": "FY5253Quarter.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.kwds.html#pandas.tseries.offsets.FY5253Quarter.kwds"}, {"function_name": "pandas.tseries.offsets.FY5253Quarter.kwds", "full_function": "FY5253Quarter.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.kwds.html#pandas.tseries.offsets.FY5253Quarter.kwds"}, {"function_name": "pandas.tseries.offsets.FY5253Quarter.kwds", "full_function": "FY5253Quarter.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.kwds.html#pandas.tseries.offsets.FY5253Quarter.kwds"}, {"function_name": "pandas.tseries.offsets.FY5253Quarter.is_anchored", "full_function": "FY5253Quarter.is_anchored()#", "function_text": "Return boolean whether the frequency is a unit frequency (n=1).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.is_anchored.html#pandas.tseries.offsets.FY5253Quarter.is_anchored"}, {"function_name": "pandas.tseries.offsets.FY5253Quarter.is_anchored", "full_function": "FY5253Quarter.is_anchored()#", "function_text": "Return boolean whether the frequency is a unit frequency (n=1).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.is_anchored.html#pandas.tseries.offsets.FY5253Quarter.is_anchored"}, {"function_name": "pandas.tseries.offsets.FY5253Quarter.is_month_end", "full_function": "FY5253Quarter.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.is_month_end.html#pandas.tseries.offsets.FY5253Quarter.is_month_end"}, {"function_name": "pandas.tseries.offsets.FY5253Quarter.is_quarter_end", "full_function": "FY5253Quarter.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.is_quarter_end.html#pandas.tseries.offsets.FY5253Quarter.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.FY5253Quarter.is_year_end", "full_function": "FY5253Quarter.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.FY5253Quarter.is_year_end.html#pandas.tseries.offsets.FY5253Quarter.is_year_end"}]}, {"name": "Easter", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#easter", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.html#pandas.tseries.offsets.Easter", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.freqstr.html#pandas.tseries.offsets.Easter.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.name.html#pandas.tseries.offsets.Easter.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.normalize.html#pandas.tseries.offsets.Easter.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.n.html#pandas.tseries.offsets.Easter.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.copy.html#pandas.tseries.offsets.Easter.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.is_on_offset.html#pandas.tseries.offsets.Easter.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.is_month_end.html#pandas.tseries.offsets.Easter.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.is_quarter_end.html#pandas.tseries.offsets.Easter.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.is_year_end.html#pandas.tseries.offsets.Easter.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.kwds.html#pandas.tseries.offsets.Easter.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.nanos.html#pandas.tseries.offsets.Easter.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.rule_code.html#pandas.tseries.offsets.Easter.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.is_anchored.html#pandas.tseries.offsets.Easter.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.is_month_start.html#pandas.tseries.offsets.Easter.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.is_quarter_start.html#pandas.tseries.offsets.Easter.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.is_year_start.html#pandas.tseries.offsets.Easter.is_year_start"], "function_definitions": [{"function_name": "pandas.tseries.offsets.Easter", "full_function": "class pandas.tseries.offsets.Easter#", "function_text": "DateOffset for the Easter holiday using logic defined in dateutil.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of years represented.\n"}, {"param_name": "normalize", "param_type": "bool, default False", "param_desc": "Normalize start/end dates to midnight before generating date range.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.html#pandas.tseries.offsets.Easter"}, {"function_name": "pandas.tseries.offsets.Easter.freqstr", "full_function": "Easter.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.freqstr.html#pandas.tseries.offsets.Easter.freqstr"}, {"function_name": "pandas.tseries.offsets.Easter.name", "full_function": "Easter.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.name.html#pandas.tseries.offsets.Easter.name"}, {"function_name": "pandas.tseries.offsets.Easter.name", "full_function": "Easter.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.name.html#pandas.tseries.offsets.Easter.name"}, {"function_name": "pandas.tseries.offsets.Easter.name", "full_function": "Easter.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.name.html#pandas.tseries.offsets.Easter.name"}, {"function_name": "pandas.tseries.offsets.Easter.copy", "full_function": "Easter.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.copy.html#pandas.tseries.offsets.Easter.copy"}, {"function_name": "pandas.tseries.offsets.Easter.is_on_offset", "full_function": "Easter.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.is_on_offset.html#pandas.tseries.offsets.Easter.is_on_offset"}, {"function_name": "pandas.tseries.offsets.Easter.is_month_end", "full_function": "Easter.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.is_month_end.html#pandas.tseries.offsets.Easter.is_month_end"}, {"function_name": "pandas.tseries.offsets.Easter.is_quarter_end", "full_function": "Easter.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.is_quarter_end.html#pandas.tseries.offsets.Easter.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.Easter.is_year_end", "full_function": "Easter.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.is_year_end.html#pandas.tseries.offsets.Easter.is_year_end"}, {"function_name": "pandas.tseries.offsets.Easter.kwds", "full_function": "Easter.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.kwds.html#pandas.tseries.offsets.Easter.kwds"}, {"function_name": "pandas.tseries.offsets.Easter.kwds", "full_function": "Easter.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.kwds.html#pandas.tseries.offsets.Easter.kwds"}, {"function_name": "pandas.tseries.offsets.Easter.kwds", "full_function": "Easter.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.kwds.html#pandas.tseries.offsets.Easter.kwds"}, {"function_name": "pandas.tseries.offsets.Easter.is_anchored", "full_function": "Easter.is_anchored()#", "function_text": "Return boolean whether the frequency is a unit frequency (n=1).", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.is_anchored.html#pandas.tseries.offsets.Easter.is_anchored"}, {"function_name": "pandas.tseries.offsets.Easter.is_month_start", "full_function": "Easter.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.is_month_start.html#pandas.tseries.offsets.Easter.is_month_start"}, {"function_name": "pandas.tseries.offsets.Easter.is_quarter_start", "full_function": "Easter.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.is_quarter_start.html#pandas.tseries.offsets.Easter.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.Easter.is_year_start", "full_function": "Easter.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Easter.is_year_start.html#pandas.tseries.offsets.Easter.is_year_start"}]}, {"name": "Tick", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#tick", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.html#pandas.tseries.offsets.Tick", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.delta.html#pandas.tseries.offsets.Tick.delta", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.kwds.html#pandas.tseries.offsets.Tick.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.nanos.html#pandas.tseries.offsets.Tick.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.rule_code.html#pandas.tseries.offsets.Tick.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.copy.html#pandas.tseries.offsets.Tick.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.is_on_offset.html#pandas.tseries.offsets.Tick.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.is_month_end.html#pandas.tseries.offsets.Tick.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.is_quarter_end.html#pandas.tseries.offsets.Tick.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.is_year_end.html#pandas.tseries.offsets.Tick.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.freqstr.html#pandas.tseries.offsets.Tick.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.name.html#pandas.tseries.offsets.Tick.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.normalize.html#pandas.tseries.offsets.Tick.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.n.html#pandas.tseries.offsets.Tick.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.is_anchored.html#pandas.tseries.offsets.Tick.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.is_month_start.html#pandas.tseries.offsets.Tick.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.is_quarter_start.html#pandas.tseries.offsets.Tick.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.is_year_start.html#pandas.tseries.offsets.Tick.is_year_start"], "function_definitions": [{"function_name": "pandas.tseries.offsets.Tick", "full_function": "class pandas.tseries.offsets.Tick#", "function_text": "Attributes", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.html#pandas.tseries.offsets.Tick"}, {"function_name": "pandas.tseries.offsets.Tick", "full_function": "class pandas.tseries.offsets.Tick#", "function_text": "Attributes", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.html#pandas.tseries.offsets.Tick"}, {"function_name": "pandas.tseries.offsets.Tick.kwds", "full_function": "Tick.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.kwds.html#pandas.tseries.offsets.Tick.kwds"}, {"function_name": "pandas.tseries.offsets.Tick.nanos", "full_function": "Tick.nanos#", "function_text": "Return an integer of the total number of nanoseconds.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.nanos.html#pandas.tseries.offsets.Tick.nanos"}, {"function_name": "pandas.tseries.offsets.Tick.nanos", "full_function": "Tick.nanos#", "function_text": "Return an integer of the total number of nanoseconds.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.nanos.html#pandas.tseries.offsets.Tick.nanos"}, {"function_name": "pandas.tseries.offsets.Tick.copy", "full_function": "Tick.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.copy.html#pandas.tseries.offsets.Tick.copy"}, {"function_name": "pandas.tseries.offsets.Tick.is_on_offset", "full_function": "Tick.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.is_on_offset.html#pandas.tseries.offsets.Tick.is_on_offset"}, {"function_name": "pandas.tseries.offsets.Tick.is_month_end", "full_function": "Tick.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.is_month_end.html#pandas.tseries.offsets.Tick.is_month_end"}, {"function_name": "pandas.tseries.offsets.Tick.is_quarter_end", "full_function": "Tick.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.is_quarter_end.html#pandas.tseries.offsets.Tick.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.Tick.is_year_end", "full_function": "Tick.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.is_year_end.html#pandas.tseries.offsets.Tick.is_year_end"}, {"function_name": "pandas.tseries.offsets.Tick.freqstr", "full_function": "Tick.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.freqstr.html#pandas.tseries.offsets.Tick.freqstr"}, {"function_name": "pandas.tseries.offsets.Tick.name", "full_function": "Tick.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.name.html#pandas.tseries.offsets.Tick.name"}, {"function_name": "pandas.tseries.offsets.Tick.name", "full_function": "Tick.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.name.html#pandas.tseries.offsets.Tick.name"}, {"function_name": "pandas.tseries.offsets.Tick.name", "full_function": "Tick.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.name.html#pandas.tseries.offsets.Tick.name"}, {"function_name": "pandas.tseries.offsets.Tick.is_anchored", "full_function": "Tick.is_anchored()#", "function_text": "Return False.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.is_anchored.html#pandas.tseries.offsets.Tick.is_anchored"}, {"function_name": "pandas.tseries.offsets.Tick.is_month_start", "full_function": "Tick.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.is_month_start.html#pandas.tseries.offsets.Tick.is_month_start"}, {"function_name": "pandas.tseries.offsets.Tick.is_quarter_start", "full_function": "Tick.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.is_quarter_start.html#pandas.tseries.offsets.Tick.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.Tick.is_year_start", "full_function": "Tick.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Tick.is_year_start.html#pandas.tseries.offsets.Tick.is_year_start"}]}, {"name": "Day", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#day", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.html#pandas.tseries.offsets.Day", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.delta.html#pandas.tseries.offsets.Day.delta", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.kwds.html#pandas.tseries.offsets.Day.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.nanos.html#pandas.tseries.offsets.Day.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.rule_code.html#pandas.tseries.offsets.Day.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.copy.html#pandas.tseries.offsets.Day.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.is_on_offset.html#pandas.tseries.offsets.Day.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.is_month_end.html#pandas.tseries.offsets.Day.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.is_quarter_end.html#pandas.tseries.offsets.Day.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.is_year_end.html#pandas.tseries.offsets.Day.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.freqstr.html#pandas.tseries.offsets.Day.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.name.html#pandas.tseries.offsets.Day.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.normalize.html#pandas.tseries.offsets.Day.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.n.html#pandas.tseries.offsets.Day.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.is_anchored.html#pandas.tseries.offsets.Day.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.is_month_start.html#pandas.tseries.offsets.Day.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.is_quarter_start.html#pandas.tseries.offsets.Day.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.is_year_start.html#pandas.tseries.offsets.Day.is_year_start"], "function_definitions": [{"function_name": "pandas.tseries.offsets.Day", "full_function": "class pandas.tseries.offsets.Day#", "function_text": "Offset n days.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of days represented.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.html#pandas.tseries.offsets.Day"}, {"function_name": "pandas.tseries.offsets.Day", "full_function": "class pandas.tseries.offsets.Day#", "function_text": "Offset n days.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of days represented.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.html#pandas.tseries.offsets.Day"}, {"function_name": "pandas.tseries.offsets.Day.kwds", "full_function": "Day.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.kwds.html#pandas.tseries.offsets.Day.kwds"}, {"function_name": "pandas.tseries.offsets.Day.nanos", "full_function": "Day.nanos#", "function_text": "Return an integer of the total number of nanoseconds.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.nanos.html#pandas.tseries.offsets.Day.nanos"}, {"function_name": "pandas.tseries.offsets.Day.nanos", "full_function": "Day.nanos#", "function_text": "Return an integer of the total number of nanoseconds.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.nanos.html#pandas.tseries.offsets.Day.nanos"}, {"function_name": "pandas.tseries.offsets.Day.copy", "full_function": "Day.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.copy.html#pandas.tseries.offsets.Day.copy"}, {"function_name": "pandas.tseries.offsets.Day.is_on_offset", "full_function": "Day.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.is_on_offset.html#pandas.tseries.offsets.Day.is_on_offset"}, {"function_name": "pandas.tseries.offsets.Day.is_month_end", "full_function": "Day.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.is_month_end.html#pandas.tseries.offsets.Day.is_month_end"}, {"function_name": "pandas.tseries.offsets.Day.is_quarter_end", "full_function": "Day.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.is_quarter_end.html#pandas.tseries.offsets.Day.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.Day.is_year_end", "full_function": "Day.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.is_year_end.html#pandas.tseries.offsets.Day.is_year_end"}, {"function_name": "pandas.tseries.offsets.Day.freqstr", "full_function": "Day.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.freqstr.html#pandas.tseries.offsets.Day.freqstr"}, {"function_name": "pandas.tseries.offsets.Day.name", "full_function": "Day.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.name.html#pandas.tseries.offsets.Day.name"}, {"function_name": "pandas.tseries.offsets.Day.name", "full_function": "Day.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.name.html#pandas.tseries.offsets.Day.name"}, {"function_name": "pandas.tseries.offsets.Day.name", "full_function": "Day.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.name.html#pandas.tseries.offsets.Day.name"}, {"function_name": "pandas.tseries.offsets.Day.is_anchored", "full_function": "Day.is_anchored()#", "function_text": "Return False.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.is_anchored.html#pandas.tseries.offsets.Day.is_anchored"}, {"function_name": "pandas.tseries.offsets.Day.is_month_start", "full_function": "Day.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.is_month_start.html#pandas.tseries.offsets.Day.is_month_start"}, {"function_name": "pandas.tseries.offsets.Day.is_quarter_start", "full_function": "Day.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.is_quarter_start.html#pandas.tseries.offsets.Day.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.Day.is_year_start", "full_function": "Day.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Day.is_year_start.html#pandas.tseries.offsets.Day.is_year_start"}]}, {"name": "Hour", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#hour", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.html#pandas.tseries.offsets.Hour", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.delta.html#pandas.tseries.offsets.Hour.delta", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.kwds.html#pandas.tseries.offsets.Hour.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.nanos.html#pandas.tseries.offsets.Hour.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.rule_code.html#pandas.tseries.offsets.Hour.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.copy.html#pandas.tseries.offsets.Hour.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.is_on_offset.html#pandas.tseries.offsets.Hour.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.is_month_end.html#pandas.tseries.offsets.Hour.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.is_quarter_end.html#pandas.tseries.offsets.Hour.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.is_year_end.html#pandas.tseries.offsets.Hour.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.freqstr.html#pandas.tseries.offsets.Hour.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.name.html#pandas.tseries.offsets.Hour.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.normalize.html#pandas.tseries.offsets.Hour.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.n.html#pandas.tseries.offsets.Hour.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.is_anchored.html#pandas.tseries.offsets.Hour.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.is_month_start.html#pandas.tseries.offsets.Hour.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.is_quarter_start.html#pandas.tseries.offsets.Hour.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.is_year_start.html#pandas.tseries.offsets.Hour.is_year_start"], "function_definitions": [{"function_name": "pandas.tseries.offsets.Hour", "full_function": "class pandas.tseries.offsets.Hour#", "function_text": "Offset n hours.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of hours represented.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.html#pandas.tseries.offsets.Hour"}, {"function_name": "pandas.tseries.offsets.Hour", "full_function": "class pandas.tseries.offsets.Hour#", "function_text": "Offset n hours.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of hours represented.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.html#pandas.tseries.offsets.Hour"}, {"function_name": "pandas.tseries.offsets.Hour.kwds", "full_function": "Hour.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.kwds.html#pandas.tseries.offsets.Hour.kwds"}, {"function_name": "pandas.tseries.offsets.Hour.nanos", "full_function": "Hour.nanos#", "function_text": "Return an integer of the total number of nanoseconds.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.nanos.html#pandas.tseries.offsets.Hour.nanos"}, {"function_name": "pandas.tseries.offsets.Hour.nanos", "full_function": "Hour.nanos#", "function_text": "Return an integer of the total number of nanoseconds.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.nanos.html#pandas.tseries.offsets.Hour.nanos"}, {"function_name": "pandas.tseries.offsets.Hour.copy", "full_function": "Hour.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.copy.html#pandas.tseries.offsets.Hour.copy"}, {"function_name": "pandas.tseries.offsets.Hour.is_on_offset", "full_function": "Hour.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.is_on_offset.html#pandas.tseries.offsets.Hour.is_on_offset"}, {"function_name": "pandas.tseries.offsets.Hour.is_month_end", "full_function": "Hour.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.is_month_end.html#pandas.tseries.offsets.Hour.is_month_end"}, {"function_name": "pandas.tseries.offsets.Hour.is_quarter_end", "full_function": "Hour.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.is_quarter_end.html#pandas.tseries.offsets.Hour.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.Hour.is_year_end", "full_function": "Hour.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.is_year_end.html#pandas.tseries.offsets.Hour.is_year_end"}, {"function_name": "pandas.tseries.offsets.Hour.freqstr", "full_function": "Hour.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.freqstr.html#pandas.tseries.offsets.Hour.freqstr"}, {"function_name": "pandas.tseries.offsets.Hour.name", "full_function": "Hour.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.name.html#pandas.tseries.offsets.Hour.name"}, {"function_name": "pandas.tseries.offsets.Hour.name", "full_function": "Hour.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.name.html#pandas.tseries.offsets.Hour.name"}, {"function_name": "pandas.tseries.offsets.Hour.name", "full_function": "Hour.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.name.html#pandas.tseries.offsets.Hour.name"}, {"function_name": "pandas.tseries.offsets.Hour.is_anchored", "full_function": "Hour.is_anchored()#", "function_text": "Return False.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.is_anchored.html#pandas.tseries.offsets.Hour.is_anchored"}, {"function_name": "pandas.tseries.offsets.Hour.is_month_start", "full_function": "Hour.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.is_month_start.html#pandas.tseries.offsets.Hour.is_month_start"}, {"function_name": "pandas.tseries.offsets.Hour.is_quarter_start", "full_function": "Hour.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.is_quarter_start.html#pandas.tseries.offsets.Hour.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.Hour.is_year_start", "full_function": "Hour.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Hour.is_year_start.html#pandas.tseries.offsets.Hour.is_year_start"}]}, {"name": "Minute", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#minute", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.html#pandas.tseries.offsets.Minute", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.delta.html#pandas.tseries.offsets.Minute.delta", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.kwds.html#pandas.tseries.offsets.Minute.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.nanos.html#pandas.tseries.offsets.Minute.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.rule_code.html#pandas.tseries.offsets.Minute.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.copy.html#pandas.tseries.offsets.Minute.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.is_on_offset.html#pandas.tseries.offsets.Minute.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.is_month_end.html#pandas.tseries.offsets.Minute.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.is_quarter_end.html#pandas.tseries.offsets.Minute.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.is_year_end.html#pandas.tseries.offsets.Minute.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.freqstr.html#pandas.tseries.offsets.Minute.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.name.html#pandas.tseries.offsets.Minute.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.normalize.html#pandas.tseries.offsets.Minute.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.n.html#pandas.tseries.offsets.Minute.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.is_anchored.html#pandas.tseries.offsets.Minute.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.is_month_start.html#pandas.tseries.offsets.Minute.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.is_quarter_start.html#pandas.tseries.offsets.Minute.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.is_year_start.html#pandas.tseries.offsets.Minute.is_year_start"], "function_definitions": [{"function_name": "pandas.tseries.offsets.Minute", "full_function": "class pandas.tseries.offsets.Minute#", "function_text": "Offset n minutes.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of minutes represented.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.html#pandas.tseries.offsets.Minute"}, {"function_name": "pandas.tseries.offsets.Minute", "full_function": "class pandas.tseries.offsets.Minute#", "function_text": "Offset n minutes.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of minutes represented.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.html#pandas.tseries.offsets.Minute"}, {"function_name": "pandas.tseries.offsets.Minute.kwds", "full_function": "Minute.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.kwds.html#pandas.tseries.offsets.Minute.kwds"}, {"function_name": "pandas.tseries.offsets.Minute.nanos", "full_function": "Minute.nanos#", "function_text": "Return an integer of the total number of nanoseconds.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.nanos.html#pandas.tseries.offsets.Minute.nanos"}, {"function_name": "pandas.tseries.offsets.Minute.nanos", "full_function": "Minute.nanos#", "function_text": "Return an integer of the total number of nanoseconds.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.nanos.html#pandas.tseries.offsets.Minute.nanos"}, {"function_name": "pandas.tseries.offsets.Minute.copy", "full_function": "Minute.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.copy.html#pandas.tseries.offsets.Minute.copy"}, {"function_name": "pandas.tseries.offsets.Minute.is_on_offset", "full_function": "Minute.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.is_on_offset.html#pandas.tseries.offsets.Minute.is_on_offset"}, {"function_name": "pandas.tseries.offsets.Minute.is_month_end", "full_function": "Minute.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.is_month_end.html#pandas.tseries.offsets.Minute.is_month_end"}, {"function_name": "pandas.tseries.offsets.Minute.is_quarter_end", "full_function": "Minute.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.is_quarter_end.html#pandas.tseries.offsets.Minute.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.Minute.is_year_end", "full_function": "Minute.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.is_year_end.html#pandas.tseries.offsets.Minute.is_year_end"}, {"function_name": "pandas.tseries.offsets.Minute.freqstr", "full_function": "Minute.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.freqstr.html#pandas.tseries.offsets.Minute.freqstr"}, {"function_name": "pandas.tseries.offsets.Minute.name", "full_function": "Minute.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.name.html#pandas.tseries.offsets.Minute.name"}, {"function_name": "pandas.tseries.offsets.Minute.name", "full_function": "Minute.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.name.html#pandas.tseries.offsets.Minute.name"}, {"function_name": "pandas.tseries.offsets.Minute.name", "full_function": "Minute.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.name.html#pandas.tseries.offsets.Minute.name"}, {"function_name": "pandas.tseries.offsets.Minute.is_anchored", "full_function": "Minute.is_anchored()#", "function_text": "Return False.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.is_anchored.html#pandas.tseries.offsets.Minute.is_anchored"}, {"function_name": "pandas.tseries.offsets.Minute.is_month_start", "full_function": "Minute.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.is_month_start.html#pandas.tseries.offsets.Minute.is_month_start"}, {"function_name": "pandas.tseries.offsets.Minute.is_quarter_start", "full_function": "Minute.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.is_quarter_start.html#pandas.tseries.offsets.Minute.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.Minute.is_year_start", "full_function": "Minute.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Minute.is_year_start.html#pandas.tseries.offsets.Minute.is_year_start"}]}, {"name": "Second", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#second", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.html#pandas.tseries.offsets.Second", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.delta.html#pandas.tseries.offsets.Second.delta", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.kwds.html#pandas.tseries.offsets.Second.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.nanos.html#pandas.tseries.offsets.Second.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.rule_code.html#pandas.tseries.offsets.Second.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.copy.html#pandas.tseries.offsets.Second.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.is_on_offset.html#pandas.tseries.offsets.Second.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.is_month_end.html#pandas.tseries.offsets.Second.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.is_quarter_end.html#pandas.tseries.offsets.Second.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.is_year_end.html#pandas.tseries.offsets.Second.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.freqstr.html#pandas.tseries.offsets.Second.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.name.html#pandas.tseries.offsets.Second.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.normalize.html#pandas.tseries.offsets.Second.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.n.html#pandas.tseries.offsets.Second.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.is_anchored.html#pandas.tseries.offsets.Second.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.is_month_start.html#pandas.tseries.offsets.Second.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.is_quarter_start.html#pandas.tseries.offsets.Second.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.is_year_start.html#pandas.tseries.offsets.Second.is_year_start"], "function_definitions": [{"function_name": "pandas.tseries.offsets.Second", "full_function": "class pandas.tseries.offsets.Second#", "function_text": "Offset n seconds.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of seconds represented.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.html#pandas.tseries.offsets.Second"}, {"function_name": "pandas.tseries.offsets.Second", "full_function": "class pandas.tseries.offsets.Second#", "function_text": "Offset n seconds.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of seconds represented.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.html#pandas.tseries.offsets.Second"}, {"function_name": "pandas.tseries.offsets.Second.kwds", "full_function": "Second.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.kwds.html#pandas.tseries.offsets.Second.kwds"}, {"function_name": "pandas.tseries.offsets.Second.nanos", "full_function": "Second.nanos#", "function_text": "Return an integer of the total number of nanoseconds.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.nanos.html#pandas.tseries.offsets.Second.nanos"}, {"function_name": "pandas.tseries.offsets.Second.nanos", "full_function": "Second.nanos#", "function_text": "Return an integer of the total number of nanoseconds.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.nanos.html#pandas.tseries.offsets.Second.nanos"}, {"function_name": "pandas.tseries.offsets.Second.copy", "full_function": "Second.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.copy.html#pandas.tseries.offsets.Second.copy"}, {"function_name": "pandas.tseries.offsets.Second.is_on_offset", "full_function": "Second.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.is_on_offset.html#pandas.tseries.offsets.Second.is_on_offset"}, {"function_name": "pandas.tseries.offsets.Second.is_month_end", "full_function": "Second.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.is_month_end.html#pandas.tseries.offsets.Second.is_month_end"}, {"function_name": "pandas.tseries.offsets.Second.is_quarter_end", "full_function": "Second.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.is_quarter_end.html#pandas.tseries.offsets.Second.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.Second.is_year_end", "full_function": "Second.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.is_year_end.html#pandas.tseries.offsets.Second.is_year_end"}, {"function_name": "pandas.tseries.offsets.Second.freqstr", "full_function": "Second.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.freqstr.html#pandas.tseries.offsets.Second.freqstr"}, {"function_name": "pandas.tseries.offsets.Second.name", "full_function": "Second.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.name.html#pandas.tseries.offsets.Second.name"}, {"function_name": "pandas.tseries.offsets.Second.name", "full_function": "Second.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.name.html#pandas.tseries.offsets.Second.name"}, {"function_name": "pandas.tseries.offsets.Second.name", "full_function": "Second.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.name.html#pandas.tseries.offsets.Second.name"}, {"function_name": "pandas.tseries.offsets.Second.is_anchored", "full_function": "Second.is_anchored()#", "function_text": "Return False.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.is_anchored.html#pandas.tseries.offsets.Second.is_anchored"}, {"function_name": "pandas.tseries.offsets.Second.is_month_start", "full_function": "Second.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.is_month_start.html#pandas.tseries.offsets.Second.is_month_start"}, {"function_name": "pandas.tseries.offsets.Second.is_quarter_start", "full_function": "Second.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.is_quarter_start.html#pandas.tseries.offsets.Second.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.Second.is_year_start", "full_function": "Second.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Second.is_year_start.html#pandas.tseries.offsets.Second.is_year_start"}]}, {"name": "Milli", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#milli", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.html#pandas.tseries.offsets.Milli", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.delta.html#pandas.tseries.offsets.Milli.delta", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.kwds.html#pandas.tseries.offsets.Milli.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.nanos.html#pandas.tseries.offsets.Milli.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.rule_code.html#pandas.tseries.offsets.Milli.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.copy.html#pandas.tseries.offsets.Milli.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.is_on_offset.html#pandas.tseries.offsets.Milli.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.is_month_end.html#pandas.tseries.offsets.Milli.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.is_quarter_end.html#pandas.tseries.offsets.Milli.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.is_year_end.html#pandas.tseries.offsets.Milli.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.freqstr.html#pandas.tseries.offsets.Milli.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.name.html#pandas.tseries.offsets.Milli.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.normalize.html#pandas.tseries.offsets.Milli.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.n.html#pandas.tseries.offsets.Milli.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.is_anchored.html#pandas.tseries.offsets.Milli.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.is_month_start.html#pandas.tseries.offsets.Milli.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.is_quarter_start.html#pandas.tseries.offsets.Milli.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.is_year_start.html#pandas.tseries.offsets.Milli.is_year_start"], "function_definitions": [{"function_name": "pandas.tseries.offsets.Milli", "full_function": "class pandas.tseries.offsets.Milli#", "function_text": "Offset n milliseconds.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of milliseconds represented.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.html#pandas.tseries.offsets.Milli"}, {"function_name": "pandas.tseries.offsets.Milli", "full_function": "class pandas.tseries.offsets.Milli#", "function_text": "Offset n milliseconds.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of milliseconds represented.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.html#pandas.tseries.offsets.Milli"}, {"function_name": "pandas.tseries.offsets.Milli.kwds", "full_function": "Milli.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.kwds.html#pandas.tseries.offsets.Milli.kwds"}, {"function_name": "pandas.tseries.offsets.Milli.nanos", "full_function": "Milli.nanos#", "function_text": "Return an integer of the total number of nanoseconds.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.nanos.html#pandas.tseries.offsets.Milli.nanos"}, {"function_name": "pandas.tseries.offsets.Milli.nanos", "full_function": "Milli.nanos#", "function_text": "Return an integer of the total number of nanoseconds.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.nanos.html#pandas.tseries.offsets.Milli.nanos"}, {"function_name": "pandas.tseries.offsets.Milli.copy", "full_function": "Milli.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.copy.html#pandas.tseries.offsets.Milli.copy"}, {"function_name": "pandas.tseries.offsets.Milli.is_on_offset", "full_function": "Milli.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.is_on_offset.html#pandas.tseries.offsets.Milli.is_on_offset"}, {"function_name": "pandas.tseries.offsets.Milli.is_month_end", "full_function": "Milli.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.is_month_end.html#pandas.tseries.offsets.Milli.is_month_end"}, {"function_name": "pandas.tseries.offsets.Milli.is_quarter_end", "full_function": "Milli.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.is_quarter_end.html#pandas.tseries.offsets.Milli.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.Milli.is_year_end", "full_function": "Milli.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.is_year_end.html#pandas.tseries.offsets.Milli.is_year_end"}, {"function_name": "pandas.tseries.offsets.Milli.freqstr", "full_function": "Milli.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.freqstr.html#pandas.tseries.offsets.Milli.freqstr"}, {"function_name": "pandas.tseries.offsets.Milli.name", "full_function": "Milli.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.name.html#pandas.tseries.offsets.Milli.name"}, {"function_name": "pandas.tseries.offsets.Milli.name", "full_function": "Milli.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.name.html#pandas.tseries.offsets.Milli.name"}, {"function_name": "pandas.tseries.offsets.Milli.name", "full_function": "Milli.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.name.html#pandas.tseries.offsets.Milli.name"}, {"function_name": "pandas.tseries.offsets.Milli.is_anchored", "full_function": "Milli.is_anchored()#", "function_text": "Return False.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.is_anchored.html#pandas.tseries.offsets.Milli.is_anchored"}, {"function_name": "pandas.tseries.offsets.Milli.is_month_start", "full_function": "Milli.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.is_month_start.html#pandas.tseries.offsets.Milli.is_month_start"}, {"function_name": "pandas.tseries.offsets.Milli.is_quarter_start", "full_function": "Milli.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.is_quarter_start.html#pandas.tseries.offsets.Milli.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.Milli.is_year_start", "full_function": "Milli.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Milli.is_year_start.html#pandas.tseries.offsets.Milli.is_year_start"}]}, {"name": "Micro", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#micro", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.html#pandas.tseries.offsets.Micro", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.delta.html#pandas.tseries.offsets.Micro.delta", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.kwds.html#pandas.tseries.offsets.Micro.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.nanos.html#pandas.tseries.offsets.Micro.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.rule_code.html#pandas.tseries.offsets.Micro.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.copy.html#pandas.tseries.offsets.Micro.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.is_on_offset.html#pandas.tseries.offsets.Micro.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.is_month_end.html#pandas.tseries.offsets.Micro.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.is_quarter_end.html#pandas.tseries.offsets.Micro.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.is_year_end.html#pandas.tseries.offsets.Micro.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.freqstr.html#pandas.tseries.offsets.Micro.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.name.html#pandas.tseries.offsets.Micro.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.normalize.html#pandas.tseries.offsets.Micro.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.n.html#pandas.tseries.offsets.Micro.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.is_anchored.html#pandas.tseries.offsets.Micro.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.is_month_start.html#pandas.tseries.offsets.Micro.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.is_quarter_start.html#pandas.tseries.offsets.Micro.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.is_year_start.html#pandas.tseries.offsets.Micro.is_year_start"], "function_definitions": [{"function_name": "pandas.tseries.offsets.Micro", "full_function": "class pandas.tseries.offsets.Micro#", "function_text": "Offset n microseconds.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of microseconds represented.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.html#pandas.tseries.offsets.Micro"}, {"function_name": "pandas.tseries.offsets.Micro", "full_function": "class pandas.tseries.offsets.Micro#", "function_text": "Offset n microseconds.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of microseconds represented.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.html#pandas.tseries.offsets.Micro"}, {"function_name": "pandas.tseries.offsets.Micro.kwds", "full_function": "Micro.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.kwds.html#pandas.tseries.offsets.Micro.kwds"}, {"function_name": "pandas.tseries.offsets.Micro.nanos", "full_function": "Micro.nanos#", "function_text": "Return an integer of the total number of nanoseconds.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.nanos.html#pandas.tseries.offsets.Micro.nanos"}, {"function_name": "pandas.tseries.offsets.Micro.nanos", "full_function": "Micro.nanos#", "function_text": "Return an integer of the total number of nanoseconds.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.nanos.html#pandas.tseries.offsets.Micro.nanos"}, {"function_name": "pandas.tseries.offsets.Micro.copy", "full_function": "Micro.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.copy.html#pandas.tseries.offsets.Micro.copy"}, {"function_name": "pandas.tseries.offsets.Micro.is_on_offset", "full_function": "Micro.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.is_on_offset.html#pandas.tseries.offsets.Micro.is_on_offset"}, {"function_name": "pandas.tseries.offsets.Micro.is_month_end", "full_function": "Micro.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.is_month_end.html#pandas.tseries.offsets.Micro.is_month_end"}, {"function_name": "pandas.tseries.offsets.Micro.is_quarter_end", "full_function": "Micro.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.is_quarter_end.html#pandas.tseries.offsets.Micro.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.Micro.is_year_end", "full_function": "Micro.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.is_year_end.html#pandas.tseries.offsets.Micro.is_year_end"}, {"function_name": "pandas.tseries.offsets.Micro.freqstr", "full_function": "Micro.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.freqstr.html#pandas.tseries.offsets.Micro.freqstr"}, {"function_name": "pandas.tseries.offsets.Micro.name", "full_function": "Micro.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.name.html#pandas.tseries.offsets.Micro.name"}, {"function_name": "pandas.tseries.offsets.Micro.name", "full_function": "Micro.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.name.html#pandas.tseries.offsets.Micro.name"}, {"function_name": "pandas.tseries.offsets.Micro.name", "full_function": "Micro.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.name.html#pandas.tseries.offsets.Micro.name"}, {"function_name": "pandas.tseries.offsets.Micro.is_anchored", "full_function": "Micro.is_anchored()#", "function_text": "Return False.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.is_anchored.html#pandas.tseries.offsets.Micro.is_anchored"}, {"function_name": "pandas.tseries.offsets.Micro.is_month_start", "full_function": "Micro.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.is_month_start.html#pandas.tseries.offsets.Micro.is_month_start"}, {"function_name": "pandas.tseries.offsets.Micro.is_quarter_start", "full_function": "Micro.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.is_quarter_start.html#pandas.tseries.offsets.Micro.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.Micro.is_year_start", "full_function": "Micro.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Micro.is_year_start.html#pandas.tseries.offsets.Micro.is_year_start"}]}, {"name": "Nano", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#nano", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.html#pandas.tseries.offsets.Nano", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.delta.html#pandas.tseries.offsets.Nano.delta", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.kwds.html#pandas.tseries.offsets.Nano.kwds", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.nanos.html#pandas.tseries.offsets.Nano.nanos", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.rule_code.html#pandas.tseries.offsets.Nano.rule_code", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.copy.html#pandas.tseries.offsets.Nano.copy", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.is_on_offset.html#pandas.tseries.offsets.Nano.is_on_offset", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.is_month_end.html#pandas.tseries.offsets.Nano.is_month_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.is_quarter_end.html#pandas.tseries.offsets.Nano.is_quarter_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.is_year_end.html#pandas.tseries.offsets.Nano.is_year_end", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.freqstr.html#pandas.tseries.offsets.Nano.freqstr", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.name.html#pandas.tseries.offsets.Nano.name", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.normalize.html#pandas.tseries.offsets.Nano.normalize", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.n.html#pandas.tseries.offsets.Nano.n", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.is_anchored.html#pandas.tseries.offsets.Nano.is_anchored", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.is_month_start.html#pandas.tseries.offsets.Nano.is_month_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.is_quarter_start.html#pandas.tseries.offsets.Nano.is_quarter_start", "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.is_year_start.html#pandas.tseries.offsets.Nano.is_year_start"], "function_definitions": [{"function_name": "pandas.tseries.offsets.Nano", "full_function": "class pandas.tseries.offsets.Nano#", "function_text": "Offset n nanoseconds.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of nanoseconds represented.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.html#pandas.tseries.offsets.Nano"}, {"function_name": "pandas.tseries.offsets.Nano", "full_function": "class pandas.tseries.offsets.Nano#", "function_text": "Offset n nanoseconds.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 1", "param_desc": "The number of nanoseconds represented.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.html#pandas.tseries.offsets.Nano"}, {"function_name": "pandas.tseries.offsets.Nano.kwds", "full_function": "Nano.kwds#", "function_text": "Return a dict of extra parameters for the offset.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.kwds.html#pandas.tseries.offsets.Nano.kwds"}, {"function_name": "pandas.tseries.offsets.Nano.nanos", "full_function": "Nano.nanos#", "function_text": "Return an integer of the total number of nanoseconds.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.nanos.html#pandas.tseries.offsets.Nano.nanos"}, {"function_name": "pandas.tseries.offsets.Nano.nanos", "full_function": "Nano.nanos#", "function_text": "Return an integer of the total number of nanoseconds.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.nanos.html#pandas.tseries.offsets.Nano.nanos"}, {"function_name": "pandas.tseries.offsets.Nano.copy", "full_function": "Nano.copy()#", "function_text": "Return a copy of the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.copy.html#pandas.tseries.offsets.Nano.copy"}, {"function_name": "pandas.tseries.offsets.Nano.is_on_offset", "full_function": "Nano.is_on_offset(dt)#", "function_text": "Return boolean whether a timestamp intersects with this frequency.", "parameter_names_desc": [{"param_name": "dt", "param_type": "datetime.datetime", "param_desc": "Timestamp to check intersections with frequency.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.is_on_offset.html#pandas.tseries.offsets.Nano.is_on_offset"}, {"function_name": "pandas.tseries.offsets.Nano.is_month_end", "full_function": "Nano.is_month_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.is_month_end.html#pandas.tseries.offsets.Nano.is_month_end"}, {"function_name": "pandas.tseries.offsets.Nano.is_quarter_end", "full_function": "Nano.is_quarter_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.is_quarter_end.html#pandas.tseries.offsets.Nano.is_quarter_end"}, {"function_name": "pandas.tseries.offsets.Nano.is_year_end", "full_function": "Nano.is_year_end(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year end.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.is_year_end.html#pandas.tseries.offsets.Nano.is_year_end"}, {"function_name": "pandas.tseries.offsets.Nano.freqstr", "full_function": "Nano.freqstr#", "function_text": "Return a string representing the frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.freqstr.html#pandas.tseries.offsets.Nano.freqstr"}, {"function_name": "pandas.tseries.offsets.Nano.name", "full_function": "Nano.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.name.html#pandas.tseries.offsets.Nano.name"}, {"function_name": "pandas.tseries.offsets.Nano.name", "full_function": "Nano.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.name.html#pandas.tseries.offsets.Nano.name"}, {"function_name": "pandas.tseries.offsets.Nano.name", "full_function": "Nano.name#", "function_text": "Return a string representing the base frequency.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.name.html#pandas.tseries.offsets.Nano.name"}, {"function_name": "pandas.tseries.offsets.Nano.is_anchored", "full_function": "Nano.is_anchored()#", "function_text": "Return False.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.is_anchored.html#pandas.tseries.offsets.Nano.is_anchored"}, {"function_name": "pandas.tseries.offsets.Nano.is_month_start", "full_function": "Nano.is_month_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the month start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.is_month_start.html#pandas.tseries.offsets.Nano.is_month_start"}, {"function_name": "pandas.tseries.offsets.Nano.is_quarter_start", "full_function": "Nano.is_quarter_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the quarter start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.is_quarter_start.html#pandas.tseries.offsets.Nano.is_quarter_start"}, {"function_name": "pandas.tseries.offsets.Nano.is_year_start", "full_function": "Nano.is_year_start(ts)#", "function_text": "Return boolean whether a timestamp occurs on the year start.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.Nano.is_year_start.html#pandas.tseries.offsets.Nano.is_year_start"}]}, {"name": "Frequencies", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html#frequencies", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.tseries.frequencies.to_offset.html#pandas.tseries.frequencies.to_offset"], "function_definitions": [{"function_name": "pandas.tseries.frequencies.to_offset", "full_function": "pandas.tseries.frequencies.to_offset(freq, is_period=False)#", "function_text": "Return DateOffset object from string or datetime.timedelta object.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.frequencies.to_offset.html#pandas.tseries.frequencies.to_offset"}]}], "name": "Date offsets", "url": "https://pandas.pydata.org/docs/reference/offset_frequency.html"}, "window.html": {"functions": [{"name": "Rolling window functions", "url": "https://pandas.pydata.org/docs/reference/window.html#rolling-window-functions", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.count.html#pandas.core.window.rolling.Rolling.count", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.mean.html#pandas.core.window.rolling.Rolling.mean", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.var.html#pandas.core.window.rolling.Rolling.var", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.min.html#pandas.core.window.rolling.Rolling.min", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.corr.html#pandas.core.window.rolling.Rolling.corr", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.skew.html#pandas.core.window.rolling.Rolling.skew", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.apply.html#pandas.core.window.rolling.Rolling.apply", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.quantile.html#pandas.core.window.rolling.Rolling.quantile", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.rank.html#pandas.core.window.rolling.Rolling.rank", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.sum.html#pandas.core.window.rolling.Rolling.sum", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.median.html#pandas.core.window.rolling.Rolling.median", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.std.html#pandas.core.window.rolling.Rolling.std", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.max.html#pandas.core.window.rolling.Rolling.max", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.cov.html#pandas.core.window.rolling.Rolling.cov", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.kurt.html#pandas.core.window.rolling.Rolling.kurt", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.aggregate.html#pandas.core.window.rolling.Rolling.aggregate", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.sem.html#pandas.core.window.rolling.Rolling.sem"], "function_definitions": [{"function_name": "pandas.core.window.rolling.Rolling.count", "full_function": "Rolling.count(numeric_only=False)", "function_text": "Calculate the rolling count of non NaN observations.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.count.html#pandas.core.window.rolling.Rolling.count"}, {"function_name": "pandas.core.window.rolling.Rolling.mean", "full_function": "Rolling.mean(numeric_only=False, engine=None, engine_kwargs=None)", "function_text": "Calculate the rolling mean.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}, {"param_name": "engine", "param_type": "str, default None", "param_desc": "\n'cython' : Runs the operation through C-extensions from cython.\n'numba' : Runs the operation through JIT compiled code from numba.\nNone : Defaults to 'cython' or globally setting compute.use_numba\n\nNew in version 1.3.0.\n\n\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\nFor 'numba' engine, the engine can accept nopython, nogil\nand parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{'nopython': True, 'nogil': False, 'parallel': False}\n\nNew in version 1.3.0.\n\n\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.mean.html#pandas.core.window.rolling.Rolling.mean"}, {"function_name": "pandas.core.window.rolling.Rolling.var", "full_function": "Rolling.var(ddof=1, numeric_only=False, engine=None, engine_kwargs=None)", "function_text": "Calculate the rolling variance.", "parameter_names_desc": [{"param_name": "ddof", "param_type": "int, default 1", "param_desc": "Delta Degrees of Freedom. The divisor used in calculations\nis N - ddof, where N represents the number of elements.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}, {"param_name": "engine", "param_type": "str, default None", "param_desc": "\n'cython' : Runs the operation through C-extensions from cython.\n'numba' : Runs the operation through JIT compiled code from numba.\nNone : Defaults to 'cython' or globally setting compute.use_numba\n\nNew in version 1.4.0.\n\n\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\nFor 'numba' engine, the engine can accept nopython, nogil\nand parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{'nopython': True, 'nogil': False, 'parallel': False}\n\nNew in version 1.4.0.\n\n\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.var.html#pandas.core.window.rolling.Rolling.var"}, {"function_name": "pandas.core.window.rolling.Rolling.min", "full_function": "Rolling.min(numeric_only=False, engine=None, engine_kwargs=None)", "function_text": "Calculate the rolling minimum.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}, {"param_name": "engine", "param_type": "str, default None", "param_desc": "\n'cython' : Runs the operation through C-extensions from cython.\n'numba' : Runs the operation through JIT compiled code from numba.\nNone : Defaults to 'cython' or globally setting compute.use_numba\n\nNew in version 1.3.0.\n\n\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\nFor 'numba' engine, the engine can accept nopython, nogil\nand parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{'nopython': True, 'nogil': False, 'parallel': False}\n\nNew in version 1.3.0.\n\n\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.min.html#pandas.core.window.rolling.Rolling.min"}, {"function_name": "pandas.core.window.rolling.Rolling.corr", "full_function": "Rolling.corr(other=None, pairwise=None, ddof=1, numeric_only=False)", "function_text": "Calculate the rolling correlation.", "parameter_names_desc": [{"param_name": "other", "param_type": "Series or DataFrame, optional", "param_desc": "If not supplied then will default to self and produce pairwise\noutput.\n"}, {"param_name": "pairwise", "param_type": "bool, default None", "param_desc": "If False then only matching columns between self and other will be\nused and the output will be a DataFrame.\nIf True then all pairwise combinations will be calculated and the\noutput will be a MultiIndexed DataFrame in the case of DataFrame\ninputs. In the case of missing elements, only complete pairwise\nobservations will be used.\n"}, {"param_name": "ddof", "param_type": "int, default 1", "param_desc": "Delta Degrees of Freedom. The divisor used in calculations\nis N - ddof, where N represents the number of elements.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.corr.html#pandas.core.window.rolling.Rolling.corr"}, {"function_name": "pandas.core.window.rolling.Rolling.skew", "full_function": "Rolling.skew(numeric_only=False)", "function_text": "Calculate the rolling unbiased skewness.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.skew.html#pandas.core.window.rolling.Rolling.skew"}, {"function_name": "pandas.core.window.rolling.Rolling.apply", "full_function": "Rolling.apply(func, raw=False, engine=None, engine_kwargs=None, args=None, kwargs=None)", "function_text": "Calculate the rolling custom aggregation function.", "parameter_names_desc": [{"param_name": "func", "param_type": "function", "param_desc": "Must produce a single value from an ndarray input if raw=True\nor a single value from a Series if raw=False. Can also accept a\nNumba JIT function with engine='numba' specified.\n"}, {"param_name": "raw", "param_type": "bool, default False", "param_desc": "\nFalse : passes each row or column as a Series to the\nfunction.\nTrue : the passed function will receive ndarray\nobjects instead.\nIf you are just applying a NumPy reduction function this will\nachieve much better performance.\n\n"}, {"param_name": "engine", "param_type": "str, default None", "param_desc": "\n'cython' : Runs rolling apply through C-extensions from cython.\n'numba' : Runs rolling apply through JIT compiled code from numba.\nOnly available when raw is set to True.\nNone : Defaults to 'cython' or globally setting compute.use_numba\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\nFor 'numba' engine, the engine can accept nopython, nogil\nand parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\napplied to both the func and the apply rolling aggregation.\n\n"}, {"param_name": "args", "param_type": "tuple, default None", "param_desc": "Positional arguments to be passed into func.\n"}, {"param_name": "kwargs", "param_type": "dict, default None", "param_desc": "Keyword arguments to be passed into func.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.apply.html#pandas.core.window.rolling.Rolling.apply"}, {"function_name": "pandas.core.window.rolling.Rolling.quantile", "full_function": "Rolling.quantile(q, interpolation='linear', numeric_only=False)", "function_text": "Calculate the rolling quantile.", "parameter_names_desc": [{"param_name": "quantile", "param_type": "float", "param_desc": "Quantile to compute. 0 <= quantile <= 1.\n\nDeprecated since version 2.1.0: This will be renamed to ‘q’ in a future version.\n\n"}, {"param_name": "interpolation", "param_type": "{‘linear’, ‘lower’, ‘higher’, ‘midpoint’, ‘nearest’}", "param_desc": "This optional parameter specifies the interpolation method to use,\nwhen the desired quantile lies between two data points i and j:\n\n\nlinear: i + (j - i) * fraction, where fraction is the\nfractional part of the index surrounded by i and j.\nlower: i.\nhigher: j.\nnearest: i or j whichever is nearest.\nmidpoint: (i + j) / 2.\n\n\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.quantile.html#pandas.core.window.rolling.Rolling.quantile"}, {"function_name": "pandas.core.window.rolling.Rolling.rank", "full_function": "Rolling.rank(method='average', ascending=True, pct=False, numeric_only=False)", "function_text": "Calculate the rolling rank.", "parameter_names_desc": [{"param_name": "method", "param_type": "{‘average’, ‘min’, ‘max’}, default ‘average’", "param_desc": "How to rank the group of records that have the same value (i.e. ties):\n\naverage: average rank of the group\nmin: lowest rank in the group\nmax: highest rank in the group\n\n"}, {"param_name": "ascending", "param_type": "bool, default True", "param_desc": "Whether or not the elements should be ranked in ascending order.\n"}, {"param_name": "pct", "param_type": "bool, default False", "param_desc": "Whether or not to display the returned rankings in percentile\nform.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.rank.html#pandas.core.window.rolling.Rolling.rank"}, {"function_name": "pandas.core.window.rolling.Rolling.sum", "full_function": "Rolling.sum(numeric_only=False, engine=None, engine_kwargs=None)", "function_text": "Calculate the rolling sum.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}, {"param_name": "engine", "param_type": "str, default None", "param_desc": "\n'cython' : Runs the operation through C-extensions from cython.\n'numba' : Runs the operation through JIT compiled code from numba.\nNone : Defaults to 'cython' or globally setting compute.use_numba\n\nNew in version 1.3.0.\n\n\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\nFor 'numba' engine, the engine can accept nopython, nogil\nand parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{'nopython': True, 'nogil': False, 'parallel': False}\n\nNew in version 1.3.0.\n\n\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.sum.html#pandas.core.window.rolling.Rolling.sum"}, {"function_name": "pandas.core.window.rolling.Rolling.median", "full_function": "Rolling.median(numeric_only=False, engine=None, engine_kwargs=None)", "function_text": "Calculate the rolling median.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}, {"param_name": "engine", "param_type": "str, default None", "param_desc": "\n'cython' : Runs the operation through C-extensions from cython.\n'numba' : Runs the operation through JIT compiled code from numba.\nNone : Defaults to 'cython' or globally setting compute.use_numba\n\nNew in version 1.3.0.\n\n\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\nFor 'numba' engine, the engine can accept nopython, nogil\nand parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{'nopython': True, 'nogil': False, 'parallel': False}\n\nNew in version 1.3.0.\n\n\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.median.html#pandas.core.window.rolling.Rolling.median"}, {"function_name": "pandas.core.window.rolling.Rolling.std", "full_function": "Rolling.std(ddof=1, numeric_only=False, engine=None, engine_kwargs=None)", "function_text": "Calculate the rolling standard deviation.", "parameter_names_desc": [{"param_name": "ddof", "param_type": "int, default 1", "param_desc": "Delta Degrees of Freedom. The divisor used in calculations\nis N - ddof, where N represents the number of elements.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}, {"param_name": "engine", "param_type": "str, default None", "param_desc": "\n'cython' : Runs the operation through C-extensions from cython.\n'numba' : Runs the operation through JIT compiled code from numba.\nNone : Defaults to 'cython' or globally setting compute.use_numba\n\nNew in version 1.4.0.\n\n\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\nFor 'numba' engine, the engine can accept nopython, nogil\nand parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{'nopython': True, 'nogil': False, 'parallel': False}\n\nNew in version 1.4.0.\n\n\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.std.html#pandas.core.window.rolling.Rolling.std"}, {"function_name": "pandas.core.window.rolling.Rolling.max", "full_function": "Rolling.max(numeric_only=False, *args, engine=None, engine_kwargs=None, **kwargs)", "function_text": "Calculate the rolling maximum.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}, {"param_name": "engine", "param_type": "str, default None", "param_desc": "\n'cython' : Runs the operation through C-extensions from cython.\n'numba' : Runs the operation through JIT compiled code from numba.\nNone : Defaults to 'cython' or globally setting compute.use_numba\n\nNew in version 1.3.0.\n\n\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\nFor 'numba' engine, the engine can accept nopython, nogil\nand parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{'nopython': True, 'nogil': False, 'parallel': False}\n\nNew in version 1.3.0.\n\n\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.max.html#pandas.core.window.rolling.Rolling.max"}, {"function_name": "pandas.core.window.rolling.Rolling.cov", "full_function": "Rolling.cov(other=None, pairwise=None, ddof=1, numeric_only=False)", "function_text": "Calculate the rolling sample covariance.", "parameter_names_desc": [{"param_name": "other", "param_type": "Series or DataFrame, optional", "param_desc": "If not supplied then will default to self and produce pairwise\noutput.\n"}, {"param_name": "pairwise", "param_type": "bool, default None", "param_desc": "If False then only matching columns between self and other will be\nused and the output will be a DataFrame.\nIf True then all pairwise combinations will be calculated and the\noutput will be a MultiIndexed DataFrame in the case of DataFrame\ninputs. In the case of missing elements, only complete pairwise\nobservations will be used.\n"}, {"param_name": "ddof", "param_type": "int, default 1", "param_desc": "Delta Degrees of Freedom. The divisor used in calculations\nis N - ddof, where N represents the number of elements.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.cov.html#pandas.core.window.rolling.Rolling.cov"}, {"function_name": "pandas.core.window.rolling.Rolling.kurt", "full_function": "Rolling.kurt(numeric_only=False)", "function_text": "Calculate the rolling Fisher’s definition of kurtosis without bias.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.kurt.html#pandas.core.window.rolling.Rolling.kurt"}, {"function_name": "pandas.core.window.rolling.Rolling.aggregate", "full_function": "Rolling.aggregate(func, *args, **kwargs)", "function_text": "Aggregate using one or more operations over the specified axis.", "parameter_names_desc": [{"param_name": "func", "param_type": "function, str, list or dict", "param_desc": "Function to use for aggregating the data. If a function, must either\nwork when passed a Series/Dataframe or when passed to Series/Dataframe.apply.\nAccepted combinations are:\n\nfunction\nstring function name\nlist of functions and/or function names, e.g. [np.sum, 'mean']\ndict of axis labels -> functions, function names or list of such.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.aggregate.html#pandas.core.window.rolling.Rolling.aggregate"}, {"function_name": "pandas.core.window.rolling.Rolling.sem", "full_function": "Rolling.sem(ddof=1, numeric_only=False)", "function_text": "Calculate the rolling standard error of mean.", "parameter_names_desc": [{"param_name": "ddof", "param_type": "int, default 1", "param_desc": "Delta Degrees of Freedom. The divisor used in calculations\nis N - ddof, where N represents the number of elements.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.sem.html#pandas.core.window.rolling.Rolling.sem"}]}, {"name": "Weighted window functions", "url": "https://pandas.pydata.org/docs/reference/window.html#weighted-window-functions", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Window.mean.html#pandas.core.window.rolling.Window.mean", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Window.var.html#pandas.core.window.rolling.Window.var", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Window.sum.html#pandas.core.window.rolling.Window.sum", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Window.std.html#pandas.core.window.rolling.Window.std"], "function_definitions": [{"function_name": "pandas.core.window.rolling.Window.mean", "full_function": "Window.mean(numeric_only=False, **kwargs)", "function_text": "Calculate the rolling weighted window mean.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Window.mean.html#pandas.core.window.rolling.Window.mean"}, {"function_name": "pandas.core.window.rolling.Window.var", "full_function": "Window.var(ddof=1, numeric_only=False, **kwargs)", "function_text": "Calculate the rolling weighted window variance.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Window.var.html#pandas.core.window.rolling.Window.var"}, {"function_name": "pandas.core.window.rolling.Window.sum", "full_function": "Window.sum(numeric_only=False, **kwargs)", "function_text": "Calculate the rolling weighted window sum.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Window.sum.html#pandas.core.window.rolling.Window.sum"}, {"function_name": "pandas.core.window.rolling.Window.std", "full_function": "Window.std(ddof=1, numeric_only=False, **kwargs)", "function_text": "Calculate the rolling weighted window standard deviation.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Window.std.html#pandas.core.window.rolling.Window.std"}]}, {"name": "Expanding window functions", "url": "https://pandas.pydata.org/docs/reference/window.html#expanding-window-functions", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.count.html#pandas.core.window.expanding.Expanding.count", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.mean.html#pandas.core.window.expanding.Expanding.mean", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.var.html#pandas.core.window.expanding.Expanding.var", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.min.html#pandas.core.window.expanding.Expanding.min", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.corr.html#pandas.core.window.expanding.Expanding.corr", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.skew.html#pandas.core.window.expanding.Expanding.skew", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.apply.html#pandas.core.window.expanding.Expanding.apply", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.quantile.html#pandas.core.window.expanding.Expanding.quantile", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.rank.html#pandas.core.window.expanding.Expanding.rank", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.sum.html#pandas.core.window.expanding.Expanding.sum", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.median.html#pandas.core.window.expanding.Expanding.median", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.std.html#pandas.core.window.expanding.Expanding.std", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.max.html#pandas.core.window.expanding.Expanding.max", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.cov.html#pandas.core.window.expanding.Expanding.cov", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.kurt.html#pandas.core.window.expanding.Expanding.kurt", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.aggregate.html#pandas.core.window.expanding.Expanding.aggregate", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.sem.html#pandas.core.window.expanding.Expanding.sem"], "function_definitions": [{"function_name": "pandas.core.window.expanding.Expanding.count", "full_function": "Expanding.count(numeric_only=False)", "function_text": "Calculate the expanding count of non NaN observations.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.count.html#pandas.core.window.expanding.Expanding.count"}, {"function_name": "pandas.core.window.expanding.Expanding.mean", "full_function": "Expanding.mean(numeric_only=False, engine=None, engine_kwargs=None)", "function_text": "Calculate the expanding mean.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}, {"param_name": "engine", "param_type": "str, default None", "param_desc": "\n'cython' : Runs the operation through C-extensions from cython.\n'numba' : Runs the operation through JIT compiled code from numba.\nNone : Defaults to 'cython' or globally setting compute.use_numba\n\nNew in version 1.3.0.\n\n\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\nFor 'numba' engine, the engine can accept nopython, nogil\nand parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{'nopython': True, 'nogil': False, 'parallel': False}\n\nNew in version 1.3.0.\n\n\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.mean.html#pandas.core.window.expanding.Expanding.mean"}, {"function_name": "pandas.core.window.expanding.Expanding.var", "full_function": "Expanding.var(ddof=1, numeric_only=False, engine=None, engine_kwargs=None)", "function_text": "Calculate the expanding variance.", "parameter_names_desc": [{"param_name": "ddof", "param_type": "int, default 1", "param_desc": "Delta Degrees of Freedom. The divisor used in calculations\nis N - ddof, where N represents the number of elements.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}, {"param_name": "engine", "param_type": "str, default None", "param_desc": "\n'cython' : Runs the operation through C-extensions from cython.\n'numba' : Runs the operation through JIT compiled code from numba.\nNone : Defaults to 'cython' or globally setting compute.use_numba\n\nNew in version 1.4.0.\n\n\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\nFor 'numba' engine, the engine can accept nopython, nogil\nand parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{'nopython': True, 'nogil': False, 'parallel': False}\n\nNew in version 1.4.0.\n\n\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.var.html#pandas.core.window.expanding.Expanding.var"}, {"function_name": "pandas.core.window.expanding.Expanding.min", "full_function": "Expanding.min(numeric_only=False, engine=None, engine_kwargs=None)", "function_text": "Calculate the expanding minimum.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}, {"param_name": "engine", "param_type": "str, default None", "param_desc": "\n'cython' : Runs the operation through C-extensions from cython.\n'numba' : Runs the operation through JIT compiled code from numba.\nNone : Defaults to 'cython' or globally setting compute.use_numba\n\nNew in version 1.3.0.\n\n\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\nFor 'numba' engine, the engine can accept nopython, nogil\nand parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{'nopython': True, 'nogil': False, 'parallel': False}\n\nNew in version 1.3.0.\n\n\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.min.html#pandas.core.window.expanding.Expanding.min"}, {"function_name": "pandas.core.window.expanding.Expanding.corr", "full_function": "Expanding.corr(other=None, pairwise=None, ddof=1, numeric_only=False)", "function_text": "Calculate the expanding correlation.", "parameter_names_desc": [{"param_name": "other", "param_type": "Series or DataFrame, optional", "param_desc": "If not supplied then will default to self and produce pairwise\noutput.\n"}, {"param_name": "pairwise", "param_type": "bool, default None", "param_desc": "If False then only matching columns between self and other will be\nused and the output will be a DataFrame.\nIf True then all pairwise combinations will be calculated and the\noutput will be a MultiIndexed DataFrame in the case of DataFrame\ninputs. In the case of missing elements, only complete pairwise\nobservations will be used.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.corr.html#pandas.core.window.expanding.Expanding.corr"}, {"function_name": "pandas.core.window.expanding.Expanding.skew", "full_function": "Expanding.skew(numeric_only=False)", "function_text": "Calculate the expanding unbiased skewness.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.skew.html#pandas.core.window.expanding.Expanding.skew"}, {"function_name": "pandas.core.window.expanding.Expanding.apply", "full_function": "Expanding.apply(func, raw=False, engine=None, engine_kwargs=None, args=None, kwargs=None)", "function_text": "Calculate the expanding custom aggregation function.", "parameter_names_desc": [{"param_name": "func", "param_type": "function", "param_desc": "Must produce a single value from an ndarray input if raw=True\nor a single value from a Series if raw=False. Can also accept a\nNumba JIT function with engine='numba' specified.\n"}, {"param_name": "raw", "param_type": "bool, default False", "param_desc": "\nFalse : passes each row or column as a Series to the\nfunction.\nTrue : the passed function will receive ndarray\nobjects instead.\nIf you are just applying a NumPy reduction function this will\nachieve much better performance.\n\n"}, {"param_name": "engine", "param_type": "str, default None", "param_desc": "\n'cython' : Runs rolling apply through C-extensions from cython.\n'numba' : Runs rolling apply through JIT compiled code from numba.\nOnly available when raw is set to True.\nNone : Defaults to 'cython' or globally setting compute.use_numba\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\nFor 'numba' engine, the engine can accept nopython, nogil\nand parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\napplied to both the func and the apply rolling aggregation.\n\n"}, {"param_name": "args", "param_type": "tuple, default None", "param_desc": "Positional arguments to be passed into func.\n"}, {"param_name": "kwargs", "param_type": "dict, default None", "param_desc": "Keyword arguments to be passed into func.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.apply.html#pandas.core.window.expanding.Expanding.apply"}, {"function_name": "pandas.core.window.expanding.Expanding.quantile", "full_function": "Expanding.quantile(q, interpolation='linear', numeric_only=False)", "function_text": "Calculate the expanding quantile.", "parameter_names_desc": [{"param_name": "quantile", "param_type": "float", "param_desc": "Quantile to compute. 0 <= quantile <= 1.\n\nDeprecated since version 2.1.0: This will be renamed to ‘q’ in a future version.\n\n"}, {"param_name": "interpolation", "param_type": "{‘linear’, ‘lower’, ‘higher’, ‘midpoint’, ‘nearest’}", "param_desc": "This optional parameter specifies the interpolation method to use,\nwhen the desired quantile lies between two data points i and j:\n\n\nlinear: i + (j - i) * fraction, where fraction is the\nfractional part of the index surrounded by i and j.\nlower: i.\nhigher: j.\nnearest: i or j whichever is nearest.\nmidpoint: (i + j) / 2.\n\n\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.quantile.html#pandas.core.window.expanding.Expanding.quantile"}, {"function_name": "pandas.core.window.expanding.Expanding.rank", "full_function": "Expanding.rank(method='average', ascending=True, pct=False, numeric_only=False)", "function_text": "Calculate the expanding rank.", "parameter_names_desc": [{"param_name": "method", "param_type": "{‘average’, ‘min’, ‘max’}, default ‘average’", "param_desc": "How to rank the group of records that have the same value (i.e. ties):\n\naverage: average rank of the group\nmin: lowest rank in the group\nmax: highest rank in the group\n\n"}, {"param_name": "ascending", "param_type": "bool, default True", "param_desc": "Whether or not the elements should be ranked in ascending order.\n"}, {"param_name": "pct", "param_type": "bool, default False", "param_desc": "Whether or not to display the returned rankings in percentile\nform.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.rank.html#pandas.core.window.expanding.Expanding.rank"}, {"function_name": "pandas.core.window.expanding.Expanding.sum", "full_function": "Expanding.sum(numeric_only=False, engine=None, engine_kwargs=None)", "function_text": "Calculate the expanding sum.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}, {"param_name": "engine", "param_type": "str, default None", "param_desc": "\n'cython' : Runs the operation through C-extensions from cython.\n'numba' : Runs the operation through JIT compiled code from numba.\nNone : Defaults to 'cython' or globally setting compute.use_numba\n\nNew in version 1.3.0.\n\n\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\nFor 'numba' engine, the engine can accept nopython, nogil\nand parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{'nopython': True, 'nogil': False, 'parallel': False}\n\nNew in version 1.3.0.\n\n\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.sum.html#pandas.core.window.expanding.Expanding.sum"}, {"function_name": "pandas.core.window.expanding.Expanding.median", "full_function": "Expanding.median(numeric_only=False, engine=None, engine_kwargs=None)", "function_text": "Calculate the expanding median.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}, {"param_name": "engine", "param_type": "str, default None", "param_desc": "\n'cython' : Runs the operation through C-extensions from cython.\n'numba' : Runs the operation through JIT compiled code from numba.\nNone : Defaults to 'cython' or globally setting compute.use_numba\n\nNew in version 1.3.0.\n\n\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\nFor 'numba' engine, the engine can accept nopython, nogil\nand parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{'nopython': True, 'nogil': False, 'parallel': False}\n\nNew in version 1.3.0.\n\n\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.median.html#pandas.core.window.expanding.Expanding.median"}, {"function_name": "pandas.core.window.expanding.Expanding.std", "full_function": "Expanding.std(ddof=1, numeric_only=False, engine=None, engine_kwargs=None)", "function_text": "Calculate the expanding standard deviation.", "parameter_names_desc": [{"param_name": "ddof", "param_type": "int, default 1", "param_desc": "Delta Degrees of Freedom. The divisor used in calculations\nis N - ddof, where N represents the number of elements.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}, {"param_name": "engine", "param_type": "str, default None", "param_desc": "\n'cython' : Runs the operation through C-extensions from cython.\n'numba' : Runs the operation through JIT compiled code from numba.\nNone : Defaults to 'cython' or globally setting compute.use_numba\n\nNew in version 1.4.0.\n\n\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\nFor 'numba' engine, the engine can accept nopython, nogil\nand parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{'nopython': True, 'nogil': False, 'parallel': False}\n\nNew in version 1.4.0.\n\n\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.std.html#pandas.core.window.expanding.Expanding.std"}, {"function_name": "pandas.core.window.expanding.Expanding.max", "full_function": "Expanding.max(numeric_only=False, engine=None, engine_kwargs=None)", "function_text": "Calculate the expanding maximum.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}, {"param_name": "engine", "param_type": "str, default None", "param_desc": "\n'cython' : Runs the operation through C-extensions from cython.\n'numba' : Runs the operation through JIT compiled code from numba.\nNone : Defaults to 'cython' or globally setting compute.use_numba\n\nNew in version 1.3.0.\n\n\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\nFor 'numba' engine, the engine can accept nopython, nogil\nand parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{'nopython': True, 'nogil': False, 'parallel': False}\n\nNew in version 1.3.0.\n\n\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.max.html#pandas.core.window.expanding.Expanding.max"}, {"function_name": "pandas.core.window.expanding.Expanding.cov", "full_function": "Expanding.cov(other=None, pairwise=None, ddof=1, numeric_only=False)", "function_text": "Calculate the expanding sample covariance.", "parameter_names_desc": [{"param_name": "other", "param_type": "Series or DataFrame, optional", "param_desc": "If not supplied then will default to self and produce pairwise\noutput.\n"}, {"param_name": "pairwise", "param_type": "bool, default None", "param_desc": "If False then only matching columns between self and other will be\nused and the output will be a DataFrame.\nIf True then all pairwise combinations will be calculated and the\noutput will be a MultiIndexed DataFrame in the case of DataFrame\ninputs. In the case of missing elements, only complete pairwise\nobservations will be used.\n"}, {"param_name": "ddof", "param_type": "int, default 1", "param_desc": "Delta Degrees of Freedom. The divisor used in calculations\nis N - ddof, where N represents the number of elements.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.cov.html#pandas.core.window.expanding.Expanding.cov"}, {"function_name": "pandas.core.window.expanding.Expanding.kurt", "full_function": "Expanding.kurt(numeric_only=False)", "function_text": "Calculate the expanding Fisher’s definition of kurtosis without bias.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.kurt.html#pandas.core.window.expanding.Expanding.kurt"}, {"function_name": "pandas.core.window.expanding.Expanding.aggregate", "full_function": "Expanding.aggregate(func, *args, **kwargs)", "function_text": "Aggregate using one or more operations over the specified axis.", "parameter_names_desc": [{"param_name": "func", "param_type": "function, str, list or dict", "param_desc": "Function to use for aggregating the data. If a function, must either\nwork when passed a Series/Dataframe or when passed to Series/Dataframe.apply.\nAccepted combinations are:\n\nfunction\nstring function name\nlist of functions and/or function names, e.g. [np.sum, 'mean']\ndict of axis labels -> functions, function names or list of such.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.aggregate.html#pandas.core.window.expanding.Expanding.aggregate"}, {"function_name": "pandas.core.window.expanding.Expanding.sem", "full_function": "Expanding.sem(ddof=1, numeric_only=False)", "function_text": "Calculate the expanding standard error of mean.", "parameter_names_desc": [{"param_name": "ddof", "param_type": "int, default 1", "param_desc": "Delta Degrees of Freedom. The divisor used in calculations\nis N - ddof, where N represents the number of elements.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.expanding.Expanding.sem.html#pandas.core.window.expanding.Expanding.sem"}]}, {"name": "Exponentially-weighted window functions", "url": "https://pandas.pydata.org/docs/reference/window.html#exponentially-weighted-window-functions", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.core.window.ewm.ExponentialMovingWindow.mean.html#pandas.core.window.ewm.ExponentialMovingWindow.mean", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.ewm.ExponentialMovingWindow.std.html#pandas.core.window.ewm.ExponentialMovingWindow.std", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.ewm.ExponentialMovingWindow.corr.html#pandas.core.window.ewm.ExponentialMovingWindow.corr", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.ewm.ExponentialMovingWindow.sum.html#pandas.core.window.ewm.ExponentialMovingWindow.sum", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.ewm.ExponentialMovingWindow.var.html#pandas.core.window.ewm.ExponentialMovingWindow.var", "https://pandas.pydata.org/docs/reference/api/pandas.core.window.ewm.ExponentialMovingWindow.cov.html#pandas.core.window.ewm.ExponentialMovingWindow.cov"], "function_definitions": [{"function_name": "pandas.core.window.ewm.ExponentialMovingWindow.mean", "full_function": "ExponentialMovingWindow.mean(numeric_only=False, engine=None, engine_kwargs=None)", "function_text": "Calculate the ewm (exponential weighted moment) mean.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}, {"param_name": "engine", "param_type": "str, default None", "param_desc": "\n'cython' : Runs the operation through C-extensions from cython.\n'numba' : Runs the operation through JIT compiled code from numba.\nNone : Defaults to 'cython' or globally setting compute.use_numba\n\nNew in version 1.3.0.\n\n\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\nFor 'numba' engine, the engine can accept nopython, nogil\nand parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{'nopython': True, 'nogil': False, 'parallel': False}\n\nNew in version 1.3.0.\n\n\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.ewm.ExponentialMovingWindow.mean.html#pandas.core.window.ewm.ExponentialMovingWindow.mean"}, {"function_name": "pandas.core.window.ewm.ExponentialMovingWindow.std", "full_function": "ExponentialMovingWindow.std(bias=False, numeric_only=False)", "function_text": "Calculate the ewm (exponential weighted moment) standard deviation.", "parameter_names_desc": [{"param_name": "bias", "param_type": "bool, default False", "param_desc": "Use a standard estimation bias correction.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.ewm.ExponentialMovingWindow.std.html#pandas.core.window.ewm.ExponentialMovingWindow.std"}, {"function_name": "pandas.core.window.ewm.ExponentialMovingWindow.corr", "full_function": "ExponentialMovingWindow.corr(other=None, pairwise=None, numeric_only=False)", "function_text": "Calculate the ewm (exponential weighted moment) sample correlation.", "parameter_names_desc": [{"param_name": "other", "param_type": "Series or DataFrame, optional", "param_desc": "If not supplied then will default to self and produce pairwise\noutput.\n"}, {"param_name": "pairwise", "param_type": "bool, default None", "param_desc": "If False then only matching columns between self and other will be\nused and the output will be a DataFrame.\nIf True then all pairwise combinations will be calculated and the\noutput will be a MultiIndex DataFrame in the case of DataFrame\ninputs. In the case of missing elements, only complete pairwise\nobservations will be used.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.ewm.ExponentialMovingWindow.corr.html#pandas.core.window.ewm.ExponentialMovingWindow.corr"}, {"function_name": "pandas.core.window.ewm.ExponentialMovingWindow.sum", "full_function": "ExponentialMovingWindow.sum(numeric_only=False, engine=None, engine_kwargs=None)", "function_text": "Calculate the ewm (exponential weighted moment) sum.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}, {"param_name": "engine", "param_type": "str, default None", "param_desc": "\n'cython' : Runs the operation through C-extensions from cython.\n'numba' : Runs the operation through JIT compiled code from numba.\nNone : Defaults to 'cython' or globally setting compute.use_numba\n\nNew in version 1.3.0.\n\n\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\nFor 'numba' engine, the engine can accept nopython, nogil\nand parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{'nopython': True, 'nogil': False, 'parallel': False}\n\nNew in version 1.3.0.\n\n\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.ewm.ExponentialMovingWindow.sum.html#pandas.core.window.ewm.ExponentialMovingWindow.sum"}, {"function_name": "pandas.core.window.ewm.ExponentialMovingWindow.var", "full_function": "ExponentialMovingWindow.var(bias=False, numeric_only=False)", "function_text": "Calculate the ewm (exponential weighted moment) variance.", "parameter_names_desc": [{"param_name": "bias", "param_type": "bool, default False", "param_desc": "Use a standard estimation bias correction.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.ewm.ExponentialMovingWindow.var.html#pandas.core.window.ewm.ExponentialMovingWindow.var"}, {"function_name": "pandas.core.window.ewm.ExponentialMovingWindow.cov", "full_function": "ExponentialMovingWindow.cov(other=None, pairwise=None, bias=False, numeric_only=False)", "function_text": "Calculate the ewm (exponential weighted moment) sample covariance.", "parameter_names_desc": [{"param_name": "other", "param_type": "Series or DataFrame , optional", "param_desc": "If not supplied then will default to self and produce pairwise\noutput.\n"}, {"param_name": "pairwise", "param_type": "bool, default None", "param_desc": "If False then only matching columns between self and other will be\nused and the output will be a DataFrame.\nIf True then all pairwise combinations will be calculated and the\noutput will be a MultiIndex DataFrame in the case of DataFrame\ninputs. In the case of missing elements, only complete pairwise\nobservations will be used.\n"}, {"param_name": "bias", "param_type": "bool, default False", "param_desc": "Use a standard estimation bias correction.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nNew in version 1.5.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.window.ewm.ExponentialMovingWindow.cov.html#pandas.core.window.ewm.ExponentialMovingWindow.cov"}]}, {"name": "Window indexer", "url": "https://pandas.pydata.org/docs/reference/window.html#window-indexer", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.api.indexers.BaseIndexer.html#pandas.api.indexers.BaseIndexer", "https://pandas.pydata.org/docs/reference/api/pandas.api.indexers.VariableOffsetWindowIndexer.html#pandas.api.indexers.VariableOffsetWindowIndexer", "https://pandas.pydata.org/docs/reference/api/pandas.api.indexers.FixedForwardWindowIndexer.html#pandas.api.indexers.FixedForwardWindowIndexer"], "function_definitions": [{"function_name": "pandas.api.indexers.BaseIndexer", "full_function": "class pandas.api.indexers.BaseIndexer(index_array=None, window_size=0, **kwargs)", "function_text": "Base class for window bounds calculations.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.indexers.BaseIndexer.html#pandas.api.indexers.BaseIndexer"}, {"function_name": "pandas.api.indexers.VariableOffsetWindowIndexer", "full_function": "class pandas.api.indexers.VariableOffsetWindowIndexer(index_array=None, window_size=0, index=None, offset=None, **kwargs)", "function_text": "Calculate window boundaries based on a non-fixed offset such as a BusinessDay.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.indexers.VariableOffsetWindowIndexer.html#pandas.api.indexers.VariableOffsetWindowIndexer"}, {"function_name": "pandas.api.indexers.FixedForwardWindowIndexer", "full_function": "class pandas.api.indexers.FixedForwardWindowIndexer(index_array=None, window_size=0, **kwargs)", "function_text": "Creates window boundaries for fixed-length windows that include the current row.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.api.indexers.FixedForwardWindowIndexer.html#pandas.api.indexers.FixedForwardWindowIndexer"}]}], "name": "Window", "url": "https://pandas.pydata.org/docs/reference/window.html"}, "groupby.html": {"functions": [{"name": "Indexing, iteration", "url": "https://pandas.pydata.org/docs/reference/groupby.html#indexing-iteration", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.__iter__.html#pandas.core.groupby.DataFrameGroupBy.__iter__", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.groups.html#pandas.core.groupby.DataFrameGroupBy.groups", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.indices.html#pandas.core.groupby.DataFrameGroupBy.indices", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.get_group.html#pandas.core.groupby.DataFrameGroupBy.get_group", "https://pandas.pydata.org/docs/reference/api/pandas.Grouper.html#pandas.Grouper", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.__iter__.html#pandas.core.groupby.SeriesGroupBy.__iter__", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.groups.html#pandas.core.groupby.SeriesGroupBy.groups", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.indices.html#pandas.core.groupby.SeriesGroupBy.indices", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.get_group.html#pandas.core.groupby.SeriesGroupBy.get_group"], "function_definitions": [{"function_name": "pandas.core.groupby.DataFrameGroupBy.__iter__", "full_function": "DataFrameGroupBy.__iter__()", "function_text": "Groupby iterator.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.__iter__.html#pandas.core.groupby.DataFrameGroupBy.__iter__"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.groups", "full_function": "property DataFrameGroupBy.groups", "function_text": "Dict {group name -> group labels}.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.groups.html#pandas.core.groupby.DataFrameGroupBy.groups"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.indices", "full_function": "property DataFrameGroupBy.indices", "function_text": "Dict {group name -> group indices}.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.indices.html#pandas.core.groupby.DataFrameGroupBy.indices"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.get_group", "full_function": "DataFrameGroupBy.get_group(name, obj=None)", "function_text": "Construct DataFrame from group with provided name.", "parameter_names_desc": [{"param_name": "name", "param_type": "object", "param_desc": "The name of the group to get as a DataFrame.\n"}, {"param_name": "obj", "param_type": "DataFrame, default None", "param_desc": "The DataFrame to take the DataFrame out of. If\nit is None, the object groupby was called on will\nbe used.\n\nDeprecated since version 2.1.0: The obj is deprecated and will be removed in a future version.\nDo df.iloc[gb.indices.get(name)]\ninstead of gb.get_group(name, obj=df).\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.get_group.html#pandas.core.groupby.DataFrameGroupBy.get_group"}, {"function_name": "pandas.Grouper", "full_function": "class pandas.Grouper(*args, **kwargs)", "function_text": "A Grouper allows the user to specify a groupby instruction for an object.", "parameter_names_desc": [{"param_name": "key", "param_type": "str, defaults to None", "param_desc": "Groupby key, which selects the grouping column of the target.\n"}, {"param_name": "level", "param_type": "name/number, defaults to None", "param_desc": "The level for the target index.\n"}, {"param_name": "freq", "param_type": "str / frequency object, defaults to None", "param_desc": "This will groupby the specified frequency if the target selection\n(via key or level) is a datetime-like object. For full specification\nof available frequencies, please see here.\n"}, {"param_name": "axis", "param_type": "str, int, defaults to 0", "param_desc": "Number/name of the axis.\n"}, {"param_name": "sort", "param_type": "bool, default to False", "param_desc": "Whether to sort the resulting labels.\n"}, {"param_name": "closed", "param_type": "{‘left’ or ‘right’}", "param_desc": "Closed end of interval. Only when freq parameter is passed.\n"}, {"param_name": "label", "param_type": "{‘left’ or ‘right’}", "param_desc": "Interval boundary to use for labeling.\nOnly when freq parameter is passed.\n"}, {"param_name": "convention", "param_type": "{‘start’, ‘end’, ‘e’, ‘s’}", "param_desc": "If grouper is PeriodIndex and freq parameter is passed.\n"}, {"param_name": "origin", "param_type": "Timestamp or str, default ‘start_day’", "param_desc": "The timestamp on which to adjust the grouping. The timezone of origin must\nmatch the timezone of the index.\nIf string, must be one of the following:\n\n‘epoch’: origin is 1970-01-01\n‘start’: origin is the first value of the timeseries\n‘start_day’: origin is the first day at midnight of the timeseries\n‘end’: origin is the last value of the timeseries\n‘end_day’: origin is the ceiling midnight of the last day\n\n\nNew in version 1.3.0.\n\n"}, {"param_name": "offset", "param_type": "Timedelta or str, default is None", "param_desc": "An offset timedelta added to the origin.\n"}, {"param_name": "dropna", "param_type": "bool, default True", "param_desc": "If True, and if group keys contain NA values, NA values together with\nrow/column will be dropped. If False, NA values will also be treated as\nthe key in groups.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.Grouper.html#pandas.Grouper"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.__iter__", "full_function": "SeriesGroupBy.__iter__()", "function_text": "Groupby iterator.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.__iter__.html#pandas.core.groupby.SeriesGroupBy.__iter__"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.groups", "full_function": "property SeriesGroupBy.groups", "function_text": "Dict {group name -> group labels}.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.groups.html#pandas.core.groupby.SeriesGroupBy.groups"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.indices", "full_function": "property SeriesGroupBy.indices", "function_text": "Dict {group name -> group indices}.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.indices.html#pandas.core.groupby.SeriesGroupBy.indices"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.get_group", "full_function": "SeriesGroupBy.get_group(name, obj=None)", "function_text": "Construct DataFrame from group with provided name.", "parameter_names_desc": [{"param_name": "name", "param_type": "object", "param_desc": "The name of the group to get as a DataFrame.\n"}, {"param_name": "obj", "param_type": "DataFrame, default None", "param_desc": "The DataFrame to take the DataFrame out of. If\nit is None, the object groupby was called on will\nbe used.\n\nDeprecated since version 2.1.0: The obj is deprecated and will be removed in a future version.\nDo df.iloc[gb.indices.get(name)]\ninstead of gb.get_group(name, obj=df).\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.get_group.html#pandas.core.groupby.SeriesGroupBy.get_group"}]}, {"name": "Function application helper", "url": "https://pandas.pydata.org/docs/reference/groupby.html#function-application-helper", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.NamedAgg.html#pandas.NamedAgg"], "function_definitions": [{"function_name": "pandas.NamedAgg", "full_function": "class pandas.NamedAgg(column, aggfunc)", "function_text": "Helper for column specific aggregation with control over output column names.", "parameter_names_desc": [{"param_name": "column", "param_type": "Hashable", "param_desc": "Column label in the DataFrame to apply aggfunc.\n"}, {"param_name": "aggfunc", "param_type": "function or str", "param_desc": "Function to apply to the provided column. If string, the name of a built-in\npandas function.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.NamedAgg.html#pandas.NamedAgg"}]}, {"name": "Function application", "url": "https://pandas.pydata.org/docs/reference/groupby.html#function-application", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.apply.html#pandas.core.groupby.SeriesGroupBy.apply", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.agg.html#pandas.core.groupby.SeriesGroupBy.agg", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.aggregate.html#pandas.core.groupby.SeriesGroupBy.aggregate", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.transform.html#pandas.core.groupby.SeriesGroupBy.transform", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.pipe.html#pandas.core.groupby.SeriesGroupBy.pipe", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.filter.html#pandas.core.groupby.DataFrameGroupBy.filter", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.apply.html#pandas.core.groupby.DataFrameGroupBy.apply", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.agg.html#pandas.core.groupby.DataFrameGroupBy.agg", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.aggregate.html#pandas.core.groupby.DataFrameGroupBy.aggregate", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.transform.html#pandas.core.groupby.DataFrameGroupBy.transform", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.pipe.html#pandas.core.groupby.DataFrameGroupBy.pipe", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.filter.html#pandas.core.groupby.SeriesGroupBy.filter"], "function_definitions": [{"function_name": "pandas.core.groupby.SeriesGroupBy.apply", "full_function": "SeriesGroupBy.apply(func, *args, **kwargs)", "function_text": "Apply function func group-wise and combine the results together.", "parameter_names_desc": [{"param_name": "func", "param_type": "callable", "param_desc": "A callable that takes a series as its first argument, and\nreturns a dataframe, a series or a scalar. In addition the\ncallable may take positional and keyword arguments.\n"}, {"param_name": "include_groups", "param_type": "bool, default True", "param_desc": "When True, will attempt to apply func to the groupings in\nthe case that they are columns of the DataFrame. If this raises a\nTypeError, the result will be computed with the groupings excluded.\nWhen False, the groupings will be excluded when applying func.\n\nNew in version 2.2.0.\n\n\nDeprecated since version 2.2.0: Setting include_groups to True is deprecated. Only the value\nFalse will be allowed in a future version of pandas.\n\n"}, {"param_name": "args, kwargs", "param_type": "tuple and dict", "param_desc": "Optional positional and keyword arguments to pass to func.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.apply.html#pandas.core.groupby.SeriesGroupBy.apply"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.agg", "full_function": "SeriesGroupBy.agg(func=None, *args, engine=None, engine_kwargs=None, **kwargs)", "function_text": "Aggregate using one or more operations over the specified axis.", "parameter_names_desc": [{"param_name": "func", "param_type": "function, str, list, dict or None", "param_desc": "Function to use for aggregating the data. If a function, must either\nwork when passed a Series or when passed to Series.apply.\nAccepted combinations are:\n\nfunction\nstring function name\nlist of functions and/or function names, e.g. [np.sum, 'mean']\nNone, in which case **kwargs are used with Named Aggregation. Here the\noutput has one column for each element in **kwargs. The name of the\ncolumn is keyword, whereas the value determines the aggregation used to compute\nthe values in the column.\nCan also accept a Numba JIT function with\nengine='numba' specified. Only passing a single function is supported\nwith this engine.\nIf the 'numba' engine is chosen, the function must be\na user defined function with values and index as the\nfirst and second arguments respectively in the function signature.\nEach group’s index will be passed to the user defined function\nand optionally available for use.\n\n\n\nDeprecated since version 2.1.0: Passing a dictionary is deprecated and will raise in a future version\nof pandas. Pass a list of aggregations instead.\n\n"}, {"param_name": "engine", "param_type": "str, default None", "param_desc": "\n'cython' : Runs the function through C-extensions from cython.\n'numba' : Runs the function through JIT compiled code from numba.\nNone : Defaults to 'cython' or globally setting compute.use_numba\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\nFor 'numba' engine, the engine can accept nopython, nogil\nand parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\napplied to the function\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.agg.html#pandas.core.groupby.SeriesGroupBy.agg"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.aggregate", "full_function": "SeriesGroupBy.aggregate(func=None, *args, engine=None, engine_kwargs=None, **kwargs)", "function_text": "Aggregate using one or more operations over the specified axis.", "parameter_names_desc": [{"param_name": "func", "param_type": "function, str, list, dict or None", "param_desc": "Function to use for aggregating the data. If a function, must either\nwork when passed a Series or when passed to Series.apply.\nAccepted combinations are:\n\nfunction\nstring function name\nlist of functions and/or function names, e.g. [np.sum, 'mean']\nNone, in which case **kwargs are used with Named Aggregation. Here the\noutput has one column for each element in **kwargs. The name of the\ncolumn is keyword, whereas the value determines the aggregation used to compute\nthe values in the column.\nCan also accept a Numba JIT function with\nengine='numba' specified. Only passing a single function is supported\nwith this engine.\nIf the 'numba' engine is chosen, the function must be\na user defined function with values and index as the\nfirst and second arguments respectively in the function signature.\nEach group’s index will be passed to the user defined function\nand optionally available for use.\n\n\n\nDeprecated since version 2.1.0: Passing a dictionary is deprecated and will raise in a future version\nof pandas. Pass a list of aggregations instead.\n\n"}, {"param_name": "engine", "param_type": "str, default None", "param_desc": "\n'cython' : Runs the function through C-extensions from cython.\n'numba' : Runs the function through JIT compiled code from numba.\nNone : Defaults to 'cython' or globally setting compute.use_numba\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\nFor 'numba' engine, the engine can accept nopython, nogil\nand parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\napplied to the function\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.aggregate.html#pandas.core.groupby.SeriesGroupBy.aggregate"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.transform", "full_function": "SeriesGroupBy.transform(func, *args, engine=None, engine_kwargs=None, **kwargs)", "function_text": "Call function producing a same-indexed Series on each group.", "parameter_names_desc": [{"param_name": "f", "param_type": "function, str", "param_desc": "Function to apply to each group. See the Notes section below for requirements.\nAccepted inputs are:\n\nString\nPython function\nNumba JIT function with engine='numba' specified.\n\nOnly passing a single function is supported with this engine.\nIf the 'numba' engine is chosen, the function must be\na user defined function with values and index as the\nfirst and second arguments respectively in the function signature.\nEach group’s index will be passed to the user defined function\nand optionally available for use.\nIf a string is chosen, then it needs to be the name\nof the groupby method you want to use.\n"}, {"param_name": "engine", "param_type": "str, default None", "param_desc": "\n'cython' : Runs the function through C-extensions from cython.\n'numba' : Runs the function through JIT compiled code from numba.\nNone : Defaults to 'cython' or the global setting compute.use_numba\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\nFor 'numba' engine, the engine can accept nopython, nogil\nand parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\napplied to the function\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.transform.html#pandas.core.groupby.SeriesGroupBy.transform"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.pipe", "full_function": "SeriesGroupBy.pipe(func, *args, **kwargs)", "function_text": "Apply a func with arguments to this GroupBy object and return its result.", "parameter_names_desc": [{"param_name": "func", "param_type": "callable or tuple of (callable, str)", "param_desc": "Function to apply to this GroupBy object or, alternatively,\na (callable, data_keyword) tuple where data_keyword is a\nstring indicating the keyword of callable that expects the\nGroupBy object.\n"}, {"param_name": "args", "param_type": "iterable, optional", "param_desc": "Positional arguments passed into func.\n"}, {"param_name": "kwargs", "param_type": "dict, optional", "param_desc": "A dictionary of keyword arguments passed into func.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.pipe.html#pandas.core.groupby.SeriesGroupBy.pipe"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.filter", "full_function": "DataFrameGroupBy.filter(func, dropna=True, *args, **kwargs)", "function_text": "Filter elements from groups that don’t satisfy a criterion.", "parameter_names_desc": [{"param_name": "func", "param_type": "function", "param_desc": "Criterion to apply to each group. Should return True or False.\n"}, {"param_name": "dropna", "param_type": "bool", "param_desc": "Drop groups that do not pass the filter. True by default; if False,\ngroups that evaluate False are filled with NaNs.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.filter.html#pandas.core.groupby.DataFrameGroupBy.filter"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.apply", "full_function": "DataFrameGroupBy.apply(func, *args, include_groups=True, **kwargs)", "function_text": "Apply function func group-wise and combine the results together.", "parameter_names_desc": [{"param_name": "func", "param_type": "callable", "param_desc": "A callable that takes a dataframe as its first argument, and\nreturns a dataframe, a series or a scalar. In addition the\ncallable may take positional and keyword arguments.\n"}, {"param_name": "include_groups", "param_type": "bool, default True", "param_desc": "When True, will attempt to apply func to the groupings in\nthe case that they are columns of the DataFrame. If this raises a\nTypeError, the result will be computed with the groupings excluded.\nWhen False, the groupings will be excluded when applying func.\n\nNew in version 2.2.0.\n\n\nDeprecated since version 2.2.0: Setting include_groups to True is deprecated. Only the value\nFalse will be allowed in a future version of pandas.\n\n"}, {"param_name": "args, kwargs", "param_type": "tuple and dict", "param_desc": "Optional positional and keyword arguments to pass to func.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.apply.html#pandas.core.groupby.DataFrameGroupBy.apply"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.agg", "full_function": "DataFrameGroupBy.agg(func=None, *args, engine=None, engine_kwargs=None, **kwargs)", "function_text": "Aggregate using one or more operations over the specified axis.", "parameter_names_desc": [{"param_name": "func", "param_type": "function, str, list, dict or None", "param_desc": "Function to use for aggregating the data. If a function, must either\nwork when passed a DataFrame or when passed to DataFrame.apply.\nAccepted combinations are:\n\nfunction\nstring function name\nlist of functions and/or function names, e.g. [np.sum, 'mean']\ndict of axis labels -> functions, function names or list of such.\nNone, in which case **kwargs are used with Named Aggregation. Here the\noutput has one column for each element in **kwargs. The name of the\ncolumn is keyword, whereas the value determines the aggregation used to compute\nthe values in the column.\nCan also accept a Numba JIT function with\nengine='numba' specified. Only passing a single function is supported\nwith this engine.\nIf the 'numba' engine is chosen, the function must be\na user defined function with values and index as the\nfirst and second arguments respectively in the function signature.\nEach group’s index will be passed to the user defined function\nand optionally available for use.\n\n\n"}, {"param_name": "engine", "param_type": "str, default None", "param_desc": "\n'cython' : Runs the function through C-extensions from cython.\n'numba' : Runs the function through JIT compiled code from numba.\nNone : Defaults to 'cython' or globally setting compute.use_numba\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\nFor 'numba' engine, the engine can accept nopython, nogil\nand parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\napplied to the function\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.agg.html#pandas.core.groupby.DataFrameGroupBy.agg"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.aggregate", "full_function": "DataFrameGroupBy.aggregate(func=None, *args, engine=None, engine_kwargs=None, **kwargs)", "function_text": "Aggregate using one or more operations over the specified axis.", "parameter_names_desc": [{"param_name": "func", "param_type": "function, str, list, dict or None", "param_desc": "Function to use for aggregating the data. If a function, must either\nwork when passed a DataFrame or when passed to DataFrame.apply.\nAccepted combinations are:\n\nfunction\nstring function name\nlist of functions and/or function names, e.g. [np.sum, 'mean']\ndict of axis labels -> functions, function names or list of such.\nNone, in which case **kwargs are used with Named Aggregation. Here the\noutput has one column for each element in **kwargs. The name of the\ncolumn is keyword, whereas the value determines the aggregation used to compute\nthe values in the column.\nCan also accept a Numba JIT function with\nengine='numba' specified. Only passing a single function is supported\nwith this engine.\nIf the 'numba' engine is chosen, the function must be\na user defined function with values and index as the\nfirst and second arguments respectively in the function signature.\nEach group’s index will be passed to the user defined function\nand optionally available for use.\n\n\n"}, {"param_name": "engine", "param_type": "str, default None", "param_desc": "\n'cython' : Runs the function through C-extensions from cython.\n'numba' : Runs the function through JIT compiled code from numba.\nNone : Defaults to 'cython' or globally setting compute.use_numba\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\nFor 'numba' engine, the engine can accept nopython, nogil\nand parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\napplied to the function\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.aggregate.html#pandas.core.groupby.DataFrameGroupBy.aggregate"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.transform", "full_function": "DataFrameGroupBy.transform(func, *args, engine=None, engine_kwargs=None, **kwargs)", "function_text": "Call function producing a same-indexed DataFrame on each group.", "parameter_names_desc": [{"param_name": "f", "param_type": "function, str", "param_desc": "Function to apply to each group. See the Notes section below for requirements.\nAccepted inputs are:\n\nString\nPython function\nNumba JIT function with engine='numba' specified.\n\nOnly passing a single function is supported with this engine.\nIf the 'numba' engine is chosen, the function must be\na user defined function with values and index as the\nfirst and second arguments respectively in the function signature.\nEach group’s index will be passed to the user defined function\nand optionally available for use.\nIf a string is chosen, then it needs to be the name\nof the groupby method you want to use.\n"}, {"param_name": "engine", "param_type": "str, default None", "param_desc": "\n'cython' : Runs the function through C-extensions from cython.\n'numba' : Runs the function through JIT compiled code from numba.\nNone : Defaults to 'cython' or the global setting compute.use_numba\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\nFor 'numba' engine, the engine can accept nopython, nogil\nand parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\napplied to the function\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.transform.html#pandas.core.groupby.DataFrameGroupBy.transform"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.pipe", "full_function": "DataFrameGroupBy.pipe(func, *args, **kwargs)", "function_text": "Apply a func with arguments to this GroupBy object and return its result.", "parameter_names_desc": [{"param_name": "func", "param_type": "callable or tuple of (callable, str)", "param_desc": "Function to apply to this GroupBy object or, alternatively,\na (callable, data_keyword) tuple where data_keyword is a\nstring indicating the keyword of callable that expects the\nGroupBy object.\n"}, {"param_name": "args", "param_type": "iterable, optional", "param_desc": "Positional arguments passed into func.\n"}, {"param_name": "kwargs", "param_type": "dict, optional", "param_desc": "A dictionary of keyword arguments passed into func.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.pipe.html#pandas.core.groupby.DataFrameGroupBy.pipe"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.filter", "full_function": "SeriesGroupBy.filter(func, dropna=True, *args, **kwargs)", "function_text": "Filter elements from groups that don’t satisfy a criterion.", "parameter_names_desc": [{"param_name": "func", "param_type": "function", "param_desc": "Criterion to apply to each group. Should return True or False.\n"}, {"param_name": "dropna", "param_type": "bool", "param_desc": "Drop groups that do not pass the filter. True by default; if False,\ngroups that evaluate False are filled with NaNs.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.filter.html#pandas.core.groupby.SeriesGroupBy.filter"}]}, {"name": "DataFrameGroupBy computations / descriptive stats", "url": "https://pandas.pydata.org/docs/reference/groupby.html#dataframegroupby-computations-descriptive-stats", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.all.html#pandas.core.groupby.DataFrameGroupBy.all", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.bfill.html#pandas.core.groupby.DataFrameGroupBy.bfill", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.corrwith.html#pandas.core.groupby.DataFrameGroupBy.corrwith", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cov.html#pandas.core.groupby.DataFrameGroupBy.cov", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cummax.html#pandas.core.groupby.DataFrameGroupBy.cummax", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cumprod.html#pandas.core.groupby.DataFrameGroupBy.cumprod", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.describe.html#pandas.core.groupby.DataFrameGroupBy.describe", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.ffill.html#pandas.core.groupby.DataFrameGroupBy.ffill", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.first.html#pandas.core.groupby.DataFrameGroupBy.first", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.idxmax.html#pandas.core.groupby.DataFrameGroupBy.idxmax", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.last.html#pandas.core.groupby.DataFrameGroupBy.last", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.mean.html#pandas.core.groupby.DataFrameGroupBy.mean", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.min.html#pandas.core.groupby.DataFrameGroupBy.min", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.nth.html#pandas.core.groupby.DataFrameGroupBy.nth", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.ohlc.html#pandas.core.groupby.DataFrameGroupBy.ohlc", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.prod.html#pandas.core.groupby.DataFrameGroupBy.prod", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.rank.html#pandas.core.groupby.DataFrameGroupBy.rank", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.rolling.html#pandas.core.groupby.DataFrameGroupBy.rolling", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.sem.html#pandas.core.groupby.DataFrameGroupBy.sem", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.size.html#pandas.core.groupby.DataFrameGroupBy.size", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.std.html#pandas.core.groupby.DataFrameGroupBy.std", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.var.html#pandas.core.groupby.DataFrameGroupBy.var", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.take.html#pandas.core.groupby.DataFrameGroupBy.take", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.any.html#pandas.core.groupby.DataFrameGroupBy.any", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.corr.html#pandas.core.groupby.DataFrameGroupBy.corr", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.count.html#pandas.core.groupby.DataFrameGroupBy.count", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cumcount.html#pandas.core.groupby.DataFrameGroupBy.cumcount", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cummin.html#pandas.core.groupby.DataFrameGroupBy.cummin", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cumsum.html#pandas.core.groupby.DataFrameGroupBy.cumsum", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.diff.html#pandas.core.groupby.DataFrameGroupBy.diff", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.fillna.html#pandas.core.groupby.DataFrameGroupBy.fillna", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.head.html#pandas.core.groupby.DataFrameGroupBy.head", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.idxmin.html#pandas.core.groupby.DataFrameGroupBy.idxmin", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.max.html#pandas.core.groupby.DataFrameGroupBy.max", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.median.html#pandas.core.groupby.DataFrameGroupBy.median", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.ngroup.html#pandas.core.groupby.DataFrameGroupBy.ngroup", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.nunique.html#pandas.core.groupby.DataFrameGroupBy.nunique", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.pct_change.html#pandas.core.groupby.DataFrameGroupBy.pct_change", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.quantile.html#pandas.core.groupby.DataFrameGroupBy.quantile", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.resample.html#pandas.core.groupby.DataFrameGroupBy.resample", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.sample.html#pandas.core.groupby.DataFrameGroupBy.sample", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.shift.html#pandas.core.groupby.DataFrameGroupBy.shift", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.skew.html#pandas.core.groupby.DataFrameGroupBy.skew", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.sum.html#pandas.core.groupby.DataFrameGroupBy.sum", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.tail.html#pandas.core.groupby.DataFrameGroupBy.tail", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.value_counts.html#pandas.core.groupby.DataFrameGroupBy.value_counts"], "function_definitions": [{"function_name": "pandas.core.groupby.DataFrameGroupBy.all", "full_function": "DataFrameGroupBy.all(skipna=True)", "function_text": "Return True if all values in the group are truthful, else False.", "parameter_names_desc": [{"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Flag to ignore nan values during truth testing.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.all.html#pandas.core.groupby.DataFrameGroupBy.all"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.bfill", "full_function": "DataFrameGroupBy.bfill(limit=None)", "function_text": "Backward fill the values.", "parameter_names_desc": [{"param_name": "limit", "param_type": "int, optional", "param_desc": "Limit of how many values to fill.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.bfill.html#pandas.core.groupby.DataFrameGroupBy.bfill"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.corrwith", "full_function": "DataFrameGroupBy.corrwith(other, axis=_NoDefault.no_default, drop=False, method='pearson', numeric_only=False)", "function_text": "Compute pairwise correlation.", "parameter_names_desc": [{"param_name": "other", "param_type": "DataFrame, Series", "param_desc": "Object with which to compute correlations.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "The axis to use. 0 or ‘index’ to compute row-wise, 1 or ‘columns’ for\ncolumn-wise.\n"}, {"param_name": "drop", "param_type": "bool, default False", "param_desc": "Drop missing indices from result.\n"}, {"param_name": "method", "param_type": "{‘pearson’, ‘kendall’, ‘spearman’} or callable", "param_desc": "Method of correlation:\n\npearson : standard correlation coefficient\nkendall : Kendall Tau correlation coefficient\nspearman : Spearman rank correlation\n\ncallable: callable with input two 1d ndarraysand returning a float.\n\n\n\n\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int or boolean data.\n\nNew in version 1.5.0.\n\n\nChanged in version 2.0.0: The default value of numeric_only is now False.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.corrwith.html#pandas.core.groupby.DataFrameGroupBy.corrwith"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.cov", "full_function": "DataFrameGroupBy.cov(min_periods=None, ddof=1, numeric_only=False)", "function_text": "Compute pairwise covariance of columns, excluding NA/null values.", "parameter_names_desc": [{"param_name": "min_periods", "param_type": "int, optional", "param_desc": "Minimum number of observations required per pair of columns\nto have a valid result.\n"}, {"param_name": "ddof", "param_type": "int, default 1", "param_desc": "Delta degrees of freedom. The divisor used in calculations\nis N - ddof, where N represents the number of elements.\nThis argument is applicable only when no nan is in the dataframe.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int or boolean data.\n\nNew in version 1.5.0.\n\n\nChanged in version 2.0.0: The default value of numeric_only is now False.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cov.html#pandas.core.groupby.DataFrameGroupBy.cov"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.cummax", "full_function": "DataFrameGroupBy.cummax(axis=_NoDefault.no_default, numeric_only=False, **kwargs)", "function_text": "Cumulative max for each group.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cummax.html#pandas.core.groupby.DataFrameGroupBy.cummax"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.cumprod", "full_function": "DataFrameGroupBy.cumprod(axis=_NoDefault.no_default, *args, **kwargs)", "function_text": "Cumulative product for each group.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cumprod.html#pandas.core.groupby.DataFrameGroupBy.cumprod"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.describe", "full_function": "DataFrameGroupBy.describe(percentiles=None, include=None, exclude=None)", "function_text": "Generate descriptive statistics.", "parameter_names_desc": [{"param_name": "percentiles", "param_type": "list-like of numbers, optional", "param_desc": "The percentiles to include in the output. All should\nfall between 0 and 1. The default is\n[.25, .5, .75], which returns the 25th, 50th, and\n75th percentiles.\n"}, {"param_name": "include", "param_type": "‘all’, list-like of dtypes or None (default), optional", "param_desc": "A white list of data types to include in the result. Ignored\nfor Series. Here are the options:\n\n‘all’ : All columns of the input will be included in the output.\nA list-like of dtypes : Limits the results to the\nprovided data types.\nTo limit the result to numeric types submit\nnumpy.number. To limit it instead to object columns submit\nthe numpy.object data type. Strings\ncan also be used in the style of\nselect_dtypes (e.g. df.describe(include=['O'])). To\nselect pandas categorical columns, use 'category'\nNone (default) : The result will include all numeric columns.\n\n"}, {"param_name": "exclude", "param_type": "list-like of dtypes or None (default), optional,", "param_desc": "A black list of data types to omit from the result. Ignored\nfor Series. Here are the options:\n\nA list-like of dtypes : Excludes the provided data types\nfrom the result. To exclude numeric types submit\nnumpy.number. To exclude object columns submit the data\ntype numpy.object. Strings can also be used in the style of\nselect_dtypes (e.g. df.describe(exclude=['O'])). To\nexclude pandas categorical columns, use 'category'\nNone (default) : The result will exclude nothing.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.describe.html#pandas.core.groupby.DataFrameGroupBy.describe"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.ffill", "full_function": "DataFrameGroupBy.ffill(limit=None)", "function_text": "Forward fill the values.", "parameter_names_desc": [{"param_name": "limit", "param_type": "int, optional", "param_desc": "Limit of how many values to fill.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.ffill.html#pandas.core.groupby.DataFrameGroupBy.ffill"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.first", "full_function": "DataFrameGroupBy.first(numeric_only=False, min_count=-1, skipna=True)", "function_text": "Compute the first entry of each column within each group.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n"}, {"param_name": "min_count", "param_type": "int, default -1", "param_desc": "The required number of valid values to perform the operation. If fewer\nthan min_count valid values are present the result will be NA.\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA.\n\nNew in version 2.2.1.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.first.html#pandas.core.groupby.DataFrameGroupBy.first"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.idxmax", "full_function": "DataFrameGroupBy.idxmax(axis=_NoDefault.no_default, skipna=True, numeric_only=False)", "function_text": "Return index of first occurrence of maximum over requested axis.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.idxmax.html#pandas.core.groupby.DataFrameGroupBy.idxmax"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.last", "full_function": "DataFrameGroupBy.last(numeric_only=False, min_count=-1, skipna=True)", "function_text": "Compute the last entry of each column within each group.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns. If None, will attempt to use\neverything, then use only numeric data.\n"}, {"param_name": "min_count", "param_type": "int, default -1", "param_desc": "The required number of valid values to perform the operation. If fewer\nthan min_count valid values are present the result will be NA.\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA.\n\nNew in version 2.2.1.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.last.html#pandas.core.groupby.DataFrameGroupBy.last"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.mean", "full_function": "DataFrameGroupBy.mean(numeric_only=False, engine=None, engine_kwargs=None)", "function_text": "Compute mean of groups, excluding missing values.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nChanged in version 2.0.0: numeric_only no longer accepts None and defaults to False.\n\n"}, {"param_name": "engine", "param_type": "str, default None", "param_desc": "\n'cython' : Runs the operation through C-extensions from cython.\n'numba' : Runs the operation through JIT compiled code from numba.\nNone : Defaults to 'cython' or globally setting\ncompute.use_numba\n\n\nNew in version 1.4.0.\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\nFor 'numba' engine, the engine can accept nopython, nogil\nand parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{{'nopython': True, 'nogil': False, 'parallel': False}}\n\n\nNew in version 1.4.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.mean.html#pandas.core.groupby.DataFrameGroupBy.mean"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.min", "full_function": "DataFrameGroupBy.min(numeric_only=False, min_count=-1, engine=None, engine_kwargs=None)", "function_text": "Compute min of group values.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nChanged in version 2.0.0: numeric_only no longer accepts None.\n\n"}, {"param_name": "min_count", "param_type": "int, default -1", "param_desc": "The required number of valid values to perform the operation. If fewer\nthan min_count non-NA values are present the result will be NA.\n"}, {"param_name": "engine", "param_type": "str, default None None", "param_desc": "\n'cython' : Runs rolling apply through C-extensions from cython.\n\n'numba'Runs rolling apply through JIT compiled code from numba.Only available when raw is set to True.\n\n\n\nNone : Defaults to 'cython' or globally setting compute.use_numba\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\n\nFor 'numba' engine, the engine can accept nopython, nogiland parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\napplied to both the func and the apply groupby aggregation.\n\n\n\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.min.html#pandas.core.groupby.DataFrameGroupBy.min"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.nth", "full_function": "property DataFrameGroupBy.nth", "function_text": "Take the nth row from each group if n is an int, otherwise a subset of rows.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, slice or list of ints and slices", "param_desc": "A single nth value for the row or a list of nth values or slices.\n\nChanged in version 1.4.0: Added slice and lists containing slices.\nAdded index notation.\n\n"}, {"param_name": "dropna", "param_type": "{‘any’, ‘all’, None}, default None", "param_desc": "Apply the specified dropna operation before counting which row is\nthe nth row. Only supported if n is an int.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.nth.html#pandas.core.groupby.DataFrameGroupBy.nth"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.ohlc", "full_function": "DataFrameGroupBy.ohlc()", "function_text": "Compute open, high, low and close values of a group, excluding missing values.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.ohlc.html#pandas.core.groupby.DataFrameGroupBy.ohlc"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.prod", "full_function": "DataFrameGroupBy.prod(numeric_only=False, min_count=0)", "function_text": "Compute prod of group values.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nChanged in version 2.0.0: numeric_only no longer accepts None.\n\n"}, {"param_name": "min_count", "param_type": "int, default 0", "param_desc": "The required number of valid values to perform the operation. If fewer\nthan min_count non-NA values are present the result will be NA.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.prod.html#pandas.core.groupby.DataFrameGroupBy.prod"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.rank", "full_function": "DataFrameGroupBy.rank(method='average', ascending=True, na_option='keep', pct=False, axis=_NoDefault.no_default)", "function_text": "Provide the rank of values within each group.", "parameter_names_desc": [{"param_name": "method", "param_type": "{‘average’, ‘min’, ‘max’, ‘first’, ‘dense’}, default ‘average’", "param_desc": "\naverage: average rank of group.\nmin: lowest rank in group.\nmax: highest rank in group.\nfirst: ranks assigned in order they appear in the array.\ndense: like ‘min’, but rank always increases by 1 between groups.\n\n"}, {"param_name": "ascending", "param_type": "bool, default True", "param_desc": "False for ranks by high (1) to low (N).\n"}, {"param_name": "na_option", "param_type": "{‘keep’, ‘top’, ‘bottom’}, default ‘keep’", "param_desc": "\nkeep: leave NA values where they are.\ntop: smallest rank if ascending.\nbottom: smallest rank if descending.\n\n"}, {"param_name": "pct", "param_type": "bool, default False", "param_desc": "Compute percentage rank of data within each group.\n"}, {"param_name": "axis", "param_type": "int, default 0", "param_desc": "The axis of the object over which to compute the rank.\n\nDeprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\nthe axis keyword is not necessary.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.rank.html#pandas.core.groupby.DataFrameGroupBy.rank"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.rolling", "full_function": "DataFrameGroupBy.rolling(*args, **kwargs)", "function_text": "Return a rolling grouper, providing rolling functionality per group.", "parameter_names_desc": [{"param_name": "window", "param_type": "int, timedelta, str, offset, or BaseIndexer subclass", "param_desc": "Size of the moving window.\nIf an integer, the fixed number of observations used for\neach window.\nIf a timedelta, str, or offset, the time period of each window. Each\nwindow will be a variable sized based on the observations included in\nthe time-period. This is only valid for datetimelike indexes.\nTo learn more about the offsets & frequency strings, please see this link.\nIf a BaseIndexer subclass, the window boundaries\nbased on the defined get_window_bounds method. Additional rolling\nkeyword arguments, namely min_periods, center, closed and\nstep will be passed to get_window_bounds.\n"}, {"param_name": "min_periods", "param_type": "int, default None", "param_desc": "Minimum number of observations in window required to have a value;\notherwise, result is np.nan.\nFor a window that is specified by an offset,\nmin_periods will default to 1.\nFor a window that is specified by an integer, min_periods will default\nto the size of the window.\n"}, {"param_name": "center", "param_type": "bool, default False", "param_desc": "If False, set the window labels as the right edge of the window index.\nIf True, set the window labels as the center of the window index.\n"}, {"param_name": "win_type", "param_type": "str, default None", "param_desc": "If None, all points are evenly weighted.\nIf a string, it must be a valid scipy.signal window function.\nCertain Scipy window types require additional parameters to be passed\nin the aggregation function. The additional parameters must match\nthe keywords specified in the Scipy window type method signature.\n"}, {"param_name": "on", "param_type": "str, optional", "param_desc": "For a DataFrame, a column label or Index level on which\nto calculate the rolling window, rather than the DataFrame’s index.\nProvided integer column is ignored and excluded from result since\nan integer index is not used to calculate the rolling window.\n"}, {"param_name": "axis", "param_type": "int or str, default 0", "param_desc": "If 0 or 'index', roll across the rows.\nIf 1 or 'columns', roll across the columns.\nFor Series this parameter is unused and defaults to 0.\n"}, {"param_name": "closed", "param_type": "str, default None", "param_desc": "If 'right', the first point in the window is excluded from calculations.\nIf 'left', the last point in the window is excluded from calculations.\nIf 'both', no points in the window are excluded from calculations.\nIf 'neither', the first and last points in the window are excluded\nfrom calculations.\nDefault None ('right').\n"}, {"param_name": "method", "param_type": "str {‘single’, ‘table’}, default ‘single’", "param_desc": "Execute the rolling operation per single column or row ('single')\nor over the entire object ('table').\nThis argument is only implemented when specifying engine='numba'\nin the method call.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.rolling.html#pandas.core.groupby.DataFrameGroupBy.rolling"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.sem", "full_function": "DataFrameGroupBy.sem(ddof=1, numeric_only=False)", "function_text": "Compute standard error of the mean of groups, excluding missing values.", "parameter_names_desc": [{"param_name": "ddof", "param_type": "int, default 1", "param_desc": "Degrees of freedom.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int or boolean data.\n\nNew in version 1.5.0.\n\n\nChanged in version 2.0.0: numeric_only now defaults to False.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.sem.html#pandas.core.groupby.DataFrameGroupBy.sem"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.size", "full_function": "DataFrameGroupBy.size()", "function_text": "Compute group sizes.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.size.html#pandas.core.groupby.DataFrameGroupBy.size"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.std", "full_function": "DataFrameGroupBy.std(ddof=1, engine=None, engine_kwargs=None, numeric_only=False)", "function_text": "Compute standard deviation of groups, excluding missing values.", "parameter_names_desc": [{"param_name": "ddof", "param_type": "int, default 1", "param_desc": "Degrees of freedom.\n"}, {"param_name": "engine", "param_type": "str, default None", "param_desc": "\n'cython' : Runs the operation through C-extensions from cython.\n'numba' : Runs the operation through JIT compiled code from numba.\nNone : Defaults to 'cython' or globally setting\ncompute.use_numba\n\n\nNew in version 1.4.0.\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\nFor 'numba' engine, the engine can accept nopython, nogil\nand parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{{'nopython': True, 'nogil': False, 'parallel': False}}\n\n\nNew in version 1.4.0.\n\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int or boolean data.\n\nNew in version 1.5.0.\n\n\nChanged in version 2.0.0: numeric_only now defaults to False.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.std.html#pandas.core.groupby.DataFrameGroupBy.std"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.var", "full_function": "DataFrameGroupBy.var(ddof=1, engine=None, engine_kwargs=None, numeric_only=False)", "function_text": "Compute variance of groups, excluding missing values.", "parameter_names_desc": [{"param_name": "ddof", "param_type": "int, default 1", "param_desc": "Degrees of freedom.\n"}, {"param_name": "engine", "param_type": "str, default None", "param_desc": "\n'cython' : Runs the operation through C-extensions from cython.\n'numba' : Runs the operation through JIT compiled code from numba.\nNone : Defaults to 'cython' or globally setting\ncompute.use_numba\n\n\nNew in version 1.4.0.\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\nFor 'numba' engine, the engine can accept nopython, nogil\nand parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{{'nopython': True, 'nogil': False, 'parallel': False}}\n\n\nNew in version 1.4.0.\n\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int or boolean data.\n\nNew in version 1.5.0.\n\n\nChanged in version 2.0.0: numeric_only now defaults to False.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.var.html#pandas.core.groupby.DataFrameGroupBy.var"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.take", "full_function": "DataFrameGroupBy.take(indices, axis=_NoDefault.no_default, **kwargs)", "function_text": "Return the elements in the given positional indices in each group.", "parameter_names_desc": [{"param_name": "indices", "param_type": "array-like", "param_desc": "An array of ints indicating which positions to take.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’, None}, default 0", "param_desc": "The axis on which to select elements. 0 means that we are\nselecting rows, 1 means that we are selecting columns.\n\nDeprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\nthe axis keyword is not necessary.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.take.html#pandas.core.groupby.DataFrameGroupBy.take"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.any", "full_function": "DataFrameGroupBy.any(skipna=True)", "function_text": "Return True if any value in the group is truthful, else False.", "parameter_names_desc": [{"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Flag to ignore nan values during truth testing.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.any.html#pandas.core.groupby.DataFrameGroupBy.any"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.corr", "full_function": "DataFrameGroupBy.corr(method='pearson', min_periods=1, numeric_only=False)", "function_text": "Compute pairwise correlation of columns, excluding NA/null values.", "parameter_names_desc": [{"param_name": "method", "param_type": "{‘pearson’, ‘kendall’, ‘spearman’} or callable", "param_desc": "Method of correlation:\n\npearson : standard correlation coefficient\nkendall : Kendall Tau correlation coefficient\nspearman : Spearman rank correlation\n\ncallable: callable with input two 1d ndarraysand returning a float. Note that the returned matrix from corr\nwill have 1 along the diagonals and will be symmetric\nregardless of the callable’s behavior.\n\n\n\n\n"}, {"param_name": "min_periods", "param_type": "int, optional", "param_desc": "Minimum number of observations required per pair of columns\nto have a valid result. Currently only available for Pearson\nand Spearman correlation.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int or boolean data.\n\nNew in version 1.5.0.\n\n\nChanged in version 2.0.0: The default value of numeric_only is now False.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.corr.html#pandas.core.groupby.DataFrameGroupBy.corr"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.count", "full_function": "DataFrameGroupBy.count()", "function_text": "Compute count of group, excluding missing values.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.count.html#pandas.core.groupby.DataFrameGroupBy.count"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.cumcount", "full_function": "DataFrameGroupBy.cumcount(ascending=True)", "function_text": "Number each item in each group from 0 to the length of that group - 1.", "parameter_names_desc": [{"param_name": "ascending", "param_type": "bool, default True", "param_desc": "If False, number in reverse, from length of group - 1 to 0.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cumcount.html#pandas.core.groupby.DataFrameGroupBy.cumcount"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.cummin", "full_function": "DataFrameGroupBy.cummin(axis=_NoDefault.no_default, numeric_only=False, **kwargs)", "function_text": "Cumulative min for each group.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cummin.html#pandas.core.groupby.DataFrameGroupBy.cummin"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.cumsum", "full_function": "DataFrameGroupBy.cumsum(axis=_NoDefault.no_default, *args, **kwargs)", "function_text": "Cumulative sum for each group.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cumsum.html#pandas.core.groupby.DataFrameGroupBy.cumsum"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.diff", "full_function": "DataFrameGroupBy.diff(periods=1, axis=_NoDefault.no_default)", "function_text": "First discrete difference of element.", "parameter_names_desc": [{"param_name": "periods", "param_type": "int, default 1", "param_desc": "Periods to shift for calculating difference, accepts negative values.\n"}, {"param_name": "axis", "param_type": "axis to shift, default 0", "param_desc": "Take difference over rows (0) or columns (1).\n\nDeprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\nthe axis keyword is not necessary.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.diff.html#pandas.core.groupby.DataFrameGroupBy.diff"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.fillna", "full_function": "DataFrameGroupBy.fillna(value=None, method=None, axis=_NoDefault.no_default, inplace=False, limit=None, downcast=_NoDefault.no_default)", "function_text": "Fill NA/NaN values using the specified method within groups.", "parameter_names_desc": [{"param_name": "value", "param_type": "scalar, dict, Series, or DataFrame", "param_desc": "Value to use to fill holes (e.g. 0), alternately a\ndict/Series/DataFrame of values specifying which value to use for\neach index (for a Series) or column (for a DataFrame). Values not\nin the dict/Series/DataFrame will not be filled. This value cannot\nbe a list. Users wanting to use the value argument and not method\nshould prefer DataFrame.fillna() as this\nwill produce the same result and be more performant.\n"}, {"param_name": "method", "param_type": "{{‘bfill’, ‘ffill’, None}}, default None", "param_desc": "Method to use for filling holes. 'ffill' will propagate\nthe last valid observation forward within a group.\n'bfill' will use next valid observation to fill the gap.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}", "param_desc": "Axis along which to fill missing values. When the DataFrameGroupBy\naxis argument is 0, using axis=1 here will produce\nthe same results as DataFrame.fillna(). When the\nDataFrameGroupBy axis argument is 1, using axis=0\nor axis=1 here will produce the same results.\n"}, {"param_name": "inplace", "param_type": "bool, default False", "param_desc": "Broken. Do not set to True.\n"}, {"param_name": "limit", "param_type": "int, default None", "param_desc": "If method is specified, this is the maximum number of consecutive\nNaN values to forward/backward fill within a group. In other words,\nif there is a gap with more than this number of consecutive NaNs,\nit will only be partially filled. If method is not specified, this is the\nmaximum number of entries along the entire axis where NaNs will be\nfilled. Must be greater than 0 if not None.\n"}, {"param_name": "downcast", "param_type": "dict, default is None", "param_desc": "A dict of item->dtype of what to downcast if possible,\nor the string ‘infer’ which will try to downcast to an appropriate\nequal type (e.g. float64 to int64 if possible).\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.fillna.html#pandas.core.groupby.DataFrameGroupBy.fillna"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.head", "full_function": "DataFrameGroupBy.head(n=5)", "function_text": "Return first n rows of each group.", "parameter_names_desc": [{"param_name": "n", "param_type": "int", "param_desc": "If positive: number of entries to include from start of each group.\nIf negative: number of entries to exclude from end of each group.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.head.html#pandas.core.groupby.DataFrameGroupBy.head"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.idxmin", "full_function": "DataFrameGroupBy.idxmin(axis=_NoDefault.no_default, skipna=True, numeric_only=False)", "function_text": "Return index of first occurrence of minimum over requested axis.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.idxmin.html#pandas.core.groupby.DataFrameGroupBy.idxmin"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.max", "full_function": "DataFrameGroupBy.max(numeric_only=False, min_count=-1, engine=None, engine_kwargs=None)", "function_text": "Compute max of group values.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nChanged in version 2.0.0: numeric_only no longer accepts None.\n\n"}, {"param_name": "min_count", "param_type": "int, default -1", "param_desc": "The required number of valid values to perform the operation. If fewer\nthan min_count non-NA values are present the result will be NA.\n"}, {"param_name": "engine", "param_type": "str, default None None", "param_desc": "\n'cython' : Runs rolling apply through C-extensions from cython.\n\n'numba'Runs rolling apply through JIT compiled code from numba.Only available when raw is set to True.\n\n\n\nNone : Defaults to 'cython' or globally setting compute.use_numba\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\n\nFor 'numba' engine, the engine can accept nopython, nogiland parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\napplied to both the func and the apply groupby aggregation.\n\n\n\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.max.html#pandas.core.groupby.DataFrameGroupBy.max"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.median", "full_function": "DataFrameGroupBy.median(numeric_only=False)", "function_text": "Compute median of groups, excluding missing values.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nChanged in version 2.0.0: numeric_only no longer accepts None and defaults to False.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.median.html#pandas.core.groupby.DataFrameGroupBy.median"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.ngroup", "full_function": "DataFrameGroupBy.ngroup(ascending=True)", "function_text": "Number each group from 0 to the number of groups - 1.", "parameter_names_desc": [{"param_name": "ascending", "param_type": "bool, default True", "param_desc": "If False, number in reverse, from number of group - 1 to 0.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.ngroup.html#pandas.core.groupby.DataFrameGroupBy.ngroup"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.nunique", "full_function": "DataFrameGroupBy.nunique(dropna=True)", "function_text": "Return DataFrame with counts of unique elements in each position.", "parameter_names_desc": [{"param_name": "dropna", "param_type": "bool, default True", "param_desc": "Don’t include NaN in the counts.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.nunique.html#pandas.core.groupby.DataFrameGroupBy.nunique"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.pct_change", "full_function": "DataFrameGroupBy.pct_change(periods=1, fill_method=_NoDefault.no_default, limit=_NoDefault.no_default, freq=None, axis=_NoDefault.no_default)", "function_text": "Calculate pct_change of each value to previous entry in group.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.pct_change.html#pandas.core.groupby.DataFrameGroupBy.pct_change"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.quantile", "full_function": "DataFrameGroupBy.quantile(q=0.5, interpolation='linear', numeric_only=False)", "function_text": "Return group values at the given quantile, a la numpy.percentile.", "parameter_names_desc": [{"param_name": "q", "param_type": "float or array-like, default 0.5 (50% quantile)", "param_desc": "Value(s) between 0 and 1 providing the quantile(s) to compute.\n"}, {"param_name": "interpolation", "param_type": "{‘linear’, ‘lower’, ‘higher’, ‘midpoint’, ‘nearest’}", "param_desc": "Method to use when the desired quantile falls between two points.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int or boolean data.\n\nNew in version 1.5.0.\n\n\nChanged in version 2.0.0: numeric_only now defaults to False.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.quantile.html#pandas.core.groupby.DataFrameGroupBy.quantile"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.resample", "full_function": "DataFrameGroupBy.resample(rule, *args, include_groups=True, **kwargs)", "function_text": "Provide resampling when using a TimeGrouper.", "parameter_names_desc": [{"param_name": "rule", "param_type": "str or DateOffset", "param_desc": "The offset string or object representing target grouper conversion.\n"}, {"param_name": "include_groups", "param_type": "bool, default True", "param_desc": "When True, will attempt to include the groupings in the operation in\nthe case that they are columns of the DataFrame. If this raises a\nTypeError, the result will be computed with the groupings excluded.\nWhen False, the groupings will be excluded when applying func.\n\nNew in version 2.2.0.\n\n\nDeprecated since version 2.2.0: Setting include_groups to True is deprecated. Only the value\nFalse will be allowed in a future version of pandas.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.resample.html#pandas.core.groupby.DataFrameGroupBy.resample"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.sample", "full_function": "DataFrameGroupBy.sample(n=None, frac=None, replace=False, weights=None, random_state=None)", "function_text": "Return a random sample of items from each group.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, optional", "param_desc": "Number of items to return for each group. Cannot be used with\nfrac and must be no larger than the smallest group unless\nreplace is True. Default is one if frac is None.\n"}, {"param_name": "frac", "param_type": "float, optional", "param_desc": "Fraction of items to return. Cannot be used with n.\n"}, {"param_name": "replace", "param_type": "bool, default False", "param_desc": "Allow or disallow sampling of the same row more than once.\n"}, {"param_name": "weights", "param_type": "list-like, optional", "param_desc": "Default None results in equal probability weighting.\nIf passed a list-like then values must have the same length as\nthe underlying DataFrame or Series object and will be used as\nsampling probabilities after normalization within each group.\nValues must be non-negative with at least one positive element\nwithin each group.\n"}, {"param_name": "random_state", "param_type": "int, array-like, BitGenerator, np.random.RandomState, np.random.Generator, optional", "param_desc": "If int, array-like, or BitGenerator, seed for random number generator.\nIf np.random.RandomState or np.random.Generator, use as given.\n\nChanged in version 1.4.0: np.random.Generator objects now accepted\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.sample.html#pandas.core.groupby.DataFrameGroupBy.sample"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.shift", "full_function": "DataFrameGroupBy.shift(periods=1, freq=None, axis=_NoDefault.no_default, fill_value=_NoDefault.no_default, suffix=None)", "function_text": "Shift each group by periods observations.", "parameter_names_desc": [{"param_name": "periods", "param_type": "int | Sequence[int], default 1", "param_desc": "Number of periods to shift. If a list of values, shift each group by\neach period.\n"}, {"param_name": "freq", "param_type": "str, optional", "param_desc": "Frequency string.\n"}, {"param_name": "axis", "param_type": "axis to shift, default 0", "param_desc": "Shift direction.\n\nDeprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\nthe axis keyword is not necessary.\n\n"}, {"param_name": "fill_value", "param_type": "optional", "param_desc": "The scalar value to use for newly introduced missing values.\n\nChanged in version 2.1.0: Will raise a ValueError if freq is provided too.\n\n"}, {"param_name": "suffix", "param_type": "str, optional", "param_desc": "A string to add to each shifted column if there are multiple periods.\nIgnored otherwise.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.shift.html#pandas.core.groupby.DataFrameGroupBy.shift"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.skew", "full_function": "DataFrameGroupBy.skew(axis=_NoDefault.no_default, skipna=True, numeric_only=False, **kwargs)", "function_text": "Return unbiased skew within groups.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’, None}, default 0", "param_desc": "Axis for the function to be applied on.\nSpecifying axis=None will apply the aggregation across both axes.\n\nNew in version 2.0.0.\n\n\nDeprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\nthe axis keyword is not necessary.\n\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values when computing the result.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.skew.html#pandas.core.groupby.DataFrameGroupBy.skew"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.sum", "full_function": "DataFrameGroupBy.sum(numeric_only=False, min_count=0, engine=None, engine_kwargs=None)", "function_text": "Compute sum of group values.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nChanged in version 2.0.0: numeric_only no longer accepts None.\n\n"}, {"param_name": "min_count", "param_type": "int, default 0", "param_desc": "The required number of valid values to perform the operation. If fewer\nthan min_count non-NA values are present the result will be NA.\n"}, {"param_name": "engine", "param_type": "str, default None None", "param_desc": "\n'cython' : Runs rolling apply through C-extensions from cython.\n\n'numba'Runs rolling apply through JIT compiled code from numba.Only available when raw is set to True.\n\n\n\nNone : Defaults to 'cython' or globally setting compute.use_numba\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\n\nFor 'numba' engine, the engine can accept nopython, nogiland parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\napplied to both the func and the apply groupby aggregation.\n\n\n\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.sum.html#pandas.core.groupby.DataFrameGroupBy.sum"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.tail", "full_function": "DataFrameGroupBy.tail(n=5)", "function_text": "Return last n rows of each group.", "parameter_names_desc": [{"param_name": "n", "param_type": "int", "param_desc": "If positive: number of entries to include from end of each group.\nIf negative: number of entries to exclude from start of each group.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.tail.html#pandas.core.groupby.DataFrameGroupBy.tail"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.value_counts", "full_function": "DataFrameGroupBy.value_counts(subset=None, normalize=False, sort=True, ascending=False, dropna=True)", "function_text": "Return a Series or DataFrame containing counts of unique rows.", "parameter_names_desc": [{"param_name": "subset", "param_type": "list-like, optional", "param_desc": "Columns to use when counting unique combinations.\n"}, {"param_name": "normalize", "param_type": "bool, default False", "param_desc": "Return proportions rather than frequencies.\n"}, {"param_name": "sort", "param_type": "bool, default True", "param_desc": "Sort by frequencies.\n"}, {"param_name": "ascending", "param_type": "bool, default False", "param_desc": "Sort in ascending order.\n"}, {"param_name": "dropna", "param_type": "bool, default True", "param_desc": "Don’t include counts of rows that contain NA values.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.value_counts.html#pandas.core.groupby.DataFrameGroupBy.value_counts"}]}, {"name": "SeriesGroupBy computations / descriptive stats", "url": "https://pandas.pydata.org/docs/reference/groupby.html#seriesgroupby-computations-descriptive-stats", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.all.html#pandas.core.groupby.SeriesGroupBy.all", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.bfill.html#pandas.core.groupby.SeriesGroupBy.bfill", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.count.html#pandas.core.groupby.SeriesGroupBy.count", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cumcount.html#pandas.core.groupby.SeriesGroupBy.cumcount", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cummin.html#pandas.core.groupby.SeriesGroupBy.cummin", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cumsum.html#pandas.core.groupby.SeriesGroupBy.cumsum", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.diff.html#pandas.core.groupby.SeriesGroupBy.diff", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.fillna.html#pandas.core.groupby.SeriesGroupBy.fillna", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.head.html#pandas.core.groupby.SeriesGroupBy.head", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.idxmax.html#pandas.core.groupby.SeriesGroupBy.idxmax", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.is_monotonic_increasing.html#pandas.core.groupby.SeriesGroupBy.is_monotonic_increasing", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.max.html#pandas.core.groupby.SeriesGroupBy.max", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.median.html#pandas.core.groupby.SeriesGroupBy.median", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.ngroup.html#pandas.core.groupby.SeriesGroupBy.ngroup", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.nsmallest.html#pandas.core.groupby.SeriesGroupBy.nsmallest", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.nunique.html#pandas.core.groupby.SeriesGroupBy.nunique", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.ohlc.html#pandas.core.groupby.SeriesGroupBy.ohlc", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.prod.html#pandas.core.groupby.SeriesGroupBy.prod", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.rank.html#pandas.core.groupby.SeriesGroupBy.rank", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.rolling.html#pandas.core.groupby.SeriesGroupBy.rolling", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.sem.html#pandas.core.groupby.SeriesGroupBy.sem", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.size.html#pandas.core.groupby.SeriesGroupBy.size", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.std.html#pandas.core.groupby.SeriesGroupBy.std", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.var.html#pandas.core.groupby.SeriesGroupBy.var", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.take.html#pandas.core.groupby.SeriesGroupBy.take", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.any.html#pandas.core.groupby.SeriesGroupBy.any", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.corr.html#pandas.core.groupby.SeriesGroupBy.corr", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cov.html#pandas.core.groupby.SeriesGroupBy.cov", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cummax.html#pandas.core.groupby.SeriesGroupBy.cummax", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cumprod.html#pandas.core.groupby.SeriesGroupBy.cumprod", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.describe.html#pandas.core.groupby.SeriesGroupBy.describe", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.ffill.html#pandas.core.groupby.SeriesGroupBy.ffill", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.first.html#pandas.core.groupby.SeriesGroupBy.first", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.last.html#pandas.core.groupby.SeriesGroupBy.last", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.idxmin.html#pandas.core.groupby.SeriesGroupBy.idxmin", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.is_monotonic_decreasing.html#pandas.core.groupby.SeriesGroupBy.is_monotonic_decreasing", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.mean.html#pandas.core.groupby.SeriesGroupBy.mean", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.min.html#pandas.core.groupby.SeriesGroupBy.min", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.nlargest.html#pandas.core.groupby.SeriesGroupBy.nlargest", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.nth.html#pandas.core.groupby.SeriesGroupBy.nth", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.unique.html#pandas.core.groupby.SeriesGroupBy.unique", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.pct_change.html#pandas.core.groupby.SeriesGroupBy.pct_change", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.quantile.html#pandas.core.groupby.SeriesGroupBy.quantile", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.resample.html#pandas.core.groupby.SeriesGroupBy.resample", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.sample.html#pandas.core.groupby.SeriesGroupBy.sample", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.shift.html#pandas.core.groupby.SeriesGroupBy.shift", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.skew.html#pandas.core.groupby.SeriesGroupBy.skew", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.sum.html#pandas.core.groupby.SeriesGroupBy.sum", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.tail.html#pandas.core.groupby.SeriesGroupBy.tail", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.value_counts.html#pandas.core.groupby.SeriesGroupBy.value_counts"], "function_definitions": [{"function_name": "pandas.core.groupby.SeriesGroupBy.all", "full_function": "SeriesGroupBy.all(skipna=True)", "function_text": "Return True if all values in the group are truthful, else False.", "parameter_names_desc": [{"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Flag to ignore nan values during truth testing.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.all.html#pandas.core.groupby.SeriesGroupBy.all"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.bfill", "full_function": "SeriesGroupBy.bfill(limit=None)", "function_text": "Backward fill the values.", "parameter_names_desc": [{"param_name": "limit", "param_type": "int, optional", "param_desc": "Limit of how many values to fill.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.bfill.html#pandas.core.groupby.SeriesGroupBy.bfill"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.count", "full_function": "SeriesGroupBy.count()", "function_text": "Compute count of group, excluding missing values.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.count.html#pandas.core.groupby.SeriesGroupBy.count"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.cumcount", "full_function": "SeriesGroupBy.cumcount(ascending=True)", "function_text": "Number each item in each group from 0 to the length of that group - 1.", "parameter_names_desc": [{"param_name": "ascending", "param_type": "bool, default True", "param_desc": "If False, number in reverse, from length of group - 1 to 0.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cumcount.html#pandas.core.groupby.SeriesGroupBy.cumcount"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.cummin", "full_function": "SeriesGroupBy.cummin(axis=_NoDefault.no_default, numeric_only=False, **kwargs)", "function_text": "Cumulative min for each group.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cummin.html#pandas.core.groupby.SeriesGroupBy.cummin"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.cumsum", "full_function": "SeriesGroupBy.cumsum(axis=_NoDefault.no_default, *args, **kwargs)", "function_text": "Cumulative sum for each group.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cumsum.html#pandas.core.groupby.SeriesGroupBy.cumsum"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.diff", "full_function": "SeriesGroupBy.diff(periods=1, axis=_NoDefault.no_default)", "function_text": "First discrete difference of element.", "parameter_names_desc": [{"param_name": "periods", "param_type": "int, default 1", "param_desc": "Periods to shift for calculating difference, accepts negative values.\n"}, {"param_name": "axis", "param_type": "axis to shift, default 0", "param_desc": "Take difference over rows (0) or columns (1).\n\nDeprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\nthe axis keyword is not necessary.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.diff.html#pandas.core.groupby.SeriesGroupBy.diff"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.fillna", "full_function": "SeriesGroupBy.fillna(value=None, method=None, axis=_NoDefault.no_default, inplace=False, limit=None, downcast=_NoDefault.no_default)", "function_text": "Fill NA/NaN values using the specified method within groups.", "parameter_names_desc": [{"param_name": "value", "param_type": "scalar, dict, Series, or DataFrame", "param_desc": "Value to use to fill holes (e.g. 0), alternately a\ndict/Series/DataFrame of values specifying which value to use for\neach index (for a Series) or column (for a DataFrame). Values not\nin the dict/Series/DataFrame will not be filled. This value cannot\nbe a list. Users wanting to use the value argument and not method\nshould prefer Series.fillna() as this\nwill produce the same result and be more performant.\n"}, {"param_name": "method", "param_type": "{{‘bfill’, ‘ffill’, None}}, default None", "param_desc": "Method to use for filling holes. 'ffill' will propagate\nthe last valid observation forward within a group.\n'bfill' will use next valid observation to fill the gap.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}", "param_desc": "Unused, only for compatibility with DataFrameGroupBy.fillna().\n"}, {"param_name": "inplace", "param_type": "bool, default False", "param_desc": "Broken. Do not set to True.\n"}, {"param_name": "limit", "param_type": "int, default None", "param_desc": "If method is specified, this is the maximum number of consecutive\nNaN values to forward/backward fill within a group. In other words,\nif there is a gap with more than this number of consecutive NaNs,\nit will only be partially filled. If method is not specified, this is the\nmaximum number of entries along the entire axis where NaNs will be\nfilled. Must be greater than 0 if not None.\n"}, {"param_name": "downcast", "param_type": "dict, default is None", "param_desc": "A dict of item->dtype of what to downcast if possible,\nor the string ‘infer’ which will try to downcast to an appropriate\nequal type (e.g. float64 to int64 if possible).\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.fillna.html#pandas.core.groupby.SeriesGroupBy.fillna"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.head", "full_function": "SeriesGroupBy.head(n=5)", "function_text": "Return first n rows of each group.", "parameter_names_desc": [{"param_name": "n", "param_type": "int", "param_desc": "If positive: number of entries to include from start of each group.\nIf negative: number of entries to exclude from end of each group.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.head.html#pandas.core.groupby.SeriesGroupBy.head"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.idxmax", "full_function": "SeriesGroupBy.idxmax(axis=_NoDefault.no_default, skipna=True)", "function_text": "Return the row label of the maximum value.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.idxmax.html#pandas.core.groupby.SeriesGroupBy.idxmax"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.is_monotonic_increasing", "full_function": "property SeriesGroupBy.is_monotonic_increasing", "function_text": "Return whether each group’s values are monotonically increasing.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.is_monotonic_increasing.html#pandas.core.groupby.SeriesGroupBy.is_monotonic_increasing"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.max", "full_function": "SeriesGroupBy.max(numeric_only=False, min_count=-1, engine=None, engine_kwargs=None)", "function_text": "Compute max of group values.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nChanged in version 2.0.0: numeric_only no longer accepts None.\n\n"}, {"param_name": "min_count", "param_type": "int, default -1", "param_desc": "The required number of valid values to perform the operation. If fewer\nthan min_count non-NA values are present the result will be NA.\n"}, {"param_name": "engine", "param_type": "str, default None None", "param_desc": "\n'cython' : Runs rolling apply through C-extensions from cython.\n\n'numba'Runs rolling apply through JIT compiled code from numba.Only available when raw is set to True.\n\n\n\nNone : Defaults to 'cython' or globally setting compute.use_numba\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\n\nFor 'numba' engine, the engine can accept nopython, nogiland parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\napplied to both the func and the apply groupby aggregation.\n\n\n\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.max.html#pandas.core.groupby.SeriesGroupBy.max"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.median", "full_function": "SeriesGroupBy.median(numeric_only=False)", "function_text": "Compute median of groups, excluding missing values.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nChanged in version 2.0.0: numeric_only no longer accepts None and defaults to False.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.median.html#pandas.core.groupby.SeriesGroupBy.median"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.ngroup", "full_function": "SeriesGroupBy.ngroup(ascending=True)", "function_text": "Number each group from 0 to the number of groups - 1.", "parameter_names_desc": [{"param_name": "ascending", "param_type": "bool, default True", "param_desc": "If False, number in reverse, from number of group - 1 to 0.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.ngroup.html#pandas.core.groupby.SeriesGroupBy.ngroup"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.nsmallest", "full_function": "SeriesGroupBy.nsmallest(n=5, keep='first')", "function_text": "Return the smallest n elements.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 5", "param_desc": "Return this many ascending sorted values.\n"}, {"param_name": "keep", "param_type": "{‘first’, ‘last’, ‘all’}, default ‘first’", "param_desc": "When there are duplicate values that cannot all fit in a\nSeries of n elements:\n\nfirst : return the first n occurrences in order\nof appearance.\nlast : return the last n occurrences in reverse\norder of appearance.\nall : keep all occurrences. This can result in a Series of\nsize larger than n.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.nsmallest.html#pandas.core.groupby.SeriesGroupBy.nsmallest"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.nunique", "full_function": "SeriesGroupBy.nunique(dropna=True)", "function_text": "Return number of unique elements in the group.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.nunique.html#pandas.core.groupby.SeriesGroupBy.nunique"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.ohlc", "full_function": "SeriesGroupBy.ohlc()", "function_text": "Compute open, high, low and close values of a group, excluding missing values.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.ohlc.html#pandas.core.groupby.SeriesGroupBy.ohlc"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.prod", "full_function": "SeriesGroupBy.prod(numeric_only=False, min_count=0)", "function_text": "Compute prod of group values.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nChanged in version 2.0.0: numeric_only no longer accepts None.\n\n"}, {"param_name": "min_count", "param_type": "int, default 0", "param_desc": "The required number of valid values to perform the operation. If fewer\nthan min_count non-NA values are present the result will be NA.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.prod.html#pandas.core.groupby.SeriesGroupBy.prod"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.rank", "full_function": "SeriesGroupBy.rank(method='average', ascending=True, na_option='keep', pct=False, axis=_NoDefault.no_default)", "function_text": "Provide the rank of values within each group.", "parameter_names_desc": [{"param_name": "method", "param_type": "{‘average’, ‘min’, ‘max’, ‘first’, ‘dense’}, default ‘average’", "param_desc": "\naverage: average rank of group.\nmin: lowest rank in group.\nmax: highest rank in group.\nfirst: ranks assigned in order they appear in the array.\ndense: like ‘min’, but rank always increases by 1 between groups.\n\n"}, {"param_name": "ascending", "param_type": "bool, default True", "param_desc": "False for ranks by high (1) to low (N).\n"}, {"param_name": "na_option", "param_type": "{‘keep’, ‘top’, ‘bottom’}, default ‘keep’", "param_desc": "\nkeep: leave NA values where they are.\ntop: smallest rank if ascending.\nbottom: smallest rank if descending.\n\n"}, {"param_name": "pct", "param_type": "bool, default False", "param_desc": "Compute percentage rank of data within each group.\n"}, {"param_name": "axis", "param_type": "int, default 0", "param_desc": "The axis of the object over which to compute the rank.\n\nDeprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\nthe axis keyword is not necessary.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.rank.html#pandas.core.groupby.SeriesGroupBy.rank"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.rolling", "full_function": "SeriesGroupBy.rolling(*args, **kwargs)", "function_text": "Return a rolling grouper, providing rolling functionality per group.", "parameter_names_desc": [{"param_name": "window", "param_type": "int, timedelta, str, offset, or BaseIndexer subclass", "param_desc": "Size of the moving window.\nIf an integer, the fixed number of observations used for\neach window.\nIf a timedelta, str, or offset, the time period of each window. Each\nwindow will be a variable sized based on the observations included in\nthe time-period. This is only valid for datetimelike indexes.\nTo learn more about the offsets & frequency strings, please see this link.\nIf a BaseIndexer subclass, the window boundaries\nbased on the defined get_window_bounds method. Additional rolling\nkeyword arguments, namely min_periods, center, closed and\nstep will be passed to get_window_bounds.\n"}, {"param_name": "min_periods", "param_type": "int, default None", "param_desc": "Minimum number of observations in window required to have a value;\notherwise, result is np.nan.\nFor a window that is specified by an offset,\nmin_periods will default to 1.\nFor a window that is specified by an integer, min_periods will default\nto the size of the window.\n"}, {"param_name": "center", "param_type": "bool, default False", "param_desc": "If False, set the window labels as the right edge of the window index.\nIf True, set the window labels as the center of the window index.\n"}, {"param_name": "win_type", "param_type": "str, default None", "param_desc": "If None, all points are evenly weighted.\nIf a string, it must be a valid scipy.signal window function.\nCertain Scipy window types require additional parameters to be passed\nin the aggregation function. The additional parameters must match\nthe keywords specified in the Scipy window type method signature.\n"}, {"param_name": "on", "param_type": "str, optional", "param_desc": "For a DataFrame, a column label or Index level on which\nto calculate the rolling window, rather than the DataFrame’s index.\nProvided integer column is ignored and excluded from result since\nan integer index is not used to calculate the rolling window.\n"}, {"param_name": "axis", "param_type": "int or str, default 0", "param_desc": "If 0 or 'index', roll across the rows.\nIf 1 or 'columns', roll across the columns.\nFor Series this parameter is unused and defaults to 0.\n"}, {"param_name": "closed", "param_type": "str, default None", "param_desc": "If 'right', the first point in the window is excluded from calculations.\nIf 'left', the last point in the window is excluded from calculations.\nIf 'both', no points in the window are excluded from calculations.\nIf 'neither', the first and last points in the window are excluded\nfrom calculations.\nDefault None ('right').\n"}, {"param_name": "method", "param_type": "str {‘single’, ‘table’}, default ‘single’", "param_desc": "Execute the rolling operation per single column or row ('single')\nor over the entire object ('table').\nThis argument is only implemented when specifying engine='numba'\nin the method call.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.rolling.html#pandas.core.groupby.SeriesGroupBy.rolling"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.sem", "full_function": "SeriesGroupBy.sem(ddof=1, numeric_only=False)", "function_text": "Compute standard error of the mean of groups, excluding missing values.", "parameter_names_desc": [{"param_name": "ddof", "param_type": "int, default 1", "param_desc": "Degrees of freedom.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int or boolean data.\n\nNew in version 1.5.0.\n\n\nChanged in version 2.0.0: numeric_only now defaults to False.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.sem.html#pandas.core.groupby.SeriesGroupBy.sem"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.size", "full_function": "SeriesGroupBy.size()", "function_text": "Compute group sizes.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.size.html#pandas.core.groupby.SeriesGroupBy.size"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.std", "full_function": "SeriesGroupBy.std(ddof=1, engine=None, engine_kwargs=None, numeric_only=False)", "function_text": "Compute standard deviation of groups, excluding missing values.", "parameter_names_desc": [{"param_name": "ddof", "param_type": "int, default 1", "param_desc": "Degrees of freedom.\n"}, {"param_name": "engine", "param_type": "str, default None", "param_desc": "\n'cython' : Runs the operation through C-extensions from cython.\n'numba' : Runs the operation through JIT compiled code from numba.\nNone : Defaults to 'cython' or globally setting\ncompute.use_numba\n\n\nNew in version 1.4.0.\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\nFor 'numba' engine, the engine can accept nopython, nogil\nand parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{{'nopython': True, 'nogil': False, 'parallel': False}}\n\n\nNew in version 1.4.0.\n\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int or boolean data.\n\nNew in version 1.5.0.\n\n\nChanged in version 2.0.0: numeric_only now defaults to False.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.std.html#pandas.core.groupby.SeriesGroupBy.std"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.var", "full_function": "SeriesGroupBy.var(ddof=1, engine=None, engine_kwargs=None, numeric_only=False)", "function_text": "Compute variance of groups, excluding missing values.", "parameter_names_desc": [{"param_name": "ddof", "param_type": "int, default 1", "param_desc": "Degrees of freedom.\n"}, {"param_name": "engine", "param_type": "str, default None", "param_desc": "\n'cython' : Runs the operation through C-extensions from cython.\n'numba' : Runs the operation through JIT compiled code from numba.\nNone : Defaults to 'cython' or globally setting\ncompute.use_numba\n\n\nNew in version 1.4.0.\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\nFor 'numba' engine, the engine can accept nopython, nogil\nand parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{{'nopython': True, 'nogil': False, 'parallel': False}}\n\n\nNew in version 1.4.0.\n\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int or boolean data.\n\nNew in version 1.5.0.\n\n\nChanged in version 2.0.0: numeric_only now defaults to False.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.var.html#pandas.core.groupby.SeriesGroupBy.var"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.take", "full_function": "SeriesGroupBy.take(indices, axis=_NoDefault.no_default, **kwargs)", "function_text": "Return the elements in the given positional indices in each group.", "parameter_names_desc": [{"param_name": "indices", "param_type": "array-like", "param_desc": "An array of ints indicating which positions to take in each group.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’, None}, default 0", "param_desc": "The axis on which to select elements. 0 means that we are\nselecting rows, 1 means that we are selecting columns.\nFor SeriesGroupBy this parameter is unused and defaults to 0.\n\nDeprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\nthe axis keyword is not necessary.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.take.html#pandas.core.groupby.SeriesGroupBy.take"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.any", "full_function": "SeriesGroupBy.any(skipna=True)", "function_text": "Return True if any value in the group is truthful, else False.", "parameter_names_desc": [{"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Flag to ignore nan values during truth testing.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.any.html#pandas.core.groupby.SeriesGroupBy.any"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.corr", "full_function": "SeriesGroupBy.corr(other, method='pearson', min_periods=None)", "function_text": "Compute correlation with other Series, excluding missing values.", "parameter_names_desc": [{"param_name": "other", "param_type": "Series", "param_desc": "Series with which to compute the correlation.\n"}, {"param_name": "method", "param_type": "{‘pearson’, ‘kendall’, ‘spearman’} or callable", "param_desc": "Method used to compute correlation:\n\npearson : Standard correlation coefficient\nkendall : Kendall Tau correlation coefficient\nspearman : Spearman rank correlation\ncallable: Callable with input two 1d ndarrays and returning a float.\n\n\nWarning\nNote that the returned matrix from corr will have 1 along the\ndiagonals and will be symmetric regardless of the callable’s\nbehavior.\n\n"}, {"param_name": "min_periods", "param_type": "int, optional", "param_desc": "Minimum number of observations needed to have a valid result.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.corr.html#pandas.core.groupby.SeriesGroupBy.corr"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.cov", "full_function": "SeriesGroupBy.cov(other, min_periods=None, ddof=1)", "function_text": "Compute covariance with Series, excluding missing values.", "parameter_names_desc": [{"param_name": "other", "param_type": "Series", "param_desc": "Series with which to compute the covariance.\n"}, {"param_name": "min_periods", "param_type": "int, optional", "param_desc": "Minimum number of observations needed to have a valid result.\n"}, {"param_name": "ddof", "param_type": "int, default 1", "param_desc": "Delta degrees of freedom. The divisor used in calculations\nis N - ddof, where N represents the number of elements.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cov.html#pandas.core.groupby.SeriesGroupBy.cov"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.cummax", "full_function": "SeriesGroupBy.cummax(axis=_NoDefault.no_default, numeric_only=False, **kwargs)", "function_text": "Cumulative max for each group.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cummax.html#pandas.core.groupby.SeriesGroupBy.cummax"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.cumprod", "full_function": "SeriesGroupBy.cumprod(axis=_NoDefault.no_default, *args, **kwargs)", "function_text": "Cumulative product for each group.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cumprod.html#pandas.core.groupby.SeriesGroupBy.cumprod"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.describe", "full_function": "SeriesGroupBy.describe(percentiles=None, include=None, exclude=None)", "function_text": "Generate descriptive statistics.", "parameter_names_desc": [{"param_name": "percentiles", "param_type": "list-like of numbers, optional", "param_desc": "The percentiles to include in the output. All should\nfall between 0 and 1. The default is\n[.25, .5, .75], which returns the 25th, 50th, and\n75th percentiles.\n"}, {"param_name": "include", "param_type": "‘all’, list-like of dtypes or None (default), optional", "param_desc": "A white list of data types to include in the result. Ignored\nfor Series. Here are the options:\n\n‘all’ : All columns of the input will be included in the output.\nA list-like of dtypes : Limits the results to the\nprovided data types.\nTo limit the result to numeric types submit\nnumpy.number. To limit it instead to object columns submit\nthe numpy.object data type. Strings\ncan also be used in the style of\nselect_dtypes (e.g. df.describe(include=['O'])). To\nselect pandas categorical columns, use 'category'\nNone (default) : The result will include all numeric columns.\n\n"}, {"param_name": "exclude", "param_type": "list-like of dtypes or None (default), optional,", "param_desc": "A black list of data types to omit from the result. Ignored\nfor Series. Here are the options:\n\nA list-like of dtypes : Excludes the provided data types\nfrom the result. To exclude numeric types submit\nnumpy.number. To exclude object columns submit the data\ntype numpy.object. Strings can also be used in the style of\nselect_dtypes (e.g. df.describe(exclude=['O'])). To\nexclude pandas categorical columns, use 'category'\nNone (default) : The result will exclude nothing.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.describe.html#pandas.core.groupby.SeriesGroupBy.describe"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.ffill", "full_function": "SeriesGroupBy.ffill(limit=None)", "function_text": "Forward fill the values.", "parameter_names_desc": [{"param_name": "limit", "param_type": "int, optional", "param_desc": "Limit of how many values to fill.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.ffill.html#pandas.core.groupby.SeriesGroupBy.ffill"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.first", "full_function": "SeriesGroupBy.first(numeric_only=False, min_count=-1, skipna=True)", "function_text": "Compute the first entry of each column within each group.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n"}, {"param_name": "min_count", "param_type": "int, default -1", "param_desc": "The required number of valid values to perform the operation. If fewer\nthan min_count valid values are present the result will be NA.\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA.\n\nNew in version 2.2.1.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.first.html#pandas.core.groupby.SeriesGroupBy.first"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.last", "full_function": "SeriesGroupBy.last(numeric_only=False, min_count=-1, skipna=True)", "function_text": "Compute the last entry of each column within each group.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns. If None, will attempt to use\neverything, then use only numeric data.\n"}, {"param_name": "min_count", "param_type": "int, default -1", "param_desc": "The required number of valid values to perform the operation. If fewer\nthan min_count valid values are present the result will be NA.\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA.\n\nNew in version 2.2.1.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.last.html#pandas.core.groupby.SeriesGroupBy.last"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.idxmin", "full_function": "SeriesGroupBy.idxmin(axis=_NoDefault.no_default, skipna=True)", "function_text": "Return the row label of the minimum value.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.idxmin.html#pandas.core.groupby.SeriesGroupBy.idxmin"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.is_monotonic_decreasing", "full_function": "property SeriesGroupBy.is_monotonic_decreasing", "function_text": "Return whether each group’s values are monotonically decreasing.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.is_monotonic_decreasing.html#pandas.core.groupby.SeriesGroupBy.is_monotonic_decreasing"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.mean", "full_function": "SeriesGroupBy.mean(numeric_only=False, engine=None, engine_kwargs=None)", "function_text": "Compute mean of groups, excluding missing values.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nChanged in version 2.0.0: numeric_only no longer accepts None and defaults to False.\n\n"}, {"param_name": "engine", "param_type": "str, default None", "param_desc": "\n'cython' : Runs the operation through C-extensions from cython.\n'numba' : Runs the operation through JIT compiled code from numba.\nNone : Defaults to 'cython' or globally setting\ncompute.use_numba\n\n\nNew in version 1.4.0.\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\nFor 'numba' engine, the engine can accept nopython, nogil\nand parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{{'nopython': True, 'nogil': False, 'parallel': False}}\n\n\nNew in version 1.4.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.mean.html#pandas.core.groupby.SeriesGroupBy.mean"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.min", "full_function": "SeriesGroupBy.min(numeric_only=False, min_count=-1, engine=None, engine_kwargs=None)", "function_text": "Compute min of group values.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nChanged in version 2.0.0: numeric_only no longer accepts None.\n\n"}, {"param_name": "min_count", "param_type": "int, default -1", "param_desc": "The required number of valid values to perform the operation. If fewer\nthan min_count non-NA values are present the result will be NA.\n"}, {"param_name": "engine", "param_type": "str, default None None", "param_desc": "\n'cython' : Runs rolling apply through C-extensions from cython.\n\n'numba'Runs rolling apply through JIT compiled code from numba.Only available when raw is set to True.\n\n\n\nNone : Defaults to 'cython' or globally setting compute.use_numba\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\n\nFor 'numba' engine, the engine can accept nopython, nogiland parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\napplied to both the func and the apply groupby aggregation.\n\n\n\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.min.html#pandas.core.groupby.SeriesGroupBy.min"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.nlargest", "full_function": "SeriesGroupBy.nlargest(n=5, keep='first')", "function_text": "Return the largest n elements.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, default 5", "param_desc": "Return this many descending sorted values.\n"}, {"param_name": "keep", "param_type": "{‘first’, ‘last’, ‘all’}, default ‘first’", "param_desc": "When there are duplicate values that cannot all fit in a\nSeries of n elements:\n\nfirst : return the first n occurrences in order\nof appearance.\nlast : return the last n occurrences in reverse\norder of appearance.\nall : keep all occurrences. This can result in a Series of\nsize larger than n.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.nlargest.html#pandas.core.groupby.SeriesGroupBy.nlargest"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.nth", "full_function": "property SeriesGroupBy.nth", "function_text": "Take the nth row from each group if n is an int, otherwise a subset of rows.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, slice or list of ints and slices", "param_desc": "A single nth value for the row or a list of nth values or slices.\n\nChanged in version 1.4.0: Added slice and lists containing slices.\nAdded index notation.\n\n"}, {"param_name": "dropna", "param_type": "{‘any’, ‘all’, None}, default None", "param_desc": "Apply the specified dropna operation before counting which row is\nthe nth row. Only supported if n is an int.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.nth.html#pandas.core.groupby.SeriesGroupBy.nth"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.unique", "full_function": "SeriesGroupBy.unique()", "function_text": "Return unique values for each group.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.unique.html#pandas.core.groupby.SeriesGroupBy.unique"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.pct_change", "full_function": "SeriesGroupBy.pct_change(periods=1, fill_method=_NoDefault.no_default, limit=_NoDefault.no_default, freq=None, axis=_NoDefault.no_default)", "function_text": "Calculate pct_change of each value to previous entry in group.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.pct_change.html#pandas.core.groupby.SeriesGroupBy.pct_change"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.quantile", "full_function": "SeriesGroupBy.quantile(q=0.5, interpolation='linear', numeric_only=False)", "function_text": "Return group values at the given quantile, a la numpy.percentile.", "parameter_names_desc": [{"param_name": "q", "param_type": "float or array-like, default 0.5 (50% quantile)", "param_desc": "Value(s) between 0 and 1 providing the quantile(s) to compute.\n"}, {"param_name": "interpolation", "param_type": "{‘linear’, ‘lower’, ‘higher’, ‘midpoint’, ‘nearest’}", "param_desc": "Method to use when the desired quantile falls between two points.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int or boolean data.\n\nNew in version 1.5.0.\n\n\nChanged in version 2.0.0: numeric_only now defaults to False.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.quantile.html#pandas.core.groupby.SeriesGroupBy.quantile"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.resample", "full_function": "SeriesGroupBy.resample(rule, *args, include_groups=True, **kwargs)", "function_text": "Provide resampling when using a TimeGrouper.", "parameter_names_desc": [{"param_name": "rule", "param_type": "str or DateOffset", "param_desc": "The offset string or object representing target grouper conversion.\n"}, {"param_name": "include_groups", "param_type": "bool, default True", "param_desc": "When True, will attempt to include the groupings in the operation in\nthe case that they are columns of the DataFrame. If this raises a\nTypeError, the result will be computed with the groupings excluded.\nWhen False, the groupings will be excluded when applying func.\n\nNew in version 2.2.0.\n\n\nDeprecated since version 2.2.0: Setting include_groups to True is deprecated. Only the value\nFalse will be allowed in a future version of pandas.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.resample.html#pandas.core.groupby.SeriesGroupBy.resample"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.sample", "full_function": "SeriesGroupBy.sample(n=None, frac=None, replace=False, weights=None, random_state=None)", "function_text": "Return a random sample of items from each group.", "parameter_names_desc": [{"param_name": "n", "param_type": "int, optional", "param_desc": "Number of items to return for each group. Cannot be used with\nfrac and must be no larger than the smallest group unless\nreplace is True. Default is one if frac is None.\n"}, {"param_name": "frac", "param_type": "float, optional", "param_desc": "Fraction of items to return. Cannot be used with n.\n"}, {"param_name": "replace", "param_type": "bool, default False", "param_desc": "Allow or disallow sampling of the same row more than once.\n"}, {"param_name": "weights", "param_type": "list-like, optional", "param_desc": "Default None results in equal probability weighting.\nIf passed a list-like then values must have the same length as\nthe underlying DataFrame or Series object and will be used as\nsampling probabilities after normalization within each group.\nValues must be non-negative with at least one positive element\nwithin each group.\n"}, {"param_name": "random_state", "param_type": "int, array-like, BitGenerator, np.random.RandomState, np.random.Generator, optional", "param_desc": "If int, array-like, or BitGenerator, seed for random number generator.\nIf np.random.RandomState or np.random.Generator, use as given.\n\nChanged in version 1.4.0: np.random.Generator objects now accepted\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.sample.html#pandas.core.groupby.SeriesGroupBy.sample"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.shift", "full_function": "SeriesGroupBy.shift(periods=1, freq=None, axis=_NoDefault.no_default, fill_value=_NoDefault.no_default, suffix=None)", "function_text": "Shift each group by periods observations.", "parameter_names_desc": [{"param_name": "periods", "param_type": "int | Sequence[int], default 1", "param_desc": "Number of periods to shift. If a list of values, shift each group by\neach period.\n"}, {"param_name": "freq", "param_type": "str, optional", "param_desc": "Frequency string.\n"}, {"param_name": "axis", "param_type": "axis to shift, default 0", "param_desc": "Shift direction.\n\nDeprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\nthe axis keyword is not necessary.\n\n"}, {"param_name": "fill_value", "param_type": "optional", "param_desc": "The scalar value to use for newly introduced missing values.\n\nChanged in version 2.1.0: Will raise a ValueError if freq is provided too.\n\n"}, {"param_name": "suffix", "param_type": "str, optional", "param_desc": "A string to add to each shifted column if there are multiple periods.\nIgnored otherwise.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.shift.html#pandas.core.groupby.SeriesGroupBy.shift"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.skew", "full_function": "SeriesGroupBy.skew(axis=_NoDefault.no_default, skipna=True, numeric_only=False, **kwargs)", "function_text": "Return unbiased skew within groups.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’, None}, default 0", "param_desc": "Axis for the function to be applied on.\nThis parameter is only for compatibility with DataFrame and is unused.\n\nDeprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\nthe axis keyword is not necessary.\n\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values when computing the result.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns. Not implemented for Series.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.skew.html#pandas.core.groupby.SeriesGroupBy.skew"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.sum", "full_function": "SeriesGroupBy.sum(numeric_only=False, min_count=0, engine=None, engine_kwargs=None)", "function_text": "Compute sum of group values.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nChanged in version 2.0.0: numeric_only no longer accepts None.\n\n"}, {"param_name": "min_count", "param_type": "int, default 0", "param_desc": "The required number of valid values to perform the operation. If fewer\nthan min_count non-NA values are present the result will be NA.\n"}, {"param_name": "engine", "param_type": "str, default None None", "param_desc": "\n'cython' : Runs rolling apply through C-extensions from cython.\n\n'numba'Runs rolling apply through JIT compiled code from numba.Only available when raw is set to True.\n\n\n\nNone : Defaults to 'cython' or globally setting compute.use_numba\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, default None None", "param_desc": "\nFor 'cython' engine, there are no accepted engine_kwargs\n\nFor 'numba' engine, the engine can accept nopython, nogiland parallel dictionary keys. The values must either be True or\nFalse. The default engine_kwargs for the 'numba' engine is\n{'nopython': True, 'nogil': False, 'parallel': False} and will be\napplied to both the func and the apply groupby aggregation.\n\n\n\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.sum.html#pandas.core.groupby.SeriesGroupBy.sum"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.tail", "full_function": "SeriesGroupBy.tail(n=5)", "function_text": "Return last n rows of each group.", "parameter_names_desc": [{"param_name": "n", "param_type": "int", "param_desc": "If positive: number of entries to include from end of each group.\nIf negative: number of entries to exclude from start of each group.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.tail.html#pandas.core.groupby.SeriesGroupBy.tail"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.tail", "full_function": "SeriesGroupBy.tail(n=5)", "function_text": "Return last n rows of each group.", "parameter_names_desc": [{"param_name": "n", "param_type": "int", "param_desc": "If positive: number of entries to include from end of each group.\nIf negative: number of entries to exclude from start of each group.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.tail.html#pandas.core.groupby.SeriesGroupBy.tail"}]}, {"name": "Plotting and visualization", "url": "https://pandas.pydata.org/docs/reference/groupby.html#plotting-and-visualization", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.boxplot.html#pandas.core.groupby.DataFrameGroupBy.boxplot", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.hist.html#pandas.core.groupby.SeriesGroupBy.hist", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.plot.html#pandas.core.groupby.SeriesGroupBy.plot", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.hist.html#pandas.core.groupby.DataFrameGroupBy.hist", "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.plot.html#pandas.core.groupby.DataFrameGroupBy.plot"], "function_definitions": [{"function_name": "pandas.core.groupby.DataFrameGroupBy.boxplot", "full_function": "DataFrameGroupBy.boxplot(subplots=True, column=None, fontsize=None, rot=0, grid=True, ax=None, figsize=None, layout=None, sharex=False, sharey=True, backend=None, **kwargs)", "function_text": "Make box plots from DataFrameGroupBy data.", "parameter_names_desc": [{"param_name": "grouped", "param_type": "Grouped DataFrame", "param_desc": ""}, {"param_name": "subplots", "param_type": "bool", "param_desc": "\nFalse - no subplots will be used\nTrue - create a subplot for each group.\n\n"}, {"param_name": "column", "param_type": "column name or list of names, or vector", "param_desc": "Can be any valid input to groupby.\n"}, {"param_name": "fontsize", "param_type": "float or str", "param_desc": ""}, {"param_name": "rot", "param_type": "label rotation angle", "param_desc": ""}, {"param_name": "grid", "param_type": "Setting this to True will show the grid", "param_desc": ""}, {"param_name": "ax", "param_type": "Matplotlib axis object, default None", "param_desc": ""}, {"param_name": "figsize", "param_type": "A tuple (width, height) in inches", "param_desc": ""}, {"param_name": "layout", "param_type": "tuple (optional)", "param_desc": "The layout of the plot: (rows, columns).\n"}, {"param_name": "sharex", "param_type": "bool, default False", "param_desc": "Whether x-axes will be shared among subplots.\n"}, {"param_name": "sharey", "param_type": "bool, default True", "param_desc": "Whether y-axes will be shared among subplots.\n"}, {"param_name": "backend", "param_type": "str, default None", "param_desc": "Backend to use instead of the backend specified in the option\nplotting.backend. For instance, ‘matplotlib’. Alternatively, to\nspecify the plotting.backend for the whole session, set\npd.options.plotting.backend.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.boxplot.html#pandas.core.groupby.DataFrameGroupBy.boxplot"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.hist", "full_function": "SeriesGroupBy.hist(by=None, ax=None, grid=True, xlabelsize=None, xrot=None, ylabelsize=None, yrot=None, figsize=None, bins=10, backend=None, legend=False, **kwargs)", "function_text": "Draw histogram of the input series using matplotlib.", "parameter_names_desc": [{"param_name": "by", "param_type": "object, optional", "param_desc": "If passed, then used to form histograms for separate groups.\n"}, {"param_name": "ax", "param_type": "matplotlib axis object", "param_desc": "If not passed, uses gca().\n"}, {"param_name": "grid", "param_type": "bool, default True", "param_desc": "Whether to show axis grid lines.\n"}, {"param_name": "xlabelsize", "param_type": "int, default None", "param_desc": "If specified changes the x-axis label size.\n"}, {"param_name": "xrot", "param_type": "float, default None", "param_desc": "Rotation of x axis labels.\n"}, {"param_name": "ylabelsize", "param_type": "int, default None", "param_desc": "If specified changes the y-axis label size.\n"}, {"param_name": "yrot", "param_type": "float, default None", "param_desc": "Rotation of y axis labels.\n"}, {"param_name": "figsize", "param_type": "tuple, default None", "param_desc": "Figure size in inches by default.\n"}, {"param_name": "bins", "param_type": "int or sequence, default 10", "param_desc": "Number of histogram bins to be used. If an integer is given, bins + 1\nbin edges are calculated and returned. If bins is a sequence, gives\nbin edges, including left edge of first bin and right edge of last\nbin. In this case, bins is returned unmodified.\n"}, {"param_name": "backend", "param_type": "str, default None", "param_desc": "Backend to use instead of the backend specified in the option\nplotting.backend. For instance, ‘matplotlib’. Alternatively, to\nspecify the plotting.backend for the whole session, set\npd.options.plotting.backend.\n"}, {"param_name": "legend", "param_type": "bool, default False", "param_desc": "Whether to show the legend.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.hist.html#pandas.core.groupby.SeriesGroupBy.hist"}, {"function_name": "pandas.core.groupby.SeriesGroupBy.plot", "full_function": "property SeriesGroupBy.plot", "function_text": "Make plots of Series or DataFrame.", "parameter_names_desc": [{"param_name": "data", "param_type": "Series or DataFrame", "param_desc": "The object for which the method is called.\n"}, {"param_name": "x", "param_type": "label or position, default None", "param_desc": "Only used if data is a DataFrame.\n"}, {"param_name": "y", "param_type": "label, position or list of label, positions, default None", "param_desc": "Allows plotting of one column versus another. Only used if data is a\nDataFrame.\n"}, {"param_name": "kind", "param_type": "str", "param_desc": "The kind of plot to produce:\n\n‘line’ : line plot (default)\n‘bar’ : vertical bar plot\n‘barh’ : horizontal bar plot\n‘hist’ : histogram\n‘box’ : boxplot\n‘kde’ : Kernel Density Estimation plot\n‘density’ : same as ‘kde’\n‘area’ : area plot\n‘pie’ : pie plot\n‘scatter’ : scatter plot (DataFrame only)\n‘hexbin’ : hexbin plot (DataFrame only)\n\n"}, {"param_name": "ax", "param_type": "matplotlib axes object, default None", "param_desc": "An axes of the current figure.\n"}, {"param_name": "subplots", "param_type": "bool or sequence of iterables, default False", "param_desc": "Whether to group columns into subplots:\n\nFalse : No subplots will be used\nTrue : Make separate subplots for each column.\nsequence of iterables of column labels: Create a subplot for each\ngroup of columns. For example [(‘a’, ‘c’), (‘b’, ‘d’)] will\ncreate 2 subplots: one with columns ‘a’ and ‘c’, and one\nwith columns ‘b’ and ‘d’. Remaining columns that aren’t specified\nwill be plotted in additional subplots (one per column).\n\nNew in version 1.5.0.\n\n\n\n"}, {"param_name": "sharex", "param_type": "bool, default True if ax is None else False", "param_desc": "In case subplots=True, share x axis and set some x axis labels\nto invisible; defaults to True if ax is None otherwise False if\nan ax is passed in; Be aware, that passing in both an ax and\nsharex=True will alter all x axis labels for all axis in a figure.\n"}, {"param_name": "sharey", "param_type": "bool, default False", "param_desc": "In case subplots=True, share y axis and set some y axis labels to invisible.\n"}, {"param_name": "layout", "param_type": "tuple, optional", "param_desc": "(rows, columns) for the layout of subplots.\n"}, {"param_name": "figsize", "param_type": "a tuple (width, height) in inches", "param_desc": "Size of a figure object.\n"}, {"param_name": "use_index", "param_type": "bool, default True", "param_desc": "Use index as ticks for x axis.\n"}, {"param_name": "title", "param_type": "str or list", "param_desc": "Title to use for the plot. If a string is passed, print the string\nat the top of the figure. If a list is passed and subplots is\nTrue, print each item in the list above the corresponding subplot.\n"}, {"param_name": "grid", "param_type": "bool, default None (matlab style default)", "param_desc": "Axis grid lines.\n"}, {"param_name": "legend", "param_type": "bool or {‘reverse’}", "param_desc": "Place legend on axis subplots.\n"}, {"param_name": "style", "param_type": "list or dict", "param_desc": "The matplotlib line style per column.\n"}, {"param_name": "logx", "param_type": "bool or ‘sym’, default False", "param_desc": "Use log scaling or symlog scaling on x axis.\n"}, {"param_name": "logy", "param_type": "bool or ‘sym’ default False", "param_desc": "Use log scaling or symlog scaling on y axis.\n"}, {"param_name": "loglog", "param_type": "bool or ‘sym’, default False", "param_desc": "Use log scaling or symlog scaling on both x and y axes.\n"}, {"param_name": "xticks", "param_type": "sequence", "param_desc": "Values to use for the xticks.\n"}, {"param_name": "yticks", "param_type": "sequence", "param_desc": "Values to use for the yticks.\n"}, {"param_name": "xlim", "param_type": "2-tuple/list", "param_desc": "Set the x limits of the current axes.\n"}, {"param_name": "ylim", "param_type": "2-tuple/list", "param_desc": "Set the y limits of the current axes.\n"}, {"param_name": "xlabel", "param_type": "label, optional", "param_desc": "Name to use for the xlabel on x-axis. Default uses index name as xlabel, or the\nx-column name for planar plots.\n\nChanged in version 2.0.0: Now applicable to histograms.\n\n"}, {"param_name": "ylabel", "param_type": "label, optional", "param_desc": "Name to use for the ylabel on y-axis. Default will show no ylabel, or the\ny-column name for planar plots.\n\nChanged in version 2.0.0: Now applicable to histograms.\n\n"}, {"param_name": "rot", "param_type": "float, default None", "param_desc": "Rotation for ticks (xticks for vertical, yticks for horizontal\nplots).\n"}, {"param_name": "fontsize", "param_type": "float, default None", "param_desc": "Font size for xticks and yticks.\n"}, {"param_name": "colormap", "param_type": "str or matplotlib colormap object, default None", "param_desc": "Colormap to select colors from. If string, load colormap with that\nname from matplotlib.\n"}, {"param_name": "colorbar", "param_type": "bool, optional", "param_desc": "If True, plot colorbar (only relevant for ‘scatter’ and ‘hexbin’\nplots).\n"}, {"param_name": "position", "param_type": "float", "param_desc": "Specify relative alignments for bar plot layout.\nFrom 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\n(center).\n"}, {"param_name": "table", "param_type": "bool, Series or DataFrame, default False", "param_desc": "If True, draw a table using the data in the DataFrame and the data\nwill be transposed to meet matplotlib’s default layout.\nIf a Series or DataFrame is passed, use passed data to draw a\ntable.\n"}, {"param_name": "yerr", "param_type": "DataFrame, Series, array-like, dict and str", "param_desc": "See Plotting with Error Bars for\ndetail.\n"}, {"param_name": "xerr", "param_type": "DataFrame, Series, array-like, dict and str", "param_desc": "Equivalent to yerr.\n"}, {"param_name": "stacked", "param_type": "bool, default False in line and bar plots, and True in area plot", "param_desc": "If True, create stacked plot.\n"}, {"param_name": "secondary_y", "param_type": "bool or sequence, default False", "param_desc": "Whether to plot on the secondary y-axis if a list/tuple, which\ncolumns to plot on secondary y-axis.\n"}, {"param_name": "mark_right", "param_type": "bool, default True", "param_desc": "When using a secondary_y axis, automatically mark the column\nlabels with “(right)” in the legend.\n"}, {"param_name": "include_bool", "param_type": "bool, default is False", "param_desc": "If True, boolean values can be plotted.\n"}, {"param_name": "backend", "param_type": "str, default None", "param_desc": "Backend to use instead of the backend specified in the option\nplotting.backend. For instance, ‘matplotlib’. Alternatively, to\nspecify the plotting.backend for the whole session, set\npd.options.plotting.backend.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.plot.html#pandas.core.groupby.SeriesGroupBy.plot"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.hist", "full_function": "DataFrameGroupBy.hist(column=None, by=None, grid=True, xlabelsize=None, xrot=None, ylabelsize=None, yrot=None, ax=None, sharex=False, sharey=False, figsize=None, layout=None, bins=10, backend=None, legend=False, **kwargs)", "function_text": "Make a histogram of the DataFrame’s columns.", "parameter_names_desc": [{"param_name": "data", "param_type": "DataFrame", "param_desc": "The pandas object holding the data.\n"}, {"param_name": "column", "param_type": "str or sequence, optional", "param_desc": "If passed, will be used to limit data to a subset of columns.\n"}, {"param_name": "by", "param_type": "object, optional", "param_desc": "If passed, then used to form histograms for separate groups.\n"}, {"param_name": "grid", "param_type": "bool, default True", "param_desc": "Whether to show axis grid lines.\n"}, {"param_name": "xlabelsize", "param_type": "int, default None", "param_desc": "If specified changes the x-axis label size.\n"}, {"param_name": "xrot", "param_type": "float, default None", "param_desc": "Rotation of x axis labels. For example, a value of 90 displays the\nx labels rotated 90 degrees clockwise.\n"}, {"param_name": "ylabelsize", "param_type": "int, default None", "param_desc": "If specified changes the y-axis label size.\n"}, {"param_name": "yrot", "param_type": "float, default None", "param_desc": "Rotation of y axis labels. For example, a value of 90 displays the\ny labels rotated 90 degrees clockwise.\n"}, {"param_name": "ax", "param_type": "Matplotlib axes object, default None", "param_desc": "The axes to plot the histogram on.\n"}, {"param_name": "sharex", "param_type": "bool, default True if ax is None else False", "param_desc": "In case subplots=True, share x axis and set some x axis labels to\ninvisible; defaults to True if ax is None otherwise False if an ax\nis passed in.\nNote that passing in both an ax and sharex=True will alter all x axis\nlabels for all subplots in a figure.\n"}, {"param_name": "sharey", "param_type": "bool, default False", "param_desc": "In case subplots=True, share y axis and set some y axis labels to\ninvisible.\n"}, {"param_name": "figsize", "param_type": "tuple, optional", "param_desc": "The size in inches of the figure to create. Uses the value in\nmatplotlib.rcParams by default.\n"}, {"param_name": "layout", "param_type": "tuple, optional", "param_desc": "Tuple of (rows, columns) for the layout of the histograms.\n"}, {"param_name": "bins", "param_type": "int or sequence, default 10", "param_desc": "Number of histogram bins to be used. If an integer is given, bins + 1\nbin edges are calculated and returned. If bins is a sequence, gives\nbin edges, including left edge of first bin and right edge of last\nbin. In this case, bins is returned unmodified.\n"}, {"param_name": "backend", "param_type": "str, default None", "param_desc": "Backend to use instead of the backend specified in the option\nplotting.backend. For instance, ‘matplotlib’. Alternatively, to\nspecify the plotting.backend for the whole session, set\npd.options.plotting.backend.\n"}, {"param_name": "legend", "param_type": "bool, default False", "param_desc": "Whether to show the legend.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.hist.html#pandas.core.groupby.DataFrameGroupBy.hist"}, {"function_name": "pandas.core.groupby.DataFrameGroupBy.plot", "full_function": "property DataFrameGroupBy.plot", "function_text": "Make plots of Series or DataFrame.", "parameter_names_desc": [{"param_name": "data", "param_type": "Series or DataFrame", "param_desc": "The object for which the method is called.\n"}, {"param_name": "x", "param_type": "label or position, default None", "param_desc": "Only used if data is a DataFrame.\n"}, {"param_name": "y", "param_type": "label, position or list of label, positions, default None", "param_desc": "Allows plotting of one column versus another. Only used if data is a\nDataFrame.\n"}, {"param_name": "kind", "param_type": "str", "param_desc": "The kind of plot to produce:\n\n‘line’ : line plot (default)\n‘bar’ : vertical bar plot\n‘barh’ : horizontal bar plot\n‘hist’ : histogram\n‘box’ : boxplot\n‘kde’ : Kernel Density Estimation plot\n‘density’ : same as ‘kde’\n‘area’ : area plot\n‘pie’ : pie plot\n‘scatter’ : scatter plot (DataFrame only)\n‘hexbin’ : hexbin plot (DataFrame only)\n\n"}, {"param_name": "ax", "param_type": "matplotlib axes object, default None", "param_desc": "An axes of the current figure.\n"}, {"param_name": "subplots", "param_type": "bool or sequence of iterables, default False", "param_desc": "Whether to group columns into subplots:\n\nFalse : No subplots will be used\nTrue : Make separate subplots for each column.\nsequence of iterables of column labels: Create a subplot for each\ngroup of columns. For example [(‘a’, ‘c’), (‘b’, ‘d’)] will\ncreate 2 subplots: one with columns ‘a’ and ‘c’, and one\nwith columns ‘b’ and ‘d’. Remaining columns that aren’t specified\nwill be plotted in additional subplots (one per column).\n\nNew in version 1.5.0.\n\n\n\n"}, {"param_name": "sharex", "param_type": "bool, default True if ax is None else False", "param_desc": "In case subplots=True, share x axis and set some x axis labels\nto invisible; defaults to True if ax is None otherwise False if\nan ax is passed in; Be aware, that passing in both an ax and\nsharex=True will alter all x axis labels for all axis in a figure.\n"}, {"param_name": "sharey", "param_type": "bool, default False", "param_desc": "In case subplots=True, share y axis and set some y axis labels to invisible.\n"}, {"param_name": "layout", "param_type": "tuple, optional", "param_desc": "(rows, columns) for the layout of subplots.\n"}, {"param_name": "figsize", "param_type": "a tuple (width, height) in inches", "param_desc": "Size of a figure object.\n"}, {"param_name": "use_index", "param_type": "bool, default True", "param_desc": "Use index as ticks for x axis.\n"}, {"param_name": "title", "param_type": "str or list", "param_desc": "Title to use for the plot. If a string is passed, print the string\nat the top of the figure. If a list is passed and subplots is\nTrue, print each item in the list above the corresponding subplot.\n"}, {"param_name": "grid", "param_type": "bool, default None (matlab style default)", "param_desc": "Axis grid lines.\n"}, {"param_name": "legend", "param_type": "bool or {‘reverse’}", "param_desc": "Place legend on axis subplots.\n"}, {"param_name": "style", "param_type": "list or dict", "param_desc": "The matplotlib line style per column.\n"}, {"param_name": "logx", "param_type": "bool or ‘sym’, default False", "param_desc": "Use log scaling or symlog scaling on x axis.\n"}, {"param_name": "logy", "param_type": "bool or ‘sym’ default False", "param_desc": "Use log scaling or symlog scaling on y axis.\n"}, {"param_name": "loglog", "param_type": "bool or ‘sym’, default False", "param_desc": "Use log scaling or symlog scaling on both x and y axes.\n"}, {"param_name": "xticks", "param_type": "sequence", "param_desc": "Values to use for the xticks.\n"}, {"param_name": "yticks", "param_type": "sequence", "param_desc": "Values to use for the yticks.\n"}, {"param_name": "xlim", "param_type": "2-tuple/list", "param_desc": "Set the x limits of the current axes.\n"}, {"param_name": "ylim", "param_type": "2-tuple/list", "param_desc": "Set the y limits of the current axes.\n"}, {"param_name": "xlabel", "param_type": "label, optional", "param_desc": "Name to use for the xlabel on x-axis. Default uses index name as xlabel, or the\nx-column name for planar plots.\n\nChanged in version 2.0.0: Now applicable to histograms.\n\n"}, {"param_name": "ylabel", "param_type": "label, optional", "param_desc": "Name to use for the ylabel on y-axis. Default will show no ylabel, or the\ny-column name for planar plots.\n\nChanged in version 2.0.0: Now applicable to histograms.\n\n"}, {"param_name": "rot", "param_type": "float, default None", "param_desc": "Rotation for ticks (xticks for vertical, yticks for horizontal\nplots).\n"}, {"param_name": "fontsize", "param_type": "float, default None", "param_desc": "Font size for xticks and yticks.\n"}, {"param_name": "colormap", "param_type": "str or matplotlib colormap object, default None", "param_desc": "Colormap to select colors from. If string, load colormap with that\nname from matplotlib.\n"}, {"param_name": "colorbar", "param_type": "bool, optional", "param_desc": "If True, plot colorbar (only relevant for ‘scatter’ and ‘hexbin’\nplots).\n"}, {"param_name": "position", "param_type": "float", "param_desc": "Specify relative alignments for bar plot layout.\nFrom 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\n(center).\n"}, {"param_name": "table", "param_type": "bool, Series or DataFrame, default False", "param_desc": "If True, draw a table using the data in the DataFrame and the data\nwill be transposed to meet matplotlib’s default layout.\nIf a Series or DataFrame is passed, use passed data to draw a\ntable.\n"}, {"param_name": "yerr", "param_type": "DataFrame, Series, array-like, dict and str", "param_desc": "See Plotting with Error Bars for\ndetail.\n"}, {"param_name": "xerr", "param_type": "DataFrame, Series, array-like, dict and str", "param_desc": "Equivalent to yerr.\n"}, {"param_name": "stacked", "param_type": "bool, default False in line and bar plots, and True in area plot", "param_desc": "If True, create stacked plot.\n"}, {"param_name": "secondary_y", "param_type": "bool or sequence, default False", "param_desc": "Whether to plot on the secondary y-axis if a list/tuple, which\ncolumns to plot on secondary y-axis.\n"}, {"param_name": "mark_right", "param_type": "bool, default True", "param_desc": "When using a secondary_y axis, automatically mark the column\nlabels with “(right)” in the legend.\n"}, {"param_name": "include_bool", "param_type": "bool, default is False", "param_desc": "If True, boolean values can be plotted.\n"}, {"param_name": "backend", "param_type": "str, default None", "param_desc": "Backend to use instead of the backend specified in the option\nplotting.backend. For instance, ‘matplotlib’. Alternatively, to\nspecify the plotting.backend for the whole session, set\npd.options.plotting.backend.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.plot.html#pandas.core.groupby.DataFrameGroupBy.plot"}]}], "name": "GroupBy", "url": "https://pandas.pydata.org/docs/reference/groupby.html"}, "resampling.html": {"functions": [{"name": "Indexing, iteration", "url": "https://pandas.pydata.org/docs/reference/resampling.html#indexing-iteration", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.__iter__.html#pandas.core.resample.Resampler.__iter__", "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.indices.html#pandas.core.resample.Resampler.indices", "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.groups.html#pandas.core.resample.Resampler.groups", "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.get_group.html#pandas.core.resample.Resampler.get_group"], "function_definitions": [{"function_name": "pandas.core.resample.Resampler.__iter__", "full_function": "Resampler.__iter__()", "function_text": "Groupby iterator.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.__iter__.html#pandas.core.resample.Resampler.__iter__"}, {"function_name": "pandas.core.resample.Resampler.indices", "full_function": "property Resampler.indices", "function_text": "Dict {group name -> group indices}.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.indices.html#pandas.core.resample.Resampler.indices"}, {"function_name": "pandas.core.resample.Resampler.groups", "full_function": "property Resampler.groups", "function_text": "Dict {group name -> group labels}.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.groups.html#pandas.core.resample.Resampler.groups"}, {"function_name": "pandas.core.resample.Resampler.get_group", "full_function": "Resampler.get_group(name, obj=None)", "function_text": "Construct DataFrame from group with provided name.", "parameter_names_desc": [{"param_name": "name", "param_type": "object", "param_desc": "The name of the group to get as a DataFrame.\n"}, {"param_name": "obj", "param_type": "DataFrame, default None", "param_desc": "The DataFrame to take the DataFrame out of. If\nit is None, the object groupby was called on will\nbe used.\n\nDeprecated since version 2.1.0: The obj is deprecated and will be removed in a future version.\nDo df.iloc[gb.indices.get(name)]\ninstead of gb.get_group(name, obj=df).\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.get_group.html#pandas.core.resample.Resampler.get_group"}]}, {"name": "Function application", "url": "https://pandas.pydata.org/docs/reference/resampling.html#function-application", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.apply.html#pandas.core.resample.Resampler.apply", "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.transform.html#pandas.core.resample.Resampler.transform", "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.aggregate.html#pandas.core.resample.Resampler.aggregate", "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.pipe.html#pandas.core.resample.Resampler.pipe"], "function_definitions": [{"function_name": "pandas.core.resample.Resampler.apply", "full_function": "Resampler.apply(func=None, *args, **kwargs)", "function_text": "Aggregate using one or more operations over the specified axis.", "parameter_names_desc": [{"param_name": "func", "param_type": "function, str, list or dict", "param_desc": "Function to use for aggregating the data. If a function, must either\nwork when passed a DataFrame or when passed to DataFrame.apply.\nAccepted combinations are:\n\nfunction\nstring function name\nlist of functions and/or function names, e.g. [np.sum, 'mean']\ndict of axis labels -> functions, function names or list of such.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.apply.html#pandas.core.resample.Resampler.apply"}, {"function_name": "pandas.core.resample.Resampler.transform", "full_function": "final Resampler.transform(arg, *args, **kwargs)", "function_text": "Call function producing a like-indexed Series on each group.", "parameter_names_desc": [{"param_name": "arg", "param_type": "function", "param_desc": "To apply to each group. Should return a Series with the same index.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.transform.html#pandas.core.resample.Resampler.transform"}, {"function_name": "pandas.core.resample.Resampler.aggregate", "full_function": "final Resampler.aggregate(func=None, *args, **kwargs)", "function_text": "Aggregate using one or more operations over the specified axis.", "parameter_names_desc": [{"param_name": "func", "param_type": "function, str, list or dict", "param_desc": "Function to use for aggregating the data. If a function, must either\nwork when passed a DataFrame or when passed to DataFrame.apply.\nAccepted combinations are:\n\nfunction\nstring function name\nlist of functions and/or function names, e.g. [np.sum, 'mean']\ndict of axis labels -> functions, function names or list of such.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.aggregate.html#pandas.core.resample.Resampler.aggregate"}, {"function_name": "pandas.core.resample.Resampler.pipe", "full_function": "final Resampler.pipe(func, *args, **kwargs)", "function_text": "Apply a func with arguments to this Resampler object and return its result.", "parameter_names_desc": [{"param_name": "func", "param_type": "callable or tuple of (callable, str)", "param_desc": "Function to apply to this Resampler object or, alternatively,\na (callable, data_keyword) tuple where data_keyword is a\nstring indicating the keyword of callable that expects the\nResampler object.\n"}, {"param_name": "args", "param_type": "iterable, optional", "param_desc": "Positional arguments passed into func.\n"}, {"param_name": "kwargs", "param_type": "dict, optional", "param_desc": "A dictionary of keyword arguments passed into func.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.pipe.html#pandas.core.resample.Resampler.pipe"}]}, {"name": "Upsampling", "url": "https://pandas.pydata.org/docs/reference/resampling.html#upsampling", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.ffill.html#pandas.core.resample.Resampler.ffill", "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.nearest.html#pandas.core.resample.Resampler.nearest", "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.asfreq.html#pandas.core.resample.Resampler.asfreq", "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.bfill.html#pandas.core.resample.Resampler.bfill", "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.fillna.html#pandas.core.resample.Resampler.fillna", "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.interpolate.html#pandas.core.resample.Resampler.interpolate"], "function_definitions": [{"function_name": "pandas.core.resample.Resampler.ffill", "full_function": "final Resampler.ffill(limit=None)", "function_text": "Forward fill the values.", "parameter_names_desc": [{"param_name": "limit", "param_type": "int, optional", "param_desc": "Limit of how many values to fill.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.ffill.html#pandas.core.resample.Resampler.ffill"}, {"function_name": "pandas.core.resample.Resampler.nearest", "full_function": "final Resampler.nearest(limit=None)", "function_text": "Resample by using the nearest value.", "parameter_names_desc": [{"param_name": "limit", "param_type": "int, optional", "param_desc": "Limit of how many values to fill.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.nearest.html#pandas.core.resample.Resampler.nearest"}, {"function_name": "pandas.core.resample.Resampler.asfreq", "full_function": "final Resampler.asfreq(fill_value=None)", "function_text": "Return the values at the new freq, essentially a reindex.", "parameter_names_desc": [{"param_name": "fill_value", "param_type": "scalar, optional", "param_desc": "Value to use for missing values, applied during upsampling (note\nthis does not fill NaNs that already were present).\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.asfreq.html#pandas.core.resample.Resampler.asfreq"}, {"function_name": "pandas.core.resample.Resampler.bfill", "full_function": "final Resampler.bfill(limit=None)", "function_text": "Backward fill the new missing values in the resampled data.", "parameter_names_desc": [{"param_name": "limit", "param_type": "int, optional", "param_desc": "Limit of how many values to fill.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.bfill.html#pandas.core.resample.Resampler.bfill"}, {"function_name": "pandas.core.resample.Resampler.fillna", "full_function": "final Resampler.fillna(method, limit=None)", "function_text": "Fill missing values introduced by upsampling.", "parameter_names_desc": [{"param_name": "method", "param_type": "{‘pad’, ‘backfill’, ‘ffill’, ‘bfill’, ‘nearest’}", "param_desc": "Method to use for filling holes in resampled data\n\n‘pad’ or ‘ffill’: use previous valid observation to fill gap\n(forward fill).\n‘backfill’ or ‘bfill’: use next valid observation to fill gap.\n‘nearest’: use nearest valid observation to fill gap.\n\n"}, {"param_name": "limit", "param_type": "int, optional", "param_desc": "Limit of how many consecutive missing values to fill.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.fillna.html#pandas.core.resample.Resampler.fillna"}, {"function_name": "pandas.core.resample.Resampler.interpolate", "full_function": "final Resampler.interpolate(method='linear', *, axis=0, limit=None, inplace=False, limit_direction='forward', limit_area=None, downcast=_NoDefault.no_default, **kwargs)", "function_text": "Interpolate values between target timestamps according to different methods.", "parameter_names_desc": [{"param_name": "method", "param_type": "str, default ‘linear’", "param_desc": "Interpolation technique to use. One of:\n\n‘linear’: Ignore the index and treat the values as equally\nspaced. This is the only method supported on MultiIndexes.\n‘time’: Works on daily and higher resolution data to interpolate\ngiven length of interval.\n‘index’, ‘values’: use the actual numerical values of the index.\n‘pad’: Fill in NaNs using existing values.\n‘nearest’, ‘zero’, ‘slinear’, ‘quadratic’, ‘cubic’,\n‘barycentric’, ‘polynomial’: Passed to\nscipy.interpolate.interp1d, whereas ‘spline’ is passed to\nscipy.interpolate.UnivariateSpline. These methods use the numerical\nvalues of the index. Both ‘polynomial’ and ‘spline’ require that\nyou also specify an order (int), e.g.\ndf.interpolate(method='polynomial', order=5). Note that,\nslinear method in Pandas refers to the Scipy first order spline\ninstead of Pandas first order spline.\n‘krogh’, ‘piecewise_polynomial’, ‘spline’, ‘pchip’, ‘akima’,\n‘cubicspline’: Wrappers around the SciPy interpolation methods of\nsimilar names. See Notes.\n‘from_derivatives’: Refers to\nscipy.interpolate.BPoly.from_derivatives.\n\n"}, {"param_name": "axis", "param_type": "{{0 or ‘index’, 1 or ‘columns’, None}}, default None", "param_desc": "Axis to interpolate along. For Series this parameter is unused\nand defaults to 0.\n"}, {"param_name": "limit", "param_type": "int, optional", "param_desc": "Maximum number of consecutive NaNs to fill. Must be greater than\n0.\n"}, {"param_name": "inplace", "param_type": "bool, default False", "param_desc": "Update the data in place if possible.\n"}, {"param_name": "limit_direction", "param_type": "{{‘forward’, ‘backward’, ‘both’}}, Optional", "param_desc": "Consecutive NaNs will be filled in this direction.\n\nIf limit is specified:\nIf ‘method’ is ‘pad’ or ‘ffill’, ‘limit_direction’ must be ‘forward’.\nIf ‘method’ is ‘backfill’ or ‘bfill’, ‘limit_direction’ must be\n‘backwards’.\n\n\nIf ‘limit’ is not specified:\nIf ‘method’ is ‘backfill’ or ‘bfill’, the default is ‘backward’\nelse the default is ‘forward’\n\n\nraises ValueError if limit_direction is ‘forward’ or ‘both’ andmethod is ‘backfill’ or ‘bfill’.\n\nraises ValueError if limit_direction is ‘backward’ or ‘both’ andmethod is ‘pad’ or ‘ffill’.\n\n\n\n\n"}, {"param_name": "limit_area", "param_type": "{{None, ‘inside’, ‘outside’}}, default None", "param_desc": "If limit is specified, consecutive NaNs will be filled with this\nrestriction.\n\nNone: No fill restriction.\n‘inside’: Only fill NaNs surrounded by valid values\n(interpolate).\n‘outside’: Only fill NaNs outside valid values (extrapolate).\n\n"}, {"param_name": "downcast", "param_type": "optional, ‘infer’ or None, defaults to None", "param_desc": "Downcast dtypes if possible.\n\nDeprecated since version 2.1.0.\n\n"}, {"param_name": "``**kwargs``", "param_type": "optional", "param_desc": "Keyword arguments to pass on to the interpolating function.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.interpolate.html#pandas.core.resample.Resampler.interpolate"}]}, {"name": "Computations / descriptive stats", "url": "https://pandas.pydata.org/docs/reference/resampling.html#computations-descriptive-stats", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.count.html#pandas.core.resample.Resampler.count", "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.first.html#pandas.core.resample.Resampler.first", "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.max.html#pandas.core.resample.Resampler.max", "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.median.html#pandas.core.resample.Resampler.median", "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.ohlc.html#pandas.core.resample.Resampler.ohlc", "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.size.html#pandas.core.resample.Resampler.size", "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.std.html#pandas.core.resample.Resampler.std", "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.var.html#pandas.core.resample.Resampler.var", "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.nunique.html#pandas.core.resample.Resampler.nunique", "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.last.html#pandas.core.resample.Resampler.last", "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.mean.html#pandas.core.resample.Resampler.mean", "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.min.html#pandas.core.resample.Resampler.min", "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.prod.html#pandas.core.resample.Resampler.prod", "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.sem.html#pandas.core.resample.Resampler.sem", "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.sum.html#pandas.core.resample.Resampler.sum", "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.quantile.html#pandas.core.resample.Resampler.quantile"], "function_definitions": [{"function_name": "pandas.core.resample.Resampler.count", "full_function": "final Resampler.count()", "function_text": "Compute count of group, excluding missing values.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.count.html#pandas.core.resample.Resampler.count"}, {"function_name": "pandas.core.resample.Resampler.first", "full_function": "final Resampler.first(numeric_only=False, min_count=0, skipna=True, *args, **kwargs)", "function_text": "Compute the first entry of each column within each group.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n"}, {"param_name": "min_count", "param_type": "int, default -1", "param_desc": "The required number of valid values to perform the operation. If fewer\nthan min_count valid values are present the result will be NA.\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA.\n\nNew in version 2.2.1.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.first.html#pandas.core.resample.Resampler.first"}, {"function_name": "pandas.core.resample.Resampler.max", "full_function": "final Resampler.max(numeric_only=False, min_count=0, *args, **kwargs)", "function_text": "Compute max value of group.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.max.html#pandas.core.resample.Resampler.max"}, {"function_name": "pandas.core.resample.Resampler.median", "full_function": "final Resampler.median(numeric_only=False, *args, **kwargs)", "function_text": "Compute median of groups, excluding missing values.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nChanged in version 2.0.0: numeric_only no longer accepts None and defaults to False.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.median.html#pandas.core.resample.Resampler.median"}, {"function_name": "pandas.core.resample.Resampler.ohlc", "full_function": "final Resampler.ohlc(*args, **kwargs)", "function_text": "Compute open, high, low and close values of a group, excluding missing values.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.ohlc.html#pandas.core.resample.Resampler.ohlc"}, {"function_name": "pandas.core.resample.Resampler.size", "full_function": "final Resampler.size()", "function_text": "Compute group sizes.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.size.html#pandas.core.resample.Resampler.size"}, {"function_name": "pandas.core.resample.Resampler.std", "full_function": "final Resampler.std(ddof=1, numeric_only=False, *args, **kwargs)", "function_text": "Compute standard deviation of groups, excluding missing values.", "parameter_names_desc": [{"param_name": "ddof", "param_type": "int, default 1", "param_desc": "Degrees of freedom.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int or boolean data.\n\nNew in version 1.5.0.\n\n\nChanged in version 2.0.0: numeric_only now defaults to False.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.std.html#pandas.core.resample.Resampler.std"}, {"function_name": "pandas.core.resample.Resampler.var", "full_function": "final Resampler.var(ddof=1, numeric_only=False, *args, **kwargs)", "function_text": "Compute variance of groups, excluding missing values.", "parameter_names_desc": [{"param_name": "ddof", "param_type": "int, default 1", "param_desc": "Degrees of freedom.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int or boolean data.\n\nNew in version 1.5.0.\n\n\nChanged in version 2.0.0: numeric_only now defaults to False.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.var.html#pandas.core.resample.Resampler.var"}, {"function_name": "pandas.core.resample.Resampler.nunique", "full_function": "final Resampler.nunique(*args, **kwargs)", "function_text": "Return number of unique elements in the group.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.nunique.html#pandas.core.resample.Resampler.nunique"}, {"function_name": "pandas.core.resample.Resampler.last", "full_function": "final Resampler.last(numeric_only=False, min_count=0, skipna=True, *args, **kwargs)", "function_text": "Compute the last entry of each column within each group.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns. If None, will attempt to use\neverything, then use only numeric data.\n"}, {"param_name": "min_count", "param_type": "int, default -1", "param_desc": "The required number of valid values to perform the operation. If fewer\nthan min_count valid values are present the result will be NA.\n"}, {"param_name": "skipna", "param_type": "bool, default True", "param_desc": "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA.\n\nNew in version 2.2.1.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.last.html#pandas.core.resample.Resampler.last"}, {"function_name": "pandas.core.resample.Resampler.mean", "full_function": "final Resampler.mean(numeric_only=False, *args, **kwargs)", "function_text": "Compute mean of groups, excluding missing values.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int or boolean data.\n\nChanged in version 2.0.0: numeric_only now defaults to False.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.mean.html#pandas.core.resample.Resampler.mean"}, {"function_name": "pandas.core.resample.Resampler.min", "full_function": "final Resampler.min(numeric_only=False, min_count=0, *args, **kwargs)", "function_text": "Compute min value of group.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.min.html#pandas.core.resample.Resampler.min"}, {"function_name": "pandas.core.resample.Resampler.prod", "full_function": "final Resampler.prod(numeric_only=False, min_count=0, *args, **kwargs)", "function_text": "Compute prod of group values.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nChanged in version 2.0.0: numeric_only no longer accepts None.\n\n"}, {"param_name": "min_count", "param_type": "int, default 0", "param_desc": "The required number of valid values to perform the operation. If fewer\nthan min_count non-NA values are present the result will be NA.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.prod.html#pandas.core.resample.Resampler.prod"}, {"function_name": "pandas.core.resample.Resampler.sem", "full_function": "final Resampler.sem(ddof=1, numeric_only=False, *args, **kwargs)", "function_text": "Compute standard error of the mean of groups, excluding missing values.", "parameter_names_desc": [{"param_name": "ddof", "param_type": "int, default 1", "param_desc": "Degrees of freedom.\n"}, {"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int or boolean data.\n\nNew in version 1.5.0.\n\n\nChanged in version 2.0.0: numeric_only now defaults to False.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.sem.html#pandas.core.resample.Resampler.sem"}, {"function_name": "pandas.core.resample.Resampler.sum", "full_function": "final Resampler.sum(numeric_only=False, min_count=0, *args, **kwargs)", "function_text": "Compute sum of group values.", "parameter_names_desc": [{"param_name": "numeric_only", "param_type": "bool, default False", "param_desc": "Include only float, int, boolean columns.\n\nChanged in version 2.0.0: numeric_only no longer accepts None.\n\n"}, {"param_name": "min_count", "param_type": "int, default 0", "param_desc": "The required number of valid values to perform the operation. If fewer\nthan min_count non-NA values are present the result will be NA.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.sum.html#pandas.core.resample.Resampler.sum"}, {"function_name": "pandas.core.resample.Resampler.quantile", "full_function": "final Resampler.quantile(q=0.5, **kwargs)", "function_text": "Return value at the given quantile.", "parameter_names_desc": [{"param_name": "q", "param_type": "float or array-like, default 0.5 (50% quantile)", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.quantile.html#pandas.core.resample.Resampler.quantile"}]}], "name": "Resampling", "url": "https://pandas.pydata.org/docs/reference/resampling.html"}, "style.html": {"functions": [{"name": "Styler constructor", "url": "https://pandas.pydata.org/docs/reference/style.html#styler-constructor", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.html#pandas.io.formats.style.Styler", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.from_custom_template.html#pandas.io.formats.style.Styler.from_custom_template"], "function_definitions": [{"function_name": "pandas.io.formats.style.Styler", "full_function": "class pandas.io.formats.style.Styler(data, precision=None, table_styles=None, uuid=None, caption=None, table_attributes=None, cell_ids=True, na_rep=None, uuid_len=5, decimal=None, thousands=None, escape=None, formatter=None)", "function_text": "Helps style a DataFrame or Series according to the data with HTML and CSS.", "parameter_names_desc": [{"param_name": "data", "param_type": "Series or DataFrame", "param_desc": "Data to be styled - either a Series or DataFrame.\n"}, {"param_name": "precision", "param_type": "int, optional", "param_desc": "Precision to round floats to. If not given defaults to\npandas.options.styler.format.precision.\n\nChanged in version 1.4.0.\n\n"}, {"param_name": "table_styles", "param_type": "list-like, default None", "param_desc": "List of {selector: (attr, value)} dicts; see Notes.\n"}, {"param_name": "uuid", "param_type": "str, default None", "param_desc": "A unique identifier to avoid CSS collisions; generated automatically.\n"}, {"param_name": "caption", "param_type": "str, tuple, default None", "param_desc": "String caption to attach to the table. Tuple only used for LaTeX dual captions.\n"}, {"param_name": "table_attributes", "param_type": "str, default None", "param_desc": "Items that show up in the opening <table> tag\nin addition to automatic (by default) id.\n"}, {"param_name": "cell_ids", "param_type": "bool, default True", "param_desc": "If True, each cell will have an id attribute in their HTML tag.\nThe id takes the form T_<uuid>_row<num_row>_col<num_col>\nwhere <uuid> is the unique identifier, <num_row> is the row\nnumber and <num_col> is the column number.\n"}, {"param_name": "na_rep", "param_type": "str, optional", "param_desc": "Representation for missing values.\nIf na_rep is None, no special formatting is applied, and falls back to\npandas.options.styler.format.na_rep.\n"}, {"param_name": "uuid_len", "param_type": "int, default 5", "param_desc": "If uuid is not specified, the length of the uuid to randomly generate\nexpressed in hex characters, in range [0, 32].\n"}, {"param_name": "decimal", "param_type": "str, optional", "param_desc": "Character used as decimal separator for floats, complex and integers. If not\ngiven uses pandas.options.styler.format.decimal.\n\nNew in version 1.3.0.\n\n"}, {"param_name": "thousands", "param_type": "str, optional, default None", "param_desc": "Character used as thousands separator for floats, complex and integers. If not\ngiven uses pandas.options.styler.format.thousands.\n\nNew in version 1.3.0.\n\n"}, {"param_name": "escape", "param_type": "str, optional", "param_desc": "Use ‘html’ to replace the characters &, <, >, ', and \"\nin cell display string with HTML-safe sequences.\nUse ‘latex’ to replace the characters &, %, $, #, _,\n{, }, ~, ^, and \\ in the cell display string with\nLaTeX-safe sequences. Use ‘latex-math’ to replace the characters\nthe same way as in ‘latex’ mode, except for math substrings,\nwhich either are surrounded by two characters $ or start with\nthe character \\( and end with \\).\nIf not given uses pandas.options.styler.format.escape.\n\nNew in version 1.3.0.\n\n"}, {"param_name": "formatter", "param_type": "str, callable, dict, optional", "param_desc": "Object to define how values are displayed. See Styler.format. If not given\nuses pandas.options.styler.format.formatter.\n\nNew in version 1.4.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.html#pandas.io.formats.style.Styler"}, {"function_name": "pandas.io.formats.style.Styler.from_custom_template", "full_function": "classmethod Styler.from_custom_template(searchpath, html_table=None, html_style=None)", "function_text": "Factory function for creating a subclass of Styler.", "parameter_names_desc": [{"param_name": "searchpath", "param_type": "str or list", "param_desc": "Path or paths of directories containing the templates.\n"}, {"param_name": "html_table", "param_type": "str", "param_desc": "Name of your custom template to replace the html_table template.\n\nNew in version 1.3.0.\n\n"}, {"param_name": "html_style", "param_type": "str", "param_desc": "Name of your custom template to replace the html_style template.\n\nNew in version 1.3.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.from_custom_template.html#pandas.io.formats.style.Styler.from_custom_template"}]}, {"name": "Styler properties", "url": "https://pandas.pydata.org/docs/reference/style.html#styler-properties", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.env.html#pandas.io.formats.style.Styler.env", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.template_html_style.html#pandas.io.formats.style.Styler.template_html_style", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.template_latex.html#pandas.io.formats.style.Styler.template_latex", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.loader.html#pandas.io.formats.style.Styler.loader", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.template_html.html#pandas.io.formats.style.Styler.template_html", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.template_html_table.html#pandas.io.formats.style.Styler.template_html_table", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.template_string.html#pandas.io.formats.style.Styler.template_string"], "function_definitions": [{"function_name": "pandas.io.formats.style.Styler.from_custom_template", "full_function": "classmethod Styler.from_custom_template(searchpath, html_table=None, html_style=None)", "function_text": "Factory function for creating a subclass of Styler.", "parameter_names_desc": [{"param_name": "searchpath", "param_type": "str or list", "param_desc": "Path or paths of directories containing the templates.\n"}, {"param_name": "html_table", "param_type": "str", "param_desc": "Name of your custom template to replace the html_table template.\n\nNew in version 1.3.0.\n\n"}, {"param_name": "html_style", "param_type": "str", "param_desc": "Name of your custom template to replace the html_style template.\n\nNew in version 1.3.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.from_custom_template.html#pandas.io.formats.style.Styler.from_custom_template"}, {"function_name": "pandas.io.formats.style.Styler.from_custom_template", "full_function": "classmethod Styler.from_custom_template(searchpath, html_table=None, html_style=None)", "function_text": "Factory function for creating a subclass of Styler.", "parameter_names_desc": [{"param_name": "searchpath", "param_type": "str or list", "param_desc": "Path or paths of directories containing the templates.\n"}, {"param_name": "html_table", "param_type": "str", "param_desc": "Name of your custom template to replace the html_table template.\n\nNew in version 1.3.0.\n\n"}, {"param_name": "html_style", "param_type": "str", "param_desc": "Name of your custom template to replace the html_style template.\n\nNew in version 1.3.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.from_custom_template.html#pandas.io.formats.style.Styler.from_custom_template"}, {"function_name": "pandas.io.formats.style.Styler.from_custom_template", "full_function": "classmethod Styler.from_custom_template(searchpath, html_table=None, html_style=None)", "function_text": "Factory function for creating a subclass of Styler.", "parameter_names_desc": [{"param_name": "searchpath", "param_type": "str or list", "param_desc": "Path or paths of directories containing the templates.\n"}, {"param_name": "html_table", "param_type": "str", "param_desc": "Name of your custom template to replace the html_table template.\n\nNew in version 1.3.0.\n\n"}, {"param_name": "html_style", "param_type": "str", "param_desc": "Name of your custom template to replace the html_style template.\n\nNew in version 1.3.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.from_custom_template.html#pandas.io.formats.style.Styler.from_custom_template"}, {"function_name": "pandas.io.formats.style.Styler.from_custom_template", "full_function": "classmethod Styler.from_custom_template(searchpath, html_table=None, html_style=None)", "function_text": "Factory function for creating a subclass of Styler.", "parameter_names_desc": [{"param_name": "searchpath", "param_type": "str or list", "param_desc": "Path or paths of directories containing the templates.\n"}, {"param_name": "html_table", "param_type": "str", "param_desc": "Name of your custom template to replace the html_table template.\n\nNew in version 1.3.0.\n\n"}, {"param_name": "html_style", "param_type": "str", "param_desc": "Name of your custom template to replace the html_style template.\n\nNew in version 1.3.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.from_custom_template.html#pandas.io.formats.style.Styler.from_custom_template"}, {"function_name": "pandas.io.formats.style.Styler.from_custom_template", "full_function": "classmethod Styler.from_custom_template(searchpath, html_table=None, html_style=None)", "function_text": "Factory function for creating a subclass of Styler.", "parameter_names_desc": [{"param_name": "searchpath", "param_type": "str or list", "param_desc": "Path or paths of directories containing the templates.\n"}, {"param_name": "html_table", "param_type": "str", "param_desc": "Name of your custom template to replace the html_table template.\n\nNew in version 1.3.0.\n\n"}, {"param_name": "html_style", "param_type": "str", "param_desc": "Name of your custom template to replace the html_style template.\n\nNew in version 1.3.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.from_custom_template.html#pandas.io.formats.style.Styler.from_custom_template"}, {"function_name": "pandas.io.formats.style.Styler.from_custom_template", "full_function": "classmethod Styler.from_custom_template(searchpath, html_table=None, html_style=None)", "function_text": "Factory function for creating a subclass of Styler.", "parameter_names_desc": [{"param_name": "searchpath", "param_type": "str or list", "param_desc": "Path or paths of directories containing the templates.\n"}, {"param_name": "html_table", "param_type": "str", "param_desc": "Name of your custom template to replace the html_table template.\n\nNew in version 1.3.0.\n\n"}, {"param_name": "html_style", "param_type": "str", "param_desc": "Name of your custom template to replace the html_style template.\n\nNew in version 1.3.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.from_custom_template.html#pandas.io.formats.style.Styler.from_custom_template"}, {"function_name": "pandas.io.formats.style.Styler.from_custom_template", "full_function": "classmethod Styler.from_custom_template(searchpath, html_table=None, html_style=None)", "function_text": "Factory function for creating a subclass of Styler.", "parameter_names_desc": [{"param_name": "searchpath", "param_type": "str or list", "param_desc": "Path or paths of directories containing the templates.\n"}, {"param_name": "html_table", "param_type": "str", "param_desc": "Name of your custom template to replace the html_table template.\n\nNew in version 1.3.0.\n\n"}, {"param_name": "html_style", "param_type": "str", "param_desc": "Name of your custom template to replace the html_style template.\n\nNew in version 1.3.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.from_custom_template.html#pandas.io.formats.style.Styler.from_custom_template"}]}, {"name": "Style application", "url": "https://pandas.pydata.org/docs/reference/style.html#style-application", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.apply.html#pandas.io.formats.style.Styler.apply", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.apply_index.html#pandas.io.formats.style.Styler.apply_index", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.format.html#pandas.io.formats.style.Styler.format", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.relabel_index.html#pandas.io.formats.style.Styler.relabel_index", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.concat.html#pandas.io.formats.style.Styler.concat", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.set_table_styles.html#pandas.io.formats.style.Styler.set_table_styles", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.set_tooltips.html#pandas.io.formats.style.Styler.set_tooltips", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.set_sticky.html#pandas.io.formats.style.Styler.set_sticky", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.set_uuid.html#pandas.io.formats.style.Styler.set_uuid", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.pipe.html#pandas.io.formats.style.Styler.pipe", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.map.html#pandas.io.formats.style.Styler.map", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.map_index.html#pandas.io.formats.style.Styler.map_index", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.format_index.html#pandas.io.formats.style.Styler.format_index", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.hide.html#pandas.io.formats.style.Styler.hide", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.set_td_classes.html#pandas.io.formats.style.Styler.set_td_classes", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.set_table_attributes.html#pandas.io.formats.style.Styler.set_table_attributes", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.set_caption.html#pandas.io.formats.style.Styler.set_caption", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.set_properties.html#pandas.io.formats.style.Styler.set_properties", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.clear.html#pandas.io.formats.style.Styler.clear"], "function_definitions": [{"function_name": "pandas.io.formats.style.Styler.apply", "full_function": "Styler.apply(func, axis=0, subset=None, **kwargs)", "function_text": "Apply a CSS-styling function column-wise, row-wise, or table-wise.", "parameter_names_desc": [{"param_name": "func", "param_type": "function", "param_desc": "func should take a Series if axis in [0,1] and return a list-like\nobject of same length, or a Series, not necessarily of same length, with\nvalid index labels considering subset.\nfunc should take a DataFrame if axis is None and return either\nan ndarray with the same shape or a DataFrame, not necessarily of the same\nshape, with valid index and columns labels considering subset.\n\nChanged in version 1.3.0.\n\n\nChanged in version 1.4.0.\n\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’, None}, default 0", "param_desc": "Apply to each column (axis=0 or 'index'), to each row\n(axis=1 or 'columns'), or to the entire DataFrame at once\nwith axis=None.\n"}, {"param_name": "subset", "param_type": "label, array-like, IndexSlice, optional", "param_desc": "A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\nor single key, to DataFrame.loc[:, <subset>] where the columns are\nprioritised, to limit data to before applying the function.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.apply.html#pandas.io.formats.style.Styler.apply"}, {"function_name": "pandas.io.formats.style.Styler.apply_index", "full_function": "Styler.apply_index(func, axis=0, level=None, **kwargs)", "function_text": "Apply a CSS-styling function to the index or column headers, level-wise.", "parameter_names_desc": [{"param_name": "func", "param_type": "function", "param_desc": "func should take a Series and return a string array of the same length.\n"}, {"param_name": "axis", "param_type": "{0, 1, “index”, “columns”}", "param_desc": "The headers over which to apply the function.\n"}, {"param_name": "level", "param_type": "int, str, list, optional", "param_desc": "If index is MultiIndex the level(s) over which to apply the function.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.apply_index.html#pandas.io.formats.style.Styler.apply_index"}, {"function_name": "pandas.io.formats.style.Styler.format", "full_function": "Styler.format(formatter=None, subset=None, na_rep=None, precision=None, decimal='.', thousands=None, escape=None, hyperlinks=None)", "function_text": "Format the text display value of cells.", "parameter_names_desc": [{"param_name": "formatter", "param_type": "str, callable, dict or None", "param_desc": "Object to define how values are displayed. See notes.\n"}, {"param_name": "subset", "param_type": "label, array-like, IndexSlice, optional", "param_desc": "A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\nor single key, to DataFrame.loc[:, <subset>] where the columns are\nprioritised, to limit data to before applying the function.\n"}, {"param_name": "na_rep", "param_type": "str, optional", "param_desc": "Representation for missing values.\nIf na_rep is None, no special formatting is applied.\n"}, {"param_name": "precision", "param_type": "int, optional", "param_desc": "Floating point precision to use for display purposes, if not determined by\nthe specified formatter.\n\nNew in version 1.3.0.\n\n"}, {"param_name": "decimal", "param_type": "str, default “.”", "param_desc": "Character used as decimal separator for floats, complex and integers.\n\nNew in version 1.3.0.\n\n"}, {"param_name": "thousands", "param_type": "str, optional, default None", "param_desc": "Character used as thousands separator for floats, complex and integers.\n\nNew in version 1.3.0.\n\n"}, {"param_name": "escape", "param_type": "str, optional", "param_desc": "Use ‘html’ to replace the characters &, <, >, ', and \"\nin cell display string with HTML-safe sequences.\nUse ‘latex’ to replace the characters &, %, $, #, _,\n{, }, ~, ^, and \\ in the cell display string with\nLaTeX-safe sequences.\nUse ‘latex-math’ to replace the characters the same way as in ‘latex’ mode,\nexcept for math substrings, which either are surrounded\nby two characters $ or start with the character \\( and\nend with \\). Escaping is done before formatter.\n\nNew in version 1.3.0.\n\n"}, {"param_name": "hyperlinks", "param_type": "{“html”, “latex”}, optional", "param_desc": "Convert string patterns containing https://, http://, ftp:// or www. to\nHTML <a> tags as clickable URL hyperlinks if “html”, or LaTeX href\ncommands if “latex”.\n\nNew in version 1.4.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.format.html#pandas.io.formats.style.Styler.format"}, {"function_name": "pandas.io.formats.style.Styler.relabel_index", "full_function": "Styler.relabel_index(labels, axis=0, level=None)", "function_text": "Relabel the index, or column header, keys to display a set of specified values.", "parameter_names_desc": [{"param_name": "labels", "param_type": "list-like or Index", "param_desc": "New labels to display. Must have same length as the underlying values not\nhidden.\n"}, {"param_name": "axis", "param_type": "{“index”, 0, “columns”, 1}", "param_desc": "Apply to the index or columns.\n"}, {"param_name": "level", "param_type": "int, str, list, optional", "param_desc": "The level(s) over which to apply the new labels. If None will apply\nto all levels of an Index or MultiIndex which are not hidden.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.relabel_index.html#pandas.io.formats.style.Styler.relabel_index"}, {"function_name": "pandas.io.formats.style.Styler.concat", "full_function": "Styler.concat(other)", "function_text": "Append another Styler to combine the output into a single table.", "parameter_names_desc": [{"param_name": "other", "param_type": "Styler", "param_desc": "The other Styler object which has already been styled and formatted. The\ndata for this Styler must have the same columns as the original, and the\nnumber of index levels must also be the same to render correctly.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.concat.html#pandas.io.formats.style.Styler.concat"}, {"function_name": "pandas.io.formats.style.Styler.set_table_styles", "full_function": "Styler.set_table_styles(table_styles=None, axis=0, overwrite=True, css_class_names=None)", "function_text": "Set the table styles included within the <style> HTML element.", "parameter_names_desc": [{"param_name": "table_styles", "param_type": "list or dict", "param_desc": "If supplying a list, each individual table_style should be a\ndictionary with selector and props keys. selector\nshould be a CSS selector that the style will be applied to\n(automatically prefixed by the table’s UUID) and props\nshould be a list of tuples with (attribute, value).\nIf supplying a dict, the dict keys should correspond to\ncolumn names or index values, depending upon the specified\naxis argument. These will be mapped to row or col CSS\nselectors. MultiIndex values as dict keys should be\nin their respective tuple form. The dict values should be\na list as specified in the form with CSS selectors and\nprops that will be applied to the specified row or column.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’, None}, default 0", "param_desc": "Apply to each column (axis=0 or 'index'), to each row\n(axis=1 or 'columns'). Only used if table_styles is\ndict.\n"}, {"param_name": "overwrite", "param_type": "bool, default True", "param_desc": "Styles are replaced if True, or extended if False. CSS\nrules are preserved so most recent styles set will dominate\nif selectors intersect.\n"}, {"param_name": "css_class_names", "param_type": "dict, optional", "param_desc": "A dict of strings used to replace the default CSS classes described below.\n\nNew in version 1.4.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.set_table_styles.html#pandas.io.formats.style.Styler.set_table_styles"}, {"function_name": "pandas.io.formats.style.Styler.set_tooltips", "full_function": "Styler.set_tooltips(ttips, props=None, css_class=None)", "function_text": "Set the DataFrame of strings on Styler generating :hover tooltips.", "parameter_names_desc": [{"param_name": "ttips", "param_type": "DataFrame", "param_desc": "DataFrame containing strings that will be translated to tooltips, mapped\nby identical column and index values that must exist on the underlying\nStyler data. None, NaN values, and empty strings will be ignored and\nnot affect the rendered HTML.\n"}, {"param_name": "props", "param_type": "list-like or str, optional", "param_desc": "List of (attr, value) tuples or a valid CSS string. If None adopts\nthe internal default values described in notes.\n"}, {"param_name": "css_class", "param_type": "str, optional", "param_desc": "Name of the tooltip class used in CSS, should conform to HTML standards.\nOnly useful if integrating tooltips with external CSS. If None uses the\ninternal default value ‘pd-t’.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.set_tooltips.html#pandas.io.formats.style.Styler.set_tooltips"}, {"function_name": "pandas.io.formats.style.Styler.set_sticky", "full_function": "Styler.set_sticky(axis=0, pixel_size=None, levels=None)", "function_text": "Add CSS to permanently display the index or column headers in a scrolling frame.", "parameter_names_desc": [{"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’}, default 0", "param_desc": "Whether to make the index or column headers sticky.\n"}, {"param_name": "pixel_size", "param_type": "int, optional", "param_desc": "Required to configure the width of index cells or the height of column\nheader cells when sticking a MultiIndex (or with a named Index).\nDefaults to 75 and 25 respectively.\n"}, {"param_name": "levels", "param_type": "int, str, list, optional", "param_desc": "If axis is a MultiIndex the specific levels to stick. If None will\nstick all levels.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.set_sticky.html#pandas.io.formats.style.Styler.set_sticky"}, {"function_name": "pandas.io.formats.style.Styler.set_uuid", "full_function": "Styler.set_uuid(uuid)", "function_text": "Set the uuid applied to id attributes of HTML elements.", "parameter_names_desc": [{"param_name": "uuid", "param_type": "str", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.set_uuid.html#pandas.io.formats.style.Styler.set_uuid"}, {"function_name": "pandas.io.formats.style.Styler.pipe", "full_function": "Styler.pipe(func, *args, **kwargs)", "function_text": "Apply func(self, *args, **kwargs), and return the result.", "parameter_names_desc": [{"param_name": "func", "param_type": "function", "param_desc": "Function to apply to the Styler. Alternatively, a\n(callable, keyword) tuple where keyword is a string\nindicating the keyword of callable that expects the Styler.\n"}, {"param_name": "*args", "param_type": "optional", "param_desc": "Arguments passed to func.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.pipe.html#pandas.io.formats.style.Styler.pipe"}, {"function_name": "pandas.io.formats.style.Styler.map", "full_function": "Styler.map(func, subset=None, **kwargs)", "function_text": "Apply a CSS-styling function elementwise.", "parameter_names_desc": [{"param_name": "func", "param_type": "function", "param_desc": "func should take a scalar and return a string.\n"}, {"param_name": "subset", "param_type": "label, array-like, IndexSlice, optional", "param_desc": "A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\nor single key, to DataFrame.loc[:, <subset>] where the columns are\nprioritised, to limit data to before applying the function.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.map.html#pandas.io.formats.style.Styler.map"}, {"function_name": "pandas.io.formats.style.Styler.map_index", "full_function": "Styler.map_index(func, axis=0, level=None, **kwargs)", "function_text": "Apply a CSS-styling function to the index or column headers, elementwise.", "parameter_names_desc": [{"param_name": "func", "param_type": "function", "param_desc": "func should take a scalar and return a string.\n"}, {"param_name": "axis", "param_type": "{0, 1, “index”, “columns”}", "param_desc": "The headers over which to apply the function.\n"}, {"param_name": "level", "param_type": "int, str, list, optional", "param_desc": "If index is MultiIndex the level(s) over which to apply the function.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.map_index.html#pandas.io.formats.style.Styler.map_index"}, {"function_name": "pandas.io.formats.style.Styler.format_index", "full_function": "Styler.format_index(formatter=None, axis=0, level=None, na_rep=None, precision=None, decimal='.', thousands=None, escape=None, hyperlinks=None)", "function_text": "Format the text display value of index labels or column headers.", "parameter_names_desc": [{"param_name": "formatter", "param_type": "str, callable, dict or None", "param_desc": "Object to define how values are displayed. See notes.\n"}, {"param_name": "axis", "param_type": "{0, “index”, 1, “columns”}", "param_desc": "Whether to apply the formatter to the index or column headers.\n"}, {"param_name": "level", "param_type": "int, str, list", "param_desc": "The level(s) over which to apply the generic formatter.\n"}, {"param_name": "na_rep", "param_type": "str, optional", "param_desc": "Representation for missing values.\nIf na_rep is None, no special formatting is applied.\n"}, {"param_name": "precision", "param_type": "int, optional", "param_desc": "Floating point precision to use for display purposes, if not determined by\nthe specified formatter.\n"}, {"param_name": "decimal", "param_type": "str, default “.”", "param_desc": "Character used as decimal separator for floats, complex and integers.\n"}, {"param_name": "thousands", "param_type": "str, optional, default None", "param_desc": "Character used as thousands separator for floats, complex and integers.\n"}, {"param_name": "escape", "param_type": "str, optional", "param_desc": "Use ‘html’ to replace the characters &, <, >, ', and \"\nin cell display string with HTML-safe sequences.\nUse ‘latex’ to replace the characters &, %, $, #, _,\n{, }, ~, ^, and \\ in the cell display string with\nLaTeX-safe sequences.\nEscaping is done before formatter.\n"}, {"param_name": "hyperlinks", "param_type": "{“html”, “latex”}, optional", "param_desc": "Convert string patterns containing https://, http://, ftp:// or www. to\nHTML <a> tags as clickable URL hyperlinks if “html”, or LaTeX href\ncommands if “latex”.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.format_index.html#pandas.io.formats.style.Styler.format_index"}, {"function_name": "pandas.io.formats.style.Styler.hide", "full_function": "Styler.hide(subset=None, axis=0, level=None, names=False)", "function_text": "Hide the entire index / column headers, or specific rows / columns from display.", "parameter_names_desc": [{"param_name": "subset", "param_type": "label, array-like, IndexSlice, optional", "param_desc": "A valid 1d input or single key along the axis within\nDataFrame.loc[<subset>, :] or DataFrame.loc[:, <subset>] depending\nupon axis, to limit data to select hidden rows / columns.\n"}, {"param_name": "axis", "param_type": "{“index”, 0, “columns”, 1}", "param_desc": "Apply to the index or columns.\n"}, {"param_name": "level", "param_type": "int, str, list", "param_desc": "The level(s) to hide in a MultiIndex if hiding the entire index / column\nheaders. Cannot be used simultaneously with subset.\n"}, {"param_name": "names", "param_type": "bool", "param_desc": "Whether to hide the level name(s) of the index / columns headers in the case\nit (or at least one the levels) remains visible.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.hide.html#pandas.io.formats.style.Styler.hide"}, {"function_name": "pandas.io.formats.style.Styler.set_td_classes", "full_function": "Styler.set_td_classes(classes)", "function_text": "Set the class attribute of <td> HTML elements.", "parameter_names_desc": [{"param_name": "classes", "param_type": "DataFrame", "param_desc": "DataFrame containing strings that will be translated to CSS classes,\nmapped by identical column and index key values that must exist on the\nunderlying Styler data. None, NaN values, and empty strings will\nbe ignored and not affect the rendered HTML.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.set_td_classes.html#pandas.io.formats.style.Styler.set_td_classes"}, {"function_name": "pandas.io.formats.style.Styler.set_table_attributes", "full_function": "Styler.set_table_attributes(attributes)", "function_text": "Set the table attributes added to the <table> HTML element.", "parameter_names_desc": [{"param_name": "attributes", "param_type": "str", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.set_table_attributes.html#pandas.io.formats.style.Styler.set_table_attributes"}, {"function_name": "pandas.io.formats.style.Styler.set_caption", "full_function": "Styler.set_caption(caption)", "function_text": "Set the text added to a <caption> HTML element.", "parameter_names_desc": [{"param_name": "caption", "param_type": "str, tuple, list", "param_desc": "For HTML output either the string input is used or the first element of the\ntuple. For LaTeX the string input provides a caption and the additional\ntuple input allows for full captions and short captions, in that order.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.set_caption.html#pandas.io.formats.style.Styler.set_caption"}, {"function_name": "pandas.io.formats.style.Styler.set_properties", "full_function": "Styler.set_properties(subset=None, **kwargs)", "function_text": "Set defined CSS-properties to each <td> HTML element for the given subset.", "parameter_names_desc": [{"param_name": "subset", "param_type": "label, array-like, IndexSlice, optional", "param_desc": "A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\nor single key, to DataFrame.loc[:, <subset>] where the columns are\nprioritised, to limit data to before applying the function.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.set_properties.html#pandas.io.formats.style.Styler.set_properties"}, {"function_name": "pandas.io.formats.style.Styler.clear", "full_function": "Styler.clear()", "function_text": "Reset the Styler, removing any previously applied styles.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.clear.html#pandas.io.formats.style.Styler.clear"}]}, {"name": "Builtin styles", "url": "https://pandas.pydata.org/docs/reference/style.html#builtin-styles", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.highlight_null.html#pandas.io.formats.style.Styler.highlight_null", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.highlight_min.html#pandas.io.formats.style.Styler.highlight_min", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.highlight_quantile.html#pandas.io.formats.style.Styler.highlight_quantile", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.text_gradient.html#pandas.io.formats.style.Styler.text_gradient", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.highlight_max.html#pandas.io.formats.style.Styler.highlight_max", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.highlight_between.html#pandas.io.formats.style.Styler.highlight_between", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.background_gradient.html#pandas.io.formats.style.Styler.background_gradient", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.bar.html#pandas.io.formats.style.Styler.bar"], "function_definitions": [{"function_name": "pandas.io.formats.style.Styler.highlight_null", "full_function": "Styler.highlight_null(color='red', subset=None, props=None)", "function_text": "Highlight missing values with a style.", "parameter_names_desc": [{"param_name": "color", "param_type": "str, default ‘red’", "param_desc": "Background color to use for highlighting.\n\n\nNew in version 1.5.0.\n\n\n"}, {"param_name": "subset", "param_type": "label, array-like, IndexSlice, optional", "param_desc": "A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\nor single key, to DataFrame.loc[:, <subset>] where the columns are\nprioritised, to limit data to before applying the function.\n"}, {"param_name": "props", "param_type": "str, default None", "param_desc": "CSS properties to use for highlighting. If props is given, color\nis not used.\n\n\nNew in version 1.3.0.\n\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.highlight_null.html#pandas.io.formats.style.Styler.highlight_null"}, {"function_name": "pandas.io.formats.style.Styler.highlight_min", "full_function": "Styler.highlight_min(subset=None, color='yellow', axis=0, props=None)", "function_text": "Highlight the minimum with a style.", "parameter_names_desc": [{"param_name": "subset", "param_type": "label, array-like, IndexSlice, optional", "param_desc": "A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\nor single key, to DataFrame.loc[:, <subset>] where the columns are\nprioritised, to limit data to before applying the function.\n"}, {"param_name": "color", "param_type": "str, default ‘yellow’", "param_desc": "Background color to use for highlighting.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’, None}, default 0", "param_desc": "Apply to each column (axis=0 or 'index'), to each row\n(axis=1 or 'columns'), or to the entire DataFrame at once\nwith axis=None.\n"}, {"param_name": "props", "param_type": "str, default None", "param_desc": "CSS properties to use for highlighting. If props is given, color\nis not used.\n\n\nNew in version 1.3.0.\n\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.highlight_min.html#pandas.io.formats.style.Styler.highlight_min"}, {"function_name": "pandas.io.formats.style.Styler.highlight_quantile", "full_function": "Styler.highlight_quantile(subset=None, color='yellow', axis=0, q_left=0.0, q_right=1.0, interpolation='linear', inclusive='both', props=None)", "function_text": "Highlight values defined by a quantile with a style.", "parameter_names_desc": [{"param_name": "subset", "param_type": "label, array-like, IndexSlice, optional", "param_desc": "A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\nor single key, to DataFrame.loc[:, <subset>] where the columns are\nprioritised, to limit data to before applying the function.\n"}, {"param_name": "color", "param_type": "str, default ‘yellow’", "param_desc": "Background color to use for highlighting.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’, None}, default 0", "param_desc": "Axis along which to determine and highlight quantiles. If None quantiles\nare measured over the entire DataFrame. See examples.\n"}, {"param_name": "q_left", "param_type": "float, default 0", "param_desc": "Left bound, in [0, q_right), for the target quantile range.\n"}, {"param_name": "q_right", "param_type": "float, default 1", "param_desc": "Right bound, in (q_left, 1], for the target quantile range.\n"}, {"param_name": "interpolation", "param_type": "{‘linear’, ‘lower’, ‘higher’, ‘midpoint’, ‘nearest’}", "param_desc": "Argument passed to Series.quantile or DataFrame.quantile for\nquantile estimation.\n"}, {"param_name": "inclusive", "param_type": "{‘both’, ‘neither’, ‘left’, ‘right’}", "param_desc": "Identify whether quantile bounds are closed or open.\n"}, {"param_name": "props", "param_type": "str, default None", "param_desc": "CSS properties to use for highlighting. If props is given, color\nis not used.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.highlight_quantile.html#pandas.io.formats.style.Styler.highlight_quantile"}, {"function_name": "pandas.io.formats.style.Styler.text_gradient", "full_function": "Styler.text_gradient(cmap='PuBu', low=0, high=0, axis=0, subset=None, vmin=None, vmax=None, gmap=None)", "function_text": "Color the text in a gradient style.", "parameter_names_desc": [{"param_name": "cmap", "param_type": "str or colormap", "param_desc": "Matplotlib colormap.\n"}, {"param_name": "low", "param_type": "float", "param_desc": "Compress the color range at the low end. This is a multiple of the data\nrange to extend below the minimum; good values usually in [0, 1],\ndefaults to 0.\n"}, {"param_name": "high", "param_type": "float", "param_desc": "Compress the color range at the high end. This is a multiple of the data\nrange to extend above the maximum; good values usually in [0, 1],\ndefaults to 0.\n"}, {"param_name": "axis", "param_type": "{0, 1, “index”, “columns”, None}, default 0", "param_desc": "Apply to each column (axis=0 or 'index'), to each row\n(axis=1 or 'columns'), or to the entire DataFrame at once\nwith axis=None.\n"}, {"param_name": "subset", "param_type": "label, array-like, IndexSlice, optional", "param_desc": "A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\nor single key, to DataFrame.loc[:, <subset>] where the columns are\nprioritised, to limit data to before applying the function.\n"}, {"param_name": "vmin", "param_type": "float, optional", "param_desc": "Minimum data value that corresponds to colormap minimum value.\nIf not specified the minimum value of the data (or gmap) will be used.\n"}, {"param_name": "vmax", "param_type": "float, optional", "param_desc": "Maximum data value that corresponds to colormap maximum value.\nIf not specified the maximum value of the data (or gmap) will be used.\n"}, {"param_name": "gmap", "param_type": "array-like, optional", "param_desc": "Gradient map for determining the text colors. If not supplied\nwill use the underlying data from rows, columns or frame. If given as an\nndarray or list-like must be an identical shape to the underlying data\nconsidering axis and subset. If given as DataFrame or Series must\nhave same index and column labels considering axis and subset.\nIf supplied, vmin and vmax should be given relative to this\ngradient map.\n\nNew in version 1.3.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.text_gradient.html#pandas.io.formats.style.Styler.text_gradient"}, {"function_name": "pandas.io.formats.style.Styler.highlight_max", "full_function": "Styler.highlight_max(subset=None, color='yellow', axis=0, props=None)", "function_text": "Highlight the maximum with a style.", "parameter_names_desc": [{"param_name": "subset", "param_type": "label, array-like, IndexSlice, optional", "param_desc": "A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\nor single key, to DataFrame.loc[:, <subset>] where the columns are\nprioritised, to limit data to before applying the function.\n"}, {"param_name": "color", "param_type": "str, default ‘yellow’", "param_desc": "Background color to use for highlighting.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’, None}, default 0", "param_desc": "Apply to each column (axis=0 or 'index'), to each row\n(axis=1 or 'columns'), or to the entire DataFrame at once\nwith axis=None.\n"}, {"param_name": "props", "param_type": "str, default None", "param_desc": "CSS properties to use for highlighting. If props is given, color\nis not used.\n\n\nNew in version 1.3.0.\n\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.highlight_max.html#pandas.io.formats.style.Styler.highlight_max"}, {"function_name": "pandas.io.formats.style.Styler.highlight_between", "full_function": "Styler.highlight_between(subset=None, color='yellow', axis=0, left=None, right=None, inclusive='both', props=None)", "function_text": "Highlight a defined range with a style.", "parameter_names_desc": [{"param_name": "subset", "param_type": "label, array-like, IndexSlice, optional", "param_desc": "A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\nor single key, to DataFrame.loc[:, <subset>] where the columns are\nprioritised, to limit data to before applying the function.\n"}, {"param_name": "color", "param_type": "str, default ‘yellow’", "param_desc": "Background color to use for highlighting.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’, None}, default 0", "param_desc": "If left or right given as sequence, axis along which to apply those\nboundaries. See examples.\n"}, {"param_name": "left", "param_type": "scalar or datetime-like, or sequence or array-like, default None", "param_desc": "Left bound for defining the range.\n"}, {"param_name": "right", "param_type": "scalar or datetime-like, or sequence or array-like, default None", "param_desc": "Right bound for defining the range.\n"}, {"param_name": "inclusive", "param_type": "{‘both’, ‘neither’, ‘left’, ‘right’}", "param_desc": "Identify whether bounds are closed or open.\n"}, {"param_name": "props", "param_type": "str, default None", "param_desc": "CSS properties to use for highlighting. If props is given, color\nis not used.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.highlight_between.html#pandas.io.formats.style.Styler.highlight_between"}, {"function_name": "pandas.io.formats.style.Styler.background_gradient", "full_function": "Styler.background_gradient(cmap='PuBu', low=0, high=0, axis=0, subset=None, text_color_threshold=0.408, vmin=None, vmax=None, gmap=None)", "function_text": "Color the background in a gradient style.", "parameter_names_desc": [{"param_name": "cmap", "param_type": "str or colormap", "param_desc": "Matplotlib colormap.\n"}, {"param_name": "low", "param_type": "float", "param_desc": "Compress the color range at the low end. This is a multiple of the data\nrange to extend below the minimum; good values usually in [0, 1],\ndefaults to 0.\n"}, {"param_name": "high", "param_type": "float", "param_desc": "Compress the color range at the high end. This is a multiple of the data\nrange to extend above the maximum; good values usually in [0, 1],\ndefaults to 0.\n"}, {"param_name": "axis", "param_type": "{0, 1, “index”, “columns”, None}, default 0", "param_desc": "Apply to each column (axis=0 or 'index'), to each row\n(axis=1 or 'columns'), or to the entire DataFrame at once\nwith axis=None.\n"}, {"param_name": "subset", "param_type": "label, array-like, IndexSlice, optional", "param_desc": "A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\nor single key, to DataFrame.loc[:, <subset>] where the columns are\nprioritised, to limit data to before applying the function.\n"}, {"param_name": "text_color_threshold", "param_type": "float or int", "param_desc": "Luminance threshold for determining text color in [0, 1]. Facilitates text\nvisibility across varying background colors. All text is dark if 0, and\nlight if 1, defaults to 0.408.\n"}, {"param_name": "vmin", "param_type": "float, optional", "param_desc": "Minimum data value that corresponds to colormap minimum value.\nIf not specified the minimum value of the data (or gmap) will be used.\n"}, {"param_name": "vmax", "param_type": "float, optional", "param_desc": "Maximum data value that corresponds to colormap maximum value.\nIf not specified the maximum value of the data (or gmap) will be used.\n"}, {"param_name": "gmap", "param_type": "array-like, optional", "param_desc": "Gradient map for determining the background colors. If not supplied\nwill use the underlying data from rows, columns or frame. If given as an\nndarray or list-like must be an identical shape to the underlying data\nconsidering axis and subset. If given as DataFrame or Series must\nhave same index and column labels considering axis and subset.\nIf supplied, vmin and vmax should be given relative to this\ngradient map.\n\nNew in version 1.3.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.background_gradient.html#pandas.io.formats.style.Styler.background_gradient"}, {"function_name": "pandas.io.formats.style.Styler.bar", "full_function": "Styler.bar(subset=None, axis=0, *, color=None, cmap=None, width=100, height=100, align='mid', vmin=None, vmax=None, props='width: 10em;')", "function_text": "Draw bar chart in the cell backgrounds.", "parameter_names_desc": [{"param_name": "subset", "param_type": "label, array-like, IndexSlice, optional", "param_desc": "A valid 2d input to DataFrame.loc[<subset>], or, in the case of a 1d input\nor single key, to DataFrame.loc[:, <subset>] where the columns are\nprioritised, to limit data to before applying the function.\n"}, {"param_name": "axis", "param_type": "{0 or ‘index’, 1 or ‘columns’, None}, default 0", "param_desc": "Apply to each column (axis=0 or 'index'), to each row\n(axis=1 or 'columns'), or to the entire DataFrame at once\nwith axis=None.\n"}, {"param_name": "color", "param_type": "str or 2-tuple/list", "param_desc": "If a str is passed, the color is the same for both\nnegative and positive numbers. If 2-tuple/list is used, the\nfirst element is the color_negative and the second is the\ncolor_positive (eg: [‘#d65f5f’, ‘#5fba7d’]).\n"}, {"param_name": "cmap", "param_type": "str, matplotlib.cm.ColorMap", "param_desc": "A string name of a matplotlib Colormap, or a Colormap object. Cannot be\nused together with color.\n\nNew in version 1.4.0.\n\n"}, {"param_name": "width", "param_type": "float, default 100", "param_desc": "The percentage of the cell, measured from the left, in which to draw the\nbars, in [0, 100].\n"}, {"param_name": "height", "param_type": "float, default 100", "param_desc": "The percentage height of the bar in the cell, centrally aligned, in [0,100].\n\nNew in version 1.4.0.\n\n"}, {"param_name": "align", "param_type": "str, int, float, callable, default ‘mid’", "param_desc": "How to align the bars within the cells relative to a width adjusted center.\nIf string must be one of:\n\n‘left’ : bars are drawn rightwards from the minimum data value.\n‘right’ : bars are drawn leftwards from the maximum data value.\n‘zero’ : a value of zero is located at the center of the cell.\n‘mid’ : a value of (max-min)/2 is located at the center of the cell,\nor if all values are negative (positive) the zero is\naligned at the right (left) of the cell.\n‘mean’ : the mean value of the data is located at the center of the cell.\n\nIf a float or integer is given this will indicate the center of the cell.\nIf a callable should take a 1d or 2d array and return a scalar.\n\nChanged in version 1.4.0.\n\n"}, {"param_name": "vmin", "param_type": "float, optional", "param_desc": "Minimum bar value, defining the left hand limit\nof the bar drawing range, lower values are clipped to vmin.\nWhen None (default): the minimum value of the data will be used.\n"}, {"param_name": "vmax", "param_type": "float, optional", "param_desc": "Maximum bar value, defining the right hand limit\nof the bar drawing range, higher values are clipped to vmax.\nWhen None (default): the maximum value of the data will be used.\n"}, {"param_name": "props", "param_type": "str, optional", "param_desc": "The base CSS of the cell that is extended to add the bar chart. Defaults to\n“width: 10em;”.\n\nNew in version 1.4.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.bar.html#pandas.io.formats.style.Styler.bar"}]}, {"name": "Style export and import", "url": "https://pandas.pydata.org/docs/reference/style.html#style-export-and-import", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_html.html#pandas.io.formats.style.Styler.to_html", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_excel.html#pandas.io.formats.style.Styler.to_excel", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.export.html#pandas.io.formats.style.Styler.export", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_latex.html#pandas.io.formats.style.Styler.to_latex", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_string.html#pandas.io.formats.style.Styler.to_string", "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.use.html#pandas.io.formats.style.Styler.use"], "function_definitions": [{"function_name": "pandas.io.formats.style.Styler.to_html", "full_function": "Styler.to_html(buf=None, *, table_uuid=None, table_attributes=None, sparse_index=None, sparse_columns=None, bold_headers=False, caption=None, max_rows=None, max_columns=None, encoding=None, doctype_html=False, exclude_styles=False, **kwargs)", "function_text": "Write Styler to a file, buffer or string in HTML-CSS format.", "parameter_names_desc": [{"param_name": "buf", "param_type": "str, path object, file-like object, optional", "param_desc": "String, path object (implementing os.PathLike[str]), or file-like\nobject implementing a string write() function. If None, the result is\nreturned as a string.\n"}, {"param_name": "table_uuid", "param_type": "str, optional", "param_desc": "Id attribute assigned to the <table> HTML element in the format:\n<table id=\"T_<table_uuid>\" ..>\nIf not given uses Styler’s initially assigned value.\n"}, {"param_name": "table_attributes", "param_type": "str, optional", "param_desc": "Attributes to assign within the <table> HTML element in the format:\n<table .. <table_attributes> >\nIf not given defaults to Styler’s preexisting value.\n"}, {"param_name": "sparse_index", "param_type": "bool, optional", "param_desc": "Whether to sparsify the display of a hierarchical index. Setting to False\nwill display each explicit level element in a hierarchical key for each row.\nDefaults to pandas.options.styler.sparse.index value.\n\nNew in version 1.4.0.\n\n"}, {"param_name": "sparse_columns", "param_type": "bool, optional", "param_desc": "Whether to sparsify the display of a hierarchical index. Setting to False\nwill display each explicit level element in a hierarchical key for each\ncolumn. Defaults to pandas.options.styler.sparse.columns value.\n\nNew in version 1.4.0.\n\n"}, {"param_name": "bold_headers", "param_type": "bool, optional", "param_desc": "Adds “font-weight: bold;” as a CSS property to table style header cells.\n\nNew in version 1.4.0.\n\n"}, {"param_name": "caption", "param_type": "str, optional", "param_desc": "Set, or overwrite, the caption on Styler before rendering.\n\nNew in version 1.4.0.\n\n"}, {"param_name": "max_rows", "param_type": "int, optional", "param_desc": "The maximum number of rows that will be rendered. Defaults to\npandas.options.styler.render.max_rows/max_columns.\n\nNew in version 1.4.0.\n\n"}, {"param_name": "max_columns", "param_type": "int, optional", "param_desc": "The maximum number of columns that will be rendered. Defaults to\npandas.options.styler.render.max_columns, which is None.\nRows and columns may be reduced if the number of total elements is\nlarge. This value is set to pandas.options.styler.render.max_elements,\nwhich is 262144 (18 bit browser rendering).\n\nNew in version 1.4.0.\n\n"}, {"param_name": "encoding", "param_type": "str, optional", "param_desc": "Character encoding setting for file output (and meta tags if available).\nDefaults to pandas.options.styler.render.encoding value of “utf-8”.\n"}, {"param_name": "doctype_html", "param_type": "bool, default False", "param_desc": "Whether to output a fully structured HTML file including all\nHTML elements, or just the core <style> and <table> elements.\n"}, {"param_name": "exclude_styles", "param_type": "bool, default False", "param_desc": "Whether to include the <style> element and all associated element\nclass and id identifiers, or solely the <table> element without\nstyling identifiers.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_html.html#pandas.io.formats.style.Styler.to_html"}, {"function_name": "pandas.io.formats.style.Styler.to_excel", "full_function": "Styler.to_excel(excel_writer, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, encoding=None, inf_rep='inf', verbose=True, freeze_panes=None, storage_options=None)", "function_text": "Write Styler to an Excel sheet.", "parameter_names_desc": [{"param_name": "excel_writer", "param_type": "path-like, file-like, or ExcelWriter object", "param_desc": "File path or existing ExcelWriter.\n"}, {"param_name": "sheet_name", "param_type": "str, default ‘Sheet1’", "param_desc": "Name of sheet which will contain DataFrame.\n"}, {"param_name": "na_rep", "param_type": "str, default ‘’", "param_desc": "Missing data representation.\n"}, {"param_name": "float_format", "param_type": "str, optional", "param_desc": "Format string for floating point numbers. For example\nfloat_format=\"%.2f\" will format 0.1234 to 0.12.\n"}, {"param_name": "columns", "param_type": "sequence or list of str, optional", "param_desc": "Columns to write.\n"}, {"param_name": "header", "param_type": "bool or list of str, default True", "param_desc": "Write out the column names. If a list of string is given it is\nassumed to be aliases for the column names.\n"}, {"param_name": "index", "param_type": "bool, default True", "param_desc": "Write row names (index).\n"}, {"param_name": "index_label", "param_type": "str or sequence, optional", "param_desc": "Column label for index column(s) if desired. If not specified, and\nheader and index are True, then the index names are used. A\nsequence should be given if the DataFrame uses MultiIndex.\n"}, {"param_name": "startrow", "param_type": "int, default 0", "param_desc": "Upper left cell row to dump data frame.\n"}, {"param_name": "startcol", "param_type": "int, default 0", "param_desc": "Upper left cell column to dump data frame.\n"}, {"param_name": "engine", "param_type": "str, optional", "param_desc": "Write engine to use, ‘openpyxl’ or ‘xlsxwriter’. You can also set this\nvia the options io.excel.xlsx.writer or\nio.excel.xlsm.writer.\n"}, {"param_name": "merge_cells", "param_type": "bool, default True", "param_desc": "Write MultiIndex and Hierarchical Rows as merged cells.\n"}, {"param_name": "inf_rep", "param_type": "str, default ‘inf’", "param_desc": "Representation for infinity (there is no native representation for\ninfinity in Excel).\n"}, {"param_name": "freeze_panes", "param_type": "tuple of int (length 2), optional", "param_desc": "Specifies the one-based bottommost row and rightmost column that\nis to be frozen.\n"}, {"param_name": "storage_options", "param_type": "dict, optional", "param_desc": "Extra options that make sense for a particular storage connection, e.g.\nhost, port, username, password, etc. For HTTP(S) URLs the key-value pairs\nare forwarded to urllib.request.Request as header options. For other\nURLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are\nforwarded to fsspec.open. Please see fsspec and urllib for more\ndetails, and for more examples on storage options refer here.\n\nNew in version 1.5.0.\n\n"}, {"param_name": "engine_kwargs", "param_type": "dict, optional", "param_desc": "Arbitrary keyword arguments passed to excel engine.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_excel.html#pandas.io.formats.style.Styler.to_excel"}, {"function_name": "pandas.io.formats.style.Styler.export", "full_function": "Styler.export()", "function_text": "Export the styles applied to the current Styler.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.export.html#pandas.io.formats.style.Styler.export"}, {"function_name": "pandas.io.formats.style.Styler.to_latex", "full_function": "Styler.to_latex(buf=None, *, column_format=None, position=None, position_float=None, hrules=None, clines=None, label=None, caption=None, sparse_index=None, sparse_columns=None, multirow_align=None, multicol_align=None, siunitx=False, environment=None, encoding=None, convert_css=False)", "function_text": "Write Styler to a file, buffer or string in LaTeX format.", "parameter_names_desc": [{"param_name": "buf", "param_type": "str, path object, file-like object, or None, default None", "param_desc": "String, path object (implementing os.PathLike[str]), or file-like\nobject implementing a string write() function. If None, the result is\nreturned as a string.\n"}, {"param_name": "column_format", "param_type": "str, optional", "param_desc": "The LaTeX column specification placed in location:\n\\begin{tabular}{<column_format>}\nDefaults to ‘l’ for index and\nnon-numeric data columns, and, for numeric data columns,\nto ‘r’ by default, or ‘S’ if siunitx is True.\n"}, {"param_name": "position", "param_type": "str, optional", "param_desc": "The LaTeX positional argument (e.g. ‘h!’) for tables, placed in location:\n\\\\begin{table}[<position>].\n"}, {"param_name": "position_float", "param_type": "{“centering”, “raggedleft”, “raggedright”}, optional", "param_desc": "The LaTeX float command placed in location:\n\\begin{table}[<position>]\n\\<position_float>\nCannot be used if environment is “longtable”.\n"}, {"param_name": "hrules", "param_type": "bool", "param_desc": "Set to True to add \\toprule, \\midrule and \\bottomrule from the\n{booktabs} LaTeX package.\nDefaults to pandas.options.styler.latex.hrules, which is False.\n\nChanged in version 1.4.0.\n\n"}, {"param_name": "clines", "param_type": "str, optional", "param_desc": "Use to control adding \\cline commands for the index labels separation.\nPossible values are:\n\n\nNone: no cline commands are added (default).\n“all;data”: a cline is added for every index value extending the\nwidth of the table, including data entries.\n“all;index”: as above with lines extending only the width of the\nindex entries.\n“skip-last;data”: a cline is added for each index value except the\nlast level (which is never sparsified), extending the widtn of the\ntable.\n“skip-last;index”: as above with lines extending only the width of the\nindex entries.\n\n\n\nNew in version 1.4.0.\n\n"}, {"param_name": "label", "param_type": "str, optional", "param_desc": "The LaTeX label included as: \\label{<label>}.\nThis is used with \\ref{<label>} in the main .tex file.\n"}, {"param_name": "caption", "param_type": "str, tuple, optional", "param_desc": "If string, the LaTeX table caption included as: \\caption{<caption>}.\nIf tuple, i.e (“full caption”, “short caption”), the caption included\nas: \\caption[<caption[1]>]{<caption[0]>}.\n"}, {"param_name": "sparse_index", "param_type": "bool, optional", "param_desc": "Whether to sparsify the display of a hierarchical index. Setting to False\nwill display each explicit level element in a hierarchical key for each row.\nDefaults to pandas.options.styler.sparse.index, which is True.\n"}, {"param_name": "sparse_columns", "param_type": "bool, optional", "param_desc": "Whether to sparsify the display of a hierarchical index. Setting to False\nwill display each explicit level element in a hierarchical key for each\ncolumn. Defaults to pandas.options.styler.sparse.columns, which\nis True.\n"}, {"param_name": "multirow_align", "param_type": "{“c”, “t”, “b”, “naive”}, optional", "param_desc": "If sparsifying hierarchical MultiIndexes whether to align text centrally,\nat the top or bottom using the multirow package. If not given defaults to\npandas.options.styler.latex.multirow_align, which is “c”.\nIf “naive” is given renders without multirow.\n\nChanged in version 1.4.0.\n\n"}, {"param_name": "multicol_align", "param_type": "{“r”, “c”, “l”, “naive-l”, “naive-r”}, optional", "param_desc": "If sparsifying hierarchical MultiIndex columns whether to align text at\nthe left, centrally, or at the right. If not given defaults to\npandas.options.styler.latex.multicol_align, which is “r”.\nIf a naive option is given renders without multicol.\nPipe decorators can also be added to non-naive values to draw vertical\nrules, e.g. “|r” will draw a rule on the left side of right aligned merged\ncells.\n\nChanged in version 1.4.0.\n\n"}, {"param_name": "siunitx", "param_type": "bool, default False", "param_desc": "Set to True to structure LaTeX compatible with the {siunitx} package.\n"}, {"param_name": "environment", "param_type": "str, optional", "param_desc": "If given, the environment that will replace ‘table’ in \\\\begin{table}.\nIf ‘longtable’ is specified then a more suitable template is\nrendered. If not given defaults to\npandas.options.styler.latex.environment, which is None.\n\nNew in version 1.4.0.\n\n"}, {"param_name": "encoding", "param_type": "str, optional", "param_desc": "Character encoding setting. Defaults\nto pandas.options.styler.render.encoding, which is “utf-8”.\n"}, {"param_name": "convert_css", "param_type": "bool, default False", "param_desc": "Convert simple cell-styles from CSS to LaTeX format. Any CSS not found in\nconversion table is dropped. A style can be forced by adding option\n–latex. See notes.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_latex.html#pandas.io.formats.style.Styler.to_latex"}, {"function_name": "pandas.io.formats.style.Styler.to_string", "full_function": "Styler.to_string(buf=None, *, encoding=None, sparse_index=None, sparse_columns=None, max_rows=None, max_columns=None, delimiter=' ')", "function_text": "Write Styler to a file, buffer or string in text format.", "parameter_names_desc": [{"param_name": "buf", "param_type": "str, path object, file-like object, optional", "param_desc": "String, path object (implementing os.PathLike[str]), or file-like\nobject implementing a string write() function. If None, the result is\nreturned as a string.\n"}, {"param_name": "encoding", "param_type": "str, optional", "param_desc": "Character encoding setting for file output (and meta tags if available).\nDefaults to pandas.options.styler.render.encoding value of “utf-8”.\n"}, {"param_name": "sparse_index", "param_type": "bool, optional", "param_desc": "Whether to sparsify the display of a hierarchical index. Setting to False\nwill display each explicit level element in a hierarchical key for each row.\nDefaults to pandas.options.styler.sparse.index value.\n"}, {"param_name": "sparse_columns", "param_type": "bool, optional", "param_desc": "Whether to sparsify the display of a hierarchical index. Setting to False\nwill display each explicit level element in a hierarchical key for each\ncolumn. Defaults to pandas.options.styler.sparse.columns value.\n"}, {"param_name": "max_rows", "param_type": "int, optional", "param_desc": "The maximum number of rows that will be rendered. Defaults to\npandas.options.styler.render.max_rows, which is None.\n"}, {"param_name": "max_columns", "param_type": "int, optional", "param_desc": "The maximum number of columns that will be rendered. Defaults to\npandas.options.styler.render.max_columns, which is None.\nRows and columns may be reduced if the number of total elements is\nlarge. This value is set to pandas.options.styler.render.max_elements,\nwhich is 262144 (18 bit browser rendering).\n"}, {"param_name": "delimiter", "param_type": "str, default single space", "param_desc": "The separator between data elements.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.to_string.html#pandas.io.formats.style.Styler.to_string"}, {"function_name": "pandas.io.formats.style.Styler.use", "full_function": "Styler.use(styles)", "function_text": "Set the styles on the current Styler.", "parameter_names_desc": [{"param_name": "styles", "param_type": "dict(str, Any)", "param_desc": "\nList of attributes to add to Styler. Dict keys should contain only:\n“apply”: list of styler functions, typically added with apply or\nmap.\n“table_attributes”: HTML attributes, typically added with\nset_table_attributes.\n“table_styles”: CSS selectors and properties, typically added with\nset_table_styles.\n“hide_index”: whether the index is hidden, typically added with\nhide_index, or a boolean list for hidden levels.\n“hide_columns”: whether column headers are hidden, typically added with\nhide_columns, or a boolean list for hidden levels.\n“hide_index_names”: whether index names are hidden.\n“hide_column_names”: whether column header names are hidden.\n“css”: the css class names used.\n\n\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.use.html#pandas.io.formats.style.Styler.use"}]}], "name": "Style", "url": "https://pandas.pydata.org/docs/reference/style.html"}, "plotting.html": {"functions": [], "name": "Plotting", "url": "https://pandas.pydata.org/docs/reference/plotting.html"}, "options.html": {"functions": [{"name": "Working with options", "url": "https://pandas.pydata.org/docs/reference/options.html#working-with-options", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.describe_option.html#pandas.describe_option", "https://pandas.pydata.org/docs/reference/api/pandas.get_option.html#pandas.get_option", "https://pandas.pydata.org/docs/reference/api/pandas.option_context.html#pandas.option_context", "https://pandas.pydata.org/docs/reference/api/pandas.reset_option.html#pandas.reset_option", "https://pandas.pydata.org/docs/reference/api/pandas.set_option.html#pandas.set_option"], "function_definitions": [{"function_name": "pandas.describe_option", "full_function": "pandas.describe_option(pat, _print_desc=False) = <pandas._config.config.CallableDynamicDoc object>#", "function_text": "Prints the description for one or more registered options.", "parameter_names_desc": [{"param_name": "pat", "param_type": "str", "param_desc": "Regexp pattern. All matching keys will have their description displayed.\n"}, {"param_name": "_print_desc", "param_type": "bool, default True", "param_desc": "If True (default) the description(s) will be printed to stdout.\nOtherwise, the description(s) will be returned as a unicode string\n(for testing).\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.describe_option.html#pandas.describe_option"}, {"function_name": "pandas.get_option", "full_function": "pandas.get_option(pat) = <pandas._config.config.CallableDynamicDoc object>#", "function_text": "Retrieves the value of the specified option.", "parameter_names_desc": [{"param_name": "OptionError", "param_type": "if no such option exists", "param_desc": ""}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.get_option.html#pandas.get_option"}, {"function_name": "pandas.option_context", "full_function": "class pandas.option_context(*args)", "function_text": "Context manager to temporarily set options in the with statement context.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.option_context.html#pandas.option_context"}, {"function_name": "pandas.reset_option", "full_function": "pandas.reset_option(pat) = <pandas._config.config.CallableDynamicDoc object>#", "function_text": "Reset one or more options to their default value.", "parameter_names_desc": [{"param_name": "pat", "param_type": "str/regex", "param_desc": "If specified only options matching prefix* will be reset.\nNote: partial matches are supported for convenience, but unless you\nuse the full option name (e.g. x.y.z.option_name), your code may break\nin future versions if new options with similar names are introduced.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.reset_option.html#pandas.reset_option"}, {"function_name": "pandas.set_option", "full_function": "pandas.set_option(pat, value) = <pandas._config.config.CallableDynamicDoc object>#", "function_text": "Sets the value of the specified option.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.set_option.html#pandas.set_option"}]}, {"name": "Numeric formatting", "url": "https://pandas.pydata.org/docs/reference/options.html#numeric-formatting", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.set_eng_float_format.html#pandas.set_eng_float_format"], "function_definitions": [{"function_name": "pandas.set_eng_float_format", "full_function": "pandas.set_eng_float_format(accuracy=3, use_eng_prefix=False)", "function_text": "Format float representation in DataFrame with SI notation.", "parameter_names_desc": [{"param_name": "accuracy", "param_type": "int, default 3", "param_desc": "Number of decimal digits after the floating point.\n"}, {"param_name": "use_eng_prefix", "param_type": "bool, default False", "param_desc": "Whether to represent a value with SI prefixes.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.set_eng_float_format.html#pandas.set_eng_float_format"}]}], "name": "Options and settings", "url": "https://pandas.pydata.org/docs/reference/options.html"}, "extensions.html": {"functions": [], "name": "Extensions", "url": "https://pandas.pydata.org/docs/reference/extensions.html"}, "testing.html": {"functions": [{"name": "Assertion functions", "url": "https://pandas.pydata.org/docs/reference/testing.html#assertion-functions", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.testing.assert_frame_equal.html#pandas.testing.assert_frame_equal", "https://pandas.pydata.org/docs/reference/api/pandas.testing.assert_index_equal.html#pandas.testing.assert_index_equal", "https://pandas.pydata.org/docs/reference/api/pandas.testing.assert_series_equal.html#pandas.testing.assert_series_equal", "https://pandas.pydata.org/docs/reference/api/pandas.testing.assert_extension_array_equal.html#pandas.testing.assert_extension_array_equal"], "function_definitions": [{"function_name": "pandas.testing.assert_frame_equal", "full_function": "pandas.testing.assert_frame_equal(left, right, check_dtype=True, check_index_type='equiv', check_column_type='equiv', check_frame_type=True, check_names=True, by_blocks=False, check_exact=_NoDefault.no_default, check_datetimelike_compat=False, check_categorical=True, check_like=False, check_freq=True, check_flags=True, rtol=_NoDefault.no_default, atol=_NoDefault.no_default, obj='DataFrame')", "function_text": "Check that left and right DataFrame are equal.", "parameter_names_desc": [{"param_name": "left", "param_type": "DataFrame", "param_desc": "First DataFrame to compare.\n"}, {"param_name": "right", "param_type": "DataFrame", "param_desc": "Second DataFrame to compare.\n"}, {"param_name": "check_dtype", "param_type": "bool, default True", "param_desc": "Whether to check the DataFrame dtype is identical.\n"}, {"param_name": "check_index_type", "param_type": "bool or {‘equiv’}, default ‘equiv’", "param_desc": "Whether to check the Index class, dtype and inferred_type\nare identical.\n"}, {"param_name": "check_column_type", "param_type": "bool or {‘equiv’}, default ‘equiv’", "param_desc": "Whether to check the columns class, dtype and inferred_type\nare identical. Is passed as the exact argument of\nassert_index_equal().\n"}, {"param_name": "check_frame_type", "param_type": "bool, default True", "param_desc": "Whether to check the DataFrame class is identical.\n"}, {"param_name": "check_names", "param_type": "bool, default True", "param_desc": "Whether to check that the names attribute for both the index\nand column attributes of the DataFrame is identical.\n"}, {"param_name": "by_blocks", "param_type": "bool, default False", "param_desc": "Specify how to compare internal data. If False, compare by columns.\nIf True, compare by blocks.\n"}, {"param_name": "check_exact", "param_type": "bool, default False", "param_desc": "Whether to compare number exactly.\n\nChanged in version 2.2.0: Defaults to True for integer dtypes if none of\ncheck_exact, rtol and atol are specified.\n\n"}, {"param_name": "check_datetimelike_compat", "param_type": "bool, default False", "param_desc": "Compare datetime-like which is comparable ignoring dtype.\n"}, {"param_name": "check_categorical", "param_type": "bool, default True", "param_desc": "Whether to compare internal Categorical exactly.\n"}, {"param_name": "check_like", "param_type": "bool, default False", "param_desc": "If True, ignore the order of index & columns.\nNote: index labels must match their respective rows\n(same as in columns) - same labels must be with the same data.\n"}, {"param_name": "check_freq", "param_type": "bool, default True", "param_desc": "Whether to check the freq attribute on a DatetimeIndex or TimedeltaIndex.\n"}, {"param_name": "check_flags", "param_type": "bool, default True", "param_desc": "Whether to check the flags attribute.\n"}, {"param_name": "rtol", "param_type": "float, default 1e-5", "param_desc": "Relative tolerance. Only used when check_exact is False.\n"}, {"param_name": "atol", "param_type": "float, default 1e-8", "param_desc": "Absolute tolerance. Only used when check_exact is False.\n"}, {"param_name": "obj", "param_type": "str, default ‘DataFrame’", "param_desc": "Specify object name being compared, internally used to show appropriate\nassertion message.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.testing.assert_frame_equal.html#pandas.testing.assert_frame_equal"}, {"function_name": "pandas.testing.assert_index_equal", "full_function": "pandas.testing.assert_index_equal(left, right, exact='equiv', check_names=True, check_exact=True, check_categorical=True, check_order=True, rtol=1e-05, atol=1e-08, obj='Index')", "function_text": "Check that left and right Index are equal.", "parameter_names_desc": [{"param_name": "left", "param_type": "Index", "param_desc": ""}, {"param_name": "right", "param_type": "Index", "param_desc": ""}, {"param_name": "exact", "param_type": "bool or {‘equiv’}, default ‘equiv’", "param_desc": "Whether to check the Index class, dtype and inferred_type\nare identical. If ‘equiv’, then RangeIndex can be substituted for\nIndex with an int64 dtype as well.\n"}, {"param_name": "check_names", "param_type": "bool, default True", "param_desc": "Whether to check the names attribute.\n"}, {"param_name": "check_exact", "param_type": "bool, default True", "param_desc": "Whether to compare number exactly.\n"}, {"param_name": "check_categorical", "param_type": "bool, default True", "param_desc": "Whether to compare internal Categorical exactly.\n"}, {"param_name": "check_order", "param_type": "bool, default True", "param_desc": "Whether to compare the order of index entries as well as their values.\nIf True, both indexes must contain the same elements, in the same order.\nIf False, both indexes must contain the same elements, but in any order.\n"}, {"param_name": "rtol", "param_type": "float, default 1e-5", "param_desc": "Relative tolerance. Only used when check_exact is False.\n"}, {"param_name": "atol", "param_type": "float, default 1e-8", "param_desc": "Absolute tolerance. Only used when check_exact is False.\n"}, {"param_name": "obj", "param_type": "str, default ‘Index’", "param_desc": "Specify object name being compared, internally used to show appropriate\nassertion message.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.testing.assert_index_equal.html#pandas.testing.assert_index_equal"}, {"function_name": "pandas.testing.assert_series_equal", "full_function": "pandas.testing.assert_series_equal(left, right, check_dtype=True, check_index_type='equiv', check_series_type=True, check_names=True, check_exact=_NoDefault.no_default, check_datetimelike_compat=False, check_categorical=True, check_category_order=True, check_freq=True, check_flags=True, rtol=_NoDefault.no_default, atol=_NoDefault.no_default, obj='Series', *, check_index=True, check_like=False)", "function_text": "Check that left and right Series are equal.", "parameter_names_desc": [{"param_name": "left", "param_type": "Series", "param_desc": ""}, {"param_name": "right", "param_type": "Series", "param_desc": ""}, {"param_name": "check_dtype", "param_type": "bool, default True", "param_desc": "Whether to check the Series dtype is identical.\n"}, {"param_name": "check_index_type", "param_type": "bool or {‘equiv’}, default ‘equiv’", "param_desc": "Whether to check the Index class, dtype and inferred_type\nare identical.\n"}, {"param_name": "check_series_type", "param_type": "bool, default True", "param_desc": "Whether to check the Series class is identical.\n"}, {"param_name": "check_names", "param_type": "bool, default True", "param_desc": "Whether to check the Series and Index names attribute.\n"}, {"param_name": "check_exact", "param_type": "bool, default False", "param_desc": "Whether to compare number exactly.\n\nChanged in version 2.2.0: Defaults to True for integer dtypes if none of\ncheck_exact, rtol and atol are specified.\n\n"}, {"param_name": "check_datetimelike_compat", "param_type": "bool, default False", "param_desc": "Compare datetime-like which is comparable ignoring dtype.\n"}, {"param_name": "check_categorical", "param_type": "bool, default True", "param_desc": "Whether to compare internal Categorical exactly.\n"}, {"param_name": "check_category_order", "param_type": "bool, default True", "param_desc": "Whether to compare category order of internal Categoricals.\n"}, {"param_name": "check_freq", "param_type": "bool, default True", "param_desc": "Whether to check the freq attribute on a DatetimeIndex or TimedeltaIndex.\n"}, {"param_name": "check_flags", "param_type": "bool, default True", "param_desc": "Whether to check the flags attribute.\n"}, {"param_name": "rtol", "param_type": "float, default 1e-5", "param_desc": "Relative tolerance. Only used when check_exact is False.\n"}, {"param_name": "atol", "param_type": "float, default 1e-8", "param_desc": "Absolute tolerance. Only used when check_exact is False.\n"}, {"param_name": "obj", "param_type": "str, default ‘Series’", "param_desc": "Specify object name being compared, internally used to show appropriate\nassertion message.\n"}, {"param_name": "check_index", "param_type": "bool, default True", "param_desc": "Whether to check index equivalence. If False, then compare only values.\n\nNew in version 1.3.0.\n\n"}, {"param_name": "check_like", "param_type": "bool, default False", "param_desc": "If True, ignore the order of the index. Must be False if check_index is False.\nNote: same labels must be with the same data.\n\nNew in version 1.5.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.testing.assert_series_equal.html#pandas.testing.assert_series_equal"}, {"function_name": "pandas.testing.assert_extension_array_equal", "full_function": "pandas.testing.assert_extension_array_equal(left, right, check_dtype=True, index_values=None, check_exact=_NoDefault.no_default, rtol=_NoDefault.no_default, atol=_NoDefault.no_default, obj='ExtensionArray')", "function_text": "Check that left and right ExtensionArrays are equal.", "parameter_names_desc": [{"param_name": "left, right", "param_type": "ExtensionArray", "param_desc": "The two arrays to compare.\n"}, {"param_name": "check_dtype", "param_type": "bool, default True", "param_desc": "Whether to check if the ExtensionArray dtypes are identical.\n"}, {"param_name": "index_values", "param_type": "Index | numpy.ndarray, default None", "param_desc": "Optional index (shared by both left and right), used in output.\n"}, {"param_name": "check_exact", "param_type": "bool, default False", "param_desc": "Whether to compare number exactly.\n\nChanged in version 2.2.0: Defaults to True for integer dtypes if none of\ncheck_exact, rtol and atol are specified.\n\n"}, {"param_name": "rtol", "param_type": "float, default 1e-5", "param_desc": "Relative tolerance. Only used when check_exact is False.\n"}, {"param_name": "atol", "param_type": "float, default 1e-8", "param_desc": "Absolute tolerance. Only used when check_exact is False.\n"}, {"param_name": "obj", "param_type": "str, default ‘ExtensionArray’", "param_desc": "Specify object name being compared, internally used to show appropriate\nassertion message.\n\nNew in version 2.0.0.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.testing.assert_extension_array_equal.html#pandas.testing.assert_extension_array_equal"}]}, {"name": "Exceptions and warnings", "url": "https://pandas.pydata.org/docs/reference/testing.html#exceptions-and-warnings", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.errors.AbstractMethodError.html#pandas.errors.AbstractMethodError", "https://pandas.pydata.org/docs/reference/api/pandas.errors.CategoricalConversionWarning.html#pandas.errors.CategoricalConversionWarning", "https://pandas.pydata.org/docs/reference/api/pandas.errors.ClosedFileError.html#pandas.errors.ClosedFileError", "https://pandas.pydata.org/docs/reference/api/pandas.errors.DatabaseError.html#pandas.errors.DatabaseError", "https://pandas.pydata.org/docs/reference/api/pandas.errors.DtypeWarning.html#pandas.errors.DtypeWarning", "https://pandas.pydata.org/docs/reference/api/pandas.errors.EmptyDataError.html#pandas.errors.EmptyDataError", "https://pandas.pydata.org/docs/reference/api/pandas.errors.IndexingError.html#pandas.errors.IndexingError", "https://pandas.pydata.org/docs/reference/api/pandas.errors.InvalidComparison.html#pandas.errors.InvalidComparison", "https://pandas.pydata.org/docs/reference/api/pandas.errors.InvalidVersion.html#pandas.errors.InvalidVersion", "https://pandas.pydata.org/docs/reference/api/pandas.errors.LossySetitemError.html#pandas.errors.LossySetitemError", "https://pandas.pydata.org/docs/reference/api/pandas.errors.NoBufferPresent.html#pandas.errors.NoBufferPresent", "https://pandas.pydata.org/docs/reference/api/pandas.errors.NumbaUtilError.html#pandas.errors.NumbaUtilError", "https://pandas.pydata.org/docs/reference/api/pandas.errors.OptionError.html#pandas.errors.OptionError", "https://pandas.pydata.org/docs/reference/api/pandas.errors.OutOfBoundsTimedelta.html#pandas.errors.OutOfBoundsTimedelta", "https://pandas.pydata.org/docs/reference/api/pandas.errors.ParserWarning.html#pandas.errors.ParserWarning", "https://pandas.pydata.org/docs/reference/api/pandas.errors.PossibleDataLossError.html#pandas.errors.PossibleDataLossError", "https://pandas.pydata.org/docs/reference/api/pandas.errors.PyperclipException.html#pandas.errors.PyperclipException", "https://pandas.pydata.org/docs/reference/api/pandas.errors.SettingWithCopyError.html#pandas.errors.SettingWithCopyError", "https://pandas.pydata.org/docs/reference/api/pandas.errors.SpecificationError.html#pandas.errors.SpecificationError", "https://pandas.pydata.org/docs/reference/api/pandas.errors.UnsortedIndexError.html#pandas.errors.UnsortedIndexError", "https://pandas.pydata.org/docs/reference/api/pandas.errors.ValueLabelTypeMismatch.html#pandas.errors.ValueLabelTypeMismatch", "https://pandas.pydata.org/docs/reference/api/pandas.errors.AttributeConflictWarning.html#pandas.errors.AttributeConflictWarning", "https://pandas.pydata.org/docs/reference/api/pandas.errors.ChainedAssignmentError.html#pandas.errors.ChainedAssignmentError", "https://pandas.pydata.org/docs/reference/api/pandas.errors.CSSWarning.html#pandas.errors.CSSWarning", "https://pandas.pydata.org/docs/reference/api/pandas.errors.DataError.html#pandas.errors.DataError", "https://pandas.pydata.org/docs/reference/api/pandas.errors.DuplicateLabelError.html#pandas.errors.DuplicateLabelError", "https://pandas.pydata.org/docs/reference/api/pandas.errors.IncompatibilityWarning.html#pandas.errors.IncompatibilityWarning", "https://pandas.pydata.org/docs/reference/api/pandas.errors.InvalidColumnName.html#pandas.errors.InvalidColumnName", "https://pandas.pydata.org/docs/reference/api/pandas.errors.InvalidIndexError.html#pandas.errors.InvalidIndexError", "https://pandas.pydata.org/docs/reference/api/pandas.errors.IntCastingNaNError.html#pandas.errors.IntCastingNaNError", "https://pandas.pydata.org/docs/reference/api/pandas.errors.MergeError.html#pandas.errors.MergeError", "https://pandas.pydata.org/docs/reference/api/pandas.errors.NullFrequencyError.html#pandas.errors.NullFrequencyError", "https://pandas.pydata.org/docs/reference/api/pandas.errors.NumExprClobberingError.html#pandas.errors.NumExprClobberingError", "https://pandas.pydata.org/docs/reference/api/pandas.errors.OutOfBoundsDatetime.html#pandas.errors.OutOfBoundsDatetime", "https://pandas.pydata.org/docs/reference/api/pandas.errors.ParserError.html#pandas.errors.ParserError", "https://pandas.pydata.org/docs/reference/api/pandas.errors.PerformanceWarning.html#pandas.errors.PerformanceWarning", "https://pandas.pydata.org/docs/reference/api/pandas.errors.PossiblePrecisionLoss.html#pandas.errors.PossiblePrecisionLoss", "https://pandas.pydata.org/docs/reference/api/pandas.errors.PyperclipWindowsException.html#pandas.errors.PyperclipWindowsException", "https://pandas.pydata.org/docs/reference/api/pandas.errors.SettingWithCopyWarning.html#pandas.errors.SettingWithCopyWarning", "https://pandas.pydata.org/docs/reference/api/pandas.errors.UndefinedVariableError.html#pandas.errors.UndefinedVariableError", "https://pandas.pydata.org/docs/reference/api/pandas.errors.UnsupportedFunctionCall.html#pandas.errors.UnsupportedFunctionCall"], "function_definitions": [{"function_name": "pandas.errors.AbstractMethodError", "full_function": "exception pandas.errors.AbstractMethodError(class_instance, methodtype='method')", "function_text": "Raise this error instead of NotImplementedError for abstract methods.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.AbstractMethodError.html#pandas.errors.AbstractMethodError"}, {"function_name": "pandas.errors.CategoricalConversionWarning", "full_function": "exception pandas.errors.CategoricalConversionWarning", "function_text": "Warning is raised when reading a partial labeled Stata file using a iterator.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.CategoricalConversionWarning.html#pandas.errors.CategoricalConversionWarning"}, {"function_name": "pandas.errors.ClosedFileError", "full_function": "exception pandas.errors.ClosedFileError", "function_text": "Exception is raised when trying to perform an operation on a closed HDFStore file.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.ClosedFileError.html#pandas.errors.ClosedFileError"}, {"function_name": "pandas.errors.DatabaseError", "full_function": "exception pandas.errors.DatabaseError", "function_text": "Error is raised when executing sql with bad syntax or sql that throws an error.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.DatabaseError.html#pandas.errors.DatabaseError"}, {"function_name": "pandas.errors.DtypeWarning", "full_function": "exception pandas.errors.DtypeWarning", "function_text": "Warning raised when reading different dtypes in a column from a file.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.DtypeWarning.html#pandas.errors.DtypeWarning"}, {"function_name": "pandas.errors.EmptyDataError", "full_function": "exception pandas.errors.EmptyDataError", "function_text": "Exception raised in pd.read_csv when empty data or header is encountered.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.EmptyDataError.html#pandas.errors.EmptyDataError"}, {"function_name": "pandas.errors.IndexingError", "full_function": "exception pandas.errors.IndexingError", "function_text": "Exception is raised when trying to index and there is a mismatch in dimensions.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.IndexingError.html#pandas.errors.IndexingError"}, {"function_name": "pandas.errors.InvalidComparison", "full_function": "exception pandas.errors.InvalidComparison", "function_text": "Exception is raised by _validate_comparison_value to indicate an invalid comparison.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.InvalidComparison.html#pandas.errors.InvalidComparison"}, {"function_name": "pandas.errors.InvalidVersion", "full_function": "exception pandas.errors.InvalidVersion", "function_text": "An invalid version was found, users should refer to PEP 440.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.InvalidVersion.html#pandas.errors.InvalidVersion"}, {"function_name": "pandas.errors.LossySetitemError", "full_function": "exception pandas.errors.LossySetitemError", "function_text": "Raised when trying to do a __setitem__ on an np.ndarray that is not lossless.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.LossySetitemError.html#pandas.errors.LossySetitemError"}, {"function_name": "pandas.errors.NoBufferPresent", "full_function": "exception pandas.errors.NoBufferPresent", "function_text": "Exception is raised in _get_data_buffer to signal that there is no requested buffer.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.NoBufferPresent.html#pandas.errors.NoBufferPresent"}, {"function_name": "pandas.errors.NumbaUtilError", "full_function": "exception pandas.errors.NumbaUtilError", "function_text": "Error raised for unsupported Numba engine routines.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.NumbaUtilError.html#pandas.errors.NumbaUtilError"}, {"function_name": "pandas.errors.OptionError", "full_function": "exception pandas.errors.OptionError", "function_text": "Exception raised for pandas.options.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.OptionError.html#pandas.errors.OptionError"}, {"function_name": "pandas.errors.OutOfBoundsTimedelta", "full_function": "exception pandas.errors.OutOfBoundsTimedelta#", "function_text": "Raised when encountering a timedelta value that cannot be represented.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.OutOfBoundsTimedelta.html#pandas.errors.OutOfBoundsTimedelta"}, {"function_name": "pandas.errors.ParserWarning", "full_function": "exception pandas.errors.ParserWarning", "function_text": "Warning raised when reading a file that doesn’t use the default ‘c’ parser.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.ParserWarning.html#pandas.errors.ParserWarning"}, {"function_name": "pandas.errors.PossibleDataLossError", "full_function": "exception pandas.errors.PossibleDataLossError", "function_text": "Exception raised when trying to open a HDFStore file when already opened.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.PossibleDataLossError.html#pandas.errors.PossibleDataLossError"}, {"function_name": "pandas.errors.PyperclipException", "full_function": "exception pandas.errors.PyperclipException", "function_text": "Exception raised when clipboard functionality is unsupported.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.PyperclipException.html#pandas.errors.PyperclipException"}, {"function_name": "pandas.errors.SettingWithCopyError", "full_function": "exception pandas.errors.SettingWithCopyError", "function_text": "Exception raised when trying to set on a copied slice from a DataFrame.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.SettingWithCopyError.html#pandas.errors.SettingWithCopyError"}, {"function_name": "pandas.errors.SpecificationError", "full_function": "exception pandas.errors.SpecificationError", "function_text": "Exception raised by agg when the functions are ill-specified.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.SpecificationError.html#pandas.errors.SpecificationError"}, {"function_name": "pandas.errors.UnsortedIndexError", "full_function": "exception pandas.errors.UnsortedIndexError", "function_text": "Error raised when slicing a MultiIndex which has not been lexsorted.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.UnsortedIndexError.html#pandas.errors.UnsortedIndexError"}, {"function_name": "pandas.errors.ValueLabelTypeMismatch", "full_function": "exception pandas.errors.ValueLabelTypeMismatch", "function_text": "Warning raised by to_stata on a category column that contains non-string values.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.ValueLabelTypeMismatch.html#pandas.errors.ValueLabelTypeMismatch"}, {"function_name": "pandas.errors.AttributeConflictWarning", "full_function": "exception pandas.errors.AttributeConflictWarning", "function_text": "Warning raised when index attributes conflict when using HDFStore.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.AttributeConflictWarning.html#pandas.errors.AttributeConflictWarning"}, {"function_name": "pandas.errors.ChainedAssignmentError", "full_function": "exception pandas.errors.ChainedAssignmentError", "function_text": "Warning raised when trying to set using chained assignment.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.ChainedAssignmentError.html#pandas.errors.ChainedAssignmentError"}, {"function_name": "pandas.errors.CSSWarning", "full_function": "exception pandas.errors.CSSWarning", "function_text": "Warning is raised when converting css styling fails.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.CSSWarning.html#pandas.errors.CSSWarning"}, {"function_name": "pandas.errors.DataError", "full_function": "exception pandas.errors.DataError", "function_text": "Exceptionn raised when performing an operation on non-numerical data.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.DataError.html#pandas.errors.DataError"}, {"function_name": "pandas.errors.DuplicateLabelError", "full_function": "exception pandas.errors.DuplicateLabelError", "function_text": "Error raised when an operation would introduce duplicate labels.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.DuplicateLabelError.html#pandas.errors.DuplicateLabelError"}, {"function_name": "pandas.errors.IncompatibilityWarning", "full_function": "exception pandas.errors.IncompatibilityWarning", "function_text": "Warning raised when trying to use where criteria on an incompatible HDF5 file.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.IncompatibilityWarning.html#pandas.errors.IncompatibilityWarning"}, {"function_name": "pandas.errors.InvalidColumnName", "full_function": "exception pandas.errors.InvalidColumnName", "function_text": "Warning raised by to_stata the column contains a non-valid stata name.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.InvalidColumnName.html#pandas.errors.InvalidColumnName"}, {"function_name": "pandas.errors.InvalidIndexError", "full_function": "exception pandas.errors.InvalidIndexError", "function_text": "Exception raised when attempting to use an invalid index key.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.InvalidIndexError.html#pandas.errors.InvalidIndexError"}, {"function_name": "pandas.errors.IntCastingNaNError", "full_function": "exception pandas.errors.IntCastingNaNError", "function_text": "Exception raised when converting (astype) an array with NaN to an integer type.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.IntCastingNaNError.html#pandas.errors.IntCastingNaNError"}, {"function_name": "pandas.errors.MergeError", "full_function": "exception pandas.errors.MergeError", "function_text": "Exception raised when merging data.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.MergeError.html#pandas.errors.MergeError"}, {"function_name": "pandas.errors.NullFrequencyError", "full_function": "exception pandas.errors.NullFrequencyError", "function_text": "Exception raised when a freq cannot be null.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.NullFrequencyError.html#pandas.errors.NullFrequencyError"}, {"function_name": "pandas.errors.NumExprClobberingError", "full_function": "exception pandas.errors.NumExprClobberingError", "function_text": "Exception raised when trying to use a built-in numexpr name as a variable name.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.NumExprClobberingError.html#pandas.errors.NumExprClobberingError"}, {"function_name": "pandas.errors.OutOfBoundsDatetime", "full_function": "exception pandas.errors.OutOfBoundsDatetime#", "function_text": "Raised when the datetime is outside the range that can be represented.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.OutOfBoundsDatetime.html#pandas.errors.OutOfBoundsDatetime"}, {"function_name": "pandas.errors.ParserError", "full_function": "exception pandas.errors.ParserError", "function_text": "Exception that is raised by an error encountered in parsing file contents.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.ParserError.html#pandas.errors.ParserError"}, {"function_name": "pandas.errors.PerformanceWarning", "full_function": "exception pandas.errors.PerformanceWarning", "function_text": "Warning raised when there is a possible performance impact.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.PerformanceWarning.html#pandas.errors.PerformanceWarning"}, {"function_name": "pandas.errors.PossiblePrecisionLoss", "full_function": "exception pandas.errors.PossiblePrecisionLoss", "function_text": "Warning raised by to_stata on a column with a value outside or equal to int64.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.PossiblePrecisionLoss.html#pandas.errors.PossiblePrecisionLoss"}, {"function_name": "pandas.errors.PyperclipWindowsException", "full_function": "exception pandas.errors.PyperclipWindowsException(message)", "function_text": "Exception raised when clipboard functionality is unsupported by Windows.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.PyperclipWindowsException.html#pandas.errors.PyperclipWindowsException"}, {"function_name": "pandas.errors.SettingWithCopyWarning", "full_function": "exception pandas.errors.SettingWithCopyWarning", "function_text": "Warning raised when trying to set on a copied slice from a DataFrame.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.SettingWithCopyWarning.html#pandas.errors.SettingWithCopyWarning"}, {"function_name": "pandas.errors.UndefinedVariableError", "full_function": "exception pandas.errors.UndefinedVariableError(name, is_local=None)", "function_text": "Exception raised by query or eval when using an undefined variable name.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.UndefinedVariableError.html#pandas.errors.UndefinedVariableError"}, {"function_name": "pandas.errors.UnsupportedFunctionCall", "full_function": "exception pandas.errors.UnsupportedFunctionCall", "function_text": "Exception raised when attempting to call a unsupported numpy function.", "parameter_names_desc": [], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.errors.UnsupportedFunctionCall.html#pandas.errors.UnsupportedFunctionCall"}]}, {"name": "Bug report function", "url": "https://pandas.pydata.org/docs/reference/testing.html#bug-report-function", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.show_versions.html#pandas.show_versions"], "function_definitions": [{"function_name": "pandas.show_versions", "full_function": "pandas.show_versions(as_json=False)", "function_text": "Provide useful information, important for bug reports.", "parameter_names_desc": [{"param_name": "as_json", "param_type": "str or bool, default False", "param_desc": "\nIf False, outputs info in a human readable form to the console.\nIf str, it will be considered as a path to a file.\nInfo will be written to that file in JSON format.\nIf True, outputs info in JSON format to the console.\n\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.show_versions.html#pandas.show_versions"}]}, {"name": "Test suite runner", "url": "https://pandas.pydata.org/docs/reference/testing.html#test-suite-runner", "function_urls": ["https://pandas.pydata.org/docs/reference/api/pandas.test.html#pandas.test"], "function_definitions": [{"function_name": "pandas.test", "full_function": "pandas.test(extra_args=None, run_doctests=False)", "function_text": "Run the pandas test suite using pytest.", "parameter_names_desc": [{"param_name": "extra_args", "param_type": "list[str], default None", "param_desc": "Extra marks to run the tests.\n"}, {"param_name": "run_doctests", "param_type": "bool, default False", "param_desc": "Whether to only run the Python and Cython doctests. If you would like to run\nboth doctests/regular tests, just append “–doctest-modules”/”–doctest-cython”\nto extra_args.\n"}], "function_url": "https://pandas.pydata.org/docs/reference/api/pandas.test.html#pandas.test"}]}], "name": "Testing", "url": "https://pandas.pydata.org/docs/reference/testing.html"}, "missing_value.html": {"functions": [], "name": "Missing values", "url": "https://pandas.pydata.org/docs/reference/missing_value.html"}, "api/pandas.tseries.frequencies.to_offset.html": {"functions": [], "name": "pandas.tseries.frequencies.to_offset", "url": "https://pandas.pydata.org/docs/reference/api/pandas.tseries.frequencies.to_offset.html"}, "api/pandas.plotting.andrews_curves.html": {"functions": [], "name": "pandas.plotting.andrews_curves", "url": "https://pandas.pydata.org/docs/reference/api/pandas.plotting.andrews_curves.html"}, "api/pandas.plotting.autocorrelation_plot.html": {"functions": [], "name": "pandas.plotting.autocorrelation_plot", "url": "https://pandas.pydata.org/docs/reference/api/pandas.plotting.autocorrelation_plot.html"}, "api/pandas.plotting.bootstrap_plot.html": {"functions": [], "name": "pandas.plotting.bootstrap_plot", "url": "https://pandas.pydata.org/docs/reference/api/pandas.plotting.bootstrap_plot.html"}, "api/pandas.plotting.boxplot.html": {"functions": [], "name": "pandas.plotting.boxplot", "url": "https://pandas.pydata.org/docs/reference/api/pandas.plotting.boxplot.html"}, "api/pandas.plotting.deregister_matplotlib_converters.html": {"functions": [], "name": "pandas.plotting.deregister_matplotlib_converters", "url": "https://pandas.pydata.org/docs/reference/api/pandas.plotting.deregister_matplotlib_converters.html"}, "api/pandas.plotting.lag_plot.html": {"functions": [], "name": "pandas.plotting.lag_plot", "url": "https://pandas.pydata.org/docs/reference/api/pandas.plotting.lag_plot.html"}, "api/pandas.plotting.parallel_coordinates.html": {"functions": [], "name": "pandas.plotting.parallel_coordinates", "url": "https://pandas.pydata.org/docs/reference/api/pandas.plotting.parallel_coordinates.html"}, "api/pandas.plotting.plot_params.html": {"functions": [], "name": "pandas.plotting.plot_params", "url": "https://pandas.pydata.org/docs/reference/api/pandas.plotting.plot_params.html"}, "api/pandas.plotting.radviz.html": {"functions": [], "name": "pandas.plotting.radviz", "url": "https://pandas.pydata.org/docs/reference/api/pandas.plotting.radviz.html"}, "api/pandas.plotting.register_matplotlib_converters.html": {"functions": [], "name": "pandas.plotting.register_matplotlib_converters", "url": "https://pandas.pydata.org/docs/reference/api/pandas.plotting.register_matplotlib_converters.html"}, "api/pandas.plotting.scatter_matrix.html": {"functions": [], "name": "pandas.plotting.scatter_matrix", "url": "https://pandas.pydata.org/docs/reference/api/pandas.plotting.scatter_matrix.html"}, "api/pandas.plotting.table.html": {"functions": [], "name": "pandas.plotting.table", "url": "https://pandas.pydata.org/docs/reference/api/pandas.plotting.table.html"}, "api/pandas.api.extensions.register_extension_dtype.html": {"functions": [], "name": "pandas.api.extensions.register_extension_dtype", "url": "https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.register_extension_dtype.html"}, "api/pandas.api.extensions.register_dataframe_accessor.html": {"functions": [], "name": "pandas.api.extensions.register_dataframe_accessor", "url": "https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.register_dataframe_accessor.html"}, "api/pandas.api.extensions.register_series_accessor.html": {"functions": [], "name": "pandas.api.extensions.register_series_accessor", "url": "https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.register_series_accessor.html"}, "api/pandas.api.extensions.register_index_accessor.html": {"functions": [], "name": "pandas.api.extensions.register_index_accessor", "url": "https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.register_index_accessor.html"}, "api/pandas.api.extensions.ExtensionDtype.html": {"functions": [], "name": "pandas.api.extensions.ExtensionDtype", "url": "https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionDtype.html"}, "api/pandas.api.extensions.ExtensionArray.html": {"functions": [], "name": "pandas.api.extensions.ExtensionArray", "url": "https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray.html"}, "api/pandas.arrays.NumpyExtensionArray.html": {"functions": [], "name": "pandas.arrays.NumpyExtensionArray", "url": "https://pandas.pydata.org/docs/reference/api/pandas.arrays.NumpyExtensionArray.html"}, "api/pandas.api.indexers.check_array_indexer.html": {"functions": [], "name": "pandas.api.indexers.check_array_indexer", "url": "https://pandas.pydata.org/docs/reference/api/pandas.api.indexers.check_array_indexer.html"}, "api/pandas.NA.html": {"functions": [], "name": "pandas.NA", "url": "https://pandas.pydata.org/docs/reference/api/pandas.NA.html"}, "api/pandas.NaT.html": {"functions": [], "name": "pandas.NaT", "url": "https://pandas.pydata.org/docs/reference/api/pandas.NaT.html"}}